- en: 9 Train, Validate, Test
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 训练、验证、测试
- en: 原文：[https://mlbook.explained.ai/bulldozer-testing.html](https://mlbook.explained.ai/bulldozer-testing.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mlbook.explained.ai/bulldozer-testing.html](https://mlbook.explained.ai/bulldozer-testing.html)
- en: '[Terence Parr](http://parrt.cs.usfca.edu) and [Jeremy Howard](http://www.fast.ai/about/#jeremy)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[特伦斯·帕特](http://parrt.cs.usfca.edu) 和 [杰里米·霍华德](http://www.fast.ai/about/#jeremy)'
- en: Copyright © 2018-2019 Terence Parr. All rights reserved.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 版权所有 © 2018-2019 特伦斯·帕特。保留所有权利。
- en: '*Please don''t replicate on web or redistribute in any way.*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*请勿在网络上复制或以任何方式重新分发。*'
- en: This book generated from markup+markdown+python+latex source with [Bookish](https://github.com/parrt/bookish).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是从 markup+markdown+python+latex 源代码生成的，使用了[Bookish](https://github.com/parrt/bookish)。
- en: You can make **comments or annotate** this page by going to the annotated version
    of this page. You'll see existing annotated bits highlighted in yellow. They are
    *PUBLICLY VISIBLE*. Or, you can send comments, suggestions, or fixes directly
    to [Terence](mailto:parrt@cs.usfca.edu).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过访问此页面的注释版本来**评论或注释**此页。您会看到现有的注释部分以黄色突出显示。它们是**公开可见的**。或者，您可以直接将评论、建议或修复发送到[特伦斯](mailto:parrt@cs.usfca.edu)。
- en: Contents
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 目录
- en: '[The testing trilogy](#sec:trilogy)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[测试三部曲](#sec:trilogy)'
- en: '[Splitting time-insensitive datasets](#sec:split-time-insens)'
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分割对时间不敏感的数据集](#sec:split-time-insens)'
- en: '[Splitting time-sensitive datasets](#sec:9.1.2)'
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分割对时间敏感的数据集](#sec:9.1.2)'
- en: '[Rectifying training and validation sets](#sec:rectifying)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[校正训练和验证集](#sec:rectifying)'
- en: '[Preparing the training set](#sec:9.2.1)'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[准备训练集](#sec:9.2.1)'
- en: '[Preparing consistent training and validation sets](#sec:9.2.2)'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[准备一致的训练和验证集](#sec:9.2.2)'
- en: '[Getting baseline validation metrics](#sec:9.2.3)'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[获得基线验证指标](#sec:9.2.3)'
- en: '[Tuning a Random Forest model](#sec:tuning)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调整随机森林模型](#sec:tuning)'
- en: '[Choosing a time-sensitive training set](#sec:9.3.1)'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[选择对时间敏感的训练集](#sec:9.3.1)'
- en: '[Choosing max_features and min_samples_leaf](#sec:9.3.2)'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[选择max_features和min_samples_leaf](#sec:9.3.2)'
- en: '[Dropping irrelevant features](#sec:9.3.3)'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[删除无关特征](#sec:9.3.3)'
- en: '[Adjusting prices for inflation](#sec:9.3.4)'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调整通货膨胀价格](#sec:9.3.4)'
- en: '[Getting a true measure of generality](#sec:test-set)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[获得真正的泛化度量](#sec:test-set)'
- en: '[Summary](#sec:9.5)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[摘要](#sec:9.5)'
- en: 'Being able to properly measure the accuracy of a model is a critical skill
    for a machine learning practitioner, and the goal of this chapter is to acquire
    that skill by applying it to our bulldozer dataset. Evaluating the accuracy of
    a model requires two key elements:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 能够正确测量模型的准确度是机器学习从业者的一项关键技能，本章的目标是通过将其应用于我们的推土机数据集来获得这项技能。评估模型的准确度需要两个关键要素：
- en: a metric that quantifies accuracy between predicted and true values
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个量化预测值和真实值之间准确度的指标
- en: a set of observations outside of the training data whose predictions are tested
    by the metric
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一组位于训练数据之外的观察结果，其预测值由该指标进行测试
- en: Models that perform poorly on training data will never generalize well to data
    they have never seen. Models that perform well on training data might or might
    not generalize well.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练数据上表现不佳的模型永远不会很好地泛化到他们从未见过的数据。在训练数据上表现良好的模型可能或可能不会很好地泛化。
- en: '**Section 5.2** *Training and evaluating an initial model* introduced the ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    and MAE (mean absolute value) metrics, and we''ll explore more metrics in **Chapter
    11** *Measuring regression model performance*. In **Section 3.2.4** *Checking
    model generality*, we separated validation data from training data because we
    care about a model''s performance on future observations, not how well it does
    on its own training data.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**第5.2节** *训练和评估初始模型*介绍了![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)和MAE（平均绝对值）指标，我们将在**第11章**
    *测量回归模型性能*中探讨更多指标。在**第3.2.4节** *检查模型泛化性*中，我们将验证数据与训练数据分开，因为我们关心模型对未来观察结果的表现，而不是它在自身训练数据上的表现。'
- en: Keeping separate training and validation sets can be a hassle, though, as we'll
    see in this chapter. To avoid the hassle so far, we've been using the RF model's
    handy OOB (out-of-bag) samples as a substitute for a validation set. In general,
    accuracy metrics derived from the OOB samples are excellent estimates of the true
    validation scores but only for time-insensitive data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，保持独立的训练和验证集可能会很麻烦，正如我们在本章中将会看到的。为了避免这些麻烦，到目前为止，我们一直在使用RF模型的便捷的OOB（袋外）样本作为验证集的替代品。一般来说，从OOB样本中得出的准确度指标是真实验证分数的优秀估计，但仅适用于对时间不敏感的数据。
- en: 2Linear regression models, on the other hand, do assume a linear relationship
    between features and price, which allows them to extrapolate.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 2 线性回归模型另一方面，确实假设了特征和价格之间的线性关系，这使得它们可以进行外推。
- en: Time-sensitive datasets, such as the bulldozer dataset, can look very different
    depending on the time period. Inflation alone means that future prices far beyond
    the training period will be much higher. An RF bulldozer price predictor trained
    on data from years 2000-2005 won't make accurate predictions for bulldozers sold
    in 2020\. Metrics derived from OOB samples are, therefore, overly optimistic about
    the generality of a model and how it will perform on future predictions. Per **Section
    3.4.3** *Comparing the digit classifier's performance to a linear model*, RF models
    make no assumption about the underlying relationship between features and target
    variable, which means that RFs cannot extrapolate beyond the range of their training
    experience.2 See also Rachel Thomas' [How (and why) to create a good validation
    set](https://www.fast.ai/2017/11/13/validation-sets/) article.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 时间敏感的数据集，如推土机数据集，根据时间段的不同可能看起来非常不同。仅通货膨胀就意味着未来的价格将远远高于训练期。在2000-2005年期间训练的RF推土机价格预测器不会对2020年销售的推土机做出准确的预测。因此，从OOB样本中得出的指标对模型的泛化能力和未来预测的表现过于乐观。根据**第3.4.3节**
    *将数字分类器的性能与线性模型进行比较*，RF模型对特征和目标变量之间的潜在关系没有任何假设，这意味着RF不能超出其训练经验的范围进行外推。2 参见Rachel
    Thomas的[如何（以及为什么）创建一个好的验证集](https://www.fast.ai/2017/11/13/validation-sets/)文章。
- en: That means we must obtain a validation set beyond the date range of the training
    set in order to properly measure an RF's accuracy on time-sensitive data. We'll
    kick off this chapter by splitting off a validation set in **Section 9.1** *The
    testing trilogy*. Unfortunately, measuring accuracy with a separate validation
    set triggers a bit of unpleasantness, which we'll experience in **Section 9.2**
    *Rectifying training and validation sets*. In a nutshell, we have to make sure
    that categories in training and validation sets use the same encoding and that
    missing numeric values are filled in with medians computed only from the training
    set. Once we have a useful measure of accuracy via the validation set, we'll tune
    our model to improve its accuracy and generality in **Section 9.3** *Tuning a
    Random Forest model*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们必须获得一个验证集，它超出了训练集的日期范围，以便正确测量RF在时间敏感数据上的准确性。我们将通过在**第9.1节** *测试三部曲*中分割出一个验证集来开始本章。不幸的是，使用单独的验证集来衡量准确性会引发一些不愉快的事情，我们将在**第9.2节**
    *校正训练集和验证集*中体验到这一点。简而言之，我们必须确保训练集和验证集中的类别使用相同的编码，并且缺失的数值值必须用仅从训练集计算出的中位数填充。一旦我们通过验证集获得了一个有用的准确性度量，我们将在**第9.3节**
    *调整随机森林模型*中调整我们的模型以提高其准确性和泛化能力。
- en: The final step in our model development process is to evaluate the performance
    of the model on a test set, which we'll do in **Section 9.4** *Getting a true
    measure of generality*. The test set is outside of the training set, like the
    validation set, but must be hidden away and never run through intermediate models.
    The metric reported by this final test is the only objective estimate of a model's
    generality.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型开发过程的最后一步是在测试集上评估模型的性能，我们将在**第9.4节** *获得真正的泛化度量*中这样做。测试集与验证集一样，位于训练集之外，但必须隐藏起来，并且永远不要通过中间模型运行。这个最终测试报告的指标是模型泛化能力的唯一客观估计。
- en: 9.1 The testing trilogy
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 测试三部曲
- en: The only true measure of model generality comes from computing metrics on a
    test set that has never previously been run through the model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型泛化的唯一真正度量来自于在从未通过模型运行过的测试集上计算指标。
- en: 'Developing a machine learning model requires three sets of observations: training,
    validation, and test sets. The model trains just on the training set and model
    accuracy is evaluated using the validation set during development. After tuning
    the model on the validation set, we run the test set through the model to get
    our final measure of model accuracy and generality. If we peek at the test set
    and run it through an intermediate model rather than our final model, the test
    set becomes just another validation set. Every change made to a model after testing
    it on a dataset, tailors the model to that dataset; that dataset is no longer
    an objective measure of generality.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 开发一个机器学习模型需要三组观察数据：训练集、验证集和测试集。模型仅在训练集上训练，并在开发过程中使用验证集来评估模型精度。在验证集上调整模型后，我们将测试集通过模型运行以获取模型精度和泛化能力的最终度量。如果我们查看测试集并通过一个中间模型而不是最终模型运行它，测试集就变成了另一个验证集。在数据集上测试模型后对模型所做的任何更改，都会使模型适应该数据集；该数据集就不再是泛化能力的客观度量。
- en: To develop a model in practice, we're usually given a single dataset, rather
    than separate training, validation, and test sets. That means we need a general
    procedure for splitting datasets appropriately.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中开发模型时，我们通常只得到一个数据集，而不是分开的训练、验证和测试集。这意味着我们需要一个通用的程序来适当地分割数据集。
- en: 9.1.1 Splitting time-insensitive datasets
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 分割时间不敏感的数据集
- en: 'For datasets that do not change significantly over the time period of interest,
    we want to extract validation and test sets using random sampling of records.
    This is called the *holdout method*. To get (roughly) 70% of dataframe `df` into
    training and 15% into both validation and test sets, we can do this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在感兴趣的时间段内变化不大的数据集，我们希望使用记录的随机抽样来提取验证集和测试集。这被称为**保留法**。为了将大约70%的数据框`df`用于训练，15%用于验证和测试集，我们可以这样做：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Note**: Squirrel away the `df_test` testing subset in a vault for a single
    use during final testing.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：将`df_test`测试子集存放在保险库中，以便在最终测试时单次使用。'
- en: After training a model using `df_train`, we'd run `df_valid` data through the
    model and compute a metric, such as ![](../Images/ec985123b9b52e80981e6500795e8d16.png).
    Then we'd tune the model so that it's more accurate on `df_valid` data. When we're
    happy with the model, we'd finally use `df_test` to measure generality.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`df_train`训练模型后，我们会将`df_valid`数据通过模型运行并计算一个指标，例如![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)。然后我们会调整模型，使其在`df_valid`数据上更准确。当我们对模型满意时，我们最终会使用`df_test`来衡量泛化能力。
- en: Because we're selecting validation and test sets randomly, it's possible that
    the sets will contain a disproportionate number of outlier records, such as really
    expensive bulldozers. Such tests are not representative and yield pessimistic
    accuracy metrics. Running the split-train-validate sequence in a loop, would extract
    different subsets each time and the resulting accuracy metrics would fluctuate.
    (Note that only the highlighted `train_test_split()` line would be part of the
    loop; never recompute `df_test`.) A good strategy then would be to take the average
    accuracy metric over several runs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是随机选择验证集和测试集，这些集可能包含不成比例的异常记录，例如非常昂贵的推土机。这样的测试不具有代表性，并产生悲观的精度指标。循环运行拆分-训练-验证序列，每次都会提取不同的子集，并且产生的精度指标会波动。（注意，只有突出显示的`train_test_split()`行将是循环的一部分；永远不要重新计算`df_test`。）因此，一个很好的策略是取多次运行的平均精度指标。
- en: '![](../Images/177289fda2b000654d07f277f087867d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/177289fda2b000654d07f277f087867d.png)'
- en: '**Figure 9.1**. Illustration of 3-fold cross validation training on two (blue)
    chunks, testing on the third (orange) until the model computes an accuracy metric
    for all three chunks'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**图9.1**. 3折交叉验证训练在两个（蓝色）块上，在第三个（橙色）块上测试，直到模型为所有三个块计算精度指标'
- en: 'A slight variation on this procedure is called *k-fold cross validation* and
    splits the dataset into k chunks of equal size. We train the model on k-1 chunks
    and test it on the other, repeating the procedure k times so that we every chunk
    gets used as a validation set, as shown in **Figure 9.1**. The overall validation
    error is the average of the k validation errors. Here''s how to use sklearn for
    5-fold cross validation using an RF model:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这种程序的轻微变化被称为**k折交叉验证**，将数据集分成k个大小相等的块。我们在k-1个块上训练模型，在另一个块上测试，重复k次，以确保每个块都用作验证集，如图**9.1**所示。整体验证误差是k个验证误差的平均值。以下是使用RF模型进行5折交叉验证的sklearn用法：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Cross validation and repeated subsampling are excellent techniques for measuring
    model accuracy, but are unsuitable for time-sensitive datasets.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证和重复子采样是衡量模型准确性的优秀技术，但它们不适用于对时间敏感的数据集。
- en: 9.1.2 Splitting time-sensitive datasets
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 分割时间敏感数据集
- en: When observation features or target variables change meaningfully over time,
    random extraction of validation sets isn't appropriate. Randomly splitting a dataset
    would yield training and validation sets that overlap in time. That's a problem
    because it allows the model to train on data from the future and validation metrics
    would be overly optimistic. Imagine how your model would be used in practice.
    At some point, you must train a model on the data you have and then deploy it.
    Any observations subsequently submitted to the model for prediction are necessarily
    from dates beyond the end of the data used to train the model. Training should
    always mimic deployment and so our validation set should be from dates beyond
    the end of the training set.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当观测特征或目标变量随时间有意义地变化时，随机提取验证集是不合适的。随机分割数据集会产生在时间上重叠的训练集和验证集。这是一个问题，因为它允许模型在未来的数据上训练，并且验证指标会过于乐观。想象一下你的模型在实际应用中的使用情况。在某个时候，你必须使用你拥有的数据来训练模型，然后部署它。随后提交给模型进行预测的任何观测值必然是来自训练模型所使用数据的结束日期之后的日期。训练应该始终模仿部署，因此我们的验证集应该来自训练集结束日期之后的日期。
- en: 'The process for extracting training, validation, and test sets for time-sensitive
    data is:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 提取时间敏感数据的训练、验证和测试集的过程是：
- en: Sort the records by date, earliest to latest
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按日期排序记录，从最早到最新
- en: Extract the last, say, 15% of the records as `df_test`
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取最后，比如说，15%的记录作为`df_test`
- en: Extract the second to last 15% of the records as `df_valid`
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取倒数第二的15%的记录作为`df_valid`
- en: The remaining 70% of the original data is `df_train`
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原始数据的剩余70%是`df_train`
- en: For example, **Figure 9.2** illustrates the splitting process for a toy dataset
    derived from the bulldozer dataset where the records have been sorted from 2/19/08
    to 07/27/11\. Keep in mind that our final model will be tested on `df_test` but
    trained on the combined data in training and validation sets.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**图9.2**展示了从推土机数据集派生出的玩具数据集的分割过程，其中记录已按2/19/08到07/27/11的顺序排序。记住，我们的最终模型将在`df_test`上进行测试，但在训练集和验证集的合并数据上训练。
- en: '![](../Images/4886e4ad23dcef9b8503eeca69e9ab59.png)**Figure 9.2**. Sorting
    and splitting time-sensitive data for testing'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/4886e4ad23dcef9b8503eeca69e9ab59.png)**图9.2**. 对测试时间敏感数据进行排序和分割'
- en: 'For the real bulldozer dataset, Kaggle provides a training set with 401,126
    records and a validation set with 11,574 records. Because we need three datasets,
    let''s use the provided validation set as our testing set and split off 12,000
    records from the end of the training set as our validation set. What remains is
    our training set. Here are the nonoverlapping date ranges:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际的推土机数据集，Kaggle提供了一个包含401,126条记录的训练集和一个包含11,574条记录的验证集。因为我们需要三个数据集，所以让我们使用提供的验证集作为我们的测试集，并从训练集的末尾分割出12,000条记录作为我们的验证集。剩下的就是我们的训练集。以下是非重叠的日期范围：
- en: '| Subset | Start date | End date | Number of records |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 子集 | 开始日期 | 结束日期 | 记录数 |'
- en: '| :-: | :-: | :-: | :-: |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| :-: | :-: | :-: | :-: |'
- en: '| Training | 1989-01-17 | 2011-08-19 | 389,126 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 训练 | 1989-01-17 | 2011-08-19 | 389,126 |'
- en: '| Validation | 2011-08-19 | 2011-12-30 | 12,000 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 验证 | 2011-08-19 | 2011-12-30 | 12,000 |'
- en: '| Testing | 2012-01-01 | 2012-04-28 | 11,574 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 测试 | 2012-01-01 | 2012-04-28 | 11,574 |'
- en: 'If you look in `prep-bulldozer.py` in the `data` directory, you''ll see code
    similar to the following that separates the original Kaggle training set into
    training and validation sets:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看`data`目录下的`prep-bulldozer.py`文件，你会看到以下类似的代码，它将原始的Kaggle训练集分为训练集和验证集：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 9.2 Rectifying training and validation sets
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 矫正训练和验证集
- en: 'In an ideal world, datasets would be purely numeric and without missing values.
    Feature engineering would still be useful, but numericalizing data such as encoding
    categorical variables, wouldn''t be necessary. And we wouldn''t have to conjure
    up missing values. Alas, real-world datasets are full of categorical variables
    and riddled with missing values, which introduces synchronization issues between
    training and validation/test sets. **Figure 9.2** illustrates a number of potential
    hazards:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想的世界里，数据集应该是纯数字的，并且没有缺失值。特征工程仍然是有用的，但将数据数值化，例如对分类变量进行编码，就不必要了。我们也不必创造缺失值。然而，现实世界的数据集充满了分类变量，并且充满了缺失值，这会在训练集和验证/测试集之间引入同步问题。**图9.2**展示了若干潜在的风险：
- en: If category `TEX` in column `UsageBand` is encoded as integer value 1 in the
    training set, the validation and test set must use the same encoding of 1.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果列 `UsageBand` 中的类别 `TEX` 在训练集中编码为整数值 1，则验证集和测试集必须使用相同的编码 1。
- en: Missing categorical values should be encoded as integer 0 in all sets.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有集合中缺失的类别值应编码为整数 0。
- en: Missing numeric values in column `Hours` should be filled with the median of
    just those values from `Hours` in the training set.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列 `Hours` 中缺失的数值应使用训练集中 `Hours` 的中位数进行填充。
- en: Categorical values in validation or test sets not present in the training set,
    such as `MG` in column `Group`, should be encoded as integer 0; the model has
    never seen `MG`, so we encode such values as if they were missing.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证集或测试集中不存在于训练集中的类别值，例如列 `Group` 中的 `MG`，应编码为整数 0；模型从未见过 `MG`，因此我们将这些值编码为缺失值。
- en: 'We can abstract that list into these important rules for preparing separated
    training and test sets:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个列表抽象成以下重要规则，用于准备分离的训练集和测试集：
- en: Transformations must be applied to features consistently across data subsets.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须对数据子集中的特征应用一致的转换。
- en: Transformations of validation and test sets can only use data derived from the
    training set.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证集和测试集的转换只能使用从训练集派生出的数据。
- en: To follow those rules, we have to remember all transformations done to the training
    set for later application to the validation and test sets. In practice, that means
    tracking the median of all numeric columns, all category to category-to-code mappings,
    and which categories were one-hot encoded. Special care is required to ensure
    that one-hot encoded variables use the same name and number of columns in the
    training and testing sets. It sounds simple enough, but it's easy to screw up
    the synchronization between training and testing sets. Synchronization bugs usually
    show up as poor model accuracy, rather than as something obvious like a program
    exception.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要遵循这些规则，我们必须记住对训练集所做的所有转换，以便稍后应用于验证集和测试集。在实践中，这意味着跟踪所有数值列的中位数、所有类别到代码映射，以及哪些类别被进行了一热编码。需要特别注意确保一热编码变量在训练集和测试集中使用相同的名称和列数。听起来很简单，但很容易搞错训练集和测试集之间的同步。同步错误通常表现为模型精度差，而不是像程序异常这样的明显问题。
- en: 9.2.1 Preparing the training set
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 准备训练集
- en: Over the last two chapters, we've worked purely on the bulldozer training set
    to clean, encode, and perform feature engineering. Now, it's time to learn how
    to correctly prepare separate training and validation sets. We'll prepare the
    data as we did before, but will also track the data transformations that we perform.
    Then, we can apply those transformations to the validation set. We'll reuse as
    many functions as we can from the previous chapters, but some functions will require
    some updates and we'll organize some of the code snippets into new functions.
    You can find all the code from this chapter in the auto-generated [notebook](https://mlbook.explained.ai/notebooks/bulldozer-testing/prep.ipynb).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的两章中，我们一直在推土机训练集上纯粹进行清理、编码和特征工程。现在，是时候学习如何正确地准备单独的训练集和验证集了。我们将像以前一样准备数据，但也会跟踪我们执行的数据转换。然后，我们可以将这些转换应用于验证集。我们将尽可能多地重用前几章中的函数，但一些函数将需要一些更新，我们将一些代码片段组织到新的函数中。你可以在这个章节中找到所有代码的自动生成的[notebook](https://mlbook.explained.ai/notebooks/bulldozer-testing/prep.ipynb)。
- en: 'To get started, cut-and-paste the common set of import statements used in the
    last chapter into a new notebook. Then, copy in functions `test()`, `fix_missing_num()`,
    `extract_sizes()`, `df_normalize_strings()`, `df_cat_to_catcode()`, and `df_split_dates()`.
    Now, let''s encapsulate all of the cleanup work that we did in **Chapter 7** *Exploring
    and Cleaning the Bulldozer Dataset* into a `clean()` function for use on validation
    and test sets later:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，将上一章中使用的常用导入语句复制粘贴到一个新的笔记本中。然后，复制函数 `test()`、`fix_missing_num()`、`extract_sizes()`、`df_normalize_strings()`、`df_cat_to_catcode()`
    和 `df_split_dates()`。现在，让我们将我们在**第 7 章** *探索和清理推土机数据集* 中所做的所有清理工作封装到一个 `clean()`
    函数中，以便稍后用于验证集和测试集：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In **Chapter 8** *Bulldozer Feature Engineering*, we ordinal encoded `ProductSize`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第 8 章** *推土机特征工程*中，我们对 `ProductSize` 进行了序数编码：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'and one-hot encoded features `Hydraulics_Flow` and `Enclosure`. Here''s a generic
    function to one-hot encode categorical variables:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以及一热编码的特征 `Hydraulics_Flow` 和 `Enclosure`。这是一个用于一热编码类别变量的通用函数：
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Feature `fiProductClassDesc` has lots of interesting information that we split
    into four new features:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 特征 `fiProductClassDesc` 有很多有趣的信息，我们将其拆分为四个新的特征：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As we did with the cleanup procedure, let''s encapsulate our feature engineering
    work into a function because we''ll need to reuse this function on different amounts
    of training data later:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在清理过程中所做的那样，让我们将特征工程工作封装到一个函数中，因为我们稍后需要在不同数量的训练数据上重用此函数：
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It's easy enough to remember to one-hot `Hydraulics_Flow` and `Enclosure` later
    when working on the validation set, but we still need to track the training categories.
    If the categories in training and validation sets were identical, we wouldn't
    need to track anything; we could just apply `onehot()` to the validation set.
    If, however, the validation set contained a category not in the training set,
    we'd get a different number of columns in the validation set than in the training
    set. Before one-hot encoding, we have to line up the categories from training
    and validation. More on this shortly.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 记住稍后在验证集上对 `Hydraulics_Flow` 和 `Enclosure` 进行一维编码很容易，但我们仍然需要跟踪训练类别。如果训练集和验证集中的类别相同，我们就不需要跟踪任何东西；我们只需将
    `onehot()` 应用到验证集上。然而，如果验证集包含训练集中没有的类别，那么验证集和训练集中的列数将不同。在执行一维编码之前，我们必须对齐训练集和验证集中的类别。关于这一点，稍后会有更多说明。
- en: After cleanup and feature engineering comes the “numericalization” phase, which
    fixes any missing values and uses our default label encoding of categorical variables
    to remove any remaining non-numeric values. That means tracking the median of
    all numerical columns and recording the label encodings.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在清理和特征工程之后，是“数值化”阶段，该阶段修复任何缺失值并使用我们的默认标签编码对分类变量进行编码，以消除任何剩余的非数值值。这意味着跟踪所有数值列的平均值并记录标签编码。
- en: 'Rather than manually identifying numeric columns, we can ask Pandas via `is_numeric_dtype()`,
    which gives us a generic mechanism for replacing missing values in numeric columns
    and recording their medians:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是手动识别数值列，我们可以通过 `is_numeric_dtype()` 来询问 Pandas，这为我们提供了一个通用的机制，用于替换数值列中的缺失值并记录它们的平均值：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You might be wondering why we're creating `_na` columns even if a numeric training
    column has no missing values. The reason is that we have to be prepared to handle
    missing data in the validation or test sets, which would require `_na` columns.
    A RF model won't be confused by a column full of `False` values, so it's safe
    to inject columns that end up being superfluous.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道为什么我们即使数值训练列没有缺失值也要创建 `_na` 列。原因是我们必须准备好处理验证集或测试集中的缺失数据，这需要 `_na` 列。RF
    模型不会因为一列全是 `False` 值而困惑，所以注入最终变得多余的列是安全的。
- en: 'For our dataset, the return value of `df_fix_missing_nums()` looks like:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的数据集，`df_fix_missing_nums()` 的返回值如下：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To apply label-encoding transformations consistently across training and validation
    sets, we have to update `df_string_to_cat()` from the **Chapter 7** *Exploring
    and Cleaning the Bulldozer Dataset* to return a dictionary mapping a column name
    to the category index. The key functionality from Pandas is `df[colname].cat.categories`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在训练集和验证集上持续应用标签编码转换，我们必须更新 **第 7 章** *探索和清理推土机数据集* 中的 `df_string_to_cat()`，使其返回一个将列名映射到类别索引的字典。Pandas
    的关键功能是 `df[colname].cat.categories`：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here''s an example of the categories stored in the dictionary at `catencoders[''Ripper'']`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 `catencoders['Ripper']` 中存储的类别字典的一个示例：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'With those functions in place, we can encapsulate the numericalization phase
    with a wrapper function:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些函数到位后，我们可以使用包装函数封装数值化阶段：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'At this point, we have functions that apply our cleanup, feature engineering,
    and numericalization procedures. Let''s load our raw data and grab the last 100,000
    records:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们有了应用清理、特征工程和数值化流程的函数。让我们加载数据并获取最后 100,000 条记录：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, our complete preparation procedure for the training records boils down
    to this simple sequence:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们的完整准备流程简化为以下简单序列：
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Variables `medians` and `catencoders` track the information we need to consistently
    apply our transformations to the validation and test sets. We also need to remember
    that we one-hot encoded `Hydraulics_Flow` and `Enclosure`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 `medians` 和 `catencoders` 跟踪我们需要的信息，以便一致地将我们的转换应用于验证集和测试集。我们还需要记住，我们已将 `Hydraulics_Flow`
    和 `Enclosure` 进行了一维编码。
- en: Once we're sure all columns are numeric and that there are no missing values,
    we can train a model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确认所有列都是数值的，并且没有缺失值，我们就可以训练一个模型。
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: OOB R^2 0.91907 using 14,865,112 tree nodes with 45.0 median tree height
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用14,865,112个树节点，45.0的中等树高度，OOB R^2 0.91907
- en: That ![](../Images/ec985123b9b52e80981e6500795e8d16.png) metric computed from
    OOB samples is about the same that we saw at the end of the last chapter, which
    is a good sanity check. Since the OOB samples are within the same date range as
    the training samples, the OOB ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    metric is overly optimistic. To get a better estimate of model generality, we
    really need a validation set.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从OOB样本计算出的那个缺失的![](../Images/ec985123b9b52e80981e6500795e8d16.png)指标与我们在上一章末尾看到的大致相同，这是一个很好的合理性检查。由于OOB样本与训练样本处于相同的日期范围内，OOB的![](../Images/ec985123b9b52e80981e6500795e8d16.png)指标过于乐观。为了更好地估计模型的一般性，我们真的需要一个验证集。
- en: 9.2.2 Preparing consistent training and validation sets
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 准备一致的训练和验证集
- en: To evaluate our model using a validation set, we need to load the raw validation
    data and then transform it as we did with the training set. The key difference
    is that we can only use data from the training set to label encode categories
    and fix missing values in the validation set, which we've saved in variables `catencoders`
    and `medians`. Models should never be trained on future data because that's a
    form of data leakage. Part of the answer would have leaked into the training data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用验证集评估我们的模型，我们需要加载原始验证数据，然后像处理训练集那样转换它。关键区别在于我们只能使用训练集中的数据来对类别进行标签编码，并在验证集中修复缺失值，这些值我们已经保存在变量`catencoders`和`medians`中。模型永远不应该在未来的数据上训练，因为这是一种数据泄露。部分答案已经泄露到训练数据中。
- en: This is a very subtle point so it's worth emphasizing the potential hazards
    by annotating **Figure 9.2**, as shown in **Figure 9.3**.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常微妙的问题，因此值得通过注释**图9.2**来强调其潜在风险，如图**图9.3**所示。
- en: '![](../Images/1e105f771756b7965de7c7592658e976.png)**Figure 9.3**. Hazards
    in split training and test subset'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/1e105f771756b7965de7c7592658e976.png)**图9.3**. 分割训练和测试子集的潜在风险'
- en: The missing `Hours` value in the validation set should be replaced with the
    median of the `Hours` values from just the training set. When tested in production
    on a set of future records, we won't be retraining the model using those future
    records. Therefore, to get an accurate picture of future performance, no data
    from validation or test sets should ever be used in training the model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集中缺失的`Hours`值应该用仅来自训练集的`Hours`值的中位数来替换。在生产环境中对一组未来记录进行测试时，我们不会使用那些未来记录重新训练模型。因此，为了获得未来性能的准确图景，验证集或测试集中的数据永远不应该用于模型的训练。
- en: 'And, we certainly shouldn''t replace the missing value in the validation set
    with just the median of the validation data (6758 and 7191). One way to highlight
    the medians data leakage issue is to imagine testing a single future record with
    a missing value:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然不应该用验证数据的中位数（6758和7191）来替换验证集中缺失的值。一种突出中位数数据泄露问题的方法是想象测试一个带有缺失值的单个未来记录：
- en: '![](../Images/6efea931758c793e8409ad1259fdda9d.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6efea931758c793e8409ad1259fdda9d.png)'
- en: 'When there are literally no other `Hours` values with which to compute a median,
    our only choice is to compute the median from the training data alone. Here''s
    a function to fill in missing values using medians from the training data:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当实际上没有其他`Hours`值可以用来计算中位数时，我们唯一的选择就是仅从训练数据中计算中位数。这是一个用训练数据中的中位数填充缺失值的函数：
- en: '[PRE16]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'After missing numeric values, the next big hazard is inconsistent label encoding
    across training and validation sets. Consistency requires:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理缺失的数值后，下一个大问题是训练集和验证集中标签编码的不一致性。一致性需要：
- en: Each category must be encoded as the same numeric category code across all training
    and test sets.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个类别必须在所有训练和测试集中编码为相同的数值类别代码。
- en: Missing category values, in any set, must end up as integer code 0\.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任何集合中缺失的分类值必须最终以整数代码0结束。
- en: Categories found in test sets but not in the training set must be encoded as
    missing values, and ultimately as code 0.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集中找到但在训练集中未找到的类别必须编码为缺失值，并最终编码为代码0。
- en: The following function transforms all categorical variables according to those
    consistency rules, using the category indexes from the training set.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数根据那些一致性规则转换所有分类变量，使用训练集的类别索引。
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: After calling this function, missing category values in training and validation
    sets will be `np.nan` values, which will become zeros after we call `df_cat_to_catcode()`
    during the final numericalization step.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 调用此函数后，训练集和验证集中的缺失类别值将是`np.nan`值，在最终数值化步骤中调用`df_cat_to_catcode()`后，这些值将变为零。
- en: Ensuring consistent one-hot encoding is another, related, hazard. The name and
    number of columns in the training and validation sets must be the same. This consistency
    is only a problem if there are categories in the validation set that are unknown
    to the training set. Such unknown categories should be encoded as missing values
    in the validation set, as we saw in the CS/Math/Physics example from **Section
    8.3** *One-hot encoding Hydraulics_Flow*. The model has no experience with that
    category, so we lump it together with missing values.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 确保一致的单一热编码是另一个相关风险。训练集和验证集中列的名称和数量必须相同。这种一致性只有在验证集中存在训练集所不知道的类别时才成问题。这些未知类别应在验证集中编码为缺失值，正如我们在第8.3节**单热编码水力学流**的CS/数学/物理示例中看到的那样。该模型对该类别没有经验，所以我们将其与缺失值一起归为一类。
- en: 'To ensure consistency, we just have to apply the training category index for
    column *x* to the validation set column *x* before one-hot encoding it:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保一致性，我们只需在单热编码之前将训练类别索引应用于验证集列*x*：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The reason that we delete the category index from `catencoders` is to simplify
    the loop in `df_apply_cats()`. That function does not have to test if `colname
    in df_test` to avoid an indexing exception from `df_test[colname]`. (The original
    categorical column *x* will not be in `df_test` after one-hot encoding.)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`catencoders`中删除类别索引的原因是为了简化`df_apply_cats()`中的循环。该函数不需要测试`colname in df_test`以避免从`df_test[colname]`中出现的索引异常。（在单热编码后，原始的类别列*x*将不会出现在`df_test`中。）
- en: 'To perform feature engineering on the validation set, we split dates, encode
    the product size, and split apart the product description as we did before. The
    only difference is how we apply the one-hot encoding:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证集上执行特征工程时，我们像之前一样分割日期，编码产品尺寸，并将产品描述分开。唯一的不同之处在于我们应用单热编码的方式：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To numericalize the validation set, we apply categories with `df_apply_cats()`
    instead of calling `df_string_to_cat()`, use medians from the training set to
    fix any missing values, and then do the usual category-to-code conversion:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将验证集数值化，我们使用`df_apply_cats()`应用类别，而不是调用`df_string_to_cat()`，使用训练集的中位数来修复任何缺失值，然后进行通常的类别到代码的转换：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Program defensively**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**防御性编程**'
- en: 'Machine learning models are difficult to debug because bugs often only show
    up as fluctuations in model accuracy. It''s a good idea to practice some defensive
    programming. Here''s are two functions that do some basic sanity checking on the
    features before we shove them into the model:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型难以调试，因为错误通常只表现为模型精度的波动。练习一些防御性编程是个好主意。以下是在我们将特征推入模型之前对特征进行一些基本合理性检查的两个函数：
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here''s a common invocation sequence:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个常见的调用序列：
- en: '[PRE22]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'With all of those functions in hand, we''re finally ready to load and prepare
    a validation set with this simple code sequence:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有所有这些函数后，我们终于准备好使用以下简单的代码序列加载和准备一个验证集：
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: At this point, we've got prepared training data in `X` and `y` and prepared
    validation data in `X_valid` and `y_valid`; let's see how well the model does
    on the validation set.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在`X`和`y`中准备好了训练数据，在`X_valid`和`y_valid`中准备好了验证数据；让我们看看模型在验证集上的表现如何。
- en: 9.2.3 Getting baseline validation metrics
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 获取基线验证指标
- en: For this bulldozer dataset, we've been measuring model performance with the
    unitless ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score (in range negative
    infinity to 1.0), because that's what sklearn's RF implementation gives us easily
    for OOB samples. The MAE measure is easier to interpret, though, and so let's
    compute that as well for validation set predictions. To compare how well our model
    performs in comparison to the Kaggle competitors, we also need to compute the
    so-called *root mean squared log error* (*RMSLE*) (see the *Common regression
    metrics* box). Because we've already taken the log of `y_valid`, squaring the
    difference between predicted and true values and then taking the square root gives
    us RMSLE. Good RMSLE errors are down near 0.23 for this data set.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个推土机数据集，我们一直使用无单位的![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)分数（范围从负无穷大到1.0）来衡量模型性能，因为这是sklearn的RF实现为我们提供的易于获取的OOB样本。然而，MAE度量更容易解释，因此我们也为验证集预测计算那个。为了比较我们的模型与Kaggle竞争对手的表现，我们还需要计算所谓的*均方对数误差*（*RMSLE*）（见*常见回归指标*框）。因为我们已经对`y_valid`取了对数，所以平方预测值和真实值之间的差异然后取平方根就得到了RMSLE。对于这个数据集，好的RMSLE误差接近0.23。
- en: '**Common regression metrics**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**常见的回归指标**'
- en: 'There are a number of very common, and very similar, metrics used to evaluate
    the accuracy of regressors. We''ve already used mean absolute value, MAE, which
    is just the average absolute difference between predicted and true values:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多非常常见且非常相似的指标用于评估回归器的准确性。我们已经使用了平均绝对值，MAE，它只是预测值和真实值之间平均绝对差异：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The absolute value prevents negative and positive deviations from canceling
    each other out. Instead of taking the absolute value, we could square the differences,
    giving us *mean squared error* (*MSE*). Squaring the difference also has the effect
    of emphasizing any predictions that are very far away from their true values:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对值防止了负偏差和正偏差相互抵消。我们不是取绝对值，而是平方差异，得到*均方误差*（*MSE*）。平方差异还有强调任何与真实值相差很远的预测的效果：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: To ignore a few significantly-deviant predictions, it's better to use MAE than
    MSE. It all depends on what you care about.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略一些显著偏离的预测，使用MAE（平均绝对误差）比MSE（均方误差）更好。这完全取决于你关心的是什么。
- en: 'Because the units of MSE are the square of the target variable units, such
    as square dollars, practitioners often use *root mean squared error* (*RMSE*):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于MSE的单位是目标变量单位的平方，例如平方美元，从业者通常使用*均方根误差*（*RMSE*）：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: If we take the logarithm of the target variable, as we've done with the bulldozer
    dataset (`y=np.log(y)`), then computing MSE is actually computing *mean squared
    log error* (*MSLE*). Similarly, if we take the square root of that, we get *root
    mean squared log error* (*RMSLE*).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取目标变量的对数，就像我们在推土机数据集（`y=np.log(y)`）中所做的那样，那么计算MSE实际上是在计算*均方对数误差*（*MSLE*）。同样，如果我们取那个数的平方根，我们得到*均方对数误差*（*RMSLE*）。
- en: Avoid a common pitfall by ensuring the columns of the validation set line up
    with the columns in the training set. Use Pandas' `reindex()` function before
    running a validation set through a model.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通过确保验证集的列与训练集的列对齐来避免一个常见的错误。在将验证集通过模型运行之前，使用Pandas的`reindex()`函数。
- en: 'Model `rf` has been trained on `X` and `y`, but we can''t immediately ask for
    predictions for the observations in `X_valid`. The order of columns in the validation
    set could differ from the training set because the order in which we transform
    and inject new columns could be different. The sklearn models convert Pandas dataframes
    to numpy 2D arrays in `fit()` and `predict()` without concern for column order,
    so let''s make sure they line up:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 模型`rf`已经在`X`和`y`上训练，但我们不能立即为`X_valid`中的观测值请求预测。验证集列的顺序可能与训练集不同，因为转换和注入新列的顺序可能不同。sklearn模型在`fit()`和`predict()`中将Pandas数据框转换为numpy
    2D数组，而不考虑列顺序，所以让我们确保它们对齐：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, we can make predictions from `X_valid` and compute ![](../Images/ec985123b9b52e80981e6500795e8d16.png),
    RMSLE, and MAE scores:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从`X_valid`中进行预测，并计算RMSLE、MAE分数：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Validation R^2 0.88148, RMSLE 0.24890, MAE $5939
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集R^2 0.88148，RMSLE 0.24890，MAE 5939
- en: The average bulldozer price is about $31,000 so being off by $5939 is not great,
    but we can improve on the scores a bit by tuning the model. As far as the Kaggle
    competition is concerned, that score would put us at the edge of the top 10% if
    our validation set were the same as the private leaderboard test set. (The competition
    is closed and so we can't test our model on the same test set; comparing to the
    leaderboard just gives us a ballpark performance measure.)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 平均推土机价格约为31,000美元，因此偏差5939美元并不理想，但我们可以通过调优模型来稍微提高分数。就Kaggle竞赛而言，这个分数将使我们处于前10%的边缘，前提是我们的验证集与私有排行榜测试集相同。（竞赛已经结束，所以我们无法在相同的测试集上测试我们的模型；与排行榜的比较仅为我们提供了一个大致的性能指标。）
- en: 9.3 Tuning a Random Forest model
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 调优随机森林模型
- en: 'One of the nice characteristics of RF models is that they don''t require a
    lot of tuning to get good accuracy. To get maximize accuracy, though, there are
    three common hyperparameters that we can tweak: the number of decision trees in
    the forest (`n_estimators`), the number of randomly-selected features considered
    during training for each node in the trees (`max_features`), and the minimum number
    of samples grouped into a leaf node (`min_samples_leaf`). We''ll define these
    hyperparameters precisely in **Chapter 17** *Forests of Randomized Decision Trees*,
    but for now, let''s just assume they are important.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林模型的一个很好的特性是它们不需要很多调优就能获得良好的准确性。然而，为了获得最大化的准确性，有三个常见的超参数我们可以调整：森林中决策树的数量（`n_estimators`）、在树的每个节点训练期间考虑的随机选择特征的数量（`max_features`），以及分组到叶节点中的最小样本数（`min_samples_leaf`）。我们将在第17章“随机决策树森林”中精确地定义这些超参数，但现在，让我们假设它们很重要。
- en: Tuning a model involves repeatedly wiggling hyperparameters, retraining the
    model, and computing a metric based upon predictions from a validation set. The
    optimal hyperparameters are those that give us the best validation metric. During
    model development and experimentation related to feature engineering, we're more
    concerned with short training duration than finding optimal hyperparameters. It's
    only after we've more-or-less finished feature engineering that we tweak hyperparameters,
    looking for the best model. As a final tuning step, we'll try removing unimportant
    features.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 调优模型涉及反复调整超参数、重新训练模型，并基于验证集的预测计算一个指标。最佳超参数是那些给我们带来最佳验证指标的参数。在模型开发和与特征工程相关的实验中，我们更关心的是短训练时间，而不是寻找最佳超参数。只有在我们的特征工程大致完成之后，我们才会调整超参数，寻找最佳模型。作为最后的调优步骤，我们将尝试移除不重要的特征。
- en: To increase the speed with which we can try different models, we want to keep
    training time low, so we typically work with a subset of the training data and
    use between 20 and 50 trees in the RF model. (We've been using 100,000 out of
    about 400,000 records so far.) We sometimes set `min_samples_leaf` to the highest
    value that still gives us decent accuracy, because larger values of `min_samples_leaf`
    decrease tree size and smaller trees are faster to build. `min_samples_leaf`=1
    is the default and finds the most detail in the training data, but results in
    the biggest trees.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加快我们尝试不同模型的速度，我们希望保持训练时间低，所以我们通常使用训练数据的一个子集，并在RF模型中使用20到50棵树。（到目前为止，我们已经使用了大约400,000条记录中的100,000条。）我们有时会将`min_samples_leaf`设置为仍然能给我们提供良好准确性的最高值，因为更大的`min_samples_leaf`值会减小树的大小，而较小的树构建得更快。`min_samples_leaf`=1是默认值，它能在训练数据中找到最详细的特征，但会导致树变得最大。
- en: When it's time to tune the model for accuracy, we gradually increase the number
    of trees until accuracy levels off. In the last chapter, we used 150 trees during
    feature engineering because we wanted to compare the effect of various features
    with a fairly stable metric. Due to the randomness of model construction, the
    same metric on the same data and same hyperparameters will fluctuate. The fewer
    the trees, the more the metric will fluctuate. For the remainder of this chapter,
    we'll bump the number of trees to 200, hoping to squeeze out a tiny bit more accuracy
    and increase metric stability. As we tune the model, we want to know that differences
    in accuracy are due to changes in hyperparameters, not random fluctuations.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当是时候调整模型以提升准确度时，我们逐渐增加树的数量，直到准确度趋于平稳。在上一章中，我们在特征工程期间使用了150棵树，因为我们想通过一个相当稳定的指标来比较各种特征的效果。由于模型构建的随机性，相同的指标在相同的数据和相同的超参数上将会波动。树的数量越少，指标波动越大。在本章的剩余部分，我们将树的数量增加到200，希望挤出一点更多的准确度并提高指标稳定性。在调整模型时，我们希望知道准确度的差异是由于超参数的变化，而不是随机波动。
- en: Practitioners will often use a technique called a *grid search* to tune hyperparameters,
    which would try lots of combinations, looking for the best set of hyperparameters.
    Such a search takes forever to run and isn't necessary for RF models. We can choose
    hyperparameters in sequence. First, increase the number of trees until accuracy
    stops improving. Next, using the number of trees from the first step, try a few
    values of `max_features` (`'sqrt'`, 0.1 to 0.6) and pick the one that gives the
    best metric. Finally, using the best `max_features`, run `min_samples_leaf` from
    1 to about 15, again picking the best one.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 实践者通常会使用一种称为*网格搜索*的技术来调整超参数，这将尝试很多组合，寻找最佳的超参数集。这样的搜索需要花费很长时间，对于RF模型来说并不必要。我们可以按顺序选择超参数。首先，增加树的数量，直到准确度不再提高。接下来，使用第一步中的树的数量，尝试几个`max_features`（`'sqrt'`,
    0.1到0.6）的值，并选择给出最佳指标的值。最后，使用最佳的`max_features`，从1到大约15运行`min_samples_leaf`，再次选择最佳值。
- en: 9.3.1 Choosing a time-sensitive training set
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 选择时间敏感的训练集
- en: Always choose your training and validation sets before attempting to tune the
    model. The idea is to start with the characteristics that affect accuracy the
    most and work your way to the more modest improvements obtained from tuning model
    hyperparameters.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试调整模型之前，始终选择训练集和验证集。想法是从影响准确度最大的特征开始，逐步过渡到通过调整模型超参数获得的更小的改进。
- en: 'Before we start the tuning process, let''s choose a larger training set than
    the 100,000 records we''ve been using. In general, we want to use all training
    data available to us, but that''s not always the case in time-sensitive datasets
    such as this. Clearly, the prices from 1989, at the start of the training set,
    would be lowball figures for the bulldozers sold in 2011\. We have find a balance
    between using more training data and the biased prices of earlier observations.
    Through experimentation, we arrived at a training dataset with all samples from
    2007 and later by simply iterating through multiple training set date ranges.
    Here''s how to load just that training set:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始调整过程之前，让我们选择一个比我们之前使用的10万条记录更大的训练集。一般来说，我们希望使用我们拥有的所有训练数据，但在时间敏感的数据集中，如这个例子，情况并不总是如此。显然，训练集开始时的1989年的价格对于2011年销售的推土机来说将是低估的价格。我们需要在使用更多训练数据和早期观察的偏差价格之间找到一个平衡。通过实验，我们通过迭代多个训练集日期范围，得到了一个包含2007年和以后所有样本的训练数据集。以下是加载该训练集的方法：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'With new training data, we have to run the same data preparation process as
    before. That means also reprocessing the validation set because our `medians`
    and `catencoders` will have changed, since they are computed from the training
    set. Here''s the complete sequence for preparing both training and validation
    sets:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的训练数据时，我们必须运行与之前相同的数据准备流程。这意味着还需要重新处理验证集，因为我们的`中位数`和`catencoders`已经改变，因为它们是从训练集计算得出的。以下是准备训练集和验证集的完整序列：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s also create a method that trains a model, measures accuracy, and reports
    some metrics:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再创建一个方法，该方法训练模型，测量准确度，并报告一些指标：
- en: '[PRE31]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here are the metrics for our model trained on the larger training set and tested
    on the updated validation set:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在较大的训练集上训练并在更新的验证集上测试的模型的指标：
- en: '[PRE32]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: OOB R^2 0.91934 using 34,346,352 tree nodes 45.0 median tree height Validation
    R^2 0.88339, RMSLE 0.24688, MAE $5967
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: OOB R^2 0.91934，使用34,346,352个树节点，45.0的中位树高，验证R^2 0.88339，RMSLE 0.24688，MAE $5967
- en: Those are slightly better than the metrics we got from using just 100,000 training
    records. RMSLE has gone from 0.2489 to 0.2469\. With this new baseline, let's
    tune the hyperparameters.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果略好于仅使用 100,000 个训练记录所得到的指标。RMSLE 从 0.2489 降低到 0.2469。有了这个新的基线，让我们调整超参数。
- en: 9.3.2 Choosing max_features and min_samples_leaf
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 选择 max_features 和 min_samples_leaf
- en: 'When constructing a decision tree node, an RF model randomly selects and examines
    a subset of the feature set. The size of that feature set affects a number of
    things, including accuracy and generality. The more features we allow the model
    to consider for each node, the higher the accuracy but the less general the model.
    (If we allowed the model to consider all features, the model would become overfit
    and much less general.) With a simple loop, we can try different values of `max_features`,
    such as 0.1 to 0.6 stepping by 0.1 (that is, try 10% to 60% of the features):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建决策树节点时，RF 模型会随机选择并检查特征集的一个子集。该特征集的大小会影响多个方面，包括准确性和泛化性。我们允许模型为每个节点考虑的特征越多，准确性就越高，但模型的泛化性就越低。（如果我们允许模型考虑所有特征，模型就会过拟合，泛化性就会降低。）通过一个简单的循环，我们可以尝试不同的
    `max_features` 值，例如从 0.1 到 0.6，步长为 0.1（即尝试 10% 到 60% 的特征）：
- en: '[PRE33]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: n_estimators=200, max_features=0.1, min_samples_leaf=1 OOB R^2 0.91818 using
    38,555,212 tree nodes 45.0 median tree height Validation R^2 0.88949, RMSLE 0.24034,
    MAE $6036 n_estimators=200, max_features=0.2, min_samples_leaf=1 OOB R^2 0.92319
    using 37,329,962 tree nodes 44.0 median tree height Validation R^2 0.89522, RMSLE
    0.23402, MAE $5746 n_estimators=200, max_features=0.3, min_samples_leaf=1 OOB
    R^2 0.92398 using 36,429,076 tree nodes 44.0 median tree height Validation R^2
    0.89574, RMSLE 0.23344, MAE $5681 n_estimators=200, max_features=0.4, min_samples_leaf=1
    OOB R^2 0.92372 using 35,765,980 tree nodes 44.0 median tree height Validation
    R^2 0.89454, RMSLE 0.23479, MAE $5704 n_estimators=200, max_features=0.5, min_samples_leaf=1
    OOB R^2 0.92345 using 35,358,180 tree nodes 45.0 median tree height Validation
    R^2 0.89359, RMSLE 0.23584, MAE $5732
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: n_estimators=200, max_features=0.1, min_samples_leaf=1 OOB R^2 0.91818 使用 38,555,212
    个树节点 45.0 中值树高 验证 R^2 0.88949, RMSLE 0.24034, MAE $6036 n_estimators=200, max_features=0.2,
    min_samples_leaf=1 OOB R^2 0.92319 使用 37,329,962 个树节点 44.0 中值树高 验证 R^2 0.89522,
    RMSLE 0.23402, MAE $5746 n_estimators=200, max_features=0.3, min_samples_leaf=1
    OOB R^2 0.92398 使用 36,429,076 个树节点 44.0 中值树高 验证 R^2 0.89574, RMSLE 0.23344, MAE
    $5681 n_estimators=200, max_features=0.4, min_samples_leaf=1 OOB R^2 0.92372 使用
    35,765,980 个树节点 44.0 中值树高 验证 R^2 0.89454, RMSLE 0.23479, MAE $5704 n_estimators=200,
    max_features=0.5, min_samples_leaf=1 OOB R^2 0.92345 使用 35,358,180 个树节点 45.0 中值树高
    验证 R^2 0.89359, RMSLE 0.23584, MAE $5732
- en: 'It looks like `max_features`=0.3 gives the lowest RMSLE error, so let''s hold
    `max_features` steady while we optimize `min_samples_leaf`, the next hyperparameter:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 `max_features`=0.3 提供了最低的 RMSLE 错误，所以在我们优化下一个超参数 `min_samples_leaf` 的同时，让我们保持
    `max_features` 不变：
- en: '[PRE34]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: n_estimators=200, max_features=0.3, min_samples_leaf=2 OOB R^2 0.92170 using
    17,839,822 tree nodes 40.0 median tree height Validation R^2 0.89650, RMSLE 0.23259,
    MAE $5678 n_estimators=200, max_features=0.3, min_samples_leaf=3 OOB R^2 0.91926
    using 11,489,890 tree nodes 38.0 median tree height Validation R^2 0.89635, RMSLE
    0.23276, MAE $5696 n_estimators=200, max_features=0.3, min_samples_leaf=4 OOB
    R^2 0.91697 using 8,470,446 tree nodes 36.0 median tree height Validation R^2
    0.89558, RMSLE 0.23362, MAE $5734 n_estimators=200, max_features=0.3, min_samples_leaf=5
    OOB R^2 0.91485 using 6,710,466 tree nodes 35.0 median tree height Validation
    R^2 0.89463, RMSLE 0.23468, MAE $5762 n_estimators=200, max_features=0.3, min_samples_leaf=6
    OOB R^2 0.91304 using 5,555,130 tree nodes 34.0 median tree height Validation
    R^2 0.89401, RMSLE 0.23537, MAE $5792
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: n_estimators=200, max_features=0.3, min_samples_leaf=2 OOB R^2 0.92170 使用 17,839,822
    个树节点 40.0 中值树高 验证 R^2 0.89650, RMSLE 0.23259, MAE $5678 n_estimators=200, max_features=0.3,
    min_samples_leaf=3 OOB R^2 0.91926 使用 11,489,890 个树节点 38.0 中值树高 验证 R^2 0.89635,
    RMSLE 0.23276, MAE $5696 n_estimators=200, max_features=0.3, min_samples_leaf=4
    OOB R^2 0.91697 使用 8,470,446 个树节点 36.0 中值树高 验证 R^2 0.89558, RMSLE 0.23362, MAE
    $5734 n_estimators=200, max_features=0.3, min_samples_leaf=5 OOB R^2 0.91485 使用
    6,710,466 个树节点 35.0 中值树高 验证 R^2 0.89463, RMSLE 0.23468, MAE $5762 n_estimators=200,
    max_features=0.3, min_samples_leaf=6 OOB R^2 0.91304 使用 5,555,130 个树节点 34.0 中值树高
    验证 R^2 0.89401, RMSLE 0.23537, MAE $5792
- en: 'A value of 2 or 3 for `min_samples_leaf` yields the lowest error, depending
    on the run, so now we have decent values for both hyperparameters. Subsequent
    validation tests will like this:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_samples_leaf` 的值为 2 或 3 时，根据运行情况，可以得到最低的错误，因此现在我们有了两个超参数的合理值。后续的验证测试将类似于以下内容：'
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: OOB R^2 0.92182 using 17,843,764 tree nodes 40.0 median tree height Validation
    R^2 0.89639, RMSLE 0.23272, MAE $5687
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: OOB R^2 0.92182 使用 17,843,764 个树节点 40.0 中值树高 验证 R^2 0.89639, RMSLE 0.23272,
    MAE $5687
- en: The tuned model has better scores than the untuned model. The RMSLE has gone
    from 0.2469 to 0.2327\. That's a big bump if we're fighting tooth-and-nail in
    a Kaggle competition, but is not a huge win for practical model. The model is
    still off-line average of $5687.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的模型比未调整的模型得分更高。均方根对数似然误差（RMSLE）从0.2469降至0.2327。如果我们在一个激烈的Kaggle竞赛中全力以赴，这将是一个很大的提升，但对于实际模型来说并不是一个巨大的胜利。模型的离线平均值为5687。
- en: 9.3.3 Dropping irrelevant features
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 删除无关特征
- en: RF models are very good about ignoring features that are not predictive of the
    target variable, but they're not magic. We can often improve the overall performance
    of the model by dropping some of the unimportant features. Dropping features could
    come at the cost of reduced accuracy for a few records, but our goal, in this
    case, is to reduce the overall RMSLE error as used in the Kaggle competition.
    By selectively dropping the least important features, we'll arrive at a set of
    33 features from the original 83 that gives us slightly better accuracy. (Training
    a model on this feature subset is also much faster as a bonus.)
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: RF模型在忽略对目标变量没有预测性的特征方面做得很好，但它们并非万能。我们通常可以通过删除一些不重要的特征来提高模型的总体性能。删除特征可能会降低一些记录的准确性，但在这个案例中，我们的目标是减少Kaggle竞赛中使用的总体RMSLE误差。通过选择性地删除最不重要的特征，我们将从原始的83个特征中得出一个包含33个特征的特征集，这会给我们带来略微更好的准确性。（在这个特征子集上训练模型也是一个额外的优点。）
- en: '[![](../Images/2e9f825f18ce1a97ed32b18fae850aca.png)](images/bulldozer-testing/bulldozer-testing_prep_34.svg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](../Images/2e9f825f18ce1a97ed32b18fae850aca.png)(images/bulldozer-testing/bulldozer-testing_prep_34.svg)'
- en: Our strategy will be to repeatedly train a model on the current feature set,
    compute the feature importances, and drop the least important 10% from the feature
    set. Looking at the top 30 in the feature importance graph, we see a quick drop
    off in importance. We want to toss out the least helpful, but we can't do it in
    one pass by just taking all features above an importance threshold.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的战略将是反复在当前特征集上训练模型，计算特征重要性，并从特征集中删除最不重要的10%。查看特征重要性图中的前30名，我们会看到重要性迅速下降。我们希望丢弃最无帮助的特征，但我们不能通过只取重要性阈值以上的所有特征来一次性完成。
- en: The permutation importance mechanism used in these graphs effectively shares
    importance between collinear features, those that are not independent of each
    other. Features `YearMade` and `age` are good examples of collinear features.
    If we dropped `YearMade`, then `age` would become much more important. Those two
    features have such large importance values we'd never drop them, but collinearity
    between less important features means we must take a conservative approach. After
    dropping the bottom 10% of the features, we'll recompute feature importance to
    recheck which features the model thinks are important before dropping the next
    10%, and so on. The following function embodies that strategy.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图中使用的排列重要性机制有效地在共线性特征之间共享重要性，这些特征彼此之间并不独立。`YearMade`和`age`是共线性特征的很好例子。如果我们删除`YearMade`，那么`age`就会变得非常重要。这两个特征的重要性值非常大，我们永远不会删除它们，但较不重要的特征之间的共线性意味着我们必须采取保守的方法。在删除了10%的最不重要的特征后，我们将重新计算特征重要性，以重新检查模型在删除下一个10%之前认为哪些特征是重要的，依此类推。以下函数体现了这种策略。
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We can use that function to select the best feature set:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用该函数来选择最佳特征集：
- en: '[PRE37]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'That takes a long time to run as it''s retraining the model for each iteration,
    but the output looks like:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每次迭代都需要重新训练模型，所以运行时间很长，但输出结果如下：
- en: '[PRE38]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Using the 33 features in `best_features`, let''s train a model and get some
    metrics:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`best_features`中的33个特征，让我们训练一个模型并获取一些指标：
- en: '[PRE39]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: OOB R^2 0.90841 using 14,362,342 tree nodes 39.0 median tree height Validation
    R^2 0.89852, RMSLE 0.23031, MAE $5642
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: OOB R^2 0.90841，使用14,362,342个树节点，39.0的中位树高，验证R^2 0.89852，RMSLE 0.23031，MAE 5642
- en: By choosing the right feature subset, the RMSLE has dropped from 0.2327 to 0.2303\.
    Using many fewer features also significantly reduces the size of the trees in
    the model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 通过选择正确的特征子集，RMSLE从0.2327降至0.2303。使用更少的特征也显著减少了模型中树的大小。
- en: 9.3.4 Adjusting prices for inflation
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.4 调整价格以应对通货膨胀
- en: 'Inflation causes prices to grow over time and the bulldozer dataset has roughly
    20 years of data. Earlier records in the training set have lower sale prices on
    average than later records. Identical bulldozers sold in 1990 and 2010 would have
    significantly different prices, which would give conflicting training information
    to a model. An RF model predicts the average price computed from all identical,
    or nearly identical, bulldozers. Consequently, our model must be systematically
    underpredicting bulldozer prices in the validation set. In fact, we can verify
    that easily:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 通货膨胀导致价格随时间增长，推土机数据集大约有20年的数据。训练集中的早期记录的平均售价通常低于后期记录。1990年和2010年销售的相同推土机会有显著不同的价格，这会给模型提供相互矛盾的训练信息。RF模型预测所有相同或几乎相同的推土机的平均价格。因此，我们的模型在验证集中必须系统地低估推土机价格。事实上，我们可以很容易地验证这一点：
- en: '[PRE40]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Model underpredicts by $2352, 0.03588 log(dollars)
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 模型低估了$2352，0.03588 log(dollars)
- en: Because of the increasing trend in prices, our model systematically underpredicts
    by a few thousand dollars, but the underprediction is only an average. In some
    cases, the model will overpredict. While properly dealing with time-sensitive
    datasets is beyond the intended scope of this book, we can still illustrate the
    problem briefly and then make a small tweak to our model to improve overall accuracy
    before moving on.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 由于价格的增长趋势，我们的模型系统地低估了几千美元，但这种低估只是一个平均值。在某些情况下，模型会高估。虽然妥善处理时间敏感型数据集超出了本书的预期范围，我们仍然可以简要说明这个问题，然后在我们继续前进之前对模型进行一些小的调整以提高整体准确性。
- en: Time-sensitive datasets with prices are particularly challenging to predict
    because there's lots more going on than just inflation. The average bulldozer
    price over time does not simply grow steadily, as shown in **Figure 9.4**. (Code
    for this figure is in the [notebook](https://mlbook.explained.ai/notebooks/bulldozer-testing/trend.ipynb)
    for this chapter.) For example, the financial crises of 2000 and 2007 show fairly
    substantial drops in the average bulldozer price. Training a model on these prices
    too closely risks training the model to expect future crises, even though predicting
    the market is generally not possible. Instead, it's safer to assume prices grow,
    on average, along the orange trend line, which effectively smooths out these price
    crashes.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 带有价格的时间敏感型数据集尤其难以预测，因为除了通货膨胀之外还有许多其他因素。随着时间的推移，推土机的平均价格并不是简单地稳步增长，如图**9.4**所示。（本章节中该图的代码在[notebook](https://mlbook.explained.ai/notebooks/bulldozer-testing/trend.ipynb)中。）例如，2000年和2007年的金融危机显示出推土机平均价格相当大的下降。在这些价格上训练模型过于紧密可能会使模型期望未来的危机，尽管预测市场通常是不可能的。相反，更安全的方法是假设价格平均沿着橙色趋势线增长，这有效地平滑了这些价格崩溃。
- en: '[![](../Images/9ac09e42a6a0759853dfe6969f83051e.png)](images/bulldozer-testing/bulldozer-testing_trend_1.svg)**Figure
    9.4**. Average Bulldozer Price'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/9ac09e42a6a0759853dfe6969f83051e.png)](images/bulldozer-testing/bulldozer-testing_trend_1.svg)**图9.4**.
    平均推土机价格'
- en: Unfortunately, adjusting a model according to the overall price trend line only
    affects the overall accuracy. If we'd like to improve the accuracy for individual
    bulldozers or population segments, we need trend lines for each segment. For example,
    larger bulldozers should cost more than smaller bulldozers, which we can see in
    **Figure 9.5**. (Code for this figure is in the [notebook](https://mlbook.explained.ai/notebooks/bulldozer-testing/prod-trend.ipynb)
    for this chapter.) To get a more accurate model, we'd need to adjust prices differently,
    depending on `ProductSize`. There could be lots of features and combinations of
    features that dictate price fluctuations. To improve accuracy, we'd need to combine
    the efforts of multiple models that looked at different aspects of the training
    set. (See the [winners' discussion on Kaggle](https://www.kaggle.com/c/bluebook-for-bulldozers/discussion/4368).)
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，根据整体价格趋势线调整模型只会影响整体准确性。如果我们想提高个别推土机或人口群体的准确性，我们需要每个群体的趋势线。例如，大型推土机应该比小型推土机贵，这在**图9.5**中可以看到。（本章节中该图的代码在[notebook](https://mlbook.explained.ai/notebooks/bulldozer-testing/prod-trend.ipynb)中。）为了得到更准确的模型，我们需要根据`ProductSize`调整价格。可能有大量特征和特征的组合决定了价格波动。为了提高准确性，我们需要结合多个模型的努力，这些模型从训练集的不同方面进行观察。（参见Kaggle上的[获奖者讨论](https://www.kaggle.com/c/bluebook-for-bulldozers/discussion/4368)。）
- en: '[![](../Images/5a5d6426a91432b830dcf3e100158b6e.png)](images/bulldozer-testing/bulldozer-testing_prod-trend_1.svg)**Figure
    9.5**. Average Bulldozer Price Per ProductSize'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/5a5d6426a91432b830dcf3e100158b6e.png)](images/bulldozer-testing/bulldozer-testing_prod-trend_1.svg)**图9.5**.
    平均按产品尺寸划分的推土机价格'
- en: 'We''re sticking to a single model in this book, but we can still tweak the
    output of this model by adding in the underprediction amount computed from the
    validation set. It will hurt some predictions and help others but, on average,
    the adjustment will improve the RMSLE:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们坚持使用单个模型，但我们可以通过添加从验证集计算出的低估量来调整该模型的输出。这会损害一些预测并帮助其他预测，但平均而言，调整将提高RMSLE：
- en: '[PRE41]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Adjusted-model validation R^2 0.90098, RMSLE 0.22750, MAE 5464
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的模型验证R^2 0.90098，RMSLE 0.22750，MAE 5464
- en: The highlighted code line has our simple tweak to the model predictions. Our
    RMSLE error drops from 0.2303 to 0.2275\. We can think of `underprediction` as
    another parameter of a new meta-model or we can think of `underprediction` has
    a second (additive) model that takes the output of a previous model and generates
    new output. Either way, we're updating our model based upon information derived
    from the validation set results, just like we did with hyper parameters, which
    means that we've tailored our model somewhat to this validation set. Nonetheless,
    the tweak is still useful for any other test sets we have, as long as they are
    in the near future.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 突出的代码行是对模型预测的简单调整。我们的RMSLE错误从0.2303降至0.2275。我们可以将`低估`视为新元模型的一个参数，或者我们可以将`低估`视为一个第二（加性）模型，它接受先前模型的输出并生成新的输出。无论如何，我们都是根据验证集结果的信息更新我们的模型，就像我们处理超参数一样，这意味着我们已经根据这个验证集调整了我们的模型。尽管如此，这个调整对于任何其他我们拥有的测试集仍然有用，只要它们在不久的将来。
- en: '{TODO: What about adding "DaysSinceFirstSale" feature to detrend in model?}'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '{待办：关于在模型中添加"DaysSinceFirstSale"特征以去趋势，有何看法？}'
- en: 9.4 Getting a true measure of generality
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 获得泛化的真实度量
- en: At this point, we have a final model that is based upon a selected training
    subset, a subset of features, tuned hyper parameters, and a tweak to adjust for
    inflation. Our best RMSLE on the validation set is 0.2275, but because we've turned
    the model hyper parameters and computed an inflation adjustment on the validation
    set, metrics derived from the validation set are overly optimistic. That's why
    we carved out a test set that we've totally ignored until now. We can finally
    use that test set to get an objective measure of model generality.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们有一个基于所选训练子集、特征子集、调整的超参数和调整通货膨胀的调整的最终模型。我们在验证集上的最佳RMSLE为0.2275，但由于我们在验证集上调整了模型超参数并计算了通货膨胀调整，从验证集导出的指标过于乐观。这就是为什么我们划分出一个测试集，我们直到现在才完全忽略它。我们最终可以使用这个测试集来获得模型泛化的客观度量。
- en: First, let's load and prepare a training set that includes the validation set
    in order to use as much training data as possible. (File `bulldozer-train-all.feather`
    is created by `prep-bulldozer.py` in the `data` directory.)
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们加载并准备一个包含验证集的训练集，以便尽可能多地使用训练数据。（文件`bulldozer-train-all.feather`由`data`目录中的`prep-bulldozer.py`创建。）
- en: '[PRE42]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next, load and prepare the test set, just like we did for the validation set:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，加载并准备测试集，就像我们为验证集所做的那样：
- en: '[PRE43]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then train a model and compute metrics using the test set:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用测试集训练模型并计算指标：
- en: '[PRE44]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: OOB R^2 0.90900 using 15,344,480 tree nodes 39.0 median tree height Validation
    R^2 0.89356, RMSLE 0.23961, MAE $6018
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 使用15,344,480个树节点，OOB R^2 0.90900，中值树高度39.0，验证R^2 0.89356，RMSLE 0.23961，MAE $6018
- en: So, how good is our model? Well, that depends on what we care about. One of
    the most important characteristics of a model is how well it generalizes from
    the training data to unseen future data. From this perspective, our model is very
    good because the test RMSLE error of 0.2396 is very similar to the validation
    RMSLE, 0.2275\. The model isn't over fit to the training data and, therefore,
    doesn't fall apart when we move from the validation to the test set.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们的模型有多好？这取决于我们关心什么。模型最重要的特性之一是它从训练数据到未见过的未来数据的泛化能力。从这个角度来看，我们的模型非常好，因为测试RMSLE错误为0.2396，与验证RMSLE
    0.2275非常相似。模型没有过度拟合训练数据，因此当我们从验证集移动到测试集时，模型不会崩溃。
- en: If we care about the model's performance in comparison to Kaggle competitors,
    our model's accuracy on a test set is also excellent. The Kaggle [private leaderboard](https://www.kaggle.com/c/bluebook-for-bulldozers/leaderboard)
    lists the performance of competitors' models on an unseen test set, just as we've
    done for our test set. But, the Kaggle competition is now closed, so we can't
    submit our model for evaluation using the actual final test set used in the competition.
    While the two test sets aren't identical, comparing the scores gives us a rough
    estimate of how well our model would perform in the competition. Our model's score
    of 0.2396 would put us at about 20th position, somewhere in the top 5%. (Out of
    475 competitors, the highest score, lowest RMSLE, was 0.22909.)
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们关心我们的模型与Kaggle竞争者的表现，我们的模型在测试集上的准确率也非常出色。Kaggle [私有排行榜](https://www.kaggle.com/c/bluebook-for-bulldozers/leaderboard)列出了竞争者模型在未见过的测试集上的表现，就像我们对我们测试集所做的那样。但是，Kaggle比赛现在已经结束，所以我们不能使用比赛实际使用的最终测试集来评估我们的模型。虽然两个测试集并不完全相同，但比较分数可以给我们一个大致估计，我们的模型在比赛中的表现会如何。我们的模型得分为0.2396，将使我们处于大约第20位，大约在顶部5%左右。（在475名竞争者中，最高分，最低RMSLE是0.22909。）
- en: If you compare the private and public leaderboards, you'll see that 108 out
    of 475 competitors were able to get an RMSLE of 0.0 on the provided validation
    set. In other words, if you create an ensemble of enough models and work really
    hard, you can tailor your model to perfectly predict a known validation set. Those
    models are almost certainly dramatically overfit, which is why most of them performed
    very poorly on the unseen test set, whose results are shown on the private leaderboard.
    108 models got perfect scores on the visible validation set, but position 108
    for the unseen test set is below a benchmark model provided by Kaggle. Nothing
    worse than the benchmark score counts for the contest. The point is that it's
    possible to find a particular combination of models and features that nails a
    specific, known data set, but that doesn't mean the model is useful. Models are
    only potentially useful if they generalize well to unseen data sets.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你比较私有和公共排行榜，你会看到在提供的验证集中，475名参赛者中有108人能够将RMSLE降至0.0。换句话说，如果你创建足够多的模型并非常努力地工作，你可以调整你的模型以完美预测一个已知的验证集。这些模型几乎肯定过度拟合，这也是为什么它们在未见过的测试集上表现非常糟糕，其结果在私有排行榜上显示。108个模型在可见的验证集上获得了满分，但在未见过的测试集上的排名108低于Kaggle提供的基准模型。比基准分数还差的分数对比赛来说毫无意义。重点是，有可能找到特定的模型和特征组合，以完美匹配特定的已知数据集，但这并不意味着模型是有用的。模型只有当它们很好地泛化到未见过的数据集时，才具有潜在的有用性。
- en: 'Instead of asking how our model compares to other models, a better question
    asks whether or not our model is useful. Let''s take a look at the various scores
    we got after various training and testing stages:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是询问我们的模型与其他模型相比如何，一个更好的问题是我们的模型是否有用。让我们看看在各个训练和测试阶段后得到的各种分数：
- en: '|   | OOB R^2 | RMSLE | MAE |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|   | OOB R^2 | RMSLE | MAE |'
- en: '| --- | --- | --- | --- |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Stage |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 |'
- en: '| --- |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Training 100k records | 0.8815 | 0.2489 | 5939 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 训练10万条记录 | 0.8815 | 0.2489 | 5939 |'
- en: '| Training set >= 2007 | 0.8834 | 0.2469 | 5967 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 训练集 >= 2007 | 0.8834 | 0.2469 | 5967 |'
- en: '| After tuning | 0.8964 | 0.2327 | 5687 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 调优后 | 0.8964 | 0.2327 | 5687 |'
- en: '| Best feature subset | 0.8985 | 0.2303 | 5642 |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 最佳特征子集 | 0.8985 | 0.2303 | 5642 |'
- en: '| Inflation adjusted | 0.9010 | 0.2275 | 5464 |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 调整通货膨胀后 | 0.9010 | 0.2275 | 5464 |'
- en: '| Test set | 0.8936 | 0.2396 | 6018 |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 测试集 | 0.8936 | 0.2396 | 6018 |'
- en: After all of that hard work on the model using the validation set, the average
    bulldozer price prediction is still off by $5464\. We started at $5939, but that
    might not be a meaningful improvement for a practical system. Price predictions
    are off by more than 15% on the validation set and about 20% on the test set.
    On the other hand, our model would still be useful if it were more accurate than
    a human.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用验证集对模型进行所有这些艰苦的工作之后，平均推土机价格预测仍然偏离了5464美元。我们开始于5939美元，但这可能对实际系统来说不是有意义的改进。价格预测在验证集上偏离了超过15%，在测试集上大约偏离了20%。另一方面，如果我们的模型比人类更准确，它仍然是有用的。
- en: 9.5 Summary
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 摘要
- en: We just finished a three-chapter sequence on the bulldozer data set. We've learned
    some new data cleaning and string normalization techniques, but more importantly,
    we learned how to deal with missing values. During feature engineering, we split
    apart dates and encoded categorical variables using ordinal encodings and one-hot
    encodings. In this chapter, we saw how to create validation and test sets for
    time-sensitive data and studied how to keep them consistent with the training
    data. Let's summarize the techniques from this chapter.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚完成了一个关于推土机数据集的三章序列。我们学习了一些新的数据清洗和字符串归一化技术，但更重要的是，我们学习了如何处理缺失值。在特征工程中，我们将日期分开，并使用顺序编码和独热编码对分类变量进行编码。在本章中，我们看到了如何为时间敏感数据创建验证集和测试集，并研究了如何使它们与训练数据保持一致。让我们总结本章的技术。
- en: To put machine learning into practice, we need a training set, a validation
    set, and a test set. The test set is extracted first and held out to be used once
    by our final model as an objective measure of generality. We train the model on
    the training set and test it on the validation set. Model tuning occurs by observing
    the effects of changing hyperparameters on validation set metrics. We never tune
    the model on the test set and never run the test set through an intermediate model.
    If the data is time-sensitive, we can't extract random subsets for validation
    and testing. We sort by date then split off the last 15% as the test set; the
    second to last 15% is the validation set.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要将机器学习应用于实践，我们需要一个训练集、一个验证集和一个测试集。首先提取测试集，并将其保留以供我们的最终模型一次性使用，作为泛化性的客观衡量标准。我们在训练集上训练模型，并在验证集上测试它。通过观察改变超参数对验证集指标的影响来进行模型调优。我们决不在测试集上调整模型，也决不将测试集通过中间模型运行。如果数据是时间敏感的，我们无法提取随机子集进行验证和测试。我们按日期排序，然后分割出最后15%作为测试集；倒数第二的15%是验证集。
- en: We have to prepare both the training and validation sets in the same way, but
    there are a number of consistency hazards. Each transformation to the training
    set must be tracked for application to the validation set. For example, in this
    chapter, we tracked the medians of all numerical columns, the categorical variables
    we one-hot encoded, and the category indexes for all categorical columns. To prevent
    one-hot encoding from introducing extra columns, apply the categorical index from
    the training set so that previously-unseen categories become missing values. Before
    making predictions using our validation set, make sure that order of the columns
    is the same in both data sets. Keep in mind the general rule that transformations
    done to the validation set can only use data computed from the training set, such
    as medians for filling in missing values.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须以相同的方式准备训练集和验证集，但存在许多一致性风险。对训练集的每次转换都必须跟踪以应用于验证集。例如，在本章中，我们跟踪了所有数值列的中位数、我们进行独热编码的分类变量以及所有分类列的类别索引。为了防止独热编码引入额外的列，应用训练集中的分类索引，使得之前未见的类别成为缺失值。在使用验证集进行预测之前，确保两个数据集中列的顺序相同。记住一般规则，对验证集所做的转换只能使用从训练集计算出的数据，例如用中位数填充缺失值。
- en: 'Tuning your model can include choosing the right training set, particularly
    for time-sensitive data. Sometimes the most recent data provides a more accurate
    picture of the future. There are three key RF hyperparameters to tune: the number
    of trees, the number of features considered per decision node, and the minimum
    size of decision tree leaves. Using a grid search that tries lots of combinations,
    we''ve found it effective to try them one-by-one, and in that order. After tuning
    the hyperparameters, follow the procedure to drop irrelevant features: train a
    model on the current feature set, compute the feature importances, drop the least
    important 10% from the feature set, repeat.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 调整你的模型可能包括选择合适的训练集，尤其是对于时间敏感的数据。有时最近的数据能提供对未来更准确的预测。有三个关键的RF超参数需要调整：树的数量、每个决策节点考虑的特征数量以及决策树叶子的最小大小。使用尝试大量组合的网格搜索，我们发现逐个尝试并按此顺序进行是有效的。在调整超参数后，按照以下程序删除无关特征：在当前特征集上训练模型，计算特征重要性，从特征集中删除最不重要的10%，重复此过程。
- en: As a final step, bring out your test set and run it through the model. The score
    you get, good or bad, is your objective measure of generality. If the test metrics
    are much worse than the validation metrics, then your model is overfit to the
    validation data. Remember that every time you try a new model or a combination
    of models, it's one more chance to find a model that just happens to work well
    on your validation set.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，拿出你的测试集并通过模型运行它。你得到的分数，无论好坏，都是你泛化能力的客观衡量标准。如果测试指标远低于验证指标，那么你的模型对验证数据过拟合了。记住，每次你尝试一个新的模型或模型组合，都是找到在验证集上恰好表现良好的模型的机会。
