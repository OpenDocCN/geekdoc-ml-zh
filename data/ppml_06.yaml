- en: Chapter 4 Analysis of Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 算法分析
- en: 原文：[https://ppml.dev/algorithms.html](https://ppml.dev/algorithms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ppml.dev/algorithms.html](https://ppml.dev/algorithms.html)
- en: In the previous chapters we discussed how the hardware architectures we use
    (Chapter [2](hardware.html#hardware)), the nature of the data we analyse and how
    we represent data with data structures (Chapter [3](types-structures.html#types-structures))
    contribute to the performance of a machine learning pipeline. The last major piece
    of this puzzle is the algorithmic complexity of the algorithms that power the
    machine learning models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论了我们所使用的硬件架构（第[2](hardware.html#hardware)章）、我们分析的数据的性质以及我们如何使用数据结构来表示数据（第[3](types-structures.html#types-structures)章），这些都对机器学习管道的性能产生了影响。这个谜题的最后一块主要部分是驱动机器学习模型的算法的算法复杂度。
- en: Algorithmic complexity is defined, in the abstract, as the amount of resources
    required by an algorithm to complete. After using pseudocode to write a high-level
    description of the machine learning algorithm we would like to implement (Section
    [4.1](algorithms.html#pseudocode)), we can determine the complexity of its components
    and how they contribute to the complexity of the algorithm as a whole. We represent
    and reason about complexity in mathematical terms with big-\(O\) notation (Section
    [4.2](algorithms.html#bigO-intro)). Quantifying it (Section [4.3](algorithms.html#bigO-benchmark))
    presents several issues that are specific to machine learning (Section [4.4](algorithms.html#bigO-ml)),
    which we will illustrate with three examples (Section [4.5](algorithms.html#bigO-examples)).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 算法复杂度在抽象上定义为算法完成所需资源的数量。在用伪代码编写我们想要实现的机器学习算法的高层次描述（第[4.1](algorithms.html#pseudocode)节）之后，我们可以确定其组件的复杂度以及它们如何影响整个算法的复杂度。我们用大-\(O\)符号（第[4.2](algorithms.html#bigO-intro)节）的数学术语来表示和推理复杂度。量化它（第[4.3](algorithms.html#bigO-benchmark)节）提出了几个特定于机器学习的问题（第[4.4](algorithms.html#bigO-ml)节），我们将通过三个例子（第[4.5](algorithms.html#bigO-examples)节）来阐述这些问题。
- en: 4.1 Writing Pseudocode
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 编写伪代码
- en: 'The first step in reasoning about an algorithm is to write it down using *pseudocode*,
    combining the understandability of natural language and the precision of code
    to facilitate our analysis and the subsequent implementation in software. Natural
    language is easier to read, but it is also ambiguous. Code, on the other hand,
    is too specific: it forces us to think about implementation details and programming-language
    conventions thus making it harder to focus on the overall picture.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 推理算法的第一步是使用*pseudocode*将其写下来，结合自然语言的易读性和代码的精确性，以方便我们的分析和随后的软件实现。自然语言更容易阅读，但它也是模糊的。另一方面，代码过于具体：它迫使我们考虑实现细节和编程语言约定，这使得我们更难关注整体图景。
- en: 'Pseudocode is meant to offset the weaknesses of natural language and code while
    preserving their strong points. Ideally, it provides a high-level description
    of an algorithm that facilitates its analysis and implementation by making the
    intent of each step clear while suppressing those details that are irrelevant
    for understanding the algorithm. There is no universal standard on how to write
    pseudocode, although some general guidelines exist (see, for instance, Chapter
    9 in “Code Complete” (McConnell [2004](#ref-codecomplete))). The three key guidelines
    that are commonly accepted are:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pseudocode旨在弥补自然语言和代码的弱点，同时保留它们的优点。理想情况下，它提供了一个算法的高级描述，通过使每一步的意图清晰，同时抑制那些对理解算法无关紧要的细节，从而促进其分析和实现。虽然有一些通用的指南（例如，“Code
    Complete”第9章[2004](#ref-codecomplete)），但关于如何编写伪代码没有普遍的标准。通常接受的三条关键指南是：
- en: Each step of the algorithm should be a separate, self-contained item in an enumeration.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的每一步都应该是一个列举中的独立、自包含的项目。
- en: Pseudocode should combine the styles of good code and of good natural language
    to some extent. For instance, it may fall short of full sentences. It should avoid
    idioms and conventions specific to any particular programming language, using
    a lax syntax for code statements. For the same reason, variable names should come
    from the domain of the problem the algorithm is trying to solve rather than from
    how they will be implemented (for instance, in terms of data structures). We will
    return to this point in Section [6.2](writing-code.html#naming).
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伪代码应在一定程度上结合良好代码和良好自然语言的风格。例如，它可能不足以构成完整的句子。它应避免特定编程语言的习语和约定，使用宽松的语法来表示代码语句。同样，变量名应来自算法试图解决的问题域，而不是它们将如何实现（例如，以数据结构的形式）。我们将在第[6.2](writing-code.html#naming)节中回到这一点。
- en: Pseudocode should ignore unnecessary details and use short-hand notation when
    possible, leaving the context to more in-depth forms of documentation. In other
    words, the level of detail should be that of a high-level view of the overall
    structure of the algorithm so that we can focus on its intent.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伪代码应忽略不必要的细节，并在可能的情况下使用缩写符号，将上下文留给更深入的文档形式。换句话说，细节的级别应该是算法整体结构的概览，以便我们可以专注于其意图。
- en: Admittedly, these recommendations are vague because the best way of conveying
    a high-level view of an algorithm to the reader depends on a combination of the
    pseudocode style and the reader’s background. As usual, knowing the audience is
    key in communicating effectively.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 诚然，这些推荐是模糊的，因为将算法的高级视图传达给读者的最佳方式取决于伪代码风格和读者背景的结合。通常，了解受众是有效沟通的关键。
- en: 'Writing good pseudocode for machine learning algorithms, or for machine learning
    pipelines spanning multiple algorithms, has two additional complications: the
    role played by the data and the need to integrate some amount of mathematical
    notation.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为机器学习算法编写良好的伪代码，或为跨越多个算法的机器学习管道编写伪代码，有两个额外的复杂性：数据所起的作用以及需要整合一定量的数学符号。
- en: Firstly, if we are to treat data as code (Section [5.1](design-code.html#data-as-code)),
    we may want to include more details about them in the pseudocode than we would
    in other settings. Such information may include, for example, the dimensions of
    the data and those characteristics of its features that are crucial for the algorithm
    to function. In a sense, this is similar to including some type information about
    key objects, and it is useful in clarifying what the inputs and the outputs of
    the algorithm are as well as in giving more context to key steps.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果我们把数据视为代码（第[5.1](design-code.html#data-as-code)节），我们可能希望在伪代码中包含比其他设置更多的细节。此类信息可能包括数据的维度和对其特征的一些关键特性，这些特性对于算法的功能至关重要。在某种程度上，这类似于包含一些关于关键对象类型的信息，这对于阐明算法的输入和输出以及为关键步骤提供更多上下文是有用的。
- en: Secondly, mathematical notation may be the best tool to describe key steps in
    a clear and readable way, so we may want to integrate it with natural language
    and code to the best effect. In order to do that, we should define all the variables
    and the functions used in the notation while leaving additional details to a separate
    document. For practical purposes, mentioning the meaning of each symbol when introducing
    new mathematical notation (for instance, “the prior Beta distribution \(\pi(\alpha,
    \beta) \sim \mathit{Be}(\alpha, \beta)\)” as opposed to just “\(\pi(\alpha, \beta)
    \sim \mathit{Be}(\alpha, \beta)\)”) is often enough to give context (what are
    properties of \(\pi\), how it will be used, etc.). Complex formulas, derivations
    and formal proofs would reduce the readability of pseudocode by making it overlong
    and forcing the reader to concentrate on understanding them instead of looking
    at the overall logic of the algorithm.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，数学符号可能是描述关键步骤的清晰和可读性的最佳工具，因此我们可能希望将其与自然语言和代码结合以产生最佳效果。为了做到这一点，我们应该定义在符号中使用的所有变量和函数，同时将额外的细节留给单独的文档。出于实用目的，在引入新的数学符号时（例如，“先验Beta分布
    \(\pi(\alpha, \beta) \sim \mathit{Be}(\alpha, \beta)\)”而不是仅仅“\(\pi(\alpha, \beta)
    \sim \mathit{Be}(\alpha, \beta)\)”），通常足以提供上下文（\(\pi\)的性质是什么，它将如何被使用等）。复杂的公式、推导和形式证明会通过使其过长并迫使读者专注于理解它们而不是查看算法的整体逻辑来降低伪代码的可读性。
- en: 'Describing all algorithms used in a machine learning pipeline using pseudocode
    has some further advantages we will touch on in later chapters:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用伪代码描述机器学习管道中使用的所有算法有一些进一步的优点，我们将在后面的章节中讨论：
- en: it makes code review easier (see Section [6.6](writing-code.html#code-review));
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使代码审查更容易（参见第 [6.6](writing-code.html#code-review) 节）；
- en: it facilitates iterative refinement because pseudocode is easier to modify than
    code (see Section [5.3.1](design-code.html#scoping-pipeline));
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过伪代码比代码更容易修改而促进迭代细化（参见第 [5.3.1](design-code.html#scoping-pipeline) 节）；
- en: it provides design documentation in a form that is easy to maintain (see Section
    [8.3](documenting-code.html#designdocs)).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它以易于维护的形式提供设计文档（参见第 [8.3](documenting-code.html#designdocs) 节）；
- en: 4.2 Computational Complexity and Big-\(O\) Notation
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 计算复杂性和大-\(O\) 符号
- en: 'Computational complexity is a branch of computer science that focuses on classifying
    computational problems according to their inherent difficulty across three different
    dimensions:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 计算复杂性是计算机科学的一个分支，它专注于根据其固有的难度在三个不同维度上对计算问题进行分类：
- en: as a function of input size (say, the sample size or the number of variables);
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为输入大小的函数（例如，样本大小或变量的数量）；
- en: as a function of how much resources will be used, in particular time (say, CPU
    time spent) and space (memory or storage use);
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为资源使用量的函数，特别是时间（例如，CPU 时间消耗）和空间（内存或存储使用）；
- en: on average (how long it will typically take), in the best case or in the worst
    case (how long it can possibly take).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均情况下（通常需要多长时间），在最佳情况或最坏情况下（可能需要多长时间）。
- en: 'In other words, we would like to infer how much resources an algorithm will
    use just from its specification: this is called *algorithm analysis*. Typically,
    the specification takes the form of pseudocode. As for the resources, we must
    first choose our unit of measurement. In the case of space complexity, the choice
    is usually obvious: either an absolute memory unit (such as MB, GB) or a relative
    one (such as the number of double-precision floating point values) for various
    types of memory (RAM, GPU memory, storage). In the case of time complexity, we
    must choose a set of fundamental operations that we consider to have a theoretical
    complexity of \(1\). Such operations can range from simple (arithmetic operations)
    to complex (models trained) depending on the level of abstraction we would like
    to work at. On the one hand, the lower the level of abstraction, the more we need
    to know about the specific implementation details of the algorithm. This is only
    feasible up to a point because pseudocode will omit most such details. It is also
    undesirable to some extent because it makes the analysis less general: a different
    implementation of the same algorithm may end up in a different class of complexity
    while exhibiting about the same behaviour in practice. On the other hand, the
    higher the level of abstraction, the higher the chance of obtaining an estimate
    of complexity that is only loosely connected to reality. The more complex the
    operations, the more unlikely it will be that they have the same complexity and
    that their complexity can be taken to be constant.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们希望仅从算法的规范中推断出它将使用多少资源：这被称为 *算法分析*。通常，规范采用伪代码的形式。至于资源，我们首先必须选择我们的度量单位。在空间复杂性的情况下，选择通常是显而易见的：对于各种类型的内存（RAM、GPU
    内存、存储），要么是绝对内存单位（如 MB、GB），要么是相对单位（如双精度浮点值的数量）。在时间复杂性的情况下，我们必须选择一组基本操作，我们认为它们具有理论上的复杂度为
    \(1\)。这些操作可以从简单（算术运算）到复杂（训练的模型）不等，这取决于我们希望工作的抽象级别。一方面，抽象级别越低，我们越需要了解算法的具体实现细节。这只有在一定程度上是可行的，因为伪代码将省略大多数此类细节。这在某种程度上也是不希望的，因为它使得分析不那么通用：同一算法的不同实现可能最终属于不同的复杂性类别，而在实践中表现出几乎相同的行为。另一方面，抽象级别越高，获得与现实仅松散相关的复杂性估计的可能性就越高。操作越复杂，它们具有相同复杂性的可能性就越小，并且它们的复杂性可以被认为是常数。
- en: 'The estimates of computational complexity produced by algorithm analysis are
    written using *big-\(O\)* and related notations, which define the class of complexity
    in the limit of the input sizes (Knuth [1976](#ref-knuth-big0), [1997](#ref-aocp)).
    (All algorithms are fast with small inputs.) More in detail:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 算法分析产生的计算复杂性估计使用 *big-\(O\)* 和相关符号书写，这些符号定义了输入大小极限下的复杂性类别（Knuth [1976](#ref-knuth-big0),
    [1997](#ref-aocp))。 (所有算法在输入较小的情况下都是快速的。) 更详细地说：
- en: We describe the *worst-case* scenario using *big-\(O\)* notation. Formally,
    an algorithm with input of size \(N \to \infty\) has a complexity \(f(N) = O(g(N))\)
    if there exists a \(c_0 > 0\) such that \(f(N) \leqslant c_0 g(N)\). It represents
    an upper bound in complexity.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用**大-\(O\)**符号描述**最坏情况**场景。形式上，一个输入大小为\(N \to \infty\)的算法，如果存在一个\(c_0 > 0\)使得\(f(N)
    \leqslant c_0 g(N)\)，则其复杂度为\(f(N) = O(g(N))\)。这代表复杂度的一个上界。
- en: 'We describe the *best-case* scenario using *big-\(\Omega\)* notation: \(f(N)
    = \Omega(g(N))\), \(f(N) \geqslant c_1 g(N)\) with \(c_1 > 0\). It represents
    a lower bound in complexity.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用**大-\(\Omega\)**符号描述**最佳情况**场景：\(f(N) = \Omega(g(N))\)，\(f(N) \geqslant
    c_1 g(N)\)且\(c_1 > 0\)。这代表复杂度的一个下界。
- en: 'We describe the *average case* using *big-\(\Theta\)* notation: \(f(N) = \Theta(g(N))\),
    \(c_2 g(N) \leqslant f(N) \leqslant c_3 g(N)\) with \(c_2, c_3 > 0\). It represents
    the average complexity.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用**大-\(\Theta\)**符号描述**平均情况**：\(f(N) = \Theta(g(N))\)，\(c_2 g(N) \leqslant
    f(N) \leqslant c_3 g(N)\)且\(c_2, c_3 > 0\)。这代表平均复杂度。
- en: In practice, we often just write things like “it is \(O(g(N))\) on average and
    \(O(h(N))\) in the worst case” and use big-\(O\) for all three cases. If we are
    considering inputs that are best described with a combination of different sizes
    (say, \(\{M, N, P\}\)), *big-\(O\)* will be a multivariate function like \(O(g(M,
    N, P))\).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们经常只写像“平均情况下是\(O(g(N))\)，最坏情况下是\(O(h(N))\)”这样的东西，并且对所有三种情况都使用大-\(O\)。如果我们考虑的是可以用不同大小组合来最好描述的输入（比如说，\(\{M,
    N, P\}\)），**大-\(O\)**将是一个多元函数，如\(O(g(M, N, P))\)。
- en: '![A graphical comparison of computational complexity classes.](../Images/c15ab8b704fda37f4d619933b63cc935.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![计算复杂度类别的图形比较。](../Images/c15ab8b704fda37f4d619933b63cc935.png)'
- en: 'Figure 4.1: A graphical comparison of computational complexity classes.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：计算复杂度类别的图形比较。
- en: 'Different classes of complexity in common use are shown in Figure [4.1](algorithms.html#fig:figure-complexity).
    Algorithms that belong to \(O(1)\), \(O(\log N)\), \(O(N)\) and \(O(N \log N)\)
    are considered efficient, while those that belong to \(O(N^2)\) or higher classes
    of complexity are more demanding. In a sense, this classification reflects the
    economics of running compute systems: it may be feasible to double our hardware
    requirements every time \(N\) doubles, but increasing it by a power of 2 or more
    is rarely possible!'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的不同复杂度类别在图[4.1](algorithms.html#fig:figure-complexity)中展示。属于\(O(1)\)、\(O(\log
    N)\)、\(O(N)\)和\(O(N \log N)\)的算法被认为是高效的，而属于\(O(N^2)\)或更高复杂度类别的算法则要求更高。从某种意义上说，这种分类反映了运行计算系统的经济性：每次\(N\)加倍时，可能可行地加倍我们的硬件需求，但增加2的幂或更多则很少可能！
- en: 'How can we use big-\(O\) notation? If we are comparing algorithms in different
    classes of complexity, we can concentrate only on the leading term: \(O(3 \cdot
    2^N + 3.42 N^2) \gg O(2 N^3 + 3 N^2)\) is functionally equivalent to \(O(2^N)
    \gg O(N^3)\) because the difference in the order of magnitude makes lower-order
    terms and even the coefficient of the leading term irrelevant. If we are comparing
    algorithms in the same class of complexity, we only report the leading term and
    its coefficient: \(O(1.2 N^2 + 3N) \gg O(0.9 N^2 + 2 \log N)\) becomes \(O(1.2
    N^2) \gg O(0.9 N^2)\). In the former case, we can say algorithms scale in fundamentally
    different ways as their inputs grow in size. In the latter, we can say that algorithms
    scale similarly but still rank them.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何使用大-\(O\)符号？如果我们正在比较不同复杂度类别的算法，我们可以只关注最高阶项：\(O(3 \cdot 2^N + 3.42 N^2) \gg
    O(2 N^3 + 3 N^2)\)在功能上等同于\(O(2^N) \gg O(N^3)\)，因为量级上的差异使得低阶项甚至最高阶项的系数都无关紧要。如果我们正在比较同一复杂度类别的算法，我们只报告最高阶项及其系数：\(O(1.2
    N^2 + 3N) \gg O(0.9 N^2 + 2 \log N)\)变为\(O(1.2 N^2) \gg O(0.9 N^2)\)。在前一种情况下，我们可以说算法在输入规模增长时以不同的方式扩展。在后一种情况下，我们可以说算法扩展方式相似，但仍然可以对其进行排名。
- en: In most practical settings, however, interpreting big-\(O\) notation requires
    a more nuanced approach because of its intrinsic limitations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在大多数实际设置中，由于其固有的局限性，解释大-\(O\)符号需要更细致的方法。
- en: Big-\(O\) notation does not include constant terms, so it may not necessarily
    map well to real-world performance. Algorithms with complex initialisation phases
    that do not scale with input sizes may be slower than algorithms with higher complexity
    for even moderate input sizes. This may be the case of algorithms that cache partial
    results or sufficient statistics when the caching is more expensive than recomputing
    those quantities from scratch as needed.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大-O记号不包括常数项，因此它可能不一定很好地映射到现实世界的性能。具有复杂初始化阶段且不随输入大小缩放的算法可能比具有更高复杂度的算法在中等输入大小下运行得更慢。这可能适用于那些在缓存比从零开始重新计算这些数量更昂贵时缓存部分结果或足够统计量的算法。
- en: 'Similarly, the coefficients in big-\(O\) notation are usually not realistic:
    for instance, a time complexity \(O(2N)\) does not guarantee that doubling \(N\)
    will double running time. How the algorithm is implemented, on what hardware,
    etc. may not affect the class of complexity but they always have a strong effect
    on the associated coefficients. As a result, we should estimate those coefficients
    from empirical run-times to obtain realistic performance curves, and use the latter
    to compare algorithms within the same class of complexity.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似地，大-O记号中的系数通常并不现实：例如，时间复杂度 \(O(2N)\) 并不能保证 \(N\) 加倍时运行时间也会加倍。算法的实现方式、硬件等可能不会影响复杂度类别，但它们总是对相关系数有强烈的影响。因此，我们应该从经验运行时间中估计这些系数，以获得现实性能曲线，并使用这些曲线来比较同一复杂度类别的算法。
- en: 'There is a compromise between space and time complexity: we trade off one for
    the other. Arguably, space complexity is more important than time complexity.
    In principle, we can wait a bit longer to get the results, but if our program
    runs out of memory, it will crash and we will get no results at all.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间复杂度和时间复杂度之间存在权衡：我们在这两者之间进行权衡。可以说，空间复杂度比时间复杂度更重要。原则上，我们可以等待更长的时间来获取结果，但如果我们的程序耗尽内存，它将崩溃，我们将无法得到任何结果。
- en: 4.3 Big-\(O\) Notation and Benchmarking
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 大-O记号和基准测试
- en: 'Producing empirical performance curves for all relevant dimensions of computational
    complexity differs from other forms of benchmarking in a few ways. If we know
    the theoretical class of complexity an algorithm belongs to, a simple linear model
    will suffice for estimating the coefficients of the terms in its big-\(O\) notation:
    we will show some examples in Section [4.5](algorithms.html#bigO-examples). However,
    we should take some care in how performance is measured and in how we interpret
    the empirical curves.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为所有相关的计算复杂度维度生成经验性能曲线与其他形式的基准测试有所不同。如果我们知道算法所属的理论复杂度类别，一个简单的线性模型就足以估计其大-O记号中项的系数：我们将在第
    [4.5](algorithms.html#bigO-examples) 节中展示一些示例。然而，我们在测量性能和解释经验曲线时应该小心谨慎。
- en: Firstly, we should plan the collection of the performance measurements following
    the best practices in the design of physical (Montgomery [20AD](#ref-montgomery))
    and computer simulation (Santner, Williams, and Notz [2018](#ref-santner)) experiments.
    If we are measuring complexity along a single dimension, we should collect multiple
    performance measurements for each input size. The average performance at each
    input size will provide a more stable estimate than a single measurement, and
    we can use the distribution of the performance measurements to establish confidence
    bands around the average. Bands based on empirical quantiles (say, the interval
    between the [5%, 95%] quantiles) are often preferable to bands based on the quantiles
    of the normal distribution (say, average performance \(\pm\) the standard deviation
    times the 95% quantile of the standard normal) because the latter is symmetric
    around the average and fails to account for the fact that performance is skewed.
    Performance is naturally bounded below by zero (instant execution!) and the average
    performance may be close enough to zero that the bottom of the confidence band
    is negative!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们应该按照物理（Montgomery [20AD](#ref-montgomery)）和计算机模拟（Santner, Williams, and
    Notz [2018](#ref-santner)）实验设计中的最佳实践来规划性能测量的收集。如果我们沿着单维测量复杂性，我们应该为每个输入大小收集多个性能测量值。每个输入大小的平均性能将比单个测量值提供更稳定的估计，并且我们可以使用性能测量的分布来建立围绕平均值的置信区间。基于经验分位数（例如，[5%，95%]
    分位数之间的区间）的区间通常比基于正态分布分位数（例如，平均性能 \(\pm\) 标准差乘以标准正态分布的 95% 分位数）的区间更可取，因为后者在平均值周围是对称的，并且未能考虑到性能是偏斜的事实。性能自然地被零（即时执行！）所限制，并且平均性能可能足够接近零，以至于置信区间的底部是负的！
- en: If we are measuring complexity along multiple dimensions, it is best to use
    a single experimental design that involves all of them in order to separate the
    main effect of each dimension from their interactions. Big-\(O\) notation may
    not include terms that contain more than one dimension, and in that case it is
    interesting to check whether that is true in practice as well. Or big-\(O\) notation
    may include such terms, and then the only consistent way of estimating their coefficients
    is to vary all the involved input sizes simultaneously.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在多个维度上测量复杂性，最好使用一个包含所有这些维度的单一实验设计，以便将每个维度的主效应与其相互作用分开。大 \(O\) 符号可能不包括包含多个维度的项，在这种情况下，检查这在实践中是否也成立是有趣的。或者大
    \(O\) 符号可能包括这样的项，然后估计它们的系数的唯一一致方法是同时改变所有涉及到的输入大小。
- en: 'If we are comparing two algorithms in the same complexity class, we should
    do that on performance differences generated on the same sets of inputs to increase
    the precision of our comparison. If we use different inputs, the performance measures
    we collect for each input size are independent across algorithms: if those algorithms
    are \(O(f(N))\) and \(O(g(N))\) respectively, \[\begin{equation*} \operatorname{VAR}(f(N)
    - g(N)) = \operatorname{VAR}(f(N)) + \operatorname{VAR}(g(N)). \end{equation*}\]
    However, if we use the same inputs for both algorithms \[\begin{multline*} \operatorname{VAR}(f(N)
    - g(N)) = \operatorname{VAR}(f(N)) + \operatorname{VAR}(g(N)) - \\ 2\operatorname{COV}(f(N),
    g(N)) \end{multline*}\] because the performance measures are no longer independent.
    Since \(\operatorname{COV}(f(N), g(N)) > 0\), the empirical differences in performance
    will have smaller variability and thus greater precision.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在同一复杂性类中比较两个算法，我们应该在相同输入集上生成的性能差异上进行比较，以提高我们比较的精确度。如果我们使用不同的输入，我们为每个输入大小收集的性能度量在算法之间是独立的：如果这些算法分别是
    \(O(f(N))\) 和 \(O(g(N))\)，则有 \[\begin{equation*} \operatorname{VAR}(f(N) - g(N))
    = \operatorname{VAR}(f(N)) + \operatorname{VAR}(g(N)). \end{equation*}\] 然而，如果我们为两个算法使用相同的输入
    \[\begin{multline*} \operatorname{VAR}(f(N) - g(N)) = \operatorname{VAR}(f(N))
    + \operatorname{VAR}(g(N)) - \\ 2\operatorname{COV}(f(N), g(N)) \end{multline*}\]
    因为性能度量不再独立。由于 \(\operatorname{COV}(f(N), g(N)) > 0\)，性能的差异将具有更小的变异性，因此具有更高的精确度。
- en: 'Secondly, we should carefully choose the compute system we use. The system
    should “stand still” while we are taking performance measurements: if other tasks
    are running at the same time, they may try to access shared resources that are
    also involved in our performance measures. This has two negative effects: it makes
    performance measures noisier and it inflates the estimated coefficients by making
    the average performance worse.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们应该仔细选择我们使用的计算系统。当我们进行性能测量时，系统应该“静止不动”：如果同时运行其他任务，它们可能会尝试访问也涉及我们性能度量的共享资源。这有两个负面影响：它使性能度量更嘈杂，并通过使平均性能变差来使估计的系数膨胀。
- en: Thirdly, we should be careful in using performance curves to predict performance
    outside the range of the input sizes (or the combinations of input sizes) we actually
    measured. In any compute system with finite resources, resource contention will
    increase as the system reaches saturation. Hence we should use a compute system
    with enough resources to handle all the input sizes we consider without going
    anywhere near capacity. We are interested in measuring the performance of the
    algorithm, not of the compute system, so we should put stress on the former and
    not on the latter.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们在使用性能曲线预测实际测量输入大小（或输入大小的组合）范围之外的性能时应该小心。在任何具有有限资源的计算系统中，当系统达到饱和时，资源竞争会增加。因此，我们应该使用具有足够资源来处理我们考虑的所有输入大小，而不会接近容量的计算系统。我们感兴趣的是测量算法的性能，而不是计算系统的性能，因此我们应该强调前者而不是后者。
- en: 'Finally, note that most experimental design approaches assume that performance
    measures are independent. Hence we should strive to make our empirical measures
    as independent as possible by resetting the state of the compute system before
    each run: for instance, we should remove all temporary objects.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请注意，大多数实验设计方法都假设性能度量是独立的。因此，我们应该努力使我们的经验度量尽可能独立，通过在每次运行之前重置计算系统的状态来实现：例如，我们应该移除所有临时对象。
- en: 4.4 Algorithm Analysis for Machine Learning
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 机器学习算法分析
- en: Algorithm analysis presents some additional complications in the context of
    machine learning software.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习软件的背景下，算法分析带来了一些额外的复杂性。
- en: The first set of complications is related to defining the size of the input.
    Machine learning algorithms typically have a large number of different inputs,
    and the size of each input has several dimensions (such as the sample size and
    the number of variables). Hence algorithms will belong to different classes of
    complexity for different dimensions, and it will be unlikely that any will dominate
    the others in all dimensions. Sometimes we can reduce the number of dimensions
    we are considering by assuming some are bounded because of the intrinsic nature
    of the inputs or by expressing one dimension as a function of another (say, the
    number of variables is \(p \approx \sqrt{n}\) where \(n\) is the sample size).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第一组复杂性是与定义输入大小相关的。机器学习算法通常有大量不同的输入，每个输入的大小有几个维度（例如样本大小和变量数量）。因此，算法将属于不同复杂度类别的不同维度，并且不太可能在所有维度上主导其他维度。有时，我们可以通过假设某些维度由于输入的内禀性质是有界的，或者通过将一个维度表示为另一个维度的函数（例如，变量数量
    \(p \approx \sqrt{n}\) 其中 \(n\) 是样本大小）来减少我们考虑的维度数量。
- en: 'Furthermore, computational complexity depends strongly on the assumptions we
    make on the distributions of the inputs and not just on their sizes. More assumptions
    usually allow us to access algorithms with better performance, and make it possible
    to use closed-form results: the more knowledge we put in the form of assumptions,
    the less we have to learn empirical measures. Assuming some form of sparsity or
    regularity, or actively enforcing it in the learning process, will reduce the
    complexity of machine learning models to the point they become tractable. In most
    settings, not making any such assumption will mean exponential or combinatorial
    worst-case complexity. It is another trade-off: assumptions versus complexity.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，计算复杂度强烈依赖于我们对输入分布的假设，而不仅仅是它们的大小。更多的假设通常使我们能够访问性能更好的算法，并使使用闭式结果成为可能：我们以假设的形式投入的知识越多，我们就越不需要学习经验度量。假设某种形式的稀疏性或规律性，或在学习过程中积极强制执行它，可以将机器学习模型的复杂度降低到可处理的程度。在大多数情况下，不做出任何这样的假设将意味着指数或组合最坏情况复杂度。这是另一种权衡：假设与复杂度。
- en: For stochastic algorithms, we can only meaningfully reason on the average case.
    Consider Markov chain Monte Carlo (MCMC) posterior inference in Bayesian models,
    or stochastic gradient descent (SGD) for deep neural networks. Each time we run
    them, they go through a different sequence of steps and they may produce a different
    posterior distribution or model. As a consequence, each run will take a different
    amount of time and it will use a different amount of memory. The construction
    of such algorithms gives convergence guarantees and convergence rates, so we have
    some expectations about average complexity, but there is always some degree of
    uncertainty.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于随机算法，我们只能在平均情况下进行有意义的推理。考虑贝叶斯模型中的马尔可夫链蒙特卡洛（MCMC）后验推理，或者深度神经网络中的随机梯度下降（SGD）。每次运行它们时，它们都会通过不同的步骤序列，并可能产生不同的后验分布或模型。因此，每次运行所需的时间不同，使用的内存量也不同。这类算法的构建提供了收敛保证和收敛率，因此我们对平均复杂度有一些期望，但总存在一定程度的不确定性。
- en: 4.5 Some Examples of Algorithm Analysis
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 一些算法分析的例子
- en: We will now apply the concepts we just introduced by investigating the time
    complexity of estimating the coefficients of linear regression models (Section
    [4.5.1](algorithms.html#bigO-lm)); the trade-off between time and space complexity
    in sparse matrices (Section [4.5.2](algorithms.html#bigO-sparsem)); and the time
    and space complexity of an MCMC algorithm to generate random directed acyclic
    graphs from a uniform distribution (Section [4.5.3](algorithms.html#bigO-dags)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将通过研究线性回归模型系数的估计时间复杂度（第 [4.5.1](algorithms.html#bigO-lm) 节）来应用我们刚刚介绍的概念；稀疏矩阵中时间和空间复杂度之间的权衡（第
    [4.5.2](algorithms.html#bigO-sparsem) 节）；以及从均匀分布生成随机有向无环图（DAG）的 MCMC 算法的时间和空间复杂度（第
    [4.5.3](algorithms.html#bigO-dags) 节）。
- en: 4.5.1 Estimating Linear Regression Models
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.1 估计线性回归模型
- en: 'Linear models are the foundation upon which most of statistics and machine
    learning are built: we often use them either as standalone models or as part of
    more complex ones. Generally speaking, a linear model takes a vector \(\mathbf{y}\)
    and a matrix \(\mathbf{X}\) of real numbers and tries to explain \(\mathbf{y}\)
    as a function of \(\mathbf{X}\) that is linear in the parameters \(\boldsymbol{\beta}\).
    We can famously (Weisberg [2014](#ref-weisberg)) estimate \(\boldsymbol{\beta}\)
    with the closed-form expression \[\begin{equation*} \underset{p \times 1}{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}
    = (\underset{p \times n}{\mathbf{X}^\mathrm{T}\vphantom{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}}
    \, \underset{n \times p}{\mathbf{X}\vphantom{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}})^{-1}
    \underset{p \times n}{\mathbf{X}^\mathrm{T}\vphantom{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}}
    \, \underset{n \times 1}{\mathbf{y}} \end{equation*}\] which is, at the same time,
    the ordinary least squares estimate (from the orthogonal projection of \(\mathbf{y}\)
    onto the space spanned by the \(\mathbf{X}\)) and the maximum likelihood estimate
    of \(\boldsymbol{\beta}\) (under the assumption residuals are independent and
    normally distributed with a common variance). Note how we have annotated the formula
    above with the dimensions of both \(\mathbf{X}\) and \(\mathbf{y}\). Those are
    our inputs: their dimensions depend on the sample size \(n\) and on the number
    of variables \(p\).[⁹](#fn9) The algorithmic complexity of estimating \(\boldsymbol{\beta}\)
    will be a function of both.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型是大多数统计学和机器学习建立的基础：我们通常要么使用它们作为独立模型，要么作为更复杂模型的一部分。一般来说，线性模型接受一个实数向量 \(\mathbf{y}\)
    和一个实数矩阵 \(\mathbf{X}\)，并试图将 \(\mathbf{y}\) 解释为 \(\mathbf{X}\) 的函数，该函数在参数 \(\boldsymbol{\beta}\)
    上是线性的。我们可以用著名的闭式表达式（Weisberg [2014](#ref-weisberg)）估计 \(\boldsymbol{\beta}\)，表达式如下：\[\begin{equation*}
    \underset{p \times 1}{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}} = (\underset{p
    \times n}{\mathbf{X}^\mathrm{T}\vphantom{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}}
    \, \underset{n \times p}{\mathbf{X}\vphantom{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}})^{-1}
    \underset{p \times n}{\mathbf{X}^\mathrm{T}\vphantom{\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}}}
    \, \underset{n \times 1}{\mathbf{y}} \end{equation*}\]这个表达式同时是普通最小二乘估计（从 \(\mathbf{y}\)
    在 \(\mathbf{X}\) 张成的空间上的正交投影）和 \(\boldsymbol{\beta}\) 的最大似然估计（在残差独立且正态分布且具有相同方差的假设下）。注意我们如何在上述公式中标注了
    \(\mathbf{X}\) 和 \(\mathbf{y}\) 的维度。这些是我们的输入：它们的维度取决于样本大小 \(n\) 和变量的数量 \(p\)。[⁹](#fn9)
    估计 \(\boldsymbol{\beta}\) 的算法复杂度将取决于这两个因素。
- en: 'Another option to estimate \(\boldsymbol{\beta}\) is to use the QR decomposition
    of \(\mathbf{X}\) (Weisberg [2014](#ref-weisberg), Appendix A.9). Starting from
    the \(\mathbf{X}\boldsymbol{\beta}= \mathbf{y}\) formulation of the linear regression
    model, we perform the following steps:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 估计 \(\boldsymbol{\beta}\) 的另一种方法是使用 \(\mathbf{X}\) 的 QR 分解（Weisberg [2014](#ref-weisberg)，附录
    A.9）。从线性回归模型的 \(\mathbf{X}\boldsymbol{\beta}= \mathbf{y}\) 公式开始，我们执行以下步骤：
- en: compute the QR decomposition of \(\mathbf{X}\) (\(\mathbf{Q}\) is \(n \times
    p\), \(\mathbf{R}\) is \(p \times p\));
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 \(\mathbf{X}\) 的 QR 分解（\(\mathbf{Q}\) 是 \(n \times p\)，\(\mathbf{R}\) 是 \(p
    \times p\)）；
- en: rewrite the problem as \(\mathbf{R} \boldsymbol{\beta}= \mathbf{Q}^\mathrm{T}\mathbf{y}\);
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将问题重写为 \(\mathbf{R} \boldsymbol{\beta}= \mathbf{Q}^\mathrm{T}\mathbf{y}\)；
- en: compute \(\mathbf{Q}^\mathrm{T}\mathbf{y}\);
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 \(\mathbf{Q}^\mathrm{T}\mathbf{y}\);
- en: solve the resulting (triangular) linear system for \(\boldsymbol{\beta}\).
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解出结果（三角）线性系统以得到 \(\boldsymbol{\beta}\)。
- en: 'Let’s call this estimator \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\). If
    we discount numerical issues with pathological \(\mathbf{X}\)s, \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)
    and \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) give identical estimates of
    \(\boldsymbol{\beta}\): they are identical in terms of statistical properties,
    and neither makes any assumption of the distribution of \(\mathbf{X}\). However,
    we may still prefer one to the other because of their time complexity.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们称这个估计量为 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)。如果我们不考虑病态 \(\mathbf{X}\)
    的数值问题，\(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) 和 \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    给出相同的 \(\boldsymbol{\beta}\) 估计：它们在统计属性上是相同的，并且它们都没有对 \(\mathbf{X}\) 的分布做出任何假设。然而，我们可能仍然更喜欢其中一个，因为它们的时间复杂度不同。
- en: 'Firstly, what is the time complexity of computing \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)?
    The steps we would perform if we were estimating it by hand are:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，计算 \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 的时间复杂度是什么？如果我们手动估计它，我们会执行以下步骤：
- en: compute \(\mathbf{X}^\mathrm{T}\mathbf{X}\);
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 \(\mathbf{X}^\mathrm{T}\mathbf{X}\);
- en: invert it and compute \((\mathbf{X}^\mathrm{T}\mathbf{X})^{-1}\);
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取其逆并计算 \((\mathbf{X}^\mathrm{T}\mathbf{X})^{-1}\)；
- en: compute \(\mathbf{X}^\mathrm{T}\mathbf{y}\);
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 \(\mathbf{X}^\mathrm{T}\mathbf{y}\)；
- en: multiply the results from steps 2 and 3.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将步骤 2 和 3 的结果相乘。
- en: 'Given the simplicity of \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\), this
    description will suffice as the pseudocode for our analysis. From easily available
    sources (say, Wikipedia), we can find the time complexity of the operation in
    each step:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 的简单性，这个描述将足够作为我们分析的伪代码。从容易获取的资源（比如，维基百科），我们可以找到每个步骤中操作的复杂度：
- en: multiplying an \(r \times s\) matrix and an \(s \times t\) matrix takes \(O(rst)\)
    operations (Wikipedia [2021](#ref-wiki-matmult)[b](#ref-wiki-matmult));
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乘以一个 \(r \times s\) 矩阵和一个 \(s \times t\) 矩阵需要 \(O(rst)\) 次操作（维基百科 [2021](#ref-wiki-matmult)[b](#ref-wiki-matmult)）；
- en: computing the inverse of an \(r \times r\) matrix is \(O(r^3)\) using a Cholesky
    decomposition (Wikipedia [2021](#ref-wiki-chol)[a](#ref-wiki-chol)) or Gram-Schmidt
    (Wikipedia [2021](#ref-wiki-qr)[c](#ref-wiki-qr)).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Cholesky 分解（维基百科 [2021](#ref-wiki-chol)[a](#ref-wiki-chol)）或 Gram-Schmidt（维基百科
    [2021](#ref-wiki-qr)[c](#ref-wiki-qr)）计算 \(r \times r\) 矩阵的逆是 \(O(r^3)\)。
- en: 'These time complexities use arithmetic operations as the elementary operations,
    which is natural because matrices are just sets of numbers that are combined and
    transformed using those operations. The actual contents of \(\mathbf{X}\) and
    \(\mathbf{y}\) are irrelevant: both matrices appear in the big-\(O\) notation
    just with their dimensions.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这些时间复杂度使用算术运算作为基本运算，这是自然的，因为矩阵只是由这些运算组合和转换的数字集合。实际上 \(\mathbf{X}\) 和 \(\mathbf{y}\)
    的内容是无关紧要的：这两个矩阵在大 \(-O\) 符号中只出现它们的维度。
- en: 'Therefore, step 1 is \(O(pnp) = O(np^2)\), step 2 is \(O(p^3)\), step 3 is
    \(O(np)\) and step 4 is \(O(p^2)\). The overall time complexity is \[\begin{equation}
    O(np^2 + p^3 + np + p^2) = O(p^3 + (n + 1)p^2 + np) \tag{4.1} \end{equation}\]
    and it can be interpreted as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，步骤 1 是 \(O(pnp) = O(np^2)\)，步骤 2 是 \(O(p^3)\)，步骤 3 是 \(O(np)\) 且步骤 4 是 \(O(p^2)\)。整体时间复杂度是
    \[\begin{equation} O(np^2 + p^3 + np + p^2) = O(p^3 + (n + 1)p^2 + np) \tag{4.1}
    \end{equation}\] 并且可以这样解释：
- en: 'Estimating \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) is \(O(p^3)\) in
    the number of parameters \(p\): if \(p\) doubles, it takes eight times as long.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在参数数量 \(p\) 上估计 \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 是 \(O(p^3)\)：如果
    \(p\) 加倍，它需要八倍的时间。
- en: 'Estimating \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) is \(O(n)\) in the
    sample size \(n\): if \(n\) doubles, it takes twice as long.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在样本大小 \(n\) 中估计 \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 的时间复杂度为 \(O(n)\)：如果
    \(n\) 加倍，所需时间也加倍。
- en: 'Let’s look now at \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\). For time
    complexity we have that:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)。对于时间复杂度，我们有：
- en: solving an \(r \times s\) linear system with Gram-Schmidt is \(O(rs^2)\);[^(10)](#fn10)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Gram-Schmidt 解 \(r \times s\) 线性系统的时间复杂度为 \(O(rs^2)\)；[^(10)](#fn10)
- en: back-substitution to solve the triangular linear system in step 4 is \(O(s^2)\).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第四步中解三角线性系统进行回代的时间复杂度为 \(O(s^2)\)。
- en: Therefore, step 1 is \(O(np^2)\), step 3 is \(O(np)\) and step 4 is \(O(p^2)\).
    (Step 2 is merely for notation.) The overall time complexity is then \[\begin{equation}
    O(np^2 + np + p^2) = O((n + 1)p^2 + np), \tag{4.2} \end{equation}\] making \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)
    quadratic in the number of parameters and linear in the sample size. We can expect
    it to be faster than the closed-form estimator as \(p\) grows (\(O(p^2)\) instead
    of \(O(p^3)\)), but we cannot say which approach is faster as \(n\) grows because
    they are both \(O(n)\).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第一步的时间复杂度为 \(O(np^2)\)，第三步为 \(O(np)\)，第四步为 \(O(p^2)\)。（第二步仅用于表示。）因此，整体时间复杂度为
    \[\begin{equation} O(np^2 + np + p^2) = O((n + 1)p^2 + np), \tag{4.2} \end{equation}\]
    使得 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) 在参数数量上是二次的，在样本大小上是线性的。我们可以预期当
    \(p\) 增加时（\(O(p^2)\) 而不是 \(O(p^3)\)），它将比闭式估计量更快，但我们不能说哪种方法在 \(n\) 增加时更快，因为它们都是
    \(O(n)\)。
- en: 'Therefore, which algorithm is best depends on the data we expect to work on:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，哪种算法最好取决于我们期望处理的数据：
- en: if \(n \to \infty\) but \(p\) is bounded, \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    and \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) perform similarly well;
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 \(n \to \infty\) 但 \(p\) 有界时，\(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    和 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) 的表现相似；
- en: if \(p \to \infty\), \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) will be
    faster.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 \(p \to \infty\) 时，\(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) 将更快。
- en: How well do the time complexities in [(4.1)](algorithms.html#eq:betaEX) and
    [(4.2)](algorithms.html#eq:betaQR) map to real-world running times? We can answer
    this question by benchmarking \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) and
    \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) as we discussed in Section [4.3](algorithms.html#bigO-benchmark).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[(4.1)](algorithms.html#eq:betaEX) 和 [(4.2)](algorithms.html#eq:betaQR) 中的时间复杂度如何映射到实际的运行时间？我们可以通过基准测试
    \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 和 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)
    来回答这个问题，正如我们在第 [4.3](algorithms.html#bigO-benchmark) 节中讨论的那样。'
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![Marginal running times as a function of $n$ (with $p = 200$, top left) and
    of $p$ (with $n = 50000$, top right); the closed-form formula is shown in orange
    and the QR estimator in blue, each with 90% confidence bands. Joint running times
    in $(n, p)$ are shown in the bottom left and right panels for the closed-form
    formula and the QR estimator, respectively.](../Images/83d64531eef1af66eb66b554672c31d1.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![边际运行时间作为 \(n\) 的函数（\(p = 200\)，左上角）和作为 \(p\) 的函数（\(n = 50000\)，右上角）；闭式公式以橙色显示，QR
    估计量以蓝色显示，每个都带有 90% 的置信区间。在左下角和右下角面板中分别显示了闭式公式和 QR 估计量的联合运行时间。](../Images/83d64531eef1af66eb66b554672c31d1.png)'
- en: 'Figure 4.2: Marginal running times as a function of \(n\) (with \(p = 200\),
    top left) and of \(p\) (with \(n = 50000\), top right); the closed-form formula
    is shown in orange and the QR estimator in blue, each with 90% confidence bands.
    Joint running times in \((n, p)\) are shown in the bottom left and right panels
    for the closed-form formula and the QR estimator, respectively.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2：边际运行时间作为 \(n\) 的函数（\(p = 200\)，左上角）和作为 \(p\) 的函数（\(n = 50000\)，右上角）；闭式公式以橙色显示，QR
    估计量以蓝色显示，每个都带有 90% 的置信区间。在左下角和右下角面板中分别显示了闭式公式和 QR 估计量的联合运行时间。
- en: 'We plotted the results in Figure [4.2](algorithms.html#fig:ols-microbenchmark-plots).
    The top panels confirm the conclusions we reached earlier: both \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    and \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) have a time complexity that
    is linear in \(n\), hence they scale similarly; but \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    has a cubic time complexity in \(p\), which makes it much slower than \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)
    as \(p\) increases. The level plots in the bottom panels show that \(n\) and \(p\)
    jointly influence running times, which we should expect since both [(4.1)](algorithms.html#eq:betaEX)
    and [(4.2)](algorithms.html#eq:betaQR) contain mixed terms in which both \(n\)
    and \(p\) appear.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图 [4.2](algorithms.html#fig:ols-microbenchmark-plots) 中绘制了结果。顶部面板证实了我们之前得出的结论：\(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    和 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) 的时间复杂度与 \(n\) 线性相关，因此它们的缩放相似；但是
    \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 在 \(p\) 上的时间复杂度是三次方的，这使得当 \(p\)
    增加时，它比 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\) 慢得多。底部面板的水平图显示 \(n\) 和 \(p\)
    共同影响运行时间，这是我们应该预期的，因为 [(4.1)](algorithms.html#eq:betaEX) 和 [(4.2)](algorithms.html#eq:betaQR)
    都包含混合项，其中 \(n\) 和 \(p\) 都出现。
- en: Considering how little noise is in the running times we measured, we can reliably
    estimate the coefficients of the terms in [(4.1)](algorithms.html#eq:betaEX) and
    [(4.2)](algorithms.html#eq:betaQR) using a simple linear regression.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们所测量的运行时间中噪音很少，我们可以可靠地估计 [(4.1)](algorithms.html#eq:betaEX) 和 [(4.2)](algorithms.html#eq:betaQR)
    中项的系数，使用简单的线性回归。
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The models in `bigO.EX` and `bigO.QR` allow us to predict the running times
    for any combinations of \(n\) and \(p\). We can also use them to check how much
    the empirical complexity curves they encode overlap the corresponding empirical
    running times and check for outliers.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`bigO.EX` 和 `bigO.QR` 中的模型允许我们预测 \(n\) 和 \(p\) 的任何组合的运行时间。我们还可以使用它们来检查它们编码的经验复杂度曲线与相应的经验运行时间重叠的程度，并检查异常值。'
- en: 'As a final note, there are several additional considerations we should weigh
    before choosing which algorithm to use: the matrix inverse in \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    is known to be numerically unstable, which is why \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)
    is preferred in scientific software. `lm()` in both R and Julia, `fitlm()` in
    MATLAB are implemented on top of QR but, interestingly, `LinearRegression()` in
    Scikit-learn (Scikit-learn Developers [2022](#ref-sklearn)) is not.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的注意事项，在选择使用哪种算法之前，我们应该权衡几个额外的考虑因素：\(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    中的矩阵逆在数值上是不稳定的，这就是为什么在科学软件中更倾向于使用 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)。R
    和 Julia 中的 `lm()`，MATLAB 中的 `fitlm()` 都是在 QR 的基础上实现的，但有趣的是，Scikit-learn 中的 `LinearRegression()`（Scikit-learn
    开发者 [2022](#ref-sklearn)）并不是。
- en: 4.5.2 Sparse Matrices Representation
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.2 稀疏矩阵表示
- en: Matrices in which most cells are zero are called sparse matrices, as opposed
    to dense matrices in which most or all elements are non-zero. In the case of dense
    (\(m \times n\)) matrices, we need to store in memory the values of all the cells,
    which means that their complexity is \(O(mn)\). However, in the case of sparse
    matrices, we can just store the non-zero values and their coordinates, with the
    understanding that all other cells are equal to zero.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数单元格为零的矩阵称为稀疏矩阵，与大多数或所有元素非零的密集矩阵相对。在密集 (\(m \times n\)) 矩阵的情况下，我们需要在内存中存储所有单元格的值，这意味着它们的复杂度是
    \(O(mn)\)。然而，在稀疏矩阵的情况下，我们只需存储非零值及其坐标，理解到所有其他单元格都等于零。
- en: 'R provides several such representations in the Matrix package (Bates and Maechler
    [2021](#ref-matrixpkg)), and Python does the same in scipy (Virtanen et al. [2020](#ref-scipy)):
    the default is the column-oriented, compressed format described in Section [3.2.3](types-structures.html#matrices).
    Consider the matrix originally shown in Figure [3.4](types-structures.html#fig:matrices),
    in which 9 cells out of 15 are zeroes.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: R 在 Matrix 包中提供了几种这样的表示（Bates 和 Maechler [2021](#ref-matrixpkg)），Python 在 scipy
    中也做了同样的事情（Virtanen 等人 [2020](#ref-scipy)）：默认是第 [3.2.3](types-structures.html#matrices)
    节中描述的列导向、压缩格式。考虑原始显示在图 [3.4](types-structures.html#fig:matrices) 中的矩阵，其中 15 个单元格中有
    9 个是零。
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How are the elements of `m` stored in memory?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`m` 的元素是如何存储在内存中的？'
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Comparing the notation in Section [3.2.3](types-structures.html#matrices) and
    the documentation of Matrix, we can see that:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 将 [3.2.3](types-structures.html#matrices) 节中的符号与 Matrix 的文档进行比较，我们可以看到：
- en: '`i` contains the vector \(R\), row coordinates of the non-zero cells in the
    matrix;'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`i` 包含向量 \(R\)，矩阵中非零单元格的行坐标；'
- en: '`p` contains the vector \(C\), the start and end indexes of the columns; and'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p` 包含向量 \(C\)，列的开始和结束索引；'
- en: '`x` contains the vector \(V\) of the values of the non-zero cells.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x` 包含非零单元格的值向量 \(V\)。'
- en: Note that both `i` and `p` are 0-based indexes to facilitate the use of the
    `dgCMatrix` class in the code inside the Matrix package, while R uses 1-based
    indexing.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`i` 和 `p` 都是0基于索引，以方便在 Matrix 包内部的代码中使用 `dgCMatrix` 类，而 R 使用1基于索引。
- en: The overall space complexity of such a sparse matrix is then \(O(3z)\), where
    \(z\) is the number of non-zero cells. R stores real numbers in double precision
    (64 bits each) and indexes as 32-bits integers, which means `m` needs 128 bits
    (16 bytes) of memory for each non-zero cell. So dense matrices use \(8mn\) bytes
    of memory while sparse matrices use \(16z\) bytes; if \(z \ll mn\) we can save
    most of the memory we would have allocated for a dense matrix.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这样一个稀疏矩阵的整体空间复杂度是 \(O(3z)\)，其中 \(z\) 是非零单元格的数量。R 使用双精度（每个64位）存储实数，并使用32位整数作为索引，这意味着
    `m` 需要为每个非零单元格分配128位（16字节）的内存。因此，稠密矩阵使用 \(8mn\) 字节内存，而稀疏矩阵使用 \(16z\) 字节；如果 \(z
    \ll mn\)，我们可以节省大部分原本为稠密矩阵分配的内存。
- en: 'The catch is that operations may have a higher time complexity for sparse matrices
    than for dense matrices. Even the most simple: looking up the value of a cell
    \((i, j)\) has time complexity \(O(1)\) in a dense matrix, but for a sparse matrix
    such as `m` we need to:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但问题是，对于稀疏矩阵的操作可能比稠密矩阵的操作具有更高的时间复杂度。即使是简单的操作：在稠密矩阵中查找单元格 \((i, j)\) 的值具有 \(O(1)\)
    的时间复杂度，但对于稀疏矩阵如 `m`，我们需要：
- en: Look up what are the first and the last values in `x` for the column \(j\) by
    reading the \(j\)th element of `p`.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过读取 `p` 的第 \(j\) 个元素来查找 `x` 中该列的第一个和最后一个值。
- en: Position ourselves on the row number for that first value in `i`, and read every
    successive number until we find the row number \(j\) or we reach the end of the
    column.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将我们定位在 `i` 中第一个值的行号上，并读取每个后续的数字，直到我们找到行号 \(j\) 或达到列的末尾。
- en: Read the value of the cell from `x`, which has the same position in `x` as the
    row number in `i`; or return zero if we reach the end of the column.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 `x` 中读取单元格的值，它在 `x` 中的位置与 `i` 中的行号相同；或者如果达到列的末尾，则返回零。
- en: These three steps have an overall time complexity of \(O(1) + O(z/n) + O(1)
    = O(2 + z/n)\) assuming \(z/n\) non-zero elements per column on average. Hence
    reading a cell from a sparse matrix appears to be more expensive than reading
    the same cell from a dense matrix.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个步骤的总时间复杂度为 \(O(1) + O(z/n) + O(1) = O(2 + z/n)\)，假设每列平均有 \(z/n\) 个非零元素。因此，从稀疏矩阵中读取单元格似乎比从稠密矩阵中读取相同单元格更昂贵。
- en: 'Assigning a non-zero value to a cell in a sparse matrix is more expensive as
    well. For each of `i` and `x` we need to:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在稀疏矩阵中给一个单元格赋非零值也要花费更多。对于 `i` 和 `x` 中的每一个，我们需要：
- en: allocate a new array of length \(z + 1\);
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配一个长度为 \(z + 1\) 的新数组；
- en: copy the \(z\) values from the old array;
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从旧数组中复制 \(z\) 个值；
- en: add the values corresponding to the new cell;
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将新单元格对应的值相加；
- en: replace the old array with the new one.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用新数组替换旧数组。
- en: Therefore, time and space complexity both are \(O(z)\). Handling `p` is also
    \(O(z)\), and it is more complex since we will need to recompute half of the values
    on average.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，时间和空间复杂度都是 \(O(z)\)。处理 `p` 也是 \(O(z)\)，而且它更复杂，因为我们平均需要重新计算一半的值。
- en: 'This is troubling because we cannot predict the average time and space complexity
    just by looking at the input size: we can only do that by making assumptions on
    the distribution of the values in the cells. Furthermore, this distribution may
    change during the execution of our software as we assign new non-zero values to
    the sparse matrix. We can, however, compare the empirical running times of read
    and write operations on dense and sparse matrices to get a practical understanding
    of how they differ, as we did in the previous section with \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\)
    and \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这很令人烦恼，因为我们不能仅通过查看输入大小来预测平均时间和空间复杂度：我们只能通过假设单元格中值的分布来做到这一点。此外，这种分布可能在我们的软件执行过程中发生变化，因为我们向稀疏矩阵分配新的非零值。然而，我们可以比较稠密和稀疏矩阵上读写操作的实证运行时间，以获得它们差异的实际理解，就像我们在上一节中用
    \(\boldsymbol{\widehat{\beta}}_{\mathrm{EX}}\) 和 \(\boldsymbol{\widehat{\beta}}_{\mathrm{QR}}\)
    所做的那样。
- en: Consider a square matrix allocated as either a sparse or a dense matrix with
    \(n = 1000\) and the proportions of non-zero cells of \(z/n = \{ 0.01, 0.02, 0.05,\)
    \(0.10, 0.20, 0.50, 1\}\). We can measure the time it takes to read (with the
    `read10()` function) or write (with the `write10()` function) the values of 10
    random cells for either type of matrix as \(z\) (`zz` in the code below) increases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个 \(n = 1000\) 的正方形矩阵，其非零单元格的比例为 \(z/n = \{ 0.01, 0.02, 0.05, 0.10, 0.20,
    0.50, 1\}\)。我们可以测量随着 \(z\) (`zz` 以下代码中) 的增加，读取（使用 `read10()` 函数）或写入（使用 `write10()`
    函数）10 个随机单元格所需的时间。
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Read (left) and write (right panel) performance for sparse (orange) and dense
    (blue) square matrices of size 1000\. 90% confidence bars are so thin as to not
    be visible.](../Images/a176234975fbcaaf86df1216a8c59bb1.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![稀疏（橙色）和密集（蓝色）正方形矩阵（大小为 1000）的读取（左侧面板）和写入（右侧面板）性能。90% 置信区间非常窄，以至于几乎看不见。](../Images/a176234975fbcaaf86df1216a8c59bb1.png)'
- en: 'Figure 4.3: Read (left) and write (right panel) performance for sparse (orange)
    and dense (blue) square matrices of size 1000\. 90% confidence bars are so thin
    as to not be visible.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：稀疏（橙色）和密集（蓝色）正方形矩阵（大小为 1000）的读取（左侧面板）和写入（右侧面板）性能。90% 置信区间非常窄，以至于几乎看不见。
- en: 'The resulting running times are shown in Figure [4.3](algorithms.html#fig:sparsem-microbenchmark-plots).
    As we expected, both reading from and writing to a dense matrix is \(O(1)\): running
    times do not change as \(z\) increases. This is not true in the case of a sparse
    matrix. The running time of `write10()` increases linearly in \(z/n\), and so
    does that of `read10()` until \(z/n = 0.5\). Reading times do not increase further
    for \(z/n = 1\): in fact, they decrease slightly. We can interpret this as \(O(2
    + z/n)\) converging to a constant \(O(3)\) as \(z/n \to 1\), making a (no longer)
    sparse matrix just an inefficient dense matrix that requires extra coordinate
    look-ups.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 结果运行时间显示在图 [4.3](algorithms.html#fig:sparsem-microbenchmark-plots) 中。正如我们所预期的那样，从密集矩阵中读取和写入都是
    \(O(1)\)：运行时间不会随着 \(z\) 的增加而改变。在稀疏矩阵的情况下则不是这样。`write10()` 的运行时间在 \(z/n\) 上线性增加，`read10()`
    的运行时间也是如此，直到 \(z/n = 0.5\)。对于 \(z/n = 1\)，读取时间不再增加：实际上，它们略有下降。我们可以将这解释为 \(O(2
    + z/n)\) 在 \(z/n \to 1\) 时收敛到常数 \(O(3)\)，使得（不再是）稀疏矩阵仅仅是一个效率低下的密集矩阵，需要额外的坐标查找。
- en: Finally, we can regress the running times (in seconds) on \(O(z/n)\) to determine
    the slope of the linear trends we see for sparse matrices, that is, the orange
    lines in the two panels of Figure [4.3](algorithms.html#fig:sparsem-microbenchmark-plots).
    For writing performance, the slope is 0.09; while for reading performance it is
    0.03 if we consider only \(z/n \leqslant 0.5\). Hence writing times increase by
    approximately 10% for every million cells in the matrix, and read times by 3%.
    This, of course, is true for large matrices with millions of elements; performance
    may very well be different for smaller matrices with just a few tens of elements.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将运行时间（以秒为单位）对 \(O(z/n)\) 进行回归，以确定我们看到的稀疏矩阵的线性趋势的斜率，即图 [4.3](algorithms.html#fig:sparsem-microbenchmark-plots)
    两个面板中的橙色线。对于写入性能，斜率为 0.09；而对于读取性能，如果只考虑 \(z/n \leqslant 0.5\)，则斜率为 0.03。因此，矩阵中的每个百万个单元格的写入时间增加约
    10%，读取时间增加 3%。当然，这对于具有数百万个元素的矩阵来说是正确的；对于只有几十个元素的较小矩阵，性能可能会有很大不同。
- en: 4.5.3 Uniform Simulations of Directed Acyclic Graphs
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.3 有向无环图的均匀模拟
- en: 'Many complex probabilistic models can be represented graphically as *directed
    acyclic graphs* (DAGs), in which each node is associated with a random variable
    and arcs represent dependence relationships between those variables: notable examples
    are Bayesian networks (Scutari and Denis [2021](#ref-scutari)), neural networks
    (Goodfellow, Bengio, and Courville [2016](#ref-goodfellow)), Bayesian hierarchical
    models (Gelman et al. [2013](#ref-gelman)) and vector auto-regressive (VAR) time
    series (Tsay [2010](#ref-tsay)). The DAGs make it possible to divide and conquer
    large multivariate distributions into smaller ones in which each variable only
    depends on its parents.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 许多复杂的概率模型可以图形化表示为 *有向无环图* (DAGs)，其中每个节点都与一个随机变量相关联，弧线表示这些变量之间的依赖关系：显著的例子包括贝叶斯网络（Scutari
    和 Denis [2021](#ref-scutari)）、神经网络（Goodfellow、Bengio 和 Courville [2016](#ref-goodfellow)）、贝叶斯层次模型（Gelman
    等人 [2013](#ref-gelman)）和向量自回归（VAR）时间序列（Tsay [2010](#ref-tsay)）。DAGs 使得将大型多元分布分解成更小的分布成为可能，在这些分布中，每个变量只依赖于其父节点。
- en: When evaluating various aspects of these models, it may be useful to be able
    to generate random DAGs to use in simulation studies. In particular, we may want
    to generate DAGs with uniform probability since this is considered a non-informative
    prior distribution on the space of the possible model structures. A simple MCMC
    algorithm to do this is illustrated in (Melançon, Dutour, and Bousquet-Mélou [2001](#ref-melancon)).
    We wrote it down as pseudocode in Algorithm [4.1](algorithms.html#tab:melancon).
    For simplicity, we omit both *burn-in* (dropping the DAGs generated in the initial
    iterations to give time to the algorithm to converge to the uniform distributions
    over DAGs) and *thinning* (returning only one DAG every several generated DAGs
    to return a set of DAGs that are more nearly independent) even though both are
    standard practice in the literature.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估这些模型的各个方面时，能够生成随机 DAG 用于模拟研究可能是有用的。特别是，我们可能希望以均匀概率生成 DAG，因为这被认为是在可能模型结构空间上的非信息先验分布。一个简单的
    MCMC 算法用于此目的在（Melançon, Dutour, 和 Bousquet-Mélou [2001](#ref-melancon)）中进行了说明。我们将它以伪代码的形式记录在算法
    [4.1](algorithms.html#tab:melancon) 中。为了简化，我们省略了 *burn-in*（丢弃初始迭代中生成的 DAG，以便算法有时间收敛到
    DAG 上的均匀分布）和 *thinning*（每生成几个 DAG 返回一个 DAG，以返回一组更接近独立的 DAG），尽管这两者在文献中都是标准做法。
- en: 'Table 4.1: Random DAG Generation'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1：随机 DAG 生成
- en: '| **Algorithm 4.1** Random DAG Generation |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| **算法 4.1** 随机有向无环图（DAG）生成 |'
- en: '| **Input:** a set of nodes \(\mathbf{V}\) (possibly with associated labels),
    the number \(N\) of graphs to generate. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| **输入：** 节点集 \(\mathbf{V}\)（可能带有相关标签），要生成的图的数量 \(N\)。 |'
- en: '| **Output:** a set \(\mathbf{G}\) of \(N\) directed acyclic graphs. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| **输出：** 一个包含 \(N\) 个有向无环图的集合 \(\mathbf{G}\)。 |'
- en: '| \(\quad\) 1\. Initialise an empty graph with nodes \(\mathbf{V}\) and arcs
    \(A_0 = \{\varnothing\}\). |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| \(\quad\) 1\. 初始化一个包含节点 \(\mathbf{V}\) 和弧 \(A_0 = \{\varnothing\}\) 的空图。
    |'
- en: '| \(\quad\) 2\. Initialise an empty set of graphs \(\mathbf{G}\). |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| \(\quad\) 2\. 初始化一个空的图集 \(\mathbf{G}\). |'
- en: '| \(\quad\) 3\. For a large number of iterations \(n = 1, \ldots, N\): |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| \(\quad\) 3\. 进行大量迭代 \(n = 1, \ldots, N\): |'
- en: '| \(\qquad\) (a) Sample two random nodes \(v_i\) and \(v_j \in \mathbf{V}\)
    with \(v_i \neq v_j\). |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| \(\qquad\) (a) 从节点集 \(\mathbf{V}\) 中随机选择两个不同的节点 \(v_i\) 和 \(v_j \in \mathbf{V}\)（\(v_i
    \neq v_j\)）。 |'
- en: '| \(\qquad\) (b) If \(\{v_i \to v_j\} \in A_{n - 1}\), then \(A_{n} \leftarrow
    A_{n - 1} \setminus \{v_i \to v_j\}\). |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| \(\qquad\) (b) 如果 \(\{v_i \to v_j\} \in A_{n - 1}\)，则 \(A_{n} \leftarrow
    A_{n - 1} \setminus \{v_i \to v_j\}\)。 |'
- en: '| \(\qquad\) (c) If \(\{v_i \to v_j\} \not\in A_{n - 1}\), check whether the
    graph is still acyclic after adding \(\{v_i \to v_j\}\) |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| \(\qquad\) (c) 如果 \(\{v_i \to v_j\} \not\in A_{n - 1}\)，检查在添加 \(\{v_i \to
    v_j\}\) 后图是否仍然是无环的 |'
- en: '| \(\qquad\qquad\) i. If the graph is still acyclic, \(A_{n} \leftarrow A_{n
    - 1} \cup \{v_i \to v_j\}\). |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| \(\qquad\qquad\) i. 如果图仍然是无环的，则 \(A_{n} \leftarrow A_{n - 1} \cup \{v_i \to
    v_j\}\)。 |'
- en: '| \(\qquad\qquad\) ii. If the graph is no longer acyclic, nothing is done.
    |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| \(\qquad\qquad\) ii. 如果图不再是无环的，则不做任何操作。 |'
- en: '| \(\qquad\) (d) \(\mathbf{G} \leftarrow \mathbf{G} \cup A_{n}\). |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| \(\qquad\) (d) \(\mathbf{G} \leftarrow \mathbf{G} \cup A_{n}\). |'
- en: 'How can we represent DAGs in this algorithm? Any graph is uniquely identified
    by its nodes \(\mathbf{V}\) and its arc set \(A\). As an example, consider a graph
    with nodes \(\mathbf{V}= \{ v_1, v_2, v_3, v_4 \}\) and arcs \(\{ \{ v_1 \to v_3\},\)
    \(\{v_2 \to v_3\},\) \(\{v_3 \to v_4 \} \}\). Its *adjacency matrix* is a square
    matrix in which the cell \((i, j)\) is equal to 1 if the arc \(v_i \to v_j\) is
    present in the DAG, and to 0 if it is not: \[\begin{equation*} \begin{bmatrix}
    0 & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 0 \end{bmatrix}.
    \end{equation*}\] We can store an adjacency matrix in a dense or a sparse matrix
    of size \(|\mathbf{V}|\): depending on how many arcs we expect to see in the DAG,
    the trade-off between space and time complexity may be acceptable as discussed
    in Section [4.5.2](algorithms.html#bigO-sparsem). The *adjacency list* of a graph
    is a set containing the children sets of each node: \[\begin{equation*} \left\{
    v_1 = \{ v_3 \}, v_2 = \{ v_3 \}, v_3 = \{ v_4\}, v_4 = \varnothing \right\}.
    \end{equation*}\] This representation is competitive with a sparse adjacency matrix
    in terms of space complexity: both are \(O(|A|)\), where \(|A|\) is the size of
    the arc set of the DAG (that is, the number of arcs it contains). If we assume
    that the DAGs contain few arcs so that \(O(|A|) = O(|\mathbf{V}|)\), then space
    complexity is better than the \(O(|\mathbf{V}|^2)\) of adjacency matrices. As
    for time complexity, path finding is \(O(|\mathbf{V}| + |A|)\) in adjacency lists
    but \(O(|\mathbf{V}|^2)\) for adjacency matrices. Adjacency matrices, on the other
    hand, allow for \(O(1)\) arc insertion, arc deletion, and finding whether an arc
    is present or not in the DAG. All these operations are either \(O(|\mathbf{V}|)\)
    or \(O(|A|)\) in adjacency lists.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个算法中我们如何表示DAGs？任何图都由其节点 \(\mathbf{V}\) 和其弧集 \(A\) 唯一确定。例如，考虑一个具有节点 \(\mathbf{V}=
    \{ v_1, v_2, v_3, v_4 \}\) 和弧 \(\{ \{ v_1 \to v_3\},\) \(\{v_2 \to v_3\},\) \(\{v_3
    \to v_4 \} \}\) 的图。其 *邻接矩阵* 是一个方阵，其中单元格 \((i, j)\) 等于1，如果弧 \(v_i \to v_j\) 在DAG中存在，否则等于0：\[\begin{equation*}
    \begin{bmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 0 &
    0 \end{bmatrix}. \end{equation*}\] 我们可以将邻接矩阵存储在大小为 \(|\mathbf{V}|\) 的密集或稀疏矩阵中：根据我们期望在DAG中看到多少弧，空间和时间复杂度之间的权衡可能是可接受的，如第[4.5.2](algorithms.html#bigO-sparsem)节所述。图的
    *邻接表* 是一个包含每个节点子集集合的集合：\[\begin{equation*} \left\{ v_1 = \{ v_3 \}, v_2 = \{ v_3
    \}, v_3 = \{ v_4\}, v_4 = \varnothing \right\}. \end{equation*}\] 这种表示在空间复杂度方面与稀疏邻接矩阵具有竞争力：两者都是
    \(O(|A|)\)，其中 \(|A|\) 是DAG的弧集大小（即它包含的弧的数量）。如果我们假设DAG包含很少的弧，使得 \(O(|A|) = O(|\mathbf{V}|)\)，那么空间复杂度优于邻接矩阵的
    \(O(|\mathbf{V}|^2)\)。至于时间复杂度，在邻接表中路径查找是 \(O(|\mathbf{V}| + |A|)\)，但在邻接矩阵中是 \(O(|\mathbf{V}|^2)\)。另一方面，邻接矩阵允许进行
    \(O(1)\) 的弧插入、弧删除以及确定弧是否存在于DAG中。所有这些操作在邻接表中都是 \(O(|\mathbf{V}|\) 或 \(O(|A|)\)。
- en: 'For the moment, let’s represent DAGs with dense adjacency matrices. We can
    determine the time complexity of an MCMC step in Algorithm [4.1](algorithms.html#tab:melancon)
    as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们用密集邻接矩阵来表示DAGs。我们可以根据以下方式确定MCMC步骤的时间复杂度，如算法[4.1](algorithms.html#tab:melancon)所示：
- en: For each iteration, adding and removing arcs is \(O(1)\) since we just read
    or write a value in a specific cell of the adjacency matrix.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每次迭代，添加和删除弧是 \(O(1)\) 的，因为我们只需在邻接矩阵的特定单元格中读取或写入一个值。
- en: Choosing a pair of nodes at random can also be considered \(O(1)\), since we
    choose two nodes regardless of \(|\mathbf{V}|\) or \(|A_n|\).
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机选择一对节点也可以被认为是 \(O(1)\) 的，因为我们选择两个节点，而不管 \(|\mathbf{V}|\) 或 \(|A_n|\) 的大小如何。
- en: Both depth-first and breadth-first search have time complexity \(O(|\mathbf{V}|^2)\)
    since we have to scan the whole adjacency matrix to look for each node’s children.
    We only perform such a search if we sample a candidate arc that is not already
    present, because in order to include an arc \(v_i \to v_j\) we must make sure
    that there is no path from \(v_j\) to \(v_i\) in order to keep the DAG acyclic.
    That in turn happens with probability \(O(|A_n| / |\mathbf{V}|^2)\).
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论是深度优先搜索还是广度优先搜索，它们的时间复杂度都是 \(O(|\mathbf{V}|^2)\)，因为我们必须扫描整个邻接矩阵以查找每个节点的子节点。我们只执行这种搜索，因为我们采样了一个尚未存在的候选弧，因为为了包含弧
    \(v_i \to v_j\)，我们必须确保从 \(v_j\) 到 \(v_i\) 没有路径，以保持DAG的循环性。这反过来又以概率 \(O(|A_n| /
    |\mathbf{V}|^2)\) 发生。
- en: 'The overall time complexity of Algorithm [4.1](algorithms.html#tab:melancon)
    for \(N\) MCMC iterations then is: \[\begin{equation*} O\left(N \left(1 + 1 +
    |\mathbf{V}|^2 \frac{|A_n|}{|\mathbf{V}|^2} \right)\right) \approx O(N|A_n|).
    \end{equation*}\] However, we are assuming a uniform probability distribution
    over all possible DAGs: under this assumption (Melançon, Dutour, and Bousquet-Mélou
    [2001](#ref-melancon)) reports that \(O(|A_n|) \approx O(|\mathbf{V}|^2/4)\),
    making Algorithm [4.1](algorithms.html#tab:melancon) \(O(N|\mathbf{V}|^2/4)\).
    If we assumed a different probability distribution for the DAGs, the time complexity
    of the algorithm would change even if \(\mathbf{V}\) and \(N\) stayed the same
    because the average \(|A_n|\) would be different. Furthermore, note that computing
    the overall time complexity of Algorithm [4.1](algorithms.html#tab:melancon) as
    \(N\) times the complexity of an individual step implies that we are assuming
    that all MCMC steps have the same time complexity. This is not exactly true because
    of the \(O(|A_n| / |\mathbf{V}|^2)\) term, which may be lower for early MCMC steps
    (when \(|A_n|\) is bound by the number of steps \(n\)) that for later steps (when
    \(|A_n| \approx |\mathbf{V}|^2/4\) because Algorithm [4.1](algorithms.html#tab:melancon)
    has converged to the uniform distribution). It is, however, a reasonable working
    assumption if \(N\) is large enough and if most MCMC steps will be performed after
    reaching the stationary distribution.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(N\) 次MCMC迭代，算法[4.1](algorithms.html#tab:melancon)的整体时间复杂度是：\[\begin{equation*}
    O\left(N \left(1 + 1 + |\mathbf{V}|^2 \frac{|A_n|}{|\mathbf{V}|^2} \right)\right)
    \approx O(N|A_n|). \end{equation*}\] 然而，我们假设所有可能的DAG上的概率分布是均匀的：在这个假设下（Melançon,
    Dutour, and Bousquet-Mélou [2001](#ref-melancon)）报告说 \(O(|A_n|) \approx O(|\mathbf{V}|^2/4)\)，使得算法[4.1](algorithms.html#tab:melancon)的时间复杂度为
    \(O(N|\mathbf{V}|^2/4)\)。如果我们假设DAG的不同概率分布，即使 \(\mathbf{V}\) 和 \(N\) 保持不变，算法的时间复杂度也会改变，因为平均
    \(|A_n|\) 会不同。此外，请注意，将算法[4.1](algorithms.html#tab:melancon)的整体时间复杂度计算为单个步骤复杂度的
    \(N\) 倍意味着我们假设所有MCMC步骤具有相同的时间复杂度。这并不完全正确，因为 \(O(|A_n| / |\mathbf{V}|^2)\) 项，对于早期MCMC步骤（当
    \(|A_n|\) 受步骤数 \(n\) 的限制时）可能低于后期步骤（当 \(|A_n| \approx |\mathbf{V}|^2/4\) 因为算法[4.1](algorithms.html#tab:melancon)已经收敛到均匀分布）。然而，如果
    \(N\) 足够大，并且大多数MCMC步骤将在达到稳态分布后执行，这仍然是一个合理的假设。
- en: For each DAG we generate, we also have to consider the cost of saving it in
    a different data structure for later use. Transforming the adjacency matrix into
    another data structure is necessarily \(O(|\mathbf{V}|^2)\) since we need to read
    every cell in the adjacency matrix to find out which arcs are in the DAG. We do
    not always perform that transformation because we may reject a new DAG instead
    of returning it, but it is difficult to evaluate how often that happens. A reasonable
    guess is that we almost always save sparse graphs, since there will typically
    be no path between \(v_j\) and \(v_i\) (that is the only case in which we do reject
    the current DAG proposal, and we do not need the transformation). As \(|A_n| \to
    |\mathbf{V}|\) that condition will become easier to meet, so we can say that for
    a large number of iterations \(\approx O(|\mathbf{V}|^2 \cdot 0) = O(1)\) for
    most iterations.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们生成的每个DAG，我们还需要考虑将其保存到不同的数据结构以供以后使用所需的成本。将邻接矩阵转换为另一个数据结构是必要的 \(O(|\mathbf{V}|^2)\)，因为我们需要读取邻接矩阵中的每个单元格以找出哪些弧在DAG中。我们并不总是执行这种转换，因为我们可能会拒绝一个新的DAG而不是返回它，但很难评估这种情况发生的频率。一个合理的猜测是我们几乎总是保存稀疏图，因为通常
    \(v_j\) 和 \(v_i\) 之间不会有路径（这就是我们唯一拒绝当前DAG提议的情况，我们不需要转换）。当 \(|A_n| \to |\mathbf{V}|\)
    时，这个条件将更容易满足，因此我们可以这样说，对于大量迭代，\(\approx O(|\mathbf{V}|^2 \cdot 0) = O(1)\) 对于大多数迭代。
- en: 'As for space complexity, the adjacency matrix uses \(O(|\mathbf{V}|^2)\) space:
    it is the most wasteful way of representing a graph. Any other data structure
    we may save DAGs into will likely use less space.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 至于空间复杂度，邻接矩阵使用 \(O(|\mathbf{V}|^2)\) 的空间：这是表示图的最浪费方式。我们可能保存DAG的任何其他数据结构都可能使用更少的空间。
- en: We can investigate all the statements above as in Sections [4.5.1](algorithms.html#bigO-lm)
    and [4.5.2](algorithms.html#bigO-sparsem).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像在章节[4.5.1](algorithms.html#bigO-lm)和[4.5.2](algorithms.html#bigO-sparsem)中那样调查上述所有陈述。
- en: '[PRE10]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Running times for Algorithm \@ref(tab:melancon) as a function of the number
    of nodes, generating 200 DAGs.](../Images/5efa5dc6b2b3bb55321d8614e5e37a12.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![算法@ref(tab:melancon)的运行时间作为节点数量的函数，生成200个DAG。](../Images/5efa5dc6b2b3bb55321d8614e5e37a12.png)'
- en: 'Figure 4.4: Running times for Algorithm [4.1](algorithms.html#tab:melancon)
    as a function of the number of nodes, generating 200 DAGs.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：算法 [4.1](algorithms.html#tab:melancon) 的运行时间作为节点数量的函数，生成 200 个 DAG。
- en: 'How do time and space complexity change if we represent DAGs with adjacency
    lists instead? Both path finding (say, by depth-first search) and saving DAGs
    in a different data structure have a time complexity of \(O(|\mathbf{V}| + |A_n|)\)
    for adjacency lists. However, the overall time complexity of each MCMC iteration
    is still quadratic: \[\begin{multline*} O\left(N \left(1 + 1 + (|\mathbf{V}| +
    |A_n|) \frac{|A_n|}{|\mathbf{V}|^2}\right)\right) \approx \\ O\left(N \left(1
    + 1 + (|\mathbf{V}| + |\mathbf{V}|^2) \frac{|\mathbf{V}|^2}{|\mathbf{V}|^2}\right)\right)
    \approx O(N|\mathbf{V}|^2), \end{multline*}\] again assuming that \(O(|A_n|) \approx
    O(|\mathbf{V}|^2/4)\). The space complexity of an adjacency list is \(O(|\mathbf{V}|
    + |A_n|)\). On average, this becomes \(O(|\mathbf{V}|^2)\) under the same assumption.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用邻接表来表示 DAG，时间和空间复杂度会如何变化？路径查找（例如，通过深度优先搜索）以及将 DAG 存储在不同的数据结构中的时间复杂度都是 \(O(|\mathbf{V}|
    + |A_n|)\)。然而，每个 MCMC 迭代的整体时间复杂度仍然是二次的：\[\begin{multline*} O\left(N \left(1 +
    1 + (|\mathbf{V}| + |A_n|) \frac{|A_n|}{|\mathbf{V}|^2}\right)\right) \approx
    \\ O\left(N \left(1 + 1 + (|\mathbf{V}| + |\mathbf{V}|^2) \frac{|\mathbf{V}|^2}{|\mathbf{V}|^2}\right)\right)
    \approx O(N|\mathbf{V}|^2), \end{multline*}\]再次假设 \(O(|A_n|) \approx O(|\mathbf{V}|^2/4)\)。邻接表的空间复杂度是
    \(O(|\mathbf{V}| + |A_n|)\)。在相同的假设下，平均来说，这变成了 \(O(|\mathbf{V}|^2)\)。
- en: 4.6 Big-\(O\) Notation and Real-World Performance
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 大 \(O\) 符号和现实世界性能
- en: 'Big-\(O\) notation is a useful measure to assess scalability, and it can often
    be related to the practical performance of real machine learning software. However,
    this becomes increasingly difficult as such software becomes more complex, for
    several reasons. For instance:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 大 \(O\) 符号是评估可扩展性的有用度量，它通常可以与真实机器学习软件的实际性能相关联。然而，随着此类软件变得更加复杂，这变得越来越困难，原因有几个。例如：
- en: 'Software in a machine learning pipeline is heterogeneous: various parts are
    typically written in different programming languages and are built on different
    libraries. Each part may be faster or slower than another because of that, even
    when they belong to the same class of complexity. More on that in Section [6.1](writing-code.html#programming-language).
    Software upgrades may also change the relative speeds of different parts of the
    pipeline and introduce new bottlenecks.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习管道中的软件是异构的：各个部分通常用不同的编程语言编写，并建立在不同的库上。由于这个原因，每个部分可能比另一个部分更快或更慢，即使它们属于同一类复杂度。更多内容请参阅第
    [6.1](writing-code.html#programming-language) 节。软件升级也可能改变管道不同部分的相对速度，并引入新的瓶颈。
- en: Both these things being equal, the same algorithm may be faster or slower depending
    on the data structures used to store its inputs and outputs. We saw that to be
    the case in Section [4.5.2](algorithms.html#bigO-sparsem), and we touched on this
    point in Section [3.4](types-structures.html#right-data-structures) as well. The
    same is true for variable types, as discussed in Section [3.3](types-structures.html#right-variables).
    High-level languages abstract these details to a large extent, which may lead
    to surprises when benchmarking software.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当这两个因素相等时，相同的算法可能因为用于存储其输入和输出的数据结构不同而更快或更慢。我们在第 [4.5.2](algorithms.html#bigO-sparsem)
    节中看到了这种情况，在第 [3.4](types-structures.html#right-data-structures) 节中也提到了这一点。对于变量类型，正如第
    [3.3](types-structures.html#right-variables) 节所讨论的，也是如此。高级语言在很大程度上抽象了这些细节，这可能导致在基准测试软件时出现意外。
- en: 'Differences in hardware can be impactful enough to completely hide differences
    in the class of complexity of different algorithms for practical ranges of input
    sizes. Conversely, they can also introduce apparent discrepancies in performance.
    This can realistically happen when the input sizes are small enough to make adjacent
    classes of complexity comparable: an \(O(N^2)\) algorithm on a CPU core will be
    slower than an \(O(N^3)\) algorithm on a GPU with a hundred of free units for
    \(N \leqslant 100\). Fixed costs that are ignored when deriving computational
    complexity may also be relevant due to the relative difference, for instance,
    in the latency of different types of memory (Section [2.1.2](hardware.html#hardware-memory)).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件的不同可能对实际输入规模范围内的不同算法复杂度类别的差异产生足够大的影响，以至于完全隐藏这些差异。相反，它们也可能引入性能上的明显差异。当输入规模足够小，使得相邻的复杂度类别可以比较时，这种情况可能会发生：对于
    \(N \leqslant 100\)，在具有一百个空闲单元的 GPU 上运行的 \(O(N^3)\) 算法将比在 CPU 内核上运行的 \(O(N^2)\)
    算法慢。在推导计算复杂度时被忽略的固定成本，由于相对差异，例如不同类型内存的延迟（见第 [2.1.2](hardware.html#hardware-memory)
    节），也可能相关。
- en: If we use any remote systems (Section [2.3](hardware.html#hardware-cloud)),
    the hardware we are running a machine learning pipeline on may vary without our
    knowledge, either in its configuration or in its overall load. Furthermore, benchmarking
    remote systems accurately is inherently more difficult, as is troubleshooting
    them.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们使用任何远程系统（见第 [2.3](hardware.html#hardware-cloud) 节），我们在其上运行机器学习管道的硬件可能在我们不知情的情况下发生变化，无论是其配置还是整体负载。此外，准确基准测试远程系统固有的更困难，同样，故障排除也是如此。
- en: The performance of some parts of the pipeline may be artificially limited by
    that of the external systems that provide the inputs to the machine learning models
    or that consume their outputs. Individual parts of the same system may also slow
    down each other as they consume each other’s outputs.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流程中某些部分的表现可能被提供输入给机器学习模型或消耗其输出的外部系统的性能人为限制。同一系统的各个部分在消耗彼此的输出时也可能相互减慢。
- en: To summarise, we may be able to map computational complexity to real-world performance
    for the individual components of a machine learning pipeline running on simple
    hardware configurations. It is unlikely that we can do that with any degree of
    accuracy when systems become larger and contain a larger number of software and
    hardware components. The resulting complexity can easily make our expectations
    and intuitions about performance unreliable. In such a situation, identifying
    performance issues requires measuring the current performance of each component
    as a baseline, identifying which components are executed most often (which are
    sometimes said to be in the “critical path” or in the “hot path”) and trying to
    redesign them to make them more efficient.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们可能能够将计算复杂度映射到在简单硬件配置上运行的机器学习管道各个组件的实际性能。当系统变得更大，包含更多的软件和硬件组件时，我们不太可能以任何程度的准确性做到这一点。由此产生的复杂性很容易使我们对性能的期望和直觉变得不可靠。在这种情况下，识别性能问题需要测量每个组件的当前性能作为基准，确定哪些组件被执行得最频繁（有时被称为“关键路径”或“热点路径”），并尝试重新设计它们以提高效率。
