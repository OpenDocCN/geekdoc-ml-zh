- en: KWS Feature Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KWS 特征工程
- en: '![](../media/file964.jpg)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file964.jpg)'
- en: '*DALL·E 3 Prompt: 1950s style cartoon scene set in an audio research room.
    Two scientists, one holding a magnifying glass and the other taking notes, examine
    large charts pinned to the wall. These charts depict FFT graphs and time curves
    related to audio data analysis. The room has a retro ambiance, with wooden tables,
    vintage lamps, and classic audio analysis tools.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*DALL·E 3 Prompt: 1950s style cartoon scene set in an audio research room.
    Two scientists, one holding a magnifying glass and the other taking notes, examine
    large charts pinned to the wall. These charts depict FFT graphs and time curves
    related to audio data analysis. The room has a retro ambiance, with wooden tables,
    vintage lamps, and classic audio analysis tools.*'
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: In this hands-on tutorial, the emphasis is on the critical role that feature
    engineering plays in optimizing the performance of machine learning models applied
    to audio classification tasks, such as speech recognition. It is essential to
    be aware that the performance of any machine learning model relies heavily on
    the quality of features used, and we will deal with “under-the-hood” mechanics
    of feature extraction, mainly focusing on Mel-frequency Cepstral Coefficients
    (MFCCs), a cornerstone in the field of audio signal processing.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个动手教程中，重点是特征工程在优化应用于音频分类任务（如语音识别）的机器学习模型性能中的关键作用。重要的是要意识到任何机器学习模型的性能在很大程度上依赖于所使用的特征质量，我们将处理特征提取的“内部机制”，主要关注梅尔频率倒谱系数（MFCCs），这是音频信号处理领域的基石。
- en: Machine learning models, especially traditional algorithms, don’t understand
    audio waves. They understand numbers arranged in some meaningful way, i.e., features.
    These features encapsulate the characteristics of the audio signal, making it
    easier for models to distinguish between different sounds.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型，尤其是传统算法，不理解音频波形。它们理解以某种有意义方式排列的数字，即特征。这些特征封装了音频信号的特征，使得模型更容易区分不同的声音。
- en: This tutorial will deal with generating features specifically for audio classification.
    This can be particularly interesting for applying machine learning to a variety
    of audio data, whether for speech recognition, music categorization, insect classification
    based on wingbeat sounds, or other sound analysis tasks
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本教程将处理为音频分类生成特定特征。这对于将机器学习应用于各种音频数据特别有趣，无论是用于语音识别、音乐分类、基于翅膀拍打声的昆虫分类，还是其他声音分析任务。
- en: The KWS
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KWS
- en: The most common TinyML application is Keyword Spotting (KWS), a subset of the
    broader field of speech recognition. While general speech recognition transcribes
    all spoken words into text, Keyword Spotting focuses on detecting specific “keywords”
    or “wake words” in a continuous audio stream. The system is trained to recognize
    these keywords as predefined phrases or words, such as *yes* or *no*. In short,
    KWS is a specialized form of speech recognition with its own set of challenges
    and requirements.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的 TinyML 应用是关键词识别（KWS），它是更广泛的语音识别领域的一个子集。虽然通用语音识别将所有 spoken words 转录成文本，但关键词识别专注于检测连续音频流中的特定“关键词”或“唤醒词”。系统被训练来识别这些关键词作为预定义的短语或单词，如
    *yes* 或 *no*。简而言之，KWS 是一种具有自己一套挑战和要求的专门化的语音识别形式。
- en: 'Here a typical KWS Process using MFCC Feature Converter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个典型的使用梅尔频率倒谱系数（MFCC）特征转换器的 KWS 流程：
- en: '![](../media/file965.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file965.jpg)'
- en: Applications of KWS
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: KWS 的应用
- en: '**Voice Assistants**: In devices like Amazon’s Alexa or Google Home, KWS is
    used to detect the wake word (“Alexa” or “Hey Google”) to activate the device.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音助手**: 在亚马逊的 Alexa 或 Google Home 等设备中，KWS 用于检测唤醒词（“Alexa”或“Hey Google”）以激活设备。'
- en: '**Voice-Activated Controls**: In automotive or industrial settings, KWS can
    be used to initiate specific commands like “Start engine” or “Turn off lights.”'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音激活控制**: 在汽车或工业环境中，KWS 可以用来启动特定的命令，如“启动引擎”或“关灯”。'
- en: '**Security Systems**: Voice-activated security systems may use KWS to authenticate
    users based on a spoken passphrase.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全系统**: 语音激活的安全系统可能使用 KWS 根据语音密码短语验证用户。'
- en: '**Telecommunication Services**: Customer service lines may use KWS to route
    calls based on spoken keywords.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电信服务**: 客户服务线路可能使用关键词识别（KWS）来根据语音关键词路由电话。'
- en: Differences from General Speech Recognition
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与通用语音识别的不同之处
- en: '**Computational Efficiency**: KWS is usually designed to be less computationally
    intensive than full speech recognition, as it only needs to recognize a small
    set of phrases.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算效率**: KWS 通常设计为比完整的语音识别计算量更小，因为它只需要识别一小组短语。'
- en: '**Real-time Processing**: KWS often operates in real-time and is optimized
    for low-latency detection of keywords.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时处理**：KWS通常在实时模式下运行，并针对低延迟的关键词检测进行了优化。'
- en: '**Resource Constraints**: KWS models are often designed to be lightweight,
    so they can run on devices with limited computational resources, like microcontrollers
    or mobile phones.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源限制**：KWS模型通常被设计成轻量级，以便在计算资源有限的设备上运行，例如微控制器或手机。'
- en: '**Focused Task**: While general speech recognition models are trained to handle
    a broad range of vocabulary and accents, KWS models are fine-tuned to recognize
    specific keywords, often in noisy environments accurately.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注任务**：虽然通用语音识别模型被训练以处理广泛的词汇和口音，但KWS模型经过微调以准确识别特定的关键词，通常在嘈杂环境中也能准确识别。'
- en: Overview to Audio Signals
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频信号概述
- en: 'Understanding the basic properties of audio signals is crucial for effective
    feature extraction and, ultimately, for successfully applying machine learning
    algorithms in audio classification tasks. Audio signals are complex waveforms
    that capture fluctuations in air pressure over time. These signals can be characterized
    by several fundamental attributes: sampling rate, frequency, and amplitude.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 理解音频信号的基本特性对于有效的特征提取以及最终在音频分类任务中成功应用机器学习算法至关重要。音频信号是复杂的波形，它捕捉了随时间变化的空气压力波动。这些信号可以通过几个基本属性来描述：采样率、频率和幅度。
- en: '**Frequency and Amplitude**: [Frequency](https://en.wikipedia.org/wiki/Audio_frequency)
    refers to the number of oscillations a waveform undergoes per unit time and is
    also measured in Hz. In the context of audio signals, different frequencies correspond
    to different pitches. [Amplitude](https://en.wikipedia.org/wiki/Amplitude), on
    the other hand, measures the magnitude of the oscillations and correlates with
    the loudness of the sound. Both frequency and amplitude are essential features
    that capture audio signals’ tonal and rhythmic qualities.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频率和幅度**：[频率](https://en.wikipedia.org/wiki/Audio_frequency)是指波形在单位时间内经历的振荡次数，也以Hz为单位测量。在音频信号的上下文中，不同的频率对应不同的音调。[幅度](https://en.wikipedia.org/wiki/Amplitude)另一方面，测量振荡的幅度，与声音的响度相关。频率和幅度都是捕捉音频信号音调和节奏特性的基本特征。'
- en: '**Sampling Rate**: The [sampling rate](https://en.wikipedia.org/wiki/Sampling_(signal_processing)),
    often denoted in Hertz (Hz), defines the number of samples taken per second when
    digitizing an analog signal. A higher sampling rate allows for a more accurate
    digital representation of the signal but also demands more computational resources
    for processing. Typical sampling rates include 44.1 kHz for CD-quality audio and
    16 kHz or 8 kHz for speech recognition tasks. Understanding the trade-offs in
    selecting an appropriate sampling rate is essential for balancing accuracy and
    computational efficiency. In general, with TinyML projects, we work with 16 kHz.
    Although music tones can be heard at frequencies up to 20 kHz, voice maxes out
    at 8 kHz. Traditional telephone systems use an 8 kHz sampling frequency.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样率**：[采样率](https://en.wikipedia.org/wiki/Sampling_(signal_processing))，通常以赫兹（Hz）表示，定义了在数字化模拟信号时每秒采集的样本数。较高的采样率可以更准确地表示信号，但也需要更多的计算资源来处理。典型的采样率包括CD音质的44.1
    kHz，以及用于语音识别任务的16 kHz或8 kHz。理解选择适当采样率的权衡对于平衡准确性和计算效率至关重要。在TinyML项目中，我们通常使用16 kHz。尽管音乐音调可以达到高达20
    kHz的频率，但人声的最高频率为8 kHz。传统的电话系统使用8 kHz的采样频率。'
- en: For an accurate representation of the signal, the sampling rate must be at least
    twice the highest frequency present in the signal.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了准确表示信号，采样率必须至少是信号中最高频率的两倍。
- en: '**Time Domain vs. Frequency Domain**: Audio signals can be analyzed in the
    time and frequency domains. In the time domain, a signal is represented as a waveform
    where the amplitude is plotted against time. This representation helps to observe
    temporal features like onset and duration but the signal’s tonal characteristics
    are not well evidenced. Conversely, a frequency domain representation provides
    a view of the signal’s constituent frequencies and their respective amplitudes,
    typically obtained via a Fourier Transform. This is invaluable for tasks that
    require understanding the signal’s spectral content, such as identifying musical
    notes or speech phonemes (our case).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时域与频域**：音频信号可以在时域和频域中进行分析。在时域中，信号以波形的形式表示，振幅随时间变化。这种表示有助于观察时间特征，如起始和持续时间，但信号的音调特征并不明显。相反，频域表示提供了信号组成频率及其相应振幅的视图，通常通过傅里叶变换获得。这对于需要理解信号频谱内容的任务非常有价值，例如识别音符或语音音素（我们的案例）。'
- en: 'The image below shows the words `YES` and `NO` with typical representations
    in the Time (Raw Audio) and Frequency domains:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像显示了“YES”和“NO”这两个词在时域（原始音频）和频域中的典型表示：
- en: '![](../media/file966.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file966.jpg)'
- en: Why Not Raw Audio?
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么不是原始音频？
- en: While using raw audio data directly for machine learning tasks may seem tempting,
    this approach presents several challenges that make it less suitable for building
    robust and efficient models.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 直接使用原始音频数据用于机器学习任务可能看起来很有吸引力，但这种方法存在一些挑战，使其不太适合构建稳健和高效的模型。
- en: Using raw audio data for Keyword Spotting (KWS), for example, on TinyML devices
    poses challenges due to its high dimensionality (using a 16 kHz sampling rate),
    computational complexity for capturing temporal features, susceptibility to noise,
    and lack of semantically meaningful features, making feature extraction techniques
    like MFCCs a more practical choice for resource-constrained applications.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在TinyML设备上使用原始音频数据进行关键词检测（KWS）时，由于其高维性（使用16 kHz采样率）、捕获时间特征的计算复杂性、对噪声的敏感性以及缺乏语义上有意义的特征，使得MFCCs等特征提取技术在资源受限的应用中更为实用。
- en: 'Here are some additional details of the critical issues associated with using
    raw audio:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是关于使用原始音频的一些关键问题的附加细节：
- en: '**High Dimensionality**: Audio signals, especially those sampled at high rates,
    result in large amounts of data. For example, a 1-second audio clip sampled at
    16 kHz will have 16,000 individual data points. High-dimensional data increases
    computational complexity, leading to longer training times and higher computational
    costs, making it impractical for resource-constrained environments. Furthermore,
    the wide dynamic range of audio signals requires a significant amount of bits
    per sample, while conveying little useful information.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高维性**：音频信号，尤其是以高采样率采样的信号，会产生大量数据。例如，以16 kHz采样率采样的1秒音频剪辑将包含16,000个独立的数据点。高维数据增加了计算复杂性，导致训练时间更长，计算成本更高，这使得在资源受限的环境中不切实际。此外，音频信号的广泛动态范围需要每个样本大量的比特数，而传达的信息却很少。'
- en: '**Temporal Dependencies**: Raw audio signals have temporal structures that
    simple machine learning models may find hard to capture. While recurrent neural
    networks like [LSTMs](https://annals-csis.org/Volume_18/drp/pdf/185.pdf) can model
    such dependencies, they are computationally intensive and tricky to train on tiny
    devices.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间依赖性**：原始音频信号具有时间结构，简单的机器学习模型可能难以捕捉。虽然循环神经网络（如LSTMs）可以建模这种依赖关系，但它们在小型设备上计算密集且难以训练。'
- en: '**Noise and Variability**: Raw audio signals often contain background noise
    and other non-essential elements affecting model performance. Additionally, the
    same sound can have different characteristics based on various factors such as
    distance from the microphone, the orientation of the sound source, and acoustic
    properties of the environment, adding to the complexity of the data.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**噪声和可变性**：原始音频信号通常包含背景噪声和其他非必要元素，这些都会影响模型性能。此外，同一声音可以根据麦克风距离、声音源方向和环境声学特性等因素具有不同的特征，这增加了数据的复杂性。'
- en: '**Lack of Semantic Meaning**: Raw audio doesn’t inherently contain semantically
    meaningful features for classification tasks. Features like pitch, tempo, and
    spectral characteristics, which can be crucial for speech recognition, are not
    directly accessible from raw waveform data.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏语义意义**：原始音频本身不包含用于分类任务的语义上有意义的特征。像音高、节奏和频谱特征这样的特征，对于语音识别可能至关重要，但它们不能直接从原始波形数据中获取。'
- en: '**Signal Redundancy**: Audio signals often contain redundant information, with
    certain portions of the signal contributing little to no value to the task at
    hand. This redundancy can make learning inefficient and potentially lead to overfitting.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信号冗余**：音频信号通常包含冗余信息，信号中的一些部分对当前任务的价值很小或没有价值。这种冗余可能会使学习效率低下，并可能导致过拟合。'
- en: For these reasons, feature extraction techniques such as Mel-frequency Cepstral
    Coefficients (MFCCs), Mel-Frequency Energies (MFEs), and simple Spectrograms are
    commonly used to transform raw audio data into a more manageable and informative
    format. These features capture the essential characteristics of the audio signal
    while reducing dimensionality and noise, facilitating more effective machine learning.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，特征提取技术，如梅尔频率倒谱系数（MFCCs）、梅尔频率能量（MFEs）和简单的频谱图，通常被用来将原始音频数据转换为更易于管理和信息丰富的格式。这些特征捕捉了音频信号的基本特征，同时降低了维度和噪声，促进了更有效的机器学习。
- en: Overview to MFCCs
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MFCCs概述
- en: What are MFCCs?
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是MFCCs？
- en: '[Mel-frequency Cepstral Coefficients (MFCCs)](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)
    are a set of features derived from the spectral content of an audio signal. They
    are based on human auditory perceptions and are commonly used to capture the phonetic
    characteristics of an audio signal. The MFCCs are computed through a multi-step
    process that includes pre-emphasis, framing, windowing, applying the Fast Fourier
    Transform (FFT) to convert the signal to the frequency domain, and finally, applying
    the Discrete Cosine Transform (DCT). The result is a compact representation of
    the original audio signal’s spectral characteristics.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[梅尔频率倒谱系数（MFCCs）](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)是一组从音频信号的频谱内容中派生出来的特征。它们基于人类的听觉感知，通常用于捕捉音频信号的语音特征。MFCCs通过一个多步骤的过程计算得出，包括预加重、分帧、加窗、应用快速傅里叶变换（FFT）将信号转换为频域，最后应用离散余弦变换（DCT）。结果是原始音频信号频谱特征的紧凑表示。'
- en: 'The image below shows the words `YES` and `NO` in their MFCC representation:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像显示了“YES”和“NO”单词的MFCC表示：
- en: '![](../media/file967.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file967.jpg)'
- en: This [video](https://youtu.be/SJo7vPgRlBQ?si=KSgzmDg8DtSVqzXp) explains the
    Mel Frequency Cepstral Coefficients (MFCC) and how to compute them.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这[视频](https://youtu.be/SJo7vPgRlBQ?si=KSgzmDg8DtSVqzXp)解释了梅尔频率倒谱系数（MFCC）及其计算方法。
- en: Why are MFCCs important?
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么MFCCs很重要？
- en: 'MFCCs are crucial for several reasons, particularly in the context of Keyword
    Spotting (KWS) and TinyML:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: MFCCs之所以至关重要，有多个原因，尤其是在关键词检测（KWS）和TinyML的背景下：
- en: '**Dimensionality Reduction**: MFCCs capture essential spectral characteristics
    of the audio signal while significantly reducing the dimensionality of the data,
    making it ideal for resource-constrained TinyML applications.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维度降低**：MFCCs在捕捉音频信号的基本频谱特征的同时，显著降低了数据的维度，使其非常适合资源受限的TinyML应用。'
- en: '**Robustness**: MFCCs are less susceptible to noise and variations in pitch
    and amplitude, providing a more stable and robust feature set for audio classification
    tasks.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**鲁棒性**：MFCCs对噪声和音高、振幅的变化不太敏感，为音频分类任务提供了更稳定、更鲁棒的特征集。'
- en: '**Human Auditory System Modeling**: The Mel scale in MFCCs approximates the
    human ear’s response to different frequencies, making them practical for speech
    recognition where human-like perception is desired.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类听觉系统建模**：MFCCs中的梅尔尺度近似了人耳对不同频率的响应，使得它们在需要类似人类感知的语音识别中变得实用。'
- en: '**Computational Efficiency**: The process of calculating MFCCs is computationally
    efficient, making it well-suited for real-time applications on hardware with limited
    computational resources.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算效率**：计算MFCCs的过程计算效率高，非常适合在计算资源有限的硬件上实时应用。'
- en: In summary, MFCCs offer a balance of information richness and computational
    efficiency, making them popular for audio classification tasks, particularly in
    constrained environments like TinyML.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，MFCCs在信息丰富性和计算效率之间提供了平衡，因此在音频分类任务中很受欢迎，尤其是在TinyML等受限环境中。
- en: Computing MFCCs
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算MFCCs
- en: The computation of Mel-frequency Cepstral Coefficients (MFCCs) involves several
    key steps. Let’s walk through these, which are particularly important for Keyword
    Spotting (KWS) tasks on TinyML devices.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 梅尔频率倒谱系数 (MFCCs) 的计算涉及几个关键步骤。让我们逐一了解这些步骤，这对于在TinyML设备上的关键词检测 (KWS) 任务尤为重要。
- en: '**Pre-emphasis**: The first step is pre-emphasis, which is applied to accentuate
    the high-frequency components of the audio signal and balance the frequency spectrum.
    This is achieved by applying a filter that amplifies the difference between consecutive
    samples. The formula for pre-emphasis is: <semantics><mrow><mi>y</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>x</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>α</mi><mi>x</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy="true"
    form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y(t)=x(t)-\alpha
    x(t-1)</annotation></semantics>, where <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    is the pre-emphasis factor, typically around 0.97.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预加重**: 第一步是预加重，这是为了强调音频信号的高频成分并平衡频谱。这是通过应用一个放大连续样本之间差异的滤波器来实现的。预加重的公式是：<semantics><mrow><mi>y</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>x</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>α</mi><mi>x</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy="true"
    form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y(t)=x(t)-\alpha
    x(t-1)</annotation></semantics>，其中 <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    是预加重因子，通常约为0.97。'
- en: '**Framing**: Audio signals are divided into short frames (the *frame length*),
    usually 20 to 40 milliseconds. This is based on the assumption that frequencies
    in a signal are stationary over a short period. Framing helps in analyzing the
    signal in such small time slots. The *frame stride* (or step) will displace one
    frame and the adjacent. Those steps could be sequential or overlapped.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分帧**: 音频信号被分成短帧（*帧长度*），通常为20到40毫秒。这是基于信号中的频率在短时间内是平稳的假设。分帧有助于在如此小的时隙内分析信号。*帧步长*（或步进）将移动一个帧及其相邻帧。这些步骤可以是顺序的或重叠的。'
- en: '**Windowing**: Each frame is then windowed to minimize the discontinuities
    at the frame boundaries. A commonly used window function is the Hamming window.
    Windowing prepares the signal for a Fourier transform by minimizing the edge effects.
    The image below shows three frames (10, 20, and 30) and the time samples after
    windowing (note that the frame length and frame stride are 20 ms):'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**窗口化**: 每个帧随后被窗口化以最小化帧边界处的间断性。常用的窗口函数是汉明窗口。窗口化通过最小化边缘效应为傅里叶变换准备信号。下面的图像显示了三个帧（10、20和30）以及窗口化后的时间样本（注意帧长度和帧步长为20
    ms）：'
- en: '![](../media/file968.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file968.jpg)'
- en: '**Fast Fourier Transform (FFT)** The Fast Fourier Transform (FFT) is applied
    to each windowed frame to convert it from the time domain to the frequency domain.
    The FFT gives us a complex-valued representation that includes both magnitude
    and phase information. However, for MFCCs, only the magnitude is used to calculate
    the Power Spectrum. The power spectrum is the square of the magnitude spectrum
    and measures the energy present at each frequency component.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速傅里叶变换 (FFT)** 快速傅里叶变换 (FFT) 被应用于每个窗口化的帧，将其从时域转换为频域。FFT 给出的是一个复数值表示，包括幅度和相位信息。然而，对于梅尔频率倒谱系数
    (MFCCs)，仅使用幅度来计算功率谱。功率谱是幅度谱的平方，并测量每个频率成分的能量。'
- en: The power spectrum <semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mo
    stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(f)</annotation></semantics>
    of a signal <semantics><mrow><mi>x</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo
    stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x(t)</annotation></semantics>
    is defined as <semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mo
    stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mrow><mo stretchy="true"
    form="prefix">|</mo><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mo
    stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow><mn>2</mn></msup></mrow><annotation
    encoding="application/x-tex">P(f)=|X(f)|^2</annotation></semantics>, where <semantics><mrow><mi>X</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>f</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation
    encoding="application/x-tex">X(f)</annotation></semantics> is the Fourier Transform
    of <semantics><mrow><mi>x</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo
    stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x(t)</annotation></semantics>.
    By squaring the magnitude of the Fourier Transform, we emphasize *stronger* frequencies
    over *weaker* ones, thereby capturing more relevant spectral characteristics of
    the audio signal. This is important in applications like audio classification,
    speech recognition, and Keyword Spotting (KWS), where the focus is on identifying
    distinct frequency patterns that characterize different classes of audio or phonemes
    in speech.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 信号的功率谱 <semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mo
    stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(f)</annotation></semantics>
    定义为 <semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mo
    stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mrow><mo stretchy="true"
    form="prefix">|</mo><mi>X</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mo
    stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow><mn>2</mn></msup></mrow><annotation
    encoding="application/x-tex">P(f)=|X(f)|^2</annotation></semantics>，其中 <semantics><mrow><mi>X</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>f</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation
    encoding="application/x-tex">X(f)</annotation></semantics> 是信号 <semantics><mrow><mi>x</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation
    encoding="application/x-tex">x(t)</annotation></semantics> 的傅里叶变换。通过对傅里叶变换的幅度进行平方，我们强调了
    *更强的* 频率相对于 *较弱的* 频率，从而捕捉到音频信号的更多相关频谱特性。这在音频分类、语音识别和关键词检测（KWS）等应用中非常重要，这些应用的重点是识别不同音频类别或语音音素的不同频率模式。
- en: '![](../media/file969.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file969.jpg)'
- en: '**Mel Filter Banks**: The frequency domain is then mapped to the [Mel scale](https://en.wikipedia.org/wiki/Mel_scale),
    which approximates the human ear’s response to different frequencies. The idea
    is to extract more features (more filter banks) in the lower frequencies and less
    in the high frequencies. Thus, it performs well on sounds distinguished by the
    human ear. Typically, 20 to 40 triangular filters extract the Mel-frequency energies.
    These energies are then log-transformed to convert multiplicative factors into
    additive ones, making them more suitable for further processing.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梅尔滤波器组**：然后将频域映射到 [梅尔尺度](https://en.wikipedia.org/wiki/Mel_scale)，该尺度近似人类耳朵对不同频率的响应。想法是在低频提取更多特征（更多滤波器组），而在高频提取较少。因此，它在人类耳朵区分的声音上表现良好。通常，20
    到 40 个三角滤波器提取梅尔频率能量。然后对这些能量进行对数变换，将乘法因子转换为加法因子，使其更适合进一步处理。'
- en: '![](../media/file970.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file970.jpg)'
- en: '**Discrete Cosine Transform (DCT)**: The last step is to apply the [Discrete
    Cosine Transform (DCT)](https://en.wikipedia.org/wiki/Discrete_cosine_transform)
    to the log Mel energies. The DCT helps to decorrelate the energies, effectively
    compressing the data and retaining only the most discriminative features. Usually,
    the first 12-13 DCT coefficients are retained, forming the final MFCC feature
    vector.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散余弦变换 (DCT)**：最后一步是将对数梅尔能量应用离散余弦变换 (DCT)。DCT 有助于去相关能量，有效地压缩数据并仅保留最具判别性的特征。通常，保留前
    12-13 个 DCT 系数，形成最终的 MFCC 特征向量。'
- en: '![](../media/file971.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file971.jpg)'
- en: Hands-On using Python
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 进行实践
- en: 'Let’s apply what we discussed while working on an actual audio sample. Open
    the notebook on Google CoLab and extract the MLCC features on your audio samples:
    [[Open In Colab]](https://colab.research.google.com/github/Mjrovai/Arduino_Nicla_Vision/blob/main/KWS/Audio_Data_Analysis.ipynb)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在实际音频样本上工作时应用我们讨论的内容。在Google CoLab上打开笔记本，并在您的音频样本上提取MLCC特征：[[在 Colab 中打开]](https://colab.research.google.com/github/Mjrovai/Arduino_Nicla_Vision/blob/main/KWS/Audio_Data_Analysis.ipynb)
- en: Summary
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: '*What Feature Extraction technique should we use?*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们应该使用哪种特征提取技术？*'
- en: Mel-frequency Cepstral Coefficients (MFCCs), Mel-Frequency Energies (MFEs),
    or Spectrogram are techniques for representing audio data, which are often helpful
    in different contexts.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 梅尔频率倒谱系数（MFCCs）、梅尔频率能量（MFEs）或频谱图是表示音频数据的技术，它们在不同的环境中通常很有帮助。
- en: In general, MFCCs are more focused on capturing the envelope of the power spectrum,
    which makes them less sensitive to fine-grained spectral details but more robust
    to noise. This is often desirable for speech-related tasks. On the other hand,
    spectrograms or MFEs preserve more detailed frequency information, which can be
    advantageous in tasks that require discrimination based on fine-grained spectral
    content.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，MFCCs更专注于捕捉功率谱的包络，这使得它们对细粒度频谱细节不太敏感，但对噪声更鲁棒。这对于语音相关任务通常是希望的。另一方面，频谱图或MFEs保留了更多详细的频率信息，这对于需要基于细粒度频谱内容进行区分的任务可能是有利的。
- en: MFCCs are particularly strong for
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MFCCs在以下方面特别强大
- en: '**Speech Recognition**: MFCCs are excellent for identifying phonetic content
    in speech signals.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**语音识别**：MFCCs在识别语音信号中的语音内容方面非常出色。'
- en: '**Speaker Identification**: They can be used to distinguish between different
    speakers based on voice characteristics.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**说话人识别**：它们可以根据声音特征区分不同的说话人。'
- en: '**Emotion Recognition**: MFCCs can capture the nuanced variations in speech
    indicative of emotional states.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**情感识别**：MFCCs可以捕捉到表明情绪状态的细微变化。'
- en: '**Keyword Spotting**: Especially in TinyML, where low computational complexity
    and small feature size are crucial.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**关键词检测**：特别是在TinyML中，低计算复杂度和小特征尺寸至关重要。'
- en: Spectrograms or MFEs are often more suitable for
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 频谱图或MFEs通常更适合
- en: '**Music Analysis**: Spectrograms can capture harmonic and timbral structures
    in music, which is essential for tasks like genre classification, instrument recognition,
    or music transcription.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**音乐分析**：频谱图可以捕捉音乐中的和声和音色结构，这对于流派分类、乐器识别或音乐转录等任务至关重要。'
- en: '**Environmental Sound Classification**: In recognizing non-speech, environmental
    sounds (e.g., rain, wind, traffic), the full spectrogram can provide more discriminative
    features.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**环境声音分类**：在识别非语音环境声音（例如，雨、风、交通）时，完整的频谱图可以提供更多区分性特征。'
- en: '**Birdsong Identification**: The intricate details of bird calls are often
    better captured using spectrograms.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**鸟鸣识别**：鸟鸣的复杂细节通常更适合使用频谱图来捕捉。'
- en: '**Bioacoustic Signal Processing**: In applications like dolphin or bat call
    analysis, the fine-grained frequency information in a spectrogram can be essential.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生物声信号处理**：在像海豚或蝙蝠叫声分析这样的应用中，频谱图中的细粒度频率信息可能是至关重要的。'
- en: '**Audio Quality Assurance**: Spectrograms are often used in professional audio
    analysis to identify unwanted noises, clicks, or other artifacts.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**音频质量保证**：频谱图通常在专业音频分析中用于识别不需要的噪音、点击或其他伪迹。'
- en: Resources
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[Audio_Data_Analysis Colab Notebook](https://colab.research.google.com/github/Mjrovai/Arduino_Nicla_Vision/blob/main/KWS/Audio_Data_Analysis.ipynb)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[音频数据分析 Colab 笔记本](https://colab.research.google.com/github/Mjrovai/Arduino_Nicla_Vision/blob/main/KWS/Audio_Data_Analysis.ipynb)'
