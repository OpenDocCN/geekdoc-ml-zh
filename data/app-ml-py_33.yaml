- en: Autoencoder
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨
- en: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_autoencoder.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_autoencoder.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_autoencoder.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_autoencoder.html)
- en: Michael J. Pyrcz, Professor, The University of Texas at Austin
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Michael J. Pyrczï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡æ•™æˆ
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonåº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonåº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
- en: 'Chapter of e-book â€œApplied Machine Learning in Python: a Hands-on Guide with
    Codeâ€.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç”µå­ä¹¦â€œPythonåº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„æ‰‹å†Œâ€çš„ç« èŠ‚ã€‚
- en: 'Cite this e-Book as:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å°†æ­¤ç”µå­ä¹¦å¼•ç”¨å¦‚ä¸‹ï¼š
- en: 'Pyrcz, M.J., 2024, *Applied Machine Learning in Python: A Hands-on Guide with
    Code* [e-book]. Zenodo. doi:10.5281/zenodo.15169138 [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pyrcz, M.J., 2024, *ã€ŠPythonåº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„æ‰‹å†Œã€‹* [ç”µå­ä¹¦]. Zenodo. doi:10.5281/zenodo.15169138
    [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)
- en: 'The workflows in this book and more are available here:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦ä¸­çš„å·¥ä½œæµç¨‹ä»¥åŠæ›´å¤šå†…å®¹å‡å¯åœ¨æ­¤å¤„æ‰¾åˆ°ï¼š
- en: 'Cite the MachineLearningDemos GitHub Repository as:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å°†MachineLearningDemos GitHubä»“åº“å¼•ç”¨å¦‚ä¸‹ï¼š
- en: 'Pyrcz, M.J., 2024, *MachineLearningDemos: Python Machine Learning Demonstration
    Workflows Repository* (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312\.
    GitHub repository: [GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'Pyrcz, M.J., 2024, *ã€ŠMachineLearningDemos: Pythonæœºå™¨å­¦ä¹ æ¼”ç¤ºå·¥ä½œæµç¨‹å­˜å‚¨åº“ã€‹* (0.0.3) [è½¯ä»¶].
    Zenodo. DOI: 10.5281/zenodo.13835312\. GitHubä»“åº“ï¼š[GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
- en: By Michael J. Pyrcz
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±Michael J. Pyrczç¼–å†™
- en: Â© Copyright 2024.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Â© ç‰ˆæƒæ‰€æœ‰ 2024ã€‚
- en: This chapter is a tutorial for / demonstration of **Autoencoders**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« æ˜¯å…³äº/æ¼”ç¤º**è‡ªç¼–ç å™¨**çš„æ•™ç¨‹ã€‚
- en: '**YouTube Lecture**: check out my lectures on:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**YouTube è®²åº§**ï¼šæŸ¥çœ‹æˆ‘åœ¨ä»¥ä¸‹ä¸»é¢˜ä¸Šçš„è®²åº§ï¼š'
- en: '[Artificial Neural Networks](https://youtu.be/A9PiCMY_6nM?si=NxWSU_5RgQ4w55EL)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[äººå·¥ç¥ç»ç½‘ç»œ](https://youtu.be/A9PiCMY_6nM?si=NxWSU_5RgQ4w55EL)'
- en: '[Convolutional Neural Networks](https://youtu.be/za2my_XDoOs?si=LeHU6p2_fc9dX4Yt)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å·ç§¯ç¥ç»ç½‘ç»œ](https://youtu.be/za2my_XDoOs?si=LeHU6p2_fc9dX4Yt)'
- en: These lectures are all part of my [Machine Learning Course](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)
    on YouTube with linked well-documented Python workflows and interactive dashboards.
    My goal is to share accessible, actionable, and repeatable educational content.
    If you want to know about my motivation, check out [Michaelâ€™s Story](https://michaelpyrcz.com/my-story).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è®²åº§éƒ½æ˜¯æˆ‘[æœºå™¨å­¦ä¹ è¯¾ç¨‹](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)çš„ä¸€éƒ¨åˆ†ï¼Œåœ¨YouTubeä¸Šæä¾›äº†æœ‰è‰¯å¥½æ–‡æ¡£è®°å½•çš„Pythonå·¥ä½œæµç¨‹å’Œäº¤äº’å¼ä»ªè¡¨æ¿ã€‚æˆ‘çš„ç›®æ ‡æ˜¯åˆ†äº«æ˜“äºç†è§£ã€å¯æ“ä½œå’Œå¯é‡å¤çš„æ•™è‚²å†…å®¹ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æˆ‘çš„åŠ¨æœºï¼Œè¯·æŸ¥çœ‹[Michaelçš„æ•…äº‹](https://michaelpyrcz.com/my-story)ã€‚
- en: Motivation
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ¨æœº
- en: Autoencoders are a very powerful, flexible deep learning approach for compressing
    information,
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨æ˜¯ä¸€ç§éå¸¸å¼ºå¤§ã€çµæ´»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå‹ç¼©ä¿¡æ¯ï¼Œ
- en: mapping training data to a latent space
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è®­ç»ƒæ•°æ®æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´
- en: dimensionality reduction of high dimensional data to a much lower dimensionality
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†é«˜ç»´æ•°æ®é™ç»´åˆ°æ›´ä½çš„ç»´åº¦
- en: nonlinear, general approach
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éçº¿æ€§ã€é€šç”¨æ–¹æ³•
- en: Autoencoder Architecture
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨æ¶æ„
- en: Hereâ€™s our simple autoencoder,
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æˆ‘ä»¬çš„ç®€å•è‡ªç¼–ç å™¨ï¼Œ
- en: '![](../Images/ed815fe23f4bd258b278f7aa6f0dd58e.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/ed815fe23f4bd258b278f7aa6f0dd58e.png)'
- en: Simple demonstration autoencoder.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•æ¼”ç¤ºè‡ªç¼–ç å™¨ã€‚
- en: This is literally the artificial neural network from the [Artificial Neural
    Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)
    mirrored.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šæ˜¯[äººå·¥ç¥ç»ç½‘ç»œ](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)çš„é•œåƒã€‚
- en: I do not discuss the forward pass through the network, if you are unfamiliar
    with this process, for example,
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸è®¨è®ºé€šè¿‡ç½‘ç»œçš„æ­£å‘ä¼ é€’ï¼Œå¦‚æœä½ ä¸ç†Ÿæ‚‰è¿™ä¸ªè¿‡ç¨‹ï¼Œä¾‹å¦‚ï¼Œ
- en: activation applied to the linear weighting plus bias in the nodes
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨èŠ‚ç‚¹ä¸Šåº”ç”¨æ¿€æ´»åˆ°çº¿æ€§åŠ æƒå’Œåå·®ï¼Œ
- en: then please review the artificial neural network chapter.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œè¯·æŸ¥é˜…äººå·¥ç¥ç»ç½‘ç»œç« èŠ‚ã€‚
- en: I decided to use unique numerical indices for each node for concise notation
    for connection weights, for example \(\lambda_{1,4}\), and biases, for example,
    \(b_4\), \(I\) for input nodes, \(L\) for encoder hidden layer (â€˜leftâ€™), \(M\)
    for latent node (â€˜middleâ€™), \(R\) for decoder hidden layer (â€˜rightâ€™) and finally
    \(O\) for output nodes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å†³å®šä¸ºæ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨ç‹¬ç‰¹çš„æ•°å€¼ç´¢å¼•ä»¥ç®€æ´åœ°è¡¨ç¤ºè¿æ¥æƒé‡ï¼Œä¾‹å¦‚ \(\lambda_{1,4}\)ï¼Œä»¥åŠåå·®ï¼Œä¾‹å¦‚ \(b_4\)ï¼Œ\(I\) ç”¨äºè¾“å…¥èŠ‚ç‚¹ï¼Œ\(L\)
    ç”¨äºç¼–ç å™¨éšè—å±‚ï¼ˆâ€œå·¦â€ï¼‰ï¼Œ\(M\) ç”¨äºæ½œåœ¨èŠ‚ç‚¹ï¼ˆâ€œä¸­â€ï¼‰ï¼Œ\(R\) ç”¨äºè§£ç å™¨éšè—å±‚ï¼ˆâ€œå³â€ï¼‰ï¼Œæœ€å \(O\) ç”¨äºè¾“å‡ºèŠ‚ç‚¹ã€‚
- en: The parts of the autoencoder are indicated below,
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨çš„éƒ¨åˆ†å¦‚ä¸‹æ‰€ç¤ºï¼Œ
- en: '![](../Images/652eb880f88b2d046adcc751aa2d62f6.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/652eb880f88b2d046adcc751aa2d62f6.png)'
- en: Simple demonstration autoencoder with parts labeled.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰æ ‡ç­¾éƒ¨åˆ†çš„ç®€å•æ¼”ç¤ºè‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: The signal passed through the autoencoder and notation include,
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ä¼ é€’çš„ä¿¡å·åŠå…¶è¡¨ç¤ºåŒ…æ‹¬ï¼Œ
- en: '**Input** â€“ training samples,'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥** â€“ è®­ç»ƒæ ·æœ¬ï¼Œ'
- en: \[ z \]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z \]
- en: '**Encoder** â€“ learned compression of the training samples to latent space,'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¼–ç å™¨** â€“ å­¦ä¹ å°†è®­ç»ƒæ ·æœ¬å‹ç¼©åˆ°æ½œåœ¨ç©ºé—´ï¼Œ'
- en: \[ x = f_{\theta} (z) \]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x = f_{\theta} (z) \]
- en: '**Latent Space** â€“ bottleneck summarizes patterns in the training data,'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ½œåœ¨ç©ºé—´** â€“ ç“¶é¢ˆæ€»ç»“äº†è®­ç»ƒæ•°æ®ä¸­çš„æ¨¡å¼ï¼Œ'
- en: \[ ğ‘¥ \]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘¥ \]
- en: '**Decoder** â€“ learned decompression of the latent space to reconstruction of
    the original training data,'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§£ç å™¨** â€“ å­¦ä¹ å¯¹æ½œåœ¨ç©ºé—´è¿›è¡Œè§£å‹ç¼©ä»¥é‡å»ºåŸå§‹è®­ç»ƒæ•°æ®ï¼Œ'
- en: \[ \hat{z} = g_{\phi} (x) = g_{\phi} (f_{\theta}(z) ) \]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{z} = g_{\phi} (x) = g_{\phi} (f_{\theta}(z) ) \]
- en: Reconstruction â€“ attempt to reproduce input,
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é‡å»º** â€“ å°è¯•é‡ç°è¾“å…¥ï¼Œ'
- en: \[ \hat{z} \sim z \]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{z} \sim z \]
- en: Training Model Parameters
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ¨¡å‹å‚æ•°
- en: Training an autoencoder proceeds iteratively by these steps.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿­ä»£è¿›è¡Œã€‚
- en: '![](../Images/c3a5bc8956f8ceda05ddf9b582cd141d.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3a5bc8956f8ceda05ddf9b582cd141d.png)'
- en: Training an artificial neural network proceeds iteratively by, 1\. forward pass
    to make a prediction, 2\. calculate the error derivative based on the prediction
    and truth over training data, 3\. backpropagate the error derivative back through
    the artificial neural network to calculate the derivatives of the error over all
    the model weights and biases parameters, 4\. update the model parameters based
    on the derivatives and learning rates, 5\. repeat until convergence.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒäººå·¥ç¥ç»ç½‘ç»œé€šè¿‡ä»¥ä¸‹è¿­ä»£è¿‡ç¨‹è¿›è¡Œï¼Œ1. æ­£å‘ä¼ é€’è¿›è¡Œé¢„æµ‹ï¼Œ2. æ ¹æ®é¢„æµ‹å’Œè®­ç»ƒæ•°æ®ä¸­çš„çœŸå®å€¼è®¡ç®—è¯¯å·®å¯¼æ•°ï¼Œ3. å°†è¯¯å·®å¯¼æ•°åå‘ä¼ æ’­é€šè¿‡äººå·¥ç¥ç»ç½‘ç»œä»¥è®¡ç®—æ‰€æœ‰æ¨¡å‹æƒé‡å’Œåå·®å‚æ•°çš„è¯¯å·®å¯¼æ•°ï¼Œ4.
    æ ¹æ®å¯¼æ•°å’Œå­¦ä¹ ç‡æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œ5. é‡å¤ç›´åˆ°æ”¶æ•›ã€‚
- en: Hereâ€™s some details on each step,
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯æ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯ï¼Œ
- en: '**Initializing the Model Parameters** - initialize all model parameters with
    typically small (near zero) random values. Hereâ€™s a couple common methods,'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆå§‹åŒ–æ¨¡å‹å‚æ•°** - é€šå¸¸ä½¿ç”¨æ¥è¿‘é›¶çš„å°éšæœºå€¼åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹å‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§æ–¹æ³•ï¼Œ'
- en: '**Xavier Weight Initialization** - random realizations from uniform distributions
    specified by \(U[\text{min}, \text{max}]\),'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Xavier æƒé‡åˆå§‹åŒ–** - ä»ç”± \(U[\text{min}, \text{max}]\) æŒ‡å®šçš„å‡åŒ€åˆ†å¸ƒä¸­æŠ½å–çš„éšæœºå®ç°ï¼Œ'
- en: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}}, \frac{1}{\sqrt{p}} \right]
    (p^\ell) \]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}}, \frac{1}{\sqrt{p}} \right]
    (p^\ell) \]
- en: where \(F^{-1}_U\) is the inverse of the CDF, \(p\) is the number of inputs,
    and \(p^{\ell}\) is a random cumulative probability value drawn from the uniform
    distribution, \(U[0,1]\).
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(F^{-1}_U\) æ˜¯ CDF çš„é€†ï¼Œ\(p\) æ˜¯è¾“å…¥æ•°é‡ï¼Œ\(p^{\ell}\) æ˜¯ä»å‡åŒ€åˆ†å¸ƒ \(U[0,1]\) ä¸­æŠ½å–çš„éšæœºç´¯ç§¯æ¦‚ç‡å€¼ã€‚
- en: '**Normalized Xavier Weight Initialization** - random realizations from uniform
    distributions specified by \(U[\text{min}, \text{max}]\),'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½’ä¸€åŒ– Xavier æƒé‡åˆå§‹åŒ–** - ä»ç”± \(U[\text{min}, \text{max}]\) æŒ‡å®šçš„å‡åŒ€åˆ†å¸ƒä¸­æŠ½å–çš„éšæœºå®ç°ï¼Œ'
- en: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k}
    \right] (p^\ell) \]
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k}
    \right] (p^\ell) \]
- en: where \(F^{-1}_U\) is the inverse of the CDF, \(p\) is the number of inputs,
    \(k\) is the number of outputs, and \(p^{\ell}\) is a random cumulative probability
    value drawn from the uniform distribution, \(U[0,1]\).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(F^{-1}_U\) æ˜¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„é€†ï¼Œ\(p\) æ˜¯è¾“å…¥æ•°é‡ï¼Œ\(k\) æ˜¯è¾“å‡ºæ•°é‡ï¼Œè€Œ \(p^{\ell}\) æ˜¯ä»å‡åŒ€åˆ†å¸ƒ \(U[0,1]\)
    ä¸­æŠ½å–çš„éšæœºç´¯ç§¯æ¦‚ç‡å€¼ã€‚
- en: For example, if we return to our first hidden layer node,
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªéšè—å±‚èŠ‚ç‚¹ï¼Œ
- en: '![](../Images/b2f8e46ea497049f4b95c03b8812eea7.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2f8e46ea497049f4b95c03b8812eea7.png)'
- en: First hidden layer node with 3 inputs, and 1 output.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªéšè—å±‚èŠ‚ç‚¹æœ‰3ä¸ªè¾“å…¥å’Œ1ä¸ªè¾“å‡ºã€‚
- en: we have \(p = 3\) and \(k = 1\), and we draw from the uniform distribution,
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ \(p = 3\) å’Œ \(k = 1\)ï¼Œå¹¶ä¸”æˆ‘ä»¬ä»å‡åŒ€åˆ†å¸ƒä¸­æŠ½å–ï¼Œ
- en: \[ U \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k} \right] = U \left[ \frac{-1}{\sqrt{3}+1},
    \frac{1}{\sqrt{3}+1} \right] \]
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: \[ U \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k} \right] = U \left[ \frac{-1}{\sqrt{3}+1},
    \frac{1}{\sqrt{3}+1} \right] \]
- en: '**Forward Pass** - to pass a training sample, \(z\), to calculate the reconstruction,
    $\hat{z}. Initial predictions will be random for the first iteration, but will
    improve.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ­£å‘ä¼ é€’** - å°†è®­ç»ƒæ ·æœ¬ \(z\) ä¼ é€’è¿‡å»ï¼Œè®¡ç®—é‡å»º \(\hat{z}\)ã€‚åˆå§‹é¢„æµ‹åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£å°†æ˜¯éšæœºçš„ï¼Œä½†ä¼šæ”¹è¿›ã€‚'
- en: '**Calculate the Error Derivative** - based on the miss match between the input
    training sample, \(z\), and the reconstruction, \(\hat{z}\).'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡ç®—è¯¯å·®å¯¼æ•°** - åŸºäºè¾“å…¥è®­ç»ƒæ ·æœ¬ \(z\) å’Œé‡å»º \(\hat{z}\) ä¹‹é—´çš„ä¸åŒ¹é…ã€‚'
- en: '**Backpropagate the Error Derivative** - we shift back through the artificial
    neural network to calculate the derivatives of the error over all the model weights
    and biases parameters, to accomplish this we use the chain rule,'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åå‘ä¼ æ’­è¯¯å·®å¯¼æ•°** - æˆ‘ä»¬é€šè¿‡äººå·¥ç¥ç»ç½‘ç»œåå‘ç§»åŠ¨ä»¥è®¡ç®—æ‰€æœ‰æ¨¡å‹æƒé‡å’Œåç½®å‚æ•°çš„è¯¯å·®å¯¼æ•°ï¼Œä¸ºæ­¤æˆ‘ä»¬ä½¿ç”¨é“¾å¼æ³•åˆ™ï¼Œ'
- en: \[ \frac{\partial}{\partial x} f(g(h(x))) = \frac{\partial f}{\partial g} \cdot
    \frac{\partial g}{\partial h} \cdot \frac{\partial h}{\partial x} \]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial}{\partial x} f(g(h(x))) = \frac{\partial f}{\partial g} \cdot
    \frac{\partial g}{\partial h} \cdot \frac{\partial h}{\partial x} \]
- en: '**Loop Over Batch and Average the Error Derivatives** - go to step 1 for all
    training data in the batch and then calculate the average of the error derivatives,
    for example,'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åœ¨æ‰¹æ¬¡ä¸­å¾ªç¯å¹¶å¹³å‡è¯¯å·®å¯¼æ•°** - å¯¹æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰è®­ç»ƒæ•°æ®è¿›è¡Œæ­¥éª¤1ï¼Œç„¶åè®¡ç®—è¯¯å·®å¯¼æ•°çš„å¹³å‡å€¼ï¼Œä¾‹å¦‚ï¼Œ'
- en: '**Update the Model Parameters** - based on the derivatives, \frac{\partial
    P}{\partial \lambda_{i,j}} and learning rates, \(\eta\), like this,'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ›´æ–°æ¨¡å‹å‚æ•°** - åŸºäºå¯¼æ•° \(\frac{\partial P}{\partial \lambda_{i,j}}\) å’Œå­¦ä¹ ç‡ \(\eta\)ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œ'
- en: \[ \lambda_{1,4}^{\ell} = \lambda_{1,4}^{\ell-1} - \eta \cdot \frac{1}{B} \sum_{i=1}^{B}
    \frac{\partial \mathcal{L}^{(i)}}{\partial \lambda_{1,4}} \]
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{1,4}^{\ell} = \lambda_{1,4}^{\ell-1} - \eta \cdot \frac{1}{B} \sum_{i=1}^{B}
    \frac{\partial \mathcal{L}^{(i)}}{\partial \lambda_{1,4}} \]
- en: '**Repeat Until Convergence** - return to step 1\. until the error, \(P\), is
    reduced to an acceptable level, i.e., model convergence is the condition to stop
    the iterations'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é‡å¤ç›´åˆ°æ”¶æ•›** - è¿”å›æ­¥éª¤1ï¼Œç›´åˆ°è¯¯å·® \(P\) é™ä½åˆ°å¯æ¥å—çš„æ°´å¹³ï¼Œå³æ¨¡å‹æ”¶æ•›æ˜¯åœæ­¢è¿­ä»£çš„æ¡ä»¶'
- en: Autoencoder Loss
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨æŸå¤±
- en: There is a loss and loss gradient at each output-input node pair. The error
    loss function,
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªè¾“å‡º-è¾“å…¥èŠ‚ç‚¹å¯¹ä¸­éƒ½æœ‰ä¸€ä¸ªæŸå¤±å’ŒæŸå¤±æ¢¯åº¦ã€‚è¯¯å·®æŸå¤±å‡½æ•°ï¼Œ
- en: '![](../Images/701ec6c7b420f85dae65e62285e83b13.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/701ec6c7b420f85dae65e62285e83b13.png)'
- en: Autoencoder loss at each output node, the goal is for the output to match the
    input.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„è‡ªåŠ¨ç¼–ç å™¨æŸå¤±ï¼Œç›®æ ‡æ˜¯ä½¿è¾“å‡ºä¸è¾“å…¥åŒ¹é…ã€‚
- en: We can generalize as,
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ¦‚æ‹¬ä¸ºï¼Œ
- en: \[ L = \frac{1}{2} \sum_{i=1}^3 \left(O_{i+8} - I_i \right)^2 \]
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L = \frac{1}{2} \sum_{i=1}^3 \left(O_{i+8} - I_i \right)^2 \]
- en: Note, the irregular indexing is due to my choice to use a unique node index
    at each node.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œä¸è§„åˆ™çš„ç´¢å¼•æ˜¯ç”±äºæˆ‘é€‰æ‹©åœ¨æ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨å”¯ä¸€çš„èŠ‚ç‚¹ç´¢å¼•ã€‚
- en: Error derivative at each node is,
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªèŠ‚ç‚¹çš„è¯¯å·®å¯¼æ•°æ˜¯ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial O_9} = O_9 - I_1 \]\[ \frac{\partial
    \mathcal{L}}{\partial O_{10}} = O_{10} - I_2 \]\[ \frac{\partial \mathcal{L}}{\partial
    O_{11}} = O_{11} - I_3 \]
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial O_9} = O_9 - I_1 \]\[ \frac{\partial
    \mathcal{L}}{\partial O_{10}} = O_{10} - I_2 \]\[ \frac{\partial \mathcal{L}}{\partial
    O_{11}} = O_{11} - I_3 \]
- en: Autoencoder Backpropagation
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨åå‘ä¼ æ’­
- en: Letâ€™s walk through the back propagation of our autoencoder, letâ€™s start with
    a bias in the output node, \(\frac{\partial \mathcal{L}}{\partial b_{9}}\).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨çš„åå‘ä¼ æ’­æ¥é€æ­¥åˆ†æï¼Œè®©æˆ‘ä»¬ä»ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„åç½®å¼€å§‹ï¼Œ\(\frac{\partial \mathcal{L}}{\partial
    b_{9}}\)ã€‚
- en: '![](../Images/8a6b2383ff34c83e1de1a609373cc653.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a6b2383ff34c83e1de1a609373cc653.png)'
- en: Backpropagation to the bias, \(ğ‘_9\), in the hidden decoder node, \(ğ‘‚_9\).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°éšè—è§£ç èŠ‚ç‚¹ \(ğ‘‚_9\) ä¸­çš„åç½® \(ğ‘_9\)ã€‚
- en: By the chain rule we get,
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_9} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    b_9} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = 1 \cdot 1 \cdot (O_9 - I_1) \]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_9} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    b_9} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = 1 \cdot 1 \cdot (O_9 - I_1) \]
- en: Letâ€™s explain each part. We start with the output gradient \(\frac{\partial
    \mathcal{L}}{\partial O_9}\) and step across the output node, \(O_9\), since linear
    activation is applied in the output nodes,
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è§£é‡Šæ¯ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬ä»ä¸€ä¸ªè¾“å‡ºæ¢¯åº¦ \(\frac{\partial \mathcal{L}}{\partial O_9}\) å¼€å§‹ï¼Œå¹¶è·¨è¿‡è¾“å‡ºèŠ‚ç‚¹
    \(O_9\)ï¼Œå› ä¸ºè¾“å‡ºèŠ‚ç‚¹åº”ç”¨äº†çº¿æ€§æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} = 1.0 \]
- en: Now we can calculate the derivative of the bias, \(b_9\), with respect to the
    node input,
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥è®¡ç®—åç½® \(b_9\) å…³äºèŠ‚ç‚¹è¾“å…¥çš„å¯¼æ•°ï¼Œ
- en: \[ \frac{\partial 0_{9_{\mathrm{in}}}}{\partial b_9} = \frac{\partial}{\partial
    b_9} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = 1 \]
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial 0_{9_{\mathrm{in}}}}{\partial b_9} = \frac{\partial}{\partial
    b_9} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = 1 \]
- en: Now we can proceed to the connection weight, ğœ†_7,9.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°è¿æ¥æƒé‡ï¼Œğœ†_7,9ã€‚
- en: '![](../Images/80eaca0166d0cf02f98e140c090fca18.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80eaca0166d0cf02f98e140c090fca18.png)'
- en: Backpropagation to the connection weight, \(\lambda_{7,9}\).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{7,9}\)ã€‚
- en: By the chain rule we get,
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{7,9}} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    \lambda_{7,9}} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = R_7 \cdot 1 \cdot (O_9 - I_1) \]
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{7,9}} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    \lambda_{7,9}} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = R_7 \cdot 1 \cdot (O_9 - I_1) \]
- en: Once again, since linear activation is applied in the output nodes,
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œç”±äºè¾“å‡ºèŠ‚ç‚¹åº”ç”¨äº†çº¿æ€§æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
- en: and \(\frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}}\) is simply the
    output from \(ğ‘…_7\),
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}}\) ç®€å•åœ°æ˜¯ \(ğ‘…_7\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}} = \frac{\partial}{\partial
    \lambda_{7,9}} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = R_7
    \]
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}} = \frac{\partial}{\partial
    \lambda_{7,9}} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = R_7
    \]
- en: Letâ€™s continue past \(\partial \lambda_{7,9}\) to the output from our decoder
    hidden node, \(ğ‘…_7\)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­ä» \(\partial \lambda_{7,9}\) åˆ°è§£ç å™¨éšè—èŠ‚ç‚¹ \(ğ‘…_7\) çš„è¾“å‡ºï¼Œ
- en: '![](../Images/1c85ce96ca6f0999b7bc167c32d65b89.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c85ce96ca6f0999b7bc167c32d65b89.png)'
- en: Backpropagation to the output of the decoder hidden layer node \(R_7\).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°è§£ç å™¨éšè—å±‚èŠ‚ç‚¹ \(R_7\) çš„è¾“å‡ºã€‚
- en: By the chain rule we get,
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} + \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7}
    \cdot \frac{\partial O_{10}}{\partial O_{10_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{10}} + \frac{\partial O_{11_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_{11}}{\partial O_{11_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{11}} \]
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} + \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7}
    \cdot \frac{\partial O_{10}}{\partial O_{10_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{10}} + \frac{\partial O_{11_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_{11}}{\partial O_{11_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{11}} \]
- en: that we can evaluate as,
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è¯„ä¼°ä¸ºï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \lambda_{7,9} \cdot 1 \cdot (O_9
    - I_1) + \lambda_{7,10} \cdot 1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1
    \cdot (O_{11} - I_3) \]
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \lambda_{7,9} \cdot 1 \cdot (O_9
    - I_1) + \lambda_{7,10} \cdot 1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1
    \cdot (O_{11} - I_3) \]
- en: We add the derivatives from each connection. Once again, since linear activation
    at \(ğ‘‚_{9}\), \(ğ‘‚_{10}\), and \(ğ‘‚_{11}\),
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¯ä¸ªè¿æ¥çš„å¯¼æ•°ç›¸åŠ ã€‚ç”±äº \(ğ‘‚_{9}\)ï¼Œ\(ğ‘‚_{10}\) å’Œ \(ğ‘‚_{11}\) å¤„åº”ç”¨äº†çº¿æ€§æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} = 1, \quad \frac{\partial
    O_{10}}{\partial O_{10_{\mathrm{in}}}} = 1, \quad \frac{\partial O_{11}}{\partial
    O_{11_{\mathrm{in}}}} = 1 \]
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} = 1, \quad \frac{\partial
    O_{10}}{\partial O_{10_{\mathrm{in}}}} = 1, \quad \frac{\partial O_{11}}{\partial
    O_{11_{\mathrm{in}}}} = 1 \]
- en: Also, along the connection, the derivative is simply the weight,
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ²¿ç€è¿æ¥ï¼Œå¯¼æ•°ç®€å•åœ°æ˜¯æƒé‡ï¼Œ
- en: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,9}, \quad
    \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,10}, \quad \frac{\partial
    O_{11_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,11} \]
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,9}, \quad
    \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,10}, \quad \frac{\partial
    O_{11_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,11} \]
- en: for example we can demonstrate this for \(\frac{\partial O_{9_{\mathrm{in}}}}{\partial
    R_7}\) as,
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¸º \(\frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7}\) å±•ç¤ºè¿™ä¸€ç‚¹ï¼Œ
- en: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \frac{\partial}{\partial
    R_7} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = \lambda_{7,9}
    \]
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \frac{\partial}{\partial
    R_7} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = \lambda_{7,9}
    \]
- en: Letâ€™s continue from the output from our decoder hidden layer node, \(ğ‘…_7\),
    to calculate the derivative of the bias in the node, \(b_7\).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æˆ‘ä»¬çš„è§£ç å™¨éšè—å±‚èŠ‚ç‚¹ï¼Œ\(ğ‘…_7\)ï¼Œçš„è¾“å‡ºç»§ç»­è®¡ç®—èŠ‚ç‚¹åç½® \(b_7\) çš„å¯¼æ•°ã€‚
- en: '![](../Images/604e4fcf99d1c41dd899458f80a67179.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/604e4fcf99d1c41dd899458f80a67179.png)'
- en: Backpropagation to the bias, $b_7$, in the hidden decoder node, $R_7$.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°éšè—è§£ç å™¨èŠ‚ç‚¹ \(R_7\) ä¸­çš„åç½®ï¼Œ\(b_7\)ã€‚
- en: From the chain rule we get,
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_7} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    b_7} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_7} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    b_7} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
- en: Since sigmoid activation at \(R_7\), to move across the node,
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåœ¨ \(R_7\) å¤„çš„ sigmoid æ¿€æ´»ï¼Œè¦è·¨è¿‡èŠ‚ç‚¹ï¼Œ
- en: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = \sigma' (R_7) = R_7 (1
    - R_7) \]
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = \sigma' (R_7) = R_7 (1
    - R_7) \]
- en: and for the partial derivative of the node input given the bias,
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠå¯¹äºç»™å®šåç½®çš„èŠ‚ç‚¹è¾“å…¥çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{R_{7_{\mathrm{in}}}}{\partial b_7} = \frac{\partial}{\partial b_7}
    \left( \lambda_{6,7} M_6 + b_7 \right) = 1 \]
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{R_{7_{\mathrm{in}}}}{\partial b_7} = \frac{\partial}{\partial b_7}
    \left( \lambda_{6,7} M_6 + b_7 \right) = 1 \]
- en: So now we have,
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_7} = 1 \cdot R_7 (1 - R_7) \cdot \overbrace{
    \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot 1 \cdot
    (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    L}{\partial R_7}} \]
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_7} = 1 \cdot R_7 (1 - R_7) \cdot \overbrace{
    \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot 1 \cdot
    (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    L}{\partial R_7}} \]
- en: Now we can proceed to the connection weight, \(\lambda_{6,7}\).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{6,7}\)ã€‚
- en: '![](../Images/1559af01deb817828f382cd89480ff41.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1559af01deb817828f382cd89480ff41.png)'
- en: Backpropagation to the connection weight, \(\lambda_{6,7}\).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{6,7}\)ã€‚
- en: By the chain rule we get,
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{6,7}} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    \lambda_{6,7}} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{6,7}} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    \lambda_{6,7}} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
- en: Once again, since sigmoid activation is applied in the hidden layer nodes,
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œç”±äºåœ¨éšè—å±‚èŠ‚ç‚¹ä¸­åº”ç”¨äº† sigmoid æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial R_7}{\partial R_{7_{in}}} = 1.0 \]
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_7}{\partial R_{7_{in}}} = 1.0 \]
- en: and \(\frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}}\) is simply
    the output from \(M_6\),
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}}\) ç®€å•åœ°æ˜¯ \(M_6\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}} = \frac{\partial}{\partial
    \lambda_{6,7}} \left( \lambda_{6,7} M_6 + b_6 \right) = M_6 \]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}} = \frac{\partial}{\partial
    \lambda_{6,7}} \left( \lambda_{6,7} M_6 + b_6 \right) = M_6 \]
- en: So now we have,
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_7} = M_6 \cdot R_7 (1 - R_7) \cdot
    \overbrace{ \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot
    1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    \mathcal{L}}{\partial R_7}} \]
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_7} = M_6 \cdot R_7 (1 - R_7) \cdot
    \overbrace{ \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot
    1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    \mathcal{L}}{\partial R_7}} \]
- en: Letâ€™s get continue to the output from our latent node, ğ‘€_6
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­ä»æˆ‘ä»¬çš„æ½œåœ¨èŠ‚ç‚¹ï¼Œğ‘€_6ï¼Œè¾“å‡ºã€‚
- en: '![](../Images/f4cc7dbc1493a36ab0eb828c1422d1f2.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4cc7dbc1493a36ab0eb828c1422d1f2.png)'
- en: Backpropagation to the output of the latent node, \(M_6\).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°æ½œåœ¨èŠ‚ç‚¹çš„è¾“å‡ºï¼Œ\(M_6\)ã€‚
- en: By the chain rule we get,
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6}
    \cdot \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \]
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6}
    \cdot \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \]
- en: That we can resolve as,
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†å…¶è¡¨ç¤ºä¸ºï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \lambda_{6,7} \cdot R_7 (1 -
    R_7) \cdot \frac{\partial \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8
    (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial R_8} \]
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \lambda_{6,7} \cdot R_7 (1 -
    R_7) \cdot \frac{\partial \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8
    (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial R_8} \]
- en: Once again, since sigmoid activation,
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ¬¡åˆä¸€æ¬¡ï¼Œç”±äºä½¿ç”¨äº†sigmoidæ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = R_7 (1 - R_7), \quad
    \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} = R_8 (1 - R_8) \]
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = R_7 (1 - R_7), \quad
    \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} = R_8 (1 - R_8) \]
- en: and along the connections,
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”æ²¿ç€è¿æ¥ï¼Œ
- en: \[\begin{split} \begin{aligned} \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} &= \frac{\partial}{\partial M_6} \left( \lambda_{6,7} M_6 + b_7 \right) =
    \lambda_{6,7} \\ \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6} &= \frac{\partial}{\partial
    M_6} \left( \lambda_{6,8} M_6 + b_8 \right) = \lambda_{6,8} \end{aligned} \end{split}\]
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{aligned} \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} &= \frac{\partial}{\partial M_6} \left( \lambda_{6,7} M_6 + b_7 \right) =
    \lambda_{6,7} \\ \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6} &= \frac{\partial}{\partial
    M_6} \left( \lambda_{6,8} M_6 + b_8 \right) = \lambda_{6,8} \end{aligned} \end{split}\]
- en: Letâ€™s continue from the output from our latent node, \(M_6\), to calculate the
    derivative of the bias in the node, \(b_6\).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æ½œåœ¨èŠ‚ç‚¹$M_6$çš„è¾“å‡ºç»§ç»­è®¡ç®—èŠ‚ç‚¹åç½®$b_6$çš„å¯¼æ•°ã€‚
- en: '![](../Images/90618005b205c6c5ceb09965c36cf2e1.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90618005b205c6c5ceb09965c36cf2e1.png)'
- en: Backpropagation to the bias, $b_6$, in the latent node, $M_6$. Note image shifted
    to make room.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ½œåœ¨èŠ‚ç‚¹$M_6$ä¸­çš„åç½®$b_6$çš„åå‘ä¼ æ’­ï¼Œæ³¨æ„å›¾åƒå·²ç§»åŠ¨ä»¥è…¾å‡ºç©ºé—´ã€‚
- en: From the chain rule we get,
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_6} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    b_6} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_6} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    b_6} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
- en: Since sigmoid activation at \(M_6\), to move across the node,
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåœ¨$M_6$å¤„åº”ç”¨äº†sigmoidæ¿€æ´»å‡½æ•°ï¼Œä»¥è·¨è¿‡èŠ‚ç‚¹ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
- en: and for the partial derivative of the node input given the bias,
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”å¯¹äºç»™å®šåç½®çš„èŠ‚ç‚¹è¾“å…¥çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
- en: So now we have,
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
- en: Now we can proceed to the connection weight, \(\lambda_{4,6}\).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°è¿æ¥æƒé‡ï¼Œ$\lambda_{4,6}$ã€‚
- en: '![](../Images/f5770d05672cfe3c14c6973f2775d2de.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5770d05672cfe3c14c6973f2775d2de.png)'
- en: Backpropagation to the connection weight, \(\lambda_{4,6}\).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å°†åå‘ä¼ æ’­åˆ°è¿æ¥æƒé‡$\lambda_{4,6}$ã€‚
- en: By the chain rule we get,
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    \lambda_{4,6}} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    \lambda_{4,6}} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
- en: Once again, since sigmoid activation is applied in the hidden layer nodes,
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ¬¡åˆä¸€æ¬¡ï¼Œç”±äºåœ¨éšè—å±‚èŠ‚ç‚¹ä¸­åº”ç”¨äº†sigmoidæ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{in}}} = M_6 \cdot (1 - M_6) \]
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{in}}} = M_6 \cdot (1 - M_6) \]
- en: and \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}}\) is simply
    the output from \(L_4\),
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}}\) ç®€å•åœ°æ˜¯ \(L_4\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}} = \frac{\partial}{\partial
    \lambda_{4,6}} \left( \lambda_{4,6} L_4 + \lambda_{5,6} L_5 + b_6 \right) = L_4
    \]
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}} = \frac{\partial}{\partial
    \lambda_{4,6}} \left( \lambda_{4,6} L_4 + \lambda_{5,6} L_5 + b_6 \right) = L_4
    \]
- en: So now we have,
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = L_4 \cdot M_6 (1 -
    M_6) \cdot \overbrace{ \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial
    \mathcal{L}}{\partial R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}}
    \]
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = L_4 \cdot M_6 (1 -
    M_6) \cdot \overbrace{ \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial
    \mathcal{L}}{\partial R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}}
    \]
- en: Now we can proceed to the output of our encoder hidden layer node, \(L_4\).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°ç¼–ç å™¨éšè—å±‚èŠ‚ç‚¹çš„è¾“å‡ºï¼Œ\(L_4\)ã€‚
- en: '![](../Images/1e5148ec01b8276d13a3ac564a201ab3.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e5148ec01b8276d13a3ac564a201ab3.png)'
- en: Backpropagation to the output of the encoder hidden node, \(ğ¿_4\).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: å‘ç¼–ç å™¨éšè—èŠ‚ç‚¹çš„è¾“å‡ºè¿›è¡Œåå‘ä¼ æ’­ï¼Œ\(ğ¿_4\)ã€‚
- en: By the chain rule we get this and evaluate it as,
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°è¿™ä¸ªå¹¶å¯¹å…¶è¿›è¡Œè¯„ä¼°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial L_4} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    L_4} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} = \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial L_4} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    L_4} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} = \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
- en: Once again, since sigmoid activation is applied in the latent node,
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œç”±äºåœ¨æ½œåœ¨èŠ‚ç‚¹ä¸­åº”ç”¨äº†sigmoidæ¿€æ´»ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = M_6 (1 - M_6) \]
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = M_6 (1 - M_6) \]
- en: and \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4}\) is simply the weight,
    \(\lambda_{4,6}\),
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4}\) ç®€å•åœ°æ˜¯æƒé‡ï¼Œ\(\lambda_{4,6}\)ï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4} = \frac{\partial}{\partial
    L_4} \left( \lambda_{4,6} L_4 + b_6 \right) = \lambda_{4,6} \]
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4} = \frac{\partial}{\partial
    L_4} \left( \lambda_{4,6} L_4 + b_6 \right) = \lambda_{4,6} \]
- en: Letâ€™s continue from the output from our encoder hidden layer node, \(L_4\),
    to calculate the derivative of the bias in the node, \(b_4\).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ç¼–ç å™¨éšè—å±‚èŠ‚ç‚¹çš„è¾“å‡º \(L_4\) å¼€å§‹ï¼Œè®¡ç®—èŠ‚ç‚¹ä¸­åç½® \(b_4\) çš„å¯¼æ•°ã€‚
- en: '![](../Images/cf8f925e7a89e3d992b323edfd45034e.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf8f925e7a89e3d992b323edfd45034e.png)'
- en: Backpropagation to the bias, $b_4$, in the encoder hidden layer node, $L_4$.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: å‘ç¼–ç å™¨éšè—å±‚èŠ‚ç‚¹ \(L_4\) ä¸­çš„åç½® \(b_4\) è¿›è¡Œåå‘ä¼ æ’­ã€‚
- en: From the chain rule we get,
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_4} = \frac{\partial L_{4_{\mathrm{in}}}}{\partial
    b_4} \cdot \frac{\partial L_4}{\partial L_{4_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} = 1 \cdot L_4 (1 - L_4) \cdot \frac{\partial \mathcal{L}}{\partial
    L_4} \]
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_4} = \frac{\partial L_{4_{\mathrm{in}}}}{\partial
    b_4} \cdot \frac{\partial L_4}{\partial L_{4_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} = 1 \cdot L_4 (1 - L_4) \cdot \frac{\partial \mathcal{L}}{\partial
    L_4} \]
- en: Since sigmoid activation at \(M_6\), to move across the node,
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº \(M_6\) å¤„çš„sigmoidæ¿€æ´»ï¼Œè¦ç©¿è¿‡èŠ‚ç‚¹ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
- en: and for the partial derivative of the node input given the bias,
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç»™å®šåç½®çš„èŠ‚ç‚¹è¾“å…¥çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
- en: So now we have,
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
- en: And, finally we proceed to the connection weight, \(\lambda_{1,4}\).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ç»§ç»­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{1,4}\)ã€‚
- en: '![](../Images/3623ed192b17eb44b8f6f8c59b1dc0d0.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3623ed192b17eb44b8f6f8c59b1dc0d0.png)'
- en: Backpropagation to the connection weight, \(\lambda_{1,4}\).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: å‘è¿æ¥æƒé‡ \(\lambda_{1,4}\) è¿›è¡Œåå‘ä¼ æ’­ã€‚
- en: By the chain rule we get,
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{1,4}} = \frac{\partial L^{\text{in}}_4}{\partial
    \lambda_{1,4}} \cdot \frac{\partial L_4}{\partial L^{\text{in}}_4} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} \]
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{1,4}} = \frac{\partial L^{\text{in}}_4}{\partial
    \lambda_{1,4}} \cdot \frac{\partial L_4}{\partial L^{\text{in}}_4} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} \]
- en: Once again, since sigmoid activation is applied in the hidden layer nodes,
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œç”±äºåœ¨éšè—å±‚èŠ‚ç‚¹ä¸­åº”ç”¨äº†sigmoidæ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial L_4}{\partial L_{4_{in}}} = L_4 \cdot (1 - L_4) \]
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial L_4}{\partial L_{4_{in}}} = L_4 \cdot (1 - L_4) \]
- en: and \(\frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}}\) is simply the
    output from \(I_1\),
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}}\) ç®€å•åœ°æ˜¯ \(I_1\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}} = \frac{\partial}{\partial
    \lambda_{1,4}} \left( \lambda_{1,4} I_1 + \lambda_{2,4} I_2 + \lambda_{3,4} I_3
    + b_4 \right) = I_1 \]
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}} = \frac{\partial}{\partial
    \lambda_{1,4}} \left( \lambda_{1,4} I_1 + \lambda_{2,4} I_2 + \lambda_{3,4} I_3
    + b_4 \right) = I_1 \]
- en: So now we have,
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ï¼Œ
- en: \[ \frac{\partial L}{\partial \lambda_{1,4}} = I_1 \cdot L_4 (1 - L_4) \cdot
    \underbrace{\left[ \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial L}{\partial
    M_6} \right]}_{\frac{\partial L}{\partial L_4}} \]
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial L}{\partial \lambda_{1,4}} = I_1 \cdot L_4 (1 - L_4) \cdot
    \underbrace{\left[ \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial L}{\partial
    M_6} \right]}_{\frac{\partial L}{\partial L_4}} \]
- en: Now we will build out this autoencoder from the ground up with only the NumPy
    python package for arrays and Python built-in data structure dictionaries.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨NumPy PythonåŒ…å’ŒPythonå†…ç½®æ•°æ®ç»“æ„å­—å…¸ä»å¤´å¼€å§‹æ„å»ºè¿™ä¸ªè‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: Import Required Packages
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¼å…¥æ‰€éœ€çš„åŒ…
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›æ ‡å‡†åŒ…ã€‚è¿™äº›åº”è¯¥å·²ç»é€šè¿‡Anaconda 3å®‰è£…ã€‚
- en: '[PRE0]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing â€˜python -m pip install [package-name]â€™. More assistance is available
    with the respective package docs.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœé‡åˆ°åŒ…å¯¼å…¥é”™è¯¯ï¼Œä½ å¯èƒ½éœ€è¦é¦–å…ˆå®‰è£…è¿™äº›åŒ…ä¸­çš„ä¸€äº›ã€‚è¿™é€šå¸¸å¯ä»¥é€šè¿‡åœ¨Windowsä¸Šæ‰“å¼€å‘½ä»¤çª—å£å¹¶è¾“å…¥â€˜python -m pip install [package-name]â€™æ¥å®Œæˆã€‚æ›´å¤šå¸®åŠ©å¯ä»¥åœ¨ç›¸åº”åŒ…çš„æ–‡æ¡£ä¸­æ‰¾åˆ°ã€‚
- en: Declare Functions
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å£°æ˜å‡½æ•°
- en: Hereâ€™s the functions to train and visualize our autoencoder.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæä¾›äº†è®­ç»ƒå’Œå¯è§†åŒ–æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨çš„å‡½æ•°ã€‚
- en: '[PRE1]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Visualize the Autoencoder Network
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œ
- en: Here we specify the autoencoder labels, positions, connections and colors and
    then plot the autoencoder.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‡å®šè‡ªåŠ¨ç¼–ç å™¨çš„æ ‡ç­¾ã€ä½ç½®ã€è¿æ¥å’Œé¢œè‰²ï¼Œç„¶åç»˜åˆ¶è‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: while this code is general, the actual autoencoder codes are not generalized
    to work with other architectures, for example changing the depth or width of the
    network
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™ä¸ªä»£ç æ˜¯é€šç”¨çš„ï¼Œä½†å®é™…çš„è‡ªåŠ¨ç¼–ç å™¨ä»£ç å¹¶æ²¡æœ‰æ¨å¹¿åˆ°ä¸å…¶ä»–æ¶æ„ä¸€èµ·å·¥ä½œï¼Œä¾‹å¦‚æ”¹å˜ç½‘ç»œçš„æ·±åº¦æˆ–å®½åº¦
- en: change the display parameters but do not the autoencoder architecture
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»…æ›´æ”¹æ˜¾ç¤ºå‚æ•°ï¼Œä½†ä¸è¦æ›´æ”¹è‡ªåŠ¨ç¼–ç å™¨æ¶æ„
- en: '[PRE2]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![_images/333249f6a43bbad84e15a2423db3b9cc8670650c55532adfe9fea6ac7c992872.png](../Images/330a264f2ed0fefaff128fb34a83b1e7.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![_images/333249f6a43bbad84e15a2423db3b9cc8670650c55532adfe9fea6ac7c992872.png](../Images/330a264f2ed0fefaff128fb34a83b1e7.png)'
- en: Make an Interesting Synthetic Dataset
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæœ‰è¶£çš„åˆæˆæ•°æ®é›†
- en: Generate a stochastic dataset of 1D length of 3 vectors with a pattern that
    can be summarized by our autoencoder.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ä¸ª1Dé•¿åº¦ä¸º3å‘é‡çš„éšæœºæ•°æ®é›†ï¼Œå…¶æ¨¡å¼å¯ä»¥è¢«æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨æ€»ç»“ã€‚
- en: if we generate random 1D vectors of length 3 our autoencoder would not be able
    to summarize, i.e., it is not possible to compress the information from the original
    3 values
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç”Ÿæˆé•¿åº¦ä¸º3çš„éšæœº1Då‘é‡ï¼Œæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å°†æ— æ³•æ€»ç»“ï¼Œå³ï¼Œæ— æ³•ä»åŸå§‹çš„3ä¸ªå€¼ä¸­å‹ç¼©ä¿¡æ¯
- en: we must include a pattern that can be learned by the autoencoder to observe
    dimensionality reduction through the latent node with good data reconstruction
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»åŒ…æ‹¬ä¸€ä¸ªå¯ä»¥è¢«è‡ªåŠ¨ç¼–ç å™¨å­¦ä¹ çš„æ¨¡å¼ï¼Œä»¥é€šè¿‡æ½œåœ¨èŠ‚ç‚¹è§‚å¯Ÿé€šè¿‡è‰¯å¥½çš„æ•°æ®é‡å»ºå®ç°çš„é™ç»´
- en: To do this, I have calculate dataset as a hybrid model, linear + small random
    residual. The data generation steps include,
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘å·²ç»å°†æ•°æ®é›†ä½œä¸ºä¸€ä¸ªæ··åˆæ¨¡å‹è®¡ç®—ï¼Œçº¿æ€§åŠ å°çš„éšæœºæ®‹å·®ã€‚æ•°æ®ç”Ÿæˆæ­¥éª¤åŒ…æ‹¬ï¼Œ
- en: draw a random slope \(\sim N\left[-2.0, 2.0 \right]\)
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ä¸€ä¸ªéšæœºæ–œç‡ \(\sim N\left[-2.0, 2.0 \right]\)
- en: calculate 3 points at locations \(\left[-1, 0, 1 \right]\), \(f(\left[-1, 0,
    1 \right])\)
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ä½ç½® \(\left[-1, 0, 1 \right]\), \(f(\left[-1, 0, 1 \right])\) è®¡ç®—ä¸‰ä¸ªç‚¹
- en: add random, independent residual to each location, \(f(\left[-1, 0, 1 \right])
    + N\left[0.0,\sigma \right]\), where sigma is the residual standard deviation
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‘æ¯ä¸ªä½ç½®æ·»åŠ éšæœºã€ç‹¬ç«‹çš„æ®‹å·®ï¼Œ\(f(\left[-1, 0, 1 \right]) + N\left[0.0,\sigma \right]\)ï¼Œå…¶ä¸­sigmaæ˜¯æ®‹å·®æ ‡å‡†å·®
- en: Note, the slope is retained as a label that will be compared to the latent node,
    \(M_6\) output to check, what has our autoencoder has learned?
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæ–œç‡è¢«ä¿ç•™ä½œä¸ºä¸€ä¸ªæ ‡ç­¾ï¼Œå°†ç”¨äºä¸æ½œåœ¨èŠ‚ç‚¹ \(M_6\) è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ£€æŸ¥ï¼Œæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ
- en: our hypothesis is that the autoencoder will learn a value that directly maps
    to slope to describe this dataset.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å‡è®¾æ˜¯ï¼Œè‡ªåŠ¨ç¼–ç å™¨å°†å­¦ä¹ ä¸€ä¸ªå€¼ï¼Œè¯¥å€¼ç›´æ¥æ˜ å°„åˆ°æ–œç‡ä»¥æè¿°è¿™ä¸ªæ•°æ®é›†ã€‚
- en: note, while this label is used to demonstrate the ability of the autoencoder
    to learn, it is not used to train the model!
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè™½ç„¶è¿™ä¸ªæ ‡ç­¾ç”¨äºå±•ç¤ºè‡ªåŠ¨ç¼–ç å™¨å­¦ä¹ çš„èƒ½åŠ›ï¼Œä½†å®ƒå¹¶æ²¡æœ‰ç”¨äºè®­ç»ƒæ¨¡å‹ï¼
- en: '[PRE3]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![_images/39557c0e268bdf9e355e0769aff4633ec5601e1ef244d68560aa0a4c22ac5f3f.png](../Images/9ce15f05dfa887ce6ee1f02619cb004d.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/9ce15f05dfa887ce6ee1f02619cb004d.png)'
- en: Train the Autoencoder
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨
- en: We have previously defined all the basic functions for our autoencoder so we
    can put together our autoencoder training steps with the following functions,
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹‹å‰å·²ç»å®šä¹‰äº†æˆ‘ä»¬è‡ªåŠ¨ç¼–ç å™¨æ‰€éœ€çš„æ‰€æœ‰åŸºæœ¬å‡½æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡½æ•°æ¥ç»„åˆæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒæ­¥éª¤ï¼Œ
- en: '**initialize_parameters** - initialize the weights and bias'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆå§‹åŒ–å‚æ•°** - åˆå§‹åŒ–æƒé‡å’Œåå·®'
- en: '**forward_pass** - forward pass through our autoencoder to calculate node outputs
    and data reconstruction'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å‰å‘ä¼ é€’** - é€šè¿‡æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨è¿›è¡Œå‰å‘ä¼ é€’ä»¥è®¡ç®—èŠ‚ç‚¹è¾“å‡ºå’Œæ•°æ®é‡å»º'
- en: '**mse_loss_and_derivative** - calculate the L2 loss and associated error derivative
    for each output node from training data and reconstruction'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å‡æ–¹è¯¯å·®æŸå¤±å’Œå¯¼æ•°** - è®¡ç®—æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„ L2 æŸå¤±å’Œç›¸å…³è¯¯å·®å¯¼æ•°ï¼Œè¿™äº›èŠ‚ç‚¹æ¥è‡ªè®­ç»ƒæ•°æ®å’Œé‡å»º'
- en: '**backpropagate** - backpropagate the error derivative through the network
    based on error derivative and node outputs and then average the gradients at each
    weight and bias over the batch'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åå‘ä¼ æ’­** - æ ¹æ®è¯¯å·®å¯¼æ•°å’ŒèŠ‚ç‚¹è¾“å‡ºï¼Œé€šè¿‡ç½‘ç»œåå‘ä¼ æ’­è¯¯å·®å¯¼æ•°ï¼Œç„¶ååœ¨æ¯ä¸ªæƒé‡å’Œåå·®ä¸Šå¹³å‡æ¢¯åº¦'
- en: '**update_parameters** - update the weights and biases with the average gradient
    over the batch and the learning rate'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ›´æ–°å‚æ•°** - ä½¿ç”¨æ‰¹æ¬¡çš„å¹³å‡æ¢¯åº¦å’Œå­¦ä¹ ç‡æ›´æ–°æƒé‡å’Œåå·®'
- en: go to 2 until convergence, in the case a set number of training epochs
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿›è¡Œåˆ° 2 ç›´åˆ°æ”¶æ•›ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ä¸€ä¸ªå›ºå®šçš„è®­ç»ƒå‘¨æœŸæ•°
- en: '[PRE4]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![_images/b4374d79f0f8d85887bb5f6075aa68f024e9e33bc189c7492047de36822bcb2a.png](../Images/3ab1c8fef6098b7c75943615555e53e5.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/3ab1c8fef6098b7c75943615555e53e5.png)'
- en: The average L2 loss vs. training epoch curve looks very good.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: å¹³å‡ L2 æŸå¤±ä¸è®­ç»ƒå‘¨æœŸæ›²çº¿çœ‹èµ·æ¥éå¸¸å¥½ã€‚
- en: we are seeing a pause in learning and then suddenly a fast reduction in training
    error and then slow convergence
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°å­¦ä¹ æš‚åœï¼Œç„¶åçªç„¶è®­ç»ƒè¯¯å·®å¿«é€Ÿå‡å°‘ï¼Œç„¶åç¼“æ…¢æ”¶æ•›
- en: I stopped at 10,000 epochs for efficiency
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ºäº†æ•ˆç‡åœåœ¨äº† 10,000 ä¸ªè®­ç»ƒå‘¨æœŸå¤„
- en: Evaluating Our Autoencoder Network
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„ä¼°æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œ
- en: Letâ€™s look at the output from the latent node at the network bottleneck, i.e.,
    the output of node M6.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ç½‘ç»œç“¶é¢ˆå¤„çš„æ½œåœ¨èŠ‚ç‚¹è¾“å‡ºï¼Œå³èŠ‚ç‚¹ M6 çš„è¾“å‡ºã€‚
- en: notice above that we recorded the M6 output (called node activation) for all
    training epochs and for all data.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬è®°å½•äº†æ‰€æœ‰è®­ç»ƒå‘¨æœŸå’Œæ‰€æœ‰æ•°æ®çš„ M6 è¾“å‡ºï¼ˆç§°ä¸ºèŠ‚ç‚¹æ¿€æ´»ï¼‰ã€‚
- en: letâ€™s look at the final trained network, the last epoch, and loop over all data
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŸ¥çœ‹æœ€ç»ˆè®­ç»ƒå¥½çš„ç½‘ç»œï¼Œæœ€åä¸€ä¸ªè®­ç»ƒå‘¨æœŸï¼Œå¹¶éå†æ‰€æœ‰æ•°æ®
- en: Hereâ€™s a plot of final epoch M6 output vs. the sample slopes,
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æœ€ç»ˆè®­ç»ƒå‘¨æœŸ M6 è¾“å‡ºä¸æ ·æœ¬æ–œç‡çš„å¯¹æ¯”å›¾ï¼Œ
- en: '[PRE5]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![_images/d0ab2f0cf0b3c073fe93da6aa44c8e663feb48b72910cb0e72f2f5ec9416f426.png](../Images/7815f0d074113f20a6f77a446f1f83d2.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/7815f0d074113f20a6f77a446f1f83d2.png)'
- en: As hypothesized, there is a good relationship between the output of our latent
    node at the network bottleneck and the slope of the samples used to generate the
    data!
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚é¢„æœŸï¼Œæˆ‘ä»¬çš„ç½‘ç»œç“¶é¢ˆå¤„çš„æ½œåœ¨èŠ‚ç‚¹è¾“å‡ºä¸ç”¨äºç”Ÿæˆæ•°æ®çš„æ ·æœ¬æ–œç‡ä¹‹é—´å­˜åœ¨è‰¯å¥½çš„å…³ç³»ï¼
- en: our autoencoder has learned 1 value to represent the vectors of 3 values in
    the dataset!
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å·²ç»å­¦ä¹ äº†ä¸€ä¸ªå€¼æ¥è¡¨ç¤ºæ•°æ®é›†ä¸­ 3 ä¸ªå€¼çš„å‘é‡ï¼
- en: this is a great demonstration of information compression, 3:1!
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹ä¿¡æ¯å‹ç¼©çš„ç»ä½³å±•ç¤ºï¼Œ3:1ï¼
- en: Check Training Data Reconstruction
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ£€æŸ¥è®­ç»ƒæ•°æ®é‡å»º
- en: Letâ€™s visualize the reconstructed 1D data, encoded and then decoded with out
    autoencoder network.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯è§†åŒ–ä½¿ç”¨æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œé‡å»ºçš„ 1D æ•°æ®ï¼Œç¼–ç åå†è§£ç ã€‚
- en: for all training data, I include the original data and the reconstructed data,
    i.e., data encoded and decoded by our trained autoencoder
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œæˆ‘åŒ…æ‹¬åŸå§‹æ•°æ®å’Œé‡å»ºæ•°æ®ï¼Œå³ç”±æˆ‘ä»¬è®­ç»ƒå¥½çš„è‡ªåŠ¨ç¼–ç å™¨ç¼–ç å’Œè§£ç çš„æ•°æ®
- en: for each data training sample, I include the sample slope for interest, but
    this label are not used in the in the training, nor with the encoder or decoder
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ•°æ®è®­ç»ƒæ ·æœ¬ï¼Œæˆ‘åŒ…æ‹¬æ ·æœ¬æ–œç‡ä»¥ä¾›å‚è€ƒï¼Œä½†è¿™ä¸ªæ ‡ç­¾åœ¨è®­ç»ƒä¸­ã€ç¼–ç å™¨æˆ–è§£ç å™¨ä¸­éƒ½æ²¡æœ‰ä½¿ç”¨
- en: '[PRE6]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![_images/fe7102239237e5dec48032be77d18524b61a306c2238811815f52c81fcbd5955.png](../Images/7203aaa35d3b4fe06560d8885fa0bc78.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/7203aaa35d3b4fe06560d8885fa0bc78.png)'
- en: The training data reconstruction is quite good!
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®é‡å»ºç›¸å½“ä¸é”™ï¼
- en: our autoencoder has learned to encode and decode the training data
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è‡ªç¼–ç å™¨å·²ç»å­¦ä¼šäº†ç¼–ç å’Œè§£ç è®­ç»ƒæ•°æ®
- en: demonstrating good dimensionality reduction from 3 to 1!
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å±•ç¤ºäº†ä»3ç»´åˆ°1ç»´çš„è‰¯å¥½é™ç»´æ•ˆæœï¼
- en: Check Testing Data Reconstruction
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æµ‹è¯•æ•°æ®é‡å»º
- en: Letâ€™s generate additional data and test the reconstruction.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”Ÿæˆæ›´å¤šæ•°æ®å¹¶æµ‹è¯•é‡å»ºæ•ˆæœã€‚
- en: check the performance of our training autoencoder with data not used to train
    the autoencoder, known as model generalization
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æœªç”¨äºè®­ç»ƒè‡ªç¼–ç å™¨çš„æ•°æ®è¿›è¡Œæ€§èƒ½æ£€æŸ¥ï¼Œè¿™è¢«ç§°ä¸ºæ¨¡å‹æ³›åŒ–
- en: '[PRE7]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![_images/422b0a32f31f3498764ada7f7ec63e50a53a411b5d12e6c718a4288f371d62e8.png](../Images/28e4aff8d55696fd326194c3a79007d1.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/28e4aff8d55696fd326194c3a79007d1.png)'
- en: Apply trained autoencoder to reconstruct test data.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è®­ç»ƒå¥½çš„è‡ªç¼–ç å™¨åº”ç”¨äºé‡å»ºæµ‹è¯•æ•°æ®ã€‚
- en: '[PRE8]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now visualizated the test data reconstructions,
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¯è§†åŒ–æµ‹è¯•æ•°æ®é‡å»ºï¼Œ
- en: '[PRE9]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![_images/6d4114b87e54f6dcb8a4cbefcdd99015b46e78ceca3a5d93daa4ff900d2cdf08.png](../Images/abda6b15ea724a35119dc1c5cf9554e9.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/abda6b15ea724a35119dc1c5cf9554e9.png)'
- en: Our trained autoencoder seems to have generalized well with very good performance
    reconstructing training and also the withheld testing cases.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®­ç»ƒå¥½çš„è‡ªç¼–ç å™¨ä¼¼ä¹æ³›åŒ–å¾—å¾ˆå¥½ï¼Œåœ¨é‡å»ºè®­ç»ƒæ•°æ®å’Œä¿ç•™çš„æµ‹è¯•æ¡ˆä¾‹æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚
- en: For a more complete workflow we would evaluate training and testing error in
    parallel over training epochs to check for model overfit.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å®Œæ•´çš„æµç¨‹ï¼Œæˆ‘ä»¬å°†åœ¨è®­ç»ƒå‘¨æœŸå†…å¹¶è¡Œè¯„ä¼°è®­ç»ƒå’Œæµ‹è¯•é”™è¯¯ï¼Œä»¥æ£€æŸ¥æ¨¡å‹è¿‡æ‹Ÿåˆã€‚
- en: I separated these components for brevity and clarity in the demonstration
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘å°†è¿™äº›ç»„ä»¶åˆ†å¼€ï¼Œä»¥ä¾¿åœ¨æ¼”ç¤ºä¸­æ›´ç®€æ´ã€æ›´æ¸…æ™°
- en: Comments
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„è®º
- en: This was a basic treatment of autoencoder deep learning networks. Much more
    could be done and discussed, I have many more resources. Check out my [shared
    resource inventory](https://michaelpyrcz.com/my-resources) and the YouTube lecture
    links at the start of this chapter with resource links in the videosâ€™ descriptions.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹è‡ªç¼–ç å™¨æ·±åº¦å­¦ä¹ ç½‘ç»œçš„åŸºæœ¬å¤„ç†ã€‚å¯ä»¥åšå’Œè®¨è®ºçš„è¿˜æœ‰å¾ˆå¤šï¼Œæˆ‘æœ‰å¾ˆå¤šæ›´å¤šçš„èµ„æºã€‚æŸ¥çœ‹æˆ‘çš„[èµ„æºå…±äº«æ¸…å•](https://michaelpyrcz.com/my-resources)ä»¥åŠæœ¬ç« å¼€å¤´å¸¦æœ‰èµ„æºé“¾æ¥çš„YouTubeè®²åº§é“¾æ¥ã€‚
- en: I hope this is helpful,
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™æœ‰æ‰€å¸®åŠ©ï¼Œ
- en: '*Michael*'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: About the Author
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºä½œè€…
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡çš„40è‹±äº©æ ¡å›­å†…ï¼Œè¿ˆå…‹å°”Â·çš®å°”å¥‡æ•™æˆçš„åŠå…¬å®¤ã€‚
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”å¥‡æ˜¯å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡[ç§‘å…‹é›·å°”å·¥ç¨‹å­¦é™¢](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)å’Œ[æ°å…‹é€Šåœ°çƒç§‘å­¦å­¦é™¢](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)çš„æ•™æˆï¼Œä»–åœ¨[å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡](https://www.utexas.edu/)ä»äº‹å’Œæ•™æˆåœ°ä¸‹ã€ç©ºé—´æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ã€‚è¿ˆå…‹å°”è¿˜æ˜¯ï¼Œ
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[èƒ½æºåˆ†æ](https://fri.cns.utexas.edu/energy-analytics)æ–°ç”Ÿç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œä»¥åŠå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡è‡ªç„¶ç§‘å­¦å­¦é™¢æœºå™¨å­¦ä¹ å®éªŒå®¤çš„æ ¸å¿ƒæ•™å‘˜ã€‚'
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è®¡ç®—æœºä¸åœ°çƒç§‘å­¦](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)çš„å‰¯ç¼–è¾‘ï¼Œä»¥åŠå›½é™…æ•°å­¦åœ°çƒç§‘å­¦åä¼š[æ•°å­¦åœ°çƒç§‘å­¦](https://link.springer.com/journal/11004/editorial-board)çš„è‘£äº‹ä¼šæˆå‘˜ã€‚'
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”å·²ç»æ’°å†™äº†70å¤šç¯‡[åŒè¡Œè¯„å®¡çš„å‡ºç‰ˆç‰©](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)ï¼Œä¸€ä¸ªç”¨äºç©ºé—´æ•°æ®åˆ†æçš„[PythonåŒ…](https://pypi.org/project/geostatspy/)ï¼Œåˆè‘—äº†ä¸€æœ¬å…³äºç©ºé—´æ•°æ®åˆ†æçš„æ•™ç§‘ä¹¦[åœ°çƒç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)ï¼Œå¹¶æ˜¯ä¸¤æœ¬æ–°å‘å¸ƒçš„ç”µå­ä¹¦çš„ä½œè€…ï¼Œ[Pythonä¸­åº”ç”¨åœ°çƒç»Ÿè®¡å­¦ï¼šGeostatsPyå®è·µæŒ‡å—](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)å’Œ[Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ï¼šä»£ç å®è·µæŒ‡å—](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)ã€‚
- en: All of Michaelâ€™s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michaelâ€™s work and shared educational resources visit his
    Website.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”çš„æ‰€æœ‰å¤§å­¦è®²åº§éƒ½å¯ä»¥åœ¨ä»–çš„[YouTubeé¢‘é“](https://www.youtube.com/@GeostatsGuyLectures)ä¸Šæ‰¾åˆ°ï¼Œé™„æœ‰100å¤šä¸ªPythonäº¤äº’å¼ä»ªè¡¨æ¿å’Œ40å¤šä¸ªå­˜å‚¨åº“ä¸­çš„è¯¦ç»†å·¥ä½œæµç¨‹é“¾æ¥ï¼Œè¿™äº›å­˜å‚¨åº“ä½äºä»–çš„[GitHubè´¦æˆ·](https://github.com/GeostatsGuy)ï¼Œä»¥æ”¯æŒä»»ä½•æ„Ÿå…´è¶£çš„å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«ï¼Œæä¾›å¸¸é’å†…å®¹ã€‚äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„å·¥ä½œå’Œå…±äº«æ•™è‚²èµ„æºï¼Œè¯·è®¿é—®ä»–çš„ç½‘ç«™ã€‚
- en: Want to Work Together?
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›è¿™ä¸ªå†…å®¹å¯¹é‚£äº›æƒ³è¦äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æä»¥åŠæœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«éƒ½æ¬¢è¿å‚ä¸ã€‚
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£åˆä½œã€æ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººæ˜¯çº¦ç¿°Â·ç¦æ–¯ç‰¹æ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶å°†æ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µç›¸ç»“åˆï¼Œä»¥å¼€å‘æ–°çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ï¼Œå¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)è”ç³»æˆ‘ã€‚
- en: Iâ€™m always happy to discuss,
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è®¨è®ºï¼Œ
- en: '*Michael*'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨ï¼Œåšå£«ï¼ŒP.Eng. æ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡Cockrellå·¥ç¨‹å­¦é™¢å’ŒJacksonåœ°çƒç§‘å­¦å­¦é™¢
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šèµ„æºå¯åœ¨ä»¥ä¸‹ä½ç½®è·å–ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°çƒç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [Pythonä¸­åº”ç”¨åœ°çƒç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
- en: Motivation
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ¨æœº
- en: Autoencoders are a very powerful, flexible deep learning approach for compressing
    information,
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨æ˜¯ä¸€ç§éå¸¸å¼ºå¤§ã€çµæ´»çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå‹ç¼©ä¿¡æ¯ï¼Œ
- en: mapping training data to a latent space
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è®­ç»ƒæ•°æ®æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´
- en: dimensionality reduction of high dimensional data to a much lower dimensionality
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†é«˜ç»´æ•°æ®é™ç»´åˆ°æ›´ä½çš„ç»´åº¦
- en: nonlinear, general approach
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éçº¿æ€§ï¼Œé€šç”¨æ–¹æ³•
- en: Autoencoder Architecture
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨æ¶æ„
- en: Hereâ€™s our simple autoencoder,
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æˆ‘ä»¬çš„ç®€å•è‡ªåŠ¨ç¼–ç å™¨ï¼Œ
- en: '![](../Images/ed815fe23f4bd258b278f7aa6f0dd58e.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed815fe23f4bd258b278f7aa6f0dd58e.png)'
- en: Simple demonstration autoencoder.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•æ¼”ç¤ºè‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: This is literally the artificial neural network from the [Artificial Neural
    Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)
    mirrored.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šæ˜¯æ¥è‡ª [äººå·¥ç¥ç»ç½‘ç»œ](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)
    çš„é•œåƒã€‚
- en: I do not discuss the forward pass through the network, if you are unfamiliar
    with this process, for example,
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ä¼šè®¨è®ºé€šè¿‡ç½‘ç»œçš„æ­£å‘ä¼ é€’ï¼Œå¦‚æœä½ ä¸ç†Ÿæ‚‰è¿™ä¸ªè¿‡ç¨‹ï¼Œä¾‹å¦‚ï¼Œ
- en: activation applied to the linear weighting plus bias in the nodes
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨åˆ°èŠ‚ç‚¹çº¿æ€§åŠ æƒå’Œåç½®ä¸Šçš„æ¿€æ´»å‡½æ•°
- en: then please review the artificial neural network chapter.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¯·å›é¡¾äººå·¥ç¥ç»ç½‘ç»œç« èŠ‚ã€‚
- en: I decided to use unique numerical indices for each node for concise notation
    for connection weights, for example \(\lambda_{1,4}\), and biases, for example,
    \(b_4\), \(I\) for input nodes, \(L\) for encoder hidden layer (â€˜leftâ€™), \(M\)
    for latent node (â€˜middleâ€™), \(R\) for decoder hidden layer (â€˜rightâ€™) and finally
    \(O\) for output nodes.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å†³å®šä¸ºæ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨ç‹¬ç‰¹çš„æ•°å€¼ç´¢å¼•ï¼Œä»¥ä¾¿äºç®€æ´åœ°è¡¨ç¤ºè¿æ¥æƒé‡ï¼Œä¾‹å¦‚ \(\lambda_{1,4}\)ï¼Œä»¥åŠåç½®ï¼Œä¾‹å¦‚ \(b_4\)ï¼Œ\(I\) ç”¨äºè¾“å…¥èŠ‚ç‚¹ï¼Œ\(L\)
    ç”¨äºç¼–ç å™¨éšè—å±‚ï¼ˆâ€˜å·¦â€™ï¼‰ï¼Œ\(M\) ç”¨äºæ½œåœ¨èŠ‚ç‚¹ï¼ˆâ€˜ä¸­é—´â€™ï¼‰ï¼Œ\(R\) ç”¨äºè§£ç å™¨éšè—å±‚ï¼ˆâ€˜å³â€™ï¼‰ï¼Œæœ€å \(O\) ç”¨äºè¾“å‡ºèŠ‚ç‚¹ã€‚
- en: The parts of the autoencoder are indicated below,
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ¨ç¼–ç å™¨çš„å„ä¸ªéƒ¨åˆ†å¦‚ä¸‹æ‰€ç¤ºï¼Œ
- en: '![](../Images/652eb880f88b2d046adcc751aa2d62f6.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/652eb880f88b2d046adcc751aa2d62f6.png)'
- en: Simple demonstration autoencoder with parts labeled.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰éƒ¨åˆ†æ ‡ç­¾çš„ç®€å•æ¼”ç¤ºè‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: The signal passed through the autoencoder and notation include,
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ä¼ é€’çš„ä¿¡å·åŠå…¶è¡¨ç¤ºåŒ…æ‹¬ï¼Œ
- en: '**Input** â€“ training samples,'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥** â€“ è®­ç»ƒæ ·æœ¬ï¼Œ'
- en: \[ z \]
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z \]
- en: '**Encoder** â€“ learned compression of the training samples to latent space,'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¼–ç å™¨** â€“ å°†è®­ç»ƒæ ·æœ¬å‹ç¼©åˆ°æ½œåœ¨ç©ºé—´çš„å­¦ä¹ å‹ç¼©ï¼Œ'
- en: \[ x = f_{\theta} (z) \]
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x = f_{\theta} (z) \]
- en: '**Latent Space** â€“ bottleneck summarizes patterns in the training data,'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ½œåœ¨ç©ºé—´** â€“ çª„é¢ˆéƒ¨åˆ†æ€»ç»“äº†è®­ç»ƒæ•°æ®ä¸­çš„æ¨¡å¼ï¼Œ'
- en: \[ ğ‘¥ \]
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘¥ \]
- en: '**Decoder** â€“ learned decompression of the latent space to reconstruction of
    the original training data,'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§£ç å™¨** â€“ å°†æ½œåœ¨ç©ºé—´è§£å‹ç¼©ä¸ºåŸå§‹è®­ç»ƒæ•°æ®çš„é‡å»ºï¼Œ'
- en: \[ \hat{z} = g_{\phi} (x) = g_{\phi} (f_{\theta}(z) ) \]
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{z} = g_{\phi} (x) = g_{\phi} (f_{\theta}(z) ) \]
- en: Reconstruction â€“ attempt to reproduce input,
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å»º â€“ å°è¯•é‡ç°è¾“å…¥ï¼Œ
- en: \[ \hat{z} \sim z \]
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{z} \sim z \]
- en: Training Model Parameters
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ¨¡å‹å‚æ•°
- en: Training an autoencoder proceeds iteratively by these steps.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿­ä»£è¿›è¡Œã€‚
- en: '![](../Images/c3a5bc8956f8ceda05ddf9b582cd141d.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3a5bc8956f8ceda05ddf9b582cd141d.png)'
- en: Training an artificial neural network proceeds iteratively by, 1\. forward pass
    to make a prediction, 2\. calculate the error derivative based on the prediction
    and truth over training data, 3\. backpropagate the error derivative back through
    the artificial neural network to calculate the derivatives of the error over all
    the model weights and biases parameters, 4\. update the model parameters based
    on the derivatives and learning rates, 5\. repeat until convergence.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒäººå·¥ç¥ç»ç½‘ç»œé€šè¿‡ä»¥ä¸‹è¿­ä»£è¿‡ç¨‹è¿›è¡Œï¼Œ1. å‰å‘ä¼ é€’ä»¥è¿›è¡Œé¢„æµ‹ï¼Œ2. æ ¹æ®é¢„æµ‹å’Œè®­ç»ƒæ•°æ®ä¸­çš„çœŸå®å€¼è®¡ç®—è¯¯å·®å¯¼æ•°ï¼Œ3. å°†è¯¯å·®å¯¼æ•°åå‘ä¼ æ’­é€šè¿‡äººå·¥ç¥ç»ç½‘ç»œä»¥è®¡ç®—æ‰€æœ‰æ¨¡å‹æƒé‡å’Œåç½®å‚æ•°çš„è¯¯å·®å¯¼æ•°ï¼Œ4.
    æ ¹æ®å¯¼æ•°å’Œå­¦ä¹ ç‡æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œ5. é‡å¤ç›´åˆ°æ”¶æ•›ã€‚
- en: Hereâ€™s some details on each step,
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æ¯ä¸ªæ­¥éª¤çš„ä¸€äº›ç»†èŠ‚ï¼Œ
- en: '**Initializing the Model Parameters** - initialize all model parameters with
    typically small (near zero) random values. Hereâ€™s a couple common methods,'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆå§‹åŒ–æ¨¡å‹å‚æ•°** - é€šå¸¸ä½¿ç”¨æ¥è¿‘é›¶çš„å°éšæœºå€¼åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹å‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§æ–¹æ³•ï¼Œ'
- en: '**Xavier Weight Initialization** - random realizations from uniform distributions
    specified by \(U[\text{min}, \text{max}]\),'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Xavier æƒé‡åˆå§‹åŒ–** - ç”± \(U[\text{min}, \text{max}]\) æŒ‡å®šçš„å‡åŒ€åˆ†å¸ƒçš„éšæœºå®ç°ï¼Œ'
- en: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}}, \frac{1}{\sqrt{p}} \right]
    (p^\ell) \]
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}}, \frac{1}{\sqrt{p}} \right]
    (p^\ell) \]
- en: where \(F^{-1}_U\) is the inverse of the CDF, \(p\) is the number of inputs,
    and \(p^{\ell}\) is a random cumulative probability value drawn from the uniform
    distribution, \(U[0,1]\).
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(F^{-1}_U\) æ˜¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„é€†ï¼Œ\(p\) æ˜¯è¾“å…¥çš„æ•°é‡ï¼Œè€Œ \(p^{\ell}\) æ˜¯ä»å‡åŒ€åˆ†å¸ƒ \(U[0,1]\) ä¸­æŠ½å–çš„éšæœºç´¯ç§¯æ¦‚ç‡å€¼ã€‚
- en: '**Normalized Xavier Weight Initialization** - random realizations from uniform
    distributions specified by \(U[\text{min}, \text{max}]\),'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½’ä¸€åŒ–Xavieræƒé‡åˆå§‹åŒ–** - ä»ç”± \(U[\text{min}, \text{max}]\) æŒ‡å®šçš„å‡åŒ€åˆ†å¸ƒä¸­éšæœºå®ç°ï¼Œ'
- en: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k}
    \right] (p^\ell) \]
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{i,j} = F_U^{-1} \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k}
    \right] (p^\ell) \]
- en: where \(F^{-1}_U\) is the inverse of the CDF, \(p\) is the number of inputs,
    \(k\) is the number of outputs, and \(p^{\ell}\) is a random cumulative probability
    value drawn from the uniform distribution, \(U[0,1]\).
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(F^{-1}_U\) æ˜¯ CDF çš„é€†ï¼Œ\(p\) æ˜¯è¾“å…¥æ•°é‡ï¼Œ\(k\) æ˜¯è¾“å‡ºæ•°é‡ï¼Œ\(p^{\ell}\) æ˜¯ä»å‡åŒ€åˆ†å¸ƒ \(U[0,1]\)
    ä¸­æŠ½å–çš„éšæœºç´¯ç§¯æ¦‚ç‡å€¼ã€‚
- en: For example, if we return to our first hidden layer node,
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªéšè—å±‚èŠ‚ç‚¹ï¼Œ
- en: '![](../Images/b2f8e46ea497049f4b95c03b8812eea7.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2f8e46ea497049f4b95c03b8812eea7.png)'
- en: First hidden layer node with 3 inputs, and 1 output.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªéšè—å±‚èŠ‚ç‚¹æœ‰ 3 ä¸ªè¾“å…¥ï¼Œ1 ä¸ªè¾“å‡ºã€‚
- en: we have \(p = 3\) and \(k = 1\), and we draw from the uniform distribution,
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ \(p = 3\) å’Œ \(k = 1\)ï¼Œå¹¶ä»å‡åŒ€åˆ†å¸ƒä¸­æŠ½å–ï¼Œ
- en: \[ U \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k} \right] = U \left[ \frac{-1}{\sqrt{3}+1},
    \frac{1}{\sqrt{3}+1} \right] \]
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: \[ U \left[ \frac{-1}{\sqrt{p}+k}, \frac{1}{\sqrt{p}+k} \right] = U \left[ \frac{-1}{\sqrt{3}+1},
    \frac{1}{\sqrt{3}+1} \right] \]
- en: '**Forward Pass** - to pass a training sample, \(z\), to calculate the reconstruction,
    $\hat{z}. Initial predictions will be random for the first iteration, but will
    improve.'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ­£å‘ä¼ æ’­** - å°†è®­ç»ƒæ ·æœ¬ \(z\) ä¼ é€’è¿‡å»ï¼Œè®¡ç®—é‡å»º \(\hat{z}\)ã€‚åˆå§‹é¢„æµ‹åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£å°†æ˜¯éšæœºçš„ï¼Œä½†ä¼šæ”¹è¿›ã€‚'
- en: '**Calculate the Error Derivative** - based on the miss match between the input
    training sample, \(z\), and the reconstruction, \(\hat{z}\).'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡ç®—è¯¯å·®å¯¼æ•°** - åŸºäºè¾“å…¥è®­ç»ƒæ ·æœ¬ \(z\) å’Œé‡å»º \(\hat{z}\) ä¹‹é—´çš„ä¸åŒ¹é…ã€‚'
- en: '**Backpropagate the Error Derivative** - we shift back through the artificial
    neural network to calculate the derivatives of the error over all the model weights
    and biases parameters, to accomplish this we use the chain rule,'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åå‘ä¼ æ’­è¯¯å·®å¯¼æ•°** - æˆ‘ä»¬é€šè¿‡äººå·¥ç¥ç»ç½‘ç»œå›æº¯ä»¥è®¡ç®—æ‰€æœ‰æ¨¡å‹æƒé‡å’Œåå·®å‚æ•°çš„è¯¯å·®å¯¼æ•°ï¼Œä¸ºæ­¤æˆ‘ä»¬ä½¿ç”¨é“¾å¼æ³•åˆ™ï¼Œ'
- en: \[ \frac{\partial}{\partial x} f(g(h(x))) = \frac{\partial f}{\partial g} \cdot
    \frac{\partial g}{\partial h} \cdot \frac{\partial h}{\partial x} \]
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial}{\partial x} f(g(h(x))) = \frac{\partial f}{\partial g} \cdot
    \frac{\partial g}{\partial h} \cdot \frac{\partial h}{\partial x} \]
- en: '**Loop Over Batch and Average the Error Derivatives** - go to step 1 for all
    training data in the batch and then calculate the average of the error derivatives,
    for example,'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**éå†æ‰¹é‡å¹¶å¹³å‡è¯¯å·®å¯¼æ•°** - å¯¹æ‰¹é‡ä¸­çš„æ‰€æœ‰è®­ç»ƒæ•°æ®è¿›è¡Œæ­¥éª¤ 1ï¼Œç„¶åè®¡ç®—è¯¯å·®å¯¼æ•°çš„å¹³å‡å€¼ï¼Œä¾‹å¦‚ï¼Œ'
- en: '**Update the Model Parameters** - based on the derivatives, \frac{\partial
    P}{\partial \lambda_{i,j}} and learning rates, \(\eta\), like this,'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ ¹æ®å¯¼æ•°å’Œå­¦ä¹ ç‡æ›´æ–°æ¨¡å‹å‚æ•°** - å¦‚æ­¤ï¼Œ'
- en: \[ \lambda_{1,4}^{\ell} = \lambda_{1,4}^{\ell-1} - \eta \cdot \frac{1}{B} \sum_{i=1}^{B}
    \frac{\partial \mathcal{L}^{(i)}}{\partial \lambda_{1,4}} \]
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{1,4}^{\ell} = \lambda_{1,4}^{\ell-1} - \eta \cdot \frac{1}{B} \sum_{i=1}^{B}
    \frac{\partial \mathcal{L}^{(i)}}{\partial \lambda_{1,4}} \]
- en: '**Repeat Until Convergence** - return to step 1\. until the error, \(P\), is
    reduced to an acceptable level, i.e., model convergence is the condition to stop
    the iterations'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é‡å¤ç›´åˆ°æ”¶æ•›** - è¿”å›æ­¥éª¤ 1ï¼Œç›´åˆ°è¯¯å·® \(P\) é™ä½åˆ°å¯æ¥å—çš„æ°´å¹³ï¼Œå³æ¨¡å‹æ”¶æ•›æ˜¯åœæ­¢è¿­ä»£çš„æ¡ä»¶'
- en: Autoencoder Loss
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨æŸå¤±
- en: There is a loss and loss gradient at each output-input node pair. The error
    loss function,
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªè¾“å‡º-è¾“å…¥èŠ‚ç‚¹å¯¹ä¸­éƒ½æœ‰ä¸€ä¸ªæŸå¤±å’ŒæŸå¤±æ¢¯åº¦ã€‚è¯¯å·®æŸå¤±å‡½æ•°ï¼Œ
- en: '![](../Images/701ec6c7b420f85dae65e62285e83b13.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/701ec6c7b420f85dae65e62285e83b13.png)'
- en: Autoencoder loss at each output node, the goal is for the output to match the
    input.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„è‡ªç¼–ç å™¨æŸå¤±ï¼Œç›®æ ‡æ˜¯ä½¿è¾“å‡ºä¸è¾“å…¥åŒ¹é…ã€‚
- en: We can generalize as,
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ¦‚æ‹¬ä¸ºï¼Œ
- en: \[ L = \frac{1}{2} \sum_{i=1}^3 \left(O_{i+8} - I_i \right)^2 \]
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L = \frac{1}{2} \sum_{i=1}^3 \left(O_{i+8} - I_i \right)^2 \]
- en: Note, the irregular indexing is due to my choice to use a unique node index
    at each node.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œä¸è§„åˆ™çš„ç´¢å¼•æ˜¯ç”±äºæˆ‘é€‰æ‹©åœ¨æ¯ä¸ªèŠ‚ç‚¹ä½¿ç”¨å”¯ä¸€çš„èŠ‚ç‚¹ç´¢å¼•ã€‚
- en: Error derivative at each node is,
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªèŠ‚ç‚¹çš„è¯¯å·®å¯¼æ•°æ˜¯ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial O_9} = O_9 - I_1 \]\[ \frac{\partial
    \mathcal{L}}{\partial O_{10}} = O_{10} - I_2 \]\[ \frac{\partial \mathcal{L}}{\partial
    O_{11}} = O_{11} - I_3 \]
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial O_9} = O_9 - I_1 \]\[ \frac{\partial
    \mathcal{L}}{\partial O_{10}} = O_{10} - I_2 \]\[ \frac{\partial \mathcal{L}}{\partial
    O_{11}} = O_{11} - I_3 \]
- en: Autoencoder Backpropagation
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªç¼–ç å™¨åå‘ä¼ æ’­
- en: Letâ€™s walk through the back propagation of our autoencoder, letâ€™s start with
    a bias in the output node, \(\frac{\partial \mathcal{L}}{\partial b_{9}}\).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹æˆ‘ä»¬çš„è‡ªç¼–ç å™¨çš„åå‘ä¼ æ’­ï¼Œè®©æˆ‘ä»¬ä»ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„åå·®å¼€å§‹ï¼Œ\(\frac{\partial \mathcal{L}}{\partial b_{9}}\)ã€‚
- en: '![](../Images/8a6b2383ff34c83e1de1a609373cc653.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a6b2383ff34c83e1de1a609373cc653.png)'
- en: Backpropagation to the bias, \(ğ‘_9\), in the hidden decoder node, \(ğ‘‚_9\).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: å‘éšè—è§£ç èŠ‚ç‚¹ \(ğ‘‚_9\) ä¸­çš„åå·® \(ğ‘_9\) åå‘ä¼ æ’­ã€‚
- en: By the chain rule we get,
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_9} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    b_9} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = 1 \cdot 1 \cdot (O_9 - I_1) \]
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_9} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    b_9} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = 1 \cdot 1 \cdot (O_9 - I_1) \]
- en: Letâ€™s explain each part. We start with the output gradient \(\frac{\partial
    \mathcal{L}}{\partial O_9}\) and step across the output node, \(O_9\), since linear
    activation is applied in the output nodes,
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è§£é‡Šæ¯ä¸ªéƒ¨åˆ†ã€‚æˆ‘ä»¬é¦–å…ˆä»è¾“å‡ºæ¢¯åº¦ \(\frac{\partial \mathcal{L}}{\partial O_9}\) å¼€å§‹ï¼Œå¹¶è·¨è¿‡è¾“å‡ºèŠ‚ç‚¹
    \(O_9\)ï¼Œå› ä¸ºè¾“å‡ºèŠ‚ç‚¹åº”ç”¨äº†çº¿æ€§æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
- en: Now we can calculate the derivative of the bias, \(b_9\), with respect to the
    node input,
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥è®¡ç®—åå·® \(b_9\) å…³äºèŠ‚ç‚¹è¾“å…¥çš„å¯¼æ•°ï¼Œ
- en: \[ \frac{\partial 0_{9_{\mathrm{in}}}}{\partial b_9} = \frac{\partial}{\partial
    b_9} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = 1 \]
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial 0_{9_{\mathrm{in}}}}{\partial b_9} = \frac{\partial}{\partial
    b_9} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = 1 \]
- en: Now we can proceed to the connection weight, ğœ†_7,9.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°è¿æ¥æƒé‡ \(ğœ†_7,9\)ã€‚
- en: '![](../Images/80eaca0166d0cf02f98e140c090fca18.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80eaca0166d0cf02f98e140c090fca18.png)'
- en: Backpropagation to the connection weight, \(\lambda_{7,9}\).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: å‘è¿æ¥æƒé‡ \(\lambda_{7,9}\) åå‘ä¼ æ’­ã€‚
- en: By the chain rule we get,
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{7,9}} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    \lambda_{7,9}} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = R_7 \cdot 1 \cdot (O_9 - I_1) \]
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{7,9}} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    \lambda_{7,9}} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} = R_7 \cdot 1 \cdot (O_9 - I_1) \]
- en: Once again, since linear activation is applied in the output nodes,
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œç”±äºè¾“å‡ºèŠ‚ç‚¹åº”ç”¨äº†çº¿æ€§æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_9}{\partial O_{9_{in}}} = 1.0 \]
- en: and \(\frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}}\) is simply the
    output from \(ğ‘…_7\),
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}}\) ç®€å•åœ°æ˜¯ \(ğ‘…_7\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}} = \frac{\partial}{\partial
    \lambda_{7,9}} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = R_7
    \]
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O^{\text{in}}_9}{\partial \lambda_{7,9}} = \frac{\partial}{\partial
    \lambda_{7,9}} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = R_7
    \]
- en: Letâ€™s continue past \(\partial \lambda_{7,9}\) to the output from our decoder
    hidden node, \(ğ‘…_7\)
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­åˆ° \(\partial \lambda_{7,9}\) å¹¶åˆ°è¾¾è§£ç éšè—èŠ‚ç‚¹ \(ğ‘…_7\) çš„è¾“å‡º
- en: '![](../Images/1c85ce96ca6f0999b7bc167c32d65b89.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c85ce96ca6f0999b7bc167c32d65b89.png)'
- en: Backpropagation to the output of the decoder hidden layer node \(R_7\).
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: å‘è§£ç éšè—å±‚èŠ‚ç‚¹ \(R_7\) çš„è¾“å‡ºåå‘ä¼ æ’­ã€‚
- en: By the chain rule we get,
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} + \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7}
    \cdot \frac{\partial O_{10}}{\partial O_{10_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{10}} + \frac{\partial O_{11_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_{11}}{\partial O_{11_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{11}} \]
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \frac{\partial O_{9_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_9} + \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7}
    \cdot \frac{\partial O_{10}}{\partial O_{10_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{10}} + \frac{\partial O_{11_{\mathrm{in}}}}{\partial
    R_7} \cdot \frac{\partial O_{11}}{\partial O_{11_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial O_{11}} \]
- en: that we can evaluate as,
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†å…¶è¯„ä¼°ä¸ºï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \lambda_{7,9} \cdot 1 \cdot (O_9
    - I_1) + \lambda_{7,10} \cdot 1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1
    \cdot (O_{11} - I_3) \]
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial R_7} = \lambda_{7,9} \cdot 1 \cdot (O_9
    - I_1) + \lambda_{7,10} \cdot 1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1
    \cdot (O_{11} - I_3) \]
- en: We add the derivatives from each connection. Once again, since linear activation
    at \(ğ‘‚_{9}\), \(ğ‘‚_{10}\), and \(ğ‘‚_{11}\),
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¯ä¸ªè¿æ¥çš„å¯¼æ•°ç›¸åŠ ã€‚å†æ¬¡å¼ºè°ƒï¼Œç”±äº \(ğ‘‚_{9}\)ï¼Œ\(ğ‘‚_{10}\) å’Œ \(ğ‘‚_{11}\) å¤„çš„çº¿æ€§æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} = 1, \quad \frac{\partial
    O_{10}}{\partial O_{10_{\mathrm{in}}}} = 1, \quad \frac{\partial O_{11}}{\partial
    O_{11_{\mathrm{in}}}} = 1 \]
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_9}{\partial O_{9_{\mathrm{in}}}} = 1, \quad \frac{\partial
    O_{10}}{\partial O_{10_{\mathrm{in}}}} = 1, \quad \frac{\partial O_{11}}{\partial
    O_{11_{\mathrm{in}}}} = 1 \]
- en: Also, along the connection, the derivative is simply the weight,
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ²¿ç€è¿æ¥ï¼Œå¯¼æ•°å°±æ˜¯æƒé‡ï¼Œ
- en: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,9}, \quad
    \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,10}, \quad \frac{\partial
    O_{11_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,11} \]
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,9}, \quad
    \frac{\partial O_{10_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,10}, \quad \frac{\partial
    O_{11_{\mathrm{in}}}}{\partial R_7} = \lambda_{7,11} \]
- en: for example we can demonstrate this for \(\frac{\partial O_{9_{\mathrm{in}}}}{\partial
    R_7}\) as,
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ¼”ç¤º \(\frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7}\) çš„å¯¼æ•°ï¼Œ
- en: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \frac{\partial}{\partial
    R_7} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = \lambda_{7,9}
    \]
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial O_{9_{\mathrm{in}}}}{\partial R_7} = \frac{\partial}{\partial
    R_7} \left( \lambda_{7,9} R_7 + \lambda_{8,9} R_8 + b_9 \right) = \lambda_{7,9}
    \]
- en: Letâ€™s continue from the output from our decoder hidden layer node, \(ğ‘…_7\),
    to calculate the derivative of the bias in the node, \(b_7\).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æˆ‘ä»¬è§£ç å™¨éšè—å±‚èŠ‚ç‚¹ \(ğ‘…_7\) çš„è¾“å‡ºç»§ç»­è®¡ç®—èŠ‚ç‚¹åç½® \(b_7\) çš„å¯¼æ•°ã€‚
- en: '![](../Images/604e4fcf99d1c41dd899458f80a67179.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/604e4fcf99d1c41dd899458f80a67179.png)'
- en: Backpropagation to the bias, $b_7$, in the hidden decoder node, $R_7$.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°éšè—è§£ç èŠ‚ç‚¹ \(R_7\) ä¸­çš„åç½® \(b_7\)ã€‚
- en: From the chain rule we get,
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_7} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    b_7} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_7} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    b_7} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
- en: Since sigmoid activation at \(R_7\), to move across the node,
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåœ¨ \(R_7\) å¤„åº”ç”¨äº† sigmoid æ¿€æ´»å‡½æ•°ï¼Œä¸ºäº†è·¨è¿‡èŠ‚ç‚¹ï¼Œ
- en: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = \sigma' (R_7) = R_7 (1
    - R_7) \]
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = \sigma' (R_7) = R_7 (1
    - R_7) \]
- en: and for the partial derivative of the node input given the bias,
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç»™å®šåç½®çš„èŠ‚ç‚¹è¾“å…¥çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{R_{7_{\mathrm{in}}}}{\partial b_7} = \frac{\partial}{\partial b_7}
    \left( \lambda_{6,7} M_6 + b_7 \right) = 1 \]
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{R_{7_{\mathrm{in}}}}{\partial b_7} = \frac{\partial}{\partial b_7}
    \left( \lambda_{6,7} M_6 + b_7 \right) = 1 \]
- en: So now we have,
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_7} = 1 \cdot R_7 (1 - R_7) \cdot \overbrace{
    \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot 1 \cdot
    (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    L}{\partial R_7}} \]
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_7} = 1 \cdot R_7 (1 - R_7) \cdot \overbrace{
    \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot 1 \cdot
    (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    L}{\partial R_7}} \]
- en: Now we can proceed to the connection weight, \(\lambda_{6,7}\).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°è¿æ¥æƒé‡ \(\lambda_{6,7}\)ã€‚
- en: '![](../Images/1559af01deb817828f382cd89480ff41.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1559af01deb817828f382cd89480ff41.png)'
- en: Backpropagation to the connection weight, \(\lambda_{6,7}\).
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°è¿æ¥æƒé‡ \(\lambda_{6,7}\)ã€‚
- en: By the chain rule we get,
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{6,7}} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    \lambda_{6,7}} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{6,7}} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    \lambda_{6,7}} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} \]
- en: Once again, since sigmoid activation is applied in the hidden layer nodes,
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œç”±äºåœ¨éšè—å±‚èŠ‚ç‚¹ä¸­åº”ç”¨äº† sigmoid æ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial R_7}{\partial R_{7_{in}}} = 1.0 \]
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_7}{\partial R_{7_{in}}} = 1.0 \]
- en: and \(\frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}}\) is simply
    the output from \(M_6\),
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}}\) ç®€å•åœ°æ˜¯ \(M_6\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}} = \frac{\partial}{\partial
    \lambda_{6,7}} \left( \lambda_{6,7} M_6 + b_6 \right) = M_6 \]
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_{7_{\mathrm{in}}}}{\partial \lambda_{6,7}} = \frac{\partial}{\partial
    \lambda_{6,7}} \left( \lambda_{6,7} M_6 + b_6 \right) = M_6 \]
- en: So now we have,
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_7} = M_6 \cdot R_7 (1 - R_7) \cdot
    \overbrace{ \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot
    1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    \mathcal{L}}{\partial R_7}} \]
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_7} = M_6 \cdot R_7 (1 - R_7) \cdot
    \overbrace{ \left[ \lambda_{7,9} \cdot 1 \cdot (O_9 - I_1) + \lambda_{7,10} \cdot
    1 \cdot (O_{10} - I_2) + \lambda_{7,11} \cdot 1 \cdot (O_{11} - I_3) \right] }^{\frac{\partial
    \mathcal{L}}{\partial R_7}} \]
- en: Letâ€™s get continue to the output from our latent node, ğ‘€_6
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­ä»æˆ‘ä»¬çš„æ½œåœ¨èŠ‚ç‚¹ \(M_6\) çš„è¾“å‡ºå¼€å§‹ã€‚
- en: '![](../Images/f4cc7dbc1493a36ab0eb828c1422d1f2.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4cc7dbc1493a36ab0eb828c1422d1f2.png)'
- en: Backpropagation to the output of the latent node, \(M_6\).
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: å‘æ½œåœ¨èŠ‚ç‚¹è¾“å‡º \(M_6\) åå‘ä¼ æ’­ã€‚
- en: By the chain rule we get,
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6}
    \cdot \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \]
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} \cdot \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6}
    \cdot \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \]
- en: That we can resolve as,
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†å…¶è§£æä¸ºï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \lambda_{6,7} \cdot R_7 (1 -
    R_7) \cdot \frac{\partial \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8
    (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial R_8} \]
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial M_6} = \lambda_{6,7} \cdot R_7 (1 -
    R_7) \cdot \frac{\partial \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8
    (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial R_8} \]
- en: Once again, since sigmoid activation,
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œç”±äº sigmoid æ¿€æ´»ï¼Œ
- en: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = R_7 (1 - R_7), \quad
    \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} = R_8 (1 - R_8) \]
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial R_7}{\partial R_{7_{\mathrm{in}}}} = R_7 (1 - R_7), \quad
    \frac{\partial R_8}{\partial R_{8_{\mathrm{in}}}} = R_8 (1 - R_8) \]
- en: and along the connections,
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶æ²¿ç€è¿æ¥ï¼Œ
- en: \[\begin{split} \begin{aligned} \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} &= \frac{\partial}{\partial M_6} \left( \lambda_{6,7} M_6 + b_7 \right) =
    \lambda_{6,7} \\ \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6} &= \frac{\partial}{\partial
    M_6} \left( \lambda_{6,8} M_6 + b_8 \right) = \lambda_{6,8} \end{aligned} \end{split}\]
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{aligned} \frac{\partial R_{7_{\mathrm{in}}}}{\partial
    M_6} &= \frac{\partial}{\partial M_6} \left( \lambda_{6,7} M_6 + b_7 \right) =
    \lambda_{6,7} \\ \frac{\partial R_{8_{\mathrm{in}}}}{\partial M_6} &= \frac{\partial}{\partial
    M_6} \left( \lambda_{6,8} M_6 + b_8 \right) = \lambda_{6,8} \end{aligned} \end{split}\]
- en: Letâ€™s continue from the output from our latent node, \(M_6\), to calculate the
    derivative of the bias in the node, \(b_6\).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æ½œåœ¨èŠ‚ç‚¹ \(M_6\) çš„è¾“å‡ºç»§ç»­è®¡ç®—èŠ‚ç‚¹ \(b_6\) çš„åå¯¼æ•°ã€‚
- en: '![](../Images/90618005b205c6c5ceb09965c36cf2e1.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90618005b205c6c5ceb09965c36cf2e1.png)'
- en: Backpropagation to the bias, $b_6$, in the latent node, $M_6$. Note image shifted
    to make room.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: å‘æ½œåœ¨èŠ‚ç‚¹ \(M_6\) ä¸­çš„åç½® \(b_6\) åå‘ä¼ æ’­ã€‚æ³¨æ„å›¾åƒå·²ç§»åŠ¨ä»¥è…¾å‡ºç©ºé—´ã€‚
- en: From the chain rule we get,
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_6} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    b_6} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_6} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    b_6} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
- en: Since sigmoid activation at \(M_6\), to move across the node,
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº \(M_6\) å¤„çš„ sigmoid æ¿€æ´»ï¼Œè¦ç©¿è¿‡èŠ‚ç‚¹ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
- en: and for the partial derivative of the node input given the bias,
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠå¯¹äºç»™å®šåç½®çš„èŠ‚ç‚¹è¾“å…¥çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
- en: So now we have,
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
- en: Now we can proceed to the connection weight, \(\lambda_{4,6}\).
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{4,6}\)ã€‚
- en: '![](../Images/f5770d05672cfe3c14c6973f2775d2de.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5770d05672cfe3c14c6973f2775d2de.png)'
- en: Backpropagation to the connection weight, \(\lambda_{4,6}\).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: å‘è¿æ¥æƒé‡åå‘ä¼ æ’­ï¼Œ\(\lambda_{4,6}\)ã€‚
- en: By the chain rule we get,
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    \lambda_{4,6}} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    \lambda_{4,6}} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
- en: Once again, since sigmoid activation is applied in the hidden layer nodes,
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œç”±äºåœ¨éšè—å±‚èŠ‚ç‚¹ä¸­åº”ç”¨äº†Sigmoidæ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{in}}} = M_6 \cdot (1 - M_6) \]
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{in}}} = M_6 \cdot (1 - M_6) \]
- en: and \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}}\) is simply
    the output from \(L_4\),
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}}\) ç®€å•åœ°æ˜¯ \(L_4\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}} = \frac{\partial}{\partial
    \lambda_{4,6}} \left( \lambda_{4,6} L_4 + \lambda_{5,6} L_5 + b_6 \right) = L_4
    \]
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial \lambda_{4,6}} = \frac{\partial}{\partial
    \lambda_{4,6}} \left( \lambda_{4,6} L_4 + \lambda_{5,6} L_5 + b_6 \right) = L_4
    \]
- en: So now we have,
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = L_4 \cdot M_6 (1 -
    M_6) \cdot \overbrace{ \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial
    \mathcal{L}}{\partial R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}}
    \]
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{4,6}} = L_4 \cdot M_6 (1 -
    M_6) \cdot \overbrace{ \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial
    \mathcal{L}}{\partial R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial
    \mathcal{L}}{\partial R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}}
    \]
- en: Now we can proceed to the output of our encoder hidden layer node, \(L_4\).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°ç¼–ç å™¨éšè—å±‚èŠ‚ç‚¹çš„è¾“å‡º \(L_4\)ã€‚
- en: '![](../Images/1e5148ec01b8276d13a3ac564a201ab3.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e5148ec01b8276d13a3ac564a201ab3.png)'
- en: Backpropagation to the output of the encoder hidden node, \(ğ¿_4\).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: å‘åä¼ æ’­åˆ°ç¼–ç å™¨éšè—èŠ‚ç‚¹çš„è¾“å‡º \(ğ¿_4\)ã€‚
- en: By the chain rule we get this and evaluate it as,
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°è¿™ä¸ªç»“æœå¹¶è¯„ä¼°å®ƒï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial L_4} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    L_4} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} = \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial L_4} = \frac{\partial M_{6_{\mathrm{in}}}}{\partial
    L_4} \cdot \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} = \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial
    \mathcal{L}}{\partial M_6} \]
- en: Once again, since sigmoid activation is applied in the latent node,
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œç”±äºåœ¨æ½œåœ¨èŠ‚ç‚¹ä¸­åº”ç”¨äº†Sigmoidæ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = M_6 (1 - M_6) \]
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = M_6 (1 - M_6) \]
- en: and \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4}\) is simply the weight,
    \(\lambda_{4,6}\),
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4}\) ç®€å•åœ°æ˜¯æƒé‡ï¼Œ\(\lambda_{4,6}\)ï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4} = \frac{\partial}{\partial
    L_4} \left( \lambda_{4,6} L_4 + b_6 \right) = \lambda_{4,6} \]
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial L_4} = \frac{\partial}{\partial
    L_4} \left( \lambda_{4,6} L_4 + b_6 \right) = \lambda_{4,6} \]
- en: Letâ€™s continue from the output from our encoder hidden layer node, \(L_4\),
    to calculate the derivative of the bias in the node, \(b_4\).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ç¼–ç å™¨éšè—å±‚èŠ‚ç‚¹çš„è¾“å‡º \(L_4\) å¼€å§‹ï¼Œè®¡ç®—èŠ‚ç‚¹åç½® \(b_4\) çš„å¯¼æ•°ã€‚
- en: '![](../Images/cf8f925e7a89e3d992b323edfd45034e.png)'
  id: totrans-449
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf8f925e7a89e3d992b323edfd45034e.png)'
- en: Backpropagation to the bias, $b_4$, in the encoder hidden layer node, $L_4$.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: å‘åä¼ æ’­åˆ°ç¼–ç å™¨éšè—å±‚èŠ‚ç‚¹ \(L_4\) ä¸­çš„åç½® \(b_4\)ã€‚
- en: From the chain rule we get,
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™æˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_4} = \frac{\partial L_{4_{\mathrm{in}}}}{\partial
    b_4} \cdot \frac{\partial L_4}{\partial L_{4_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} = 1 \cdot L_4 (1 - L_4) \cdot \frac{\partial \mathcal{L}}{\partial
    L_4} \]
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_4} = \frac{\partial L_{4_{\mathrm{in}}}}{\partial
    b_4} \cdot \frac{\partial L_4}{\partial L_{4_{\mathrm{in}}}} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} = 1 \cdot L_4 (1 - L_4) \cdot \frac{\partial \mathcal{L}}{\partial
    L_4} \]
- en: Since sigmoid activation at \(M_6\), to move across the node,
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº \(M_6\) å¤„çš„Sigmoidæ¿€æ´»å‡½æ•°ï¼Œè¦ç©¿è¿‡èŠ‚ç‚¹ï¼Œ
- en: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_6}{\partial M_{6_{\mathrm{in}}}} = \sigma' (M_6) = M_6 \cdot
    (1 - M_6) \]
- en: and for the partial derivative of the node input given the bias,
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠå¯¹äºç»™å®šåç½®çš„èŠ‚ç‚¹è¾“å…¥çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial M_{6_{\mathrm{in}}}}{\partial b_6} = \frac{\partial}{\partial
    b_6} \left( \lambda_{4,6} L_4 + b_6 \right) = 1 \]
- en: So now we have,
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial b_6} = 1 \cdot M_6 (1 - M_6) \cdot \overbrace{
    \left[ \lambda_{6,7} \cdot R_7 (1 - R_7) \cdot \frac{\partial \mathcal{L}}{\partial
    R_7} + \lambda_{6,8} \cdot R_8 (1 - R_8) \cdot \frac{\partial \mathcal{L}}{\partial
    R_8} \right] }^{\frac{\partial \mathcal{L}}{\partial M_6}} \]
- en: And, finally we proceed to the connection weight, \(\lambda_{1,4}\).
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ç»§ç»­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{1,4}\)ã€‚
- en: '![](../Images/3623ed192b17eb44b8f6f8c59b1dc0d0.png)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/3623ed192b17eb44b8f6f8c59b1dc0d0.png)'
- en: Backpropagation to the connection weight, \(\lambda_{1,4}\).
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­åˆ°è¿æ¥æƒé‡ï¼Œ\(\lambda_{1,4}\)ã€‚
- en: By the chain rule we get,
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼Œ
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{1,4}} = \frac{\partial L^{\text{in}}_4}{\partial
    \lambda_{1,4}} \cdot \frac{\partial L_4}{\partial L^{\text{in}}_4} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} \]
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{1,4}} = \frac{\partial L^{\text{in}}_4}{\partial
    \lambda_{1,4}} \cdot \frac{\partial L_4}{\partial L^{\text{in}}_4} \cdot \frac{\partial
    \mathcal{L}}{\partial L_4} \]
- en: Once again, since sigmoid activation is applied in the hidden layer nodes,
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œç”±äºåœ¨éšè—å±‚èŠ‚ç‚¹ä¸­åº”ç”¨äº† sigmoid æ¿€æ´»å‡½æ•°ï¼Œ
- en: \[ \frac{\partial L_4}{\partial L_{4_{in}}} = L_4 \cdot (1 - L_4) \]
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial L_4}{\partial L_{4_{in}}} = L_4 \cdot (1 - L_4) \]
- en: and \(\frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}}\) is simply the
    output from \(I_1\),
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” \(\frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}}\) ç®€å•åœ°æ˜¯ \(I_1\)
    çš„è¾“å‡ºï¼Œ
- en: \[ \frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}} = \frac{\partial}{\partial
    \lambda_{1,4}} \left( \lambda_{1,4} I_1 + \lambda_{2,4} I_2 + \lambda_{3,4} I_3
    + b_4 \right) = I_1 \]
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial L^{\text{in}}_4}{\partial \lambda_{1,4}} = \frac{\partial}{\partial
    \lambda_{1,4}} \left( \lambda_{1,4} I_1 + \lambda_{2,4} I_2 + \lambda_{3,4} I_3
    + b_4 \right) = I_1 \]
- en: So now we have,
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ï¼Œ
- en: \[ \frac{\partial L}{\partial \lambda_{1,4}} = I_1 \cdot L_4 (1 - L_4) \cdot
    \underbrace{\left[ \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial L}{\partial
    M_6} \right]}_{\frac{\partial L}{\partial L_4}} \]
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial L}{\partial \lambda_{1,4}} = I_1 \cdot L_4 (1 - L_4) \cdot
    \underbrace{\left[ \lambda_{4,6} \cdot M_6 (1 - M_6) \cdot \frac{\partial L}{\partial
    M_6} \right]}_{\frac{\partial L}{\partial L_4}} \]
- en: Now we will build out this autoencoder from the ground up with only the NumPy
    python package for arrays and Python built-in data structure dictionaries.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨ NumPy Python åŒ…å’Œ Python å†…ç½®æ•°æ®ç»“æ„å­—å…¸ä»å¤´å¼€å§‹æ„å»ºè¿™ä¸ªè‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: Import Required Packages
  id: totrans-471
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¼å…¥æ‰€éœ€çš„åŒ…
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›æ ‡å‡†åŒ…ã€‚è¿™äº›åº”è¯¥å·²ç»ä¸ Anaconda 3 ä¸€èµ·å®‰è£…ã€‚
- en: '[PRE10]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing â€˜python -m pip install [package-name]â€™. More assistance is available
    with the respective package docs.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨é‡åˆ°åŒ…å¯¼å…¥é”™è¯¯ï¼Œæ‚¨å¯èƒ½å¿…é¡»é¦–å…ˆå®‰è£…è¿™äº›åŒ…ä¸­çš„ä¸€äº›ã€‚è¿™é€šå¸¸å¯ä»¥é€šè¿‡åœ¨ Windows ä¸Šæ‰“å¼€å‘½ä»¤çª—å£å¹¶è¾“å…¥â€˜python -m pip install
    [package-name]â€™æ¥å®Œæˆã€‚æœ‰å…³ç›¸åº”åŒ…çš„æ–‡æ¡£ä¸­æä¾›äº†æ›´å¤šå¸®åŠ©ã€‚
- en: Declare Functions
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å£°æ˜å‡½æ•°
- en: Hereâ€™s the functions to train and visualize our autoencoder.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯è®­ç»ƒå’Œå¯è§†åŒ–æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨çš„å‡½æ•°ã€‚
- en: '[PRE11]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Visualize the Autoencoder Network
  id: totrans-478
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œ
- en: Here we specify the autoencoder labels, positions, connections and colors and
    then plot the autoencoder.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‡å®šè‡ªåŠ¨ç¼–ç å™¨çš„æ ‡ç­¾ã€ä½ç½®ã€è¿æ¥å’Œé¢œè‰²ï¼Œç„¶åç»˜åˆ¶è‡ªåŠ¨ç¼–ç å™¨ã€‚
- en: while this code is general, the actual autoencoder codes are not generalized
    to work with other architectures, for example changing the depth or width of the
    network
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è™½ç„¶æ­¤ä»£ç æ˜¯é€šç”¨çš„ï¼Œä½†å®é™…çš„è‡ªåŠ¨ç¼–ç å™¨ä»£ç å¹¶æ²¡æœ‰æ¨å¹¿åˆ°ä¸å…¶ä»–æ¶æ„ä¸€èµ·å·¥ä½œï¼Œä¾‹å¦‚æ”¹å˜ç½‘ç»œçš„æ·±åº¦æˆ–å®½åº¦
- en: change the display parameters but do not the autoencoder architecture
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ”¹å˜æ˜¾ç¤ºå‚æ•°ï¼Œä½†ä¸æ”¹å˜è‡ªåŠ¨ç¼–ç å™¨æ¶æ„
- en: '[PRE12]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![_images/333249f6a43bbad84e15a2423db3b9cc8670650c55532adfe9fea6ac7c992872.png](../Images/330a264f2ed0fefaff128fb34a83b1e7.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/333249f6a43bbad84e15a2423db3b9cc8670650c55532adfe9fea6ac7c992872.png)'
- en: Make an Interesting Synthetic Dataset
  id: totrans-484
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ¶ä½œä¸€ä¸ªæœ‰è¶£çš„åˆæˆæ•°æ®é›†
- en: Generate a stochastic dataset of 1D length of 3 vectors with a pattern that
    can be summarized by our autoencoder.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ä¸ªå…·æœ‰ 3 ä¸ªå‘é‡ 1D é•¿åº¦çš„éšæœºæ•°æ®é›†ï¼Œè¯¥æ¨¡å¼å¯ä»¥é€šè¿‡æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨æ€»ç»“ã€‚
- en: if we generate random 1D vectors of length 3 our autoencoder would not be able
    to summarize, i.e., it is not possible to compress the information from the original
    3 values
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç”Ÿæˆé•¿åº¦ä¸º 3 çš„éšæœº 1D å‘é‡ï¼Œæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å°†æ— æ³•æ€»ç»“ï¼Œå³ï¼Œæ— æ³•ä»åŸå§‹ 3 ä¸ªå€¼ä¸­å‹ç¼©ä¿¡æ¯
- en: we must include a pattern that can be learned by the autoencoder to observe
    dimensionality reduction through the latent node with good data reconstruction
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»åŒ…æ‹¬ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨å¯ä»¥å­¦ä¹ çš„æ¨¡å¼ï¼Œé€šè¿‡æ½œåœ¨èŠ‚ç‚¹è§‚å¯Ÿé€šè¿‡è‰¯å¥½çš„æ•°æ®é‡å»ºè¿›è¡Œé™ç»´
- en: To do this, I have calculate dataset as a hybrid model, linear + small random
    residual. The data generation steps include,
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘å·²ç»å°†æ•°æ®é›†è®¡ç®—ä¸ºä¸€ä¸ªæ··åˆæ¨¡å‹ï¼Œçº¿æ€§åŠ å°éšæœºæ®‹å·®ã€‚æ•°æ®ç”Ÿæˆæ­¥éª¤åŒ…æ‹¬ï¼Œ
- en: draw a random slope \(\sim N\left[-2.0, 2.0 \right]\)
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ä¸ªéšæœºæ–œç‡ \(\sim N\left[-2.0, 2.0 \right]\)
- en: calculate 3 points at locations \(\left[-1, 0, 1 \right]\), \(f(\left[-1, 0,
    1 \right])\)
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ä½ç½® \(\left[-1, 0, 1 \right]\) ä¸Šè®¡ç®— 3 ä¸ªç‚¹ï¼Œ\(f(\left[-1, 0, 1 \right])\)
- en: add random, independent residual to each location, \(f(\left[-1, 0, 1 \right])
    + N\left[0.0,\sigma \right]\), where sigma is the residual standard deviation
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¯ä¸ªä½ç½®æ·»åŠ éšæœºçš„ã€ç‹¬ç«‹çš„æ®‹å·®ï¼Œ\(f(\left[-1, 0, 1 \right]) + N\left[0.0,\sigma \right]\)ï¼Œå…¶ä¸­sigmaæ˜¯æ®‹å·®æ ‡å‡†å·®
- en: Note, the slope is retained as a label that will be compared to the latent node,
    \(M_6\) output to check, what has our autoencoder has learned?
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæ–œç‡è¢«ä¿ç•™ä½œä¸ºæ ‡ç­¾ï¼Œå°†ç”¨äºä¸æ½œåœ¨èŠ‚ç‚¹\(M_6\)è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ£€æŸ¥æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ
- en: our hypothesis is that the autoencoder will learn a value that directly maps
    to slope to describe this dataset.
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å‡è®¾æ˜¯è‡ªåŠ¨ç¼–ç å™¨å°†å­¦ä¼šä¸€ä¸ªå€¼ï¼Œè¯¥å€¼ç›´æ¥æ˜ å°„åˆ°æ–œç‡ä»¥æè¿°è¿™ä¸ªæ•°æ®é›†ã€‚
- en: note, while this label is used to demonstrate the ability of the autoencoder
    to learn, it is not used to train the model!
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè™½ç„¶è¿™ä¸ªæ ‡ç­¾ç”¨äºå±•ç¤ºè‡ªåŠ¨ç¼–ç å™¨å­¦ä¹ çš„èƒ½åŠ›ï¼Œä½†å®ƒå¹¶æ²¡æœ‰ç”¨äºè®­ç»ƒæ¨¡å‹ï¼
- en: '[PRE13]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![_images/39557c0e268bdf9e355e0769aff4633ec5601e1ef244d68560aa0a4c22ac5f3f.png](../Images/9ce15f05dfa887ce6ee1f02619cb004d.png)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/9ce15f05dfa887ce6ee1f02619cb004d.png)'
- en: Train the Autoencoder
  id: totrans-497
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨
- en: We have previously defined all the basic functions for our autoencoder so we
    can put together our autoencoder training steps with the following functions,
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»ä¸ºæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å®šä¹‰äº†æ‰€æœ‰åŸºæœ¬å‡½æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡½æ•°ç»„åˆæˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒæ­¥éª¤ï¼Œ
- en: '**initialize_parameters** - initialize the weights and bias'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**initialize_parameters** - åˆå§‹åŒ–æƒé‡å’Œåç½®'
- en: '**forward_pass** - forward pass through our autoencoder to calculate node outputs
    and data reconstruction'
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**forward_pass** - é€šè¿‡æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨è¿›è¡Œå‰å‘ä¼ é€’ä»¥è®¡ç®—èŠ‚ç‚¹è¾“å‡ºå’Œæ•°æ®é‡å»º'
- en: '**mse_loss_and_derivative** - calculate the L2 loss and associated error derivative
    for each output node from training data and reconstruction'
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**mse_loss_and_derivative** - è®¡ç®—è®­ç»ƒæ•°æ®å’Œé‡å»ºæ•°æ®ä¸­æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„L2æŸå¤±å’Œç›¸å…³è¯¯å·®å¯¼æ•°'
- en: '**backpropagate** - backpropagate the error derivative through the network
    based on error derivative and node outputs and then average the gradients at each
    weight and bias over the batch'
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**backpropagate** - æ ¹æ®è¯¯å·®å¯¼æ•°å’ŒèŠ‚ç‚¹è¾“å‡ºé€šè¿‡ç½‘ç»œåå‘ä¼ æ’­è¯¯å·®å¯¼æ•°ï¼Œç„¶ååœ¨æ¯ä¸ªæƒé‡å’Œåç½®ä¸Šå¹³å‡æ‰¹æ¬¡çš„æ¢¯åº¦'
- en: '**update_parameters** - update the weights and biases with the average gradient
    over the batch and the learning rate'
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**update_parameters** - ä½¿ç”¨æ‰¹æ¬¡çš„å¹³å‡æ¢¯åº¦å’Œå­¦ä¹ ç‡æ›´æ–°æƒé‡å’Œåç½®'
- en: go to 2 until convergence, in the case a set number of training epochs
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿›è¡Œåˆ°æ”¶æ•›ï¼Œåœ¨è®­ç»ƒepochè¾¾åˆ°ä¸€å®šæ•°é‡æ—¶
- en: '[PRE14]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![_images/b4374d79f0f8d85887bb5f6075aa68f024e9e33bc189c7492047de36822bcb2a.png](../Images/3ab1c8fef6098b7c75943615555e53e5.png)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/3ab1c8fef6098b7c75943615555e53e5.png)'
- en: The average L2 loss vs. training epoch curve looks very good.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: å¹³å‡L2æŸå¤±ä¸è®­ç»ƒepochæ›²çº¿çœ‹èµ·æ¥éå¸¸å¥½ã€‚
- en: we are seeing a pause in learning and then suddenly a fast reduction in training
    error and then slow convergence
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°å­¦ä¹ æš‚åœï¼Œç„¶åçªç„¶è®­ç»ƒé”™è¯¯å¿«é€Ÿå‡å°‘ï¼Œç„¶åç¼“æ…¢æ”¶æ•›
- en: I stopped at 10,000 epochs for efficiency
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘åœæ­¢åœ¨10,000ä¸ªepoch
- en: Evaluating Our Autoencoder Network
  id: totrans-510
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„ä¼°æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œ
- en: Letâ€™s look at the output from the latent node at the network bottleneck, i.e.,
    the output of node M6.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ç½‘ç»œç“¶é¢ˆå¤„çš„æ½œåœ¨èŠ‚ç‚¹è¾“å‡ºï¼Œå³èŠ‚ç‚¹M6çš„è¾“å‡ºã€‚
- en: notice above that we recorded the M6 output (called node activation) for all
    training epochs and for all data.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬è®°å½•äº†æ‰€æœ‰è®­ç»ƒepochå’Œæ‰€æœ‰æ•°æ®çš„M6è¾“å‡ºï¼ˆç§°ä¸ºèŠ‚ç‚¹æ¿€æ´»ï¼‰ã€‚
- en: letâ€™s look at the final trained network, the last epoch, and loop over all data
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æœ€ç»ˆè®­ç»ƒçš„ç½‘ç»œï¼Œæœ€åä¸€ä¸ªepochï¼Œå¹¶éå†æ‰€æœ‰æ•°æ®
- en: Hereâ€™s a plot of final epoch M6 output vs. the sample slopes,
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æœ€ç»ˆepoch M6è¾“å‡ºä¸æ ·æœ¬æ–œç‡çš„å¯¹æ¯”å›¾ï¼Œ
- en: '[PRE15]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![_images/d0ab2f0cf0b3c073fe93da6aa44c8e663feb48b72910cb0e72f2f5ec9416f426.png](../Images/7815f0d074113f20a6f77a446f1f83d2.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/7815f0d074113f20a6f77a446f1f83d2.png)'
- en: As hypothesized, there is a good relationship between the output of our latent
    node at the network bottleneck and the slope of the samples used to generate the
    data!
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œç½‘ç»œç“¶é¢ˆå¤„çš„æ½œåœ¨èŠ‚ç‚¹è¾“å‡ºä¸ç”¨äºç”Ÿæˆæ•°æ®çš„æ ·æœ¬æ–œç‡ä¹‹é—´å­˜åœ¨è‰¯å¥½çš„å…³ç³»ï¼
- en: our autoencoder has learned 1 value to represent the vectors of 3 values in
    the dataset!
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨å·²ç»å­¦ä¼šäº†1ä¸ªå€¼æ¥è¡¨ç¤ºæ•°æ®é›†ä¸­3ä¸ªå€¼çš„å‘é‡ï¼
- en: this is a great demonstration of information compression, 3:1!
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¿¡æ¯å‹ç¼©æ¼”ç¤ºï¼Œ3:1ï¼
- en: Check Training Data Reconstruction
  id: totrans-520
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ£€æŸ¥è®­ç»ƒæ•°æ®é‡å»º
- en: Letâ€™s visualize the reconstructed 1D data, encoded and then decoded with out
    autoencoder network.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯è§†åŒ–ä½¿ç”¨æˆ‘ä»¬çš„è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œé‡æ„çš„1Dæ•°æ®ï¼Œç¼–ç ç„¶åè§£ç ã€‚
- en: for all training data, I include the original data and the reconstructed data,
    i.e., data encoded and decoded by our trained autoencoder
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œæˆ‘åŒ…æ‹¬åŸå§‹æ•°æ®å’Œé‡å»ºæ•°æ®ï¼Œå³ç”±æˆ‘ä»¬è®­ç»ƒçš„è‡ªåŠ¨ç¼–ç å™¨ç¼–ç å’Œè§£ç çš„æ•°æ®
- en: for each data training sample, I include the sample slope for interest, but
    this label are not used in the in the training, nor with the encoder or decoder
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ•°æ®è®­ç»ƒæ ·æœ¬ï¼Œæˆ‘åŒ…æ‹¬æ ·æœ¬æ–œç‡ä»¥ä¾›å‚è€ƒï¼Œä½†è¿™ä¸ªæ ‡ç­¾åœ¨è®­ç»ƒä¸­ã€ç¼–ç å™¨æˆ–è§£ç å™¨ä¸­éƒ½æ²¡æœ‰ä½¿ç”¨
- en: '[PRE16]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![_images/fe7102239237e5dec48032be77d18524b61a306c2238811815f52c81fcbd5955.png](../Images/7203aaa35d3b4fe06560d8885fa0bc78.png)'
  id: totrans-525
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/7203aaa35d3b4fe06560d8885fa0bc78.png)'
- en: The training data reconstruction is quite good!
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®é‡å»ºç›¸å½“ä¸é”™ï¼
- en: our autoencoder has learned to encode and decode the training data
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è‡ªç¼–ç å™¨å·²ç»å­¦ä¼šäº†ç¼–ç å’Œè§£ç è®­ç»ƒæ•°æ®
- en: demonstrating good dimensionality reduction from 3 to 1!
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»3ç»´åˆ°1ç»´å±•ç¤ºäº†è‰¯å¥½çš„é™ç»´æ•ˆæœï¼
- en: Check Testing Data Reconstruction
  id: totrans-529
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æµ‹è¯•æ•°æ®é‡å»º
- en: Letâ€™s generate additional data and test the reconstruction.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”Ÿæˆæ›´å¤šæ•°æ®å¹¶æµ‹è¯•é‡å»ºã€‚
- en: check the performance of our training autoencoder with data not used to train
    the autoencoder, known as model generalization
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æˆ‘ä»¬è®­ç»ƒçš„è‡ªåŠ¨ç¼–ç å™¨åœ¨æœªç”¨äºè®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨çš„æ•°æ®ä¸Šçš„æ€§èƒ½ï¼Œè¿™è¢«ç§°ä¸ºæ¨¡å‹æ³›åŒ–
- en: '[PRE17]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![_images/422b0a32f31f3498764ada7f7ec63e50a53a411b5d12e6c718a4288f371d62e8.png](../Images/28e4aff8d55696fd326194c3a79007d1.png)'
  id: totrans-533
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/28e4aff8d55696fd326194c3a79007d1.png)'
- en: Apply trained autoencoder to reconstruct test data.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è®­ç»ƒå¥½çš„è‡ªåŠ¨ç¼–ç å™¨åº”ç”¨äºé‡å»ºæµ‹è¯•æ•°æ®ã€‚
- en: '[PRE18]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now visualizated the test data reconstructions,
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¯è§†åŒ–æµ‹è¯•æ•°æ®çš„é‡å»ºï¼Œ
- en: '[PRE19]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![_images/6d4114b87e54f6dcb8a4cbefcdd99015b46e78ceca3a5d93daa4ff900d2cdf08.png](../Images/abda6b15ea724a35119dc1c5cf9554e9.png)'
  id: totrans-538
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/abda6b15ea724a35119dc1c5cf9554e9.png)'
- en: Our trained autoencoder seems to have generalized well with very good performance
    reconstructing training and also the withheld testing cases.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è®­ç»ƒå¥½çš„è‡ªåŠ¨ç¼–ç å™¨ä¼¼ä¹æ³›åŒ–å¾—å¾ˆå¥½ï¼Œåœ¨é‡å»ºè®­ç»ƒæ•°æ®å’Œä¿ç•™çš„æµ‹è¯•æ¡ˆä¾‹æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚
- en: For a more complete workflow we would evaluate training and testing error in
    parallel over training epochs to check for model overfit.
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å®Œæ•´çš„æµç¨‹ï¼Œæˆ‘ä»¬å°†åœ¨è®­ç»ƒå‘¨æœŸå†…å¹¶è¡Œè¯„ä¼°è®­ç»ƒå’Œæµ‹è¯•é”™è¯¯ï¼Œä»¥æ£€æŸ¥æ¨¡å‹è¿‡æ‹Ÿåˆã€‚
- en: I separated these components for brevity and clarity in the demonstration
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘å°†è¿™äº›ç»„ä»¶åˆ†å¼€ï¼Œä»¥åœ¨æ¼”ç¤ºä¸­ä¿æŒç®€æ´å’Œæ¸…æ™°
- en: Comments
  id: totrans-542
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„è®º
- en: This was a basic treatment of autoencoder deep learning networks. Much more
    could be done and discussed, I have many more resources. Check out my [shared
    resource inventory](https://michaelpyrcz.com/my-resources) and the YouTube lecture
    links at the start of this chapter with resource links in the videosâ€™ descriptions.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹è‡ªåŠ¨ç¼–ç å™¨æ·±åº¦å­¦ä¹ ç½‘ç»œçš„åŸºæœ¬å¤„ç†ã€‚å¯ä»¥åšå’Œè®¨è®ºçš„è¿˜æœ‰å¾ˆå¤šï¼Œæˆ‘æœ‰å¾ˆå¤šæ›´å¤šçš„èµ„æºã€‚æŸ¥çœ‹æˆ‘çš„[å…±äº«èµ„æºæ¸…å•](https://michaelpyrcz.com/my-resources)ä»¥åŠæœ¬ç« å¼€å¤´å¸¦æœ‰èµ„æºé“¾æ¥çš„YouTubeè®²åº§é“¾æ¥ã€‚
- en: I hope this is helpful,
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™æœ‰æ‰€å¸®åŠ©ï¼Œ
- en: '*Michael*'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: About the Author
  id: totrans-546
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºä½œè€…
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  id: totrans-547
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨æ•™æˆåœ¨å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡40è‹±äº©æ ¡å›­çš„åŠå…¬å®¤ã€‚
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨æ˜¯[ç§‘å…‹é›·å°”å·¥ç¨‹å­¦é™¢](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)å’Œ[æ°å…‹é€Šåœ°çƒç§‘å­¦å­¦é™¢](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)çš„æ•™æˆï¼Œåœ¨[å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡](https://www.utexas.edu/)ï¼Œåœ¨é‚£é‡Œä»–ç ”ç©¶å¹¶æ•™æˆåœ°ä¸‹ã€ç©ºé—´æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ã€‚è¿ˆå…‹å°”è¿˜æ˜¯ï¼Œ
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[èƒ½æºåˆ†æ](https://fri.cns.utexas.edu/energy-analytics)æ–°ç”Ÿç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œä»¥åŠå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡è‡ªç„¶ç§‘å­¦å­¦é™¢æœºå™¨å­¦ä¹ å®éªŒå®¤çš„æ ¸å¿ƒæ•™å‘˜ã€‚'
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è®¡ç®—æœºä¸åœ°çƒç§‘å­¦](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)çš„å‰¯ç¼–è¾‘ï¼Œä»¥åŠå›½é™…æ•°å­¦åœ°çƒç§‘å­¦åä¼š[æ•°å­¦åœ°çƒç§‘å­¦](https://link.springer.com/journal/11004/editorial-board)çš„è‘£äº‹ä¼šæˆå‘˜ã€‚'
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”å·²ç»æ’°å†™äº†è¶…è¿‡70ç¯‡[åŒè¡Œè¯„å®¡çš„å‡ºç‰ˆç‰©](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)ï¼Œä¸€ä¸ªç”¨äºç©ºé—´æ•°æ®åˆ†æçš„[PythonåŒ…](https://pypi.org/project/geostatspy/)ï¼Œåˆè‘—äº†ä¸€æœ¬å…³äºç©ºé—´æ•°æ®åˆ†æçš„æ•™ç§‘ä¹¦ã€Š[åœ°è´¨ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)ã€‹ï¼Œå¹¶æ˜¯ä¸¤æœ¬æœ€è¿‘å‘å¸ƒçš„ç”µå­ä¹¦çš„ä½œè€…ï¼Œåˆ†åˆ«æ˜¯ã€Š[Pythonä¸­çš„åº”ç”¨åœ°è´¨ç»Ÿè®¡å­¦ï¼šGeostatsPyå®è·µæŒ‡å—](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)ã€‹å’Œã€Š[Pythonä¸­çš„åº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„å®è·µæŒ‡å—](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)ã€‹ã€‚
- en: All of Michaelâ€™s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michaelâ€™s work and shared educational resources visit his
    Website.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”çš„æ‰€æœ‰å¤§å­¦è®²åº§éƒ½å¯åœ¨ä»–çš„[YouTubeé¢‘é“](https://www.youtube.com/@GeostatsGuyLectures)ä¸Šæ‰¾åˆ°ï¼Œé™„æœ‰100å¤šä¸ªPythonäº¤äº’å¼ä»ªè¡¨æ¿å’Œ40å¤šä¸ªå­˜å‚¨åº“ä¸­çš„è¯¦ç»†è®°å½•å·¥ä½œæµç¨‹ï¼Œè¿™äº›å­˜å‚¨åº“ä½äºä»–çš„[GitHubè´¦æˆ·](https://github.com/GeostatsGuy)ï¼Œä»¥æ”¯æŒä»»ä½•æœ‰å…´è¶£çš„å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«ï¼Œæä¾›æŒç»­æ›´æ–°çš„å†…å®¹ã€‚æƒ³äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„å·¥ä½œå’Œå…±äº«æ•™è‚²èµ„æºï¼Œè¯·è®¿é—®ä»–çš„ç½‘ç«™ã€‚
- en: Want to Work Together?
  id: totrans-554
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›è¿™äº›å†…å®¹å¯¹é‚£äº›æƒ³äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«éƒ½æ¬¢è¿å‚ä¸ã€‚
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£åˆä½œï¼Œæ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººæ˜¯çº¦ç¿°Â·ç¦æ–¯ç‰¹æ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶ç»“åˆæ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µï¼Œå¼€å‘æ–°é¢–çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ä»¥å¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)è”ç³»æˆ‘ã€‚
- en: Iâ€™m always happy to discuss,
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è®¨è®ºï¼Œ
- en: '*Michael*'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨ï¼Œåšå£«ï¼ŒP.Eng. æ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ Cockrell å·¥ç¨‹å­¦é™¢å’Œ Jackson åœ°çƒç§‘å­¦å­¦é™¢
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šèµ„æºå¯åœ¨ä»¥ä¸‹é“¾æ¥æ‰¾åˆ°ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°è´¨ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonåº”ç”¨åœ°è´¨ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonåº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
