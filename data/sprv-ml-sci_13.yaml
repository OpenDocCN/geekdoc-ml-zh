- en: 7  Generalization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 通用化
- en: 原文：[https://ml-science-book.com/generalization.html](https://ml-science-book.com/generalization.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ml-science-book.com/generalization.html](https://ml-science-book.com/generalization.html)
- en: '[Integrating Machine Learning Into Science](./part-two.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[将机器学习融入科学](./part-two.html)'
- en: '[7  Generalization](./generalization.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[7 通用化](./generalization.html)'
- en: 'Little does Juan know that his chest X-ray was one of the data points for a
    pneumonia classifier. He presented with a fever and a bad cough at the emergency
    room, but it was “just” a bad flu. No pneumonia. The chest X-ray that ruled out
    pneumonia was labeled as “healthy” and later used to train a machine learning
    model. The pneumonia classifier is not for our imaginary Juan though, because
    this ER visit was years ago and the case is closed. While the machine learning
    experts don’t care about Juan’s images specifically, they care about cases *like*
    Juan’s: Patients coming to the emergency room with symptoms of a lung infection.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 王小二并不知道他的胸部X光片是肺炎分类器的一个数据点。他在急诊室出现了发烧和严重的咳嗽，但“只是”重感冒。没有肺炎。排除肺炎的胸部X光片被标记为“健康”，后来被用来训练机器学习模型。肺炎分类器并不是针对我们想象的王小二，因为这次急诊室访问是几年前的事，案件已经结案。虽然机器学习专家们并不关心王小二的图像，但他们关心的是像王小二这样的病例：出现肺部感染症状来到急诊室的患者。
- en: 'That’s the promise of **generalization** in machine learning: to learn general
    rules from specific data and apply them to novel data. To generalize from Juan
    to many. Without generalization, machine learning would just be an inefficient
    database. But with generalization, machine learning models become useful prediction
    machines.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是机器学习中通用化的承诺：从具体数据中学习通用规则，并将其应用于新数据。从具体到普遍。没有通用化，机器学习就只能是一个低效的数据库。但有了通用化，机器学习模型就变成了有用的预测机器。
- en: In science, generalizing from specific observations to general principles is
    a fundamental goal. Scientists usually don’t care about specific experiments,
    surveys, simulations, or studies, but they use them to learn the rules of our
    world.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学中，从具体观察中归纳出一般原则是一个基本目标。科学家通常不关心具体的实验、调查、模拟或研究，但他们使用它们来学习我们世界的规则。
- en: This chapter discusses generalization in machine learning and is structured
    into three parts, each describing generalization with increasing scope.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论机器学习中的通用化，并分为三个部分，每个部分都描述了不同范围的通用化。
- en: '**Generalize to predict in theory:** This is the theory of generalization as
    it is typically understood in machine learning. It concerns key topics from statistical
    learning theory, such as empirical risk, the IID assumption, and a discussion
    of the double descent phenomenon and its relationship to under- and overfitting.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理论上的通用化以预测：** 这是在机器学习中通常理解的通用化理论。它涉及统计学习理论中的关键主题，如经验风险、独立同分布假设，以及关于双下降现象及其与欠拟合和过拟合关系的讨论。'
- en: '**Generalize to predict in practice:** This section describes a more practical
    idea of generalization. Rarely does the training setup match the application.
    To generalize the model to the application requires attention to things like the
    data-generating process, non-IID scenarios, and distribution shifts.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实践中的通用化：** 这一部分描述了更实际的通用化概念。很少训练设置与应用场景完全匹配。要将模型推广到应用场景，需要关注数据生成过程、非独立同分布场景和分布偏移等问题。'
- en: '**Generalize to understand the phenomenon:** This type of generalization is
    often implicitly the goal of scientists. It bridges the gap from machine learning
    theory to scientific applications and discusses data representativeness and the
    data-generating process.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用化以理解现象：** 这种类型的通用化通常是科学家们隐含的目标。它连接了机器学习理论与科学应用之间的差距，并讨论了数据代表性以及数据生成过程。'
- en: Nuts are delicious but hard to crack. So the Ravens set out to build a nut quality
    predictor. Every tenth household had to bring a sample of nuts to Rattle so she
    could train a machine learning model. The model worked well on the training data,
    but it was terrible on unseen data. Rattle began to wonder how to ensure that
    machine learning models generalize.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 坚果美味但难以开裂。因此，乌鸦们着手建立一个坚果质量预测器。每第十户家庭必须向Rattle提供一个坚果样本，以便她能够训练一个机器学习模型。该模型在训练数据上表现良好，但在未见过的数据上表现糟糕。Rattle开始思考如何确保机器学习模型能够推广。
- en: '![](../Images/f430adf6dfc91e0c9d710913e218b9e3.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f430adf6dfc91e0c9d710913e218b9e3.png)'
- en: 7.1 Generalize to predict in theory
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 理论上的通用化以预测
- en: You want our models to work well on the dataset at hand but also on similar
    data. One language of similarity is that of statistical distributions. You can
    think of distributions like a huge bucket that contains infinitely many data points.
    From this bucket, you can draw data and record it. Think of the bucket that contains
    X-rays and their corresponding labels. We denote this bucket by the statistical
    distribution \(\mathbb{P}(X, Y)\), where \(X\) describes the pixels of the X-ray
    images and \(Y\) the labels.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望我们的模型在手头的数据集上表现良好，同时也适用于类似的数据。相似性的一种语言是统计分布。您可以将分布想象成一个包含无限多个数据点的巨大桶。从这个桶中，您可以抽取数据并记录它。想想包含X射线及其对应标签的桶。我们用统计分布
    \(\mathbb{P}(X, Y)\) 表示这个桶，其中 \(X\) 描述X射线图像的像素，\(Y\) 描述标签。
- en: 'Equipped with distributions, we can describe more elegantly what our models
    should optimize. Machine learning models should make as few mistakes as possible
    in expectation. More technically, they should have minimal *expected loss* \(R(\hat{f})\)
    (sometimes also called *expected risk*):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 配备了分布，我们可以更优雅地描述我们的模型应该优化的内容。机器学习模型应该在期望上犯尽可能少的错误。更技术地说，它们应该有最小的 *预期损失* \(R(\hat{f})\)（有时也称为
    *预期风险*）：
- en: \[R(\hat{f}) = \mathbb{E}_{X,Y}[L(Y, \hat{f}(X))] \]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \[R(\hat{f}) = \mathbb{E}_{X,Y}[L(Y, \hat{f}(X))] \]
- en: This formula describes the expected error the model will make on instances drawn
    from the distribution bucket \(\mathbb{P}(X,Y)\). The “error” for one data point
    is described by loss function L which quantifies the error between prediction
    \(\hat{f}(x)\) (e.g. pneumonia) and the actual outcome \(y\) (e.g. healthy). The
    problem is that you don’t know what the bucket – aka distribution – looks like.
    You only have a limited amount of data that you recorded. When you have data,
    you look at the errors the model makes on these data and average over it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式描述了模型在从分布桶 \(\mathbb{P}(X,Y)\) 中抽取的实例上预期的错误。单个数据点的“错误”由损失函数 L 描述，它量化了预测
    \(\hat{f}(x)\)（例如，肺炎）和实际结果 \(y\)（例如，健康）之间的误差。问题是您不知道这个桶——即分布——看起来像什么。您只有有限的数据量，这些数据是您记录的。当您有数据时，您会查看模型在这些数据上犯的错误，并对其平均。
- en: 'You could use the training data to estimate the expected loss, but using training
    data makes for a bad estimator of \(R(\hat{f})\). The estimated loss would be
    over-optimistic, meaning too small. If a model overfits the training data (“memorizing”
    it), the training error can be low even though the model won’t work well for new
    data. It is like preparing students for an exam by giving them the questions and
    answers beforehand. This means they can simply memorize the answers and you won’t
    get an honest assessment of the student’s skills on the subject. The X-ray classifier
    might work perfectly for Juan and the other training data subjects, but not for
    new patients. But this has a simple solution: Estimate the expected risk using
    new data.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用训练数据来估计预期损失，但使用训练数据作为 \(R(\hat{f})\) 的估计器并不好。估计的损失会过于乐观，意味着太小。如果一个模型过度拟合训练数据（“记忆”它），训练误差可能很低，即使该模型对新数据的表现不佳。这就像通过提前给出问题和答案来为学生准备考试。这意味着他们可以简单地记住答案，而您无法得到学生对该科目技能的真实评估。X射线分类器可能对胡安和其他训练数据对象工作得很好，但对新病人则不行。但这个问题有一个简单的解决方案：使用新数据估计预期风险。
- en: \[\hat{R}(\hat{f}) = \sum_{i=1}^{n_{test}} L(y^{(i)}, \hat{f}(x^{(i)}))\]
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{R}(\hat{f}) = \sum_{i=1}^{n_{test}} L(y^{(i)}, \hat{f}(x^{(i)}))\]
- en: This formula is also known as test error, out-of-sample error, generalization
    error, or empirical risk (on the test set).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式也被称为测试误差、样本外误差、泛化误差或经验风险（在测试集上）。
- en: 'Slowly but surely, we are piecing together a language to talk about generalization.
    A model generalizes well when \(\hat{R}(\hat{f})\) is low and when the so-called
    generalization gap is small, which is defined as the following difference [[1]](references.html#ref-hardtrecht2022patterns):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 慢慢但稳定地，我们正在拼凑一种语言来讨论泛化。当 \(\hat{R}(\hat{f})\) 低且所谓的泛化差距小的时候，模型泛化得好，泛化差距定义为以下差异
    [[1]](references.html#ref-hardtrecht2022patterns)：
- en: \[\delta_{gen}(\hat{f}) = R(\hat{f}) - \hat{R}(\hat{f})\]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[\delta_{gen}(\hat{f}) = R(\hat{f}) - \hat{R}(\hat{f})\]
- en: If the generalization gap is small, the model will perform similarly well for
    both training and unseen data. [¹](#fn1) Let’s explore how the generalization
    error behaves in different scenarios.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果泛化差距小，模型在训练数据和未见数据上的表现将相似。 [¹](#fn1) 让我们探索泛化误差在不同场景下的行为。
- en: Underfitting and overfitting
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 欠拟合和过拟合
- en: 'Machine learning can feel more like an art than a science, but there is an
    entire field dedicated to putting all the deep learning magic and mystical random
    forests on a scientific grounding: statistical learning theory, which provides
    a view of machine learning from a statistical lens. We explore statistical learning
    theory to shed light on generalization.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可能更像是一门艺术而不是一门科学，但有一个整个领域致力于将所有深度学习的魔法和神秘的随机森林建立在科学基础上：统计学习理论，它从统计的角度提供了机器学习的视角。我们通过探索统计学习理论来阐明泛化。
- en: 'Well-studied concepts are overfitting and its counterpart, underfitting. Underfitting
    is when the model is not complex enough to model the relation between input and
    output, so the model will have both a high training and test error but a potentially
    small generalization gap. Underfitting models are, frankly, bad! Overfitting is
    when the model function has a bit too much freedom: It fails to capture generalizable
    rules and instead “memorizes” the training data. That’s why overfitting is characterized
    by a low training error and a high test error and therefore a large generalization
    gap. Both underfitting and overfitting are undesirable as they both mean a failure
    to generalize well (measured as low out-of-sample error).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 研究良好的概念是过拟合及其对立面欠拟合。欠拟合是指模型复杂度不足以模拟输入和输出之间的关系，因此模型将具有高训练误差和高测试误差，但可能存在小的泛化差距。坦白说，欠拟合模型是糟糕的！过拟合是指模型函数有太多的自由度：它未能捕捉可泛化的规则，而是“记忆”了训练数据。这就是为什么过拟合的特点是低训练误差和高测试误差，因此存在大的泛化差距。欠拟合和过拟合都是不希望的，因为它们都意味着泛化能力差（以低样本外误差来衡量）。
- en: 'Going back to the chest X-ray example: Imagine the classification algorithm
    would be a simple logistic regression classifier based on the average grey scale
    value of parts of the image. It might work better than random guessing, but wouldn’t
    produce a useful model. A case of underfitting. Overfitting in this same case
    would look like this: Let’s say you use for the chest X-ray a decision tree that
    is allowed to be grown to full depth. Inputs are the individual pixels and all
    typical restrictions are lifted, like having a minimum amount of data in each
    leaf. The tree could grow very deep and separate all training data, meaning each
    data point gets its leaf node. So the model would work perfectly on the training
    data. But when used on new data, the decision tree would fail. [Figure 7.1](#fig-underfitting-overfitting)
    showcases underfitting and overfitting on a simple 1-dimensional case.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 回到胸部X光检查的例子：想象一下，分类算法可能是一个基于图像部分平均灰度值的简单逻辑回归分类器。它可能比随机猜测更有效，但不会产生有用的模型。这是一个欠拟合的例子。在这个相同的情况下，过拟合可能看起来像这样：假设你为胸部X光使用一个允许完全生长到深度的决策树。输入是单个像素，并且所有典型限制都被取消，比如每个叶子节点中必须有最小数量的数据。树可以长得非常深，将所有训练数据分开，意味着每个数据点都得到一个叶子节点。因此，模型在训练数据上会表现得非常完美。但是当用于新数据时，决策树会失败。[图7.1](#fig-underfitting-overfitting)展示了简单一维情况下的欠拟合和过拟合。
- en: '![](../Images/f0f62ca3cda0706e60bb656ccec905a6.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/f0f62ca3cda0706e60bb656ccec905a6.png)'
- en: 'Figure 7.1: The data (dots) were produced by the true function (dotted line)
    plus some noise. A well-trained model would approximate the true function well.
    The linear model (blue line) underfits the true curve, while the too-flexible
    model (green curve) overfits the data.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：数据（点）是由真实函数（虚线）加上一些噪声产生的。一个训练良好的模型会很好地逼近真实函数。线性模型（蓝色线）欠拟合了真实曲线，而过于灵活的模型（绿色曲线）过拟合了数据。
- en: Whether a model will underfit or overfit depends on the machine learning algorithm
    responsible and the complexity of functions it can produce. By picking certain
    types of model classes and setting their hyperparameters, you can steer the flexibility
    of the models and therefore the balance between underfitting and overfitting.
    The typical approach in machine learning is to use fairly flexible models and
    then regularize them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型是否会欠拟合或过拟合取决于负责的机器学习算法及其能产生的函数复杂性。通过选择某些类型的模型类别并设置它们的超参数，你可以调整模型的灵活性，从而平衡欠拟合和过拟合。在机器学习中，典型的做法是使用相当灵活的模型，然后对其进行正则化。
- en: Examples of such flexible models are neural networks and decision trees. Theorems
    show that both neural networks [[2]](references.html#ref-cybenko1989approximation),
    [[3]](references.html#ref-hornik1991approximation) and decision trees can approximate
    arbitrary continuous functions [[4]](references.html#ref-halmos2013measure). These
    flexible models can then be regularized by specifying certain hyperparameters
    in modeling such as the learning rate, the architecture, the loss function, or
    enabling dropout [[5]](references.html#ref-goodfellow2016deep).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活模型的例子包括神经网络和决策树。定理表明，神经网络[[2]](references.html#ref-cybenko1989approximation)、[[3]](references.html#ref-hornik1991approximation)和决策树可以逼近任意连续函数[[4]](references.html#ref-halmos2013measure)。这些灵活模型可以通过在建模中指定某些超参数（如学习率、架构、损失函数或启用dropout
    [[5]](references.html#ref-goodfellow2016deep)）来进行正则化。
- en: Underfitting and overfitting don’t tell us about the types of errors the models
    make. This will be covered in [Chapter 12](uncertainty.html) about uncertainty.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合和过拟合并不能告诉我们模型犯了什么类型的错误。这将在关于不确定性的第12章中讨论。
- en: Double descent or why deep learning works
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 双重下降或为什么深度学习有效
- en: 'We’ve painted a neat picture of what a perfectly balanced model looks like
    – models should be flexible enough not to underfit and regularized enough not
    to overfit. But now with deep learning, the over- and underfitting reasoning doesn’t
    seem to work any longer. Deep neural networks have millions or more parameters
    and can perfectly fit the training data in infinitely many ways, so you would
    expect strong overfitting. The thing is – they generalize. It is like in society:
    the laws of under and overfitting developed for the average John Doe model don’t
    apply to the fancy models rich in parameters. This surprising learning behavior
    in deep neural networks has been named *double descent* [[6]](references.html#ref-belkin2019reconciling).
    Double descent describes the out-of-sample error when increasing the ratio between
    parameters and data. The behavior can be sliced into two components:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经描绘了一个完美平衡的模型的样子——模型应该足够灵活，不会欠拟合，并且足够正则化，不会过拟合。但现在随着深度学习的发展，欠拟合和过拟合的推理似乎不再适用。深度神经网络拥有数百万或更多的参数，可以以无数种方式完美地拟合训练数据，因此你可能会预期强烈的过拟合。但事实上——它们具有泛化能力。这就像在社会中：为平均的约翰·多伊模型开发出的欠拟合和过拟合定律并不适用于参数丰富的复杂模型。这种深度神经网络中的令人惊讶的学习行为被称为*双重下降[[6]](references.html#ref-belkin2019reconciling)。双重下降描述了在增加参数与数据之间的比率时，样本外误差的行为。这种行为可以分为两个部分：
- en: '**Typical under- and overfitting:** The dataset remains fixed and you start
    with a simple neural network. If you increase the number of parameters in our
    model and fit it to the data, you observe the typical underfitting and overfitting.
    This is true until you reach the point where you have as many parameters as you
    have data points, the so-called *interpolation threshold*. The test error explodes
    when reaching the interpolation threshold.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**典型的欠拟合和过拟合：** 数据集保持不变，你从一个简单的神经网络开始。如果你增加我们模型中的参数数量并将其拟合到数据上，你会观察到典型的欠拟合和过拟合。这种情况一直持续到你拥有的参数数量与数据点数量相等，即所谓的*插值阈值*。当达到插值阈值时，测试误差会爆炸。'
- en: '**Double descent:** But unlike traditional under- and overfitting, the test
    error decreases if you increase the number of parameters beyond the interpolation
    threshold. Continuing to increase the network size, the test error may even become
    lower than the test error of the “ideal” model in the underfitting/overfitting
    world (see [Figure 7.2](#fig-double-descent)).'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**双重下降：** 但与传统意义上的欠拟合和过拟合不同，如果你在插值阈值之上增加参数数量，测试误差会降低。继续增加网络大小，测试误差甚至可能低于欠拟合/过拟合世界中的“理想”模型的测试误差（见图7.2）。'
- en: '![](../Images/34fcfde89ab940ff5fca3cec07f73b7a.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34fcfde89ab940ff5fca3cec07f73b7a.png)'
- en: 'Figure 7.2: Double Descent. Image inspired by [[7]](references.html#ref-rocks2022memorizing)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：双重下降。图像灵感来源于[[7]](references.html#ref-rocks2022memorizing)
- en: 'Double descent is not exclusive to deep neural networks but also happens for
    simple linear models [[8]](references.html#ref-schaeffer2023double), random forests,
    and decision trees, as suggested by [[6]](references.html#ref-belkin2019reconciling),
    possibly due to a shared inductive bias [[9]](references.html#ref-curth2024u).
    Double descent undermined the theory of underfitting versus overfitting. But under-
    and overfitting are still useful concepts. It is like with Newton’s theory of
    gravity when Einstein’s relativity came along: Underfitting and overfitting provide
    an accurate picture of things below the interpolation threshold, but beyond this
    threshold the classical picture becomes invalid.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 双重下降不仅限于深度神经网络，也发生在简单的线性模型 [[8]](references.html#ref-schaeffer2023double)、随机森林和决策树中，如
    [[6]](references.html#ref-belkin2019reconciling) 所建议的，可能是因为存在共同的归纳偏差 [[9]](references.html#ref-curth2024u)。双重下降颠覆了欠拟合与过拟合的理论。但欠拟合和过拟合仍然是有用的概念。这就像牛顿的引力理论在爱因斯坦的相对论出现时一样：欠拟合和过拟合提供了对插值阈值以下事物的准确描述，但超过这个阈值，经典图景就不再有效。
- en: 'Double descent describes the what but not the why. We still have no definitive
    answers as to why overparameterization works so well, but there are theories:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 双重下降描述了“是什么”，但没有解释“为什么”。我们仍然没有确切的答案来解释为什么过参数化工作得如此之好，但有一些理论：
- en: The lottery ticket hypothesis [[10]](references.html#ref-frankle2019lottery)
    says that there are subnetworks in certain trained neural networks that have similar
    performance to the overall network. Training a large network is like having multiple
    lottery tickets (aka subnetworks) and one will win.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 彩票假设 [[10]](references.html#ref-frankle2019lottery) 指出，在某些训练好的神经网络中存在子网络，其性能与整体网络相似。训练大型网络就像拥有多个彩票（即子网络）一样，其中之一会中奖。
- en: 'Benign overfitting [[11]](references.html#ref-bartlett2020benign): Many low-variance
    directions in parameter space are required to achieve highly performing models.
    This is achieved through overparameterization and makes for “benign overfitting”.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 良性过拟合 [[11]](references.html#ref-bartlett2020benign)：在参数空间中需要许多低方差方向才能实现高性能模型。这是通过过参数化实现的，形成了“良性过拟合”。
- en: 'Implicit regularization [[12]](references.html#ref-smith2020origin): Optimization
    algorithms such as stochastic gradient descent implicitly regularize the model.
    It was shown that stochastic gradient descent actually optimizes not only the
    loss but effectively the loss plus an implicit minimizer.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐式正则化 [[12]](references.html#ref-smith2020origin)：优化算法，如随机梯度下降，隐式地正则化模型。已经证明，随机梯度下降实际上不仅优化了损失，还有效地优化了损失加上一个隐式最小化器。
- en: 'We barely scratched the surface of statistical learning theory, and there are
    many more topics to explore:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是触及了统计学习理论的一角，还有许多更多的话题需要探索：
- en: Quantifying the complexity of models (like VC dimensions).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化模型的复杂性（如VC维度）。
- en: Learning guarantees for kernel methods like support vector machines.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核方法（如支持向量机）的学习保证。
- en: Studying consistency and convergence rates of learners.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究学习者的一致性和收敛速度。
- en: Providing bounds for the empirical risk.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为经验风险提供界限。
- en: 7.2 Generalize to predict in practice
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 在实践中推广以进行预测
- en: So far we’ve talked about generalization from a theoretical viewpoint that,
    in practice, is too narrow. Because in practice, you only have access to data
    but not to the underlying distributions. Data is messy, noisy, and cannot perfectly
    be trusted.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们都是从理论角度讨论泛化，这在实践中过于狭隘。因为在实践中，你只能接触到数据，但无法接触到底层分布。数据是杂乱的、有噪声的，不能完全信赖。
- en: Generalization through splitting data
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过分割数据实现泛化
- en: 'How do you obtain models that generalize while being data-efficient? The answer:
    data splitting! Let’s explore this with an example: Rajpurkar et al. [[13]](references.html#ref-rajpurkar2017chexnet)
    built a chest X-ray image classifier to detect pneumonia. To ensure that the classifier
    generalizes to new data, they split the data into training data (93.6% of the
    data), validation data (6%) to control the learning rate, and test data (0.4%)
    to evaluate the final model. If they had used 100% of the data for training the
    model, they would run into two problems: 1) The model might perform badly since
    it is unclear how many epochs to train it, and 2) the modelers would have no idea
    about the performance of the model, except for an overly optimistic estimate on
    training data.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何获得既能泛化又能高效利用数据的模型？答案是：数据拆分！让我们用一个例子来探讨这个问题：Rajpurkar等人[[13]](references.html#ref-rajpurkar2017chexnet)构建了一个胸部X光图像分类器来检测肺炎。为了确保分类器能够泛化到新的数据，他们将数据分为训练数据（93.6%的数据）、验证数据（6%）以控制学习率，以及测试数据（0.4%）以评估最终模型。如果他们使用了100%的数据来训练模型，他们可能会遇到两个问题：1)
    模型可能表现不佳，因为不清楚要训练多少个epoch，2) 模型开发者对模型的性能一无所知，除了对训练数据的过于乐观的估计。
- en: 'But if you split the data, train a model on one part, and evaluate the model
    on the remaining part, you can get an honest estimate of the out-of-sample error.
    Great, problem solved?! Careful, while their approach gets them an unbiased estimate
    of the test error, the estimate possibly has a large variance. With only 420 images
    in the test set, 10 difficult cases that ended up in the test set by chance can
    spoil your performance estimate. One strategy to lower the variance is to split
    the data more often. For example with cross-validation: Split the data, for example,
    into 5 parts, combine 4 parts for training (and validation), and the remaining
    1 part for testing. Repeat this setup 5 times so each part is once used as test
    data. Average the 5 estimates of the out-of-sample error and, voila, you have
    a more stable estimate (visualized in [Figure 7.3](#fig-cv)).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你拆分数据，在一个部分上训练一个模型，并在剩余的部分上评估模型，你就可以得到一个真实的样本外误差估计。太好了，问题解决了？！小心，虽然他们的方法使他们得到了测试误差的无偏估计，但这种估计可能有很大的方差。在测试集中只有420张图像的情况下，10个偶然进入测试集的困难案例可能会破坏你的性能估计。降低方差的一个策略是更频繁地拆分数据。例如，使用交叉验证：将数据分为5部分，例如，将4部分用于训练（和验证），剩余的1部分用于测试。重复这个设置5次，这样每个部分都至少被用作测试数据。平均5个样本外误差估计，
    voila，你就有了一个更稳定的估计（如图7.3所示）。
- en: '![](../Images/077e8c26c2ee256f25fb912d111d8a03.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/077e8c26c2ee256f25fb912d111d8a03.png)'
- en: 'Figure 7.3: 5-fold cross-validation'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3：5折交叉验证
- en: 'But there’s another problem. In each CV-loop, you split the data once into
    training and validation data. The validation data in [[13]](references.html#ref-rajpurkar2017chexnet)
    was used for adapting the learning rate, but you could also use it for hyperparameter
    tuning and model selection. A single split can lead to a similar problem as before:
    too much variance in the performance estimate. So you might want to have another
    cross-validation inside the outer cross-validation. This so-called nested cross-validation
    quickly blows up the number of models you have to train, but it is a more efficient
    use of your data. This quickly went from splitting the data into two parts (training
    and testing) to splitting the data 100 times (10-fold cross-validation within
    10-fold cross-validation). Data splitting is at the heart of generalization.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有一个问题。在每次CV循环中，你将数据拆分一次为训练和验证数据。在[[13]](references.html#ref-rajpurkar2017chexnet)中的验证数据被用于调整学习率，但你也可以用它来进行超参数调整和模型选择。单一的拆分可能导致与之前类似的问题：性能估计的方差太大。所以你可能想在外部交叉验证中再进行一次交叉验证。这种所谓的嵌套交叉验证会迅速增加你需要训练的模型数量，但它是对数据更有效的利用。这很快就从将数据分为两部分（训练和测试）变成了将数据拆分100次（10折交叉验证在10折交叉验证内）。数据拆分是泛化的核心。
- en: The tricky IID assumption
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 难以捉摸的IID假设
- en: 'Statistical theory and data splitting practices rest on a crucial assumption:
    data are IID, which stands for “independent and identically distributed” and means
    that each data point is a random sample.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 统计理论和数据拆分实践基于一个关键假设：数据是IID，即“独立同分布”，这意味着每个数据点都是一个随机样本。
- en: 'Identically distributed: All the data points are from the same distribution
    and don’t change over time. If you had one set of X-ray data for model training
    from a children’s hospital but the model application from an adult hospital, they
    are not identically distributed.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立同分布：所有数据点都来自同一分布，并且随时间不发生变化。如果你有一组来自儿童医院的X光数据用于模型训练，但模型应用在成人医院，它们就不是独立同分布的。
- en: 'Independent: A data point doesn’t reveal the ground truth of another data point.
    The X-ray data are no longer independent if a patient appears multiple times.
    Sampling one X-ray of a patient reveals information about other X-rays of the
    same patient.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立：一个数据点不会揭示另一个数据点的真实情况。如果一个患者出现多次，X光数据就不再是独立的。采样一个患者的X光片会揭示关于该患者其他X光片的信息。
- en: 'IID is a typical assumption in statistical learning theory, but also when you
    randomly split data for generalization purposes you implicitly make this assumption.
    IID is restrictive and real-world data often violates it. Some examples:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 独立同分布是统计学习理论中的一个典型假设，当你随机分割数据以进行泛化时，你隐式地做出了这个假设。独立同分布是限制性的，而现实世界的数据经常违反它。以下是一些例子：
- en: Store sales over time are not IID.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随时间推移的店铺销售额不是独立同分布的。
- en: Patient visits with possibly multiple visits per patient are not IID
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 患者的就诊记录，每位患者可能有多次就诊，不是独立同分布的。
- en: Satellite images of neighboring locations are not IID.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邻近地区的卫星图像不是独立同分布的。
- en: 'An earlier version of the paper by Rajpurkar et al. [[13]](references.html#ref-rajpurkar2017chexnet)
    ran into this non-IID problem: They split the data randomly, but for some patients,
    there were multiple X-ray images in the data. This led to data leakage: The model
    had an easier job since the model was able to overfit patient characteristics
    (e.g. scars in the X-ray image) and that would help classify the “unseen” data.
    As a kid, our imaginary Juan fell from a tree and broke his rips. This past injury
    is still visible in chest X-ray images and uniquely identifies Juan. If Juan went
    multiple times to the emergency room, his images might end up in both training
    and testing, and the model may overfit on the scans.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Rajpurkar等人早期的论文版本 [[13]](references.html#ref-rajpurkar2017chexnet) 遇到了这个非独立同分布的问题：他们随机分割数据，但对于一些患者，数据中存在多个X光片。这导致了数据泄露：模型的工作变得更容易，因为模型能够过度拟合患者特征（例如X光片中的疤痕），这有助于分类“未见”的数据。小时候，我们的想象中的胡安从树上摔下来，摔断了肋骨。过去的伤害在胸部X光片中仍然可见，并独特地识别了胡安。如果胡安多次前往急诊室，他的图像可能会同时出现在训练和测试数据中，模型可能会过度拟合扫描数据。
- en: 'Rajpurkar et al. [[13]](references.html#ref-rajpurkar2017chexnet) fixed this
    problem by ensuring that a patient’s data can only be in training or testing,
    but not both. If IID is violated, generalization can break down in parts – unless
    we account for it. The IID assumption also helps us in estimating the test error:
    If the data are IID, we can estimate the generalization error in an unbiased way
    because of the law of large numbers.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Rajpurkar等人 [[13]](references.html#ref-rajpurkar2017chexnet) 通过确保患者数据只能用于训练或测试，但不能同时用于两者来解决这个问题。如果违反了独立同分布，泛化可能会在某些部分失效——除非我们考虑到这一点。独立同分布的假设还有助于我们估计测试误差：如果数据是独立同分布的，我们可以利用大数定律以无偏的方式估计泛化误差。
- en: The real world is messy
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现实世界是混乱的。
- en: When COVID hit, many machine learning research labs dropped their projects to
    work on COVID detectors, many of them from X-ray images. Partially understandable,
    but in hindsight, a waste of effort. Sounds harsh, but Wynants et al. [[14]](references.html#ref-wynants2020prediction)
    did a systematic review of 232 prediction models for COVID and found that only
    2 (!) were promising. The remaining 230 had various problems, like non-representative
    selections of control patients, excluding patients with no event, risk of overfitting,
    unclear reporting, and lack of descriptions of the target population and care
    setting.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当COVID来袭时，许多机器学习研究实验室放弃了他们的项目，转而研究COVID检测器，其中许多来自X光片。部分可以理解，但事后看来，这是徒劳的努力。听起来很严厉，但Wynants等人
    [[14]](references.html#ref-wynants2020prediction) 对232个COVID预测模型进行了系统回顾，发现其中只有2个
    (!) 有希望。其余230个存在各种问题，如控制患者选择不具有代表性、排除无事件的患者、过度拟合的风险、报告不清晰以及缺乏对目标人群和护理环境的描述。
- en: 'If you want a functional COVID-19 X-ray classifier, you should be as close
    as possible to the data-generating process of a potential application. For instance,
    getting data directly from an ER where radiologists label the images with the
    diagnoses. This would generate a dataset that reflects a typical distribution
    of cases. However, the data that many machine learning labs used were quite different.
    So different that the research models and results are unusable. As the pandemic
    progressed, more and more X-rays of COVID-infected lungs were posted online in
    repositories. Often without metadata like missing demographics of the patient,
    without any verification process, and little documentation. But that’s not the
    worst part of COVID classifiers. For classification tasks, you also need negative
    examples, such as images of healthy lungs or from patients with, for example,
    pneumonia. These negative images were cobbled together from many pre-pandemic
    datasets. A red flag: Negative and positive X-ray data come from very different
    data-generating processes. Should a deep learning model find any hints or shortcuts
    that identify the data source, then it doesn’t have to detect COVID at all. But
    even that isn’t the worst yet. The worst is how the non-COVID dataset was assembled.
    Roberts et al. [[15]](references.html#ref-roberts2021common) looked more deeply
    into the most commonly used datasets and found the following fouls:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要一个功能性的COVID-19 X射线分类器，你应该尽可能接近潜在应用的数据生成过程。例如，直接从急诊室获取数据，那里放射科医生会对图像进行诊断标注。这将生成一个反映典型病例分布的数据集。然而，许多机器学习实验室使用的数据却相当不同。如此不同，以至于研究模型和结果都无法使用。随着大流行的进展，越来越多的COVID感染者肺部X光片被发布在存储库中。通常没有元数据，比如缺少患者的流行病学信息，没有任何验证过程，几乎没有文档。但这还不是COVID分类器的最糟糕部分。对于分类任务，你还需要负例，例如健康肺部的图像或患有肺炎等疾病的患者的图像。这些负例图像是从许多大流行前的数据集中拼凑起来的。一个红旗：负例和正例X射线数据来自非常不同的数据生成过程。如果深度学习模型发现任何识别数据源的线索或捷径，那么它甚至不需要检测COVID。但还不是最糟糕的。最糟糕的是非COVID数据集是如何组装的。Roberts等人[[15]](references.html#ref-roberts2021common)更深入地研究了最常用的数据集，并发现了以下问题：
- en: The X-ray image datasets were put together from multiple other image datasets.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X射线图像数据集是从多个其他图像数据集中拼凑起来的。
- en: One of these datasets was from children (only non-COVID).
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中一个数据集来自儿童（只有非COVID）。
- en: Some datasets were included more than once, leading to duplicated images, introducing
    non-IID problems and data leakage.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些数据集被重复包含，导致重复的图像，引入了非-IID问题和数据泄露。
- en: For some of the datasets it is intransparent how they were collected
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一些数据集，它们的收集方式不透明
- en: Other datasets were collected through “open calls” to other researchers to submit
    data without further verification.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他数据集是通过向其他研究人员发出“开放呼吁”来收集的，让他们提交数据而不进行进一步验证。
- en: 'These things should all raise red flags. It is like Frankenstein was employed
    to create a dataset. A data-generating process that deviates strongly from any
    application we can think of. A model trained on Frankenstein’s data can learn
    all matters of shortcuts and none will generalize to a meaningful application:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都应该引起红旗。这就像弗兰肯斯坦被雇佣来创建数据集。一个与任何我们可以想到的应用都强烈偏离的数据生成过程。在弗兰肯斯坦的数据上训练的模型可以学习所有捷径，但没有一个可以推广到有意义的应用：
- en: 'Identify children’s lungs: If the model can identify that the image was from
    a child, it can safely predict “not COVID”.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别儿童肺部：如果模型可以识别图像来自儿童，它可以安全地预测“非COVID”。
- en: 'Identify the year: If the model can identify the year through explicit or implicit
    markers (like the type of machine) it can safely label “not COVID” for older images.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别年份：如果模型可以通过显式或隐式标记（如机器类型）识别年份，它可以安全地将旧图像标记为“非COVID”。
- en: 'Identify the dataset: Any characteristics that images from the same dataset
    share can be used to make the prediction task easier. It is enough when a dataset
    is processed differently (e.g. greyscaling) or comes from a different X-ray machine.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别数据集：可以使用来自同一数据集的图像共享的任何特征来简化预测任务。如果数据集被不同地处理（例如，灰度化）或来自不同的X射线机，这就足够了。
- en: 'Duplicates: Some images might have ended up both in training and test data,
    making the model seem to work better than it does.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复：一些图像可能同时出现在训练数据和测试数据中，使得模型看起来比实际表现更好。
- en: Even if you find a model that perfectly predicts identically distributed data,
    the models can’t be used. No application comes with a data distribution anywhere
    identical to this mess.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你找到一个完美预测相同分布数据的模型，这些模型也无法使用。没有哪种应用的数据分布与这种混乱完全相同。
- en: 'In general, to generalize from training to application, you want the data-generating
    process considered in training to be as similar as possible to the one during
    deployment. It is difficult. The world is even messier than what we described
    here and there are many more challenges to generalization in practice:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，为了从训练泛化到应用，你希望训练中考虑到的数据生成过程尽可能类似于部署期间的过程。这是困难的。世界甚至比我们描述的还要混乱，而且在实践中有许多更多关于泛化的挑战：
- en: '**Distribution Shifts:** Imagine someone building a pneumonia classifier before
    COVID-19\. COVID introduced a new type of pneumonia and due to lockdowns and social
    distancing, other types of pneumonia occurred less frequently. A massive distribution
    shift may worsen the performance of existing models. Distribution shifts are discussed
    in [Chapter 11](robustness.html).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布偏移**：想象一下在 COVID-19 之前有人构建肺炎分类器。COVID 引入了新的肺炎类型，由于封锁和社会距离，其他类型的肺炎发生的频率较低。大规模的分布偏移可能会降低现有模型的表现。分布偏移在
    [第 11 章](robustness.html) 中讨论。'
- en: '**Non-causal models:** The more a model relies on associations but not causes,
    the worse it might generalize. See [Chapter 10](causality.html).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非因果模型**：模型越依赖于关联而不是原因，其泛化能力可能越差。参见 [第 10 章](causality.html)。'
- en: '**Using an unsuitable evaluation metric:** While this may not show up in a
    low test error, picking a metric that doesn’t reflect the application task well
    will result in a model that transfers poorly to the real-world setting.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用不合适的评估指标**：虽然这可能在低测试误差中不明显，但选择一个不能很好地反映应用任务的指标将导致模型在现实世界设置中表现不佳。'
- en: 7.3 Generalization to understand a phenomenon
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 将泛化应用于理解现象
- en: Generalization to predict other data is one thing, but especially in science
    you often want to generalize insights from the model to the phenomenon you are
    studying. In more statistical terms this is about generalizing from a data sample
    to a larger population.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 将泛化应用于预测其他数据是一回事，但特别是在科学领域，你通常希望将模型中的洞察力泛化到你正在研究的现象。在更统计学的术语中，这是从数据样本泛化到更大群体的过程。
- en: Generalization of insights may even come in innocent ways that we don’t immediately
    recognize. For example, Rajpurkar et al. [[13]](references.html#ref-rajpurkar2017chexnet)
    claimed that their X-ray classifier performs on par with radiologists, even outperforming
    them on certain metrics. We could say they only refer to the test data and leave
    it at that. However, nobody is interested in the test data, but in the population
    they represent. Like a sample of X-rays taken typically in the emergency room.
    Unfortunately, the paper doesn’t define the population, which is typical for machine
    learning papers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 洞察力的泛化甚至可能以我们立即没有意识到的方式出现。例如，Rajpurkar 等人 [[13]](references.html#ref-rajpurkar2017chexnet)
    声称，他们的 X 射线分类器在性能上与放射科医生相当，甚至在某些指标上超过了他们。我们可以说他们只提到了测试数据，就到此为止。然而，没有人对测试数据感兴趣，而是对它们所代表的群体感兴趣。就像通常在急诊室拍摄的
    X 射线样本一样。不幸的是，论文没有定义这个群体，这在机器学习论文中很典型。
- en: 'When a researcher studies a phenomenon using machine learning and interpretability,
    such as the effect of fertilizers on almond yield (like [[16]](references.html#ref-zhang2019california)),
    they are also generalizing. They generalize, explicitly or implicitly, from their
    model and data to a larger context. Quoting from the abstract of [[16]](references.html#ref-zhang2019california):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当研究人员使用机器学习和可解释性来研究一个现象，例如肥料对杏仁产量的影响（如 [[16]](references.html#ref-zhang2019california)），他们也在进行泛化。他们明确或隐含地从他们的模型和数据泛化到一个更大的背景。引用
    [[16]](references.html#ref-zhang2019california) 的摘要：
- en: We also identified several key determinants of yield based on the modeling results.
    Almond yield increased dramatically with the orchard age until about 7 years old
    in general, and the higher long-term mean maximum temperature during April–June
    enhanced the yield in the southern orchards, while a larger amount of precipitation
    in March reduced the yield, especially in northern orchards.
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们还根据建模结果确定了几个影响产量的关键因素。一般来说，杏仁产量在果园年龄达到约7岁时显著增加，而在4月至6月期间较高的长期平均最高温度增强了南部果园的产量，而3月份的降水量增加则降低了产量，尤其是在北部果园。
- en: The larger context depends on what the data *represents*. In the case of the
    fertilizer study, this might be all the 6,000 [[17]](references.html#ref-california)
    orchards in California. Or maybe it is just the ones in Central Valley? It depends
    on how representative the dataset is. The word representativeness or especially
    representative data is overloaded and people use it differently in machine learning
    [[18]](references.html#ref-clemmensen2023data) and science [[19]](references.html#ref-chasalow2021representativeness).
    In the broadest sense, “representativeness concerns the ability of one thing to
    stand for another—a sample for a population, an instance for a category” [[19]](references.html#ref-chasalow2021representativeness).
    In machine learning some claim representativeness without argument, some claim
    non-representativeness because of selection biases, some mean that the sample
    is a random sample from the distribution, and some claim coverage in the sense
    that all relevant groups are covered (maybe not in the same frequency as target
    population though), some speak of it as prototypes and archetypes. But for science
    and especially for the goal of inference – to draw conclusions about the real
    world – you need the data to represent the target population, in the sense of
    the training data being a random sample from the population.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的背景取决于数据*代表*什么。在肥料研究的案例中，这可能是加利福尼亚州所有的6,000个 [[17]](references.html#ref-california)
    果园。或者也许只是中央谷地的那些？这取决于数据集的代表性。代表性这个词，尤其是代表性数据，被过度使用，人们在机器学习和科学 [[18]](references.html#ref-clemmensen2023data)
    中有不同的使用方式。在最广泛的意义上，“代表性涉及一个事物代表另一个事物的能力——样本代表人群，实例代表类别” [[19]](references.html#ref-chasalow2021representativeness)。在机器学习中，有些人未经论证就声称具有代表性，有些人因为选择偏差而声称不具有代表性，有些人意味着样本是从分布中随机抽取的，有些人声称覆盖了所有相关群体（尽管可能不是以与目标人群相同的频率），有些人将其称为原型和典范。但科学，尤其是为了推断的目的——对现实世界进行推断——你需要数据代表目标人群，即训练数据是从人群中随机抽取的。
- en: In an ideal world, you start with your research question and define the population.
    Then you draw a perfectly representative sample because you can just randomly
    sample from the population, as easy as buying fresh bread in Germany. But that’s
    often far from reality.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个理想的世界里，你从你的研究问题开始，定义你的目标人群。然后你抽取一个完全具有代表性的样本，因为你可以从人群中随机抽取，就像在德国买新鲜面包一样简单。但现实往往远非如此。
- en: The other way would be to start with a dataset, argue which population it represents,
    and extend insights to this population. And sometimes it is a mixture of bottom-up
    and top-down approaches. Zhang et al. [[16]](references.html#ref-zhang2019california),
    for example, describes that they collected data from the 8 major growers that
    make up 185 orchards in the Central Valley of California. Some in the northern,
    some in the central, and some in the southern region. However, they do not discuss
    whether their sample of orchards is representative, so it is unclear what to make
    of the results.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是先从一个数据集开始，争论它代表了哪个群体，并将洞察力扩展到这个群体。有时它可能是自下而上和自上而下方法的混合。例如，张等人 [[16]](references.html#ref-zhang2019california)
    描述了他们从加利福尼亚中央谷地的8个主要种植者那里收集数据，这些种植者共拥有185个果园。一些位于北部，一些位于中部，一些位于南部地区。然而，他们并没有讨论他们的果园样本是否具有代表性，因此结果如何尚不清楚。
- en: 'Proving that your data is representative is difficult to impossible. If you
    know the population statistics, you can at least compare summary statistics between
    the training set and the population. As always, it is easier to disprove something:
    finding a single counter-argument is enough. For representativeness, the counter-arguments
    are called “selection biases”. Selection biases are like forces in your collection
    process that either exclude or at least undersample some groups or over-emphasize
    others. Selection bias is a good angle to view the collection process. If you
    have identified a selection bias, you can discuss its severity and maybe even
    counter it by weighting your samples. Some examples of selection biases include:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 证明你的数据具有代表性是困难的，甚至是不可能的。如果你知道人群的统计数据，你至少可以比较训练集和人群之间的汇总统计数据。正如往常一样，反驳某事更容易：找到一个反例就足够了。对于代表性，反例被称为“选择偏差”。选择偏差就像你在收集过程中的力量，要么排除某些群体，至少是抽样不足，要么过分强调其他群体。选择偏差是观察收集过程的一个好角度。如果你已经识别出选择偏差，你可以讨论其严重性，甚至可以通过加权你的样本来反驳它。选择偏差的一些例子包括：
- en: 'Survivorship bias: The sample only includes “survivors” or those whose objects/subjects
    passed a selection process.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存活者偏差：样本只包括“存活者”或那些其对象/主题通过了选择过程的人。
- en: 'Non-response bias: Human respondents can differ in meaningful ways from non-respondents.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无应答偏差：人类受访者可能以有意义的方式与非受访者不同。
- en: 'Exclusion bias: Some exclusion mechanism (e.g., due to missing data) biases
    the sample.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排除偏差：某些排除机制（例如，由于缺失数据）会偏样本。
- en: 7.4 No free lunch in generalization
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 泛化中的免费午餐
- en: 'We structured this chapter along three types of generalization: to predict
    in theory, to predict in practice, and to understand a phenomenon. One of the
    most well-known theoretical results – the so-called no-free lunch theorems – has
    taught us that generalization never comes for free [[20]](references.html#ref-wolpert1996lack).
    All versions of the theorems highlight the following: You will never have an ultimate
    learning algorithm that always spits out the best possible prediction model [[21]](references.html#ref-shalev2014understanding).
    You must take an *inductive leap* to generalize from a data sample to anything
    beyond itself. Like making context-specific assumptions (e.g. smoothness or IID)
    [[22]](references.html#ref-sterkenburg2021no). There ain’t no such thing as a
    free lunch, if you want to eat different meals, you need different cooking recipes.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将本章结构化为三种泛化类型：理论预测、实践预测和理解现象。最著名的理论结果之一——所谓的“免费午餐定理”——告诉我们，泛化从来都不是免费的[[20]](references.html#ref-wolpert1996lack)。所有定理版本都强调了以下内容：你永远不会有一个终极学习算法，它总是输出最佳可能的预测模型[[21]](references.html#ref-shalev2014understanding)。你必须进行*归纳跳跃*，从数据样本泛化到其本身之外的内容。就像做出特定情境的假设（例如平滑性或独立同分布）[[22]](references.html#ref-sterkenburg2021no)。如果你想要吃不同的饭菜，你需要不同的烹饪食谱，免费午餐是不存在的。
- en: And, unfortunately, there is no free dessert either. Even if you have a model
    that generalizes well to identically distributed data, you have to “pay” for any
    further generalization. When it comes to generalization from training to application
    or from sample to population, you need to make even more assumptions and put in
    extra effort. And sometimes you might not achieve them after all. Generalization
    is never free.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，免费甜点也没有。即使你有一个泛化到相同分布数据的模型，你也必须“支付”任何进一步的泛化成本。当从训练到应用或从样本到总体进行泛化时，你需要做出更多的假设并付出额外的努力。有时你可能最终无法实现它们。泛化从来都不是免费的。
- en: 'The cost of generalization comes up in other chapters as well:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 泛化的成本在其他章节也有所提及：
- en: When interpreting the model for the goal of understanding the phenomenon of
    interest, you make assumptions about representativeness for example (see also
    [Chapter 9](interpretability.html))
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当解释模型以理解感兴趣的现象为目标时，你会做出关于代表性等方面的假设，例如（参见[第9章](interpretability.html)）
- en: For causal inference, you make assumptions about the causal structures in the
    world ([Chapter 10](causality.html))
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于因果推断，你对世界中的因果关系结构做出假设（[第10章](causality.html)）
- en: Robustness is about guarding your models against distribution shifts ([Chapter
    11](robustness.html))
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健壮性是关于保护你的模型免受分布变化的影响（[第11章](robustness.html)）
- en: '[1]M. Hardt and B. Recht, *Patterns, predictions, and actions: Foundations
    of machine learning*. Princeton University Press, 2022.[2]G. Cybenko, “Approximation
    by superpositions of a sigmoidal function,” *Mathematics of control, signals and
    systems*, vol. 2, no. 4, pp. 303–314, 1989, doi: [10.1007/BF02551274](https://doi.org/10.1007/BF02551274).[3]K.
    Hornik, “Approximation capabilities of multilayer feedforward networks,” *Neural
    networks*, vol. 4, no. 2, pp. 251–257, 1991, doi: [10.1016/0893-6080(91)90009-T](https://doi.org/10.1016/0893-6080(91)90009-T).[4]P.
    R. Halmos, *Measure theory*, vol. 18\. Springer, 2013\. doi: [10.1007/978-1-4684-9440-2](https://doi.org/10.1007/978-1-4684-9440-2).[5]I.
    Goodfellow, Y. Bengio, and A. Courville, *Deep learning*. MIT press, 2016.[6]M.
    Belkin, D. Hsu, S. Ma, and S. Mandal, “Reconciling modern machine-learning practice
    and the classical bias–variance trade-off,” *Proceedings of the National Academy
    of Sciences of the United States of America*, vol. 116, no. 32, pp. 15849–15854,
    Aug. 2019, doi: [10.1073/pnas.1903070116](https://doi.org/10.1073/pnas.1903070116).[7]J.
    W. Rocks and P. Mehta, “Memorizing without overfitting: Bias, variance, and interpolation
    in overparameterized models,” *Physical review research*, vol. 4, no. 1, p. 013201,
    2022, doi: [10.1103/PhysRevResearch.4.013201](https://doi.org/10.1103/PhysRevResearch.4.013201).[8]R.
    Schaeffer *et al.*, “Double Descent Demystified: Identifying, Interpreting & Ablating
    the Sources of a Deep Learning Puzzle.” arXiv, Mar. 2023\. doi: [10.48550/arXiv.2303.14151](https://doi.org/10.48550/arXiv.2303.14151).[9]A.
    Curth, A. Jeffares, and M. van der Schaar, “A u-turn on double descent: Rethinking
    parameter counting in statistical learning,” *Advances in Neural Information Processing
    Systems*, vol. 36, 2024.[10]J. Frankle and M. Carbin, “The Lottery Ticket Hypothesis:
    Finding Sparse, Trainable Neural Networks.” arXiv, Mar. 2019\. doi: [10.48550/arXiv.1803.03635](https://doi.org/10.48550/arXiv.1803.03635).[11]P.
    L. Bartlett, P. M. Long, G. Lugosi, and A. Tsigler, “Benign Overfitting in Linear
    Regression,” *Proceedings of the National Academy of Sciences*, vol. 117, no.
    48, pp. 30063–30070, Dec. 2020, doi: [10.1073/pnas.1907378117](https://doi.org/10.1073/pnas.1907378117).[12]S.
    L. Smith, B. Dherin, D. G. Barrett, and S. De, “On the origin of implicit regularization
    in stochastic gradient descent,” *arXiv preprint arXiv:2101.12176*, 2021, doi:
    [10.48550/arXiv.2101.12176](https://doi.org/10.48550/arXiv.2101.12176).[13]P.
    Rajpurkar *et al.*, “CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays
    with Deep Learning.” arXiv, Dec. 2017\. doi: [10.48550/arXiv.1711.05225](https://doi.org/10.48550/arXiv.1711.05225).[14]L.
    Wynants *et al.*, “Prediction models for diagnosis and prognosis of covid-19:
    Systematic review and critical appraisal,” *BMJ (Clinical research ed.)*, vol.
    369, p. m1328, Apr. 2020, doi: [10.1136/bmj.m1328](https://doi.org/10.1136/bmj.m1328).[15]M.
    Roberts *et al.*, “Common pitfalls and recommendations for using machine learning
    to detect and prognosticate for COVID-19 using chest radiographs and CT scans,”
    *Nature Machine Intelligence*, vol. 3, no. 3, pp. 199–217, 2021, doi: [10.1038/s42256-021-00307-0](https://doi.org/10.1038/s42256-021-00307-0).[16]Z.
    Zhang, Y. Jin, B. Chen, and P. Brown, “California almond yield prediction at the
    orchard level with a machine learning approach,” *Frontiers in plant science*,
    vol. 10, p. 809, 2019, doi: [10.3389/fpls.2019.00809/full](https://doi.org/10.3389/fpls.2019.00809/full).[17]“The
    California Almond.” Accessed: Feb. 16, 2024\. [Online]. Available: [https://www.waterfordnut.com/almond.html](https://www.waterfordnut.com/almond.html)[18]L.
    H. Clemmensen and R. D. Kjærsgaard, “Data Representativity for Machine Learning
    and AI Systems.” arXiv, Feb. 2023\. Accessed: Feb. 07, 2024\. [Online]. Available:
    [http://arxiv.org/abs/2203.04706](http://arxiv.org/abs/2203.04706)[19]K. Chasalow
    and K. Levy, “Representativeness in Statistics, Politics, and Machine Learning,”
    in *Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency*,
    in FAccT ’21\. New York, NY, USA: Association for Computing Machinery, Mar. 2021,
    pp. 77–89\. doi: [10.1145/3442188.3445872](https://doi.org/10.1145/3442188.3445872).[20]D.
    H. Wolpert, “The lack of a priori distinctions between learning algorithms,” *Neural
    computation*, vol. 8, no. 7, pp. 1341–1390, 1996, doi: [10.1162/neco.1996.8.7.1341](https://doi.org/10.1162/neco.1996.8.7.1341).[21]S.
    Shalev-Shwartz and S. Ben-David, *Understanding machine learning: From theory
    to algorithms*. Cambridge university press, 2014\. doi: [10.1017/CBO9781107298019](https://doi.org/10.1017/CBO9781107298019).[22]T.
    F. Sterkenburg and P. D. Grünwald, “The no-free-lunch theorems of supervised learning,”
    *Synthese*, vol. 199, no. 3, pp. 9979–10015, 2021, doi: [10.1007/s11229-021-03233-1](https://doi.org/10.1007/s11229-021-03233-1).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]M. Hardt 和 B. Recht, 《模式、预测和行动：机器学习基础*》。普林斯顿大学出版社，2022年。[2]G. Cybenko, “通过Sigmoid函数的叠加近似,”
    *控制、信号与系统数学*, 第2卷，第4期，第303–314页，1989年，doi: [10.1007/BF02551274](https://doi.org/10.1007/BF02551274)。[3]K.
    Hornik, “多层前馈网络的逼近能力,” *神经网络*, 第4卷，第2期，第251–257页，1991年，doi: [10.1016/0893-6080(91)90009-T](https://doi.org/10.1016/0893-6080(91)90009-T)。[4]P.
    R. Halmos, 《测度论*》。第18卷。Springer，2013年。doi: [10.1007/978-1-4684-9440-2](https://doi.org/10.1007/978-1-4684-9440-2)。[5]I.
    Goodfellow, Y. Bengio, 和 A. Courville, 《深度学习*》。麻省理工学院出版社，2016年。[6]M. Belkin, D.
    Hsu, S. Ma, 和 S. Mandal, “调和现代机器学习实践与经典偏差-方差权衡,” *美国国家科学院院刊*, 第116卷，第32期，第15849–15854页，2019年8月，doi:
    [10.1073/pnas.1903070116](https://doi.org/10.1073/pnas.1903070116)。[7]J. W. Rocks
    和 P. Mehta, “无过拟合的记忆：过参数化模型中的偏差、方差和插值,” *物理评论研究*, 第4卷，第1期，第013201号，2022年，doi:
    [10.1103/PhysRevResearch.4.013201](https://doi.org/10.1103/PhysRevResearch.4.013201)。[8]R.
    Schaeffer 等人， “双下降之谜揭秘：识别、解释和消除深度学习难题的来源。” arXiv，2023年3月。doi: [10.48550/arXiv.2303.14151](https://doi.org/10.48550/arXiv.2303.14151)。[9]A.
    Curth, A. Jeffares, 和 M. van der Schaar, “对双下降的反思：重新思考统计学习中的参数计数,” *神经信息处理系统进展*,
    第36卷，2024年。[10]J. Frankle 和 M. Carbin, “彩票假设：寻找稀疏、可训练的神经网络。” arXiv，2019年3月。doi:
    [10.48550/arXiv.1803.03635](https://doi.org/10.48550/arXiv.1803.03635)。[11]P.
    L. Bartlett, P. M. Long, G. Lugosi, 和 A. Tsigler, “线性回归中的良性过拟合,” *美国国家科学院院刊*,
    第117卷，第48期，第30063–30070页，2020年12月，doi: [10.1073/pnas.1907378117](https://doi.org/10.1073/pnas.1907378117)。[12]S.
    L. Smith, B. Dherin, D. G. Barrett, 和 S. De, “关于随机梯度下降中隐式正则化的起源,” *arXiv预印本arXiv:2101.12176*,
    2021年，doi: [10.48550/arXiv.2101.12176](https://doi.org/10.48550/arXiv.2101.12176)。[13]P.
    Rajpurkar 等人， “CheXNet：使用深度学习在胸部X光片上进行放射科水平的肺炎检测。” arXiv，2017年12月。doi: [10.48550/arXiv.1711.05225](https://doi.org/10.48550/arXiv.1711.05225)。[14]L.
    Wynants 等人， “用于诊断和预后COVID-19的预测模型：系统评价和批判性评估,” *BMJ (临床研究版)*, 第369卷，第m1328号，2020年4月，doi:
    [10.1136/bmj.m1328](https://doi.org/10.1136/bmj.m1328)。[15]M. Roberts 等人， “使用胸部X光片和CT扫描检测和预测COVID-19的常见陷阱和建议,”
    *自然机器智能*, 第3卷，第3期，第199–217页，2021年，doi: [10.1038/s42256-021-00307-0](https://doi.org/10.1038/s42256-021-00307-0)。[16]Z.
    Zhang, Y. Jin, B. Chen, 和 P. Brown, “使用机器学习方法在果园水平上预测加利福尼亚杏仁产量,” *植物科学前沿*, 第10卷，第809页，2019年，doi:
    [10.3389/fpls.2019.00809/full](https://doi.org/10.3389/fpls.2019.00809/full)。[17]“加利福尼亚杏仁。”
    访问日期：2024年2月16日。[在线]。可获得：[https://www.waterfordnut.com/almond.html](https://www.waterfordnut.com/almond.html)[18]L.
    H. Clemmensen 和 R. D. Kjærsgaard, “机器学习和人工智能系统的数据代表性。” arXiv，2023年2月。访问日期：2024年2月7日。[在线]。可获得：[http://arxiv.org/abs/2203.04706](http://arxiv.org/abs/2203.04706)[19]K.
    Chasalow 和 K. Levy, “统计学、政治和机器学习中的代表性，” 在 *2021年ACM公平性、问责制和透明度会议论文集* 中，FAccT ''21。纽约，NY，USA：计算机协会，2021年3月，第77–89页。doi:
    [10.1145/3442188.3445872](https://doi.org/10.1145/3442188.3445872)。[20]D. H. Wolpert,
    “学习算法之间缺乏先验区分，” *神经计算*, 第8卷，第7期，第1341–1390页，1996年，doi: [10.1162/neco.1996.8.7.1341](https://doi.org/10.1162/neco.1996.8.7.1341)。[21]S.
    Shalev-Shwartz 和 S. Ben-David, 《理解机器学习：从理论到算法*》。剑桥大学出版社，2014年。doi: [10.1017/CBO9781107298019](https://doi.org/10.1017/CBO9781107298019)。[22]T.
    F. Sterkenburg 和 P. D. Grünwald, “监督学习的无免费午餐定理，” *综合*, 第199卷，第3期，第9979–10015页，2021年，doi:
    [10.1007/s11229-021-03233-1](https://doi.org/10.1007/s11229-021-03233-1)。'
- en: '* * *'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Confusingly, the generalization gap is sometimes referred to as the generalization
    error.[↩︎](#fnref1)
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 令人困惑的是，泛化差距有时也被称为泛化误差。[↩︎](#fnref1)
