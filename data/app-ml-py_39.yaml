- en: Machine Learning Glossary
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æœ¯è¯­è¡¨
- en: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_glossary.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_glossary.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_glossary.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_glossary.html)
- en: Michael J. Pyrcz, Professor, The University of Texas at Austin
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·JÂ·çš®å°”èŒ¨ï¼Œæ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
- en: 'Chapter of e-book â€œApplied Geostatistics in Python: a Hands-on Guide with GeostatsPyâ€.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç”µå­ä¹¦â€œPythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ï¼šGeostatsPyå®è·µæŒ‡å—â€çš„ä¸€ç« ã€‚
- en: 'Cite this e-Book as:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å°†æ­¤ç”µå­ä¹¦å¼•ç”¨å¦‚ä¸‹ï¼š
- en: 'Pyrcz, M.J., 2024, Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy,
    [https://geostatsguy.github.io/GeostatsPyDemos_Book](https://geostatsguy.github.io/GeostatsPyDemos_Book).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pyrcz, M.J., 2024, Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ï¼šGeostatsPyå®è·µæŒ‡å—ï¼Œ[https://geostatsguy.github.io/GeostatsPyDemos_Book](https://geostatsguy.github.io/GeostatsPyDemos_Book)ã€‚
- en: 'The workflows in this book and more are available here:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦ä¸­çš„å·¥ä½œæµç¨‹ä»¥åŠæ›´å¤šå†…å®¹å¯åœ¨ä»¥ä¸‹é“¾æ¥æ‰¾åˆ°ï¼š
- en: 'Cite the GeostatsPyDemos GitHub Repository as:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å°†GeostatsPyDemos GitHubä»“åº“å¼•ç”¨å¦‚ä¸‹ï¼š
- en: 'Pyrcz, M.J., 2024, GeostatsPyDemos: GeostatsPy Python Package for Spatial Data
    Analytics and Geostatistics Demonstration Workflows Repository (0.0.1). Zenodo.
    [https://zenodo.org/doi/10.5281/zenodo.12667035](https://zenodo.org/doi/10.5281/zenodo.12667035)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'Pyrcz, M.J., 2024, GeostatsPyDemos: GeostatsPy Python Package for Spatial Data
    Analytics and Geostatistics Demonstration Workflows Repository (0.0.1). Zenodo.
    [https://zenodo.org/doi/10.5281/zenodo.12667035](https://zenodo.org/doi/10.5281/zenodo.12667035)'
- en: '[![DOI](../Images/16a74734a4e89db11a986fb62be91669.png)](https://zenodo.org/doi/10.5281/zenodo.12667035)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[![DOI](../Images/16a74734a4e89db11a986fb62be91669.png)](https://zenodo.org/doi/10.5281/zenodo.12667035)'
- en: By Michael J. Pyrcz
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ï¼šè¿ˆå…‹å°”Â·JÂ·çš®å°”èŒ¨
- en: Â© Copyright 2024.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Â© ç‰ˆæƒæ‰€æœ‰ 2024ã€‚
- en: This chapter is a summary of essential **Machine Learning Terminology**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« æ˜¯**æœºå™¨å­¦ä¹ æœ¯è¯­**çš„æ‘˜è¦ã€‚
- en: Motivation for Machine Learning Concepts
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ¦‚å¿µçš„åŠ¨åŠ›
- en: Firstly, why do this? I have received the request for a course glossary from
    the students in my **Subsurface Machine Learning** combined undergraduate and
    graduate course. While I usually dedicate a definition slide in the lecture slide
    decks for salient terms, some of my students have requested course glossary, list
    of terminology for their course review. The e-book provides a great vehicle and
    motivation to finally complete this.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œä¸ºä»€ä¹ˆè¦åšè¿™ä»¶äº‹å‘¢ï¼Ÿæˆ‘æ”¶åˆ°äº†æ¥è‡ªæˆ‘çš„**åœ°ä¸‹æœºå™¨å­¦ä¹ **æœ¬ç§‘å’Œç ”ç©¶ç”Ÿè¯¾ç¨‹çš„å­¦ç”Ÿçš„è¯¾ç¨‹æœ¯è¯­è¡¨è¯·æ±‚ã€‚è™½ç„¶æˆ‘é€šå¸¸åœ¨è®²ä¹‰ä¸­ä¸ºæ˜¾è‘—æœ¯è¯­æä¾›å®šä¹‰å¹»ç¯ç‰‡ï¼Œä½†ä¸€äº›å­¦ç”Ÿè¦æ±‚è¯¾ç¨‹æœ¯è¯­è¡¨ï¼Œä»¥ä¾¿ä»–ä»¬è¿›è¡Œè¯¾ç¨‹å¤ä¹ ã€‚è¿™æœ¬ç”µå­ä¹¦æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„å·¥å…·å’ŒåŠ¨åŠ›ï¼Œæœ€ç»ˆå®Œæˆäº†è¿™é¡¹å·¥ä½œã€‚
- en: Let me begin with a confession. There is a [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary)
    written by Google developers. For those seeking the in depth, comprehensive list
    of geostatistical terms please use this book!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»ä¸€é¡¹å¦ç™½å¼€å§‹ã€‚æœ‰ä¸€ä¸ªç”±è°·æ­Œå¼€å‘è€…ç¼–å†™çš„[æœºå™¨å­¦ä¹ æœ¯è¯­è¡¨](https://developers.google.com/machine-learning/glossary)ã€‚å¯¹äºé‚£äº›å¯»æ±‚æ·±å…¥ã€å…¨é¢çš„åœ°ç†ç»Ÿè®¡æœ¯è¯­åˆ—è¡¨ï¼Œè¯·ä½¿ç”¨è¿™æœ¬ä¹¦ï¼
- en: By writing my own glossary I can limit the scope and descriptions to course
    content. I fear that many students would be overwhelmed by the size and mathematical
    notation of a standard machine learning glossary.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ç¼–å†™è‡ªå·±çš„æœ¯è¯­è¡¨ï¼Œæˆ‘å¯ä»¥å°†èŒƒå›´å’Œæè¿°é™åˆ¶åœ¨è¯¾ç¨‹å†…å®¹å†…ã€‚æˆ‘æ‹…å¿ƒè®¸å¤šå­¦ç”Ÿä¼šå› ä¸ºæ ‡å‡†æœºå™¨å­¦ä¹ æœ¯è¯­è¡¨çš„å¤§å°å’Œæ•°å­¦ç¬¦å·è€Œæ„Ÿåˆ°ä¸çŸ¥æ‰€æªã€‚
- en: Also, by including a glossary in the e-book I can link from glossary entries
    to the chapters in the e-book for convenience. I will eventual populate all the
    chapters with hyperlinks to the glossary to enable moving back and forth between
    the chapters and the glossary.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œé€šè¿‡åœ¨ç”µå­ä¹¦ä¸­åŒ…å«æœ¯è¯­è¡¨ï¼Œæˆ‘å¯ä»¥ä»æœ¯è¯­è¡¨æ¡ç›®é“¾æ¥åˆ°ç”µå­ä¹¦ä¸­çš„ç« èŠ‚ï¼Œä»¥ä¾¿äºæŸ¥é˜…ã€‚æˆ‘æœ€ç»ˆå°†æ‰€æœ‰ç« èŠ‚éƒ½æ·»åŠ åˆ°æœ¯è¯­è¡¨çš„è¶…é“¾æ¥ï¼Œä»¥ä¾¿åœ¨ç« èŠ‚å’Œæœ¯è¯­è¡¨ä¹‹é—´æ¥å›ç§»åŠ¨ã€‚
- en: Finally, like the rest of the book, I want the glossary to be a evergreen living
    document.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œåƒæœ¬ä¹¦çš„å…¶ä»–éƒ¨åˆ†ä¸€æ ·ï¼Œæˆ‘å¸Œæœ›æœ¯è¯­è¡¨æˆä¸ºä¸€ä¸ªæ°¸è‘†é’æ˜¥çš„æ´»æ–‡æ¡£ã€‚
- en: '**Adjacency Matrix** (spectral clustering)'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é‚»æ¥çŸ©é˜µ**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph with the pairwise connections between all pairwise combinations of graph
    nodes, samples.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šè¡¨ç¤ºå›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹æˆå¯¹ç»„åˆä¹‹é—´æˆå¯¹è¿æ¥çš„çŸ©é˜µã€‚'
- en: the values are indicators, 0 if not connected, 1 if connected
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›å€¼æ˜¯æŒ‡ç¤ºç¬¦ï¼Œå¦‚æœä¸è¿æ¥åˆ™ä¸º 0ï¼Œå¦‚æœè¿æ¥åˆ™ä¸º 1
- en: Note, node self connections are set to 0 in the adjacency matrix
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨é‚»æ¥çŸ©é˜µä¸­ï¼ŒèŠ‚ç‚¹è‡ªè¿æ¥è¢«è®¾ç½®ä¸º 0
- en: '**Addition Rule** (probability)'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŠ æ³•è§„åˆ™**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): when we add probabilities
    (the union of outcomes), the probability of \(A\) or \(B\) is calculated with
    the probability addition rule,'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šå½“æˆ‘ä»¬æ·»åŠ æ¦‚ç‡ï¼ˆç»“æœçš„å¹¶é›†ï¼‰æ—¶ï¼Œ\(A\) æˆ– \(B\) çš„æ¦‚ç‡æ˜¯æ ¹æ®æ¦‚ç‡åŠ æ³•è§„åˆ™è®¡ç®—çš„ï¼Œ'
- en: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
- en: given mutually exclusive events we can generalize the addition rule as,
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºäº’æ–¥äº‹ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†åŠ æ³•è§„åˆ™æ¨å¹¿ä¸ºï¼Œ
- en: \[ P\left( \bigcup_{i=1}^k A_i \right) = \sum_{i=1}^k P(A_i) \]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P\left( \bigcup_{i=1}^k A_i \right) = \sum_{i=1}^k P(A_i) \]
- en: '**Affine Correction**'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä»¿å°„æ ¡æ­£**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    distribution rescaling that can be thought of as shifting, and stretching or squeezing
    of a univariate distribution (e.g., *histogram*). For the case of affine correction
    of \(X\) to \(Y\),'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§åˆ†å¸ƒç¼©æ”¾ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºå•å˜é‡åˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œ*ç›´æ–¹å›¾*ï¼‰çš„å¹³ç§»ã€æ‹‰ä¼¸æˆ–å‹ç¼©ã€‚å¯¹äºå°†
    \(X\) å‘ \(Y\) è¿›è¡Œä»¿å°„æ ¡æ­£çš„æƒ…å†µï¼Œ'
- en: \[ y_i = \frac{\sigma_y}{\sigma_x}(x_i - \overline{x}) + \overline{y}, \quad
    \forall \quad i, \ldots, n \]
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{\sigma_y}{\sigma_x}(x_i - \overline{x}) + \overline{y}, \quad
    \forall \quad i, \ldots, n \]
- en: where \(\overline{x}\) and \(\sigma_x\) are the original mean and variance,
    and \(\overline{y}\) and \(\sigma_y\) are the new mean and variance.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\sigma_x\) æ˜¯åŸå§‹å‡å€¼å’Œæ–¹å·®ï¼Œè€Œ \(\overline{y}\) å’Œ \(\sigma_y\)
    æ˜¯æ–°çš„å‡å€¼å’Œæ–¹å·®ã€‚
- en: We can see above that the affine correlation method first centers the distribution
    (by subtracting the original mean), then rescales the dispersion (distribution
    spread) by the ratio of the new standard deviation to the original standard deviation
    and then shifts the distribution to centered on the new mean.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä»¿å°„ç›¸å…³æ–¹æ³•é¦–å…ˆå°†åˆ†å¸ƒä¸­å¿ƒåŒ–ï¼ˆé€šè¿‡å‡å»åŸå§‹å‡å€¼ï¼‰ï¼Œç„¶åé€šè¿‡æ–°æ ‡å‡†å·®ä¸åŸå§‹æ ‡å‡†å·®çš„æ¯”ä¾‹æ¥ç¼©æ”¾åˆ†æ•£åº¦ï¼ˆåˆ†å¸ƒèŒƒå›´ï¼‰ï¼Œç„¶åå°†åˆ†å¸ƒå¹³ç§»åˆ°æ–°çš„å‡å€¼ä¸­å¿ƒã€‚
- en: there is no shape change for affine correction. For shape change consider *Distribution
    Transformation* like *Gaussian Anamorphosis*.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¿å°„æ ¡æ­£æ²¡æœ‰å½¢çŠ¶å˜åŒ–ã€‚å¯¹äºå½¢çŠ¶å˜åŒ–ï¼Œå¯ä»¥è€ƒè™‘åƒ *é«˜æ–¯å˜å½¢* è¿™æ ·çš„ *åˆ†å¸ƒå˜æ¢*ã€‚
- en: '**Affinity Matrix** (spectral clustering)'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº²å’ŒçŸ©é˜µ**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph with the degree of pairwise connections between all pairwise combinations
    of graph nodes, samples.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šè¡¨ç¤ºå›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹æˆå¯¹ç»„åˆä¹‹é—´æˆå¯¹è¿æ¥ç¨‹åº¦çš„çŸ©é˜µã€‚'
- en: values indicate the strength of the connection, unlike adjacency matrix with
    indicators, 0 if not connected, 1 if connected
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›å€¼è¡¨ç¤ºè¿æ¥çš„å¼ºåº¦ï¼Œä¸æŒ‡ç¤ºç¬¦é‚»æ¥çŸ©é˜µä¸åŒï¼Œå¦‚æœä¸è¿æ¥åˆ™ä¸º 0ï¼Œå¦‚æœè¿æ¥åˆ™ä¸º 1
- en: Note, node self connections are set to 0 in the adjacency matrix
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨é‚»æ¥çŸ©é˜µä¸­ï¼ŒèŠ‚ç‚¹è‡ªè¿æ¥è¢«è®¾ç½®ä¸º 0
- en: '**Bagging Models**'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Bagging æ¨¡å‹**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): the
    application of bootstrap to obtain data realizations,'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bagging æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šå°†è‡ªåŠ©æ³•åº”ç”¨äºè·å¾—æ•°æ®å®ç°ï¼Œ'
- en: \[ Y^b, X_1^b, \dots, X_m^b, \quad b = 1, \dots, B \]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y^b, X_1^b, \dots, X_m^b, \quad b = 1, \dots, B \]
- en: to train predictive model realizations,
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥è®­ç»ƒé¢„æµ‹æ¨¡å‹å®ç°ï¼Œ
- en: \(\hat{Y}^b = \hat{f}^b (X_1^b, \dots, X_m^b)\)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{Y}^b = \hat{f}^b (X_1^b, \dots, X_m^b)\)
- en: where,
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ
- en: \((X_1^b, \dots, X_m^b)\) - the bootstrap predictor features in the \(b^{th}\)
    bootstrapped dataset
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \((X_1^b, \dots, X_m^b)\) - ç¬¬ \(b\) ä¸ªè‡ªåŠ©æ•°æ®é›†ä¸­çš„è‡ªåŠ©é¢„æµ‹ç‰¹å¾
- en: \(\hat{f}^b\) - the \(b^{th}\) bootstrapped model
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{f}^b\) - ç¬¬ \(b\) ä¸ªè‡ªåŠ©æ¨¡å‹
- en: \(\hat{Y}^b\) - predicted value for the model in the \(b^{th}\) bootstrapped
    model
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{Y}^b\) - ç¬¬ \(b^{th}\) ä¸ªè‡ªåŠ©æ¨¡å‹çš„æ¨¡å‹é¢„æµ‹å€¼
- en: to calculate prediction realizations. The ensemble of prediction realizations
    are aggregated to reduce model variance. The aggregation includes,
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºè®¡ç®—é¢„æµ‹å®ç°ã€‚é¢„æµ‹å®ç°çš„é›†åˆè¢«èšåˆä»¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚èšåˆåŒ…æ‹¬ï¼Œ
- en: '*regression* - the average of the predictions $\( \hat{Y} = \frac{1}{B} \sum_{b=1}^{B}
    \hat{Y}^b \)$'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å›å½’* - é¢„æµ‹çš„å¹³å‡å€¼ \( \hat{Y} = \frac{1}{B} \sum_{b=1}^{B} \hat{Y}^b \) '
- en: '*classification* - the mode of the predictions'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ†ç±»* - é¢„æµ‹çš„æœ€å°å€¼'
- en: \[ \hat{Y} = \text{argmax}(\hat{Y}^b) \]
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} = \text{argmax}(\hat{Y}^b) \]
- en: We can perform bagging with any prediction model, in fact the BaggingClassifier
    and BaggingRegressor functions in scikit-learn are wrappers that take the prediction
    model as an input.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•é¢„æµ‹æ¨¡å‹è¿›è¡Œè¢‹è£…ï¼Œå®é™…ä¸Š scikit-learn ä¸­çš„ BaggingClassifier å’Œ BaggingRegressor å‡½æ•°æ˜¯æ¥å—é¢„æµ‹æ¨¡å‹ä½œä¸ºè¾“å…¥çš„åŒ…è£…å™¨ã€‚
- en: '**Basis Expansion**'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºå‡½æ•°å±•å¼€**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): to add
    flexibility to our model, for example, to capture non-linearity in our model for
    regression, classification, we expand the features with a set of basis functions'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šä¸ºäº†å¢åŠ æ¨¡å‹çš„çµæ´»æ€§ï¼Œä¾‹å¦‚ï¼Œä¸ºäº†æ•æ‰å›å½’ã€åˆ†ç±»æ¨¡å‹ä¸­çš„éçº¿æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„åŸºå‡½æ•°æ‰©å±•ç‰¹å¾'
- en: in mathematics basis expansion is the approach of representing a more complicated
    function with a linear combination of simpler basis functions that make the problem
    easier to solve
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°å­¦ä¸­ï¼ŒåŸºå‡½æ•°å±•å¼€æ˜¯å°†æ›´å¤æ‚çš„å‡½æ•°è¡¨ç¤ºä¸ºæ›´ç®€å•åŸºå‡½æ•°çš„çº¿æ€§ç»„åˆçš„æ–¹æ³•ï¼Œè¿™ä½¿å¾—é—®é¢˜æ›´å®¹æ˜“è§£å†³
- en: with basis expansion we expand the dimensionality of the problem with basis
    functions of the original features, but still use linear methods on the transformed
    features.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŸºå‡½æ•°å±•å¼€ï¼Œæˆ‘ä»¬é€šè¿‡åŸå§‹ç‰¹å¾çš„åŸºå‡½æ•°æ‰©å±•é—®é¢˜çš„ç»´åº¦æ€§ï¼Œä½†ä»ç„¶åœ¨è½¬æ¢åçš„ç‰¹å¾ä¸Šä½¿ç”¨çº¿æ€§æ–¹æ³•ã€‚
- en: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
- en: 'Here an example of basis expansion, the set of basis functions for polynomial
    basis expansion:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªåŸºå‡½æ•°å±•å¼€çš„ä¾‹å­ï¼Œå¤šé¡¹å¼åŸºå‡½æ•°å±•å¼€çš„åŸºå‡½æ•°é›†åˆï¼š
- en: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
- en: '**Basis Function**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºå‡½æ•°**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): to add
    flexibility to our model, for example, to capture non-linearity in our model for
    regression, classification, we expand the features with a set of basis functions'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šä¸ºäº†å¢åŠ æ¨¡å‹çš„çµæ´»æ€§ï¼Œä¾‹å¦‚ï¼Œä¸ºäº†æ•æ‰å›å½’ã€åˆ†ç±»æ¨¡å‹ä¸­çš„éçº¿æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„åŸºå‡½æ•°æ‰©å±•ç‰¹å¾'
- en: in mathematics basis expansion is the approach of representing a more complicated
    function with a linear combination of simpler basis functions that make the problem
    easier to solve
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°å­¦ä¸­ï¼ŒåŸºå‡½æ•°å±•å¼€æ˜¯å°†æ›´å¤æ‚çš„å‡½æ•°è¡¨ç¤ºä¸ºæ›´ç®€å•åŸºå‡½æ•°çš„çº¿æ€§ç»„åˆçš„æ–¹æ³•ï¼Œè¿™ä½¿å¾—é—®é¢˜æ›´å®¹æ˜“è§£å†³
- en: with basis expansion we expand the dimensionality of the problem with basis
    functions of the original features, but still use linear methods on the transformed
    features.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŸºå‡½æ•°å±•å¼€ï¼Œæˆ‘ä»¬é€šè¿‡åŸå§‹ç‰¹å¾çš„åŸºå‡½æ•°æ‰©å±•é—®é¢˜çš„ç»´åº¦æ€§ï¼Œä½†ä»ç„¶åœ¨è½¬æ¢åçš„ç‰¹å¾ä¸Šä½¿ç”¨çº¿æ€§æ–¹æ³•ã€‚
- en: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
- en: 'were each of \(h_1\), \ldots, \(h_k\) are basis functions. For example, here
    are the basis functions for polynomial basis expansion:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(h_1, \ldots, h_k\) æ˜¯åŸºå‡½æ•°ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹æ˜¯å¤šé¡¹å¼åŸºå‡½æ•°å±•å¼€çš„åŸºå‡½æ•°ï¼š
- en: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
- en: '**Bayesâ€™ Theorem** (probability)'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è´å¶æ–¯å®šç†**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the mathematical
    model central to Bayesian probability for the Bayesian updating from prior probability,
    with likelihood probability from new information to posterior probability.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šè´å¶æ–¯æ¦‚ç‡çš„æ ¸å¿ƒæ•°å­¦æ¨¡å‹ï¼Œç”¨äºä»å…ˆéªŒæ¦‚ç‡è¿›è¡Œè´å¶æ–¯æ›´æ–°ï¼Œä»æ–°ä¿¡æ¯åˆ°åéªŒæ¦‚ç‡çš„ä¼¼ç„¶æ¦‚ç‡ã€‚ '
- en: \[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]
- en: where \(P(A)\) is the prior, \(P(B|A)\) is the likelihood, \(P(B)\) is the evidence
    term and \(P(A|B)\) is the posterior. If is convenient to substitute more descriptive
    labels for \(A\) and \(B\) to better conceptualize this approach,
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(P(A)\) æ˜¯å…ˆéªŒï¼Œ\(P(B|A)\) æ˜¯ä¼¼ç„¶ï¼Œ\(P(B)\) æ˜¯è¯æ®é¡¹ï¼Œ\(P(A|B)\) æ˜¯åéªŒã€‚å¦‚æœæ–¹ä¾¿ï¼Œå¯ä»¥ç”¨æ›´æè¿°æ€§çš„æ ‡ç­¾æ›¿æ¢
    \(A\) å’Œ \(B\) ä»¥æ›´å¥½åœ°ç†è§£è¿™ç§æ–¹æ³•ï¼Œ
- en: \[ P(\text{Model} | \text{New Data}) = \frac{P(\text{New Data} | \text{Model})
    \cdot P(\text{Model})}{P(\text{New Data})} \]
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\text{Model} | \text{New Data}) = \frac{P(\text{New Data} | \text{Model})
    \cdot P(\text{Model})}{P(\text{New Data})} \]
- en: demonstrating that we are updating our model with new data
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å±•ç¤ºæˆ‘ä»¬æ­£åœ¨ç”¨æ–°æ•°æ®æ›´æ–°æˆ‘ä»¬çš„æ¨¡å‹
- en: '**Bayesian Probability**'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è´å¶æ–¯æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): probabilities based
    on a degree of belief (expert judgement and experience) in the likelihood of an
    event. The general approach,'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåŸºäºå¯¹äº‹ä»¶å‘ç”Ÿå¯èƒ½æ€§çš„ä¿¡å¿µç¨‹åº¦ï¼ˆä¸“å®¶åˆ¤æ–­å’Œç»éªŒï¼‰çš„æ¦‚ç‡ã€‚ä¸€èˆ¬æ–¹æ³•ï¼Œ'
- en: start with prior probability, prior to the collection of new information
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»å…ˆéªŒæ¦‚ç‡å¼€å§‹ï¼Œåœ¨æ”¶é›†æ–°ä¿¡æ¯ä¹‹å‰
- en: formulate a likelihood probability, based on new information alone
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºæ–°ä¿¡æ¯å•ç‹¬åˆ¶å®šä¼¼ç„¶æ¦‚ç‡
- en: update prior with likelihood to calculate the updated posterior probability
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¼¼ç„¶æ›´æ–°å…ˆéªŒä»¥è®¡ç®—æ›´æ–°çš„åéªŒæ¦‚ç‡
- en: continue to update as new information is available
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æœ‰æ–°ä¿¡æ¯æ—¶ç»§ç»­æ›´æ–°
- en: solve probability problems that we cannot use simple frequencies, i.e., *frequentist
    probability* approach
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§£å†³æˆ‘ä»¬æ— æ³•ä½¿ç”¨ç®€å•é¢‘ç‡çš„æ¦‚ç‡é—®é¢˜ï¼Œå³*é¢‘ç‡æ´¾æ¦‚ç‡*æ–¹æ³•
- en: Bayesian updating is modeled with *Bayesâ€™ Theorem*
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è´å¶æ–¯æ›´æ–°æ˜¯é€šè¿‡*è´å¶æ–¯å®šç†*å»ºæ¨¡çš„
- en: '**Bayesian Updating for Classification**'
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»çš„è´å¶æ–¯æ›´æ–°**'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): this is how we pose the classification
    prediction problem from the perspective of Bayesian updating, based on the conditional
    probability of a category, \(k\), given \(n\) features, \(x_1, \dots , x_n\).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šè¿™æ˜¯æˆ‘ä»¬ä»è´å¶æ–¯æ›´æ–°çš„è§’åº¦æå‡ºåˆ†ç±»é¢„æµ‹é—®é¢˜çš„æ–¹æ³•ï¼ŒåŸºäºç»™å®š \(n\)
    ä¸ªç‰¹å¾ \(x_1, \dots , x_n\) çš„ç±»åˆ« \(k\) çš„æ¡ä»¶æ¦‚ç‡ã€‚'
- en: \[ P(C_k | x_1, \dots , x_n) \]
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) \]
- en: we can solve for this posterior with Bayesian updating,
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡è´å¶æ–¯æ›´æ–°æ±‚è§£è¿™ä¸ªåéªŒæ¦‚ç‡ï¼Œ
- en: \[ P(C_k | x_1, \dots , x_n) = \frac{P(x_1, \dots , x_n | C_k) P(C_k)}{P(x_1,
    \dots , x_n)} \]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) = \frac{P(x_1, \dots , x_n | C_k) P(C_k)}{P(x_1,
    \dots , x_n)} \]
- en: letâ€™s combine the likelihood and prior for the moment,
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æš‚æ—¶å°†ä¼¼ç„¶å’Œå…ˆéªŒç»“åˆèµ·æ¥ï¼Œ
- en: \[ P(x_1, \dots , x_n | C_k) P(C_k) = P(x_1, \dots , x_n, C_k) \]
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1, \dots , x_n | C_k) P(C_k) = P(x_1, \dots , x_n, C_k) \]
- en: we can expand the full joint distribution recursively as follows,
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€’å½’åœ°æ‰©å±•å®Œæ•´çš„è”åˆåˆ†å¸ƒå¦‚ä¸‹ï¼Œ
- en: \[ P(x_1, \dots , x_n, C_k) \]
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1, \dots , x_n, C_k) \]
- en: expansion of the joint with the conditional and prior,
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è”åˆåˆ†å¸ƒé€šè¿‡æ¡ä»¶åˆ†å¸ƒå’Œå…ˆéªŒåˆ†å¸ƒè¿›è¡Œæ‰©å±•ï¼Œ
- en: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2, \dots , x_n, C_k) \]
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2, \dots , x_n, C_k) \]
- en: continue recursively expanding,
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ç»§ç»­é€’å½’åœ°æ‰©å±•ï¼Œ
- en: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3, \dots
    , x_n, C_k) \]
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3, \dots
    , x_n, C_k) \]
- en: we can generalize as,
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ¨å¹¿å¦‚ä¸‹ï¼Œ
- en: \[ P(C_k | x_1, \dots , x_n) = P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots
    , x_n, C_k) P(x_3 | x_4, \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n}
    | C_k) P(C_k) \]
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) = P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots
    , x_n, C_k) P(x_3 | x_4, \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n}
    | C_k) P(C_k) \]
- en: '**Bayesian Linear Regression**'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è´å¶æ–¯çº¿æ€§å›å½’**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    the frequentist formulation of the linear regression model is,'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šçº¿æ€§å›å½’æ¨¡å‹çš„é¢‘ç‡æ´¾å…¬å¼ä¸ºï¼Œ'
- en: \[ y = b_1 \times x + b_0 + \sigma \]
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = b_1 \times x + b_0 + \sigma \]
- en: where \(x\) is the predictor feature, \(b_1\) is the slope parameter, \(b_0\)
    is the intercept parameter and \(\sigma\) is the error or noise. There is an analytical
    form for the ordinary least squares solution to fit the available data while minimizing
    the \(L^2\) norm of the data error vector.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(x\) æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œ\(b_1\) æ˜¯æ–œç‡å‚æ•°ï¼Œ\(b_0\) æ˜¯æˆªè·å‚æ•°ï¼Œ\(\sigma\) æ˜¯è¯¯å·®æˆ–å™ªå£°ã€‚å­˜åœ¨ä¸€ä¸ªè§£æå½¢å¼ï¼Œç”¨äºæ‹Ÿåˆå¯ç”¨æ•°æ®å¹¶æœ€å°åŒ–æ•°æ®è¯¯å·®å‘é‡çš„
    \(L^2\) èŒƒæ•°ã€‚
- en: 'For the Bayesian formulation of linear regression is we pose the model as a
    prediction of the distribution of the response, \(Y\), now a random variable:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºçº¿æ€§å›å½’çš„è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬å°†æ¨¡å‹è®¾å®šä¸ºå¯¹å“åº”åˆ†å¸ƒ \(Y\) çš„é¢„æµ‹ï¼Œç°åœ¨ \(Y\) æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼š
- en: \[ Y \sim N(\beta^{T}X, \sigma^{2} I) \]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y \sim N(\beta^{T}X, \sigma^{2} I) \]
- en: We estimate the model parameter distributions through Bayesian updating for
    inferring the model parameters from a prior and likelihood from training data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡è´å¶æ–¯æ›´æ–°æ¥ä¼°è®¡æ¨¡å‹å‚æ•°åˆ†å¸ƒï¼Œä»¥ä»å…ˆéªŒå’Œè®­ç»ƒæ•°æ®çš„ä¼¼ç„¶ä¸­æ¨æ–­æ¨¡å‹å‚æ•°ã€‚
- en: \[ P(\beta | y, X) = \frac{P(y,X| \beta) P(\beta)}{P(y,X)} \]
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\beta | y, X) = \frac{P(y,X| \beta) P(\beta)}{P(y,X)} \]
- en: In general for continuous features we are not able to directly calculate the
    posterior and we must use a sampling method, such as Markov chain Monte Carlo
    (McMC) to sample the posterior.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸å¯¹äºè¿ç»­ç‰¹å¾ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®—åéªŒæ¦‚ç‡ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨æŠ½æ ·æ–¹æ³•ï¼Œä¾‹å¦‚é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ï¼ˆMcMCï¼‰æ¥æŠ½æ ·åéªŒã€‚
- en: '**Big Data**'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤§æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): you have big data
    if your data has a combination of these criteria:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¦‚æœä½ çš„æ•°æ®å…·æœ‰ä»¥ä¸‹è¿™äº›æ ‡å‡†çš„ç»„åˆï¼Œé‚£ä¹ˆä½ å°±æœ‰å¤§æ•°æ®ï¼š'
- en: '*Data Volume* - many data samples and features, difficult to store, transmit
    and visualize'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®é‡* - è®¸å¤šæ•°æ®æ ·æœ¬å’Œç‰¹å¾ï¼Œéš¾ä»¥å­˜å‚¨ã€ä¼ è¾“å’Œå¯è§†åŒ–'
- en: '*Data Velocity* - high-rate collection, continuous data collection relative
    to decision making cycles, challenges keeping up with the new data while updating
    the models'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®é€Ÿåº¦* - é«˜é€Ÿç‡æ”¶é›†ï¼Œç›¸å¯¹äºå†³ç­–å‘¨æœŸè¿›è¡Œè¿ç»­æ•°æ®æ”¶é›†ï¼Œåœ¨æ›´æ–°æ¨¡å‹çš„åŒæ—¶ä¿æŒå¯¹æ–°æ•°æ®çš„è·Ÿè¿›æ˜¯ä¸€ä¸ªæŒ‘æˆ˜'
- en: '*Data Variety* - data form various sources, with various types of data, types
    of information, and scales'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®å¤šæ ·æ€§* - æ•°æ®æ¥è‡ªå„ç§æ¥æºï¼Œå…·æœ‰å„ç§ç±»å‹çš„æ•°æ®ã€ä¿¡æ¯å’Œè§„æ¨¡'
- en: '*Data Variability* - data acquisition changes during the project, even for
    a single feature there may be multiple vintages of data with different scales,
    distributions, and veracity'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®å¯å˜æ€§* - åœ¨é¡¹ç›®æœŸé—´æ•°æ®é‡‡é›†å‘ç”Ÿå˜åŒ–ï¼Œå³ä½¿æ˜¯å•ä¸ªç‰¹å¾ä¹Ÿå¯èƒ½æœ‰å¤šä¸ªç‰ˆæœ¬çš„æ•°æ®ï¼Œå…·æœ‰ä¸åŒçš„è§„æ¨¡ã€åˆ†å¸ƒå’ŒçœŸå®æ€§'
- en: '*Data Veracity* - data has various levels of accuracy, the data is not certain'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®çœŸå®æ€§* - æ•°æ®å…·æœ‰å„ç§çº§åˆ«çš„å‡†ç¡®æ€§ï¼Œæ•°æ®æ˜¯ä¸ç¡®å®šçš„'
- en: For common subsurface applications most, if not all, of these criteria are met.
    Subsurface engineering and geoscience are often working with big data!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤§å¤šæ•°ï¼ˆå¦‚æœä¸æ˜¯æ‰€æœ‰ï¼‰çš„è¿™äº›æ ‡å‡†ï¼Œåœ¨å¸¸è§çš„åœ°ä¸‹åº”ç”¨ä¸­éƒ½æ˜¯æ»¡è¶³çš„ã€‚åœ°ä¸‹å·¥ç¨‹å’Œåœ°çƒç§‘å­¦é€šå¸¸ä¸å¤§æ•°æ®æ‰“äº¤é“ï¼
- en: '**Big Data Analytics**'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤§æ•°æ®åˆ†æ**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the process of
    examining large and varied data (*big data*) sets to discover patterns and make
    decisions, the application of statistics to big data.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ£€æŸ¥å¤§å‹å’Œå¤šæ ·åŒ–çš„æ•°æ®é›†ï¼ˆ*å¤§æ•°æ®*ï¼‰ä»¥å‘ç°æ¨¡å¼å’Œåšå‡ºå†³ç­–çš„è¿‡ç¨‹ï¼Œå°†ç»Ÿè®¡å­¦åº”ç”¨äºå¤§æ•°æ®ã€‚'
- en: '**Binary Transform** (also Indicator Transform)'
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äºŒå€¼è½¬æ¢**ï¼ˆä¹Ÿç§°ä¸ºæŒ‡ç¤ºè½¬æ¢ï¼‰'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): indicator
    coding a random variable to a probability relative to a category or a threshold.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šå°†éšæœºå˜é‡æŒ‡ç¤ºç¼–ç ä¸ºç›¸å¯¹äºç±»åˆ«æˆ–é˜ˆå€¼çš„æ¦‚ç‡ã€‚'
- en: If \(i(\bf{u}:z_k)\) is an indicator for a categorical variable,
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(i(\bf{u}:z_k)\) æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡çš„æŒ‡ç¤ºå™¨ï¼Œ
- en: what is the probability of a realization equal to a category?
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°ç­‰äºä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{å¦‚æœ } Z(\bf{u}) = z_k
    \\ 0, & \text{å¦‚æœ } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_2 = 2\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 2\),
    then \(i(bf{u}_1; z_2) = 1\)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_2 = 2\), ä»¥åŠåœ¨ \(\bf{u}_1\) çš„æ•°æ®ï¼Œ\(z(\bf{u}_1) = 2\)ï¼Œé‚£ä¹ˆ \(i(bf{u}_1; z_2)
    = 1\)
- en: given threshold, \(z_1 = 1\), and a RV away from data, \(Z(\bf{u}_2)\) then
    is calculated as \(F^{-1}_{\bf{u}_2}(z_1)\) of the RV as \(i(\bf{u}_2; z_1) =
    0.23\)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 1\), ä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ï¼Œ\(Z(\bf{u}_2)\)ï¼Œé‚£ä¹ˆè®¡ç®—ä¸º \(F^{-1}_{\bf{u}_2}(z_1)\)
    çš„éšæœºå˜é‡ï¼Œ\(i(\bf{u}_2; z_1) = 0.23\)
- en: If \(I\{\bf{u}:z_k\}\) is an indicator for a continuous variable,
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(I\{\bf{u}:z_k\}\) æ˜¯ä¸€ä¸ªè¿ç»­å˜é‡çš„æŒ‡ç¤ºå™¨ï¼Œ
- en: what is the probability of a realization less than or equal to a threshold?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°å°äºæˆ–ç­‰äºé˜ˆå€¼çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{å¦‚æœ } Z(\bf{u}) \le
    z_k \\ 0, & \text{å¦‚æœ } Z(\bf{u}) > z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_1 = 6\%\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 8\%\),
    then \(i(\bf{u}_1; z_1) = 0\)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 6\%\), ä»¥åŠåœ¨ \(\bf{u}_1\) çš„æ•°æ®ï¼Œ\(z(\bf{u}_1) = 8\%\)ï¼Œé‚£ä¹ˆ \(i(\bf{u}_1;
    z_1) = 0\)
- en: given threshold, \(z_4 = 18\%\), and a RV away from data, \(Z(\bf{u}_2) = N\left[\mu
    = 16\%,\sigma = 3\%\right]\) then \(i(\bf{u}_2; z_4) = 0.75\)
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_4 = 18\%\), ä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ï¼Œ\(Z(\bf{u}_2) = N\left[\mu = 16\%,\sigma
    = 3\%\right]\)ï¼Œé‚£ä¹ˆ \(i(\bf{u}_2; z_4) = 0.75\)
- en: The indicator coding may be applied over an entire random function by indicator
    transform of all the random variables at each location.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡ç¤ºç¼–ç å¯ä»¥é€šè¿‡åœ¨æ¯ä¸ªä½ç½®çš„éšæœºå˜é‡çš„æŒ‡ç¤ºå˜æ¢åœ¨æ•´ä¸ªéšæœºå‡½æ•°ä¸Šåº”ç”¨ã€‚
- en: '**Boosting Models**'
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æå‡æ¨¡å‹**'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): addition of multiple
    week learners to build a stronger learner.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šæ·»åŠ å¤šä¸ªå¼±å­¦ä¹ å™¨ä»¥æ„å»ºæ›´å¼ºçš„å­¦ä¹ å™¨ã€‚'
- en: a weak learner is one that offers predictions just marginally better than random
    selection
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼±å­¦ä¹ å™¨æ˜¯ä¸€ç§ä»…æä¾›ç•¥å¥½äºéšæœºé€‰æ‹©çš„é¢„æµ‹çš„é¢„æµ‹å™¨
- en: This is the method in words, and then with equations,
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ç”¨æ–‡å­—æè¿°çš„æ–¹æ³•ï¼Œç„¶åç”¨æ–¹ç¨‹è¡¨ç¤ºï¼Œ
- en: build a simple model with a high error rate, the model can be quite inaccurate,
    but moves in the correct direction
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªè¯¯å·®ç‡é«˜çš„ç®€å•æ¨¡å‹ï¼Œæ¨¡å‹å¯èƒ½éå¸¸ä¸å‡†ç¡®ï¼Œä½†æ–¹å‘æ˜¯æ­£ç¡®çš„
- en: calculate the error from the model
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ¨¡å‹ä¸­è®¡ç®—è¯¯å·®
- en: fit another model to the error
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å¦ä¸€ä¸ªæ¨¡å‹æ‹Ÿåˆåˆ°è¯¯å·®ä¸Š
- en: calculate the error from this addition of the first and second model
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªæ¨¡å‹æ·»åŠ çš„è¯¯å·®
- en: repeat until the desired accuracy is obtained or some other stopping criteria
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å¤æ‰§è¡Œï¼Œç›´åˆ°è·å¾—æ‰€éœ€çš„ç²¾åº¦æˆ–æ»¡è¶³å…¶ä»–åœæ­¢æ¡ä»¶
- en: Now with equations, the general workflow for predicting \(Y\) from \(X_1,\ldots,X_m\)
    is,
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ç”¨æ–¹ç¨‹è¡¨ç¤ºï¼Œä» \(X_1,\ldots,X_m\) é¢„æµ‹ \(Y\) çš„ä¸€èˆ¬å·¥ä½œæµç¨‹æ˜¯ï¼Œ
- en: build a week learner to predict \(Y\) from \(X_1,\ldots,X_m\), \(\hat{F}_k(X)\)
    from the training data \(x_{i,j}\).
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªå¼±å­¦ä¹ å™¨æ¥ä» \(X_1,\ldots,X_m\) é¢„æµ‹ \(Y\)ï¼Œä»è®­ç»ƒæ•°æ® \(x_{i,j}\) é¢„æµ‹ \(\hat{F}_k(X)\)ã€‚
- en: loop over number of desired estimators, \(k = 1,\ldots,K\)
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æ‰€éœ€ä¼°è®¡é‡æ•°é‡è¿›è¡Œå¾ªç¯ï¼Œ\(k = 1,\ldots,K\)
- en: calculate the residuals at the training data, \(h_k(x_{i}) = y_i - \hat{F}_k(x_{i})\)
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—è®­ç»ƒæ•°æ®ä¸­çš„æ®‹å·®ï¼Œ\(h_k(x_{i}) = y_i - \hat{F}_k(x_{i})\)
- en: fit another week learner to predict \(h_k\) from \(X_1,\ldots,X_m\), \(\hat{F}_k(X)\)
    from the training data \(x_{i,j}\).
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å¦ä¸€ä¸ªå¼±å­¦ä¹ å™¨æ‹Ÿåˆåˆ°ä» \(X_1,\ldots,X_m\) é¢„æµ‹ \(h_k\)ï¼Œä»è®­ç»ƒæ•°æ® \(x_{i,j}\) é¢„æµ‹ \(\hat{F}_k(X)\)ã€‚
- en: each model builds on the previous to improve the accuracy
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹éƒ½æ˜¯åŸºäºå‰ä¸€ä¸ªæ¨¡å‹æ¥æé«˜ç²¾åº¦
- en: The regression estimator is the summation over the \(K\) simple models,
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’ä¼°è®¡é‡æ˜¯å¯¹ \(K\) ä¸ªç®€å•æ¨¡å‹çš„æ€»å’Œï¼Œ
- en: \[ \hat{Y} =\sum_{k=1}^{K} F_k(X_1,\ldots,X_m) \]
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} =\sum_{k=1}^{K} F_k(X_1,\ldots,X_m) \]
- en: '**Bootstrap**'
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é‡æŠ½æ ·**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): a statistical
    resampling procedure to calculate uncertainty in a calculated statistic from the
    sample data itself. Some general comments,'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¢‹è£…æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šä¸€ç§ç»Ÿè®¡é‡æŠ½æ ·è¿‡ç¨‹ï¼Œç”¨äºä»æ ·æœ¬æ•°æ®æœ¬èº«è®¡ç®—è®¡ç®—å‡ºçš„ç»Ÿè®¡é‡çš„ä¸ç¡®å®šæ€§ã€‚ä¸€äº›ä¸€èˆ¬æ€§è¯„è®ºï¼Œ'
- en: '*sampling with replacement* - \(n\) (number of data samples) *Monte Carlo simulation*s
    from the dataset *cumulative distribution function*, this results in a new realization
    of the data'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœ‰æ”¾å›çš„æŠ½æ ·* - ä»æ•°æ®é›†çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ä¸­è¿›è¡Œ \(n\)ï¼ˆæ•°æ®æ ·æœ¬æ•°ï¼‰*è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ*ï¼Œè¿™å¯¼è‡´æ•°æ®çš„æ–°å®ç°'
- en: '*simulates the data collection process* - the fundamental idea is to simulate
    the original data collection process. Instead of actually collecting new sample
    sets, we randomly select from the data to get data realizations'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨¡æ‹Ÿæ•°æ®æ”¶é›†è¿‡ç¨‹* - åŸºæœ¬æ€æƒ³æ˜¯æ¨¡æ‹ŸåŸå§‹æ•°æ®æ”¶é›†è¿‡ç¨‹ã€‚æˆ‘ä»¬ä¸æ˜¯å®é™…æ”¶é›†æ–°çš„æ ·æœ¬é›†ï¼Œè€Œæ˜¯ä»æ•°æ®ä¸­éšæœºé€‰æ‹©ä»¥è·å–æ•°æ®å®ç°'
- en: '*bootstrap any statistic* - this approach is very flexible as we can calculate
    realizations of any statistics from the data realizations'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é‡æŠ½æ ·ä»»ä½•ç»Ÿè®¡é‡* - è¿™ç§æ–¹æ³•éå¸¸çµæ´»ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ä»æ•°æ®å®ç°ä¸­è®¡ç®—å‡ºä»»ä½•ç»Ÿè®¡é‡çš„å®ç°'
- en: '*computationally cheap* - repeat this approach to get realizations of the statistic
    to build a complete distribution of uncertainty. Use a large number of realizations,
    \(L\), for a reliable uncertainty model.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—æˆæœ¬ä½* - é‡å¤æ­¤æ–¹æ³•ä»¥è·å–ç»Ÿè®¡é‡çš„å®ç°ï¼Œä»¥æ„å»ºä¸ç¡®å®šæ€§çš„å®Œæ•´åˆ†å¸ƒã€‚ä½¿ç”¨å¤§é‡å®ç°ï¼Œ\(L\)ï¼Œä»¥è·å¾—å¯é çš„ä¸ç¡®å®šæ€§æ¨¡å‹ã€‚'
- en: '*calculates the entire distribution of uncertainty* - for any statistic, you
    calculate any summary statistic for the uncertainty model, e.g., mean, P10 and
    P90 of the uncertainty in the mean'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—æ•´ä¸ªä¸ç¡®å®šæ€§çš„åˆ†å¸ƒ* - å¯¹äºä»»ä½•ç»Ÿè®¡é‡ï¼Œä½ è®¡ç®—ä¸ç¡®å®šæ€§æ¨¡å‹ä¸­çš„ä»»ä½•æ±‡æ€»ç»Ÿè®¡é‡ï¼Œä¾‹å¦‚ï¼Œå‡å€¼çš„å‡å€¼ã€P10 å’Œ P90'
- en: '*bagging for machine learning* - is the application of bootstrap to obtain
    data realizations to train predictive model realizations to aggregate predictions
    over ensembles of prediction models to reduce model variance'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœºå™¨å­¦ä¹ çš„è¢‹è£…æ³•* - æ˜¯å°†é‡æŠ½æ ·åº”ç”¨äºè·å–æ•°æ®å®ç°ä»¥è®­ç»ƒé¢„æµ‹æ¨¡å‹å®ç°ï¼Œå¯¹é¢„æµ‹æ¨¡å‹é›†åˆè¿›è¡Œèšåˆé¢„æµ‹ä»¥å‡å°‘æ¨¡å‹æ–¹å·®'
- en: What are the limitations of bootstrap?
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: é‡æŠ½æ ·çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿ
- en: biased sample data will likely result in a biased bootstrapped uncertainty model,
    you must first debias the samples, e.g., *declustering*
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ ·æœ¬æ•°æ®å¯èƒ½å¯¼è‡´åå·®çš„bootstrappedä¸ç¡®å®šæ€§æ¨¡å‹ï¼Œä½ å¿…é¡»é¦–å…ˆå»é™¤åå·®ï¼Œä¾‹å¦‚ï¼Œ*å»ç°‡åŒ–*
- en: you must have a sufficient sample size
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¿…é¡»æ‹¥æœ‰è¶³å¤Ÿçš„æ ·æœ¬é‡
- en: integrates uncertainty due to sparse samples in space only
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»…æ•´åˆç©ºé—´æ ·æœ¬ç¨€ç–æ€§å¸¦æ¥çš„ä¸ç¡®å®šæ€§
- en: does not account for the spatial context of the data, i.e., sample data locations,
    volume of interest nor the spatial continuity. There is a variant of bootstrap
    called [spatial bootstrap](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Spatial_Bootstrap.ipynb).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸è€ƒè™‘æ•°æ®çš„ç©ºé—´èƒŒæ™¯ï¼Œå³æ ·æœ¬æ•°æ®ä½ç½®ã€æ„Ÿå…´è¶£åŒºåŸŸçš„ä½“ç§¯æˆ–ç©ºé—´è¿ç»­æ€§ã€‚å­˜åœ¨ä¸€ç§ç§°ä¸º[ç©ºé—´è‡ªä¸¾](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Spatial_Bootstrap.ipynb)çš„è‡ªä¸¾å˜ä½“ã€‚
- en: '**Categorical Feature**'
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a feature that
    can only take one of a limited, and usually fixed, number of possible values'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªåªèƒ½å–æœ‰é™ä¸”é€šå¸¸å›ºå®šæ•°é‡çš„å¯èƒ½å€¼çš„ç‰¹å¾'
- en: '**Categorical Nominal Feature**'
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»åä¹‰ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *categorical*
    feature without any natural ordering, for example,'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªæ²¡æœ‰è‡ªç„¶æ’åºçš„*åˆ†ç±»*ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: facies = {boundstone, wackystone, packstone, brecia}
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å²© = \{ç°å²©ï¼Œç¢å±‘å²©ï¼Œç ¾å²©ï¼Œè§’ç ¾å²©\}
- en: minerals = {quartz, feldspar, calcite}
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çŸ¿ç‰© = \{çŸ³è‹±ï¼Œé•¿çŸ³ï¼Œæ–¹è§£çŸ³\}
- en: '**Categorical Ordinal Feature**'
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»æœ‰åºç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *categorical*
    feature with a natural ordering, for example,'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªå…·æœ‰è‡ªç„¶æ’åºçš„*åˆ†ç±»*ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: geologic age = {Miocene, Pliocene, Pleistocene} - ordered from older to younger
    rock
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°è´¨å¹´ä»£ = \{ä¸­æ–°ä¸–ï¼Œä¸Šæ–°ä¸–ï¼Œæ›´æ–°ä¸–\} - ä»è¾ƒè€åˆ°è¾ƒæ–°çš„å²©çŸ³æ’åº
- en: Mohs hardness = \(\{1, 2, \ldots, 10\}\) - ordered from softer to harder rock
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘©æ°ç¡¬åº¦ = \(\{1, 2, \ldots, 10\}\) - ä»è¾ƒè½¯åˆ°è¾ƒç¡¬çš„å²©çŸ³æ’åº
- en: '**Causation**'
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å› æœå…³ç³»**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): a relationship
    where a change in one or more feature(s) directly leads to a change in one or
    more other feature(s).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šä¸€ä¸ªå˜åŒ–ç›´æ¥å¯¼è‡´ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–ç‰¹å¾å˜åŒ–çš„å…³ç³»'
- en: Some important aspects of causal relationships,
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœå…³ç³»çš„ä¸€äº›é‡è¦æ–¹é¢ï¼Œ
- en: '*Asymmetry and temporal precedence* - \(A\) is caused by \(B\) does not indicate
    that \(B\) is caused by \(A\)'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸å¯¹ç§°å’Œæ—¶é—´ä¼˜å…ˆ* - \(A\) ç”± \(B\) å¯¼è‡´å¹¶ä¸è¡¨ç¤º \(B\) ç”± \(A\) å¯¼è‡´'
- en: '*Non-spurious* - not due to random effect or confounding features'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*éè™šå‡* - ä¸æ˜¯ç”±äºéšæœºæ•ˆåº”æˆ–æ··æ‚ç‰¹å¾'
- en: '*Mechanism and explanation* - a plausible mechanism or process is available
    to explain the relationship'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æœºåˆ¶å’Œè§£é‡Š* - æœ‰ä¸€ä¸ªåˆç†çš„æœºåˆ¶æˆ–è¿‡ç¨‹å¯ä»¥è§£é‡Šè¿™ç§å…³ç³»'
- en: '*Consistency* - the relationship is observable over a range of conditions,
    times, locations, populations, etc.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸€è‡´æ€§* - è¯¥å…³ç³»åœ¨ä¸€ç³»åˆ—æ¡ä»¶ã€æ—¶é—´ã€åœ°ç‚¹ã€äººç¾¤ç­‰æ¡ä»¶ä¸‹æ˜¯å¯è§‚å¯Ÿçš„'
- en: '*Strength* - stronger relationships increase the likelihood of causation given
    all the previous 1-5 hold'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¼ºåº¦* - æ›´å¼ºçš„å…³ç³»åœ¨æ‰€æœ‰å‰1-5ç‚¹éƒ½æˆç«‹çš„æƒ…å†µä¸‹ï¼Œå¢åŠ äº†å› æœå…³ç³»çš„å¯èƒ½æ€§'
- en: Establishing causation is very difficult,
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å»ºç«‹å› æœå…³ç³»éå¸¸å›°éš¾ï¼Œ
- en: in this course we typically avoid causation and causal analysis, and emphasize
    this with statements such as correlation does not imply causation
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸é¿å…å› æœå…³ç³»å’Œå› æœåˆ†æï¼Œå¹¶é€šè¿‡è¯¸å¦‚â€œç›¸å…³æ€§ä¸æ„å‘³ç€å› æœå…³ç³»â€ä¹‹ç±»çš„é™ˆè¿°æ¥å¼ºè°ƒè¿™ä¸€ç‚¹
- en: '**Cell-based Declustering**'
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºç»†èƒçš„è§£èš**'
- en: 'Data Preparation: a declustering method to assign weights to spatial samples
    based on local sampling density, such that the weighted statistics are likely
    more representative of the population. Data weights are assigned such that,'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§å°†æƒé‡åˆ†é…ç»™åŸºäºå±€éƒ¨é‡‡æ ·å¯†åº¦çš„ç©ºé—´æ ·æœ¬çš„è§£èšæ–¹æ³•ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚ä¸‹ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¯†é›†é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬æƒé‡è¾ƒä½
- en: samples in sparsely sampled areas receive more weight
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç¨€ç–é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬æƒé‡è¾ƒé«˜
- en: The goal of declustering is for the sample statistics to be independent of sample
    locations, e.g., infill drilling or blast hole samples should not change the statistics
    for the area of interest due to increased local sample density.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: è§£èšçš„ç›®æ ‡æ˜¯ä½¿æ ·æœ¬ç»Ÿè®¡é‡ç‹¬ç«‹äºæ ·æœ¬ä½ç½®ï¼Œä¾‹å¦‚ï¼Œè¡¥å……é’»æ¢æˆ–çˆ†ç ´å­”æ ·æœ¬ä¸åº”å› å±€éƒ¨æ ·æœ¬å¯†åº¦å¢åŠ è€Œæ”¹å˜æ„Ÿå…´è¶£åŒºåŸŸçš„ç»Ÿè®¡é‡ã€‚
- en: 'Cell-based declustering proceeds as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºç»†èƒçš„è§£èšè¿‡ç¨‹å¦‚ä¸‹ï¼š
- en: a cell mesh is placed over the spatial data and weights are set as proportional
    to the inverse of the number of samples in the cell
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ç©ºé—´æ•°æ®ä¸Šæ”¾ç½®ä¸€ä¸ªå•å…ƒæ ¼ç½‘æ ¼ï¼Œå¹¶å°†æƒé‡è®¾ç½®ä¸ºä¸å•å…ƒæ ¼ä¸­æ ·æœ¬æ•°é‡çš„å€’æ•°æˆæ¯”ä¾‹
- en: the cell mesh size is varied, and the cell size that minimizes the declustered
    mean (in the sample mean is biased high) or maximizes the declustered mean (if
    the sample mean is biased low) is selected
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å•å…ƒç½‘æ ¼å¤§å°æ˜¯å¯å˜çš„ï¼Œé€‰æ‹©æœ€å°åŒ–å»ç°‡å¹³å‡ï¼ˆåœ¨æ ·æœ¬å¹³å‡åé«˜æ—¶ï¼‰æˆ–æœ€å¤§åŒ–å»ç°‡å¹³å‡ï¼ˆå¦‚æœæ ·æœ¬å¹³å‡åä½ï¼‰çš„å•å…ƒå¤§å°
- en: to remove the impact of cell mesh position, the cell mesh is randomly moved
    several times and the resulting declustering weights are averaged for each datum
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¶ˆé™¤å•å…ƒç½‘æ ¼ä½ç½®çš„å½±å“ï¼Œå•å…ƒç½‘æ ¼è¢«éšæœºç§»åŠ¨å‡ æ¬¡ï¼Œå¹¶å¯¹æ¯ä¸ªæ•°æ®ç‚¹çš„å»ç°‡æƒé‡è¿›è¡Œå¹³å‡
- en: 'The weights are calculated as:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: æƒé‡è®¡ç®—å¦‚ä¸‹ï¼š
- en: \[ w(\bf{u}_j) = \frac{1}{n_l} \cdot \frac{n}{L_o} \]
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w(\bf{u}_j) = \frac{1}{n_l} \cdot \frac{n}{L_o} \]
- en: where \(n_l\) is the number of data in the current cell, \(L_o\) is the number
    of cells with data, and \(n\) is the total number of data.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(n_l\) æ˜¯å½“å‰å•å…ƒä¸­çš„æ•°æ®æ•°é‡ï¼Œ\(L_o\) æ˜¯æœ‰æ•°æ®çš„å•å…ƒæ•°é‡ï¼Œ\(n\) æ˜¯æ•°æ®æ€»æ•°ã€‚
- en: Here are some highlights for cell-based declustering,
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›åŸºäºå•å…ƒå»ç°‡çš„äº®ç‚¹ï¼Œ
- en: expert judgement to assign cell size based on the nominal sample spacing (e.g.,
    data spacing before infill drilling) will improve the performance over the automated
    method for cell size selection based on minimum or maximum declustered mean (mentioned
    above)
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®åä¹‰æ ·æœ¬é—´è·ï¼ˆä¾‹å¦‚ï¼Œåœ¨å……å¡«é’»æ¢å‰çš„æ•°æ®é—´è·ï¼‰è¿›è¡Œä¸“å®¶åˆ¤æ–­ä»¥åˆ†é…å•å…ƒå¤§å°ï¼Œå°†æé«˜åŸºäºæœ€å°æˆ–æœ€å¤§å»ç°‡å¹³å‡ï¼ˆå¦‚ä¸Šæ‰€è¿°ï¼‰çš„å•å…ƒå¤§å°é€‰æ‹©è‡ªåŠ¨åŒ–æ–¹æ³•çš„æ€§èƒ½ã€‚
- en: cell-based declustering is not aware of the boundaries of the area of interest;
    therefore, data near the boundary of the area of interest may appear to be more
    sparsely sampled and receive more weight
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºå•å…ƒçš„å»ç°‡æ–¹æ³•æ²¡æœ‰æ„è¯†åˆ°æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œï¼›å› æ­¤ï¼Œæ„Ÿå…´è¶£åŒºåŸŸè¾¹ç•Œé™„è¿‘çš„æ•°æ®å¯èƒ½çœ‹èµ·æ¥é‡‡æ ·æ›´ç¨€ç–ï¼Œå¹¶å¾—åˆ°æ›´å¤šçš„æƒé‡
- en: cell-based was developed by Professor Andre Journel in 1983, []
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºå•å…ƒçš„æ–¹æ³•æ˜¯ç”±å®‰å¾·çƒˆÂ·çº¦å†…å°”æ•™æˆåœ¨1983å¹´å¼€å‘çš„ï¼Œ[]
- en: '**Cognitive Biases**'
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®¤çŸ¥åå·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): an automated (subconscious)
    thought process used by human brain to simplify information processing from large
    amount of personal experience and learned preferences. While these have been critical
    for our evolution and survival on this planet, they can lead to the following
    issues in data science:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šäººç±»å¤§è„‘ç”¨æ¥ç®€åŒ–ä»å¤§é‡ä¸ªäººç»éªŒå’Œå­¦ä¹ åå¥½ä¸­è·å–çš„ä¿¡æ¯å¤„ç†è¿‡ç¨‹çš„è‡ªåŠ¨åŒ–ï¼ˆæ½œæ„è¯†ï¼‰æ€ç»´è¿‡ç¨‹ã€‚è™½ç„¶è¿™äº›å¯¹äºæˆ‘ä»¬åœ¨åœ°çƒä¸Šçš„è¿›åŒ–å’Œç”Ÿå­˜è‡³å…³é‡è¦ï¼Œä½†å®ƒä»¬å¯èƒ½å¯¼è‡´æ•°æ®ç§‘å­¦ä¸­çš„ä»¥ä¸‹é—®é¢˜ï¼š'
- en: '*Anchoring Bias*, too much emphasis on the first piece of information. Studies
    have shown that the first piece of information could be irrelevant as we are beginning
    to learn about a topic, and often the earliest data in a project has the largest
    uncertainty. Address anchoring bias by curating all data, integrating uncertainty,
    fostering open discussion and debate on your project team.'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*é”šå®šåå·®*ï¼Œè¿‡åˆ†å¼ºè°ƒç¬¬ä¸€æ¡ä¿¡æ¯ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå½“æˆ‘ä»¬åˆšå¼€å§‹äº†è§£ä¸€ä¸ªä¸»é¢˜æ—¶ï¼Œç¬¬ä¸€æ¡ä¿¡æ¯å¯èƒ½æ˜¯æ— å…³çš„ï¼Œè€Œä¸”ä¸€ä¸ªé¡¹ç›®ä¸­æœ€æ—©çš„æ•°æ®é€šå¸¸å…·æœ‰æœ€å¤§çš„ä¸ç¡®å®šæ€§ã€‚é€šè¿‡æ•´ç†æ‰€æœ‰æ•°æ®ã€æ•´åˆä¸ç¡®å®šæ€§ã€ä¿ƒè¿›é¡¹ç›®å›¢é˜Ÿä¸­çš„å¼€æ”¾è®¨è®ºå’Œè¾©è®ºæ¥è§£å†³é”šå®šåå·®ã€‚'
- en: '*Availability Heuristic*, overestimate importance of easily available information,
    for example, grandfather smoked 3 packs a day and lived to 100 years old, i.e.,
    relying on anecdotes. Address availability heuristic by ensuring the project team
    documents all available information and applies quantitative analysis to move
    beyond anecdotes.'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¯å¾—æ€§å¯å‘å¼*ï¼Œé«˜ä¼°å®¹æ˜“è·å¾—çš„ä¿¡æ¯çš„é‡è¦æ€§ï¼Œä¾‹å¦‚ï¼Œç¥–çˆ¶æ¯å¤©æŠ½3åŒ…çƒŸï¼Œæ´»åˆ°100å²ï¼Œå³ä¾èµ–äºè½¶äº‹ã€‚é€šè¿‡ç¡®ä¿é¡¹ç›®å›¢é˜Ÿè®°å½•æ‰€æœ‰å¯ç”¨ä¿¡æ¯å¹¶åº”ç”¨å®šé‡åˆ†ææ¥è¶…è¶Šè½¶äº‹æ¥è§£å†³å¯å¾—æ€§å¯å‘å¼ã€‚'
- en: '*Bandwagon Effect*, assessed probability increases with the number of people
    holding the same belief. Watch out for everyone jumping on board or the loudest
    voice influencing all others on your project teams. Encouraging all members of
    the project team to contribute and even separate meetings may be helpful to address
    bandwagon effect.'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä»ä¼—æ•ˆåº”*ï¼Œè¯„ä¼°çš„æ¦‚ç‡éšç€æŒæœ‰ç›¸åŒä¿¡å¿µçš„äººæ•°å¢åŠ è€Œå¢åŠ ã€‚æ³¨æ„é¿å…æ‰€æœ‰äººåœ¨é¡¹ç›®å›¢é˜Ÿä¸­ä¸€æ‹¥è€Œä¸Šæˆ–æœ€å“äº®çš„å£°éŸ³å½±å“æ‰€æœ‰äººã€‚é¼“åŠ±é¡¹ç›®å›¢é˜Ÿçš„æ‰€æœ‰æˆå‘˜è´¡çŒ®ï¼Œç”šè‡³å•ç‹¬å¼€ä¼šå¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼Œä»¥è§£å†³ä»ä¼—æ•ˆåº”ã€‚'
- en: '*Blind-spot Effect*, fail to see your own cognitive biases. This is the hardest
    cognitive bias of all. One possible solution is to invite arms length review of
    your project teamâ€™s methods, results and decisions.'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç›²ç‚¹æ•ˆåº”*ï¼Œæœªèƒ½çœ‹åˆ°è‡ªå·±çš„è®¤çŸ¥åå·®ã€‚è¿™æ˜¯æ‰€æœ‰è®¤çŸ¥åå·®ä¸­æœ€éš¾å…‹æœçš„ã€‚ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆæ˜¯é‚€è¯·å¯¹é¡¹ç›®å›¢é˜Ÿçš„æ–¹æ³•ã€ç»“æœå’Œå†³ç­–è¿›è¡Œæ— åè§å®¡æŸ¥ã€‚'
- en: '*Choice-supportive Bias*, probability increases after a commitment, i.e., a
    decision is made. For example, it was good that I bought that car supported by
    focusing on positive information about the car. This is a specific case of confirmation
    bias.'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*é€‰æ‹©æ”¯æŒåå·®*ï¼Œåœ¨åšå‡ºæ‰¿è¯ºåæ¦‚ç‡å¢åŠ ï¼Œå³åšå‡ºå†³å®šã€‚ä¾‹å¦‚ï¼Œæˆ‘è´­ä¹°é‚£è¾†è½¦çš„å†³å®šé€šè¿‡å…³æ³¨æ±½è½¦çš„æ­£ä¿¡æ¯æ˜¯å¥½çš„ã€‚è¿™æ˜¯ç¡®è®¤åå·®çš„ä¸€ä¸ªå…·ä½“æ¡ˆä¾‹ã€‚'
- en: '*Clustering Illusion*, seeing patterns in random events. Yes, this heuristic
    helped us stay alive when large predictors hunted us, i.e., false positives are
    much better than false negatives! The solution is to model uncertainty confidence
    intervals and test all data and results against random effect.'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*èšç±»é”™è§‰*ï¼Œåœ¨éšæœºäº‹ä»¶ä¸­çœ‹åˆ°æ¨¡å¼ã€‚æ˜¯çš„ï¼Œè¿™ä¸ªå¯å‘å¼æ–¹æ³•åœ¨æˆ‘ä»¬è¢«å¤§å‹é¢„æµ‹è€…è¿½æ•æ—¶å¸®åŠ©æˆ‘ä»¬ç”Ÿå­˜ä¸‹æ¥ï¼Œå³ï¼Œå‡é˜³æ€§æ¯”å‡é˜´æ€§è¦å¥½å¾—å¤šï¼è§£å†³æ–¹æ¡ˆæ˜¯å»ºç«‹ä¸ç¡®å®šæ€§ç½®ä¿¡åŒºé—´ï¼Œå¹¶æµ‹è¯•æ‰€æœ‰æ•°æ®å’Œç»“æœä¸éšæœºæ•ˆåº”ã€‚'
- en: '*Confirmation Bias*, only consider new information that supports current model.
    Choice-supportive bias is a specific case of confirmation bias. The solution to
    confirmation bias is to seek out people that you will likely disagree with and
    build skilled project teams that hold diverse technical opinions and have different
    expert experience. My approach is to get nervous if everyone in the room agrees
    with me!'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç¡®è®¤åå·®*ï¼Œåªè€ƒè™‘æ”¯æŒå½“å‰æ¨¡å‹çš„æ–°ä¿¡æ¯ã€‚é€‰æ‹©æ”¯æŒåå·®æ˜¯ç¡®è®¤åå·®çš„ä¸€ä¸ªå…·ä½“æ¡ˆä¾‹ã€‚è§£å†³ç¡®è®¤åå·®çš„æ–¹æ³•æ˜¯å¯»æ‰¾ä½ å¯èƒ½ä¼šä¸åŒæ„çš„äººï¼Œå¹¶ç»„å»ºå…·æœ‰ä¸åŒæŠ€æœ¯è§‚ç‚¹å’Œä¸åŒä¸“å®¶ç»éªŒçš„ç†Ÿç»ƒé¡¹ç›®å›¢é˜Ÿã€‚æˆ‘çš„æ–¹æ³•æ˜¯ï¼Œå¦‚æœæˆ¿é—´é‡Œæ¯ä¸ªäººéƒ½åŒæ„æˆ‘ï¼Œæˆ‘ä¼šæ„Ÿåˆ°ç´§å¼ ï¼'
- en: '*Conservatism Bias*, favor old data to newly collected data. Data curation
    and quantitative analysis are helpful.'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¿å®ˆåå·®*ï¼Œå€¾å‘äºæ—§æ•°æ®è€Œéæ–°æ”¶é›†çš„æ•°æ®ã€‚æ•°æ®æ•´ç†å’Œå®šé‡åˆ†ææ˜¯æœ‰å¸®åŠ©çš„ã€‚'
- en: '*Recency Bias*, favor the most recently collected data. Ensure your team documents
    previous data and choices to enhance team memory. Just like conservative bias,
    data curation and quantitative analysis are our first line of defense.'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è¿‘æœŸåå·®*ï¼Œå€¾å‘äºæœ€è¿‘æ”¶é›†çš„æ•°æ®ã€‚ç¡®ä¿ä½ çš„å›¢é˜Ÿè®°å½•ä»¥å‰çš„æ•°æ®å’Œé€‰æ‹©ï¼Œä»¥å¢å¼ºå›¢é˜Ÿè®°å¿†ã€‚å°±åƒä¿å®ˆåå·®ä¸€æ ·ï¼Œæ•°æ®æ•´ç†å’Œå®šé‡åˆ†ææ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€é“é˜²çº¿ã€‚'
- en: '*Survivorship Bias*, focus on success cases only. Check for any possible pre-selection
    or filters on the data available to your team.'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¹¸å­˜è€…åå·®*ï¼Œåªå…³æ³¨æˆåŠŸæ¡ˆä¾‹ã€‚æ£€æŸ¥ä½ çš„å›¢é˜Ÿå¯ç”¨çš„æ•°æ®ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•å¯èƒ½çš„é¢„é€‰æˆ–ç­›é€‰ã€‚'
- en: Robust use of statistics / data analytics protects use from bias.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡å­¦/æ•°æ®åˆ†æçš„ç¨³å¥ä½¿ç”¨å¯ä»¥ä¿æŠ¤ç”¨æˆ·å…å—åå·®çš„å½±å“ã€‚
- en: '**Complimentary Events** (probability)'
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº’è¡¥äº‹ä»¶**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the NOT operator
    for probability, if we define A then A compliment, \(A^c\), is not A and we have
    this resulting closure relationship,'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šæ¦‚ç‡çš„NOTè¿ç®—ç¬¦ï¼Œå¦‚æœæˆ‘ä»¬å®šä¹‰Aï¼Œé‚£ä¹ˆAçš„è¡¥é›†ï¼Œ\(A^c\)ï¼Œä¸æ˜¯Aï¼Œæˆ‘ä»¬å¾—åˆ°è¿™ä¸ªç»“æœé—­åŒ…å…³ç³»ï¼Œ'
- en: \[ P(A) + P(A^c) = 1.0 \]
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) + P(A^c) = 1.0 \]
- en: complimentary events may be considered for beyond univariate problems, for example
    consider this bivariate closure,
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: äº’è¡¥äº‹ä»¶å¯ä»¥è€ƒè™‘ç”¨äºè¶…å‡ºå•å˜é‡é—®é¢˜ä¹‹å¤–ï¼Œä¾‹å¦‚è€ƒè™‘è¿™ä¸ªåŒå˜é‡é—­åŒ…ï¼Œ
- en: \[ P(A|B) + P(A^c|B) = 1.0 \]
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) + P(A^c|B) = 1.0 \]
- en: Note, the given term must be the same.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç»™å®šçš„æœ¯è¯­å¿…é¡»ç›¸åŒã€‚
- en: '**Computational Complexity**'
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®¡ç®—å¤æ‚åº¦**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): represents the
    computer resources for a method, we use it in machine learning to understand how
    our machine learning methods scale as we change the dimensionality, number of
    features, and the number of training data, represented by,'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šè¡¨ç¤ºæ–¹æ³•æ‰€éœ€çš„è®¡ç®—æœºèµ„æºï¼Œæˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨å®ƒæ¥äº†è§£æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ–¹æ³•å¦‚ä½•éšç€ç»´åº¦ã€ç‰¹å¾æ•°é‡å’Œè®­ç»ƒæ•°æ®æ•°é‡çš„å˜åŒ–è€Œç¼©æ”¾ï¼Œè¡¨ç¤ºä¸ºï¼Œ'
- en: \[ ğ‘‚(ğ‘“(ğ‘›)) \]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘‚(ğ‘“(ğ‘›)) \]
- en: where \(ğ‘›\) represents size of the problem. There are 2 components of computational
    complexity,
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(ğ‘›\) ä»£è¡¨é—®é¢˜çš„å¤§å°ã€‚è®¡ç®—å¤æ‚åº¦æœ‰2ä¸ªç»„æˆéƒ¨åˆ†ï¼Œ
- en: '*time complexity* - refers to computational time and the scaling of this time
    to the size of the problem for a given algorithm'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ—¶é—´å¤æ‚åº¦* - æŒ‡çš„æ˜¯è®¡ç®—æ—¶é—´ä»¥åŠå¯¹äºç»™å®šç®—æ³•ï¼Œæ—¶é—´éšé—®é¢˜è§„æ¨¡å˜åŒ–çš„ç¼©æ”¾æ¯”ä¾‹'
- en: '*space complexity* - refers to computer memory required and the scaling of
    storage to the size of the problem for a given algorithm'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©ºé—´å¤æ‚åº¦* - æŒ‡çš„æ˜¯æ‰€éœ€çš„è®¡ç®—æœºå†…å­˜ä»¥åŠå¯¹äºç»™å®šç®—æ³•ï¼Œå­˜å‚¨éšé—®é¢˜è§„æ¨¡å˜åŒ–çš„ç¼©æ”¾æ¯”ä¾‹'
- en: For example, if time complexity is \(O(n^3)\), where is \(n\) is number of training
    data, then if we double the number of data the run time increases eight times.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæ—¶é—´å¤æ‚åº¦æ˜¯ \(O(n^3)\)ï¼Œå…¶ä¸­ \(n\) æ˜¯è®­ç»ƒæ•°æ®æ•°é‡ï¼Œé‚£ä¹ˆå¦‚æœæˆ‘ä»¬åŠ å€æ•°æ®æ•°é‡ï¼Œè¿è¡Œæ—¶é—´å°†å¢åŠ å…«å€ã€‚
- en: Additional salient points about computational complexity,
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºè®¡ç®—å¤æ‚åº¦çš„å…¶ä»–æ˜¾è‘—ç‚¹ï¼Œ
- en: '*default to worst-case complexity* - the worst case for complexity given a
    specific problem size, provides an upper bound'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é»˜è®¤æœ€åæƒ…å†µå¤æ‚åº¦* - å¯¹äºç‰¹å®šé—®é¢˜è§„æ¨¡çš„æœ€åæƒ…å†µå¤æ‚åº¦ï¼Œæä¾›äº†ä¸€ä¸ªä¸Šé™'
- en: '*asymptotic complexity* - where \(ğ‘›\) is large. Some algorithms have speed-up
    for small datasets, this is not used'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¸è¿‘å¤æ‚åº¦* - å…¶ä¸­ \(ğ‘›\) å¾ˆå¤§ã€‚ä¸€äº›ç®—æ³•å¯¹äºå°æ•°æ®é›†æœ‰åŠ é€Ÿï¼Œè¿™ä¸è¢«ä½¿ç”¨'
- en: assumes all steps are required, e.g., data is not presorted, etc.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡è®¾æ‰€æœ‰æ­¥éª¤éƒ½æ˜¯å¿…éœ€çš„ï¼Œä¾‹å¦‚ï¼Œæ•°æ®æ²¡æœ‰é¢„æ’åºï¼Œç­‰ç­‰ã€‚
- en: Time complexity examples,
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´å¤æ‚åº¦ç¤ºä¾‹ï¼Œ
- en: '*quadratic time*, \(ğ‘¶(ğ’^ğŸ)\) - for example, integer multiplication, bubble
    sort'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*äºŒæ¬¡æ—¶é—´*ï¼Œ\(ğ‘¶(ğ’^ğŸ)\) - ä¾‹å¦‚ï¼Œæ•´æ•°ä¹˜æ³•ï¼Œå†’æ³¡æ’åº'
- en: '*linear time*, \(ğ‘¶(ğ’)\) - for example, finding the min or max in an unsorted
    array'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*çº¿æ€§æ—¶é—´*ï¼Œ\(ğ‘¶(ğ’)\) - ä¾‹å¦‚ï¼Œåœ¨æœªæ’åºçš„æ•°ç»„ä¸­æ‰¾åˆ°æœ€å°å€¼æˆ–æœ€å¤§å€¼'
- en: '*fractional power*, \(ğ‘¶(ğ’^ğ’„ )\) - where \([0 < c < 1]\), for example, searching
    in a kd-tree, \(ğ‘‚(ğ‘›^(\frac{1}{2}))\)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ†æ•°å¹‚*ï¼Œ\(ğ‘¶(ğ’^ğ’„ )\) - å…¶ä¸­ \([0 < c < 1]\)ï¼Œä¾‹å¦‚ï¼Œåœ¨kdæ ‘ä¸­æœç´¢ï¼Œ\(ğ‘‚(ğ‘›^(\frac{1}{2}))\)'
- en: '*exponential Time*, \(ğ‘¶(ğŸ^ğ’)\) - for example, traveling salesman problem with
    dynamic programing'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æŒ‡æ•°æ—¶é—´*ï¼Œ\(ğ‘¶(ğŸ^ğ’)\) - ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’çš„æ—…è¡Œå•†é—®é¢˜'
- en: '**Conditional Probability**'
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¡ä»¶æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): the probability of
    an event, given another event has occurred,'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåœ¨å¦ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æƒ…å†µä¸‹ï¼Œäº‹ä»¶çš„æ¦‚ç‡ï¼Œ'
- en: \[ P(A|B) = \frac{P(A,B)}{P(A)} \]
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = \frac{P(A,B)}{P(A)} \]
- en: we read this as the probability of A given B has occurred as the joint divided
    by the marginal. We can extend conditional probabilities to any multivariate case
    by adding joints to either component. For example,
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿™è¯»ä½œAåœ¨Bå‘ç”Ÿçš„æƒ…å†µä¸‹å‘ç”Ÿçš„æ¦‚ç‡ï¼Œå³è”åˆæ¦‚ç‡é™¤ä»¥è¾¹ç¼˜æ¦‚ç‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘ä»»ä¸€ç»„ä»¶æ·»åŠ è”åˆæ¥æ‰©å±•æ¡ä»¶æ¦‚ç‡åˆ°ä»»ä½•å¤šå…ƒæƒ…å†µã€‚ä¾‹å¦‚ï¼Œ
- en: \[ P(C|B,A) = \frac{P(A,B,C)}{P(B,C)} \]
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C|B,A) = \frac{P(A,B,C)}{P(B,C)} \]
- en: '**Confidence Interval**'
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç½®ä¿¡åŒºé—´**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): the uncertainty
    in a summary statistic or model parameter represented as a range, lower and upper
    bound, based on a specified probability interval known as the confidence level.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šå°†æ€»ç»“ç»Ÿè®¡é‡æˆ–æ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§è¡¨ç¤ºä¸ºèŒƒå›´ï¼Œä¸‹é™å’Œä¸Šé™ï¼ŒåŸºäºç§°ä¸ºç½®ä¿¡æ°´å¹³çš„æŒ‡å®šæ¦‚ç‡åŒºé—´ã€‚'
- en: We communicate confidence intervals like this,
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿™æ ·ä¼ è¾¾ç½®ä¿¡åŒºé—´ï¼Œ
- en: there is a 95% probability (or 19 times out of 20) that model slope is between
    0.5 and 0.7.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰95%çš„æ¦‚ç‡ï¼ˆæˆ–è€…è¯´20æ¬¡ä¸­çš„19æ¬¡ï¼‰æ¨¡å‹æ–œç‡åœ¨0.5å’Œ0.7ä¹‹é—´ã€‚
- en: Other salient points about confidence intervals,
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºç½®ä¿¡åŒºé—´çš„å…¶ä»–æ˜¾è‘—ç‚¹ï¼Œ
- en: calculated by analytical methods, when available, or with more general and flexible
    bootstrap
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“å¯ç”¨æ—¶ï¼Œé€šè¿‡åˆ†ææ–¹æ³•è®¡ç®—ï¼Œæˆ–ä½¿ç”¨æ›´é€šç”¨å’Œçµæ´»çš„bootstrap
- en: for Bayesian methods we refer credibility intervals
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè´å¶æ–¯æ–¹æ³•ï¼Œæˆ‘ä»¬å‚è€ƒå¯ä¿¡åº¦åŒºé—´
- en: '**Confusion Matrix**'
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ··æ·†çŸ©é˜µ**'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a matrix with frequencies
    of predicted (x axis) vs. actual (y axis) categories to visualize the performance
    of a classification model.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ä¸ªçŸ©é˜µï¼Œè¡¨ç¤ºé¢„æµ‹ï¼ˆxè½´ï¼‰ä¸å®é™…ï¼ˆyè½´ï¼‰ç±»åˆ«é¢‘ç‡ï¼Œä»¥å¯è§†åŒ–åˆ†ç±»æ¨¡å‹çš„æ€§èƒ½ã€‚'
- en: visualize and diagnose all the combinations of correct and misclassification
    with the classification model, for example, category 1 is often misclassified
    as category 3.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ†ç±»æ¨¡å‹å¯è§†åŒ–å¹¶è¯Šæ–­æ‰€æœ‰æ­£ç¡®å’Œé”™è¯¯åˆ†ç±»çš„ç»„åˆï¼Œä¾‹å¦‚ï¼Œç±»åˆ«1ç»å¸¸è¢«é”™è¯¯åˆ†ç±»ä¸ºç±»åˆ«3ã€‚
- en: perfect accuracy is number of each class on the diagonal, category 1 is always
    predicted as category 1, etc.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®Œç¾å‡†ç¡®ç‡æ˜¯æ¯ä¸ªç±»åˆ«åœ¨ä¸»å¯¹è§’çº¿ä¸Šçš„æ•°é‡ï¼Œç±»åˆ«1æ€»æ˜¯è¢«é¢„æµ‹ä¸ºç±»åˆ«1ï¼Œç­‰ç­‰ã€‚
- en: the classification matrix is applied to calculate a single summary of categorical
    accuracy, for example, precision, recall, etc.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†åˆ†ç±»çŸ©é˜µåº”ç”¨äºè®¡ç®—å•ä¸ªåˆ†ç±»å‡†ç¡®æ€§çš„æ€»ç»“ï¼Œä¾‹å¦‚ï¼Œç²¾ç¡®åº¦ã€å¬å›ç‡ç­‰ã€‚
- en: '**Continuous Feature**'
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a feature that
    can take any value between a lower and upper bound. For example,'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªå¯ä»¥å–ä»‹äºä¸‹é™å’Œä¸Šé™ä¹‹é—´ä»»ä½•å€¼çš„ç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œ'
- en: porosity = \(\{13.01\%, 5.23\%, 24.62\%\}\)
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ = \(\{13.01\%, 5.23\%, 24.62\%\}\)
- en: gold grade = \(\{4.56 \text{ g/t}, 8.72 \text{ g/t}, 12.45 \text{ g/t} \}\)
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡‘å“ä½ = \(\{4.56 \text{ g/t}, 8.72 \text{ g/t}, 12.45 \text{ g/t} \}\)
- en: '**Continuous, Interval Feature**'
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­ï¼ŒåŒºé—´ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *continuous feature*
    where the intervals between numbers are equal, for example, the difference between
    1.50 and 2.50 is the same as the difference between 2.50 and 3.50, but the actual
    values do not have an objective, physical reality (exist on an arbitrary scale),
    i.e., do not have a true zero point, for example,'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ª*è¿ç»­ç‰¹å¾*ï¼Œå…¶ä¸­æ•°å­—ä¹‹é—´çš„é—´éš”æ˜¯ç›¸ç­‰çš„ï¼Œä¾‹å¦‚ï¼Œ1.50å’Œ2.50ä¹‹é—´çš„å·®å€¼ä¸2.50å’Œ3.50ä¹‹é—´çš„å·®å€¼ç›¸åŒï¼Œä½†å®é™…å€¼æ²¡æœ‰å®¢è§‚çš„ç‰©ç†ç°å®ï¼ˆå­˜åœ¨äºä»»æ„å°ºåº¦ä¸Šï¼‰ï¼Œå³æ²¡æœ‰çœŸæ­£çš„é›¶ç‚¹ï¼Œä¾‹å¦‚ï¼Œ'
- en: Celsius scale of temperature (an arbitrary scale based on water freezing at
    0 and boiling at 100)
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘„æ°æ¸©åº¦å°ºåº¦ï¼ˆåŸºäºæ°´åœ¨0â„ƒç»“å†°å’Œ100â„ƒæ²¸è…¾çš„ä»»æ„å°ºåº¦ï¼‰
- en: calendar year (there is no true zero year)
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…¬å†å¹´ä»½ï¼ˆæ²¡æœ‰çœŸæ­£çš„é›¶å¹´ï¼‰
- en: We can use addition and subtraction operations to compare continuous, interval
    features.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ æ³•å’Œå‡æ³•è¿ç®—æ¥æ¯”è¾ƒè¿ç»­çš„åŒºé—´ç‰¹å¾ã€‚
- en: '**Continuous, Ratio Feature**'
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­çš„æ¯”ç‡ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *continuous feature*
    where the intervals between numbers are equal, for example, the difference between
    1.50 and 2.50 is the same as the difference between 2.50 and 3.50, but the values
    do have an objective reality (measure an actual physical phenomenon), i.e., do
    have true zero point, for example,'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ª *è¿ç»­ç‰¹å¾*ï¼Œå…¶ä¸­æ•°å­—ä¹‹é—´çš„é—´éš”æ˜¯ç›¸ç­‰çš„ï¼Œä¾‹å¦‚ï¼Œ1.50å’Œ2.50ä¹‹é—´çš„å·®å€¼ä¸2.50å’Œ3.50ä¹‹é—´çš„å·®å€¼ç›¸åŒï¼Œä½†æ•°å€¼ç¡®å®å…·æœ‰å®¢è§‚ç°å®æ€§ï¼ˆè¡¡é‡å®é™…ç‰©ç†ç°è±¡ï¼‰ï¼Œå³ï¼Œç¡®å®æœ‰çœŸæ­£çš„é›¶ç‚¹ï¼Œä¾‹å¦‚ï¼Œ'
- en: Kelvin scale of temperature
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼€å°”æ–‡æ¸©åº¦å°ºåº¦
- en: porosity
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡
- en: permeability
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€æ°´æ€§
- en: saturation
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¥±å’Œ
- en: Since there is a true zero, continuous, ratio features can be compared with
    multiplication and division mathematical operations (in addition to addition and
    subtraction), e.g., twice as much porosity.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå­˜åœ¨çœŸæ­£çš„é›¶ç‚¹ï¼Œè¿ç»­çš„æ¯”ç‡ç‰¹å¾å¯ä»¥é€šè¿‡ä¹˜æ³•å’Œé™¤æ³•æ•°å­¦è¿ç®—ï¼ˆé™¤äº†åŠ æ³•å’Œå‡æ³•ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œä¾‹å¦‚ï¼Œå­”éš™ç‡æ˜¯ä¸¤å€ã€‚
- en: '**Continuously Differentiable**'
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­å¯å¾®**'
- en: '[Machine Learning Training and Tuning](MachineLearning_training_tuning.html):
    a function is continuously differentiable if it satisfies two key conditions:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ è®­ç»ƒå’Œè°ƒä¼˜](MachineLearning_training_tuning.html)ï¼šä¸€ä¸ªå‡½æ•°å¦‚æœæ»¡è¶³ä¸¤ä¸ªå…³é”®æ¡ä»¶ï¼Œåˆ™å®ƒæ˜¯è¿ç»­å¯å¾®çš„ï¼š'
- en: The function is differentiable, the derivative of the function exists at every
    point in its domain, i.e., the function has a well-defined slope at every possible
    point.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡½æ•°æ˜¯å¯å¾®çš„ï¼Œå‡½æ•°åœ¨å…¶å®šä¹‰åŸŸå†…çš„æ¯ä¸€ç‚¹éƒ½å­˜åœ¨å¯¼æ•°ï¼Œå³å‡½æ•°åœ¨æ¯ä¸€ä¸ªå¯èƒ½çš„ç‚¹ä¸Šéƒ½æœ‰ä¸€ä¸ªæ˜ç¡®çš„æ–œç‡ã€‚
- en: The derivative is continuous, the derivative of the function does not have any
    jumps, discontinuities, or abrupt changes, i.e, the derivative function itself
    is continuous at every point in its domain.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¼æ•°æ˜¯è¿ç»­çš„ï¼Œå‡½æ•°çš„å¯¼æ•°æ²¡æœ‰è·³è·ƒã€ä¸è¿ç»­æˆ–çªç„¶å˜åŒ–ï¼Œå³ï¼Œå¯¼æ•°å‡½æ•°åœ¨å…¶å®šä¹‰åŸŸçš„æ¯ä¸€ç‚¹ä¸Šéƒ½æ˜¯è¿ç»­çš„ã€‚
- en: For a machine learning example,
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€ä¸ªæœºå™¨å­¦ä¹ ç¤ºä¾‹ï¼Œ
- en: the \(L^2\) norm is continuously differentiable and as a result for linear and
    ridge regression we can apply partial derivatives to the loss function to calculate
    a closed form of training the model parameters
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(L^2\) èŒƒæ•°çš„å¯¼æ•°æ˜¯è¿ç»­å¯å¾®çš„ï¼Œå› æ­¤å¯¹äºçº¿æ€§å›å½’å’Œå²­å›å½’ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æŸå¤±å‡½æ•°åº”ç”¨åå¯¼æ•°æ¥è®¡ç®—æ¨¡å‹å‚æ•°è®­ç»ƒçš„é—­å¼è§£ã€‚
- en: the \(L^1\) norm is not continuously differentiable and as a result for LASSO
    regression we cannot apply partial derivatives to the loss function to calculate
    a closed form of training the model parameters. We must use iterative optimization
    to train the model parameters.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(L^1\) èŒƒæ•°çš„å¯¼æ•°ä¸æ˜¯è¿ç»­å¯å¾®çš„ï¼Œå› æ­¤å¯¹äºLASSOå›å½’ï¼Œæˆ‘ä»¬ä¸èƒ½å¯¹æŸå¤±å‡½æ•°åº”ç”¨åå¯¼æ•°æ¥è®¡ç®—æ¨¡å‹å‚æ•°è®­ç»ƒçš„é—­å¼è§£ã€‚æˆ‘ä»¬å¿…é¡»ä½¿ç”¨è¿­ä»£ä¼˜åŒ–æ¥è®­ç»ƒæ¨¡å‹å‚æ•°ã€‚
- en: '**Convolution**'
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å·ç§¯**'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): Integral
    product of two functions, after one is reversed and shifted by \(\Delta\).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»ç®—æ³•](MachineLearning_knearest_neighbours.html)ï¼šä¸¤ä¸ªå‡½æ•°çš„ç§¯åˆ†ä¹˜ç§¯ï¼Œå…¶ä¸­ä¸€ä¸ªå‡½æ•°ç»è¿‡åè½¬å¹¶å¹³ç§»
    \(\Delta\)ã€‚'
- en: one interpretation is smoothing a function with weighting function, \(ğ‘“(\Delta)\),
    is applied to calculate the weighted average of function, \(ğ‘”(x)\),
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£é‡Šæ˜¯å°†åŠ æƒå‡½æ•° \(ğ‘“(\Delta)\) åº”ç”¨äºå¹³æ»‘å‡½æ•°ï¼Œä»¥è®¡ç®—å‡½æ•° \(ğ‘”(x)\) çš„åŠ æƒå¹³å‡å€¼ï¼Œ
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
- en: this easily extends into multidimensional
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå®¹æ˜“æ‰©å±•åˆ°å¤šç»´
- en: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
- en: The choice of which function is shifted before integration does not change the
    result, the convolution operator has commutativity.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç§¯åˆ†ä¹‹å‰é€‰æ‹©å“ªä¸ªå‡½æ•°è¿›è¡Œå¹³ç§»ä¸ä¼šæ”¹å˜ç»“æœï¼Œå·ç§¯ç®—å­å…·æœ‰äº¤æ¢æ€§ã€‚
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
- en: if either function is reflected then convolution is equivalent to cross-correlation,
    measure of similarity between 2 signals as a function of displacement.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä»»ä¸€å‡½æ•°è¢«åå°„ï¼Œåˆ™å·ç§¯ç­‰ä»·äºäº’ç›¸å…³ï¼Œä½œä¸ºä½ç§»å‡½æ•°çš„ä¿¡å·ç›¸ä¼¼åº¦åº¦é‡ã€‚
- en: '**Core Data**'
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ¸å¿ƒæ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the primary sampling
    method for direct measure for subsurface resources (recovered drill cuttings are
    also direct measures with greater uncertainty and smaller, irregular scale). Comments
    on core data,'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šç›´æ¥æµ‹é‡åœ°ä¸‹èµ„æºï¼ˆå›æ”¶çš„é’»å±‘ä¹Ÿæ˜¯ç›´æ¥æµ‹é‡ï¼Œå…·æœ‰æ›´å¤§çš„ä¸ç¡®å®šæ€§å’Œè¾ƒå°çš„ã€ä¸è§„åˆ™çš„æ¯”ä¾‹ï¼‰çš„ä¸»è¦é‡‡æ ·æ–¹æ³•ã€‚å¯¹æ ¸å¿ƒæ•°æ®çš„è¯„è®ºï¼Œ'
- en: expensive / time consuming to collect for oil and gas, interrupt drilling operations,
    sparse and selective (very biased) coverage
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºçŸ³æ²¹å’Œå¤©ç„¶æ°”æ¥è¯´ï¼Œæ”¶é›†æˆæœ¬é«˜æ˜‚/è€—æ—¶ï¼Œä¼šä¸­æ–­é’»äº•ä½œä¸šï¼Œè¦†ç›–ç¨€ç–ä¸”å…·æœ‰é€‰æ‹©æ€§ï¼ˆéå¸¸åé¢‡ï¼‰
- en: very common in mining (diamond drill holes) for grade control with regular patterns
    and tight spacing
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é‡‡çŸ¿ï¼ˆé’»çŸ³é’»æ¢å­”ï¼‰ä¸­éå¸¸å¸¸è§ï¼Œç”¨äºå…·æœ‰è§„åˆ™å›¾æ¡ˆå’Œç´§å¯†é—´è·çš„å“ä½æ§åˆ¶
- en: gravity, piston, etc. coring are used to sample sediments in lakes and oceans
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡åŠ›ã€æ´»å¡ç­‰å–å¿ƒæ–¹æ³•ç”¨äºåœ¨æ¹–æ³Šå’Œæµ·æ´‹ä¸­å–æ ·æ²‰ç§¯ç‰©
- en: What do we learn from core data?
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»æ ¸å¿ƒæ•°æ®ä¸­å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ
- en: petrological features (sedimentary structures, mineral grades), petrophysical
    features (porosity, permeability), and mechanical features (elastic modulas, Poissonâ€™s
    ratio)
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å²©æ€§ç‰¹å¾ï¼ˆæ²‰ç§¯ç»“æ„ï¼ŒçŸ¿ç‰©ç­‰çº§ï¼‰ï¼Œå²©çŸ³ç‰©ç†ç‰¹å¾ï¼ˆå­”éš™åº¦ï¼Œæ¸—é€ç‡ï¼‰ï¼Œä»¥åŠåŠ›å­¦ç‰¹å¾ï¼ˆå¼¹æ€§æ¨¡é‡ï¼Œæ³Šæ¾æ¯”ï¼‰
- en: stratigraphy and ore body geometry through interpolation between wells and drill
    holes
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡äº•å’Œé’»æ¢å­”ä¹‹é—´çš„æ’å€¼æ¥è·å–åœ°å±‚å’ŒçŸ¿ä½“å‡ ä½•å½¢çŠ¶
- en: Core data are critical to support subsurface resource interpretations. They
    anchor the entire reservoir concept and framework for prediction,
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¸å¿ƒæ•°æ®å¯¹äºæ”¯æŒåœ°ä¸‹èµ„æºè§£é‡Šè‡³å…³é‡è¦ã€‚å®ƒä»¬æ˜¯æ•´ä¸ªå‚¨å±‚æ¦‚å¿µå’Œé¢„æµ‹æ¡†æ¶çš„é”šç‚¹ï¼Œ
- en: for example, core data collocated with well log data are used to calibrate (ground
    truth) facies, porosity from well logs
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸äº•æ—¥å¿—æ•°æ®åŒä½çš„æ ¸å¿ƒæ•°æ®ç”¨äºæ ¡å‡†ï¼ˆåœ°é¢çœŸå®ï¼‰å²©æ€§ï¼Œä»äº•æ—¥å¿—ä¸­è·å–å­”éš™åº¦
- en: '**Correlation**'
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›¸å…³æ€§**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): the Pearsonâ€™s
    product-moment correlation coefficient is a measure of the degree of linear relationship,'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šçš®å°”é€Šç§¯çŸ©ç›¸å…³ç³»æ•°æ˜¯çº¿æ€§å…³ç³»ç¨‹åº¦çš„åº¦é‡ï¼Œ'
- en: \[ \rho_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)\sigma_x
    \sigma_y} \]
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)\sigma_x
    \sigma_y} \]
- en: where \(\overline{x}\) and \(\overline{y}\) are the means of features \(x\)
    and \(y\). The measure is bound \(\[-1,1\]\).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\overline{y}\) æ˜¯ç‰¹å¾ \(x\) å’Œ \(y\) çš„å‡å€¼ã€‚è¯¥åº¦é‡è¢«é™åˆ¶åœ¨ \(\[-1,1\]\)ã€‚
- en: correlation coefficient is a standardized covariance
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å…³ç³»æ•°æ˜¯æ ‡å‡†åŒ–çš„åæ–¹å·®
- en: The Personâ€™s correlation coefficient is quite sensitive to outliers and departure
    from linear behavior (in the bivariate sense). We have an alternative known as
    the Spearmanâ€™s rank correlations coefficient,
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ä½©å°”é€Šç›¸å…³ç³»æ•°å¯¹å¼‚å¸¸å€¼å’Œåç¦»çº¿æ€§è¡Œä¸ºï¼ˆåœ¨åŒå˜é‡æ„ä¹‰ä¸Šï¼‰éå¸¸æ•æ„Ÿã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªç§°ä¸ºæ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•°çš„æ›¿ä»£æ–¹æ¡ˆï¼Œ
- en: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
- en: The rank correlation applies the rank transform to the data prior to calculating
    the correlation coefficient. To calculate the rank transform simply replace the
    data values with the rank \(R_x = 1,\dots,n\), where \(n\) is the maximum value
    and \(1\) is the minimum value.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: æ’åºç›¸å…³ç³»æ•°åœ¨è®¡ç®—ç›¸å…³ç³»æ•°ä¹‹å‰å°†æ•°æ®åº”ç”¨æ’åºå˜æ¢ã€‚è¦è®¡ç®—æ’åºå˜æ¢ï¼Œåªéœ€å°†æ•°æ®å€¼æ›¿æ¢ä¸ºæ’å \(R_x = 1,\dots,n\)ï¼Œå…¶ä¸­ \(n\) æ˜¯æœ€å¤§å€¼ï¼Œ\(1\)
    æ˜¯æœ€å°å€¼ã€‚
- en: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
- en: '**Covariance**'
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åæ–¹å·®**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): a measure
    of how two features vary together,'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šè¡¡é‡ä¸¤ä¸ªç‰¹å¾å¦‚ä½•ä¸€èµ·å˜åŒ–ï¼Œ'
- en: \[ C_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)}
    \]
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: \[ C_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)}
    \]
- en: where \(\overline{x}\) and \(\overline{y}\) are the means of features \(x\)
    and \(y\). The measure is bound \(\[-\sigma_x \cdot \sigm_y,\sigma_x \cdot \sigm_y\]\).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\overline{y}\) æ˜¯ç‰¹å¾ \(x\) å’Œ \(y\) çš„å‡å€¼ã€‚è¯¥åº¦é‡è¢«é™åˆ¶åœ¨ \(\[-\sigma_x
    \cdot \sigm_y,\sigma_x \cdot \sigm_y\]\)ã€‚
- en: correlation coefficient is a standardized covariance
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å…³ç³»æ•°æ˜¯æ ‡å‡†åŒ–çš„åæ–¹å·®
- en: The Personâ€™s correlation coefficient is quite sensitive to outliers and departure
    from linear behavior (in the bivariate sense). We have an alternative known as
    the Spearmanâ€™s rank correlations coefficient,
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ä½©å°”æ£®ç›¸å…³ç³»æ•°å¯¹å¼‚å¸¸å€¼å’Œåç¦»çº¿æ€§è¡Œä¸ºï¼ˆåœ¨åŒå˜é‡æ„ä¹‰ä¸Šï¼‰éå¸¸æ•æ„Ÿã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªç§°ä¸ºæ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•°çš„æ›¿ä»£æ–¹æ¡ˆï¼Œ
- en: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
- en: The rank correlation applies the rank transform to the data prior to calculating
    the correlation coefficient. To calculate the rank transform simply replace the
    data values with the rank \(R_x = 1,\dots,n\), where \(n\) is the maximum value
    and \(1\) is the minimum value.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: æ’åºç›¸å…³ç³»æ•°åœ¨è®¡ç®—ç›¸å…³ç³»æ•°ä¹‹å‰å°†ç§©å˜æ¢åº”ç”¨äºæ•°æ®ã€‚è¦è®¡ç®—ç§©å˜æ¢ï¼Œåªéœ€å°†æ•°æ®å€¼æ›¿æ¢ä¸ºç§© \(R_x = 1,\dots,n\)ï¼Œå…¶ä¸­ \(n\) æ˜¯æœ€å¤§å€¼ï¼Œ\(1\)
    æ˜¯æœ€å°å€¼ã€‚
- en: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
- en: '**Cross Validation**'
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº¤å‰éªŒè¯**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): withholding a portion
    of the data from the model parameter training to test the ability of the model
    to predict for cases not used to train the model'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨æ¨¡å‹å‚æ•°è®­ç»ƒä¸­ä¿ç•™éƒ¨åˆ†æ•°æ®ä»¥æµ‹è¯•æ¨¡å‹é¢„æµ‹æœªç”¨äºè®­ç»ƒæ¨¡å‹æ¡ˆä¾‹çš„èƒ½åŠ›'
- en: this is typically conducted by a train and test data split, with 15% - 30% of
    data assigned to testing
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™é€šå¸¸é€šè¿‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²æ¥å®Œæˆï¼Œå…¶ä¸­ 15% - 30% çš„æ•°æ®åˆ†é…ç»™æµ‹è¯•
- en: a dress rehearsal for real-world model use, the train-test split must be fair,
    resulting in similar prediction difficulty to the planned use of the model
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½œä¸ºç°å®ä¸–ç•Œæ¨¡å‹ä½¿ç”¨çš„å½©æ’ï¼Œè®­ç»ƒ-æµ‹è¯•åˆ†å‰²å¿…é¡»æ˜¯å…¬å¹³çš„ï¼Œä»è€Œäº§ç”Ÿä¸è®¡åˆ’ä½¿ç”¨æ¨¡å‹ç›¸ä¼¼çš„é¢„æµ‹éš¾åº¦
- en: there are more complicated designs such as k-fold cross validation that allows
    testing over all data via k-folds each with trained model
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­˜åœ¨æ›´å¤æ‚çš„è®¾è®¡ï¼Œå¦‚ k æŠ˜äº¤å‰éªŒè¯ï¼Œå®ƒå…è®¸é€šè¿‡ k æŠ˜æ¯æŠ˜éƒ½è®­ç»ƒæ¨¡å‹æ¥æµ‹è¯•æ‰€æœ‰æ•°æ®
- en: cross validation may be applied to check model performance for estimation accuracy
    (most common) and uncertainty model goodness ([Maldonado-Cruz and Pyrcz, 2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343))
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº¤å‰éªŒè¯å¯ä»¥åº”ç”¨äºæ£€æŸ¥æ¨¡å‹æ€§èƒ½ä»¥è¯„ä¼°ä¼°è®¡ç²¾åº¦ï¼ˆæœ€å¸¸è§ï¼‰å’Œä¸ç¡®å®šæ€§æ¨¡å‹çš„å¥½åï¼ˆ[Maldonado-Cruz and Pyrcz, 2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343)ï¼‰
- en: '**Cumulative Distribution Function** (CDF)'
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç´¯ç§¯åˆ†å¸ƒå‡½æ•°** (CDF)'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): the sum of
    a discrete PDF or the integral of a continuous PDF. Here are the important concepts,'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šç¦»æ•£æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰çš„æ€»å’Œæˆ–è¿ç»­æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰çš„ç§¯åˆ†ã€‚ä»¥ä¸‹æ˜¯é‡è¦æ¦‚å¿µï¼Œ'
- en: the CDF is stated as \(F_x(x)\), note the PDF is stated as \(f_x(x)\)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰è¡¨ç¤ºä¸º \(F_x(x)\)ï¼Œæ³¨æ„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰è¡¨ç¤ºä¸º \(f_x(x)\)
- en: is the probability that a random sample, \(X\), is less than or equal to a specific
    value \(x\); therefore, the y axis is cumulative probability
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜¯éšæœºæ ·æœ¬ \(X\) å°äºæˆ–ç­‰äºç‰¹å®šå€¼ \(x\) çš„æ¦‚ç‡ï¼›å› æ­¤ï¼Œy è½´æ˜¯ç´¯ç§¯æ¦‚ç‡
- en: \[ F_x(x) = P(X \le x) = \int_{-infty}^x f(u) du \]
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_x(x) = P(X \le x) = \int_{-infty}^x f(u) du \]
- en: for CDFs there is no bin assumption; therefore, bins are at the resolution of
    the data.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ï¼Œæ²¡æœ‰ç®±å‡è®¾ï¼›å› æ­¤ï¼Œç®±çš„åˆ†è¾¨ç‡ä¸æ•°æ®ç›¸åŒã€‚
- en: monotonically non-decreasing function, because a negative slope would indicate
    negative probability over an interval.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•è°ƒä¸å‡å‡½æ•°ï¼Œå› ä¸ºè´Ÿæ–œç‡ä¼šè¡¨æ˜åœ¨åŒºé—´ä¸Šæœ‰è´Ÿæ¦‚ç‡ã€‚
- en: The requirements for a valid CDF include,
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰çš„è¦æ±‚åŒ…æ‹¬ï¼Œ
- en: 'non-negativity constraint:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éè´Ÿçº¦æŸï¼š
- en: \[ F_x(x) = P(X \le x) \ge 0.0, \quad \forall x \]
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_x(x) = P(X \le x) \ge 0.0, \quad \forall x \]
- en: 'valid probability:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆæ¦‚ç‡ï¼š
- en: \[ 0.0 \le F_x(x) \le 1.0, \quad \forall x \]
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0.0 \le F_x(x) \le 1.0, \quad \forall x \]
- en: 'cannot have negative slope:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸èƒ½æœ‰è´Ÿæ–œç‡ï¼š
- en: \[ \frac{dF_x(x)}{dx} \ge 0.0, \quad \forall x \]
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dF_x(x)}{dx} \ge 0.0, \quad \forall x \]
- en: 'minimum and maximum (ensuring probability closure) values:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€å°å’Œæœ€å¤§ï¼ˆç¡®ä¿æ¦‚ç‡å°é—­ï¼‰å€¼ï¼š
- en: \[ \text{min}(F_x(x)) = 0.0 \quad \text{max}(F_x(x)) = 1.0 \]
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{min}(F_x(x)) = 0.0 \quad \text{max}(F_x(x)) = 1.0 \]
- en: '**Curse of Dimensionality**'
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»´åº¦è¯…å’’**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): the suite of challenges
    associated with working with many features, i.e., high dimensional space, including,'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸å¤„ç†è®¸å¤šç‰¹å¾ç›¸å…³çš„ä¸€ç³»åˆ—æŒ‘æˆ˜ï¼Œå³é«˜ç»´ç©ºé—´ï¼ŒåŒ…æ‹¬ï¼Œ'
- en: impossible to visualize data and model in high dimensionality space
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é«˜ç»´ç©ºé—´ä¸­æ— æ³•å¯è§†åŒ–å’Œæ¨¡å‹æ•°æ®
- en: usually insufficient sampling for statistical inference in vast high dimensional
    space
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸åœ¨å¹¿é˜”çš„é«˜ç»´ç©ºé—´ä¸­ï¼Œé‡‡æ ·ä¸è¶³ä»¥è¿›è¡Œç»Ÿè®¡æ¨æ–­
- en: low coverage of high dimensional predictor feature space
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜ç»´é¢„æµ‹ç‰¹å¾ç©ºé—´çš„ä½è¦†ç›–åº¦
- en: distorted feature space, including warped space dominated by corners and distances
    lose sensitivity
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰­æ›²çš„ç‰¹å¾ç©ºé—´ï¼ŒåŒ…æ‹¬ç”±è§’å’Œè·ç¦»ä¸»å¯¼çš„æ‰­æ›²ç©ºé—´ï¼Œè·ç¦»å¤±å»æ•æ„Ÿæ€§
- en: multicollinearity between features is more likely as the dimensionality increases
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€ç»´åº¦çš„å¢åŠ ï¼Œç‰¹å¾ä¹‹é—´çš„å¤šé‡å…±çº¿æ€§æ›´å¯èƒ½
- en: '**Data** (data aspects)'
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®**ï¼ˆæ•°æ®æ–¹é¢ï¼‰'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): when describing spatial
    dataset these are the fundamental aspects,'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šåœ¨æè¿°ç©ºé—´æ•°æ®é›†æ—¶ï¼Œè¿™äº›æ˜¯åŸºæœ¬æ–¹é¢ï¼Œ'
- en: '*Data coverage* - what proportion of the population has been sampled for this?'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®è¦†ç›–èŒƒå›´* - å¯¹äºè¿™æ¬¡è°ƒæŸ¥ï¼Œæœ‰å¤šå°‘æ¯”ä¾‹çš„äººå£è¢«é‡‡æ ·ï¼Ÿ'
- en: In general, hard data has high resolution (small scale, volume support), but
    with poor data coverage (measure only an extremely small proportion of the population,
    for example,
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç¡¬æ•°æ®å…·æœ‰é«˜åˆ†è¾¨ç‡ï¼ˆå°è§„æ¨¡ã€ä½“ç§¯æ”¯æŒï¼‰ï¼Œä½†æ•°æ®è¦†ç›–èŒƒå›´è¾ƒå·®ï¼ˆä»…æµ‹é‡äººå£ä¸­çš„æå°æ¯”ä¾‹ï¼Œä¾‹å¦‚ï¼Œ
- en: '*Core coverage deepwater oil and gas* - well core only sample one five hundred
    millionth to one five billionth of a deepwater reservoir, assuming 3 inch diameter
    cores with 10% core coverage in vertical wells with 500 m to 1,500 m spacing'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ·±æ°´æ²¹æ°”æ ¸å¿ƒè¦†ç›–èŒƒå›´* - äº•ç­’æ ¸å¿ƒä»…é‡‡æ ·æ·±æ°´å‚¨å±‚çš„ä¸€äº¿äº”åƒä¸‡åˆ†ä¹‹ä¸€åˆ°ä¸€äº¿äº”åƒä¸‡åˆ†ä¹‹ä¸€ï¼Œå‡è®¾3è‹±å¯¸ç›´å¾„çš„æ ¸å¿ƒåœ¨å‚ç›´äº•ä¸­ä»¥500ç±³åˆ°1500ç±³çš„é—´è·æœ‰10%çš„æ ¸å¿ƒè¦†ç›–'
- en: '*Core coverage mining grade control* - diamond drill hole cores sample one
    eight thousandth to one thirty thousandth of ore body, assuming HQ 63.5 mm diameter
    cores with 100% core coverage in vertical drill holes with 5 m to 10 m spacing'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–é‡‡çŸ¿çº§æ§åˆ¶* - é’»å­”æ ¸å¿ƒæ ·å“é‡‡æ ·çŸ¿çŸ³ä½“ç§¯çš„å…«ä¸‡åˆ†ä¹‹ä¸€åˆ°ä¸‰åä¸‡åˆ†ä¹‹ä¸€ï¼Œå‡è®¾HQ 63.5æ¯«ç±³ç›´å¾„çš„æ ¸å¿ƒåœ¨å‚ç›´é’»å­”ä¸­ä»¥5ç±³åˆ°10ç±³çš„é—´è·æœ‰100%çš„æ ¸å¿ƒè¦†ç›–'
- en: Soft data tend to have excellent (often complete) coverage, but with low resolution,
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: è½¯æ•°æ®å¾€å¾€å…·æœ‰å‡ºè‰²çš„ï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„ï¼‰è¦†ç›–èŒƒå›´ï¼Œä½†åˆ†è¾¨ç‡ä½ï¼Œ
- en: '*Seismic reflection surveys and gradiometric surveys* - data is generally available
    over the entire volume of interest, but resolution is low and generally decreasing
    with depth'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åœ°éœ‡åå°„è°ƒæŸ¥å’Œé‡åŠ›æµ‹é‡è°ƒæŸ¥* - æ•°æ®é€šå¸¸åœ¨æ•´ä¸ªæ„Ÿå…´è¶£ä½“ç§¯ä¸­å¯ç”¨ï¼Œä½†åˆ†è¾¨ç‡ä½ï¼Œå¹¶ä¸”é€šå¸¸éšç€æ·±åº¦çš„å¢åŠ è€Œé™ä½'
- en: '*Data Scale* (support size) - What is the scale or volume sampled by the individual
    samples? For example,'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®è§„æ¨¡*ï¼ˆæ”¯æŒå¤§å°ï¼‰- å•ä¸ªæ ·æœ¬é‡‡æ ·çš„è§„æ¨¡æˆ–ä½“ç§¯æ˜¯ä»€ä¹ˆï¼Ÿä¾‹å¦‚ï¼Œ'
- en: core tomography images of core samples at the pore scale, 1 - 50 \(\mu m\)
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¸æ ·å“åœ¨å­”éš™å°ºåº¦ä¸Šçš„æ ¸ç£å…±æŒ¯å›¾åƒï¼Œ1 - 50 \(\mu m\)
- en: gamma ray well log sampled at 0.3 m intervals with 1 m penetration away from
    the bore hole
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥0.3ç±³é—´éš”åœ¨ç¦»äº•ç­’1ç±³å¤„é‡‡æ ·çš„ä¼½é©¬å°„çº¿æµ‹äº•
- en: ground-based gravity gradiometry map with 20 m x 20 m x 100 m resolution
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥20ç±³x20ç±³x100ç±³åˆ†è¾¨ç‡çš„åœ°é¢é‡åŠ›æ¢¯åº¦æµ‹é‡å›¾
- en: '*Data Information Type* - What does the data tell us about the subsurface?
    For example,'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®ä¿¡æ¯ç±»å‹* - æ•°æ®å‘Šè¯‰æˆ‘ä»¬å…³äºåœ°ä¸‹ç»“æ„ä»€ä¹ˆä¿¡æ¯ï¼Ÿä¾‹å¦‚ï¼Œ'
- en: grain size distribution that may be applied to calibrate permeability and saturations
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ç”¨äºæ ¡å‡†æ¸—é€ç‡å’Œé¥±å’Œåº¦çš„ç²’åº¦åˆ†å¸ƒ
- en: fluid type to assess the location of the oil water contact
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµä½“ç±»å‹ä»¥è¯„ä¼°æ²¹æ°´æ¥è§¦ç‚¹ä½ç½®
- en: dip and continuity of important reservoir layers to access connectivity
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡è¦çš„å‚¨å±‚å±‚æ®µçš„å€¾è§’å’Œè¿ç»­æ€§ï¼Œä»¥è·å–è¿é€šæ€§
- en: mineral grade to map high, mid and low grade ore shells for mine planning
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çŸ¿çŸ³å“ä½ä»¥ç»˜åˆ¶é«˜ã€ä¸­ã€ä½å“ä½çŸ¿çŸ³å£³ä½“ï¼Œç”¨äºçŸ¿å±±è§„åˆ’
- en: '**Data Convexity**'
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®å‡¸æ€§**'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    a subset, \(A\), of Euclidean feature space is convex if, for any two points \(ğ‘¥_1\)
    and \(ğ‘¥_2\) within \(ğ´\), the entire line segment connecting these points is within
    \(A\), \(\left[ğ‘¥_1,ğ‘¥_2\right] \in A\).'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœæ¬§å‡ é‡Œå¾—ç‰¹å¾ç©ºé—´çš„ä¸€ä¸ªå­é›† \(A\)
    å¯¹äº \(A\) å†…çš„ä»»æ„ä¸¤ç‚¹ \(ğ‘¥_1\) å’Œ \(ğ‘¥_2\)ï¼Œè¿æ¥è¿™äº›ç‚¹çš„æ•´ä¸ªçº¿æ®µéƒ½åœ¨ \(A\) å†…ï¼Œåˆ™ \(A\) æ˜¯å‡¸çš„ï¼Œ\(\left[ğ‘¥_1,ğ‘¥_2\right]
    \in A\)ã€‚'
- en: '**DataFrame**'
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DataFrame**'
- en: 'Machine Learning Workflow Construction and Coding: a convenient Pandas class
    for working with data tables with rows for each sample and columns for each feature,
    due to,'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šä¸€ä¸ªæ–¹ä¾¿çš„Pandasç±»ï¼Œç”¨äºå¤„ç†å…·æœ‰æ¯è¡Œä¸€ä¸ªæ ·æœ¬å’Œæ¯åˆ—ä¸€ä¸ªç‰¹å¾çš„è¡¨æ ¼æ•°æ®ï¼Œå› ä¸ºï¼Œ
- en: convenient data structure to store, access, manipulate tabular data
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹ä¾¿çš„æ•°æ®ç»“æ„ï¼Œç”¨äºå­˜å‚¨ã€è®¿é—®ã€æ“ä½œè¡¨æ ¼æ•°æ®
- en: built-in methods to load data from a variety of file types, Python classes and
    even directly from Excel
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®ä»å„ç§æ–‡ä»¶ç±»å‹ã€Pythonç±»ç”šè‡³ç›´æ¥ä»ExcelåŠ è½½æ•°æ®çš„æ–¹æ³•
- en: built-in methods to calculate summary statistics and visualize data
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®è®¡ç®—æ±‡æ€»ç»Ÿè®¡å’Œå¯è§†åŒ–æ•°æ®çš„æ–¹æ³•
- en: built-in methods for data queries, sort, data filters
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®çš„æ•°æ®æŸ¥è¯¢ã€æ’åºã€æ•°æ®è¿‡æ»¤æ–¹æ³•
- en: built-in methods for data manipulation, cleaning, reformatting
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®çš„æ•°æ®æ“ä½œã€æ¸…ç†ã€é‡æ–°æ ¼å¼åŒ–æ–¹æ³•
- en: built-in attributes to store information about the data, e.g. size, number nulls
    and null value
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®å±æ€§ç”¨äºå­˜å‚¨æœ‰å…³æ•°æ®çš„ä¿¡æ¯ï¼Œä¾‹å¦‚å¤§å°ã€ç©ºå€¼æ•°é‡å’Œç©ºå€¼
- en: '**Data Analytics**'
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®åˆ†æ**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the use of statistics
    with visualization to support decision making.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä½¿ç”¨ç»Ÿè®¡ä¸å¯è§†åŒ–æ¥æ”¯æŒå†³ç­–ã€‚'
- en: Dr. Pyrcz says that data analytics is the same as statistics.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pyrczåšå£«è¡¨ç¤ºï¼Œæ•°æ®åˆ†æä¸ç»Ÿè®¡å­¦ç›¸åŒã€‚
- en: '**Data Preparation**'
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®å‡†å¤‡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): any workflow steps
    to enhance, improve raw data to be model ready.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä»»ä½•å¢å¼ºã€æ”¹è¿›åŸå§‹æ•°æ®ä»¥å‡†å¤‡æ¨¡å‹çš„å·¥ä½œæµç¨‹æ­¥éª¤ã€‚'
- en: data-driven science needs data, data preparation remains essential
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®é©±åŠ¨ç§‘å­¦éœ€è¦æ•°æ®ï¼Œæ•°æ®å‡†å¤‡ä»ç„¶è‡³å…³é‡è¦
- en: \(\gt >80\%\) of any subsurface study is data preparation and interpretation
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\gt >80\%\)çš„ä»»ä½•åœ°ä¸‹ç ”ç©¶éƒ½æ˜¯æ•°æ®å‡†å¤‡å’Œè§£é‡Š
- en: 'We continue to face a challenge with data:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»§ç»­é¢ä¸´æ•°æ®æŒ‘æˆ˜ï¼š
- en: data curation - format standards, version control, storage, transmission, security
    and documentation
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®æ•´ç† - æ ¼å¼æ ‡å‡†ã€ç‰ˆæœ¬æ§åˆ¶ã€å­˜å‚¨ã€ä¼ è¾“ã€å®‰å…¨å’Œæ–‡æ¡£
- en: large volume to manage - visualization, availability and data mining and exploration
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®¡ç†å¤§é‡æ•°æ® - å¯è§†åŒ–ã€å¯ç”¨æ€§å’Œæ•°æ®æŒ–æ˜ä¸æ¢ç´¢
- en: large volumes of metadata - lack of platforms, standards and formats
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§é‡çš„å…ƒæ•°æ® - ç¼ºä¹å¹³å°ã€æ ‡å‡†å’Œæ ¼å¼
- en: engineering integration, variety of data, scale, interpretation and uncertainty
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å·¥ç¨‹é›†æˆã€æ•°æ®å¤šæ ·æ€§ã€è§„æ¨¡ã€è§£é‡Šå’Œä¸ç¡®å®šæ€§
- en: Clean databases are prerequisite to all data analytics and machine learning
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: æ¸…æ´æ•°æ®åº“æ˜¯æ‰€æœ‰æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„å…ˆå†³æ¡ä»¶
- en: must start with this foundation
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¿…é¡»ä»è¿™ä¸ªåŸºç¡€å¼€å§‹
- en: garbage in, garbage out
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾“å…¥åƒåœ¾ï¼Œè¾“å‡ºåƒåœ¾
- en: '**Degree Matrix** (spectral clustering)'
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åº¦çŸ©é˜µ**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph with the number of connections for each graph nodes, samples.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šè¡¨ç¤ºå›¾çš„ä¸€ä¸ªçŸ©é˜µï¼Œæ¯ä¸ªå›¾èŠ‚ç‚¹ã€æ ·æœ¬çš„è¿æ¥æ•°ã€‚'
- en: diagonal matrix with integer for number of connections
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è§’çŸ©é˜µï¼Œç”¨æ•´æ•°è¡¨ç¤ºè¿æ¥æ•°
- en: '**DBSCAN for Density-based Clustering**'
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå¯†åº¦çš„èšç±»DBSCAN**'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    an density-based clustering algorithm, groups are seeded or grown in feature space
    at locations with sufficient point density determined by hyperparameters,'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šä¸€ç§åŸºäºå¯†åº¦çš„èšç±»ç®—æ³•ï¼Œç°‡åœ¨ç‰¹å¾ç©ºé—´ä¸­ä»¥è¶…å‚æ•°ç¡®å®šçš„è¶³å¤Ÿç‚¹å¯†åº¦ä½ç½®ç”Ÿæˆæˆ–æ‰©å±•ã€‚'
- en: \(\epsilon\) â€“ the radius of the local neighbourhood in the metric of normalized
    features. The is the scale / resolution of the clusters. If this values is set
    too small, too many samples are left as outliers and if set too large, all the
    clusters merge to one single cluster.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\epsilon\) â€“ åœ¨å½’ä¸€åŒ–ç‰¹å¾ç©ºé—´ä¸­å±€éƒ¨é‚»åŸŸçš„åŠå¾„ã€‚è¿™æ˜¯ç°‡çš„è§„æ¨¡/åˆ†è¾¨ç‡ã€‚å¦‚æœè¿™ä¸ªå€¼è®¾ç½®å¾—å¤ªå°ï¼Œå¤ªå¤šçš„æ ·æœ¬ä¼šè¢«è§†ä¸ºå¼‚å¸¸å€¼ï¼›å¦‚æœè®¾ç½®å¾—å¤ªå¤§ï¼Œæ‰€æœ‰ç°‡å°†åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„ç°‡ã€‚
- en: \(min_{Pts}\) â€“ the minimum number of points to assign a core point, where core
    points are applied to initialize or grow a cluster group.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(min_{Pts}\) â€“ åˆ†é…æ ¸å¿ƒç‚¹æ‰€éœ€çš„æœ€å°ç‚¹æ•°ï¼Œå…¶ä¸­æ ¸å¿ƒç‚¹ç”¨äºåˆå§‹åŒ–æˆ–æ‰©å±•ç°‡ç»„ã€‚
- en: Density is quantified by number of samples over a volume, where the volume is
    based on a radius over all dimensions of feature space.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: å¯†åº¦é€šè¿‡ä½“ç§¯å†…çš„æ ·æœ¬æ•°é‡æ¥é‡åŒ–ï¼Œå…¶ä¸­ä½“ç§¯åŸºäºç‰¹å¾ç©ºé—´æ‰€æœ‰ç»´åº¦çš„åŠå¾„ã€‚
- en: Automated or guided \(\epsilon\) parameter estimation is available by k-distance
    graph (in this case is k nearest neighbor).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡kè·ç¦»å›¾ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯kæœ€è¿‘é‚»ï¼‰å¯ä»¥è¿›è¡Œè‡ªåŠ¨æˆ–å¼•å¯¼çš„\(\epsilon\)å‚æ•°ä¼°è®¡ã€‚
- en: Calculate the nearest neighbor distance in normalized feature space for all
    the sample data (1,700 in this case).
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ‰€æœ‰æ ·æœ¬æ•°æ®ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ä¸º1,700ï¼‰åœ¨å½’ä¸€åŒ–ç‰¹å¾ç©ºé—´ä¸­çš„æœ€è¿‘é‚»è·ç¦»ã€‚
- en: Sort in ascending order and plot.
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰å‡åºæ’åºå¹¶ç»˜å›¾ã€‚
- en: Select the distance that maximizes the positive curvature (the elbow).
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©æœ€å¤§åŒ–æ­£æ›²ç‡çš„è·ç¦»ï¼ˆå³æ‹ç‚¹ï¼‰ã€‚
- en: Here is a summary of salient aspects for DBSCAN clustering,
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯DBSCANèšç±»çš„æ˜¾è‘—æ–¹é¢çš„æ€»ç»“ï¼Œ
- en: '*DBSCAN* - stands for Density-Based Spatial Clustering of Applications with
    Noise (Ester et al.,1996).'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DBSCAN* - ä»£è¡¨åŸºäºå¯†åº¦çš„ç©ºé—´èšç±»åº”ç”¨å™ªå£°ï¼ˆEsterç­‰ï¼Œ1996ï¼‰ã€‚'
- en: '*Advantages* - include minimum domain knowledge to estimate hyperparameters,
    the ability to represent any arbitrary shape of cluster groups and efficient to
    apply for large data sets'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ä¼˜ç‚¹* - åŒ…æ‹¬æœ€å°é¢†åŸŸçŸ¥è¯†æ¥ä¼°è®¡è¶…å‚æ•°ï¼Œèƒ½å¤Ÿè¡¨ç¤ºä»»æ„å½¢çŠ¶çš„ç°‡ç»„ï¼Œå¹¶ä¸”åœ¨å¤§æ•°æ®é›†ä¸Šåº”ç”¨é«˜æ•ˆ'
- en: '*Hierarchical Bottom-up / Agglomerative Clustering* â€“ all data samples start
    as their own group, called â€˜unvisitedâ€™ but practically as outliers until assigned
    to a group, and then the cluster group grow iteratively.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è‡ªåº•å‘ä¸Š/èšåˆèšç±»* â€“ æ‰€æœ‰æ•°æ®æ ·æœ¬æœ€åˆéƒ½æ˜¯ç‹¬ç«‹çš„ç»„ï¼Œç§°ä¸ºâ€œæœªè®¿é—®â€ï¼Œä½†å®é™…ä¸Šåœ¨åˆ†é…åˆ°ç»„ä¹‹å‰è¢«è§†ä¸ºå¼‚å¸¸å€¼ï¼Œç„¶åèšç±»ç»„è¿­ä»£å¢é•¿ã€‚'
- en: '*Mutually Exclusive* â€“ like k-means clustering, all samples may only belong
    to a single cluster group.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*äº’æ–¥æ€§* â€“ ä¸k-meansèšç±»ä¸€æ ·ï¼Œæ‰€æœ‰æ ·æœ¬åªèƒ½å±äºå•ä¸ªèšç±»ç»„ã€‚'
- en: \[ P(C_i \cap C_j | i \ne j) = 0.0 \]
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_i \cap C_j | i \ne j) = 0.0 \]
- en: '*Non-exhaustive* â€“ some samples may be left as unassigned and assumed as outliers
    for the cluster group assignment'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*éç©·å°½æ€§* â€“ ä¸€äº›æ ·æœ¬å¯èƒ½è¢«ç•™ä¸‹æœªåˆ†é…ï¼Œå¹¶å‡è®¾ä¸ºèšç±»ç»„åˆ†é…çš„å¼‚å¸¸å€¼'
- en: \[ P(C_1 \cup C_2 \cup \dots C_k) \le 1.0 \]
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_1 \cup C_2 \cup \dots C_k) \le 1.0 \]
- en: '**Decision Criteria**'
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å†³ç­–æ ‡å‡†**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a feature that
    is calculated by applying the transfer function to the subsurface model(s) to
    support decision making. The decision criteria represents value, health, environment
    and safety. For example:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€šè¿‡åº”ç”¨ä¼ é€’å‡½æ•°åˆ°åœ°ä¸‹æ¨¡å‹ï¼ˆsï¼‰æ¥è®¡ç®—çš„ç‰¹å¾ï¼Œä»¥æ”¯æŒå†³ç­–ã€‚å†³ç­–æ ‡å‡†ä»£è¡¨ä»·å€¼ã€å¥åº·ã€ç¯å¢ƒå’Œå®‰å…¨ã€‚ä¾‹å¦‚ï¼š'
- en: contaminant recovery rate to support design of a pump and treat soil remediation
    project
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ±¡æŸ“ç‰©å›æ”¶ç‡ä»¥æ”¯æŒæ³µå’ŒåœŸå£¤ä¿®å¤é¡¹ç›®çš„å·¥ç¨‹è®¾è®¡
- en: oil-in-place resources to determine if a reservoir should be developed
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°ä¸‹æ²¹èµ„æºä»¥ç¡®å®šæ˜¯å¦åº”å¼€å‘æ°´åº“
- en: Lorenz coefficient heterogeneity measure to classify a reservoir and determine
    mature analogs
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ´›ä¼¦å…¹ç³»æ•°å¼‚è´¨æ€§åº¦é‡ç”¨äºåˆ†ç±»æ°´åº“å¹¶ç¡®å®šæˆç†Ÿç±»æ¯”
- en: recovery factor or production rate to schedule production and determine optimum
    facilities
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›æ”¶å› å­æˆ–ç”Ÿäº§ç‡ä»¥å®‰æ’ç”Ÿäº§å’Œç¡®å®šæœ€ä½³è®¾æ–½
- en: recovered mineral grade and tonnage to determine economic ultimate pit shell
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›æ”¶çš„çŸ¿ç‰©å“ä½å’Œå¨æ•°ä»¥ç¡®å®šç»æµæœ€ç»ˆçŸ¿å‘å£³ä½“
- en: '**Decision Tree**'
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å†³ç­–æ ‘**'
- en: '[Decision Tree](MachineLearning_decision_tree.html): a intuitive, regression
    and classification predictive machine learning model that devides the predictor
    space, \(ğ‘‹_1,â€¦,ğ‘‹_ğ‘š\), into \(ğ½\) mutually exclusive, exhaustive regions, \(ğ‘…_ğ‘—\).'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '[å†³ç­–æ ‘](MachineLearning_decision_tree.html)ï¼šä¸€ä¸ªç›´è§‚çš„ã€å›å½’å’Œåˆ†ç±»çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒå°†é¢„æµ‹ç©ºé—´ \(ğ‘‹_1,â€¦,ğ‘‹_ğ‘š\)
    åˆ’åˆ†ä¸º \(ğ½\) ä¸ªäº’æ–¥ã€ç©·å°½çš„åŒºåŸŸï¼Œ\(ğ‘…_ğ‘—\)ã€‚'
- en: '*mutually exclusive* â€“ any combination of predictors only belongs to a single
    region, \(ğ‘…_ğ‘—\)'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*äº’æ–¥æ€§* â€“ ä»»ä½•é¢„æµ‹å› å­çš„ä»»ä½•ç»„åˆåªå±äºå•ä¸ªåŒºåŸŸï¼Œ\(ğ‘…_ğ‘—\)'
- en: '*exhaustive* â€“ all combinations of predictors belong a region, \(ğ‘…_ğ‘—\), regions
    cover entire feature space, range of the variables being considered'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©·å°½æ€§* â€“ æ‰€æœ‰é¢„æµ‹å› å­çš„æ‰€æœ‰ç»„åˆå±äºä¸€ä¸ªåŒºåŸŸï¼Œ\(ğ‘…_ğ‘—\)ï¼ŒåŒºåŸŸè¦†ç›–æ•´ä¸ªç‰¹å¾ç©ºé—´ï¼Œè€ƒè™‘çš„å˜é‡çš„èŒƒå›´'
- en: The same prediction in each region, mean of training data in region, \(\hat{Y}(ğ‘…_ğ‘—)
    = \overline{Y}(ğ‘…_ğ‘—)\)
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªåŒºåŸŸçš„ç›¸åŒé¢„æµ‹ï¼Œè¯¥åŒºåŸŸçš„è®­ç»ƒæ•°æ®å¹³å‡å€¼ï¼Œ\(\hat{Y}(ğ‘…_ğ‘—) = \overline{Y}(ğ‘…_ğ‘—)\)
- en: for classification the most common, mode-based or argmax operator
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºåˆ†ç±»ï¼Œæœ€å¸¸è§çš„æ˜¯åŸºäºæ¨¡å¼çš„æˆ–argmaxè¿ç®—ç¬¦
- en: Other salient points about decision tree,
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘çš„å…¶ä»–æ˜¾è‘—ç‰¹ç‚¹ï¼Œ
- en: '*supervised Learning* - the response feature label, \(Y\), is available over
    the training and testing data'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç›‘ç£å­¦ä¹ * - å“åº”ç‰¹å¾æ ‡ç­¾ \(Y\) åœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸­å¯ç”¨'
- en: '*hierarchical, binary segmentation* - of the predictor feature space, start
    with 1 region and sequentially divide, creating new regions'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å±‚æ¬¡ï¼ŒäºŒè¿›åˆ¶åˆ†å‰²* - é¢„æµ‹ç‰¹å¾ç©ºé—´ï¼Œä»1ä¸ªåŒºåŸŸå¼€å§‹ï¼Œç„¶åä¾æ¬¡åˆ†å‰²ï¼Œåˆ›å»ºæ–°çš„åŒºåŸŸ'
- en: '*compact, interpretable model* - since the classification is based on a hierarchy
    of binary segmentations of the feature space (one feature at a time) the model
    can be specified in a intuitive manner as a tree with binary branches**, hence
    the name decision tree. The code for the model is nested if statements, for example,'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç´§å‡‘ã€å¯è§£é‡Šçš„æ¨¡å‹* - ç”±äºåˆ†ç±»æ˜¯åŸºäºç‰¹å¾ç©ºé—´çš„äºŒè¿›åˆ¶åˆ†å‰²çš„å±‚æ¬¡ç»“æ„ï¼ˆæ¯æ¬¡ä¸€ä¸ªç‰¹å¾ï¼‰ï¼Œå› æ­¤æ¨¡å‹å¯ä»¥ç”¨ç›´è§‚çš„æ–¹å¼æŒ‡å®šä¸ºå…·æœ‰äºŒå‰åˆ†æ”¯çš„æ ‘ï¼Œå› æ­¤å¾—åå†³ç­–æ ‘ã€‚è¯¥æ¨¡å‹çš„ä»£ç æ˜¯åµŒå¥—çš„ifè¯­å¥ï¼Œä¾‹å¦‚ï¼Œ'
- en: '[PRE0]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The decision tree is constructed from the top down. We begin with a single region
    that covers the entire feature space and then proceed with a sequence of splits,
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘æ˜¯ä»ä¸Šåˆ°ä¸‹æ„å»ºçš„ã€‚æˆ‘ä»¬ä»ä¸€ä¸ªè¦†ç›–æ•´ä¸ªç‰¹å¾ç©ºé—´çš„å•ä¸ªåŒºåŸŸå¼€å§‹ï¼Œç„¶åè¿›è¡Œä¸€ç³»åˆ—çš„åˆ†å‰²ï¼Œ
- en: '*scan all possible splits* - over all regions and over all features.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ‰«ææ‰€æœ‰å¯èƒ½çš„åˆ†å‰²* - åœ¨æ‰€æœ‰åŒºåŸŸå’Œæ‰€æœ‰ç‰¹å¾ä¸Šã€‚'
- en: '*greedy optimization* - proceeds by finding the best split in any feature that
    minimizes the residual sum of squares of errors over all the training data \(y_i\)
    over all of the regions \(j = 1,\ldots,J\). There is no other information shared
    between subsequent splits.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è´ªå©ªä¼˜åŒ–* - é€šè¿‡åœ¨ä»»æ„ç‰¹å¾ä¸­æ‰¾åˆ°æœ€ä½³åˆ†å‰²æ¥å‡å°‘æ‰€æœ‰è®­ç»ƒæ•°æ® \(y_i\) åœ¨æ‰€æœ‰åŒºåŸŸ \(j = 1,\ldots,J\) ä¸Šçš„æ®‹å·®å¹³æ–¹å’Œã€‚åç»­åˆ†å‰²ä¹‹é—´æ²¡æœ‰å…±äº«å…¶ä»–ä¿¡æ¯ã€‚'
- en: \[ RSS = \sum^{J}_{j=1} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: \[ RSS = \sum^{J}_{j=1} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
- en: Hyperparameters include,
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°åŒ…æ‹¬ï¼Œ
- en: '*number of regions* â€“ very easy to understand, you know what the model will
    be'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŒºåŸŸæ•°é‡* â€“ éå¸¸å®¹æ˜“ç†è§£ï¼Œä½ çŸ¥é“æ¨¡å‹ä¼šæ˜¯ä»€ä¹ˆæ ·å­'
- en: '*minimum reduction in RSS* â€“ could stop early, e.g., a low reduction in RSS
    split could lead to a subsequent split with a larger reduction in RSS'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœ€å°å‡æ–¹è¯¯å·®å‡å°‘é‡* â€“ å¯ä»¥æå‰åœæ­¢ï¼Œä¾‹å¦‚ï¼ŒRSS å‡å°‘é‡å°çš„åˆ†å‰²å¯èƒ½å¯¼è‡´åç»­åˆ†å‰²æœ‰æ›´å¤§çš„ RSS å‡å°‘é‡'
- en: '*minimum number of training data in each region* â€“ related to the concept of
    accuracy of the region mean prediction, i.e., we need at least ğ‘› data for a reliable
    mean'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¯ä¸ªåŒºåŸŸçš„* **æœ€å°è®­ç»ƒæ•°æ®é‡** â€“ ä¸åŒºåŸŸå‡å€¼é¢„æµ‹çš„å‡†ç¡®æ€§æ¦‚å¿µç›¸å…³ï¼Œå³æˆ‘ä»¬éœ€è¦è‡³å°‘ ğ‘› ä¸ªæ•°æ®æ¥è·å¾—å¯é çš„å‡å€¼'
- en: '*maximum number of levels* â€“ forces symmetric trees, similar number of splits
    to get to each region'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœ€å¤§å±‚æ•°* â€“ å¼ºåˆ¶å¯¹ç§°æ ‘ï¼Œåˆ°è¾¾æ¯ä¸ªåŒºåŸŸçš„åˆ†å‰²æ•°é‡ç›¸ä¼¼'
- en: '**Declustering**'
  id: totrans-426
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å»ç°‡**'
- en: 'Data Preparation: various methods that assign weights to spatial samples based
    on local sampling density, such that the weighted statistics are likely more representative
    of the population. Data weights are assigned so that,'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šæ ¹æ®å±€éƒ¨é‡‡æ ·å¯†åº¦ä¸ºç©ºé—´æ ·æœ¬åˆ†é…æƒé‡çš„å„ç§æ–¹æ³•ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡é‡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…ä½¿å¾—ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¯†é›†é‡‡æ ·åŒºåŸŸé‡‡æ ·çš„æƒé‡è¾ƒä½
- en: samples in sparsely sampled areas receive more weight
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç¨€ç–é‡‡æ ·åŒºåŸŸé‡‡æ ·çš„æƒé‡è¾ƒé«˜
- en: 'There are various declustering methods:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨å¤šç§å»ç°‡æ–¹æ³•ï¼š
- en: '*cell-based declustering*'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºå•å…ƒæ ¼çš„å»ç°‡*'
- en: '*polygonal declustering*'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šè¾¹å½¢å»ç°‡*'
- en: '*kriging-based declustering*'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºå…‹é‡Œé‡‘çš„å»ç°‡*'
- en: It is important to note that no declustering method can prove that for every
    data set the resulting weighted statistics will improve the prediction of the
    population parameters, but in expectation these methods tend to reduce the bias.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œæ²¡æœ‰ä»»ä½•å»ç°‡æ–¹æ³•å¯ä»¥è¯æ˜å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œç»“æœåŠ æƒç»Ÿè®¡é‡éƒ½ä¼šæé«˜æ€»ä½“å‚æ•°çš„é¢„æµ‹ï¼Œä½†åœ¨æœŸæœ›ä¸­ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å¯ä»¥å‡å°‘åå·®ã€‚
- en: '**Declustering** (statistics)'
  id: totrans-435
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å»ç°‡**ï¼ˆç»Ÿè®¡å­¦ï¼‰'
- en: 'Data Preparation: once declustering weights are calculated for a spatial dataset,
    then declustered statistics are applied as input for only subsequent analysis
    or modeling. For example,'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€æ—¦ä¸ºç©ºé—´æ•°æ®é›†è®¡ç®—äº†å»ç°‡æƒé‡ï¼Œåˆ™å°†å»ç°‡ç»Ÿè®¡åº”ç”¨äºåç»­åˆ†ææˆ–å»ºæ¨¡çš„è¾“å…¥ã€‚ä¾‹å¦‚ï¼Œ
- en: the declustered mean is assigned as the stationary, global mean for simple kriging
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å»ç°‡å‡å€¼åˆ†é…ä¸ºç®€å•å…‹é‡Œé‡‘æ³•çš„å¹³ç¨³ã€å…¨å±€å‡å€¼
- en: the weighted CDF from all the data with weights are applied to sequential Gaussian
    simulation to ensure the back-transformed realizations approach the declustered
    distribution
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰å¸¦æƒé‡çš„æ•°æ®ç‚¹çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°åº”ç”¨äºé¡ºåºé«˜æ–¯æ¨¡æ‹Ÿï¼Œä»¥ç¡®ä¿åå˜æ¢åçš„å®ç°æ¥è¿‘å»ç°‡åˆ†å¸ƒ
- en: Any statistic can be weighted, including the entire CDF! Here are some examples
    of weighted statistics, given declustering weights, \(w(\bf{u}_j)\), for all data
    \(j=1,\ldots,n\).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•ç»Ÿè®¡é‡éƒ½å¯ä»¥åŠ æƒï¼ŒåŒ…æ‹¬æ•´ä¸ªç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ä»¥ä¸‹æ˜¯ä¸€äº›åŠ æƒç»Ÿè®¡é‡çš„ç¤ºä¾‹ï¼Œç»™å®šå»ç°‡æƒé‡ \(w(\bf{u}_j)\)ï¼Œå¯¹äºæ‰€æœ‰æ•°æ® \(j=1,\ldots,n\)ã€‚
- en: weighted sample mean,
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ æƒæ ·æœ¬å‡å€¼ï¼Œ
- en: \[ \overline{x}_{wt} = \frac{\sum_{i=1}^n w(\bf{u}_j) \cdot z(\bf{u}_j)}{\sum_{i=1}^n
    w(\bf{u}_j)} \]
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{x}_{wt} = \frac{\sum_{i=1}^n w(\bf{u}_j) \cdot z(\bf{u}_j)}{\sum_{i=1}^n
    w(\bf{u}_j)} \]
- en: where \(n\) is the number of data.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(n\) æ˜¯æ•°æ®ç‚¹çš„æ•°é‡ã€‚
- en: weighted sample variance,
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ æƒæ ·æœ¬æ–¹å·®ï¼Œ
- en: \[ s^2_{x_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) - 1} \cdot \sum_{i=1}^n
    w(\bf{u}_j) \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right)^2 \]
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: \[ s^2_{x_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) - 1} \cdot \sum_{i=1}^n
    w(\bf{u}_j) \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right)^2 \]
- en: where \(\overline{x}_{wt}\) is the declustered mean.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}_{wt}\) æ˜¯å»ç°‡å‡å€¼ã€‚
- en: weighted covariance,
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ æƒåæ–¹å·®ï¼Œ
- en: \[ C_{x,y_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) } \cdot \sum_{i=1}^n w(\bf{u}_j)
    \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right) \cdot \left( y(\bf{u}_j)
    - \overline{y}_{wt} \right) \]
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: \[ C_{x,y_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) } \cdot \sum_{i=1}^n w(\bf{u}_j)
    \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right) \cdot \left( y(\bf{u}_j)
    - \overline{y}_{wt} \right) \]
- en: where \(\overline{x}_{wt}\) and \(\overline{y}_{wt}\) are the declustered means
    for features \(X\) and \(Y\).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}_{wt}\) å’Œ \(\overline{y}_{wt}\) æ˜¯ç‰¹å¾ \(X\) å’Œ \(Y\) çš„å»ç°‡å‡å€¼ã€‚
- en: the entire CDF,
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•´ä¸ªç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼Œ
- en: \[ F_z(z) \approx \sum_{j=1}^{n(Z<z)} w(\bf{u}_j) \]
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_z(z) \approx \sum_{j=1}^{n(Z<z)} w(\bf{u}_j) \]
- en: where \(n(Z<z)\) is the number of sorted ascending data less than threshold
    \(z\). We show this as approximative as this is simplified and at data resolution
    and without an interpolation model.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(n(Z<z)\) æ˜¯å°äºé˜ˆå€¼ \(z\) çš„æ’åºå‡åºæ•°æ®çš„æ•°é‡ã€‚æˆ‘ä»¬å°†å…¶è¡¨ç¤ºä¸ºè¿‘ä¼¼å€¼ï¼Œå› ä¸ºè¿™ç®€åŒ–äº†ï¼Œå¹¶ä¸”æ˜¯åœ¨æ•°æ®åˆ†è¾¨ç‡å’Œæ²¡æœ‰æ’å€¼æ¨¡å‹çš„æƒ…å†µä¸‹ã€‚
- en: It is important to note that no declustering method can prove that for every
    data set the resulting weighted statistics will improve the prediction of the
    population parameters, but in expectation these methods tend to reduce the bias.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ²¡æœ‰ä»»ä½•å»ç°‡æ–¹æ³•å¯ä»¥è¯æ˜å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œç»“æœåŠ æƒç»Ÿè®¡é‡éƒ½ä¼šæé«˜å¯¹æ€»ä½“å‚æ•°çš„é¢„æµ‹ï¼Œä½†åœ¨æœŸæœ›ä¸­ï¼Œè¿™äº›æ–¹æ³•å€¾å‘äºå‡å°‘åå·®ã€‚
- en: '**Density-Connected** (DBSCAN)'
  id: totrans-453
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯†åº¦è¿æ¥** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    points \(A\) and \(B\) are density-connected if there is a point \(Z\) that is
    density-reachable from both points \(A\) and \(B\).'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœå­˜åœ¨ä¸€ä¸ªç‚¹ \(Z\)ï¼Œå®ƒä»ç‚¹
    \(A\) å’Œ \(B\) éƒ½å¯†åº¦å¯è¾¾ï¼Œåˆ™ç‚¹ \(A\) å’Œ \(B\) æ˜¯å¯†åº¦è¿æ¥çš„ã€‚'
- en: '**Density-based Cluster** (DBSCAN)'
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå¯†åº¦çš„èšç±»** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    a nonempty set where all points are density-connected to each other.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šä¸€ä¸ªéç©ºé›†åˆï¼Œå…¶ä¸­æ‰€æœ‰ç‚¹éƒ½ç›¸äº’å¯†åº¦è¿æ¥ã€‚'
- en: '**Density-Reachable** (DBSCAN)'
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯†åº¦å¯è¾¾** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    point \(Y\) is density reachable from \(A\) if \(Y\) belongs to a neighborhood
    of a core point that can reached from \(A\). This would require a chain of core
    points each belonging the previous core points and the last core point including
    point Y.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœ \(Y\) å±äºä¸€ä¸ªå¯ä»¥ä» \(A\)
    åˆ°è¾¾çš„æ ¸å¿ƒç‚¹çš„é‚»åŸŸï¼Œåˆ™ç‚¹ \(Y\) æ˜¯ä» \(A\) å¯†åº¦å¯è¾¾çš„ã€‚è¿™éœ€è¦ä¸€ä¸²æ ¸å¿ƒç‚¹ï¼Œæ¯ä¸ªæ ¸å¿ƒç‚¹éƒ½å±äºå‰ä¸€ä¸ªæ ¸å¿ƒç‚¹ï¼Œæœ€åä¸€ä¸ªæ ¸å¿ƒç‚¹åŒ…æ‹¬ç‚¹ \(Y\)ã€‚'
- en: '**Deterministic Model**'
  id: totrans-459
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¡®å®šæ€§æ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a model that assumes
    the system or process that is completely predictable'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå‡è®¾ç³»ç»Ÿæˆ–è¿‡ç¨‹æ˜¯å®Œå…¨å¯é¢„æµ‹çš„æ¨¡å‹'
- en: often-based on engineering and geoscience physics and expert judgement
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸åŸºäºå·¥ç¨‹å’Œåœ°çƒç§‘å­¦ç‰©ç†å­¦ä»¥åŠä¸“å®¶åˆ¤æ–­
- en: for example, numerical flow simulation or stratigraphic bounding surfaces interpreted
    from seismic
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ•°å€¼æµåŠ¨æ¨¡æ‹Ÿæˆ–ä»åœ°éœ‡è§£é‡Šçš„å±‚åºè¾¹ç•Œè¡¨é¢
- en: for this course we also state that data-driven estimation models like
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™é—¨è¯¾ç¨‹ï¼Œæˆ‘ä»¬è¿˜å£°æ˜ï¼Œæ•°æ®é©±åŠ¨ä¼°è®¡æ¨¡å‹å¦‚
- en: 'Advantages:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼š
- en: integration of physics and expert knowledge
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰©ç†å’Œä¸“å®¶çŸ¥è¯†çš„æ•´åˆ
- en: integration of various information sources
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å„ç§ä¿¡æ¯æºçš„æ•´åˆ
- en: 'Disadvantages:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼š
- en: often quite time consuming
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ç›¸å½“è€—æ—¶
- en: often no assessment of uncertainty, focus on building one model
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ä¸è¯„ä¼°ä¸ç¡®å®šæ€§ï¼Œä¸“æ³¨äºæ„å»ºä¸€ä¸ªæ¨¡å‹
- en: '**Dimensionality Reduction**'
  id: totrans-470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é™ç»´**'
- en: '[Principal Component Analysis](MachineLearning_PCA.html): methods to reduce
    the number of features within a data science workflow. There are 2 primary methods,'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸»æˆåˆ†åˆ†æ](MachineLearning_PCA.html)ï¼šåœ¨æ•°æ®ç§‘å­¦å·¥ä½œæµç¨‹ä¸­å‡å°‘ç‰¹å¾æ•°é‡çš„æ–¹æ³•ã€‚æœ‰ä¸¤ç§ä¸»è¦æ–¹æ³•ï¼Œ'
- en: '*features Selection* â€“ find the subset of original features that are most important
    for the problem'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‰¹å¾é€‰æ‹©* â€“ æ‰¾åˆ°å¯¹é—®é¢˜æœ€é‡è¦çš„åŸå§‹ç‰¹å¾å­é›†'
- en: '*feature projection* â€“ transform the data from a higher to lower dimensional
    space'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‰¹å¾æŠ•å½±* â€“ å°†æ•°æ®ä»é«˜ç»´ç©ºé—´è½¬æ¢åˆ°ä½ç»´ç©ºé—´'
- en: Known as dimension reduction or dimensionality reduction
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿç§°ä¸ºé™ç»´æˆ–ç»´åº¦ç¼©å‡
- en: motivated by the curse of dimensionality and multicollinearity
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±ç»´åº¦çš„è¯…å’’å’Œå¤šå…±çº¿æ€§æ‰€æ¿€å‘
- en: applied in statistics, machine learning and information theory
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨äºç»Ÿè®¡å­¦ã€æœºå™¨å­¦ä¹ å’Œä¿¡æ¯ç†è®º
- en: '**Directly Density Reachable** (DBSCAN)'
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›´æ¥å¯†åº¦å¯è¾¾** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    point \(X\) is directly density reachable from \(A\), if \(A\) is a core point
    and \(X\) belongs to the neighborhood, distance \(le \epsilon\) from \(A\).'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœ \(A\) æ˜¯æ ¸å¿ƒç‚¹ä¸” \(X\)
    å±äº \(A\) çš„é‚»åŸŸï¼Œè·ç¦» \(A\) å°äºç­‰äº \(\epsilon\)ï¼Œåˆ™ç‚¹ \(X\) æ˜¯ä» \(A\) ç›´æ¥å¯†åº¦å¯è¾¾çš„ã€‚'
- en: '**Discrete Feature**'
  id: totrans-479
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¦»æ•£ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *categorical
    feature* or a *continuous feature* that is binned or grouped, for example,'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ª *åˆ†ç±»ç‰¹å¾* æˆ–ä¸€ä¸ª *è¿ç»­ç‰¹å¾*ï¼Œå®ƒè¢«åˆ†ç®±æˆ–åˆ†ç»„ï¼Œä¾‹å¦‚ï¼Œ'
- en: porosity between 0 and 20% assigned to 10 bins = {0 - 2%, 2% - 4%, \ldots ,20%}
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡åœ¨ 0% åˆ° 20% ä¹‹é—´åˆ†é…åˆ° 10 ä¸ªåŒºé—´ = {0 - 2%ï¼Œ2% - 4%ï¼Œ...ï¼Œ20%}
- en: Mohs hardness = \(\{1, 2, \ldots, 10\}\) (same at *categorical feature*)
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘©æ°ç¡¬åº¦ = \(\{1, 2, \ldots, 10\}\)ï¼ˆä¸ *åˆ†ç±»ç‰¹å¾* ç›¸åŒï¼‰
- en: '**Distribution Transformations**'
  id: totrans-483
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†å¸ƒå˜æ¢**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    mapping from one distribution to another distribution through percentile values,
    resulting in a new histogram, PDF, and CDF. We perform distribution transformations
    in geostatistical methods and workflows because,'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šé€šè¿‡ç™¾åˆ†ä½æ•°ä»ä¸€ä¸ªåˆ†å¸ƒæ˜ å°„åˆ°å¦ä¸€ä¸ªåˆ†å¸ƒçš„æ˜ å°„ï¼Œä»è€Œäº§ç”Ÿæ–°çš„ç›´æ–¹å›¾ã€PDFå’ŒCDFã€‚æˆ‘ä»¬åœ¨åœ°ç»Ÿè®¡æ–¹æ³•å’Œå·¥ä½œæµç¨‹ä¸­æ‰§è¡Œåˆ†å¸ƒå˜æ¢ï¼Œå› ä¸ºï¼Œ'
- en: '*inference* - to correct a feature distribution to an expected shape, for example,
    correcting for too few or biased data'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨æ–­* - å°†ç‰¹å¾åˆ†å¸ƒæ ¡æ­£åˆ°æœŸæœ›çš„å½¢çŠ¶ï¼Œä¾‹å¦‚ï¼Œæ ¡æ­£æ•°æ®è¿‡å°‘æˆ–åå·®'
- en: '*theory* - a specific distribution assumption is required for a workflow step,
    for example, Gaussian distribution with mean of 0.0 and variance of 1.0 is required
    for sequential Gaussian simulation'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç†è®º* - å·¥ä½œæµç¨‹æ­¥éª¤éœ€è¦ç‰¹å®šçš„åˆ†å¸ƒå‡è®¾ï¼Œä¾‹å¦‚ï¼Œå¯¹äºé¡ºåºé«˜æ–¯æ¨¡æ‹Ÿï¼Œéœ€è¦å‡å€¼ä¸º0.0å’Œæ–¹å·®ä¸º1.0çš„é«˜æ–¯åˆ†å¸ƒ'
- en: '*data preparation or cleaning* - to correct for outliers, the transformation
    will map the outlier into the target distribution no longer as an outlier'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ•°æ®å‡†å¤‡æˆ–æ¸…ç†* - æ ¡æ­£å¼‚å¸¸å€¼ï¼Œå˜æ¢å°†å¼‚å¸¸å€¼æ˜ å°„åˆ°ç›®æ ‡åˆ†å¸ƒï¼Œè€Œä¸å†æ˜¯å¼‚å¸¸å€¼'
- en: How do we perform distribution transformations?
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•æ‰§è¡Œåˆ†å¸ƒå˜æ¢ï¼Ÿ
- en: 'We transform the values from the cumulative distribution function (CDF), \(F_{X}\),
    to a new CDF , \(G_{Y}\). This can be generalized with the quantile - quantile
    transformation applied to all the sample data:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰\(F_{X}\)çš„å€¼è½¬æ¢åˆ°æ–°çš„CDF \(G_{Y}\)ã€‚è¿™å¯ä»¥é€šè¿‡å¯¹æ‰€æœ‰æ ·æœ¬æ•°æ®åº”ç”¨åˆ†ä½æ•°-åˆ†ä½æ•°å˜æ¢è¿›è¡Œæ¨å¹¿ï¼š
- en: 'The forward transform:'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£å‘å˜æ¢ï¼š
- en: \[ Y = G_{Y}^{-1}(F_{X}(X)) \]
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y = G_{Y}^{-1}(F_{X}(X)) \]
- en: 'The reverse transform:'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€†å‘å˜æ¢ï¼š
- en: \[ X = F_{X}^{-1}(G_{Y}(Y)) \]
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X = F_{X}^{-1}(G_{Y}(Y)) \]
- en: 'This may be applied to any data, including parametric or nonparametric distributions.
    We just need to be able to map from one distribution to another through percentiles,
    so it is a:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥åº”ç”¨äºä»»ä½•æ•°æ®ï¼ŒåŒ…æ‹¬å‚æ•°æˆ–éå‚æ•°åˆ†å¸ƒã€‚æˆ‘ä»¬åªéœ€è¦èƒ½å¤Ÿé€šè¿‡ç™¾åˆ†ä½æ•°å°†ä¸€ä¸ªåˆ†å¸ƒæ˜ å°„åˆ°å¦ä¸€ä¸ªåˆ†å¸ƒï¼Œå› æ­¤å®ƒæ˜¯ä¸€ä¸ªï¼š
- en: rank preserving transform, for example, P25 remains P25 after distribution transformation
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿ç•™æ’åçš„å˜æ¢ï¼Œä¾‹å¦‚ï¼Œåœ¨åˆ†å¸ƒå˜æ¢åP25ä»ç„¶æ˜¯P25
- en: '**Eager Learning**'
  id: totrans-496
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ€¥åˆ‡å­¦ä¹ **'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): Model is
    a generalization of the training data constructed prior to queries'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šæ¨¡å‹æ˜¯æŸ¥è¯¢ä¹‹å‰æ„å»ºçš„è®­ç»ƒæ•°æ®çš„æ³›åŒ–'
- en: the model is input-independent after parameter training and hyperparameter tuning,
    i.e., the training data does not need to be available to make new predictions
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨å‚æ•°è®­ç»ƒå’Œè¶…å‚æ•°è°ƒæ•´åè¾“å…¥ç‹¬ç«‹ï¼Œå³ï¼Œä¸éœ€è¦è®­ç»ƒæ•°æ®å³å¯è¿›è¡Œæ–°çš„é¢„æµ‹
- en: The opposite is lazy learning.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åçš„æ˜¯æ‡’æƒ°å­¦ä¹ ã€‚
- en: '**Estimation**'
  id: totrans-500
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¼°è®¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is process of obtaining
    the single best value to represent a feature at an unsampled location, or time.
    Some additional concepts,'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯åœ¨æœªé‡‡æ ·ä½ç½®æˆ–æ—¶é—´è·å–è¡¨ç¤ºç‰¹å¾çš„å•ä¸ªæœ€ä½³å€¼çš„è¿‡ç¨‹ã€‚ä¸€äº›é¢å¤–çš„æ¦‚å¿µï¼Œ'
- en: local accuracy takes precedence over global spatial variability
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å±€éƒ¨ç²¾åº¦ä¼˜å…ˆäºå…¨å±€ç©ºé—´å˜å¼‚æ€§
- en: too smooth, not appropriate for any transform function that is sensitive to
    heterogeneity
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡äºå¹³æ»‘ï¼Œä¸é€‚åˆå¯¹å¼‚è´¨æ€§æ•æ„Ÿçš„ä»»ä½•å˜æ¢å‡½æ•°
- en: for example, inverse distance and kriging
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œé€†è·ç¦»å’Œå…‹é‡Œé‡‘æ³•
- en: many predictive machine learning models focus on estimation (e.g., k-nearest
    neighbours, decision tree, random forest, etc.)
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¸å¤šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ä¸“æ³¨äºä¼°è®¡ï¼ˆä¾‹å¦‚ï¼Œk-æœ€è¿‘é‚»ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰ï¼‰
- en: '**f1-score** (classification accuracy metric)'
  id: totrans-506
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**f1åˆ†æ•°**ï¼ˆåˆ†ç±»å‡†ç¡®åº¦æŒ‡æ ‡ï¼‰'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a categorical classification
    prediction model measure of accuracy, a single summary metric for each \(k\) category
    from the confusion matrix.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šåˆ†ç±»é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®æ€§åº¦é‡ï¼Œæ··æ·†çŸ©é˜µä¸­æ¯ä¸ª \(k\) ç±»åˆ«çš„å•ä¸€æ±‡æ€»æŒ‡æ ‡ã€‚'
- en: the harmonic mean of recall and precision
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›æ”¶ç‡å’Œç²¾åº¦çš„è°ƒå’Œå¹³å‡å€¼
- en: \[ f1-score_k = \frac{2} { \frac{1}{Precision_k} + \frac{1}{Recall_k} } \]
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f1-score_k = \frac{2} { \frac{1}{Precision_k} + \frac{1}{Recall_k} } \]
- en: As a reminder,
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæé†’ï¼Œ
- en: '*recall* - the ratio of true positives divided by all cases of the category
    in the testing dataset'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å›æ”¶ç‡* - æµ‹è¯•æ•°æ®é›†ä¸­è¯¥ç±»æ‰€æœ‰æ¡ˆä¾‹ä¸­çœŸå®æ­£ä¾‹ä¸æ‰€æœ‰æ¡ˆä¾‹çš„æ¯”ç‡'
- en: '*precision* - the ratio of true positives divided by all positives, true positives
    + false positives'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç²¾åº¦* - çœŸæ­£ä¾‹ä¸æ‰€æœ‰æ­£ä¾‹ï¼ˆçœŸæ­£ä¾‹ + å‡æ­£ä¾‹ï¼‰çš„æ¯”ç‡'
- en: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
- en: '**Feature** (also variable)'
  id: totrans-514
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾**ï¼ˆä¹Ÿç§°ä¸ºå˜é‡ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): any property measured
    or observed in a study'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨ç ”ç©¶ä¸­æµ‹é‡çš„æˆ–è§‚å¯Ÿåˆ°çš„ä»»ä½•å±æ€§'
- en: for example, porosity, permeability, mineral concentrations, saturations, contaminant
    concentration, etc.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå­”éš™ç‡ã€æ¸—é€ç‡ã€çŸ¿ç‰©æµ“åº¦ã€é¥±å’Œåº¦ã€æ±¡æŸ“ç‰©æµ“åº¦ç­‰ã€‚
- en: in data mining / machine learning this is known as a feature, statisticians
    call these variables
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®æŒ–æ˜/æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œè¿™è¢«ç§°ä¸ºç‰¹å¾ï¼Œç»Ÿè®¡å­¦å®¶å°†è¿™äº›å˜é‡ç§°ä¸º
- en: measure often requires significant analysis, interpretation, etc.
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹é‡é€šå¸¸éœ€è¦å¤§é‡çš„åˆ†æã€è§£é‡Šç­‰ã€‚
- en: when features are modified and combined to improve our models we call this feature
    engineering
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ç‰¹å¾è¢«ä¿®æ”¹å’Œç»„åˆä»¥æé«˜æˆ‘ä»¬çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºç‰¹å¾å·¥ç¨‹
- en: '**Feature Engineering**'
  id: totrans-520
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å·¥ç¨‹**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): using
    domain expertise to extract improved predictor or response features from raw data,'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šåˆ©ç”¨é¢†åŸŸä¸“ä¸šçŸ¥è¯†ä»åŸå§‹æ•°æ®ä¸­æå–æ”¹è¿›çš„é¢„æµ‹æˆ–å“åº”ç‰¹å¾ï¼Œ'
- en: improve the performance, accuracy and convergency, of inferential or predictive
    machine learning
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜æ¨ç†æˆ–é¢„æµ‹æœºå™¨å­¦ä¹ çš„æ€§èƒ½ã€å‡†ç¡®æ€§å’Œæ”¶æ•›æ€§
- en: improve model interpretability (or may worsen interpretability if our engineered
    features are in unfamiliar units)
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼ˆæˆ–è€…å¦‚æœæˆ‘ä»¬çš„å·¥ç¨‹ç‰¹å¾å¤„äºä¸ç†Ÿæ‚‰çš„å•ä½ï¼Œå¯èƒ½ä¼šé™ä½å¯è§£é‡Šæ€§ï¼‰
- en: mitigate outliers & bias, consistency with assumptions such as Gaussianity,
    linearization, dimensional expansion
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å°‘å¼‚å¸¸å€¼å’Œåå·®ï¼Œä¸é«˜æ–¯æ€§ã€çº¿æ€§åŒ–ã€ç»´åº¦æ‰©å±•ç­‰å‡è®¾ä¿æŒä¸€è‡´
- en: Feature transformation and feature selection are two forms of feature engineering.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾è½¬æ¢å’Œç‰¹å¾é€‰æ‹©æ˜¯ç‰¹å¾å·¥ç¨‹ä¸¤ç§å½¢å¼ã€‚
- en: '**Feature Importance**'
  id: totrans-526
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾é‡è¦æ€§**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a variety of machine
    learning methods to provide measures for feature ranking, for example decision
    trees summarize the reduction in mean square error through inclusion of each feature
    and is summarized as,'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’å](MachineLearning_feature_ranking.html)ï¼šæä¾›ç‰¹å¾æ’ååº¦é‡çš„å„ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œä¾‹å¦‚å†³ç­–æ ‘é€šè¿‡åŒ…å«æ¯ä¸ªç‰¹å¾æ¥æ€»ç»“å‡æ–¹è¯¯å·®çš„å‡å°‘ï¼Œæ€»ç»“å¦‚ä¸‹ï¼Œ'
- en: \[ FI(x) = \sum_{t \in T_f} \frac{N_t}{N} \Delta_{MSE_t} \]
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: \[ FI(x) = \sum_{t \in T_f} \frac{N_t}{N} \Delta_{MSE_t} \]
- en: where \(T_f\) are all nodes with feature \(x\) as the split, \(N_t\) is the
    number of training samples reaching node \(t\), \(N\) is the total number of samples
    in the dataset and \(\Delta_{MSE_t}\) is the reduction in MSE with the \(t\) split.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(T_f\) æ˜¯æ‰€æœ‰ä»¥ç‰¹å¾ \(x\) ä½œä¸ºåˆ†å‰²çš„èŠ‚ç‚¹ï¼Œ\(N_t\) æ˜¯è¾¾åˆ°èŠ‚ç‚¹ \(t\) çš„è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œ\(N\) æ˜¯æ•°æ®é›†ä¸­æ ·æœ¬çš„æ€»æ•°ï¼Œ\(\Delta_{MSE_t}\)
    æ˜¯ \(t\) åˆ†å‰²å¸¦æ¥çš„ MSE å‡å°‘é‡ã€‚
- en: Note, feature importance can be calculated in a similar manner to MSE above
    for the case of classification trees with *Gini Impurity*.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç‰¹å¾é‡è¦æ€§å¯ä»¥åƒä¸Šé¢çš„ MSE ä¸€æ ·ä»¥ç±»ä¼¼çš„æ–¹å¼è®¡ç®—ï¼Œå¯¹äºå…·æœ‰ *åŸºå°¼ä¸çº¯åº¦* çš„åˆ†ç±»æ ‘ã€‚
- en: Feature importance is part of model-based feature ranking,
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾é‡è¦æ€§æ˜¯æ¨¡å‹åŸºäºç‰¹å¾æ’åçš„ä¸€éƒ¨åˆ†ï¼Œ
- en: the accuracy of the feature importance depends on the accuracy of the model,
    i.e., an inaccurate model will likely provide incorrect feature importance
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é‡è¦æ€§çš„å‡†ç¡®æ€§å–å†³äºæ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå³ä¸å‡†ç¡®çš„æ¨¡å‹å¯èƒ½ä¼šæä¾›é”™è¯¯çš„ç‰¹å¾é‡è¦æ€§
- en: '**Feature Imputation**'
  id: totrans-533
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æ’è¡¥**'
- en: '[Feature Imputation](MachineLearning_feature_imputation.html): replacing null
    values in the data table, samples that do not have values for all features with
    plausible values for 2 reasons,'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’è¡¥](MachineLearning_feature_imputation.html)ï¼šåœ¨æ•°æ®è¡¨ä¸­æ›¿æ¢ç©ºå€¼ï¼Œå¯¹äºæ‰€æœ‰ç‰¹å¾æ²¡æœ‰å€¼çš„æ ·æœ¬ï¼Œç”¨åˆç†çš„å€¼æ›¿æ¢ï¼ŒåŸå› æœ‰äºŒï¼Œ'
- en: enable statistical calculations and models that require complete data tables,
    i.e., cannot work with missing feature values
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿éœ€è¦å®Œæ•´æ•°æ®è¡¨çš„ç»Ÿè®¡è®¡ç®—å’Œæ¨¡å‹æˆä¸ºå¯èƒ½ï¼Œå³ä¸èƒ½å¤„ç†ç¼ºå¤±ç‰¹å¾å€¼
- en: maximize model accuracy, increasing the number of reliable samples available
    for training and testing the model
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–æ¨¡å‹å‡†ç¡®æ€§ï¼Œå¢åŠ å¯ç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ¨¡å‹çš„å¯é æ ·æœ¬æ•°é‡
- en: mitigate model bias that may occur with likewise deletion in feature values
    are not missing at random
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å°‘å¯èƒ½å› ç‰¹å¾å€¼ä¸­ç±»ä¼¼åˆ é™¤è€Œå‘ç”Ÿçš„æ¨¡å‹åå·®ï¼Œå½“ç‰¹å¾å€¼ä¸æ˜¯éšæœºç¼ºå¤±æ—¶
- en: Feature imputation methods include,
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾æ’è¡¥æ–¹æ³•åŒ…æ‹¬ï¼Œ
- en: '*constant value imputation* - replace null values with feature mean or mode'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¸¸é‡å€¼æ’è¡¥* - ä½¿ç”¨ç‰¹å¾å‡å€¼æˆ–ä¼—æ•°æ›¿æ¢ç©ºå€¼'
- en: '*model-based imputation* - replace null values with a prediction of the missing
    feature with available feature values for the same sample'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºæ¨¡å‹çš„æ’è¡¥* - ä½¿ç”¨ç›¸åŒæ ·æœ¬çš„å¯ç”¨ç‰¹å¾å€¼æ¥é¢„æµ‹ç¼ºå¤±ç‰¹å¾ï¼Œå¹¶ç”¨é¢„æµ‹å€¼æ›¿æ¢ç©ºå€¼'
- en: There are also an iterative methods that depend on convergence,
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€äº›ä¾èµ–äºæ”¶æ•›çš„è¿­ä»£æ–¹æ³•ï¼Œ
- en: '*Multiple Imputation by Chained Equations (MICE)* - assign random values and
    then iterate over the missing values predicting new values'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é“¾å¼æ–¹ç¨‹å¤šé‡æ’è¡¥ (MICE)* - åˆ†é…éšæœºå€¼ï¼Œç„¶åè¿­ä»£ç¼ºå¤±å€¼é¢„æµ‹æ–°å€¼'
- en: The goal of this method is to obtain reasonable imputed values that account
    for the relationships between all the features and all the available and missing
    values
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•çš„ç›®æ ‡æ˜¯è·å¾—åˆç†çš„ä¼°è®¡å€¼ï¼Œè¿™äº›å€¼è€ƒè™‘äº†æ‰€æœ‰ç‰¹å¾ä»¥åŠæ‰€æœ‰å¯ç”¨å’Œç¼ºå¤±å€¼ä¹‹é—´çš„å…³ç³»
- en: '**Feature Projection**'
  id: totrans-544
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æŠ•å½±**'
- en: '[Principal Component Analysis](MachineLearning_PCA.html): a transforms original
    \(m\) features to \(p\) features, where \(p << m\) for dimensionality reduction'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸»æˆåˆ†åˆ†æ](MachineLearning_PCA.html)ï¼šå°†åŸå§‹ \(m\) ä¸ªç‰¹å¾è½¬æ¢ä¸º \(p\) ä¸ªç‰¹å¾ï¼Œå…¶ä¸­ \(p << m\)
    ç”¨äºé™ç»´'
- en: given features, \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\) we would require \(\binom{m}{2} = \frac{ğ‘š(ğ‘šâˆ’1)}{2}\)
    scatter plots to visualize just the two-dimensional scatter plots
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šç‰¹å¾ \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\)ï¼Œæˆ‘ä»¬éœ€è¦ \(\binom{m}{2} = \frac{ğ‘š(ğ‘šâˆ’1)}{2}\) æ•£ç‚¹å›¾æ¥å¯è§†åŒ–äºŒç»´æ•£ç‚¹å›¾
- en: these representations would not capture \(> 2\) dimensional structures
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›è¡¨ç¤ºæ— æ³•æ•æ‰ \(> 2\) ç»´ç»“æ„
- en: once we have 4 or more variables understanding our data gets very difficult.
    Recall the curse of dimensionality.
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰4ä¸ªæˆ–æ›´å¤šå˜é‡ï¼Œç†è§£æ•°æ®å°±å˜å¾—éå¸¸å›°éš¾ã€‚å›å¿†ç»´åº¦è¯…å’’ã€‚
- en: principal component analysis, multidimensional scaling and random projection
    are examples
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸»æˆåˆ†åˆ†æã€å¤šç»´ç¼©æ”¾å’ŒéšæœºæŠ•å½±æ˜¯ä¾‹å­
- en: feature selection is an alternative method for dimensionality reduction
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é€‰æ‹©æ˜¯é™ç»´çš„å¦ä¸€ç§æ–¹æ³•ã€‚
- en: '**Feature Space**'
  id: totrans-551
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾ç©ºé—´**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): commonly feature space
    only refers to the predictor features and does not include the response feature(s),
    i.e.,'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šé€šå¸¸ç‰¹å¾ç©ºé—´ä»…æŒ‡é¢„æµ‹ç‰¹å¾ï¼Œä¸åŒ…æ‹¬å“åº”ç‰¹å¾ï¼ˆå³ï¼Œ'
- en: all possible combinations of predictor features for which we need to make predictions
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åšå‡ºé¢„æµ‹çš„æ‰€æœ‰å¯èƒ½çš„é¢„æµ‹ç‰¹å¾ç»„åˆ
- en: may be referred to as predictor feature space.
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½è¢«ç§°ä¸ºé¢„æµ‹ç‰¹å¾ç©ºé—´ã€‚
- en: Typically, we train and test our machinesâ€™ predictions over the predictor feature
    space.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šè®­ç»ƒå’Œæµ‹è¯•æœºå™¨çš„é¢„æµ‹ã€‚
- en: the space is typically a hypercuboid with each axis representing a predictor
    feature and extending from the minimum to maximum, over the range of each predictor
    feature
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥ç©ºé—´é€šå¸¸æ˜¯è¶…ç«‹æ–¹ä½“ï¼Œæ¯ä¸ªè½´ä»£è¡¨ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œä»æ¯ä¸ªé¢„æµ‹ç‰¹å¾çš„æœ€å°å€¼å»¶ä¼¸åˆ°æœ€å¤§å€¼
- en: more complicated shapes of predictor feature space are possible, e.g., we could
    mask or remove subsets with poor data coverage.
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ç©ºé—´çš„æ›´å¤æ‚å½¢çŠ¶æ˜¯å¯èƒ½çš„ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å±è”½æˆ–åˆ é™¤æ•°æ®è¦†ç›–è¾ƒå·®çš„å­é›†ã€‚
- en: '**Feature Ranking**'
  id: totrans-558
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æ’åº**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): part of feature engineering,
    feature ranking is a set of methods that assign relative importance or value to
    each feature with respect to information contained for inference and importance
    in predicting a response feature.'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šç‰¹å¾å·¥ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œç‰¹å¾æ’åºæ˜¯ä¸€ç»„æ–¹æ³•ï¼Œæ ¹æ®æ¯ä¸ªç‰¹å¾åŒ…å«çš„ä¿¡æ¯é‡åŠå…¶åœ¨é¢„æµ‹å“åº”ç‰¹å¾ä¸­çš„é‡è¦æ€§æˆ–ä»·å€¼æ¥åˆ†é…ç›¸å¯¹é‡è¦æ€§æˆ–ä»·å€¼ã€‚'
- en: There are a wide variety of possible methods to accomplish this. My recommendation
    is a wide-array approach with multiple metric, while understanding the assumptions
    and limitations of each method.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆæ­¤ä»»åŠ¡æœ‰å„ç§å„æ ·çš„å¯èƒ½æ–¹æ³•ã€‚æˆ‘çš„å»ºè®®æ˜¯é‡‡ç”¨å¤šç§åº¦é‡æ ‡å‡†çš„æ–¹æ³•ï¼ŒåŒæ—¶ç†è§£æ¯ç§æ–¹æ³•çš„å‡è®¾å’Œå±€é™æ€§ã€‚
- en: 'Hereâ€™s the general types of metrics that we will consider for feature ranking:'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æˆ‘ä»¬å°†è€ƒè™‘çš„ç‰¹å¾æ’åºçš„ä¸€èˆ¬ç±»å‹æŒ‡æ ‡ï¼š
- en: '*Visual Inspection* - including data distributions, scatter plots and violin
    plots'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è§†è§‰æ£€æŸ¥* - åŒ…æ‹¬æ•°æ®åˆ†å¸ƒã€æ•£ç‚¹å›¾å’Œå°æç´å›¾'
- en: '*Statistical Summaries* - correlation analysis, mutual information'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç»Ÿè®¡æ‘˜è¦* - ç›¸å…³æ€§åˆ†æã€äº’ä¿¡æ¯'
- en: '*Model-based* - including model parameters, feature importance scores and global
    Shapley values'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºæ¨¡å‹* - åŒ…æ‹¬æ¨¡å‹å‚æ•°ã€ç‰¹å¾é‡è¦æ€§åˆ†æ•°å’Œå…¨å±€Shapleyå€¼'
- en: '*Recursive feature elimination* - and other methods that perform trail and
    error to find optimum parameters sets through withheld testing data cross validation'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é€’å½’ç‰¹å¾æ¶ˆé™¤* - ä»¥åŠå…¶ä»–é€šè¿‡ä¿ç•™æµ‹è¯•æ•°æ®äº¤å‰éªŒè¯è¿›è¡Œè¯•é”™ä»¥æ‰¾åˆ°æœ€ä½³å‚æ•°é›†çš„æ–¹æ³•'
- en: Feature ranking is primarily motivated by the curse of dimensionality, i.e.,
    work with the fewest, most informative predictor features.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾æ’åºä¸»è¦æ˜¯ç”±ç»´åº¦è¯…å’’é©±åŠ¨çš„ï¼Œå³ï¼Œä½¿ç”¨æœ€å°‘ã€æœ€æœ‰ä¿¡æ¯é‡çš„é¢„æµ‹ç‰¹å¾ã€‚
- en: '**Feature Transformations**'
  id: totrans-567
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å˜æ¢**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    type of feature engineering involving mathematical operation applied to a feature
    to improve the value of the feature in a workflow. For example,'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§ç‰¹å¾å·¥ç¨‹ï¼Œæ¶‰åŠå¯¹ç‰¹å¾åº”ç”¨æ•°å­¦è¿ç®—ä»¥æ”¹è¿›ç‰¹å¾åœ¨å·¥ä½œæµç¨‹ä¸­çš„ä»·å€¼ã€‚ä¾‹å¦‚ï¼Œ'
- en: feature truncation
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾æˆªæ–­
- en: feature normalization or standardization
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å½’ä¸€åŒ–æˆ–æ ‡å‡†åŒ–
- en: feature distribution transformation
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾åˆ†å¸ƒå˜æ¢
- en: There are many reasons that we may want to perform feature transformations.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯èƒ½æœ‰å¤šç§åŸå› æƒ³è¦æ‰§è¡Œç‰¹å¾å˜æ¢ã€‚
- en: the make the features consistent for visualization and comparison
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç‰¹å¾ä¸€è‡´ä»¥ä¾¿äºå¯è§†åŒ–å’Œæ¯”è¾ƒ
- en: to avoid bias or impose feature weighting for methods (e.g. k nearest neighbours
    regression) that rely on distances calculated in predictor feature space
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…åå·®æˆ–ä¸ºä¾èµ–äºé¢„æµ‹ç‰¹å¾ç©ºé—´ä¸­è®¡ç®—çš„è·ç¦»çš„æ–¹æ³•ï¼ˆä¾‹å¦‚ k è¿‘é‚»å›å½’ï¼‰æ–½åŠ ç‰¹å¾æƒé‡
- en: 'the method requires the variables to have a specific range or distribution:'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•è¦æ±‚å˜é‡å…·æœ‰ç‰¹å®šçš„èŒƒå›´æˆ–åˆ†å¸ƒï¼š
- en: artificial neural networks may require all features to range from [-1,1]
  id: totrans-576
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: äººå·¥ç¥ç»ç½‘ç»œå¯èƒ½è¦æ±‚æ‰€æœ‰ç‰¹å¾çš„èŒƒå›´ä» [-1,1]
- en: partial correlation coefficients require a Gaussian distribution.
  id: totrans-577
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: éƒ¨åˆ†ç›¸å…³ç³»æ•°éœ€è¦é«˜æ–¯åˆ†å¸ƒã€‚
- en: statistical tests may require a specific distribution
  id: totrans-578
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡æµ‹è¯•å¯èƒ½éœ€è¦ç‰¹å®šçš„åˆ†å¸ƒ
- en: geostatistical sequential simulation requires an indicator or Gaussian transform
  id: totrans-579
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°ç»Ÿè®¡å­¦é¡ºåºæ¨¡æ‹Ÿéœ€è¦æŒ‡ç¤ºå™¨æˆ–é«˜æ–¯å˜æ¢
- en: Feature transformations is a common basic building blocks in many machine learning
    workflows.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾å˜æ¢æ˜¯è®¸å¤šæœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸­çš„å¸¸è§åŸºæœ¬æ„å»ºå—ã€‚
- en: '**Fourth Paradigm**'
  id: totrans-581
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¬¬å››èŒƒå¼**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the data-driven
    paradigm for scientific discovery building from the,'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä»æ•°æ®é©±åŠ¨çš„èŒƒå¼è¿›è¡Œç§‘å­¦å‘ç°æ„å»ºï¼Œ'
- en: First Paradigm - empirical science - experiments and observations
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€èŒƒå¼ - ç»éªŒç§‘å­¦ - å®éªŒå’Œè§‚å¯Ÿ
- en: Second Paradigm - theoretical science - analytical expressions
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬äºŒèŒƒå¼ - ç†è®ºç§‘å­¦ - åˆ†æè¡¨è¾¾å¼
- en: Third Paradigm - computation science - numeric simulation
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰èŒƒå¼ - è®¡ç®—ç§‘å­¦ - æ•°å€¼æ¨¡æ‹Ÿ
- en: We augment with new scientific paradigms, we donâ€™t replace older paradigms.
    Each of the previous paradigm are supported by the previous paradigms, for example,
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡å¢åŠ æ–°çš„ç§‘å­¦èŒƒå¼ï¼Œè€Œä¸æ˜¯æ›¿æ¢æ—§èŒƒå¼ã€‚æ¯ä¸ªå…ˆå‰çš„èŒƒå¼éƒ½ç”±å…ˆå‰çš„èŒƒå¼æ”¯æŒï¼Œä¾‹å¦‚ï¼Œ
- en: theoretical science is build on empirical science
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç†è®ºç§‘å­¦å»ºç«‹åœ¨ç»éªŒç§‘å­¦ä¹‹ä¸Š
- en: numerical simulations integrate analytical expressions and calibrated equations
    from experiment
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°å€¼æ¨¡æ‹Ÿå°†å®éªŒä¸­çš„åˆ†æè¡¨è¾¾å¼å’Œæ ¡å‡†æ–¹ç¨‹æ•´åˆåœ¨ä¸€èµ·
- en: '**Frequentist Probability**'
  id: totrans-589
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢‘ç‡æ´¾æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): measure of the likelihood
    that an event will occur based on frequencies observed from an experiment. For
    random experiments and well-defined settings (such as coin tosses),'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåŸºäºä»å®éªŒä¸­è§‚å¯Ÿåˆ°çš„é¢‘ç‡æ¥è¡¡é‡äº‹ä»¶å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚å¯¹äºéšæœºå®éªŒå’Œå®šä¹‰è‰¯å¥½çš„è®¾ç½®ï¼ˆä¾‹å¦‚æŠ›ç¡¬å¸ï¼‰ï¼Œ'
- en: \[ \text{Prob}(A) = P(A) = \lim_{n \to \infty} \frac{n(A)}{n} \]
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Prob}(A) = P(A) = \lim_{n \to \infty} \frac{n(A)}{n} \]
- en: 'where:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼š
- en: \(n(A)\) = number of times event \(A\) occurred \(n\) = number of trails
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: \(n(A)\) = äº‹ä»¶ \(A\) å‘ç”Ÿçš„æ¬¡æ•° \(n\) = è¯•éªŒæ¬¡æ•°
- en: For example, possibility of drilling a dry hole for the next well, encountering
    sandstone at a location (\(\bf{u}_{\alpha}\)), exceeding a rock porosity of \(15
    \%\) at a location (\(\bf{u}_{\alpha}\)).
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸‹ä¸€å£äº•å¯èƒ½å¹²æ¶¸çš„å¯èƒ½æ€§ï¼Œåœ¨æŸä¸ªä½ç½® (\(\bf{u}_{\alpha}\)) é‡åˆ°ç ‚å²©ï¼Œåœ¨æŸä¸ªä½ç½® (\(\bf{u}_{\alpha}\))
    è¶…è¿‡ \(15 \%\) çš„å²©çŸ³å­”éš™ç‡ã€‚
- en: '**Gaussian Anamorphosis**'
  id: totrans-595
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é«˜æ–¯ç•¸å˜**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    quantile transformation to a Gaussian distribution.'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šå°†åˆ†ä½æ•°å˜æ¢ä¸ºé«˜æ–¯åˆ†å¸ƒã€‚'
- en: Mapping feature values through their cumulative probabilities.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å®ƒä»¬çš„ç´¯ç§¯æ¦‚ç‡æ˜ å°„ç‰¹å¾å€¼ã€‚
- en: \[ y = G_y^{-1}\left( F_x(x)\right) \]
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = G_y^{-1}\left( F_x(x)\right) \]
- en: where \(ğ¹_ğ‘¥\) is the original feature cumulative distribution function (CDF)
    and \(ğº_ğ‘¦\) is the Gaussian CDF probability density function
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(ğ¹_ğ‘¥\) æ˜¯åŸå§‹ç‰¹å¾ç´¯ç§¯åˆ†å¸ƒå‡½æ•° (CDF) å’Œ \(ğº_ğ‘¦\) æ˜¯é«˜æ–¯ CDF æ¦‚ç‡å¯†åº¦å‡½æ•°
- en: \[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp \left[-1 \frac{1}{2} \left(\frac{x-\mu}{\sigma}
    \right)^2 \right] \]
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp \left[-1 \frac{1}{2} \left(\frac{x-\mu}{\sigma}
    \right)^2 \right] \]
- en: shorthand for a normal distribution is
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£æ€åˆ†å¸ƒçš„ç¼©å†™æ˜¯
- en: \[ N[\mu,\sigma^2] \]
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: \[ N[\mu,\sigma^2] \]
- en: for example \(N[0,1]\) is standard normal
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ \(N[0,1]\) æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒ
- en: much of natural variation or measurement error is Gaussian
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§éƒ¨åˆ†è‡ªç„¶å˜å¼‚æˆ–æµ‹é‡è¯¯å·®æ˜¯é«˜æ–¯çš„
- en: parameterized fully by mean, variance and correlation coefficient (if multivariate)
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚æ•°åŒ–å®Œå…¨ç”±å‡å€¼ã€æ–¹å·®å’Œç›¸å…³æ€§ç³»æ•°ï¼ˆå¦‚æœå¤šå…ƒï¼‰å†³å®š
- en: distribution is unbounded, no min nor max, extremes are very unlikely, some
    type of truncation is often applied
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒæ˜¯æ— ç•Œçš„ï¼Œæ²¡æœ‰æœ€å°å€¼ä¹Ÿæ²¡æœ‰æœ€å¤§å€¼ï¼Œæç«¯å€¼éå¸¸ä¸å¯èƒ½ï¼Œé€šå¸¸åº”ç”¨æŸç§æˆªæ–­
- en: Warning, many workflows apply univariate Gaussian anamorphosis and then assume
    bivariate or multivariate Gaussian, this is not correct, but it is generally too
    difficult to transform our data to multivariate Gaussian.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: è­¦å‘Šï¼Œè®¸å¤šå·¥ä½œæµç¨‹åº”ç”¨å•å˜é‡é«˜æ–¯å˜å½¢ç„¶åå‡è®¾åŒå˜é‡æˆ–å¤šå˜é‡é«˜æ–¯ï¼Œè¿™æ˜¯ä¸æ­£ç¡®çš„ï¼Œä½†é€šå¸¸å¾ˆéš¾å°†æˆ‘ä»¬çš„æ•°æ®è½¬æ¢ä¸ºå¤šå˜é‡é«˜æ–¯ã€‚
- en: Methods that require a Gaussian distribution,
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦é«˜æ–¯åˆ†å¸ƒçš„æ–¹æ³•ã€‚
- en: Pearson product-moment correlation coefficients completely characterize multivariate
    relationships when data are multivariate Gaussian
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æ•°æ®æ˜¯å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ—¶ï¼Œçš®å°”é€Šç§¯çŸ©ç›¸å…³ç³»æ•°å®Œå…¨æè¿°äº†å¤šå…ƒå…³ç³»ã€‚
- en: partial correlations require bivariate Gaussian
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éƒ¨åˆ†ç›¸å…³éœ€è¦åŒå˜é‡é«˜æ–¯åˆ†å¸ƒã€‚
- en: sequential simulation (geostatistics) assumes Gaussian to reproduce the global
    distribution
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¡ºåºæ¨¡æ‹Ÿï¼ˆåœ°ç»Ÿè®¡å­¦ï¼‰å‡è®¾é«˜æ–¯åˆ†å¸ƒä»¥å†ç°å…¨å±€åˆ†å¸ƒã€‚
- en: Studentâ€™s t test for difference in means
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å€¼å·®å¼‚çš„Student's tæ£€éªŒã€‚
- en: Chi-square distributions is derived from sum of squares of Gaussian distributed
    random variables
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¡æ–¹åˆ†å¸ƒæ˜¯ä»é«˜æ–¯åˆ†å¸ƒéšæœºå˜é‡çš„å¹³æ–¹å’Œæ¨å¯¼å‡ºæ¥çš„ã€‚
- en: Gaussian naive Bayes classification assumes Gaussian conditionals
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å‡è®¾æ¡ä»¶ä¸ºé«˜æ–¯åˆ†å¸ƒã€‚
- en: '**Gibbs Sampler** (MCMC)'
  id: totrans-615
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Gibbsé‡‡æ ·å™¨** (MCMC)'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a set of algorithms to sample from a probability distribution such that the samples
    match the distribution statistics, based on,'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€ç»„ç®—æ³•ï¼Œç”¨äºä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œä½¿å¾—æ ·æœ¬åŒ¹é…åˆ†å¸ƒç»Ÿè®¡ï¼ŒåŸºäºï¼Œ'
- en: sequentially sampling from conditional distributions
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾æ¬¡ä»æ¡ä»¶åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ã€‚
- en: Since only the conditional probability density functions are required, the system
    is simplified as the full joint probability density function is not needed
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåªéœ€è¦æ¡ä»¶æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œç³»ç»Ÿç®€åŒ–ä¸ºä¸éœ€è¦å®Œæ•´çš„è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚
- en: Hereâ€™s the basic steps of the Gibbs MCMC Sampler for a bivariate case,
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯Gibbs MCMCé‡‡æ ·å™¨åŒå˜é‡æƒ…å†µçš„åŸºæœ¬æ­¥éª¤ã€‚
- en: Assign random values for \(ğ‘‹(0)\), \(ğ‘Œ(0)\)
  id: totrans-620
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸º \(ğ‘‹(0)\)ã€\(ğ‘Œ(0)\) åˆ†é…éšæœºå€¼ã€‚
- en: Sample from \(ğ‘“(ğ‘‹|ğ‘Œ(0))\) to get \(ğ‘‹(1)\)
  id: totrans-621
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä» \(ğ‘“(ğ‘‹|ğ‘Œ(0))\) ä¸­é‡‡æ ·ä»¥è·å¾— \(ğ‘‹(1)\)ã€‚
- en: Sample from \(ğ‘“(ğ‘Œ|ğ‘‹(1))\) to get \(ğ‘Œ(1)\)
  id: totrans-622
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä» \(ğ‘“(ğ‘Œ|ğ‘‹(1))\) ä¸­é‡‡æ ·ä»¥è·å¾— \(ğ‘Œ(1)\)ã€‚
- en: Repeat for the next steps for samples, \(\ell = 1,\ldots,ğ¿\)
  id: totrans-623
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹æ ·æœ¬é‡å¤ä¸‹ä¸€æ­¥ï¼Œ\(\ell = 1,\ldots,ğ¿\)ã€‚
- en: The resulting samples will have the correct joint distribution,
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: äº§ç”Ÿçš„æ ·æœ¬å°†å…·æœ‰æ­£ç¡®çš„è”åˆåˆ†å¸ƒã€‚
- en: \[ ğ‘“(ğ‘‹,ğ‘Œ) \]
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘“(ğ‘‹,ğ‘Œ) \]
- en: '**Gradient Boosting Models**'
  id: totrans-626
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¢¯åº¦æå‡æ¨¡å‹**'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): a prediction model
    that results from posing a boosting model as gradient descent problem'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šå°†æå‡æ¨¡å‹ä½œä¸ºæ¢¯åº¦ä¸‹é™é—®é¢˜æå‡ºçš„ç»“æœé¢„æµ‹æ¨¡å‹ã€‚'
- en: At each step, \(k\), a model is being fit, then the error is calculated, \(h_k(X_1,\ldots,X_m)\).
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªæ­¥éª¤ \(k\)ï¼Œä¸€ä¸ªæ¨¡å‹æ­£åœ¨è¢«æ‹Ÿåˆï¼Œç„¶åè®¡ç®—è¯¯å·® \(h_k(X_1,\ldots,X_m)\)ã€‚
- en: We can assign a loss function,
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ†é…ä¸€ä¸ªæŸå¤±å‡½æ•°ã€‚
- en: \[ L\left(y,F(X)\right) = \frac{\left(y - F(X)\right)^2}{2} \]
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L\left(y,F(X)\right) = \frac{\left(y - F(X)\right)^2}{2} \]
- en: 'So we want to minimize the \(\ell2\) loss function:'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›æœ€å°åŒ– \(\ell2\) æŸå¤±å‡½æ•°ï¼š
- en: \[ J = \sum_{i=1}^{n} L\left(y_i, F_k(X) \right) \]
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: \[ J = \sum_{i=1}^{n} L\left(y_i, F_k(X) \right) \]
- en: by adjusting our model result over our training data \(F(x_1), F(x_2),\ldots,F(x_n)\).
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è°ƒæ•´æˆ‘ä»¬çš„æ¨¡å‹ç»“æœæ¥é€‚åº”æˆ‘ä»¬çš„è®­ç»ƒæ•°æ® \(F(x_1), F(x_2),\ldots,F(x_n)\)ã€‚
- en: We can take the partial derivative of the error vs. our model,
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å–è¯¯å·®ç›¸å¯¹äºæˆ‘ä»¬çš„æ¨¡å‹çš„åå¯¼æ•°ã€‚
- en: \[ \frac{\partial J}{\partial F(x_i)} = F(x_i) - y_i \]
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial J}{\partial F(x_i)} = F(x_i) - y_i \]
- en: We can interpret the residuals as negative gradients.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†æ®‹å·®è§£é‡Šä¸ºè´Ÿæ¢¯åº¦ã€‚
- en: \[ y_i - F(x_i) = -1 \frac{\partial J}{\partial F(x_i)} \]
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i - F(x_i) = -1 \frac{\partial J}{\partial F(x_i)} \]
- en: 'So now we have a gradient descent problem:'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªæ¢¯åº¦ä¸‹é™é—®é¢˜ï¼š
- en: \[ F_{k+1}(X_i) = F_k(X_i) + h(X_i) \]\[ F_{k+1}(X_i) = F_k(X_i) + y_i - F_k(X_i)
    \]\[ F_{k+1}(X_i) = F_k(X_i) - 1 \frac{\partial J}{\partial F_k(X_i)} \]
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_{k+1}(X_i) = F_k(X_i) + h(X_i) \]\[ F_{k+1}(X_i) = F_k(X_i) + y_i - F_k(X_i)
    \]\[ F_{k+1}(X_i) = F_k(X_i) - 1 \frac{\partial J}{\partial F_k(X_i)} \]
- en: 'Of the general form:'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: é€šç”¨å½¢å¼å¦‚ä¸‹ï¼š
- en: \[ \phi_{k+1} = \phi_k - \rho \frac{\partial J}{\partial \phi_k} \]
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi_{k+1} = \phi_k - \rho \frac{\partial J}{\partial \phi_k} \]
- en: where \(phi_k\) is the current state, \(\rho\) is the learning rate, \(J\) is
    the loss function, and \(\phi_{k+1}\) is the next state of our estimator.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(phi_k\) æ˜¯å½“å‰çŠ¶æ€ï¼Œ\(\rho\) æ˜¯å­¦ä¹ ç‡ï¼Œ\(J\) æ˜¯æŸå¤±å‡½æ•°ï¼Œè€Œ \(\phi_{k+1}\) æ˜¯æˆ‘ä»¬ä¼°è®¡å™¨çš„ä¸‹ä¸€ä¸ªçŠ¶æ€ã€‚
- en: The error residual at training data is the gradient, then we are performing
    gradient descent,
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®ä¸­çš„è¯¯å·®æ®‹å·®æ˜¯æ¢¯åº¦ï¼Œå› æ­¤æˆ‘ä»¬æ­£åœ¨è¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚
- en: fitting a series of models to negative gradients
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è´Ÿæ¢¯åº¦è¿›è¡Œä¸€ç³»åˆ—æ¨¡å‹çš„æ‹Ÿåˆã€‚
- en: By approaching the problem as a gradient decent problem we are able to apply
    a variety of loss functions,
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†é—®é¢˜è§†ä¸ºæ¢¯åº¦ä¸‹é™é—®é¢˜ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåº”ç”¨å„ç§æŸå¤±å‡½æ•°ï¼Œ
- en: \(\ell2\) is our \(\frac{\left(y - F(X)\right)^2}{2}\) is practical, but is
    not robust with outliers
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\ell2\) æ˜¯æˆ‘ä»¬çš„ \(\frac{\left(y - F(X)\right)^2}{2}\)ï¼Œå®é™…åº”ç”¨ä¸­æ˜¯å¯è¡Œçš„ï¼Œä½†å¯¹å¤–éƒ¨å¼‚å¸¸å€¼ä¸ç¨³å¥
- en: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = y_i - F_k(X_i) \]
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = y_i - F_k(X_i) \]
- en: \(\ell1\) is our \(|y - F(X)|\) is more robust with outliers
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\ell1\) æ˜¯æˆ‘ä»¬çš„ \(|y - F(X)|\)ï¼Œå¯¹å¤–éƒ¨å¼‚å¸¸å€¼æ›´ç¨³å¥
- en: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = sign(y_i - F_k(X_i)) \]
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = sign(y_i - F_k(X_i)) \]
- en: there are others like Huber Loss
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿˜æœ‰å…¶ä»–ä¸€äº›ï¼Œå¦‚ Huber æŸå¤±
- en: '**Graph Laplacian** (spectral clustering)'
  id: totrans-651
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å›¾æ‹‰æ™®æ‹‰æ–¯ç®—å­**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph by integrating connections between graph nodes, samples, number of connections
    for each graph nodes, samples. Calculated as degree matrix minus adjacency matrix.
    Where,'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šé€šè¿‡æ•´åˆå›¾èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥æ¥è¡¨ç¤ºå›¾çš„çŸ©é˜µï¼ŒåŒ…æ‹¬æ¯ä¸ªå›¾èŠ‚ç‚¹å’Œæ ·æœ¬çš„è¿æ¥æ•°ã€‚è®¡ç®—ä¸ºåº¦çŸ©é˜µå‡å»é‚»æ¥çŸ©é˜µã€‚å…¶ä¸­ï¼Œ'
- en: '*degree matrix*, \(ğ·\) - degree of connection for each node'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åº¦çŸ©é˜µ*ï¼Œ\(ğ·\) - æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥åº¦'
- en: adjacency matrix, \(ğ´\) - specific connections between nodes
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‚»æ¥çŸ©é˜µï¼Œ\(ğ´\) - èŠ‚ç‚¹ä¹‹é—´çš„ç‰¹å®šè¿æ¥
- en: '**Geostatistics**'
  id: totrans-655
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åœ°ç†ç»Ÿè®¡å­¦**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a branch of applied
    statistics that integrates:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåº”ç”¨ç»Ÿè®¡å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒæ•´åˆäº†ï¼š'
- en: the spatial (geological) context
  id: totrans-657
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç©ºé—´ï¼ˆåœ°è´¨ï¼‰èƒŒæ™¯
- en: the spatial relationship
  id: totrans-658
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç©ºé—´å…³ç³»
- en: volumetric support / scale
  id: totrans-659
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½“ç§¯æ”¯æŒ/å°ºåº¦
- en: uncertainty
  id: totrans-660
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§
- en: I include all spatial statistics with geostatistics, some disagree with me on
    this. From my experience, any useful statistical method for modeling spatial phenomenon
    is adopted and added to the geostatistics toolkit! Geostatistics is an expanding
    and evolving field of study.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æ‰€æœ‰ç©ºé—´ç»Ÿè®¡éƒ½åŒ…å«åœ¨åœ°ç†ç»Ÿè®¡å­¦ä¸­ï¼Œæœ‰äº›äººä¸åŒæ„æˆ‘çš„è§‚ç‚¹ã€‚æ ¹æ®æˆ‘çš„ç»éªŒï¼Œä»»ä½•æœ‰ç”¨çš„ç”¨äºå»ºæ¨¡ç©ºé—´ç°è±¡çš„ç»Ÿè®¡æ–¹æ³•éƒ½è¢«é‡‡ç”¨å¹¶æ·»åŠ åˆ°åœ°ç†ç»Ÿè®¡å­¦å·¥å…·åŒ…ä¸­ï¼åœ°ç†ç»Ÿè®¡å­¦æ˜¯ä¸€ä¸ªä¸æ–­å‘å±•å’Œæ¼”å˜çš„ç ”ç©¶é¢†åŸŸã€‚
- en: '**Gradient-based Optimization**'
  id: totrans-662
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): a method to solve
    for model parameters by iteratively minimizing the loss function. The steps include,'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šé€šè¿‡è¿­ä»£æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥æ±‚è§£æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚æ­¥éª¤åŒ…æ‹¬ï¼Œ'
- en: start with random model parameters
  id: totrans-664
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»éšæœºçš„æ¨¡å‹å‚æ•°å¼€å§‹
- en: calculate the loss function for the model parameters
  id: totrans-665
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¨¡å‹å‚æ•°çš„æŸå¤±å‡½æ•°
- en: calculate the loss function gradient, generally donâ€™t have an equation for the
    loss function, sampling with numerical calculation of the local loss function
    derivative,
  id: totrans-666
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œé€šå¸¸æ²¡æœ‰æŸå¤±å‡½æ•°çš„æ–¹ç¨‹ï¼Œé€šè¿‡æ•°å€¼è®¡ç®—å±€éƒ¨æŸå¤±å‡½æ•°çš„å¯¼æ•°è¿›è¡Œé‡‡æ ·ï¼Œ
- en: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
- en: update the parameter estimate by stepping down slope / gradient,
  id: totrans-668
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡æ²¿æ–œå¡/æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°å‚æ•°ä¼°è®¡ï¼Œ
- en: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
- en: where \(r\) is the learning rate/step size, \(\hat{b}(1,ğ‘¡)\), is the current
    model parameter estimate and \(\hat{b}(1,ğ‘¡+1)\) is the updated parameter estimate.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(r\) æ˜¯å­¦ä¹ ç‡/æ­¥é•¿ï¼Œ\(\hat{b}(1,ğ‘¡)\) æ˜¯å½“å‰æ¨¡å‹å‚æ•°ä¼°è®¡ï¼Œè€Œ \(\hat{b}(1,ğ‘¡+1)\) æ˜¯æ›´æ–°åçš„å‚æ•°ä¼°è®¡ã€‚
- en: Some important comments about gradient-based optimization,
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›å…³äºåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–çš„é‡è¦è¯„è®ºï¼Œ
- en: '*gradient search convergence* - the method will find a local or global minimum'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¢¯åº¦æœç´¢æ”¶æ•›* - è¯¥æ–¹æ³•å°†æ‰¾åˆ°å±€éƒ¨æˆ–å…¨å±€æœ€å°å€¼'
- en: '*gradient search step size* - impact of step size, \(r\) too small, takes too
    long to converge to a solution and \(r\) too large, the solution may skip over/miss
    a global minimum or diverge'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¢¯åº¦æœç´¢æ­¥é•¿* - æ­¥é•¿çš„å½±å“ï¼Œ\(r\) å¤ªå°ï¼Œéœ€è¦å¤ªé•¿æ—¶é—´æ”¶æ•›åˆ°è§£ï¼Œè€Œ \(r\) å¤ªå¤§ï¼Œè§£å¯èƒ½è·³è¿‡/é”™è¿‡å…¨å±€æœ€å°å€¼æˆ–å‘æ•£'
- en: '*multiple model parameters* - calculate and decompose the gradient over multiple
    model parameters, with a vector representation.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šä¸ªæ¨¡å‹å‚æ•°* - åœ¨å¤šä¸ªæ¨¡å‹å‚æ•°ä¸Šè®¡ç®—å’Œåˆ†è§£æ¢¯åº¦ï¼Œä»¥å‘é‡è¡¨ç¤ºã€‚'
- en: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1, b_2)) = \left[ \begin{matrix} \nabla
    L(y_{\alpha}, F(X_{\alpha}, b_1)) & \nabla L(y_{\alpha}, F(X_{\alpha}, b_2)) \end{matrix}
    \right] \]
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1, b_2)) = \left[ \begin{matrix} \nabla
    L(y_{\alpha}, F(X_{\alpha}, b_1)) & \nabla L(y_{\alpha}, F(X_{\alpha}, b_2)) \end{matrix}
    \right] \]
- en: '*exploration of parameter space* - optimization for training machine learning
    model parameters is exploration of a high dimensional model parameter space'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å‚æ•°ç©ºé—´æ¢ç´¢* - è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–æ˜¯æ¢ç´¢é«˜ç»´æ¨¡å‹å‚æ•°ç©ºé—´'
- en: '**Graph** (spectral clustering)'
  id: totrans-677
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å›¾**ï¼ˆå…‰è°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a diagram
    that represents data in an organized manner, each sample as a node with vertices
    indicating pairwise relationships between samples.'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…‰è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šä¸€ç§ä»¥æœ‰ç»„ç»‡çš„æ–¹å¼è¡¨ç¤ºæ•°æ®çš„å›¾è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬ä½œä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œé¡¶ç‚¹è¡¨ç¤ºæ ·æœ¬ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚'
- en: for an undirected graph, vertices are bidirectional, i.e., the connection is
    symmetric, both ways with the same strength
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ— å‘å›¾ï¼Œé¡¶ç‚¹æ˜¯åŒå‘çš„ï¼Œå³è¿æ¥æ˜¯å¯¹ç§°çš„ï¼Œä¸¤ä¸ªæ–¹å‘å…·æœ‰ç›¸åŒçš„å¼ºåº¦
- en: '**Gridded Data**'
  id: totrans-680
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç½‘æ ¼æ•°æ®**'
- en: 'Machine Learning Workflow Construction and Coding: generally exhaustive, regularly
    spaced data over 2D or 3D, representing maps and models'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šé€šå¸¸åœ¨ 2D æˆ– 3D ä¸Šå…·æœ‰è¯¦å°½ä¸”å‡åŒ€åˆ†å¸ƒçš„æ•°æ®ï¼Œä»£è¡¨åœ°å›¾å’Œæ¨¡å‹
- en: stored as a .csv comma delimited file, with \(ğ‘›_ğ‘¦\) rows and \(ğ‘›_ğ‘¥\) columns
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­˜å‚¨ä¸ºé€—å·åˆ†éš”çš„ .csv æ–‡ä»¶ï¼ŒåŒ…å« \(ğ‘›_ğ‘¦\) è¡Œå’Œ \(ğ‘›_ğ‘¥\) åˆ—
- en: may also be saved/loaded as also binary for a more compact, but not human readable
    file.
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿå¯ä»¥ä¿å­˜/åŠ è½½ä¸ºäºŒè¿›åˆ¶æ ¼å¼ï¼Œä»¥è·å¾—æ›´ç´§å‡‘çš„æ–‡ä»¶ï¼Œä½†ä¸æ˜¯äººç±»å¯è¯»çš„ã€‚
- en: commonly visualized directly, for example, matplotlibâ€™s imshow function, or
    as contour maps
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ç›´æ¥å¯è§†åŒ–ï¼Œä¾‹å¦‚ï¼Œmatplotlib çš„ imshow å‡½æ•°ï¼Œæˆ–ä½œä¸ºç­‰é«˜çº¿å›¾
- en: '**Hard Data**'
  id: totrans-685
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¡¬æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data that has a
    high degree of certainty, usually from a direct measurement from the rock'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå…·æœ‰é«˜åº¦ç¡®å®šæ€§çš„æ•°æ®ï¼Œé€šå¸¸æ¥è‡ªå²©çŸ³çš„ç›´æ¥æµ‹é‡'
- en: for example, well core-based and well log-based porosity and lithofacies
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼ŒåŸºäºäº•ç­’å²©å¿ƒå’ŒåŸºäºæµ‹äº•æ•°æ®çš„å­”éš™åº¦å’Œå²©æ€§
- en: In general, hard data has high resolution (small scale, volume support), but
    with poor coverage (measure only an extremely small proportion of the population,
    for example,
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç¡¬æ•°æ®å…·æœ‰é«˜åˆ†è¾¨ç‡ï¼ˆå°å°ºåº¦ã€ä½“ç§¯æ”¯æ’‘ï¼‰ï¼Œä½†è¦†ç›–èŒƒå›´è¾ƒå·®ï¼ˆä»…æµ‹é‡äººå£ä¸­çš„æå°æ¯”ä¾‹ï¼Œä¾‹å¦‚ï¼Œ
- en: '*Core coverage deepwater oil and gas* - well core only sample one five hundred
    millionth to one five billionth of a deepwater reservoir, assuming 3 inch diameter
    cores with 10% core coverage in vertical wells with 500 m to 1,500 m spacing'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–æ·±æ°´æ²¹æ°”* - äº•ç­’å²©å¿ƒä»…é‡‡æ ·æ·±æ°´å‚¨å±‚çš„ä¸€åƒäº”ç™¾ä¸‡åˆ†ä¹‹ä¸€åˆ°ä¸€åäº¿åˆ†ä¹‹ä¸€ï¼Œå‡è®¾ä½¿ç”¨ç›´å¾„ä¸º 3 è‹±å¯¸çš„å²©å¿ƒï¼Œåœ¨å‚ç›´äº•ä¸­ï¼Œå²©å¿ƒè¦†ç›–ç‡ä¸º 10%ï¼Œäº•è·ä¸º
    500 ç±³åˆ° 1,500 ç±³'
- en: '*Core coverage mining grade control* - diamond drill hole cores sample one
    eight thousandth to one thirty thousandth of ore body, assuming HQ 63.5 mm diameter
    cores with 100% core coverage in vertical drill holes with 5 m to 10 m spacing'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–é‡‡çŸ¿çº§æ§åˆ¶* - é’»å­”å²©å¿ƒæ ·æœ¬å çŸ¿çŸ³ä½“ç§¯çš„ä¸€ä¸‡å…«åƒåˆ†ä¹‹ä¸€åˆ°ä¸‰ä¸‡åˆ†ä¹‹ä¸€ï¼Œå‡è®¾ HQ 63.5 æ¯«ç±³ç›´å¾„å²©å¿ƒï¼Œåœ¨å‚ç›´é’»å­”ä¸­å²©å¿ƒè¦†ç›–ç‡ä¸º 100%ï¼Œäº•è·ä¸º
    5 ç±³åˆ° 10 ç±³'
- en: '**Hermite Polynomials**'
  id: totrans-691
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**èµ«å°”ç±³ç‰¹å¤šé¡¹å¼**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): a family
    of orthogonal polynomials on the real number line.'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šå®æ•°çº¿ä¸Šçš„æ­£äº¤å¤šé¡¹å¼æ—ã€‚'
- en: '| Order | Hermite Polynomial \(H_e(x)\) |'
  id: totrans-693
  prefs: []
  type: TYPE_TB
  zh: '| é˜¶æ•° | èµ«å°”ç±³ç‰¹å¤šé¡¹å¼ \(H_e(x)\) |'
- en: '| --- | --- |'
  id: totrans-694
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0th Order | \(H_{e_0}(x) = 1\) |'
  id: totrans-695
  prefs: []
  type: TYPE_TB
  zh: '| é›¶é˜¶ | \(H_{e_0}(x) = 1\) |'
- en: '| 1st Order | \(H_{e_1}(x) = x\) |'
  id: totrans-696
  prefs: []
  type: TYPE_TB
  zh: '| ä¸€é˜¶ | \(H_{e_1}(x) = x\) |'
- en: '| 2nd Order | \(H_{e_2}(x) = x^2 - 1\) |'
  id: totrans-697
  prefs: []
  type: TYPE_TB
  zh: '| äºŒé˜¶ | \(H_{e_2}(x) = x^2 - 1\) |'
- en: '| 3rd Order | \(H_{e_3}(x) = x^3 - 3x\) |'
  id: totrans-698
  prefs: []
  type: TYPE_TB
  zh: '| ä¸‰é˜¶ | \(H_{e_3}(x) = x^3 - 3x\) |'
- en: '| 4th Order | \(H_{e_4}(x) = x^4 - 6x^2 + 3\) |'
  id: totrans-699
  prefs: []
  type: TYPE_TB
  zh: '| å››é˜¶ | \(H_{e_4}(x) = x^4 - 6x^2 + 3\) |'
- en: These polynomials are orthogonal with respect to a weighting function,
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤šé¡¹å¼ç›¸å¯¹äºåŠ æƒå‡½æ•°æ˜¯æ­£äº¤çš„ï¼Œ
- en: \[ ğ‘¤(ğ‘¥)=ğ‘’^{âˆ’\frac{ğ‘¥^2}{2}} \]
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘¤(ğ‘¥)=ğ‘’^{âˆ’\frac{ğ‘¥^2}{2}} \]
- en: this is the standard Gaussian probability density function without the scaler,
    \(\frac{1}{\sqrt{2\pi}}\). The definition of orthogonality is stated as,
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ ‡å‡†é«˜æ–¯æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæ²¡æœ‰ç¼©æ”¾å› å­ï¼Œ\(\frac{1}{\sqrt{2\pi}}\)ã€‚æ­£äº¤æ€§çš„å®šä¹‰å¦‚ä¸‹ï¼Œ
- en: \[ \int_{-\infty}^{\infty} H_m(x) H_n(x) w(x) \, dx = 0 \]
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \int_{-\infty}^{\infty} H_m(x) H_n(x) w(x) \, dx = 0 \]
- en: The Hermite polynomials are orthogonal over the interval \([âˆ’\infty,\infty]\)
    for the standard normal probability distribution.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: èµ«å°”ç±³ç‰¹å¤šé¡¹å¼åœ¨æ ‡å‡†æ­£æ€æ¦‚ç‡åˆ†å¸ƒçš„åŒºé—´ \([âˆ’\infty,\infty]\) ä¸Šæ˜¯æ­£äº¤çš„ã€‚
- en: By applying hermite polynomials instead of regular polynomials for polynomial
    basis expansion in polynomial regression were remove the multicollinearity between
    the predictor features,
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åœ¨å¤šé¡¹å¼å›å½’ä¸­ä½¿ç”¨èµ«å°”ç±³ç‰¹å¤šé¡¹å¼è€Œä¸æ˜¯å¸¸è§„å¤šé¡¹å¼è¿›è¡Œå¤šé¡¹å¼åŸºæ‰©å±•ï¼Œå¯ä»¥æ¶ˆé™¤é¢„æµ‹ç‰¹å¾ä¹‹é—´çš„å¤šé‡å…±çº¿æ€§ï¼Œ
- en: recall, independence of the predictor features is an assumption of the linear
    system applied in polynomial regression with the polynomial basis expansion
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›æƒ³ï¼Œé¢„æµ‹ç‰¹å¾ä¹‹é—´çš„ç‹¬ç«‹æ€§æ˜¯å¤šé¡¹å¼å›å½’ä¸­åº”ç”¨å¤šé¡¹å¼åŸºæ‰©å±•çš„çº¿æ€§ç³»ç»Ÿçš„ä¸€ä¸ªå‡è®¾
- en: '**Heuristic Algorithm**'
  id: totrans-707
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯å‘å¼ç®—æ³•**'
- en: 'Cluster Analysis: a shortcut solution to solve a difficult problem a compromise
    of optimality and accuracy for speed and practicality.'
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šè§£å†³éš¾é¢˜çš„æ·å¾„ï¼Œä¸ºäº†é€Ÿåº¦å’Œå®ç”¨æ€§ï¼Œåœ¨æœ€ä¼˜æ€§å’Œå‡†ç¡®æ€§ä¹‹é—´åšå‡ºå¦¥åã€‚
- en: this general approach is common in machine learning, computer science and mathematical
    optimization, for example, the solution for k-mean clustering a \(k^n\) solution
    space is practically solved with an heuristic algorithm.
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç§é€šç”¨æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ ã€è®¡ç®—æœºç§‘å­¦å’Œæ•°å­¦ä¼˜åŒ–ä¸­å¾ˆå¸¸è§ï¼Œä¾‹å¦‚ï¼Œkå‡å€¼èšç±»çš„ \(k^n\) è§£ç©ºé—´å®é™…ä¸Šæ˜¯é€šè¿‡å¯å‘å¼ç®—æ³•è§£å†³çš„ã€‚
- en: '**Hierarchical Clustering**'
  id: totrans-710
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å±‚æ¬¡èšç±»**'
- en: 'Cluster Analysis: all cluster group assignments are determined iteratively,
    as opposed to an partitional clustering method that determine cluster groups all
    at once. Including,'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šæ‰€æœ‰èšç±»åˆ†ç»„åˆ†é…éƒ½æ˜¯è¿­ä»£ç¡®å®šçš„ï¼Œä¸ä¸€æ¬¡æ€§ç¡®å®šæ‰€æœ‰èšç±»åˆ†ç»„çš„åˆ’åˆ†èšç±»æ–¹æ³•ç›¸åã€‚åŒ…æ‹¬ï¼Œ
- en: '*agglomerative hierarchical clustering* - start with \(n\) clusters, each data
    sample in its own cluster, and then iteratively merges clusters into larger clusters'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*èšåˆå±‚æ¬¡èšç±»* - ä» \(n\) ä¸ªèšç±»å¼€å§‹ï¼Œæ¯ä¸ªæ•°æ®æ ·æœ¬åœ¨å…¶è‡ªå·±çš„èšç±»ä¸­ï¼Œç„¶åè¿­ä»£åœ°å°†èšç±»åˆå¹¶æˆæ›´å¤§çš„èšç±»'
- en: '*divisive hierarchical clustering* - start with all data in one cluster, and
    then iteratively divide off new clusters'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ’åˆ†å±‚æ¬¡èšç±»* - ä»æ‰€æœ‰æ•°æ®åœ¨ä¸€ä¸ªèšç±»å¼€å§‹ï¼Œç„¶åè¿­ä»£åœ°åˆ’åˆ†å‡ºæ–°çš„èšç±»'
- en: k-means clustering is partitional clustering, while the solution heuristic to
    find the solution is iterative, the solution is actually all at once
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kå‡å€¼èšç±»æ˜¯åˆ’åˆ†èšç±»ï¼Œè€Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„å¯å‘å¼æ–¹æ³•æ˜¯è¿­ä»£çš„ï¼Œä½†å®é™…ä¸Šè§£å†³æ–¹æ¡ˆæ˜¯ä¸€æ¬¡æ€§å®Œæˆçš„
- en: difficult to update, once a series of splits or mergers are made it is difficult
    to go back and modify the model
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¾ˆéš¾æ›´æ–°ï¼Œä¸€æ—¦è¿›è¡Œäº†ä¸€ç³»åˆ—çš„æ‹†åˆ†æˆ–åˆå¹¶ï¼Œå°±å¾ˆéš¾è¿”å›å¹¶ä¿®æ”¹æ¨¡å‹
- en: '**Histogram**'
  id: totrans-716
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›´æ–¹å›¾**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): a representation
    of the univariate statistical distribution with a plot of frequency over an exhaustive
    set of bins over the range of possible values. These are the steps to build a
    histogram,'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šä½¿ç”¨é¢‘ç‡å›¾è¡¨ç¤ºå•å˜é‡ç»Ÿè®¡åˆ†å¸ƒï¼Œè¯¥å›¾åœ¨å¯èƒ½å€¼çš„èŒƒå›´å†…å¯¹ä¸€ç»„å®Œæ•´çš„ç®±è¿›è¡Œç»˜åˆ¶ã€‚è¿™äº›æ˜¯æ„å»ºç›´æ–¹å›¾çš„æ­¥éª¤ï¼Œ'
- en: 'Divide the continuous feature range of possible values into \(K\) equal size
    bins, \(\delta x\):'
  id: totrans-718
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å°†å¯èƒ½çš„è¿ç»­ç‰¹å¾å€¼èŒƒå›´åˆ’åˆ†ä¸º \(K\) ä¸ªç›¸ç­‰å¤§å°çš„ç®±ï¼Œ\(\delta x\):'
- en: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
- en: or use available category labels for categorical features.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ä½¿ç”¨å¯ç”¨çš„ç±»åˆ«æ ‡ç­¾è¿›è¡Œåˆ†ç±»ç‰¹å¾ã€‚
- en: Count the number of samples (frequency) in each bin, \(n_k\), \quad \(\forall
    \quad k=1,\ldots,K\).
  id: totrans-721
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯ä¸ªç®±ä¸­æ ·æœ¬çš„æ•°é‡ï¼ˆé¢‘ç‡ï¼‰ï¼Œ\(n_k\)ï¼Œ \quad \(\forall \quad k=1,\ldots,K\).
- en: Plot the frequency vs. the bin label (use bin centroid if continuous)
  id: totrans-722
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶é¢‘ç‡ä¸ç®±æ ‡ç­¾çš„å…³ç³»å›¾ï¼ˆå¦‚æœè¿ç»­ï¼Œåˆ™ä½¿ç”¨ç®±ä¸­å¿ƒï¼‰
- en: Note, histograms are typically plotted as a bar chart.
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç›´æ–¹å›¾é€šå¸¸ä»¥æŸ±çŠ¶å›¾çš„å½¢å¼ç»˜åˆ¶ã€‚
- en: '**Hybrid Model**'
  id: totrans-724
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ··åˆæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): system or process
    that includes a combination of both *deterministic model* and *stochastic model*'
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåŒ…æ‹¬ç¡®å®šæ€§æ¨¡å‹å’Œéšæœºæ¨¡å‹ç»„åˆçš„ç³»ç»Ÿæˆ–è¿‡ç¨‹'
- en: most geostatistical models are hybrid models
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°åœ°ç»Ÿè®¡æ¨¡å‹éƒ½æ˜¯æ··åˆæ¨¡å‹
- en: for example, additive deterministic trend models and stochastic residual models
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼ŒåŠ æ€§ç¡®å®šæ€§è¶‹åŠ¿æ¨¡å‹å’Œéšæœºæ®‹å·®æ¨¡å‹
- en: '**Independence** (probability)'
  id: totrans-728
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‹¬ç«‹æ€§**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): events \(A\) and
    \(B\) are independent if and only if the following relations are true,'
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šäº‹ä»¶ \(A\) å’Œ \(B\) ç‹¬ç«‹å½“ä¸”ä»…å½“ä»¥ä¸‹å…³ç³»æˆç«‹ï¼Œ'
- en: \(P(A \cap B) = P(A) \cdot P(B)\)
  id: totrans-730
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(P(A \cap B) = P(A) \cdot P(B)\)
- en: \(P(A|B) = P(A)\)
  id: totrans-731
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(P(A|B) = P(A)\)
- en: \(P(B|A) = P(B)\)
  id: totrans-732
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(P(B|A) = P(B)\)
- en: If any of these are violated we suspect that there exists some form of relationship.
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä»»ä½•è¿™äº›æ¡ä»¶è¢«è¿åï¼Œæˆ‘ä»¬æ€€ç–‘å­˜åœ¨æŸç§å½¢å¼çš„å…³ç³»ã€‚
- en: '**Indicator Transform** (also Binary Transform)'
  id: totrans-734
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŒ‡ç¤ºè½¬æ¢**ï¼ˆä¹Ÿç§°ä¸ºäºŒå…ƒè½¬æ¢ï¼‰'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): indicator
    coding a random variable to a probability relative to a category or a threshold.'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šå°†éšæœºå˜é‡ç¼–ç ä¸ºç›¸å¯¹äºç±»åˆ«æˆ–é˜ˆå€¼çš„æ¦‚ç‡çš„æŒ‡ç¤ºç¬¦ã€‚'
- en: If \(i(\bf{u}:z_k)\) is an indicator for a categorical variable,
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(i(\bf{u}:z_k)\) æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡çš„æŒ‡ç¤ºç¬¦ï¼Œ
- en: what is the probability of a realization equal to a category?
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°ç­‰äºæŸä¸€ç±»åˆ«çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_2 = 2\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 2\),
    then \(i(bf{u}_1; z_2) = 1\)
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_2 = 2\)ï¼Œä»¥åŠæ•°æ®åœ¨ \(\bf{u}_1\)ï¼Œ\(z(\bf{u}_1) = 2\)ï¼Œé‚£ä¹ˆ \(i(bf{u}_1; z_2)
    = 1\)
- en: given threshold, \(z_1 = 1\), and a RV away from data, \(Z(\bf{u}_2)\) then
    is calculated as \(F^{-1}_{\bf{u}_2}(z_1)\) of the RV as \(i(\bf{u}_2; z_1) =
    0.23\)
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 1\)ï¼Œä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ï¼Œ\(Z(\bf{u}_2)\)ï¼Œé‚£ä¹ˆè®¡ç®—ä¸º \(F^{-1}_{\bf{u}_2}(z_1)\)
    çš„éšæœºå˜é‡ï¼Œ\(i(\bf{u}_2; z_1) = 0.23\)
- en: If \(i(\bf{u}:z_k)\) is an indicator for a continuous variable,
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(i(\bf{u}:z_k)\) æ˜¯ä¸€ä¸ªè¿ç»­å˜é‡çš„æŒ‡ç¤ºç¬¦ï¼Œ
- en: what is the probability of a realization less than or equal to a threshold?
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°å°äºæˆ–ç­‰äºé˜ˆå€¼çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_1 = 6\%\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 8\%\),
    then \(i(\bf{u}_1; z_1) = 0\)
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 6\%\)ï¼Œä»¥åŠæ•°æ®åœ¨ \(\bf{u}_1\)ï¼Œ\(z(\bf{u}_1) = 8\%\)ï¼Œé‚£ä¹ˆ \(i(\bf{u}_1;
    z_1) = 0\)
- en: given threshold, \(z_4 = 18\%\), and a RV away from data, \(Z(\bf{u}_2) = N\left[\mu
    = 16\%,\sigma = 3\%\right]\) then \(i(\bf{u}_2; z_4) = 0.75\)
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_4 = 18\%\)ï¼Œä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ï¼Œ\(Z(\bf{u}_2) = N\left[\mu = 16\%,\sigma =
    3\%\right]\)ï¼Œé‚£ä¹ˆ \(i(\bf{u}_2; z_4) = 0.75\)
- en: The indicator coding may be applied over an entire random function by indicator
    transform of all the random variables at each location.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡ç¤ºç¼–ç å¯ä»¥é€šè¿‡å¯¹æ¯ä¸ªä½ç½®çš„éšæœºå˜é‡çš„æŒ‡ç¤ºå˜æ¢åº”ç”¨äºæ•´ä¸ªéšæœºå‡½æ•°ã€‚
- en: '**Indicator Variogram**'
  id: totrans-749
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŒ‡ç¤ºå˜å¼‚å›¾**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): varogramâ€™s
    calculated and modelled from the *indicator transform* of spatial data and used
    for indicator kriging. The indicator variogram is,'
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šæŒ‡ç¤ºå˜å¼‚å›¾æ˜¯ä»ç©ºé—´æ•°æ®çš„**æŒ‡ç¤ºå˜æ¢**è®¡ç®—å’Œå»ºæ¨¡çš„ï¼Œç”¨äºæŒ‡ç¤ºå…‹ç«‹æ ¼æ³•ã€‚æŒ‡ç¤ºå˜å¼‚å›¾æ˜¯ï¼Œ'
- en: \[ \gamma_i(\mathbf{h}; z_k) = \frac{1}{2N(\mathbf{h})} \sum_{\alpha=1}^{N(\mathbf{h})}
    \left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h}; z_k) \right]^2
    \]
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \gamma_i(\mathbf{h}; z_k) = \frac{1}{2N(\mathbf{h})} \sum_{\alpha=1}^{N(\mathbf{h})}
    \left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h}; z_k) \right]^2
    \]
- en: where \(i(\mathbf{u}_\alpha; z_k)\) and \(i(\mathbf{u}_\alpha + \mathbf{h};
    z_k)\) are the indicator transforms for the \(z_k\) threshold at the tail location
    \(\mathbf{u}_\alpha\) and head location \(\mathbf{u}_\alpha + \mathbf{h}\) respectively.
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(i(\mathbf{u}_\alpha; z_k)\) å’Œ \(i(\mathbf{u}_\alpha + \mathbf{h}; z_k)\)
    åˆ†åˆ«æ˜¯å°¾ç«¯ä½ç½® \(\mathbf{u}_\alpha\) å’Œå¤´éƒ¨ä½ç½® \(\mathbf{u}_\alpha + \mathbf{h}\) çš„ \(z_k\)
    é˜ˆå€¼çš„æŒ‡ç¤ºå˜æ¢ã€‚
- en: for hard data the indicator transform \(i(\bf{u},z_k)\) is either 0 or 1, in
    which case the \(\left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h};
    z_k) \right]^2\) is equal to 0 when the values at head and tail are both \(\le
    z_k\) (for continuous features) or \(= z_k\) (for categorical features), the same
    relative to the threshold, or 1 when they are different.
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç¡¬æ•°æ®ï¼ŒæŒ‡ç¤ºå˜æ¢ \(i(\bf{u},z_k)\) è¦ä¹ˆæ˜¯ 0ï¼Œè¦ä¹ˆæ˜¯ 1ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“å¤´éƒ¨å’Œå°¾éƒ¨çš„å€¼éƒ½ \(\le z_k\)ï¼ˆå¯¹äºè¿ç»­ç‰¹å¾ï¼‰æˆ–
    \(= z_k\)ï¼ˆå¯¹äºåˆ†ç±»ç‰¹å¾ï¼‰æ—¶ï¼Œ\(\left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha +
    \mathbf{h}; z_k) \right]^2\) ç­‰äº 0ï¼Œç›¸å¯¹äºé˜ˆå€¼ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œæˆ–è€…å½“å®ƒä»¬ä¸åŒæ—¶ä¸º 1ã€‚
- en: therefore, the indicator variogram is \(\frac{1}{2}\) the proportion of pairs
    that change! The indicator variogram can be related to probability of change over
    a lag distance, \(h\).
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒæŒ‡ç¤ºå˜å¼‚å›¾æ˜¯å˜åŒ–å¯¹çš„æ¯”ä¾‹çš„ä¸€åŠï¼æŒ‡ç¤ºå˜å¼‚å›¾å¯ä»¥ä¸æ»åè·ç¦» \(h\) ä¸Šçš„å˜åŒ–æ¦‚ç‡ç›¸å…³ã€‚
- en: the sill of an indicator variogram is the indicator variance calculated as,
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒ‡ç¤ºå˜å¼‚å›¾çš„å—é‡‘å€¼æ˜¯æŒ‰ä»¥ä¸‹æ–¹å¼è®¡ç®—çš„æŒ‡ç¤ºæ–¹å·®ï¼Œ
- en: \[ \sigma_i^2 = p \cdot (1 - p) \]
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_i^2 = p \cdot (1 - p) \]
- en: where \(p\) is the proportion of 1â€™s (or zeros as the function is symmetric
    over proportion)
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(p\) æ˜¯ 1 çš„æ¯”ä¾‹ï¼ˆæˆ–é›¶ï¼Œå› ä¸ºå‡½æ•°åœ¨æ¯”ä¾‹ä¸Šæ˜¯å¯¹ç§°çš„ï¼‰
- en: '**Inference, Inferential Statistics**'
  id: totrans-758
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨æ–­ï¼Œæ¨æ–­ç»Ÿè®¡å­¦**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): this is a big topic,
    but for the course I provide this simplified, functional definition, given a random
    sample from a population, describe the population, for example,'
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ä¸»é¢˜ï¼Œä½†ä¸ºäº†è¿™é—¨è¯¾ç¨‹ï¼Œæˆ‘æä¾›äº†è¿™ä¸ªç®€åŒ–çš„ã€åŠŸèƒ½æ€§çš„å®šä¹‰ï¼Œç»™å®šæ¥è‡ªæ€»ä½“çš„éšæœºæ ·æœ¬ï¼Œæè¿°æ€»ä½“ï¼Œä¾‹å¦‚ï¼Œ'
- en: given the well samples, describe the reservoir
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šäº•æ ·ï¼Œæè¿°å‚¨å±‚
- en: given the drill hole samples, describe the ore body
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé’»å­”æ ·å“ï¼Œæè¿°çŸ¿ä½“
- en: '**Inlier**'
  id: totrans-762
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å†…ç‚¹**'
- en: a regression model accuracy metric, the proportion of testing data within a
    margin, \(\epsilon\), of the model predictions, \(\hat{y}_i\),
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå›å½’æ¨¡å‹å‡†ç¡®åº¦æŒ‡æ ‡ï¼Œè¡¨ç¤ºåœ¨æ¨¡å‹é¢„æµ‹å€¼ \(\hat{y}_i\) çš„ \(\epsilon\) èŒƒå›´å†…çš„æµ‹è¯•æ•°æ®æ¯”ä¾‹ï¼Œ
- en: \[ I_R = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} I(y_i, \hat{y}_i)
    \]
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I_R = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} I(y_i, \hat{y}_i)
    \]
- en: given the indicator transform,
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šæŒ‡ç¤ºå˜æ¢ï¼Œ
- en: \[\begin{split} I(y_i, \hat{y}_i) = \begin{cases} 1, & \text{if } |y_i - \hat{y}_i|
    \leq \epsilon \\ 0, & \text{otherwise} \end{cases} \end{split}\]
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} I(y_i, \hat{y}_i) = \begin{cases} 1, & \text{if } |y_i - \hat{y}_i|
    \leq \epsilon \\ 0, & \text{otherwise} \end{cases} \end{split}\]
- en: This is a useful, intuitive measure of accuracy, the proportion of training
    or testing data with predictions that are good enough.
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ã€ç›´è§‚çš„å‡†ç¡®åº¦åº¦é‡ï¼Œè¡¨ç¤ºå…·æœ‰è¶³å¤Ÿå¥½çš„é¢„æµ‹çš„è®­ç»ƒæˆ–æµ‹è¯•æ•°æ®æ¯”ä¾‹ã€‚
- en: but, there is a choice of the size of the margin, \(\epsilon\), that could be
    related to the accuracy required for the specific application
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œå­˜åœ¨ä¸€ä¸ªä¸ç‰¹å®šåº”ç”¨æ‰€éœ€çš„å‡†ç¡®åº¦ç›¸å…³çš„è¾¹ç•Œå¤§å° \(\epsilon\) çš„é€‰æ‹©
- en: '**Instance-based Learning**'
  id: totrans-769
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå®ä¾‹çš„å­¦ä¹ **'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): also known
    as memory-based learning, compares new prediction problems (as set of predictors,
    \(ğ‘¥_1,\ldots,ğ‘¥_ğ‘š\)) with the cases observed in the training data.'
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html)ï¼šä¹Ÿç§°ä¸ºåŸºäºè®°å¿†çš„å­¦ä¹ ï¼Œæ¯”è¾ƒæ–°çš„é¢„æµ‹é—®é¢˜ï¼ˆä½œä¸ºé¢„æµ‹å™¨é›†åˆ
    \(ğ‘¥_1,\ldots,ğ‘¥_ğ‘š\)ï¼‰ä¸è®­ç»ƒæ•°æ®ä¸­è§‚å¯Ÿåˆ°çš„æ¡ˆä¾‹ã€‚'
- en: model requires access to the training data, acting as a library of observations
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹éœ€è¦è®¿é—®è®­ç»ƒæ•°æ®ï¼Œå……å½“è§‚å¯Ÿçš„åº“
- en: prediction directly from the training data
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´æ¥ä»è®­ç»ƒæ•°æ®ä¸­è¿›è¡Œé¢„æµ‹
- en: prediction complexity grows with the number of training data, \(ğ‘›\), number
    of neighbors, \(ğ‘˜\), and number of features, \(ğ‘š\).
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹å¤æ‚åº¦éšç€è®­ç»ƒæ•°æ®æ•°é‡ \(ğ‘›\)ã€é‚»å±…æ•°é‡ \(ğ‘˜\) å’Œç‰¹å¾æ•°é‡ \(ğ‘š\) çš„å¢åŠ è€Œå¢é•¿ã€‚
- en: a specific case of lazy learning
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‡’æƒ°å­¦ä¹ çš„ç‰¹å®šæƒ…å†µ
- en: '**Intersection of Events** (probability)'
  id: totrans-775
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº‹ä»¶äº¤é›†**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the intersection
    of outcomes, the probability of \(A\) and \(B\) is represented as,'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šç»“æœçš„äº¤é›†ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ'
- en: \[ P(A \cap B) = P(A,B) \]
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) \]
- en: under the assumption of independence of \(A\) and \(B\) the probability of \(A\)
    and \(B\) is,
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ \(A\) å’Œ \(B\) ç‹¬ç«‹çš„å‰æä¸‹ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡æ˜¯ï¼Œ
- en: \[ P(A,B) = P(A) \cdot P(B) \]
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = P(A) \cdot P(B) \]
- en: '**Irreducible Error**'
  id: totrans-780
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸å¯å‡å°‘è¯¯å·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is error due to
    data limitations, including missing features and missing samples, for example,
    the full predictor feature space is not adequately sampled'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šç”±äºæ•°æ®é™åˆ¶å¯¼è‡´çš„è¯¯å·®ï¼ŒåŒ…æ‹¬ç¼ºå¤±ç‰¹å¾å’Œç¼ºå¤±æ ·æœ¬ï¼Œä¾‹å¦‚ï¼Œå®Œæ•´çš„é¢„æµ‹ç‰¹å¾ç©ºé—´æ²¡æœ‰å¾—åˆ°å……åˆ†çš„é‡‡æ ·'
- en: irreducible error is not impacted by model complexity, it is a limitation of
    the data
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å¯å‡å°‘è¯¯å·®ä¸å—æ¨¡å‹å¤æ‚åº¦çš„å½±å“ï¼Œå®ƒæ˜¯æ•°æ®çš„ä¸€ä¸ªé™åˆ¶
- en: one of the three components of expected test square error, including model variance,
    model bias and irreducible error
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æ¨¡å‹æ–¹å·®ã€æ¨¡å‹åå·®å’Œä¸å¯å‡å°‘è¯¯å·®
- en: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
- en: where \(\sigma_e^2\) is irreducible error.
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma_e^2\) æ˜¯ä¸å¯å‡å°‘è¯¯å·®ã€‚
- en: '**Inertia** (clustering)'
  id: totrans-786
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æƒ¯æ€§**ï¼ˆèšç±»ï¼‰'
- en: 'Cluster Analysis: the k-means clustering loss function summarizing the difference
    between samples within the same group over all the groups,'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šk-means èšç±»æŸå¤±å‡½æ•°æ€»ç»“äº†æ‰€æœ‰ç»„å†…æ ·æœ¬ä¹‹é—´çš„å·®å¼‚ï¼Œ
- en: \[ I = \sum_{i=1}^{K} \sum_{x_j \in C_i} \| x_j - \mu_i \|^2 \]
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I = \sum_{i=1}^{K} \sum_{x_j \in C_i} \| x_j - \mu_i \|^2 \]
- en: where \(K\) is the total number of clusters, \(C_i\) represents the set of samples
    in the \(i^{th}\) cluster, \(x_j\) represents a data sample in cluster, \(C_i\),
    \(mu_i\) is the prototype of cluster \(C_i\),\(\| x_j - \mu_i \|^2\) is the squared
    Euclidean distance between sample \(x_j\) and the cluster prototype \(\mu_i \).
    The samples and prototypes and distance calculations in mD space, with \(1,\ldots,m\)
    features.
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(K\) æ˜¯èšç±»æ€»æ•°ï¼Œ\(C_i\) è¡¨ç¤ºç¬¬ \(i\) ä¸ªèšç±»çš„æ ·æœ¬é›†ï¼Œ\(x_j\) è¡¨ç¤º \(C_i\) èšç±»ä¸­çš„ä¸€ä¸ªæ•°æ®æ ·æœ¬ï¼Œ\(\mu_i\)
    æ˜¯ \(C_i\) èšç±»çš„åŸå‹ï¼Œ\(\| x_j - \mu_i \|^2\) æ˜¯æ ·æœ¬ \(x_j\) ä¸èšç±»åŸå‹ \(\mu_i\) ä¹‹é—´çš„å¹³æ–¹æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚åœ¨
    mD ç©ºé—´ä¸­ï¼Œä½¿ç”¨ \(1,\ldots,m\) ä¸ªç‰¹å¾è¿›è¡Œæ ·æœ¬ã€åŸå‹å’Œè·ç¦»è®¡ç®—ã€‚
- en: by minimizing inertia k-means clusters minimizes difference within groups while
    maximizing difference between groups
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡æœ€å°åŒ–æƒ¯æ€§ï¼Œk-means èšç±»æœ€å°åŒ–ç»„å†…çš„å·®å¼‚ï¼ŒåŒæ—¶æœ€å¤§åŒ–ç»„é—´çš„å·®å¼‚
- en: '**Joint Probability**'
  id: totrans-791
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è”åˆæ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): probability that
    considers more than one event occurring together, the probability of \(A\) and
    \(B\) is represented as,'
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šè€ƒè™‘å¤šä¸ªäº‹ä»¶åŒæ—¶å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ'
- en: \[ P(A \cap B) = P(A,B) \]
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) \]
- en: or the probability of \(A\), \(B\) and \(C\) is represented as,
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€… \(A\)ã€\(B\) å’Œ \(C\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ
- en: \[ P(A \cap B \cap C) = P(A,B,C) \]
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B \cap C) = P(A,B,C) \]
- en: under the assumption of independence of \(A\), \(B\) and \(C\) the joint probability
    may be calculated as,
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡è®¾ \(A\)ã€\(B\) å’Œ \(C\) ç‹¬ç«‹çš„æƒ…å†µä¸‹ï¼Œè”åˆæ¦‚ç‡å¯ä»¥è®¡ç®—ä¸ºï¼Œ
- en: \[ P(A,B,C) = P(A) \cdot P(B) \cdot P(C) \]
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B,C) = P(A) \cdot P(B) \cdot P(C) \]
- en: '**K Bins Discretization**'
  id: totrans-798
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**K ä¸ªæ¡¶ç¦»æ•£åŒ–**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): bin
    the range of the feature into K bins, then for each sample assignment of a value
    of 1 if the sample is within a bin and 0 if outsize the bin'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šå°†ç‰¹å¾çš„å–å€¼èŒƒå›´åˆ’åˆ†ä¸º K ä¸ªæ¡¶ï¼Œç„¶åå¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œå¦‚æœæ ·æœ¬åœ¨æ¡¶å†…ï¼Œåˆ™åˆ†é…å€¼ä¸º
    1ï¼Œå¦‚æœä¸åœ¨æ¡¶å†…ï¼Œåˆ™åˆ†é…å€¼ä¸º 0'
- en: binning strategies include uniform width bins (uniform) and uniform number of
    data in each bin (quantile)
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†æ¡¶ç­–ç•¥åŒ…æ‹¬å‡åŒ€å®½åº¦æ¡¶ï¼ˆå‡åŒ€ï¼‰å’Œæ¯ä¸ªæ¡¶ä¸­å‡åŒ€æ•°é‡çš„æ•°æ®ï¼ˆåˆ†ä½æ•°ï¼‰
- en: also known as one hot encoding
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿç§°ä¸ºç‹¬çƒ­ç¼–ç 
- en: Methods that require K bins discretization,
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦Kä¸ªæ¡¶ç¦»æ•£åŒ–çš„æ–¹æ³•ï¼Œ
- en: basis expansion to work in a higher dimensional space
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºç¡€æ‰©å±•ä»¥åœ¨æ›´é«˜ç»´ç©ºé—´ä¸­å·¥ä½œ
- en: discretization of continuous features to categorical features for categorical
    methods such as naive Bayes classifier
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºåˆ†ç±»ç‰¹å¾ï¼Œç”¨äºå¦‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ç­‰åˆ†ç±»æ–¹æ³•
- en: histogram construction and Chi-square test for difference in distributions
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´æ–¹å›¾æ„å»ºå’Œå¡æ–¹æ£€éªŒç”¨äºåˆ†å¸ƒå·®å¼‚
- en: mutual information binning
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº’ä¿¡æ¯åˆ†æ¡¶
- en: '**K-fold Cross Validation**'
  id: totrans-807
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**K æŠ˜äº¤å‰éªŒè¯**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): partitioning the
    data into K folds, and looping over the folds training the model with reminder
    of the data and testing the model with the data in the fold. Then aggregating
    the testing accuracy over all the folds.'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå°†æ•°æ®åˆ’åˆ†ä¸º K æŠ˜ï¼Œå¹¶å¯¹æ¯æŠ˜è¿›è¡Œå¾ªç¯ï¼Œä½¿ç”¨å‰©ä½™çš„æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨æŠ˜ä¸­çš„æ•°æ®ä¸Šæµ‹è¯•æ¨¡å‹ã€‚ç„¶åæ±‡æ€»æ‰€æœ‰æŠ˜çš„æµ‹è¯•å‡†ç¡®ç‡ã€‚'
- en: the train and test data split is based on K, for example, K = 4, is 25% testing
    for each fold and K = 5, is 20% testing for each fold
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²åŸºäº Kï¼Œä¾‹å¦‚ï¼ŒK = 4 æ—¶ï¼Œæ¯æŠ˜çš„æµ‹è¯•æ•°æ®ä¸º 25%ï¼ŒK = 5 æ—¶ï¼Œæ¯æŠ˜çš„æµ‹è¯•æ•°æ®ä¸º 20%
- en: this is an improvement over cross validation that only applies one train and
    test split to build a single model. The K-fold approach allows testing of all
    data and the aggregation of accuracy over all the folds tends to smooth the accuracy
    vs. hyperparameter plot for more reliable hyperparameter tuning
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹äº¤å‰éªŒè¯çš„ä¸€ç§æ”¹è¿›ï¼Œå®ƒåªåº”ç”¨ä¸€æ¬¡è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²æ¥æ„å»ºä¸€ä¸ªå•ä¸€æ¨¡å‹ã€‚K æŠ˜æ–¹æ³•å…è®¸æµ‹è¯•æ‰€æœ‰æ•°æ®ï¼Œå¹¶ä¸”å¯¹æ‰€æœ‰æŠ˜çš„å‡†ç¡®ç‡è¿›è¡Œæ±‡æ€»å¾€å¾€å¯ä»¥å¹³æ»‘å‡†ç¡®ç‡ä¸è¶…å‚æ•°çš„å›¾åƒï¼Œä»è€Œå®ç°æ›´å¯é çš„è¶…å‚æ•°è°ƒæ•´
- en: k-fold cross validation may be applied to check model performance for estimation
    accuracy (most common) and uncertainty model goodness ([Maldonado-Cruz and Pyrcz,
    2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343))
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K æŠ˜äº¤å‰éªŒè¯å¯ä»¥åº”ç”¨äºæ£€æŸ¥æ¨¡å‹æ€§èƒ½ä»¥ä¼°è®¡å‡†ç¡®åº¦ï¼ˆæœ€å¸¸è§ï¼‰å’Œä¸ç¡®å®šæ€§æ¨¡å‹çš„å¥½åï¼ˆ[Maldonado-Cruz å’Œ Pyrczï¼Œ2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343)ï¼‰
- en: '**k-Means Clustering**'
  id: totrans-812
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**k-Means èšç±»**'
- en: 'Cluster Analysis: an unsupervised machine learning method for partitional clustering,
    group assignment to unlabeled data, where dissimilarity within clustered groups
    is mini minimized. The loss function that is minimized is,'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šä¸€ç§æ— ç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºåˆ†åŒºèšç±»ï¼Œå°†æœªæ ‡è®°æ•°æ®åˆ†ç»„åˆ†é…ï¼Œå…¶ä¸­èšç±»ç»„å†…çš„å·®å¼‚æœ€å°åŒ–ã€‚æœ€å°åŒ–çš„æŸå¤±å‡½æ•°æ˜¯ï¼Œ
- en: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} || X_{\alpha} - \mu_i || \]
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} || X_{\alpha} - \mu_i || \]
- en: where \(i\) is the cluster index, \(\alpha\) is the data sample index, \(X\)
    is the data sample and \(\mu_i\) is the \(i\) cluster prototype, \(k\) is the
    total number of clusters, and \(|| X_m - \mu_m ||\) is the Euclidean distance
    from a sample to the cluster prototype in \(M\) dimensional space calculated as,
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(i\) æ˜¯èšç±»ç´¢å¼•ï¼Œ\(\alpha\) æ˜¯æ•°æ®æ ·æœ¬ç´¢å¼•ï¼Œ\(X\) æ˜¯æ•°æ®æ ·æœ¬ï¼Œ\(\mu_i\) æ˜¯ \(i\) èšç±»çš„åŸå‹ï¼Œ\(k\)
    æ˜¯èšç±»æ€»æ•°ï¼Œè€Œ \(|| X_m - \mu_m ||\) æ˜¯åœ¨ \(M\) ç»´ç©ºé—´ä¸­ä»æ ·æœ¬åˆ°èšç±»åŸå‹çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œè®¡ç®—å¦‚ä¸‹ï¼Œ
- en: \[ || X_{m,\alpha} - \mu_i || = \sqrt{ \sum_m^M \left( X_{m,\alpha} - \mu_{m,i}
    \right)^2 } \]
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: \[ || X_{m,\alpha} - \mu_i || = \sqrt{ \sum_m^M \left( X_{m,\alpha} - \mu_{m,i}
    \right)^2 } \]
- en: Here is a summary of import aspects for k-means clustering,
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯kå‡å€¼èšç±»çš„å…³é”®æ–¹é¢æ€»ç»“ï¼Œ
- en: '*k* - is given as a model hyperparameter'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k* - è¢«ä½œä¸ºæ¨¡å‹è¶…å‚æ•°'
- en: '*exhaustive and mutually exclusive groups* - all data assigned to a single
    group'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©·å°½ä¸”äº’æ–¥çš„ç»„* - æ‰€æœ‰æ•°æ®åˆ†é…åˆ°å•ä¸ªç»„'
- en: '*prototype method* - represents the training data with number of synthetic
    cases in the features space. For K-means clustering we assign and iteratively
    update \(K\) prototypes.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸå‹æ–¹æ³•* - åœ¨ç‰¹å¾ç©ºé—´ä¸­ç”¨åˆæˆæ¡ˆä¾‹çš„æ•°é‡è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚å¯¹äºK-meansèšç±»ï¼Œæˆ‘ä»¬åˆ†é…å¹¶è¿­ä»£æ›´æ–° \(K\) ä¸ªåŸå‹ã€‚'
- en: '*iterative solution* - the initial prototypes are assigned randomly in the
    feature space, the labels for each training sample are updated to the nearest
    prototype, then the prototypes are adjusted to the centroid of their assigned
    training data, repeat until there is no further update to the training data assignments.'
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¿­ä»£è§£æ³•* - åˆå§‹åŸå‹åœ¨ç‰¹å¾ç©ºé—´ä¸­éšæœºåˆ†é…ï¼Œæ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„æ ‡ç­¾æ›´æ–°ä¸ºæœ€è¿‘çš„åŸå‹ï¼Œç„¶ååŸå‹è°ƒæ•´åˆ°å…¶åˆ†é…çš„è®­ç»ƒæ•°æ®çš„è´¨å¿ƒï¼Œé‡å¤æ­¤è¿‡ç¨‹ï¼Œç›´åˆ°è®­ç»ƒæ•°æ®åˆ†é…æ²¡æœ‰è¿›ä¸€æ­¥æ›´æ–°ã€‚'
- en: '*unsupervised learning* - the training data are not labeled and are assigned
    \(K\) labels based on their proximity to the prototypes in the feature space.
    The idea is that similar things, proximity in feature space, should belong to
    the same cluster group.'
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— ç›‘ç£å­¦ä¹ * - è®­ç»ƒæ•°æ®æœªæ ‡è®°ï¼Œå¹¶æ ¹æ®å…¶åœ¨ç‰¹å¾ç©ºé—´ä¸­ä¸åŸå‹çš„æ¥è¿‘ç¨‹åº¦åˆ†é… \(K\) ä¸ªæ ‡ç­¾ã€‚æƒ³æ³•æ˜¯ç›¸ä¼¼çš„äº‹ç‰©ï¼Œåœ¨ç‰¹å¾ç©ºé—´ä¸­çš„æ¥è¿‘åº¦ï¼Œåº”è¯¥å±äºåŒä¸€ä¸ªèšç±»ç»„ã€‚'
- en: '*feature weighting* - the procedure depends on the Euclidian distance between
    training samples and prototypes in feature space. Distance is treated as the â€˜inverseâ€™
    of similarity. If the features have significantly different magnitudes, the feature(s)
    with the largest magnitudes and ranges will dominate the loss function and cluster
    groups will become anisotropic aligned orthogonal to the high range feature(s).
    While the common approach is to standardize / normalize the variables, by-feature
    weighting may be applied through unequal variances. Note, in this demonstration
    we normalize the features to range from 0.0 to 1.0.'
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‰¹å¾åŠ æƒ* - è¯¥è¿‡ç¨‹å–å†³äºè®­ç»ƒæ ·æœ¬å’ŒåŸå‹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚è·ç¦»è¢«è§†ä¸ºç›¸ä¼¼åº¦çš„â€œå€’æ•°â€ã€‚å¦‚æœç‰¹å¾å…·æœ‰æ˜¾è‘—ä¸åŒçš„å¹…åº¦ï¼Œåˆ™å¹…åº¦å’ŒèŒƒå›´æœ€å¤§çš„ç‰¹å¾å°†ä¸»å¯¼æŸå¤±å‡½æ•°ï¼Œèšç±»ç»„å°†å˜å¾—å„å‘å¼‚æ€§ï¼Œä¸é«˜èŒƒå›´ç‰¹å¾å‚ç›´å¯¹é½ã€‚è™½ç„¶å¸¸è§çš„åšæ³•æ˜¯å¯¹å˜é‡è¿›è¡Œæ ‡å‡†åŒ–/å½’ä¸€åŒ–ï¼Œä½†å¯ä»¥é€šè¿‡ä¸ç­‰æ–¹å·®åº”ç”¨ç‰¹å¾åŠ æƒã€‚æ³¨æ„ï¼Œåœ¨è¿™ä¸ªæ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å°†ç‰¹å¾å½’ä¸€åŒ–åˆ°0.0åˆ°1.0çš„èŒƒå›´ã€‚'
- en: '**k-Nearest Neighbours**'
  id: totrans-824
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**k-æœ€è¿‘é‚»ç®—æ³•**'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): a simple,
    interpretable and flexible, nonparametric predictive machine learning model based
    on a local weighting window applied to \(k\) nearest training data'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»ç®—æ³•](MachineLearning_knearest_neighbours.html)ï¼šä¸€ä¸ªç®€å•ã€å¯è§£é‡Šä¸”çµæ´»çš„éå‚æ•°é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ŒåŸºäºå¯¹
    \(k\) ä¸ªæœ€è¿‘è®­ç»ƒæ•°æ®åº”ç”¨å±€éƒ¨åŠ æƒçª—å£'
- en: The k-nearest neighbours approach is similar to a convolution approach for spatial
    interpolation. Convolution is the integral product of two functions, after one
    is reversed and shifted by \(\Delta\).
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: k-æœ€è¿‘é‚»æ–¹æ³•ä¸ç©ºé—´æ’å€¼çš„å·ç§¯æ–¹æ³•ç±»ä¼¼ã€‚å·ç§¯æ˜¯ä¸¤ä¸ªå‡½æ•°çš„ç§¯åˆ†ä¹˜ç§¯ï¼Œå…¶ä¸­ä¸€ä¸ªå‡½æ•°è¢«åè½¬å¹¶æ²¿ \(\Delta\) å¹³ç§»ã€‚
- en: one interpretation is smoothing a function with weighting function, \(ğ‘“(\Delta)\),
    is applied to calculate the weighted average of function, \(ğ‘”(x)\),
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£é‡Šæ˜¯ä½¿ç”¨åŠ æƒå‡½æ•° \(ğ‘“(\Delta)\) å¯¹å‡½æ•°è¿›è¡Œå¹³æ»‘ï¼Œä»¥è®¡ç®—å‡½æ•° \(ğ‘”(x)\) çš„åŠ æƒå¹³å‡å€¼ï¼Œ
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
- en: this easily extends into multidimensional
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå®¹æ˜“æ‰©å±•åˆ°å¤šç»´
- en: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
- en: The choice of which function is shifted before integration does not change the
    result, the convolution operator has commutativity.
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç§¯åˆ†ä¹‹å‰é€‰æ‹©å“ªä¸ªå‡½æ•°è¢«å¹³ç§»ä¸ä¼šæ”¹å˜ç»“æœï¼Œå·ç§¯ç®—å­å…·æœ‰äº¤æ¢æ€§ã€‚
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
- en: if either function is reflected then convolution is equivalent to cross-correlation,
    measure of similarity between 2 signals as a function of displacement.
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä»»ä¸€å‡½æ•°è¢«åå°„ï¼Œå·ç§¯å°±ç­‰åŒäºäº’ç›¸å…³ï¼Œå®ƒæ˜¯ä¸¤ä¸ªä¿¡å·ç›¸ä¼¼åº¦çš„åº¦é‡ï¼Œä½œä¸ºä½ç§»çš„å‡½æ•°ã€‚
- en: for k-nearest neighbours the use of \(k\) results in a locally adaptive window
    size, different from standard convolution
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºkè¿‘é‚»ï¼Œä½¿ç”¨\(k\)ä¼šå¯¼è‡´ä¸€ä¸ªå±€éƒ¨è‡ªé€‚åº”çª—å£å¤§å°ï¼Œè¿™ä¸æ ‡å‡†çš„å·ç§¯ä¸åŒ
- en: K-nearest neighbours is an instance-based, lazy learning method, the model training
    is postponed until prediction is required, no precalculation of the model. i.e.,
    prediction requires access to the data.
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: Kè¿‘é‚»æ˜¯ä¸€ç§åŸºäºå®ä¾‹çš„æ‡’æƒ°å­¦ä¹ æ–¹æ³•ï¼Œæ¨¡å‹è®­ç»ƒè¢«æ¨è¿Ÿåˆ°éœ€è¦é¢„æµ‹æ—¶ï¼Œä¸éœ€è¦é¢„å…ˆè®¡ç®—æ¨¡å‹ã€‚å³é¢„æµ‹éœ€è¦è®¿é—®æ•°æ®ã€‚
- en: to make new predictions that training data must be available
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿›è¡Œæ–°çš„é¢„æµ‹ï¼Œå¿…é¡»è¦æœ‰è®­ç»ƒæ•°æ®
- en: The hyperparameters include,
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°åŒ…æ‹¬ï¼Œ
- en: '*k number of nearest data* to utilize for prediction'
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kä¸ªæœ€è¿‘çš„æ•°æ®ç‚¹*ç”¨äºé¢„æµ‹'
- en: '*data weighting*, for example uniform weighting with the local training data
    average, or inverse distance weighting'
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ•°æ®åŠ æƒ*ï¼Œä¾‹å¦‚ä½¿ç”¨å±€éƒ¨è®­ç»ƒæ•°æ®å¹³å‡å€¼çš„å‡åŒ€åŠ æƒï¼Œæˆ–é€†è·ç¦»åŠ æƒ'
- en: Note, for the case of inverse distance weighting, the method is analogous to
    inverse distance weighted interpolation with a maximum number of local data constraint
    commonly applied for spatial interpolation.
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¯¹äºé€†è·ç¦»åŠ æƒçš„æƒ…å†µï¼Œè¯¥æ–¹æ³•ç±»ä¼¼äºé€†è·ç¦»åŠ æƒæ’å€¼ï¼Œé€šå¸¸åº”ç”¨äºç©ºé—´æ’å€¼ï¼Œå¹¶æ–½åŠ ä¸€ä¸ªæœ€å¤§å±€éƒ¨æ•°æ®æ•°é‡çº¦æŸã€‚
- en: inverse distance is available in GeostatsPy for spatial mapping.
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€†è·ç¦»åœ¨GeostatsPyä¸­å¯ç”¨äºç©ºé—´æ˜ å°„ã€‚
- en: Too find the k-nearest data a distance metric is needed,
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰¾åˆ°æœ€è¿‘çš„kä¸ªæ•°æ®ç‚¹ï¼Œéœ€è¦ä¸€ä¸ªè·ç¦»åº¦é‡ï¼Œ
- en: training data within the predictor feature space are ranked by distance (closest
    to farthest)
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´å†…çš„è®­ç»ƒæ•°æ®æŒ‰è·ç¦»æ’åºï¼ˆä»è¿‘åˆ°è¿œï¼‰
- en: 'a variety of distance metrics may be applied, including:'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ä»¥åº”ç”¨å„ç§è·ç¦»åº¦é‡ï¼ŒåŒ…æ‹¬ï¼š
- en: Euclidian distance
  id: totrans-845
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¬§å‡ é‡Œå¾—è·ç¦»
- en: \begin{equation}
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{equation}
- en: d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
    \end{equation}
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
    \end{equation}
- en: Minkowski Distance - a general expression for distance with well-known Manhattan
    and Euclidean distances are special cases,
  id: totrans-848
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Minkowskiè·ç¦» - è·ç¦»çš„é€šç”¨è¡¨è¾¾å¼ï¼Œå…¶ä¸­å·²çŸ¥çš„æ›¼å“ˆé¡¿è·ç¦»å’Œæ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œ
- en: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
- en: when \(p=2\), this becomes the Euclidean distance
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“\(p=2\)æ—¶ï¼Œè¿™å˜ä¸ºæ¬§å‡ é‡Œå¾—è·ç¦»
- en: when \(p=1\) it becomes the Manhattan distance
  id: totrans-851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“\(p=1\)æ—¶ï¼Œå®ƒå˜ä¸ºæ›¼å“ˆé¡¿è·ç¦»
- en: '**Kernel Trick** (support vector machines)'
  id: totrans-852
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ¸æŠ€å·§**ï¼ˆæ”¯æŒå‘é‡æœºï¼‰'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): we
    can incorporate our basis expansion in our method without ever needing to transform
    the training data to this higher dimensional space,'
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šæˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­åŒ…å«åŸºå‡½æ•°çš„æ‰©å±•ï¼Œè€Œæ— éœ€å°†è®­ç»ƒæ•°æ®è½¬æ¢åˆ°è¿™ä¸ªæ›´é«˜ç»´çš„ç©ºé—´ï¼Œ'
- en: \[ h(x) \]
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h(x) \]
- en: We only need the inner product over the predictor features,
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€è¦é¢„æµ‹ç‰¹å¾ä¸Šçš„å†…ç§¯ï¼Œ
- en: \[ h(x) \left( h(x') \right)^T = \langle h(x), h(x') \rangle \]
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h(x) \left( h(x') \right)^T = \langle h(x), h(x') \rangle \]
- en: Instead of the actual values in the transformed space, we just need the â€˜similarityâ€™
    between all available training data in that transformed space!
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å˜æ¢ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦æ‰€æœ‰å¯ç”¨è®­ç»ƒæ•°æ®åœ¨è¯¥å˜æ¢ç©ºé—´ä¸­çš„â€˜ç›¸ä¼¼æ€§â€™ï¼
- en: we training our support vector machines with only a similarity matrix between
    training data that will be projected to the higher dimensional space
  id: totrans-858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»…ä½¿ç”¨å°†è¢«æŠ•å½±åˆ°æ›´é«˜ç»´ç©ºé—´çš„è®­ç»ƒæ•°æ®ä¹‹é—´çš„ç›¸ä¼¼æ€§çŸ©é˜µæ¥è®­ç»ƒæ”¯æŒå‘é‡æœº
- en: we never actually need to calculate the training data values in the higher dimensional
    space
  id: totrans-859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®é™…ä¸Šæ°¸è¿œä¸éœ€è¦è®¡ç®—æ›´é«˜ç»´ç©ºé—´ä¸­çš„è®­ç»ƒæ•°æ®å€¼
- en: '**Kriging**'
  id: totrans-860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å…‹é‡Œé‡‘æ³•**'
- en: 'Data Preparation: spatial estimation approach that relies on linear weights
    that account for spatial continuity, data closeness and redundancy. The kriging
    estimate is,'
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¾èµ–äºçº¿æ€§æƒé‡çš„ç©ºé—´ä¼°è®¡æ–¹æ³•ï¼Œè¿™äº›æƒé‡è€ƒè™‘äº†ç©ºé—´è¿ç»­æ€§ã€æ•°æ®æ¥è¿‘æ€§å’Œå†—ä½™ã€‚å…‹é‡Œé‡‘ä¼°è®¡æ˜¯ï¼Œ
- en: \[ z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha})
    + \left( 1.0 - \sum_{\alpha=1}^n \lambda_{\alpha} \right) \cdot m_z \]
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha})
    + \left( 1.0 - \sum_{\alpha=1}^n \lambda_{\alpha} \right) \cdot m_z \]
- en: the right term is the unbiasedness constraint, one minus the sum of the weights
    is applied to the global mean.
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£ç¡®çš„æœ¯è¯­æ˜¯æ— åçº¦æŸï¼Œå°†æƒé‡ä¹‹å’Œå‡å»1åº”ç”¨äºå…¨å±€å‡å€¼ã€‚
- en: In the case where the trend, \(t(\bf{u})\), is removed, we now have a residual,
    \(y(\bf{u})\),
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å»é™¤è¶‹åŠ¿\(t(\bf{u})\)çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªæ®‹å·®ï¼Œ\(y(\bf{u})\)ï¼Œ
- en: \[ y(\bf{u}) = z(\bf{u}) - t(\bf{u}) \]
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y(\bf{u}) = z(\bf{u}) - t(\bf{u}) \]
- en: the residual mean is zero so we can simplify our kriging estimate as,
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: æ®‹å·®å‡å€¼ä¸ºé›¶ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç®€åŒ–æˆ‘ä»¬çš„å…‹é‡Œé‡‘ä¼°è®¡ä¸ºï¼Œ
- en: \[ y^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot y(\bf{u}_{\alpha})
    \]
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot y(\bf{u}_{\alpha})
    \]
- en: The simple kriging weights are calculated by solving a linear system of equations,
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•å…‹é‡Œé‡‘æƒé‡æ˜¯é€šè¿‡æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„æ¥è®¡ç®—çš„ï¼Œ
- en: \[ \sum_{j=1}^n \lambda_j C(\bf{u}_i,\bf{u}_j) = C(\bf{u},\bf{u}_i), \quad i=1,\ldots,n
    \]
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{j=1}^n \lambda_j C(\bf{u}_i,\bf{u}_j) = C(\bf{u},\bf{u}_i), \quad i=1,\ldots,n
    \]
- en: that may be represented with matrix notation as,
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥ç”¨çŸ©é˜µç¬¦å·è¡¨ç¤ºä¸ºï¼Œ
- en: \[\begin{split} \begin{bmatrix} C(\bf{u}_1,\bf{u}_1) & C(\bf{u}_1,\bf{u}_2)
    & \dots & C(\bf{u}_1,\bf{u}_n) \\ C(\bf{u}_2,\bf{u}_1) & C(\bf{u}_2,\bf{u}_2)
    & \dots & C(\bf{u}_2,\bf{u}_n) \\ \vdots & \vdots & \ddots & \vdots \\ C(\bf{u}_n,\bf{u}_1)
    & C(\bf{u}_n,\bf{u}_2) & \dots & C(\bf{u}_n,\bf{u}_n) \\ \end{bmatrix} \cdot \begin{bmatrix}
    \lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\ \end{bmatrix} = \begin{bmatrix}
    C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u}) \\ \vdots \\ C(\bf{u}_n,\bf{u}) \\ \end{bmatrix}
    \end{split}\]
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} C(\bf{u}_1,\bf{u}_1) & C(\bf{u}_1,\bf{u}_2)
    & \dots & C(\bf{u}_1,\bf{u}_n) \\ C(\bf{u}_2,\bf{u}_1) & C(\bf{u}_2,\bf{u}_2)
    & \dots & C(\bf{u}_2,\bf{u}_n) \\ \vdots & \vdots & \ddots & \vdots \\ C(\bf{u}_n,\bf{u}_1)
    & C(\bf{u}_n,\bf{u}_2) & \dots & C(\bf{u}_n,\bf{u}_n) \\ \end{bmatrix} \cdot \begin{bmatrix}
    \lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\ \end{bmatrix} = \begin{bmatrix}
    C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u}) \\ \vdots \\ C(\bf{u}_n,\bf{u}) \\ \end{bmatrix}
    \end{split}\]
- en: This system may be derived by substituting the equation for kriging estimates
    into the equation for estimation variance, and then setting the partial derivative
    with respect to the weights to zero.
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç³»ç»Ÿå¯ä»¥é€šè¿‡å°†å…‹é‡Œé‡‘ä¼°è®¡çš„æ–¹ç¨‹ä»£å…¥ä¼°è®¡æ–¹å·®çš„æ–¹ç¨‹ï¼Œç„¶åè®¾ç½®å…³äºæƒé‡çš„åå¯¼æ•°ä¸ºé›¶æ¥æ¨å¯¼å‡ºæ¥ã€‚
- en: we are optimizing the weights to minimize the estimation variance
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ä¼˜åŒ–æƒé‡ä»¥æœ€å°åŒ–ä¼°è®¡æ–¹å·®
- en: this system integrates the,
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç³»ç»Ÿé›†æˆäº†ï¼Œ
- en: '*spatial continuity* as quantified by the variogram (and covariance function
    to calculate the covariance, \(C\), values)'
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©ºé—´è¿ç»­æ€§*ï¼Œé€šè¿‡å˜å¼‚å‡½æ•°ï¼ˆä»¥åŠåæ–¹å·®å‡½æ•°æ¥è®¡ç®—åæ–¹å·®ï¼Œ\(C\)ï¼Œå€¼ï¼‰æ¥é‡åŒ–'
- en: '*redundancy* the degree of spatial continuity between all of the available
    data with themselves, \(C(\bf{u}_i,\bf{u}_j)\)'
  id: totrans-876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å†—ä½™*ï¼Œæ‰€æœ‰å¯ç”¨æ•°æ®ä¹‹é—´çš„ç©ºé—´è¿ç»­åº¦ï¼Œ\(C(\bf{u}_i,\bf{u}_j)\)'
- en: '*closeness* the degree of spatial continuity between the available data and
    the estimation location, \(C(\bf{u}_i,\bf{u})\)'
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é‚»è¿‘åº¦*ï¼Œå³å¯ç”¨æ•°æ®ä¸ä¼°è®¡ä½ç½®ä¹‹é—´çš„ç©ºé—´è¿ç»­åº¦ï¼Œ\(C(\bf{u}_i,\bf{u})\)'
- en: Kriging provides a measure of estimation accuracy known as kriging variance
    (a specific case of estimation variance).
  id: totrans-878
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹é‡Œé‡‘æä¾›äº†ä¸€ç§ç§°ä¸ºå…‹é‡Œé‡‘æ–¹å·®ï¼ˆä¼°è®¡æ–¹å·®çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼‰çš„ä¼°è®¡ç²¾åº¦åº¦é‡ã€‚
- en: \[ \sigma^{2}_{E}(\bf{u}) = C(0) - \sum^{n}_{\alpha = 1} \lambda_{\alpha} C(\bf{u}_0
    - \bf{u}_{\alpha}) \]
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma^{2}_{E}(\bf{u}) = C(0) - \sum^{n}_{\alpha = 1} \lambda_{\alpha} C(\bf{u}_0
    - \bf{u}_{\alpha}) \]
- en: Kriging estimates are best in that they minimize the above estimation variance.
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹é‡Œé‡‘ä¼°è®¡ä¹‹æ‰€ä»¥æœ€ä½³ï¼Œæ˜¯å› ä¸ºå®ƒä»¬æœ€å°åŒ–äº†ä¸Šè¿°ä¼°è®¡æ–¹å·®ã€‚
- en: Properties of kriging estimates include,
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹é‡Œé‡‘ä¼°è®¡çš„æ€§è´¨åŒ…æ‹¬ï¼Œ
- en: '*Exact interpolator* - kriging estimates with the data values at the data locations'
  id: totrans-882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç²¾ç¡®æ’å€¼å™¨* - åœ¨æ•°æ®ä½ç½®å¤„çš„æ•°æ®å€¼è¿›è¡Œå…‹é‡Œé‡‘ä¼°è®¡'
- en: '*Kriging variance* - a measure of uncertainty in a kriging estimate. Can be
    calculated before getting the sample information, as the kriging estimation variance
    is not dependent on the values of the data nor the kriging estimate, i.e. the
    kriging estimator is homoscedastic.'
  id: totrans-883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å…‹é‡Œé‡‘æ–¹å·®* - å…‹é‡Œé‡‘ä¼°è®¡ä¸­çš„ä¸ç¡®å®šæ€§åº¦é‡ã€‚åœ¨è·å–æ ·æœ¬ä¿¡æ¯ä¹‹å‰å°±å¯ä»¥è®¡ç®—ï¼Œå› ä¸ºå…‹é‡Œé‡‘ä¼°è®¡æ–¹å·®ä¸ä¾èµ–äºæ•°æ®çš„å€¼ä¹Ÿä¸ä¾èµ–äºå…‹é‡Œé‡‘ä¼°è®¡ï¼Œå³å…‹é‡Œé‡‘ä¼°è®¡é‡æ˜¯åŒæ–¹å·®é½æ¬¡çš„ã€‚'
- en: '*Spatial context* - kriging takes integrates spatial continuity, closeness
    and redundancy; therefore, kriging accounts for the configuration of the data
    and structural continuity of the feature being estimated.'
  id: totrans-884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©ºé—´ä¸Šä¸‹æ–‡* - å…‹é‡Œé‡‘ç»¼åˆäº†ç©ºé—´è¿ç»­æ€§ã€é‚»è¿‘åº¦å’Œå†—ä½™ï¼›å› æ­¤ï¼Œå…‹é‡Œé‡‘è€ƒè™‘äº†æ•°æ®çš„é…ç½®å’Œè¢«ä¼°è®¡ç‰¹å¾çš„è¿ç»­æ€§ç»“æ„ã€‚'
- en: '*Scale* - kriging by default assumes the estimate and data are at the same
    point support, i.e., mathematically represented as points in space with zero volume.
    Kriging may be generalized to account for the support volume of the data and estimate,'
  id: totrans-885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å°ºåº¦* - å…‹é‡Œé‡‘é»˜è®¤å‡è®¾ä¼°è®¡å’Œæ•°æ®ä½äºåŒä¸€æ”¯æ’‘ç‚¹ï¼Œå³æ•°å­¦ä¸Šè¡¨ç¤ºä¸ºç©ºé—´ä¸­é›¶ä½“ç§¯çš„ç‚¹ã€‚å…‹é‡Œé‡‘å¯ä»¥æ¨å¹¿ä»¥è€ƒè™‘æ•°æ®å’Œä¼°è®¡çš„æ”¯æ’‘ä½“ç§¯ï¼Œ'
- en: '*Multivariate* - kriging may be generalized to account for multiple secondary
    data in the spatial estimate with the cokriging system. We will cover this later.'
  id: totrans-886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šå…ƒ* - å…‹é‡Œé‡‘å¯ä»¥é€šè¿‡å…±å…‹é‡Œé‡‘ç³»ç»Ÿæ¨å¹¿ï¼Œä»¥è€ƒè™‘ç©ºé—´ä¼°è®¡ä¸­çš„å¤šä¸ªæ¬¡çº§æ•°æ®ã€‚æˆ‘ä»¬å°†åœ¨åé¢ä»‹ç»è¿™ä¸€ç‚¹ã€‚'
- en: '*Smoothing effect* - of kriging can be forecasted as the missing variance.
    The missing variance over local estimates is the kriging variance.'
  id: totrans-887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¹³æ»‘æ•ˆåº”* - å…‹é‡Œé‡‘çš„å¹³æ»‘æ•ˆåº”å¯ä»¥é¢„æµ‹ä¸ºç¼ºå¤±æ–¹å·®ã€‚å±€éƒ¨ä¼°è®¡çš„ç¼ºå¤±æ–¹å·®æ˜¯å…‹é‡Œé‡‘æ–¹å·®ã€‚'
- en: '**Kriging-based Declustering**'
  id: totrans-888
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå…‹é‡Œé‡‘çš„å»èšç±»**'
- en: 'Data Preparation: a declustering method to assign weights to spatial samples
    based on local sampling density, such that the weighted statistics are likely
    more representative of the population. Data weights are assigned so that,'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§åŸºäºå±€éƒ¨é‡‡æ ·å¯†åº¦çš„é™èšæ–¹æ³•ï¼Œä¸ºç©ºé—´æ ·æœ¬åˆ†é…æƒé‡ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚ä¸‹ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨ å¯†é‡‡æ ·åŒºåŸŸçš„æ ·æœ¬è·å¾—è¾ƒå°‘æƒé‡
- en: samples in sparsely sampled areas receive more weight
  id: totrans-891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨€ç–é‡‡æ ·åŒºåŸŸçš„æ ·æœ¬è·å¾—æ›´å¤šæƒé‡
- en: 'Kriging-based declustering proceeds as follows:'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºå…‹é‡Œé‡‘æ³•çš„é™èšè¿‡ç¨‹å¦‚ä¸‹ï¼š
- en: calculate and model the experimental variogram
  id: totrans-893
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—å¹¶å»ºæ¨¡å®éªŒå˜å¼‚å‡½æ•°
- en: apply kriging to calculate estimates over a high-resolution grid covering the
    area of interest
  id: totrans-894
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨è¦†ç›–æ„Ÿå…´è¶£åŒºåŸŸçš„é«˜åˆ†è¾¨ç‡ç½‘æ ¼ä¸Šåº”ç”¨å…‹é‡Œé‡‘æ³•è¿›è¡Œä¼°è®¡
- en: calculate the sum of the weights assigned to each data
  id: totrans-895
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—åˆ†é…ç»™æ¯ä¸ªæ•°æ®çš„æƒé‡æ€»å’Œ
- en: assign data weights proportional to this sum of weights
  id: totrans-896
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®æƒé‡åˆ†é…ä¸è¿™ä¸ªæƒé‡æ€»å’Œæˆæ¯”ä¾‹
- en: 'The weights are calculated as:'
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: æƒé‡è®¡ç®—å¦‚ä¸‹ï¼š
- en: \[ w(\bf{u}_j) = n \cdot \frac{\sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_j}{\sum_{i=1}^n
    \left[ \sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_{j,ix,iy} \right]} \]
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w(\bf{u}_j) = n \cdot \frac{\sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_j}{\sum_{i=1}^n
    \left[ \sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_{j,ix,iy} \right]} \]
- en: where \(nx\) and \(ny\) are the number of cells in the grid, \(n\) is the number
    of data, and \(\lambda_{j,ix,iy}\) is the weight assigned to the \(j\) data at
    the \(ix,iy\) grid cell.
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(nx\) å’Œ \(ny\) æ˜¯ç½‘æ ¼ä¸­çš„å•å…ƒæ ¼æ•°ï¼Œ\(n\) æ˜¯æ•°æ®æ•°é‡ï¼Œ\(\lambda_{j,ix,iy}\) æ˜¯åˆ†é…ç»™ \(ix,iy\)
    ç½‘æ ¼å•å…ƒæ ¼çš„ \(j\) æ•°æ®çš„æƒé‡ã€‚
- en: Here is an important point for kriging-based declustering,
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å…³äºåŸºäºå…‹é‡Œé‡‘æ³•çš„é™èšçš„ä¸€ä¸ªé‡è¦è§‚ç‚¹ï¼Œ
- en: like polygonal declustering, kriging-based declustering is sensitive to the
    boundaries of the area of interest; therefore, the weights assigned to the data
    near the boundary of the area of interest may change radically as the area of
    interest is expanded or contracted
  id: totrans-901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚å¤šè¾¹å½¢é™èšï¼ŒåŸºäºå…‹é‡Œé‡‘æ³•çš„é™èšå¯¹æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œæ•æ„Ÿï¼›å› æ­¤ï¼Œå½“æ„Ÿå…´è¶£åŒºåŸŸæ‰©å±•æˆ–æ”¶ç¼©æ—¶ï¼Œåˆ†é…ç»™æ„Ÿå…´è¶£åŒºåŸŸè¾¹ç•Œçš„æ•°æ®çš„æƒé‡å¯èƒ½ä¼šå‘ç”Ÿæ ¹æœ¬æ€§çš„å˜åŒ–
- en: Also, kriging-based declustering integrates the spatial continuity model from
    variogram model. Consider the following possible impacts of the variogram model
    on the declustering weights,
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼ŒåŸºäºå…‹é‡Œé‡‘æ³•çš„é™èšè¿˜æ•´åˆäº†å˜å¼‚å‡½æ•°æ¨¡å‹ä¸­çš„ç©ºé—´è¿ç»­æ€§æ¨¡å‹ã€‚è€ƒè™‘ä»¥ä¸‹å˜å¼‚å‡½æ•°æ¨¡å‹å¯¹é™èšæƒé‡çš„å½±å“ï¼Œ
- en: if there is 100% relative nugget effect, there is no spatial continuity and
    therefore, all data receives equal weight. Note for the equation above this results
    in a divide by 0.0 error that must be checked for in the code.
  id: totrans-903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæœ‰100%çš„ç›¸å¯¹å¼‚å¸¸å€¼æ•ˆåº”ï¼Œåˆ™æ²¡æœ‰ç©ºé—´è¿ç»­æ€§ï¼Œå› æ­¤ï¼Œæ‰€æœ‰æ•°æ®éƒ½è·å¾—ç›¸ç­‰çš„æƒé‡ã€‚æ³¨æ„ï¼Œä¸Šè¿°æ–¹ç¨‹ä¼šå¯¼è‡´é™¤ä»¥0.0çš„é”™è¯¯ï¼Œå¿…é¡»åœ¨ä»£ç ä¸­è¿›è¡Œæ£€æŸ¥ã€‚
- en: geometric anisotropy may significantly impact the weights as data aligned over
    specific azimuths are assessed as closer or further in terms of covariance
  id: totrans-904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡ ä½•å„å‘å¼‚æ€§å¯èƒ½ä¼šæ˜¾è‘—å½±å“æƒé‡ï¼Œå› ä¸ºæ²¿ç‰¹å®šæ–¹ä½å¯¹é½çš„æ•°æ®åœ¨åæ–¹å·®æ–¹é¢è¢«è§†ä¸ºæ›´è¿‘æˆ–æ›´è¿œ
- en: '**Kolmogorovâ€™s 3 Probability Axioms**'
  id: totrans-905
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŸ¯å°”è«å“¥æ´›å¤«çš„3ä¸ªæ¦‚ç‡å…¬ç†**'
- en: 'Probability Concepts: these are Kolmogorovâ€™s 3 axioms for valid probabilities,'
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ¦‚å¿µï¼šè¿™äº›æ˜¯æŸ¯å°”è«å“¥æ´›å¤«å¯¹æœ‰æ•ˆæ¦‚ç‡çš„3ä¸ªå…¬ç†ï¼Œ
- en: Probability of an event is a non-negative number.
  id: totrans-907
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡æ˜¯ä¸€ä¸ªéè´Ÿæ•°ã€‚
- en: \[ P(ğ´) \ge 0 \]
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(ğ´) \ge 0 \]
- en: Probability of the entire sample space, all possible outcomes, \(\Omega\), is
    one (unity), also known as probability closure.
  id: totrans-909
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•´ä¸ªæ ·æœ¬ç©ºé—´ï¼Œæ‰€æœ‰å¯èƒ½ç»“æœçš„æ¦‚ç‡ï¼Œ\(\Omega\)ï¼Œä¸º1ï¼ˆå•ä½ï¼‰ï¼Œä¹Ÿç§°ä¸ºæ¦‚ç‡å°é—­ã€‚
- en: \[ P(\Omega) = 1 \]
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\Omega) = 1 \]
- en: Additivity of mutually exclusive events for unions.
  id: totrans-911
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº’æ–¥äº‹ä»¶çš„å¹¶é›†çš„å¯åŠ æ€§ã€‚
- en: \[ P\left(â‹ƒ_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \]
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P\left(â‹ƒ_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \]
- en: e.g., probability of \(A_1\) and \(A_2\) mutual exclusive events is, \(P(A_1
    + A_2) = P(A_1) + P(A_2)\)
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œäº’æ–¥äº‹ä»¶ \(A_1\) å’Œ \(A_2\) çš„æ¦‚ç‡æ˜¯ï¼Œ\(P(A_1 + A_2) = P(A_1) + P(A_2)\)
- en: '**\(L^1\) Norm**'
  id: totrans-914
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^1\) èŒƒæ•°**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): known as Manhattan
    norm or sum of absolute residual (SAR),'
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šç§°ä¸ºæ›¼å“ˆé¡¿èŒƒæ•°æˆ–ç»å¯¹æ®‹å·®ä¹‹å’Œï¼ˆSARï¼‰ï¼Œ'
- en: \[ \sum_{i=1}^n |\Delta y_i | \]
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n |\Delta y_i | \]
- en: also expressed as the mean absolute error (MAE),
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè¡¨ç¤ºä¸ºå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€‚
- en: \[ \frac{1}{n} \sum_{i=1}^n |\Delta y_i | \]
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n |\Delta y_i | \]
- en: Minimization with \(L^1\) norm is known as minimum absolute difference.
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(L^1\) èŒƒæ•°è¿›è¡Œæœ€å°åŒ–ç§°ä¸ºæœ€å°ç»å¯¹å·®å¼‚ã€‚
- en: '**\(L^2\) Norm**'
  id: totrans-920
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^2\) èŒƒæ•°**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): known as sum of
    square residual (SSR),'
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šç§°ä¸ºå¹³æ–¹æ®‹å·®ä¹‹å’Œï¼ˆSSRï¼‰ï¼Œ'
- en: \[ \sum_{i=1}^n \sqrt{\Delta y_i} \]
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \sqrt{\Delta y_i} \]
- en: also expressed as the mean square error (MSE),
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè¡¨ç¤ºä¸ºå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œ
- en: \[ \frac{1}{n} \sum_{i=1}^n \left( \Delta y_i \right)^2 \]
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n \left( \Delta y_i \right)^2 \]
- en: and the Euclidian norm,
  id: totrans-925
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠæ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼Œ
- en: \[ \sqrt{ \sum_{i=1}^n \sqrt{\Delta y_i} } \]
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sqrt{ \sum_{i=1}^n \sqrt{\Delta y_i} } \]
- en: Minimization with \(L^2\) norm is known as the method of least squares.
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(L^2\) èŒƒæ•°è¿›è¡Œæœ€å°åŒ–è¢«ç§°ä¸ºæœ€å°äºŒä¹˜æ³•ã€‚
- en: '**\(L^1\) vs. \(L^2\) Norm**'
  id: totrans-928
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^1\) ä¸ \(L^2\) èŒƒæ•°**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): the choice of \(L^1\)
    and \(L^2\) norm is important in machine learning. To explain this letâ€™s compare
    the performance of \(L^1\) and \(L^2\) norms in loss functions while training
    model parameters.'
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œ\(L^1\) å’Œ \(L^2\)
    èŒƒæ•°çš„é€‰å–éå¸¸é‡è¦ã€‚ä¸ºäº†è§£é‡Šè¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒåœ¨è®­ç»ƒæ¨¡å‹å‚æ•°æ—¶ \(L^1\) å’Œ \(L^2\) èŒƒæ•°åœ¨æŸå¤±å‡½æ•°ä¸­çš„æ€§èƒ½ã€‚'
- en: '| Property | Least Absolute Deviations (L1) | Least Squares (L2) |'
  id: totrans-930
  prefs: []
  type: TYPE_TB
  zh: '| å±æ€§ | æœ€å°ç»å¯¹åå·®ï¼ˆL1ï¼‰ | æœ€å°äºŒä¹˜ï¼ˆL2ï¼‰ |'
- en: '| --- | --- | --- |'
  id: totrans-931
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Robustness* | Robust | Not very robust |'
  id: totrans-932
  prefs: []
  type: TYPE_TB
  zh: '| é²æ£’æ€§* | é²æ£’ | ä¸å¤ªé²æ£’ |'
- en: '| Solution Stability | Unstable solution | Stable solution |'
  id: totrans-933
  prefs: []
  type: TYPE_TB
  zh: '| è§£çš„ç¨³å®šæ€§ | ä¸ç¨³å®šè§£ | ç¨³å®šè§£ |'
- en: '| Number of Solutions | Possibly multiple solutions | Always one solution |'
  id: totrans-934
  prefs: []
  type: TYPE_TB
  zh: '| è§£çš„æ•°é‡ | å¯èƒ½å­˜åœ¨å¤šä¸ªè§£ | æ€»æ˜¯æœ‰ä¸€ä¸ªè§£ |'
- en: '| Feature Selection | Built-in feature selection | No feature selection |'
  id: totrans-935
  prefs: []
  type: TYPE_TB
  zh: '| ç‰¹å¾é€‰æ‹© | å†…ç½®ç‰¹å¾é€‰æ‹© | æ— ç‰¹å¾é€‰æ‹© |'
- en: '| Output Sparsity | Sparse outputs | Non-sparse outputs |'
  id: totrans-936
  prefs: []
  type: TYPE_TB
  zh: '| è¾“å‡ºç¨€ç–æ€§ | ç¨€ç–è¾“å‡º | éç¨€ç–è¾“å‡º |'
- en: '| Analytical Solutions | No analytical solutions | Analytical solutions |'
  id: totrans-937
  prefs: []
  type: TYPE_TB
  zh: '| è§£çš„è§£ææ€§ | æ— è§£æè§£ | è§£æè§£ |'
- en: Hereâ€™s some important points,
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›é‡è¦çš„è§‚ç‚¹ï¼Œ
- en: '*robust* - resistant to outliers'
  id: totrans-939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é²æ£’æ€§* - å¯¹å¼‚å¸¸å€¼æœ‰æŠµæŠ—åŠ›'
- en: '*unstable* - for small changes in training the trained model predictions may
    jump'
  id: totrans-940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ä¸ç¨³å®š* - å¯¹äºè®­ç»ƒçš„å°å˜åŒ–ï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹å¯èƒ½ä¼šè·³è·ƒ'
- en: '*multiple solutions* - different solution have similar or the same loss, resulting
    in solutions jumping with small changes to the training data'
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šä¸ªè§£* - ä¸åŒçš„è§£å…·æœ‰ç›¸ä¼¼æˆ–ç›¸åŒçš„æŸå¤±ï¼Œå¯¼è‡´è§£åœ¨è®­ç»ƒæ•°æ®çš„å°å˜åŒ–ä¸‹è·³è·ƒ'
- en: '*output sparsity* and *feature selection* - model parameters tend to 0.0'
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¾“å‡ºç¨€ç–æ€§* å’Œ *ç‰¹å¾é€‰æ‹©* - æ¨¡å‹å‚æ•°è¶‹å‘äº 0.0'
- en: '*analytical solutions* - an analytical solution is available to solve for the
    optimum model parameters'
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è§£æè§£* - å­˜åœ¨è§£æè§£ä»¥æ±‚è§£æœ€ä¼˜æ¨¡å‹å‚æ•°'
- en: '**\(L^1\) or \(L^2\) Normalizer**'
  id: totrans-944
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^1\) æˆ– \(L^2\) æ­£åˆ™åŒ–å™¨**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): is
    performed across features over individual samples to constrain the sum'
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šåœ¨å•ä¸ªæ ·æœ¬çš„ç‰¹å¾é—´æ‰§è¡Œä»¥çº¦æŸæ€»å’Œ'
- en: The L1 Norm has the following constraint across samples,
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: L1 èŒƒæ•°åœ¨æ ·æœ¬é—´æœ‰ä»¥ä¸‹çº¦æŸï¼Œ
- en: \[ \sum_{\alpha = 1}^m x^{\prime}_{i,\alpha} = 1.0, \quad i = 1, \ldots, n \]
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{\alpha = 1}^m x^{\prime}_{i,\alpha} = 1.0, \quad i = 1, \ldots, n \]
- en: The L1 normalizer transform,
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: L1 æ­£åˆ™åŒ–å™¨å˜æ¢ï¼Œ
- en: \[ x^{\prime}_{i,\alpha} = \frac{x_{i,\alpha}}{\sum_{\alpha=1}^m x_{i,\alpha}}
    \]
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x^{\prime}_{i,\alpha} = \frac{x_{i,\alpha}}{\sum_{\alpha=1}^m x_{i,\alpha}}
    \]
- en: The L2 Norm has the following constraint across samples,
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: L2 èŒƒæ•°åœ¨æ ·æœ¬é—´æœ‰ä»¥ä¸‹çº¦æŸï¼Œ
- en: \[ \sum_{\alpha = 1}^m \left( x^{\prime}_{i,\alpha} \right)^2 = 1.0, \quad i
    = 1, \ldots, n \]
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{\alpha = 1}^m \left( x^{\prime}_{i,\alpha} \right)^2 = 1.0, \quad i
    = 1, \ldots, n \]
- en: The L2 normalizer transform,
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: L2 æ­£åˆ™åŒ–å™¨å˜æ¢ï¼Œ
- en: \[ x^{\prime}_{i,\alpha} = \sqrt{\frac{(x_{i,\alpha})^2}{\sum_{\alpha=1}^m (x_{i,\alpha})^2}}
    \]
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x^{\prime}_{i,\alpha} = \sqrt{\frac{(x_{i,\alpha})^2}{\sum_{\alpha=1}^m (x_{i,\alpha})^2}}
    \]
- en: Example, applied in text classification and clustering, and L1 for compositional
    data (sum 1.0 constraint)
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåº”ç”¨äºæ–‡æœ¬åˆ†ç±»å’Œèšç±»ï¼Œä»¥åŠ L1 ç”¨äºç»„åˆæ•°æ®ï¼ˆæ€»å’Œ 1.0 çº¦æŸï¼‰
- en: '**LASSO Regression**'
  id: totrans-955
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**LASSO å›å½’**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): linear regression
    with \(L^1\) regularization term and regularization hyperparameter \(\lambda\),'
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šå…·æœ‰ \(L^1\) æ­£åˆ™åŒ–é¡¹å’Œæ­£åˆ™åŒ–è¶…å‚æ•° \(\lambda\)
    çš„çº¿æ€§å›å½’ï¼Œ'
- en: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
- en: As a result, LASSO regression training integrates two and often competing goals
    to find the model parameters,
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒLASSO å›å½’è®­ç»ƒé›†æˆäº†ä¸¤ä¸ªç»å¸¸ç›¸äº’ç«äº‰çš„ç›®æ ‡æ¥å¯»æ‰¾æ¨¡å‹å‚æ•°ï¼Œ
- en: find the model parameters that minimize the error with training data
  id: totrans-959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾ä½¿è®­ç»ƒæ•°æ®è¯¯å·®æœ€å°çš„æ¨¡å‹å‚æ•°
- en: minimize the slope parameters towards zero
  id: totrans-960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å°åŒ–æ–œç‡å‚æ•°è¶‹å‘äºé›¶
- en: 'The only difference between LASSO and ridge regression is:'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: LASSO å’Œå²­å›å½’ä¹‹é—´çš„å”¯ä¸€åŒºåˆ«æ˜¯ï¼š
- en: for LASSO the shrinkage term is posed as an \(\ell_1\) penalty,
  id: totrans-962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äº LASSOï¼Œæ”¶ç¼©é¡¹è¢«è¡¨ç¤ºä¸º \(\ell_1\) æƒ©ç½šé¡¹ï¼Œ
- en: \[ \lambda \sum_{\alpha=1}^m |b_{\alpha}| \]
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda \sum_{\alpha=1}^m |b_{\alpha}| \]
- en: for ridge regression the shrinkage term is posed as an \(\ell_2\) penalty,
  id: totrans-964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºå²­å›å½’ï¼Œæ”¶ç¼©é¡¹è¢«è¡¨ç¤ºä¸º \(\ell_2\) æƒ©ç½šï¼Œ
- en: \[ \lambda \sum_{\alpha=1}^m \left(b_{\alpha}\right)^2 \]
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda \sum_{\alpha=1}^m \left(b_{\alpha}\right)^2 \]
- en: 'While both ridge regression and the LASSO shrink the model parameters (\(b_{\alpha},
    \alpha = 1,\ldots,m\)) towards zero:'
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å²­å›å½’å’ŒLASSOéƒ½å°†æ¨¡å‹å‚æ•° (\(b_{\alpha}, \alpha = 1,\ldots,m\)) æ”¶ç¼©åˆ°é›¶ï¼š
- en: LASSO parameters reach zero at different rates for each predictor feature as
    the lambda, \(\lambda\), hyperparameter increases.
  id: totrans-967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€lambdaï¼Œ\(\lambda\) è¶…å‚æ•°çš„å¢åŠ ï¼ŒLASSOå‚æ•°ä»¥ä¸åŒçš„é€Ÿç‡è¾¾åˆ°é›¶ã€‚
- en: as a result LASSO provides a method for feature ranking and selection!
  id: totrans-968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒLASSOæä¾›äº†ä¸€ç§ç‰¹å¾æ’åºå’Œé€‰æ‹©çš„æ–¹æ³•ï¼
- en: The lambda, \(\lambda\), hyperparameter controls the degree of fit of the model
    and may be related to the model bias-variance trade-off.
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: lambdaï¼Œ\(\lambda\) è¶…å‚æ•°æ§åˆ¶æ¨¡å‹çš„æ‹Ÿåˆç¨‹åº¦ï¼Œå¯èƒ½ä¸æ¨¡å‹åå·®-æ–¹å·®æƒè¡¡æœ‰å…³ã€‚
- en: for \(\lambda \rightarrow 0\) the prediction model approaches linear regression,
    there is lower model bias, but the model variance is higher
  id: totrans-970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(\lambda \rightarrow 0\) æ—¶ï¼Œé¢„æµ‹æ¨¡å‹è¶‹è¿‘äºçº¿æ€§å›å½’ï¼Œæ¨¡å‹åå·®è¾ƒä½ï¼Œä½†æ¨¡å‹æ–¹å·®è¾ƒé«˜
- en: as \(\lambda\) increases the model variance decreases and the model bias increases
  id: totrans-971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€ \(\lambda\) çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®é™ä½ï¼Œæ¨¡å‹åå·®å¢åŠ 
- en: for \(\lambda \rightarrow \infty\) the coefficients all become 0.0 and the model
    is the training data response feature mean
  id: totrans-972
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(\lambda \rightarrow \infty\) æ—¶ï¼Œæ‰€æœ‰ç³»æ•°éƒ½å˜ä¸º 0.0ï¼Œæ¨¡å‹æ˜¯è®­ç»ƒæ•°æ®å“åº”ç‰¹å¾å‡å€¼
- en: '**Lazy Learning**'
  id: totrans-973
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ‡’æƒ°å­¦ä¹ **'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): model is
    a generalization of the training data and calculation is delayed until query is
    made of the model'
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šæ¨¡å‹æ˜¯è®­ç»ƒæ•°æ®çš„æ³›åŒ–ï¼Œè®¡ç®—åœ¨æŸ¥è¯¢æ¨¡å‹æ—¶æ‰è¿›è¡Œ'
- en: the model is the training data and selected hyperparameters, to make new predictions
    the training data must be available
  id: totrans-975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ˜¯è®­ç»ƒæ•°æ®å’Œé€‰å®šçš„è¶…å‚æ•°ï¼Œè¦åšå‡ºæ–°çš„é¢„æµ‹ï¼Œå¿…é¡»æä¾›è®­ç»ƒæ•°æ®
- en: The opposite is eager learning.
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åçš„æ˜¯ç§¯æå­¦ä¹ ã€‚
- en: '**Learning Rate** (gradient boosting)'
  id: totrans-977
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å­¦ä¹ ç‡** (æ¢¯åº¦æå‡)'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): controls the rate
    of updating with each new model.'
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šæ§åˆ¶æ¯æ¬¡æ–°æ¨¡å‹æ›´æ–°çš„é€Ÿç‡ã€‚'
- en: \[ f_m = f_{m-1} - \rho_m \frac{\partial L(y_\alpha, F(X_\alpha))}{\partial
    F(X_\alpha)} \]
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f_m = f_{m-1} - \rho_m \frac{\partial L(y_\alpha, F(X_\alpha))}{\partial
    F(X_\alpha)} \]
- en: where \(\rho_m\) is the learning rate, \frac{\partial L(y_\alpha, F(X_\alpha))}{\partial
    F(X_\alpha)} is the gradient, error, \(f_{m-1}\) is the previous estimate, and
    \(f_m\) is the new estimate.
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\rho_m\) æ˜¯å­¦ä¹ ç‡ï¼Œ\(\frac{\partial L(y_\alpha, F(X_\alpha))}{\partial F(X_\alpha)}\)
    æ˜¯æ¢¯åº¦ï¼Œè¯¯å·®ï¼Œ\(f_{m-1}\) æ˜¯å‰ä¸€ä¸ªä¼°è®¡ï¼Œ\(f_m\) æ˜¯æ–°çš„ä¼°è®¡ã€‚
- en: Some salient points about learning rate,
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå­¦ä¹ ç‡çš„ä¸€äº›æ˜¾è‘—ç‚¹ï¼Œ
- en: without learning rate, the boosting models learn too quickly and will have too
    high model variance
  id: totrans-982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å­¦ä¹ ç‡ï¼Œæå‡æ¨¡å‹å­¦ä¹ å¾—å¤ªå¿«ï¼Œæ¨¡å‹æ–¹å·®ä¼šå¾ˆé«˜
- en: slow down learning for a more robust model, balanced to ensure good performance,
    too small rate will require very large number of models to reach convergence
  id: totrans-983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡æ…¢å­¦ä¹ ä»¥è·å¾—æ›´ç¨³å¥çš„æ¨¡å‹ï¼Œå¹³è¡¡ä»¥ç¡®ä¿è‰¯å¥½çš„æ€§èƒ½ï¼Œè¿‡å°çš„é€Ÿç‡å°†éœ€è¦éå¸¸å¤§çš„æ¨¡å‹æ•°é‡æ‰èƒ½è¾¾åˆ°æ”¶æ•›
- en: '**Likewise Deletion** (MRMR)'
  id: totrans-984
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŒæ ·åˆ é™¤** (MRMR)'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): removal of any sample
    with any missing feature values'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šç§»é™¤ä»»ä½•å…·æœ‰ä»»ä½•ç¼ºå¤±ç‰¹å¾å€¼çš„æ ·æœ¬'
- en: if missing feature values are not missing at random (MAR) this may impart a
    bias in the data
  id: totrans-986
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœç¼ºå¤±çš„ç‰¹å¾å€¼ä¸æ˜¯éšæœºç¼ºå¤± (MAR)ï¼Œè¿™å¯èƒ½ä¼šåœ¨æ•°æ®ä¸­å¼•å…¥åå·®
- en: will result in a decrease in the effective data size and increase in model uncertainty
  id: totrans-987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å¯¼è‡´æœ‰æ•ˆæ•°æ®é‡å‡å°‘å’Œæ¨¡å‹ä¸ç¡®å®šæ€§å¢åŠ 
- en: '**Linear Regression**'
  id: totrans-988
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çº¿æ€§å›å½’**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): a linear, parametric
    prediction model,'
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šä¸€ä¸ªçº¿æ€§ã€å‚æ•°åŒ–çš„é¢„æµ‹æ¨¡å‹ï¼Œ'
- en: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
- en: The analytical solution for the model parameters, \(b_1,\ldots,b_m,b_0\), is
    available for the L2 norm loss function, the errors are summed and squared known
    a least squares.
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºL2èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œæ¨¡å‹å‚æ•° \(b_1,\ldots,b_m,b_0\) çš„è§£æè§£æ˜¯å¯ç”¨çš„ï¼Œè¯¯å·®æ˜¯æ±‚å’Œå¹¶å¹³æ–¹çš„å·²çŸ¥æœ€å°äºŒä¹˜æ³•ã€‚
- en: 'we minimize the error, residual sum of squares (RSS) over the training data:'
  id: totrans-992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®ä¸Šæœ€å°åŒ–è¯¯å·®ï¼Œæ®‹å·®å¹³æ–¹å’Œ (RSS)ï¼š
- en: \[ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0) \right)^2 \]
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
  zh: \[ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0) \right)^2 \]
- en: where \(y_i\) is the actual response feature values and \(\sum_{\alpha = 1}^m
    b_{\alpha} x_{\alpha} + b_0\) are the model predictions, over the \(\alpha = 1,\ldots,n\)
    training data.
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(y_i\) æ˜¯å®é™…å“åº”ç‰¹å¾å€¼ï¼Œ\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\) æ˜¯æ¨¡å‹é¢„æµ‹ï¼Œåœ¨
    \(\alpha = 1,\ldots,n\) çš„è®­ç»ƒæ•°æ®ä¸Šã€‚
- en: this may be simplified as the sum of square error over the training data,
  id: totrans-995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥ç®€åŒ–ä¸ºè®­ç»ƒæ•°æ®ä¸Šçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼Œ
- en: \[ \sum_{i=1}^n (\Delta y_i)^2 \]
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n (\Delta y_i)^2 \]
- en: where \(\Delta y_i\) is actual response feature observation \(y_i\) minus the
    model prediction \(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\), over the
    \(i = 1,\ldots,n\) training data.
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\Delta y_i\) æ˜¯å®é™…å“åº”ç‰¹å¾è§‚å¯Ÿ \(y_i\) å‡å»æ¨¡å‹é¢„æµ‹ \(\sum_{\alpha = 1}^m b_{\alpha}
    x_{\alpha} + b_0\)ï¼Œåœ¨ \(i = 1,\ldots,n\) çš„è®­ç»ƒæ•°æ®ä¸Šã€‚
- en: There are important assumption with our linear regression model,
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„çº¿æ€§å›å½’æ¨¡å‹æœ‰ä¸€äº›é‡è¦çš„å‡è®¾ï¼Œ
- en: '*Error-free* - predictor variables are error free, not random variables'
  id: totrans-999
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— è¯¯å·®* - é¢„æµ‹å˜é‡æ— è¯¯å·®ï¼Œä¸æ˜¯éšæœºå˜é‡'
- en: '*Linearity* - response is linear combination of feature(s)'
  id: totrans-1000
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*çº¿æ€§æ€§* - å“åº”æ˜¯ç‰¹å¾ï¼ˆsï¼‰çš„çº¿æ€§ç»„åˆ'
- en: '*Constant Variance* - error in response is constant over predictor(s) value'
  id: totrans-1001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¸¸æ•°æ–¹å·®* - å“åº”è¯¯å·®åœ¨é¢„æµ‹å€¼ä¸Šæ˜¯æ’å®šçš„'
- en: '*Independence of Error* - error in response are uncorrelated with each other'
  id: totrans-1002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¯¯å·®ç‹¬ç«‹æ€§* - å“åº”è¯¯å·®ä¹‹é—´ç›¸äº’ä¸ç›¸å…³'
- en: '*No multicollinearity* - none of the features are redundant with other features'
  id: totrans-1003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— å¤šé‡å…±çº¿æ€§* - æ²¡æœ‰ç‰¹å¾ä¸å…¶ä»–ç‰¹å¾å†—ä½™'
- en: '**Location Map**'
  id: totrans-1004
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä½ç½®å›¾**'
- en: '[Loading and Plotting Data and Models](MachineLearning_plotting_data_models.html):
    a data plot where the 2 axes are locations, e.g., \(X\) and \(Y\), Easting and
    Northing, Latitude and Longitude, etc., to show the locations and magnitudes of
    the spatial data.'
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŠ è½½æ•°æ®å’Œç»˜å›¾æ¨¡å‹](MachineLearning_plotting_data_models.html)ï¼šä¸€ä¸ªæ•°æ®å›¾ï¼Œå…¶ä¸­ä¸¤ä¸ªè½´æ˜¯ä½ç½®ï¼Œä¾‹å¦‚ \(X\)
    å’Œ \(Y\)ï¼Œä¸œè¥¿æ–¹å‘å’Œå—åŒ—æ–¹å‘ï¼Œçº¬åº¦å’Œç»åº¦ç­‰ï¼Œä»¥æ˜¾ç¤ºç©ºé—´æ•°æ®çš„ä½ç½®å’Œå¤§å°ã€‚'
- en: often the data points are colored to represent the scale of feature to visualize
    the sampled feature over the area or volume of interest
  id: totrans-1006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸æ•°æ®ç‚¹ä¼šè¢«ç€è‰²ä»¥è¡¨ç¤ºç‰¹å¾çš„æ¯”ä¾‹ï¼Œä»¥å¯è§†åŒ–æ„Ÿå…´è¶£åŒºåŸŸæˆ–ä½“ç§¯ä¸Šçš„é‡‡æ ·ç‰¹å¾
- en: advantage, visualize the data without any model that may bias our impression
    of the data
  id: totrans-1007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼Œå¯ä»¥å¯è§†åŒ–æ•°æ®ï¼Œè€Œæ— éœ€ä»»ä½•å¯èƒ½å½±å“æˆ‘ä»¬å¯¹æ•°æ®å°è±¡çš„æ¨¡å‹
- en: disadvantage, may be difficult to visualize large datasets and data in 3D
  id: totrans-1008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼Œå¯èƒ½éš¾ä»¥å¯è§†åŒ–å¤§å‹æ•°æ®é›†å’Œä¸‰ç»´æ•°æ®
- en: '**Loss Function**'
  id: totrans-1009
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŸå¤±å‡½æ•°**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): the equation that
    is minimized to train the model parameters. For example, the loss function for
    linear regression includes residual sum of square, the \(L^2\) error norm,'
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šç”¨äºè®­ç»ƒæ¨¡å‹å‚æ•°çš„æœ€å°åŒ–æ–¹ç¨‹ã€‚ä¾‹å¦‚ï¼Œçº¿æ€§å›å½’çš„æŸå¤±å‡½æ•°åŒ…æ‹¬æ®‹å·®å¹³æ–¹å’Œã€\(L^2\)
    é”™è¯¯èŒƒæ•°ï¼Œ'
- en: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 \]
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 \]
- en: for LASSO regression the loss function includes residual sum of square, the
    \(L^2\) error norm, plus a \(L^1\) regularization term,
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºLASSOå›å½’ï¼ŒæŸå¤±å‡½æ•°åŒ…æ‹¬æ®‹å·®å¹³æ–¹å’Œã€\(L^2\) é”™è¯¯èŒƒæ•°ï¼ŒåŠ ä¸Š \(L^1\) æ­£åˆ™åŒ–é¡¹ï¼Œ
- en: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
  id: totrans-1013
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
- en: for k-means clustering the loss function is,
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºk-meansèšç±»ï¼ŒæŸå¤±å‡½æ•°æ˜¯ï¼Œ
- en: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} \sqrt{ \sum_{j = 1}^m X_{\alpha,m}
    - \mu_{i,m} } \]
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} \sqrt{ \sum_{j = 1}^m X_{\alpha,m}
    - \mu_{i,m} } \]
- en: The method to minimize loss functions depends on the type of norm,
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å°åŒ–æŸå¤±å‡½æ•°çš„æ–¹æ³•å–å†³äºèŒƒæ•°çš„ç±»å‹ï¼Œ
- en: with \(L^2\) norms we apply differentiation to the loss function with respect
    to the model parameter and set it equal to zero
  id: totrans-1017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ \(L^2\) èŒƒæ•°ä¸‹ï¼Œæˆ‘ä»¬å¯¹æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å‚æ•°è¿›è¡Œå¾®åˆ†ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºç­‰äºé›¶
- en: with \(L^1\) norms in our loss functions we lose access to an analytical solution
    and use iterative optimization, e.g., steepest descent
  id: totrans-1018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨ \(L^1\) èŒƒæ•°æ—¶ï¼Œæˆ‘ä»¬å¤±å»äº†è®¿é—®è§£æè§£ï¼Œå¹¶ä½¿ç”¨è¿­ä»£ä¼˜åŒ–ï¼Œä¾‹å¦‚æœ€é€Ÿä¸‹é™æ³•
- en: '**Machine Learning Workflow Design**'
  id: totrans-1019
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹è®¾è®¡**'
- en: 'Machine Learning Workflow Construction and Coding: is based on the following
    steps,'
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šåŸºäºä»¥ä¸‹æ­¥éª¤ï¼Œ
- en: '*Specify the Goals* - for example,'
  id: totrans-1021
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æŒ‡å®šç›®æ ‡* - ä¾‹å¦‚ï¼Œ'
- en: build a numerical model
  id: totrans-1022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å»ºç«‹æ•°å€¼æ¨¡å‹
- en: evaluate different recovery processes
  id: totrans-1023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯„ä¼°ä¸åŒçš„æ¢å¤è¿‡ç¨‹
- en: '*Specify the Data* - what is available and what is missing?'
  id: totrans-1024
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æŒ‡å®šæ•°æ®* - å¯ç”¨çš„æ˜¯ä»€ä¹ˆï¼Œç¼ºå°‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ'
- en: '*Design a Set of Steps to Accomplish the Goal* - common steps include,'
  id: totrans-1025
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®¾è®¡ä¸€ç»„æ­¥éª¤ä»¥å®ç°ç›®æ ‡* - å¸¸è§æ­¥éª¤åŒ…æ‹¬ï¼Œ'
- en: load data
  id: totrans-1026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®
- en: format, check and clean data
  id: totrans-1027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¼å¼åŒ–ã€æ£€æŸ¥å’Œæ¸…ç†æ•°æ®
- en: run operation, including, statistical calculation, model or visualization
  id: totrans-1028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿è¡Œæ“ä½œï¼ŒåŒ…æ‹¬ç»Ÿè®¡è®¡ç®—ã€æ¨¡å‹æˆ–å¯è§†åŒ–
- en: transfer function
  id: totrans-1029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ é€’å‡½æ•°
- en: '*Develop Documentation* - including implementation details, defense of decisions,
    metadata, limitations and future work'
  id: totrans-1030
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¼€å‘æ–‡æ¡£* - åŒ…æ‹¬å®ç°ç»†èŠ‚ã€å†³ç­–çš„è¾©æŠ¤ã€å…ƒæ•°æ®ã€é™åˆ¶å’Œæœªæ¥å·¥ä½œ'
- en: '*Flow* - data and information flow, learning while modeling with branches and
    loop backs'
  id: totrans-1031
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æµç¨‹* - æ•°æ®å’Œä¿¡æ¯æµï¼Œé€šè¿‡åˆ†æ”¯å’Œå›ç¯å»ºæ¨¡æ—¶çš„å­¦ä¹ '
- en: '*Uncertainty* - summarize all uncertainty sources, include methods to integrate
    uncertainty, defend the uncertainty models and aspects deemed certain'
  id: totrans-1032
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸ç¡®å®šæ€§* - æ€»ç»“æ‰€æœ‰ä¸ç¡®å®šæ€§æ¥æºï¼ŒåŒ…æ‹¬é›†æˆä¸ç¡®å®šæ€§çš„æ–¹æ³•ï¼Œæå«è¢«è®¤ä¸ºç¡®å®šçš„ä¸ç¡®å®šæ€§æ¨¡å‹å’Œæ–¹é¢'
- en: '**Margin** (support vector machines)'
  id: totrans-1033
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¾¹ç¼˜** (æ”¯æŒå‘é‡æœº)'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): when
    the training data include overlapping categories it would not be possible, nor
    desirable, to develop a decision boundary that perfectly separates the categories
    for which this condition would hold,'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šå½“è®­ç»ƒæ•°æ®åŒ…æ‹¬é‡å ç±»åˆ«æ—¶ï¼Œä¸å¯èƒ½ä¹Ÿä¸å¸Œæœ›å¼€å‘ä¸€ä¸ªå®Œç¾åˆ†ç¦»è¿™äº›ç±»åˆ«çš„å†³ç­–è¾¹ç•Œï¼Œè¿™äº›ç±»åˆ«å°†æ»¡è¶³æ­¤æ¡ä»¶ï¼Œ'
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
- en: We need a model that allows for some misclassification.
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå…è®¸æŸäº›è¯¯åˆ†ç±»çš„æ¨¡å‹ã€‚
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
- en: We introduce the concept of a margin, \(ğ‘€\), and a distance from the margin
    (error, ğœ‰_ğ‘–).
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼•å…¥äº†è¾¹ç¼˜çš„æ¦‚å¿µ \(ğ‘€\) å’Œè¾¹ç¼˜è·ç¦»ï¼ˆè¯¯å·®ï¼Œ\(ğœ‰_ğ‘–\)ï¼‰ã€‚
- en: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
- en: The loss function includes the margin term, \(M\), and hence attempts to minimize
    margin while minimizing classification error weighted by hyperparameter, \(C\).
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°åŒ…æ‹¬è¾¹ç¼˜é¡¹ \(M\)ï¼Œå› æ­¤è¯•å›¾åœ¨æœ€å°åŒ–åˆ†ç±»é”™è¯¯çš„åŒæ—¶æœ€å°åŒ–è¾¹ç¼˜ï¼Œåˆ†ç±»é”™è¯¯ç”±è¶…å‚æ•° \(C\) åŠ æƒã€‚
- en: '**Marginal Probability**'
  id: totrans-1041
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¾¹ç¼˜æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): probability that
    considers only one event occurring, the probability of \(A\),'
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåªè€ƒè™‘ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ï¼Œå³ \(A\) çš„æ¦‚ç‡ï¼Œ'
- en: \[ P(A) \]
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) \]
- en: marginal probabilities may be calculated from joint probabilities through the
    process of marginalization,
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: è¾¹ç¼˜æ¦‚ç‡å¯ä»¥é€šè¿‡è¾¹ç¼˜åŒ–è¿‡ç¨‹ä»è”åˆæ¦‚ç‡ä¸­è®¡ç®—å¾—å‡ºï¼Œ
- en: \[ P(A) = \int_{-\infty}^{\infty} P(A,B) dB \]
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) = \int_{-\infty}^{\infty} P(A,B) dB \]
- en: where we integrate over all cases of the other event, \(B\), to remove its influence.
    Given discrete possible cases of event \(B\) we can simply sum the probabilities
    over all possible cases of \(B\),
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­æˆ‘ä»¬æ•´åˆå…¶ä»–äº‹ä»¶ \(B\) çš„æ‰€æœ‰æƒ…å†µï¼Œä»¥æ¶ˆé™¤å…¶å½±å“ã€‚å¯¹äºäº‹ä»¶ \(B\) çš„ç¦»æ•£å¯èƒ½æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°å¯¹æ‰€æœ‰å¯èƒ½çš„ \(B\) çš„æƒ…å†µæ±‚å’Œï¼Œ
- en: \[ P(A) = \sum_{i=1}^{k_B} P(A,B) dB \]
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) = \sum_{i=1}^{k_B} P(A,B) dB \]
- en: '**Matrix Scatter Plots**'
  id: totrans-1048
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çŸ©é˜µæ•£ç‚¹å›¾**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): composite
    plot including the combinatorial of all pair-wise scatter plots for all features.'
  id: totrans-1049
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šåŒ…æ‹¬æ‰€æœ‰ç‰¹å¾æˆå¯¹æ•£ç‚¹å›¾çš„ç»„åˆå›¾ã€‚'
- en: given \(m\) features, there are \(m \times m\) scatter plots
  id: totrans-1050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®š \(m\) ä¸ªç‰¹å¾ï¼Œæœ‰ \(m \times m\) ä¸ªæ•£ç‚¹å›¾
- en: the scatter plots are ordered, y-axis feature from \(X_1,\ldots,X_m\) over the
    rows and x-axis feature from \(X_1,\ldots,X_m\) over the columns
  id: totrans-1051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•£ç‚¹å›¾æ˜¯æœ‰åºçš„ï¼Œyè½´ç‰¹å¾æ¥è‡ª \(X_1,\ldots,X_m\) çš„è¡Œï¼Œxè½´ç‰¹å¾æ¥è‡ª \(X_1,\ldots,X_m\) çš„åˆ—
- en: the diagonal is the features plotted with themselves and are often replaced
    with feature histograms or probability density functions
  id: totrans-1052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è§’çº¿æ˜¯è‡ªèº«ç‰¹å¾ç»˜åˆ¶çš„ï¼Œé€šå¸¸è¢«ç‰¹å¾ç›´æ–¹å›¾æˆ–æ¦‚ç‡å¯†åº¦å‡½æ•°æ‰€å–ä»£
- en: We use matrix scatter plots to,
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨çŸ©é˜µæ•£ç‚¹å›¾æ¥ï¼Œ
- en: look for bivariate linear or nonlinear structures
  id: totrans-1054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾åŒå˜é‡çº¿æ€§æˆ–éçº¿æ€§ç»“æ„
- en: look for bivariate homoscedasticity (constant conditional variance) and heteroscedasticity
    (conditional variance changes with value)
  id: totrans-1055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾åŒå˜é‡åŒæ–¹å·®æ€§ï¼ˆæ¡ä»¶æ–¹å·®æ’å®šï¼‰å’Œå¼‚æ–¹å·®æ€§ï¼ˆæ¡ä»¶æ–¹å·®éšå€¼å˜åŒ–ï¼‰
- en: look for bivariate constraints, such as sum constraints with compositional data
  id: totrans-1056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾åŒå˜é‡çº¦æŸï¼Œä¾‹å¦‚ç»„åˆæ•°æ®çš„æ±‚å’Œçº¦æŸ
- en: Remember, the other features are marginalized, this is not a full m-D visualization.
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œå…¶ä»–ç‰¹å¾å·²è¢«è¾¹ç¼˜åŒ–ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„ m-D å¯è§†åŒ–ã€‚
- en: '**Maximum Relevance Minimum Redundancy** (MRMR)'
  id: totrans-1058
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æœ€å¤§ç›¸å…³æ€§æœ€å°å†—ä½™** (MRMR)'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a mutual information-based
    approach for feature ranking that accounts for feature relevance and redundancy.'
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸€ç§åŸºäºäº’ä¿¡æ¯çš„ç‰¹å¾æ’åºæ–¹æ³•ï¼Œè€ƒè™‘äº†ç‰¹å¾çš„ç›¸å…³æ€§å’Œå†—ä½™ã€‚'
- en: one example is a relevance minus redundancy summary,
  id: totrans-1060
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¾‹å­æ˜¯ç›¸å…³æ€§å‡å»å†—ä½™æ‘˜è¦ï¼Œ
- en: \[ MRMR = max \left[ frac{1}{|S|} \sum_{X_i \in S} I(X_i,Y) - \frac{1}{|S|^2}
    \sum_{X_i \in S} \sum_{X_j, i \ne j} I(X_i,X_j) \right] \]
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MRMR = max \left[ frac{1}{|S|} \sum_{X_i \in S} I(X_i,Y) - \frac{1}{|S|^2}
    \sum_{X_i \in S} \sum_{X_j, i \ne j} I(X_i,X_j) \right] \]
- en: where \(ğ‘†\) is the predictor feature subset and \(|ğ‘†|\) is the number of features
    in the subset \(ğ‘†\).
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(ğ‘†\) æ˜¯é¢„æµ‹ç‰¹å¾å­é›†ï¼Œ\(|ğ‘†|\) æ˜¯å­é›† \(ğ‘†\) ä¸­ç‰¹å¾çš„æ•°é‡ã€‚
- en: '**Metropolis-Hastings MCMC Sampler**'
  id: totrans-1063
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Metropolis-Hastings MCMCé‡‡æ ·å™¨**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    The basic steps of the Metropolis-Hastings MCMC Sampler:'
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šMetropolis-Hastings
    MCMCé‡‡æ ·å™¨çš„åŸºæœ¬æ­¥éª¤ï¼š'
- en: 'For \(\ell = 1, \ldots, L\):'
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¯¹äº \(\ell = 1, \ldots, L\):'
- en: Assign random values for the initial sample of model parameters, \(\beta(\ell
    = 1) = b_1(\ell = 1)\), \(b_0(\ell = 1)\) and \(\sigma^2(\ell = 1)\).
  id: totrans-1066
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¨¡å‹å‚æ•°çš„åˆå§‹æ ·æœ¬åˆ†é…éšæœºå€¼ï¼Œ\(\beta(\ell = 1) = b_1(\ell = 1)\), \(b_0(\ell = 1)\) å’Œ \(\sigma^2(\ell
    = 1)\).
- en: Propose new model parameters based on a proposal function, \(\beta^{\prime}
    = b_1\), \(b_0\) and \(\sigma^2\).
  id: totrans-1067
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŸºäºæè®®å‡½æ•°æå‡ºæ–°çš„æ¨¡å‹å‚æ•°ï¼Œ\(\beta^{\prime} = b_1\), \(b_0\) å’Œ \(\sigma^2\).
- en: Calculate probability of acceptance of the new proposal, as the ratio of the
    posterior probability of the new model parameters given the data to the previous
    model parameters given the data multiplied by the probability of the old step
    given the new step divided by the probability of the new step given the old.
  id: totrans-1068
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–°æè®®çš„æ¥å—æ¦‚ç‡ï¼Œä½œä¸ºç»™å®šæ•°æ®çš„åéªŒæ¦‚ç‡ä¸å…ˆå‰çš„æ¨¡å‹å‚æ•°çš„æ¯”å€¼ï¼Œä¹˜ä»¥æ—§æ­¥éª¤ç»™å®šæ–°æ­¥éª¤çš„æ¦‚ç‡é™¤ä»¥æ–°æ­¥éª¤ç»™å®šæ—§æ­¥éª¤çš„æ¦‚ç‡ã€‚
- en: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
- en: Apply Monte Carlo simulation to conditionally accept the proposal, if accepted,
    \(\ell = \ell + 1\), and sample \(\beta(\ell) = \beta^{\prime}\)
  id: totrans-1070
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä»¥æ¡ä»¶æ¥å—æè®®ï¼Œå¦‚æœæ¥å—ï¼Œ\(\ell = \ell + 1\)ï¼Œå¹¶é‡‡æ · \(\beta(\ell) = \beta^{\prime}\)
- en: Go to step 2.
  id: totrans-1071
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è½¬åˆ°æ­¥éª¤ 2ã€‚
- en: '**Minkowski Distance**'
  id: totrans-1072
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é—µå¯å¤«æ–¯åŸºè·ç¦»**'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): a general
    expression for distance with well-known Manhattan and Euclidean distances are
    special cases,'
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šè·ç¦»çš„ä¸€èˆ¬è¡¨è¾¾å¼ï¼Œå…¶ä¸­å·²çŸ¥çš„æ›¼å“ˆé¡¿å’Œæ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œ'
- en: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
- en: when \(p=2\), this becomes the Euclidean distance
  id: totrans-1075
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(p=2\) æ—¶ï¼Œè¿™å˜ä¸ºæ¬§å‡ é‡Œå¾—è·ç¦»
- en: when \(p=1\) it becomes the Manhattan distance
  id: totrans-1076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(p=1\) æ—¶ï¼Œå®ƒå˜ä¸ºæ›¼å“ˆé¡¿è·ç¦»
- en: '**Missing Feature Values**'
  id: totrans-1077
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¼ºå¤±ç‰¹å¾å€¼**'
- en: '[Feature Imputation](MachineLearning_feature_imputation.html): null values
    in the data table, samples that do not have values for all features'
  id: totrans-1078
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’è¡¥](MachineLearning_feature_imputation.html)ï¼šæ•°æ®è¡¨ä¸­çš„ç©ºå€¼ï¼Œæ²¡æœ‰æ‰€æœ‰ç‰¹å¾å€¼çš„æ ·æœ¬'
- en: There are many causes of missing feature values, for example,
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±ç‰¹å¾å€¼æœ‰è®¸å¤šåŸå› ï¼Œä¾‹å¦‚ï¼Œ
- en: sampling cost, e.g., low permeability test takes too long
  id: totrans-1080
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡‡æ ·æˆæœ¬ï¼Œä¾‹å¦‚ï¼Œä½æ¸—é€ç‡æµ‹è¯•è€—æ—¶è¿‡é•¿
- en: rock rheology sample filter, e.g., canâ€™t recover the mudstone samples
  id: totrans-1081
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å²©çŸ³æµå˜å­¦æ ·æœ¬è¿‡æ»¤å™¨ï¼Œä¾‹å¦‚ï¼Œæ— æ³•æ¢å¤æ³¥å²©æ ·æœ¬
- en: sampling to reduce uncertainty and maximize profitability instead of statistical
    representativity, dual purpose samples for information and production
  id: totrans-1082
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡‡æ ·ä»¥å‡å°‘ä¸ç¡®å®šæ€§å¹¶æœ€å¤§åŒ–ç›ˆåˆ©æ€§ï¼Œè€Œä¸æ˜¯ç»Ÿè®¡ä»£è¡¨æ€§ï¼ŒåŒé‡ç›®çš„æ ·æœ¬ç”¨äºä¿¡æ¯å’Œç”Ÿäº§
- en: Missing data consequences, more than reducing the amount of training and testing
    data, missing data, if not completely at random may result in,
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±æ•°æ®åæœï¼Œé™¤äº†å‡å°‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é‡å¤–ï¼Œç¼ºå¤±æ•°æ®ï¼Œå¦‚æœä¸æ˜¯å®Œå…¨éšæœºï¼Œå¯èƒ½ä¼šå¯¼è‡´ï¼Œ
- en: biased sample statistics resulting in biased model training and testing
  id: totrans-1084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ ·æœ¬ç»Ÿè®¡å¯¼è‡´åå·®çš„æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•
- en: biased models with biased predictions with potentially no indication of the
    bias
  id: totrans-1085
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ¨¡å‹å…·æœ‰åå·®é¢„æµ‹ï¼Œå¯èƒ½æ²¡æœ‰åå·®çš„æŒ‡ç¤º
- en: '**Missing at Random** (MAR)'
  id: totrans-1086
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éšæœºç¼ºå¤±** (MAR)'
- en: '[Feature Imputation](MachineLearning_feature_imputation.html): missing feature
    values are distributed randomly, uniform coverage over the predictor feature space,
    i.e., all values have likelihood to be missing, and no correlation between missing
    feature values.'
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’è¡¥](MachineLearning_feature_imputation.html)ï¼šç¼ºå¤±ç‰¹å¾å€¼åˆ†å¸ƒéšæœºï¼Œåœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸­å‡åŒ€è¦†ç›–ï¼Œå³æ‰€æœ‰å€¼éƒ½æœ‰ç¼ºå¤±çš„å¯èƒ½æ€§ï¼Œå¹¶ä¸”ç¼ºå¤±ç‰¹å¾å€¼ä¹‹é—´æ²¡æœ‰ç›¸å…³æ€§ã€‚'
- en: This is typically not the case as missing data often has a confounding feature,
    for example,
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é€šå¸¸ä¸æ˜¯æƒ…å†µï¼Œå› ä¸ºç¼ºå¤±æ•°æ®é€šå¸¸æœ‰ä¸€ä¸ªæ··æ‚ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ
- en: sampling cost, e.g., low permeability test takes too long
  id: totrans-1089
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡‡æ ·æˆæœ¬ï¼Œä¾‹å¦‚ï¼Œä½æ¸—é€ç‡æµ‹è¯•è€—æ—¶è¿‡é•¿
- en: rock rheology sample filter, e.g., canâ€™t recover the mudstone samples
  id: totrans-1090
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å²©çŸ³åŠ›å­¦æ ·æœ¬è¿‡æ»¤å™¨ï¼Œä¾‹å¦‚ï¼Œæ— æ³•æ¢å¤æ³¥å²©æ ·æœ¬
- en: sampling to reduce uncertainty and maximize profitability instead of statistical
    representativity, dual purpose samples for information and production
  id: totrans-1091
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡‡æ ·ä»¥å‡å°‘ä¸ç¡®å®šæ€§å’Œæœ€å¤§åŒ–ç›ˆåˆ©æ€§ï¼Œè€Œä¸æ˜¯ç»Ÿè®¡ä»£è¡¨æ€§ï¼ŒåŒé‡ç›®çš„æ ·æœ¬ç”¨äºä¿¡æ¯å’Œç”Ÿäº§
- en: Missing data consequences, more than reducing the amount of training and testing
    data, missing data, if not completely at random may result in,
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±æ•°æ®åæœï¼Œé™¤äº†å‡å°‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é‡å¤–ï¼Œå¦‚æœç¼ºå¤±æ•°æ®ä¸æ˜¯å®Œå…¨éšæœºï¼Œè¿˜å¯èƒ½å¯¼è‡´ï¼Œ
- en: biased sample statistics resulting in biased model training and testing
  id: totrans-1093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ ·æœ¬ç»Ÿè®¡å¯¼è‡´æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•åå·®
- en: biased models with biased predictions with potentially no indication of the
    bias
  id: totrans-1094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ¨¡å‹å…·æœ‰åå·®é¢„æµ‹ï¼Œå¯èƒ½æ²¡æœ‰åå·®çš„è¿¹è±¡
- en: '**Model Bias**'
  id: totrans-1095
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åå·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is error due to
    insufficient complexity and flexibility to fit the natural setting'
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯ç”±äºä¸è¶³å¤Ÿçš„å¤æ‚æ€§å’Œçµæ´»æ€§æ¥é€‚åº”è‡ªç„¶è®¾ç½®è€Œäº§ç”Ÿçš„é”™è¯¯'
- en: increasing model complexity usually results in decreasing model bias
  id: totrans-1097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ æ¨¡å‹å¤æ‚æ€§é€šå¸¸ä¼šå¯¼è‡´æ¨¡å‹åå·®å‡å°‘
- en: '*model bias variance trade-off* - as complexity increases, model variance increases
    and model bias decreases'
  id: totrans-1098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹åå·®-æ–¹å·®æƒè¡¡* - éšç€å¤æ‚æ€§çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å¢åŠ ï¼Œæ¨¡å‹åå·®å‡å°‘'
- en: one of the three components of expected test square error, including model variance,
    model bias and irreducible error
  id: totrans-1099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æ¨¡å‹æ–¹å·®ã€æ¨¡å‹åå·®å’Œä¸å¯å‡å°‘è¯¯å·®
- en: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
- en: where \(\left(E [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0)
    \right)^2\) is model bias.
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\left(E [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2\)
    æ˜¯æ¨¡å‹åå·®ã€‚
- en: '**Model-Bias Variance Trade-off**'
  id: totrans-1102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åå·®-æ–¹å·®æƒè¡¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): as complexity increases,
    model variance increases and model bias decreases.'
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šéšç€å¤æ‚æ€§çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å¢åŠ ï¼Œæ¨¡å‹åå·®å‡å°‘ã€‚'
- en: as model variance and model bias are both components of expected test square
    error, the balancing of model bias and model variance results in an optimum level
    of complexity to minimize the testing error
  id: totrans-1104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæ¨¡å‹æ–¹å·®å’Œæ¨¡å‹åå·®éƒ½æ˜¯é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ç»„æˆéƒ¨åˆ†ï¼Œå› æ­¤æ¨¡å‹åå·®å’Œæ¨¡å‹æ–¹å·®çš„å¹³è¡¡å¯¼è‡´äº†ä¸€ä¸ªæœ€ä½³å¤æ‚åº¦æ°´å¹³ï¼Œä»¥æœ€å°åŒ–æµ‹è¯•è¯¯å·®
- en: '**Model Checking**'
  id: totrans-1105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ£€æŸ¥**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is a critical last
    step for any spatial modeling workflow. Here are the critical aspects of model
    checking,'
  id: totrans-1106
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯ä»»ä½•ç©ºé—´å»ºæ¨¡å·¥ä½œæµç¨‹çš„å…³é”®æœ€åä¸€æ­¥ã€‚ä»¥ä¸‹æ˜¯æ¨¡å‹æ£€æŸ¥çš„å…³é”®æ–¹é¢ï¼Œ'
- en: '*Model Inputs* - data and statistics integration'
  id: totrans-1107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹è¾“å…¥* - æ•°æ®å’Œç»Ÿè®¡æ•°æ®çš„æ•´åˆ'
- en: check the model to ensure the model inputs are honored in the models, generally
    checked over all the realizations, for example, the output histograms and matches
    the input histogram over the realizations
  id: totrans-1108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ¨¡å‹ä»¥ç¡®ä¿æ¨¡å‹è¾“å…¥åœ¨æ¨¡å‹ä¸­å¾—åˆ°å°Šé‡ï¼Œé€šå¸¸å¯¹æ‰€æœ‰å®ç°è¿›è¡Œæ£€æŸ¥ï¼Œä¾‹å¦‚ï¼Œè¾“å‡ºç›´æ–¹å›¾ä¸å®ç°ä¸­çš„è¾“å…¥ç›´æ–¹å›¾ç›¸åŒ¹é…
- en: '*Accurate Spatial Estimates* - ability of the model to accurately predict away
    from the available sample data, over a variety of configurations, with accuracy'
  id: totrans-1109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç²¾ç¡®ç©ºé—´ä¼°è®¡* - æ¨¡å‹åœ¨å¯ç”¨æ ·æœ¬æ•°æ®ä¹‹å¤–å‡†ç¡®é¢„æµ‹çš„èƒ½åŠ›ï¼Œåœ¨å„ç§é…ç½®ä¸‹ï¼Œå…·æœ‰å‡†ç¡®æ€§'
- en: by cross validation, withholding some of the data, check the modelâ€™s ability
    to predict
  id: totrans-1110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡äº¤å‰éªŒè¯ï¼Œä¿ç•™äº†ä¸€äº›æ•°æ®ï¼Œæ£€æŸ¥æ¨¡å‹é¢„æµ‹çš„èƒ½åŠ›
- en: generally, summarized with a truth vs. predicted cross plot and measures such
    as mean square error
  id: totrans-1111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œé€šè¿‡çœŸå®å€¼ä¸é¢„æµ‹äº¤å‰å›¾å’Œå‡æ–¹è¯¯å·®ç­‰æŒ‡æ ‡è¿›è¡Œæ€»ç»“
- en: \[ MSE = \frac{1}{n} \sum_{\alpha = 1}^{n} \left(z^{*}(\bf{u}_{\alpha}) - z(\bf{u}_{\alpha})
    \right)^2 \]
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MSE = \frac{1}{n} \sum_{\alpha = 1}^{n} \left(z^{*}(\bf{u}_{\alpha}) - z(\bf{u}_{\alpha})
    \right)^2 \]
- en: '*Accurate and Precise Uncertainty Models* - uncertainty model is fair given
    the amount of information available and various sources of uncertainty'
  id: totrans-1113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç²¾ç¡®å’Œç²¾ç¡®çš„ä¸ç¡®å®šæ€§æ¨¡å‹* - åœ¨ç»™å®šä¿¡æ¯å’Œå„ç§ä¸ç¡®å®šæ€§æ¥æºçš„æƒ…å†µä¸‹ï¼Œä¸ç¡®å®šæ€§æ¨¡å‹æ˜¯åˆç†çš„'
- en: also checked through cross validation, withholding some of the data, but by
    checking the proportion of the data in specific probability intervals
  id: totrans-1114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿé€šè¿‡äº¤å‰éªŒè¯è¿›è¡Œäº†æ£€æŸ¥ï¼Œä¿ç•™äº†ä¸€äº›æ•°æ®ï¼Œä½†é€šè¿‡æ£€æŸ¥ç‰¹å®šæ¦‚ç‡åŒºé—´å†…æ•°æ®çš„æ¯”ä¾‹
- en: summarized with a proportion of withheld data in interval vs. the probability
    interval
  id: totrans-1115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨ä¿ç•™æ•°æ®åœ¨åŒºé—´å†…çš„æ¯”ä¾‹ä¸æ¦‚ç‡åŒºé—´æ¥æ€»ç»“
- en: points on the 45 degree line indicate accurate and precise uncertainty model
  id: totrans-1116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 45åº¦çº¿ä¸Šçš„ç‚¹è¡¨ç¤ºå‡†ç¡®ä¸”ç²¾ç¡®çš„æ¨¡å‹ä¸ç¡®å®šæ€§
- en: points above the 45 degree line indicate accurate and imprecise uncertainty
    model, uncertainty is too wide
  id: totrans-1117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 45åº¦çº¿ä»¥ä¸Šçš„ç‚¹è¡¨ç¤ºå‡†ç¡®å’Œä¸å‡†ç¡®çš„æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œä¸ç¡®å®šæ€§èŒƒå›´å¤ªå®½
- en: points below the 45 degree line indicate inaccurate uncertainty model, uncertainty
    is too narrow or model is biased
  id: totrans-1118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 45åº¦çº¿ä»¥ä¸‹çš„ç‚¹è¡¨ç¤ºä¸å‡†ç¡®çš„æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œä¸ç¡®å®šæ€§å¤ªçª„æˆ–æ¨¡å‹æœ‰åå·®
- en: '**Model Complexity or Flexibility**'
  id: totrans-1119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å¤æ‚åº¦æˆ–çµæ´»æ€§**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the ability of
    a model to fit to data and to be interpreted.'
  id: totrans-1120
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ¨¡å‹æ‹Ÿåˆæ•°æ®å’Œå¯è§£é‡Šçš„èƒ½åŠ›ã€‚'
- en: A variety of concepts may be used to describe model complexity,
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨å„ç§æ¦‚å¿µæ¥æè¿°æ¨¡å‹å¤æ‚åº¦ï¼Œ
- en: the number of features, predictor variables are in the model, dimensionality
    of the model, usually resulting in more model parameters
  id: totrans-1122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹ä¸­çš„ç‰¹å¾æ•°é‡ã€é¢„æµ‹å˜é‡ï¼Œæ¨¡å‹çš„ç»´åº¦ï¼Œé€šå¸¸å¯¼è‡´æ›´å¤šçš„æ¨¡å‹å‚æ•°
- en: the number of parameters, the order applied for each term, e.g. linear, quadratic,
    thresholds
  id: totrans-1123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚æ•°æ•°é‡ï¼Œæ¯ä¸ªé¡¹åº”ç”¨çš„é¡ºåºï¼Œä¾‹å¦‚çº¿æ€§ã€äºŒæ¬¡ã€é˜ˆå€¼
- en: the format of the model, i.e., a compact equation with polynomial regression
    vs. nested conditional statements with decision tree vs. thousands of weights
    and bias model parameters for a neural network
  id: totrans-1124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„æ ¼å¼ï¼Œå³ï¼Œå¤šé¡¹å¼å›å½’çš„ç´§å‡‘æ–¹ç¨‹ä¸å†³ç­–æ ‘åµŒå¥—æ¡ä»¶è¯­å¥ç›¸æ¯”ï¼Œæˆ–ç¥ç»ç½‘ç»œæˆåƒä¸Šä¸‡çš„æƒé‡å’Œåå·®æ¨¡å‹å‚æ•°
- en: For example, more complexity with a high order polynomial, larger decision trees
    etc.
  id: totrans-1125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œé«˜é˜¶å¤šé¡¹å¼ã€æ›´å¤§çš„å†³ç­–æ ‘ç­‰æ›´å¤æ‚çš„å¤æ‚æ€§ã€‚
- en: In general, more complicated or flexible models are more difficult to interpret,
  id: totrans-1126
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ›´å¤æ‚æˆ–çµæ´»çš„æ¨¡å‹æ›´éš¾ä»¥è§£é‡Šï¼Œ
- en: linear regression and the associated model parameters can be analyzed and even
    applied for feature ranking, while support vector machines with radial basis functions
    are a linear model in the nD high dimensional space
  id: totrans-1127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’åŠå…¶ç›¸å…³æ¨¡å‹å‚æ•°å¯ä»¥è¿›è¡Œåˆ†æï¼Œç”šè‡³åº”ç”¨äºç‰¹å¾æ’åºï¼Œè€Œå…·æœ‰å¾„å‘åŸºå‡½æ•°çš„æ”¯æŒå‘é‡æœºåœ¨nDé«˜ç»´ç©ºé—´ä¸­æ˜¯ä¸€ä¸ªçº¿æ€§æ¨¡å‹
- en: '**Model Generalization**'
  id: totrans-1128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ³›åŒ–**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the ability of
    a model to predict away from training data.'
  id: totrans-1129
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ¨¡å‹é¢„æµ‹è®­ç»ƒæ•°æ®ä¹‹å¤–çš„èƒ½åŠ›ã€‚'
- en: the model learns the structure in the data and does not just memorize the training
    data
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹å­¦ä¹ æ•°æ®ä¸­çš„ç»“æ„ï¼Œè€Œä¸ä»…ä»…æ˜¯è®°ä½è®­ç»ƒæ•°æ®
- en: Models that do not generalize well,
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å–„äºæ³›åŒ–çš„æ¨¡å‹ï¼Œ
- en: overfit models have high accuracy at training data and low accuracy away from
    training data, demonstrated with low testing accuracy
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡æ‹Ÿåˆæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šå…·æœ‰é«˜ç²¾åº¦ï¼Œè€Œåœ¨è®­ç»ƒæ•°æ®ä¹‹å¤–å…·æœ‰ä½ç²¾åº¦ï¼Œä»¥ä½æµ‹è¯•ç²¾åº¦ä¸ºä¾‹
- en: underfit models are too simple or inflexible for the natural phenomenon and
    have low training and testing accuracy
  id: totrans-1133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¬ æ‹Ÿåˆæ¨¡å‹å¯¹è‡ªç„¶ç°è±¡è¿‡äºç®€å•æˆ–ä¸çµæ´»ï¼Œè®­ç»ƒå’Œæµ‹è¯•å‡†ç¡®æ€§ä½
- en: '**Model Hyperparameters**'
  id: totrans-1134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹è¶…å‚æ•°**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): constrain the model
    complexity. Hyperparameters are tuned to maximize accuracy with the withheld testing
    data to prevent model overfit.'
  id: totrans-1135
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé™åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚è¶…å‚æ•°è°ƒæ•´ä»¥æœ€å¤§åŒ–ä¿ç•™æµ‹è¯•æ•°æ®ä¸­çš„å‡†ç¡®æ€§ï¼Œä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚'
- en: For a set of polynomial models from \(4^{th}\) to \(1^{st}\) order,
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä» \(4^{th}\) åˆ° \(1^{st}\) æ¬¡çš„å¤šé¡¹å¼æ¨¡å‹ï¼Œ
- en: \[ y = b_4 \cdot x^4 + b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[
    y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[ y = b_2 \cdot x^2 +
    b_1 \cdot x + b_0 \]\[ y = b_1 \cdot x + b_0 \]
  id: totrans-1137
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = b_4 \cdot x^4 + b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[
    y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[ y = b_2 \cdot x^2 +
    b_1 \cdot x + b_0 \]\[ y = b_1 \cdot x + b_0 \]
- en: the choice of polynomial order is the hyperparameter, i.e., the first order
    model is most simple and the fourth order model is most complicated.
  id: totrans-1138
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼é˜¶æ•°çš„é€‰æ‹©æ˜¯è¶…å‚æ•°ï¼Œå³ï¼Œä¸€é˜¶æ¨¡å‹æœ€ç®€å•ï¼Œå››é˜¶æ¨¡å‹æœ€å¤æ‚ã€‚
- en: '**Model Parameters**'
  id: totrans-1139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å‚æ•°**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): trainable coefficients
    for a machine learning model that control the fit to the training data.'
  id: totrans-1140
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ç”¨äºæ§åˆ¶å¯¹è®­ç»ƒæ•°æ®æ‹Ÿåˆçš„å¯è®­ç»ƒç³»æ•°ã€‚'
- en: For a polynomial model,
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šé¡¹å¼æ¨¡å‹ï¼Œ
- en: \[ y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]
  id: totrans-1142
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]
- en: \(b_3\), \(b_2\), \(b_1\), and \(b_0\) are model parameters.
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
  zh: \(b_3\)ã€\(b_2\)ã€\(b_1\) å’Œ \(b_0\) æ˜¯æ¨¡å‹å‚æ•°ã€‚
- en: '*training model parameters* - model parameters are calculated by optimization
    to minimize error and regularization terms over the training data through analytical
    solution or iterative solution, e.g., gradient descent optimization'
  id: totrans-1144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è®­ç»ƒæ¨¡å‹å‚æ•°* - æ¨¡å‹å‚æ•°é€šè¿‡ä¼˜åŒ–è®¡ç®—ï¼Œä»¥æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®å’Œæ­£åˆ™åŒ–é¡¹ï¼Œé€šè¿‡è§£æè§£æˆ–è¿­ä»£è§£ï¼Œä¾‹å¦‚ï¼Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–'
- en: Model Regularization
  id: totrans-1145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ­£åˆ™åŒ–
- en: '[Ridge Regression](MachineLearning_ridge_regression.html): adding information
    to prevent overfit (or underfit), improve model generalization.'
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
  zh: '[å²­å›å½’](MachineLearning_ridge_regression.html)ï¼šæ·»åŠ ä¿¡æ¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼ˆæˆ–æ¬ æ‹Ÿåˆï¼‰ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚'
- en: this information is known as a regularization term
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç§ä¿¡æ¯è¢«ç§°ä¸ºæ­£åˆ™åŒ–é¡¹
- en: this represents a penalty for complexity that is tuned with a regularization
    hyperparameter
  id: totrans-1148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä»£è¡¨äº†ä¸€ç§ç”±æ­£åˆ™åŒ–è¶…å‚æ•°è°ƒæ•´çš„å¤æ‚åº¦æƒ©ç½š
- en: Consider the ridge regression loss function,
  id: totrans-1149
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘å²­å›å½’æŸå¤±å‡½æ•°ï¼Œ
- en: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m b_{\alpha}^2 \]
  id: totrans-1150
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m b_{\alpha}^2 \]
- en: where \(\lambda \sum_{j=1}^m b_{\alpha}^2\) is the regularization term and \(\lambda\)
    is the regularization hyperparameter.
  id: totrans-1151
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\lambda \sum_{j=1}^m b_{\alpha}^2\) æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œè€Œ \(\lambda\) æ˜¯æ­£åˆ™åŒ–è¶…å‚æ•°ã€‚
- en: The concept of regularization is quite general and choices in machine learning
    architecture, such as,
  id: totrans-1152
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–çš„æ¦‚å¿µç›¸å½“é€šç”¨ï¼Œåœ¨æœºå™¨å­¦ä¹ æ¶æ„ä¸­çš„é€‰æ‹©ï¼Œä¾‹å¦‚ï¼Œ
- en: use of receptive fields for convolutional neural networks (CNNs)
  id: totrans-1153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ„Ÿå—é‡å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰
- en: the choice to limit decision trees to a maximum number of levels.
  id: totrans-1154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™åˆ¶å†³ç­–æ ‘çš„æœ€å¤§å±‚æ•°çš„é€‰æ‹©ã€‚
- en: There are a couple of useful perspectives on model regularization,
  id: totrans-1155
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæ¨¡å‹æ­£åˆ™åŒ–æœ‰å‡ ä¸ªæœ‰ç”¨çš„è§†è§’ï¼Œ
- en: '*Occamâ€™s razor* - regularization tunes model complexity to the simplest effective
    solution'
  id: totrans-1156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™* - æ­£åˆ™åŒ–è°ƒæ•´æ¨¡å‹å¤æ‚åº¦ä»¥è¾¾åˆ°æœ€ç®€å•çš„æœ‰æ•ˆè§£'
- en: '*Bayesian perspective* - regularization is imposing a prior on the solution.'
  id: totrans-1157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è´å¶æ–¯è§†è§’* - æ­£åˆ™åŒ–æ˜¯å¯¹è§£æ–½åŠ å…ˆéªŒã€‚'
- en: '**Model Variance**'
  id: totrans-1158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ–¹å·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is error due to
    sensitivity to the dataset'
  id: totrans-1159
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šç”±äºå¯¹æ•°æ®é›†æ•æ„Ÿè€Œäº§ç”Ÿçš„è¯¯å·®'
- en: increasing model complexity usually results in increasing model variance
  id: totrans-1160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ æ¨¡å‹å¤æ‚åº¦é€šå¸¸ä¼šå¯¼è‡´æ¨¡å‹æ–¹å·®å¢åŠ 
- en: ensemble machine learning, for example, model bagging reduce model variance
    by averaging over multiple estimators trained on bootstrap realizations of the
    dataset
  id: totrans-1161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é›†æˆæœºå™¨å­¦ä¹ ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡åœ¨æ•°æ®é›†çš„bootstrapå®ç°ä¸Šè®­ç»ƒå¤šä¸ªä¼°è®¡å™¨æ¥å¹³å‡æ¨¡å‹æ–¹å·®
- en: '*model bias variance trade-off* - as complexity increases, model variance increases
    and model bias decreases'
  id: totrans-1162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹åå·®-æ–¹å·®æƒè¡¡* - éšç€å¤æ‚åº¦çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å¢åŠ ï¼Œæ¨¡å‹åå·®å‡å°‘'
- en: one of the three components of expected test square error, including model variance,
    model bias and irreducible error
  id: totrans-1163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æ¨¡å‹æ–¹å·®ã€æ¨¡å‹åå·®å’Œä¸å¯å‡å°‘è¯¯å·®
- en: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
  id: totrans-1164
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
- en: where \(E \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[
    \hat{f}(x_1^0, \ldots, x_m,^0) \right] \right)^2 \right]\) is model variance.
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(E \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[
    \hat{f}(x_1^0, \ldots, x_m,^0) \right] \right)^2 \right]\) æ˜¯æ¨¡å‹æ–¹å·®ã€‚
- en: '**Momentum** (optimization)'
  id: totrans-1166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŠ¨é‡**ï¼ˆä¼˜åŒ–ï¼‰'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): update the previous
    step with the new step, momentum, \(\lambda\), is the weight applied to the previous
    step while \(1 - \lambda\) is the weight applied to the current step,'
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šç”¨æ–°æ­¥æ›´æ–°å‰ä¸€æ­¥ï¼ŒåŠ¨é‡ï¼Œ\(\lambda\) æ˜¯åº”ç”¨äºå‰ä¸€æ­¥çš„æƒé‡ï¼Œè€Œ
    \(1 - \lambda\) æ˜¯åº”ç”¨äºå½“å‰æ­¥çš„æƒé‡ï¼Œ'
- en: \[ \left( \left( r \cdot \nabla L \right)_{t-1} \right)^m = \lambda \cdot r
    \cdot \nabla L_{t-2} + (1 - \lambda) \cdot r \cdot \nabla L_{t-1} \]
  id: totrans-1168
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left( \left( r \cdot \nabla L \right)_{t-1} \right)^m = \lambda \cdot r
    \cdot \nabla L_{t-2} + (1 - \lambda) \cdot r \cdot \nabla L_{t-1} \]
- en: the gradients calculated from the partial derivatives of the loss function for
    each model parameter have noise. Momentum smooths out, reduces the impact of this
    noise.
  id: totrans-1169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ¯ä¸ªæ¨¡å‹å‚æ•°çš„æŸå¤±å‡½æ•°åå¯¼æ•°è®¡ç®—å‡ºçš„æ¢¯åº¦å­˜åœ¨å™ªå£°ã€‚åŠ¨é‡å¹³æ»‘ï¼Œå‡å°‘è¿™ç§å™ªå£°çš„å½±å“ã€‚
- en: momentum helps the solution proceed down the general slope of the loss function,
    rather than oscillating in local ravines or dimples
  id: totrans-1170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ¨é‡æœ‰åŠ©äºè§£å†³æ–¹æ¡ˆæ²¿ç€æŸå¤±å‡½æ•°çš„ä¸€èˆ¬æ–œç‡å‰è¿›ï¼Œè€Œä¸æ˜¯åœ¨å±€éƒ¨å³¡è°·æˆ–å‡¹æ§½ä¸­æŒ¯è¡
- en: '**Markov Chain Monte Carlo** (MCMC)'
  id: totrans-1171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›** (MCMC)'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a set of algorithms to sample from a probability distribution such that the samples
    match the distribution statistics.'
  id: totrans-1172
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€å¥—ä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·çš„ç®—æ³•ï¼Œä½¿å¾—æ ·æœ¬åŒ¹é…åˆ†å¸ƒç»Ÿè®¡é‡ã€‚'
- en: '*Markov* - screening assumption, the next sample is only dependent on the previous
    sample'
  id: totrans-1173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é©¬å°”å¯å¤«* - å±è”½å‡è®¾ï¼Œä¸‹ä¸€ä¸ªæ ·æœ¬ä»…ä¾èµ–äºå‰ä¸€ä¸ªæ ·æœ¬'
- en: '*Chain* - the samples form a sequence often demonstrating a transition from
    burn-in chain with inaccurate statistics and equilibrium chain with accurate statistics'
  id: totrans-1174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é“¾* - æ ·æœ¬å½¢æˆä¸€ä¸ªåºåˆ—ï¼Œé€šå¸¸è¡¨æ˜ä»çƒ§æ¯é“¾ï¼ˆå…·æœ‰ä¸å‡†ç¡®ç»Ÿè®¡é‡ï¼‰åˆ°å¹³è¡¡é“¾ï¼ˆå…·æœ‰å‡†ç¡®ç»Ÿè®¡é‡ï¼‰çš„è¿‡æ¸¡'
- en: '*Monte Carlo* - use of Monte Carlo simulation, random sampling from a statistical
    distribution'
  id: totrans-1175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›* - ä½¿ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œä»ç»Ÿè®¡åˆ†å¸ƒä¸­è¿›è¡Œéšæœºé‡‡æ ·'
- en: Why is this useful?
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¿™å¾ˆæœ‰ç”¨ï¼Ÿ
- en: we often donâ€™t have the target distribution, it is unknown
  id: totrans-1177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šå¸¸æ²¡æœ‰ç›®æ ‡åˆ†å¸ƒï¼Œå®ƒæ˜¯æœªçŸ¥çš„
- en: but we can sample with the correct frequencies with other form of information
    such as conditional probability density functions, Gibbs sampler, or the likelihood
    ratios of the candidate next sample and the current sample, Metropolis-Hastings
  id: totrans-1178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡å…¶ä»–å½¢å¼çš„ä¿¡æ¯ï¼ˆå¦‚æ¡ä»¶æ¦‚ç‡å¯†åº¦å‡½æ•°ã€Gibbsé‡‡æ ·æˆ–å€™é€‰ä¸‹ä¸€ä¸ªæ ·æœ¬ä¸å½“å‰æ ·æœ¬çš„ä¼¼ç„¶æ¯”ï¼‰ä»¥æ­£ç¡®çš„é¢‘ç‡è¿›è¡Œé‡‡æ ·ï¼Œä¾‹å¦‚Metropolis-Hastings
- en: '**Metropolis-Hastings Sampling** (MCMC)'
  id: totrans-1179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Metropolis-Hastings Sampling** (MCMC)'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a set of algorithms to sample from a probability distribution such that the samples
    match the distribution statistics, based on,'
  id: totrans-1180
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€å¥—ä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·çš„ç®—æ³•ï¼Œä½¿å¾—æ ·æœ¬åŒ¹é…åˆ†å¸ƒç»Ÿè®¡é‡ï¼ŒåŸºäºï¼Œ'
- en: the likelihood ratios of the candidate next sample and the current sample
  id: totrans-1181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å€™é€‰ä¸‹ä¸€ä¸ªæ ·æœ¬å’Œå½“å‰æ ·æœ¬çš„ä¼¼ç„¶æ¯”
- en: a rejection sampler based on this likelihood ratio
  id: totrans-1182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºè¿™ä¸ªä¼¼ç„¶æ¯”çš„ä¸€ä¸ªæ‹’ç»é‡‡æ ·å™¨
- en: Since only the ratio of likelihood is required, the system is simplified as
    the evidence term cancels out from the Bayesian probability
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåªéœ€è¦ä¼¼ç„¶æ¯”çš„æ¯”ç‡ï¼Œç³»ç»Ÿç®€åŒ–ä¸ºä»è´å¶æ–¯æ¦‚ç‡ä¸­å–æ¶ˆè¯æ®é¡¹
- en: 'Hereâ€™s the basic steps of the Metropolis-Hastings MCMC Sampler:'
  id: totrans-1184
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯Metropolis-Hastings MCMCé‡‡æ ·å™¨çš„åŸºæœ¬æ­¥éª¤ï¼š
- en: 'For \(\ell = 1, \ldots, L\):'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¯¹äº \(\ell = 1, \ldots, L\):'
- en: Assign random values for the initial sample of model parameters, \(\beta(\ell
    = 1) = b_1(\ell = 1)\), \(b_0(\ell = 1)\) and \(\sigma^2(\ell = 1)\).
  id: totrans-1186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¨¡å‹å‚æ•°çš„åˆå§‹æ ·æœ¬åˆ†é…éšæœºå€¼ï¼Œ\(\beta(\ell = 1) = b_1(\ell = 1)\), \(b_0(\ell = 1)\) å’Œ \(\sigma^2(\ell
    = 1)\).
- en: Propose new model parameters based on a proposal function, \(\beta^{\prime}
    = b_1\), \(b_0\) and \(\sigma^2\).
  id: totrans-1187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŸºäºå»ºè®®å‡½æ•°æå‡ºæ–°çš„æ¨¡å‹å‚æ•°ï¼Œ\(\beta^{\prime} = b_1\), \(b_0\) å’Œ \(\sigma^2\).
- en: Calculate probability of acceptance of the new proposal, as the ratio of the
    posterior probability of the new model parameters given the data to the previous
    model parameters given the data multiplied by the probability of the old step
    given the new step divided by the probability of the new step given the old.
  id: totrans-1188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–°å»ºè®®çš„æ¥å—æ¦‚ç‡ï¼Œå³æ–°æ¨¡å‹å‚æ•°åœ¨ç»™å®šæ•°æ®ä¸‹çš„åéªŒæ¦‚ç‡ä¸æ—§æ¨¡å‹å‚æ•°åœ¨ç»™å®šæ•°æ®ä¸‹çš„åéªŒæ¦‚ç‡çš„æ¯”ç‡ï¼Œä¹˜ä»¥æ—§æ­¥éª¤åœ¨ç»™å®šæ–°æ­¥éª¤ä¸‹çš„æ¦‚ç‡é™¤ä»¥æ–°æ­¥éª¤åœ¨ç»™å®šæ—§æ­¥éª¤ä¸‹çš„æ¦‚ç‡ã€‚
- en: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
  id: totrans-1189
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
- en: Apply Monte Carlo simulation to conditionally accept the proposal, if accepted,
    \(\ell = \ell + 1\), and sample \(\beta(\ell) = \beta^{\prime}\)
  id: totrans-1190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä»¥æ¡ä»¶æ¥å—å»ºè®®ï¼Œå¦‚æœè¢«æ¥å—ï¼Œ\(\ell = \ell + 1\)ï¼Œå¹¶é‡‡æ · \(\beta(\ell) = \beta^{\prime}\)
- en: Go to step 2.
  id: totrans-1191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è½¬åˆ°æ­¥éª¤2ã€‚
- en: '**Monte Carlo Simulation (MCS)**'
  id: totrans-1192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ (MCS)**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a random sample from a statistical distribution, random variable. The steps for
    MCS are:'
  id: totrans-1193
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä»ç»Ÿè®¡åˆ†å¸ƒä¸­éšæœºé‡‡æ ·ï¼Œéšæœºå˜é‡ã€‚MCSçš„æ­¥éª¤å¦‚ä¸‹ï¼š'
- en: model the feature cumulative distribution function, \(F_x(x)\)
  id: totrans-1194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å»ºç«‹ç‰¹å¾ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼Œ\(F_x(x)\)
- en: draw random value from a uniform [0,1] distribution, this is a random cumulative
    probability value, known as a p-value, \(p^{\ell}\)
  id: totrans-1195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»å‡åŒ€åˆ†å¸ƒ [0,1] ä¸­æŠ½å–éšæœºå€¼ï¼Œè¿™æ˜¯ä¸€ä¸ªéšæœºç´¯ç§¯æ¦‚ç‡å€¼ï¼Œç§°ä¸ºpå€¼ï¼Œ\(p^{\ell}\)
- en: apply the inverse of the cumulative distribution function to calculate the associated
    realization
  id: totrans-1196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„é€†æ¥è®¡ç®—ç›¸å…³çš„å®ç°
- en: \[ x^{\ell} = F_x^{-1} (p^{\ell}) \]
  id: totrans-1197
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x^{\ell} = F_x^{-1} (p^{\ell}) \]
- en: repeat to calculate enough realizations for the subsequent analysis
  id: totrans-1198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤è®¡ç®—åç»­åˆ†ææ‰€éœ€çš„è¶³å¤Ÿå®ç°
- en: Monte Carlo simulation is the basic building block of stochastic simulation
    workflows, for example,
  id: totrans-1199
  prefs: []
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ˜¯éšæœºæ¨¡æ‹Ÿå·¥ä½œæµç¨‹çš„åŸºæœ¬æ„å»ºå—ï¼Œä¾‹å¦‚ï¼Œ
- en: '*Monte Carlo simulation workflows* - apply Monte Carlo simulation many over
    all features to the transfer function to calculate a realization of the decision
    criteria, repeated for many realizations, to propagate uncertainty through a transfer
    function'
  id: totrans-1200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå·¥ä½œæµç¨‹* - å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºæ‰€æœ‰ç‰¹å¾åˆ°ä¼ é€’å‡½æ•°ï¼Œä»¥è®¡ç®—å†³ç­–æ ‡å‡†çš„å®ç°ï¼Œé‡å¤å¤šæ¬¡å®ç°ï¼Œä»¥é€šè¿‡ä¼ é€’å‡½æ•°ä¼ æ’­ä¸ç¡®å®šæ€§'
- en: '*Bootstrap* - applies Monte Carlo simulation to acquire realizations of the
    data to calculate uncertainty in sample statistics or ensembles of prediction
    models for ensemble-based machine learning'
  id: totrans-1201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è‡ªåŠ©æ³•* - å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºè·å–æ•°æ®çš„å®ç°ä»¥è®¡ç®—æ ·æœ¬ç»Ÿè®¡æˆ–åŸºäºé›†æˆæœºå™¨å­¦ä¹ çš„é¢„æµ‹æ¨¡å‹é›†çš„ä¸ç¡®å®šæ€§'
- en: '*Monte Carlo methods* - applies Monte Carlo simulation to speed up an expensive
    calculation with a limited random sample that converges on the solution as the
    number of random samples increases'
  id: totrans-1202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›æ–¹æ³•* - å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºé€šè¿‡æœ‰é™çš„éšæœºæ ·æœ¬åŠ é€Ÿæ˜‚è´µçš„è®¡ç®—ï¼Œéšç€éšæœºæ ·æœ¬æ•°é‡çš„å¢åŠ ï¼Œè§£å†³æ–¹æ¡ˆæ”¶æ•›'
- en: '**Monte Carlo Simulation Workflow**'
  id: totrans-1203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå·¥ä½œæµç¨‹**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a convenient stochastic workflow for propagating uncertainty through a transfer
    function through sampling with Monte Carlo Simulation (MCS). The workflow includes
    the following steps,'
  id: totrans-1204
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€ç§æ–¹ä¾¿çš„éšæœºå·¥ä½œæµç¨‹ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼ˆMCSï¼‰è¿›è¡Œé‡‡æ ·æ¥ä¼ æ’­ä¼ é€’å‡½æ•°çš„ä¸ç¡®å®šæ€§ã€‚è¯¥å·¥ä½œæµç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼Œ'
- en: Model all the input featuresâ€™ distributions, cumulative distribution functions,
  id: totrans-1205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ‰€æœ‰è¾“å…¥ç‰¹å¾çš„åˆ†å¸ƒã€ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼Œ
- en: \[ F_{x_1}(x_1), \quad F_{x_2}(x_2), \quad \dots \quad , F_{x_m}(x_m) \]
  id: totrans-1206
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_{x_1}(x_1), \quad F_{x_2}(x_2), \quad \dots \quad , F_{x_m}(x_m) \]
- en: Monte Carlo simulate a realizations for all the inputs,
  id: totrans-1207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹æ‰€æœ‰è¾“å…¥è¿›è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œ
- en: \[ x_1^{\ell}, \quad x_2^{\ell}, \quad \ldots \quad , x_m^{\ell} \]
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_1^{\ell}, \quad x_2^{\ell}, \quad \ldots \quad , x_m^{\ell} \]
- en: Apply to the transfer function to get a realization of the transfer function
    output, often the *decision criteria*
  id: totrans-1209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨åˆ°ä¼ é€’å‡½æ•°ä»¥è·å¾—ä¼ é€’å‡½æ•°è¾“å‡ºçš„å®ç°ï¼Œé€šå¸¸æ˜¯ *å†³ç­–æ ‡å‡†*
- en: \[ y^{\ell} = f \left(x_1^{\ell},x_2^{\ell}, \quad \ldots \quad, x_m^{\ell}
    \right) \]
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y^{\ell} = f \left(x_1^{\ell},x_2^{\ell}, \quad \ldots \quad, x_m^{\ell}
    \right) \]
- en: Repeat steps 1-3 to calculate enough realizations to model the transfer function
    output distribution.
  id: totrans-1211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤æ­¥éª¤ 1-3 ä»¥è®¡ç®—è¶³å¤Ÿçš„å®ç°æ¥æ¨¡æ‹Ÿä¼ é€’å‡½æ•°è¾“å‡ºåˆ†å¸ƒã€‚
- en: \[ F_y(y) \]
  id: totrans-1212
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_y(y) \]
- en: '**Multiplication Rule** (probability)'
  id: totrans-1213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¹˜æ³•è§„åˆ™**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): we can calculate
    the joint probability of \(A\) and \(B\) as the product of the conditional probability
    of \(B\) given \(A\) with the marginal probability of \(A\),'
  id: totrans-1214
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šæˆ‘ä»¬å¯ä»¥é€šè¿‡ \(A\) ç»™å®š \(B\) çš„æ¡ä»¶æ¦‚ç‡ä¸ \(A\)
    çš„è¾¹ç¼˜æ¦‚ç‡çš„ä¹˜ç§¯æ¥è®¡ç®— \(A\) å’Œ \(B\) çš„è”åˆæ¦‚ç‡ï¼Œ'
- en: \[ P(A \cup B) = P(A,B) = P(B|A) \cdot P(A) \]
  id: totrans-1215
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A,B) = P(B|A) \cdot P(A) \]
- en: The multiplication rule is derived as a simple manipulation of the definition
    of conditional probability, in this case,
  id: totrans-1216
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹˜æ³•è§„åˆ™æ˜¯é€šè¿‡ç®€å•æ“ä½œæ¡ä»¶æ¦‚ç‡çš„å®šä¹‰æ¨å¯¼å‡ºæ¥çš„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ
- en: \[ P(B|A) = \frac{P(A,B)}{P(A)} \]
  id: totrans-1217
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A,B)}{P(A)} \]
- en: '**Mutual Information**'
  id: totrans-1218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº’ä¿¡æ¯**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a generalized approach
    that quantifies the mutual dependence between two features.'
  id: totrans-1219
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸€ç§é€šç”¨æ–¹æ³•ï¼Œé‡åŒ–ä¸¤ä¸ªç‰¹å¾ä¹‹é—´çš„ç›¸äº’ä¾èµ–æ€§ã€‚'
- en: quantifies the amount of information gained from observing one feature about
    the other
  id: totrans-1220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡åŒ–ä»è§‚å¯Ÿä¸€ä¸ªç‰¹å¾å…³äºå¦ä¸€ä¸ªç‰¹å¾è·å¾—çš„ä¿¡æ¯é‡
- en: avoids any assumption about the form of the relationship (e.g. no assumption
    of linear relationship)
  id: totrans-1221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…å¯¹å…³ç³»å½¢å¼çš„ä»»ä½•å‡è®¾ï¼ˆä¾‹å¦‚ï¼Œæ²¡æœ‰çº¿æ€§å…³ç³»çš„å‡è®¾ï¼‰
- en: units are Shannons or bits
  id: totrans-1222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å•ä½æ˜¯é¦™å†œæˆ–æ¯”ç‰¹
- en: compares the joint probabilities to the product of the marginal probabilities
  id: totrans-1223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è”åˆæ¦‚ç‡ä¸è¾¹ç¼˜æ¦‚ç‡çš„ä¹˜ç§¯è¿›è¡Œæ¯”è¾ƒ
- en: summarizes the difference between the joint \(P(x,y)\) and the product of the
    marginals \(P(x)\cdot P(y)\), integrated over all \(x \in ğ‘‹\) and \(y \in Y\),
  id: totrans-1224
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€»ç»“äº†è”åˆ \(P(x,y)\) ä¸è¾¹ç¼˜ \(P(x)\cdot P(y)\) çš„ä¹˜ç§¯ä¹‹é—´çš„å·®å¼‚ï¼Œåœ¨æ•´ä¸ª \(x \in ğ‘‹\) å’Œ \(y \in Y\)
    ä¸Šç§¯åˆ†ï¼Œ
- en: 'For discrete or binned continuous features \(X\) and \(Y\), mutual information
    is calculated as:'
  id: totrans-1225
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¦»æ•£æˆ–åˆ†ç®±çš„è¿ç»­ç‰¹å¾ \(X\) å’Œ \(Y\)ï¼Œäº’ä¿¡æ¯è®¡ç®—å¦‚ä¸‹ï¼š
- en: \[ I(X;Y) = \sum_{y \in Y} \sum_{x \in X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) \]
  id: totrans-1226
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I(X;Y) = \sum_{y \in Y} \sum_{x \in X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) \]
- en: 'recall, given independence between \(X\) and \(Y\):'
  id: totrans-1227
  prefs: []
  type: TYPE_NORMAL
  zh: å›æƒ³ï¼Œç»™å®š \(X\) å’Œ \(Y\) ä¹‹é—´çš„ç‹¬ç«‹æ€§ï¼š
- en: \[ P_{X,Y}(x,y) = P_X(x) \cdot P_Y(y) \]
  id: totrans-1228
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P_{X,Y}(x,y) = P_X(x) \cdot P_Y(y) \]
- en: therefore if the two features are independent then the \(log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) = 0\)
  id: totrans-1229
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¦‚æœä¸¤ä¸ªç‰¹å¾æ˜¯ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆ \(log \left( \frac{P_{X,Y}(x,y)}{P_X(x) \cdot P_Y(y)} \right)
    = 0\)
- en: The joint probability \(P_{X,Y}(x,y)\) is a weighting term on the sum and enforces
    closure.
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
  zh: è”åˆæ¦‚ç‡ \(P_{X,Y}(x,y)\) æ˜¯æ±‚å’Œçš„åŠ æƒé¡¹ï¼Œå¹¶å¼ºåˆ¶å°é—­ã€‚
- en: parts of the joint distribution with greater density have greater impact on
    the mutual information metric
  id: totrans-1231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è”åˆåˆ†å¸ƒä¸­å¯†åº¦è¾ƒå¤§çš„éƒ¨åˆ†å¯¹äº’ä¿¡æ¯åº¦é‡æœ‰æ›´å¤§çš„å½±å“ã€‚
- en: For continuous (and nonbinned) features we can applied the integral form.
  id: totrans-1232
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿ç»­ï¼ˆå’Œéåˆ†ç®±ï¼‰ç‰¹å¾ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ç§¯åˆ†å½¢å¼ã€‚
- en: \[ I(X;Y) = \int_{Y} \int_{X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) dx dy \]
  id: totrans-1233
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I(X;Y) = \int_{Y} \int_{X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) dx dy \]
- en: '**Mutually Exclusive Events** (probability)'
  id: totrans-1234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº’æ–¥äº‹ä»¶**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the events do not
    intersect, i.e., do not have any common outcomes. We represent this as,'
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šäº‹ä»¶ä¸ç›¸äº¤ï¼Œå³æ²¡æœ‰å…±åŒçš„ç»“æœã€‚æˆ‘ä»¬è¡¨ç¤ºä¸ºï¼Œ'
- en: using set notation, we state events \(A\) and \(B\) are mutually exclusive as,
  id: totrans-1236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é›†åˆè¡¨ç¤ºæ³•ï¼Œæˆ‘ä»¬å£°æ˜äº‹ä»¶ \(A\) å’Œ \(B\) æ˜¯äº’æ–¥çš„ï¼Œå³å®ƒä»¬æ²¡æœ‰å…±åŒçš„ç»“æœã€‚æˆ‘ä»¬è¡¨ç¤ºä¸ºï¼Œ
- en: '\[ A \cap B = \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
  id: totrans-1237
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ A \cap B = \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
- en: and the probability for mutually exclusive as,
  id: totrans-1238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥åŠäº’æ–¥äº‹ä»¶çš„æ¦‚ç‡ï¼Œ
- en: \[ P(A,B) = 0.0 \]
  id: totrans-1239
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = 0.0 \]
- en: '**Multidimensional Scaling**'
  id: totrans-1240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤šç»´å°ºåº¦åˆ†æ**'
- en: '[Multidimensional Scaling](MachineLearning_multidimensional_scaling.html):
    a method in inferential statistics / information visualization for exploring /
    visualizing the similarity (conversely the difference) between individual samples
    from a high dimensional dataset in a low dimensional space.'
  id: totrans-1241
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šç»´å°ºåº¦åˆ†æ](MachineLearning_multidimensional_scaling.html)ï¼šä¸€ç§åœ¨æ¨æ–­ç»Ÿè®¡å­¦/ä¿¡æ¯å¯è§†åŒ–ä¸­ç”¨äºæ¢ç´¢/å¯è§†åŒ–é«˜ç»´æ•°æ®é›†ä¸­ä¸ªä½“æ ·æœ¬ä¹‹é—´ç›¸ä¼¼æ€§ï¼ˆæˆ–ç›¸åï¼Œå·®å¼‚æ€§ï¼‰çš„æ–¹æ³•ï¼Œåœ¨ä½ç»´ç©ºé—´ä¸­è¿›è¡Œã€‚'
- en: Multidimensional scaling (MDS) projects the \(m\) dimensional data to \(p\)
    dimensions such that \(p << m\).
  id: totrans-1242
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šç»´å°ºåº¦åˆ†æï¼ˆMDSï¼‰å°† \(m\) ç»´æ•°æ®æŠ•å½±åˆ° \(p\) ç»´ï¼Œä½¿å¾— \(p << m\)ã€‚
- en: while attempting to preserve the pairwise dissimilarity between the data samples
  id: totrans-1243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å°è¯•ä¿ç•™æ•°æ®æ ·æœ¬ä¹‹é—´çš„æˆå¯¹ç›¸ä¼¼åº¦çš„åŒæ—¶
- en: ideally we are able to project to \(p=2\) to easily explore the relationships
    between the samples
  id: totrans-1244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬èƒ½å¤ŸæŠ•å½±åˆ° \(p=2\) ä»¥è½»æ¾æ¢ç´¢æ ·æœ¬ä¹‹é—´çš„å…³ç³»ã€‚
- en: While principal component analysis (PCA) operates with the covariance matrix,
    multidimensional scaling operates with the distance or dissimilarity matrix. For
    multidimensional scaling,
  id: totrans-1245
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ä½¿ç”¨åæ–¹å·®çŸ©é˜µæ—¶ï¼Œå¤šç»´å°ºåº¦åˆ†æä½¿ç”¨è·ç¦»æˆ–ç›¸ä¼¼åº¦çŸ©é˜µã€‚å¯¹äºå¤šç»´å°ºåº¦åˆ†æï¼Œ
- en: you donâ€™t need to know the actual feature values, just the distance or dissimilarity
    between the samples
  id: totrans-1246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ ä¸éœ€è¦çŸ¥é“å®é™…çš„ç‰¹å¾å€¼ï¼Œåªéœ€è¦çŸ¥é“æ ·æœ¬ä¹‹é—´çš„è·ç¦»æˆ–ç›¸ä¼¼åº¦
- en: as with any distance in feature space, we consider feature standardization to
    ensure that features with larger variance do not dominate the calculation
  id: totrans-1247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°±åƒç‰¹å¾ç©ºé—´ä¸­çš„ä»»ä½•è·ç¦»ä¸€æ ·ï¼Œæˆ‘ä»¬è€ƒè™‘ç‰¹å¾æ ‡å‡†åŒ–ä»¥ç¡®ä¿å…·æœ‰è¾ƒå¤§æ–¹å·®çš„ç‰¹å¾ä¸ä¼šä¸»å¯¼è®¡ç®—ã€‚
- en: we may work with a variety of dissimilarity measures
  id: totrans-1248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å„ç§ç›¸ä¼¼åº¦åº¦é‡
- en: Comparison between multidimensional scaling and principal component analysis,
  id: totrans-1249
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šç»´å°ºåº¦åˆ†æä¸ä¸»æˆåˆ†åˆ†æçš„æ¯”è¾ƒï¼Œ
- en: principal component analysis takes the covariance matrix (\(m \times m\)) between
    all the features and finds the linear, orthogonal rotation such that the *variance
    is maximized* over the ordered principle components
  id: totrans-1250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰é€šè¿‡æ‰€æœ‰ç‰¹å¾ä¹‹é—´çš„åæ–¹å·®çŸ©é˜µï¼ˆ\(m \times m\)ï¼‰æ‰¾åˆ°çº¿æ€§ã€æ­£äº¤æ—‹è½¬ï¼Œä½¿å¾—åœ¨æœ‰åºçš„ä¸»æˆåˆ†ä¸Š*æ–¹å·®æœ€å¤§åŒ–*ã€‚
- en: multidimensional scaling takes the matrix of the pairwise distances (\(n \times
    n\)) between all the samples in feature space and finds the nonlinear projection
    such that the *error in the pairwise distances is minimized*
  id: totrans-1251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šç»´å°ºåº¦åˆ†æå°†ç‰¹å¾ç©ºé—´ä¸­æ‰€æœ‰æ ·æœ¬ä¹‹é—´çš„æˆå¯¹è·ç¦»çŸ©é˜µï¼ˆ\(n \times n\)ï¼‰æ‰¾åˆ°éçº¿æ€§æŠ•å½±ï¼Œä½¿å¾—*æˆå¯¹è·ç¦»è¯¯å·®æœ€å°åŒ–*ã€‚
- en: Some have suggest that visualizing data or models in a multidimensional scaling
    space is visualizing the space of uncertainty.
  id: totrans-1252
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº›äººè®¤ä¸ºåœ¨å¤šç»´å°ºåº¦ç©ºé—´ä¸­å¯è§†åŒ–æ•°æ®æˆ–æ¨¡å‹æ˜¯å¯è§†åŒ–ä¸ç¡®å®šæ€§ç©ºé—´ã€‚
- en: '**Naive Bayes**'
  id: totrans-1253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æœ´ç´ è´å¶æ–¯**'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): the application of the assumption
    of conditional independence to simplify the classification prediction problem
    from the perspective of Bayesian updating, based on the conditional probability
    of a category, \(k\), given \(n\) features, \(x_1, \dots , x_n\),'
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä»è´å¶æ–¯æ›´æ–°çš„è§’åº¦ï¼Œå°†æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾åº”ç”¨äºç®€åŒ–åˆ†ç±»é¢„æµ‹é—®é¢˜ï¼ŒåŸºäºç»™å®š
    \(n\) ä¸ªç‰¹å¾ \(x_1, \dots , x_n\) çš„ç±»åˆ« \(k\) çš„æ¡ä»¶æ¦‚ç‡ï¼Œ'
- en: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3 | x_4,
    \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n} | C_k) P(C_k) \]
  id: totrans-1255
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3 | x_4,
    \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n} | C_k) P(C_k) \]
- en: The likelihood, conditional probability with the joint conditional is difficult,
    likely impossible to calculate. It requires information about the joint relationship
    between \(x_1, \dots , x_n\) features. As \(n\) increases this requires a lot
    of data to inform the joint distribution.
  id: totrans-1256
  prefs: []
  type: TYPE_NORMAL
  zh: è”åˆæ¡ä»¶æ¦‚ç‡çš„ä¼¼ç„¶ï¼Œå³æ¡ä»¶æ¦‚ç‡ï¼Œéš¾ä»¥è®¡ç®—ï¼Œå¯èƒ½æ— æ³•è®¡ç®—ã€‚å®ƒéœ€è¦å…³äº \(x_1, \dots , x_n\) ç‰¹å¾ä¹‹é—´è”åˆå…³ç³»çš„ä¿¡æ¯ã€‚éšç€ \(n\)
    çš„å¢åŠ ï¼Œè¿™éœ€è¦å¤§é‡æ•°æ®æ¥å‘ŠçŸ¥è”åˆåˆ†å¸ƒã€‚
- en: With the naive Bayes approach we make the â€˜naiveâ€™ assumption that the features
    are all *conditionally independent**. This entails,
  id: totrans-1257
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ´ç´ è´å¶æ–¯æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬åšå‡ºâ€œæœ´ç´ â€çš„å‡è®¾ï¼Œå³ç‰¹å¾éƒ½æ˜¯**æ¡ä»¶ç‹¬ç«‹çš„**ã€‚è¿™åŒ…æ‹¬ï¼Œ
- en: \[ P(x_i | x_{i+1}, \ldots , x_n, C_k) = P(x_i | C_k) \]
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_i | x_{i+1}, \ldots , x_n, C_k) = P(x_i | C_k) \]
- en: for all \(i = 1, \ldots, n\) features.
  id: totrans-1259
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰ \(i = 1, \ldots, n\) ç‰¹å¾ã€‚
- en: 'We can now solve for the needed conditional probability as:'
  id: totrans-1260
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥è§£å‡ºæ‰€éœ€çš„æ¡ä»¶æ¦‚ç‡å¦‚ä¸‹ï¼š
- en: \[ P(C_k | x_1, \dots , x_n) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i | C_k)}{P(x_1,
    \dots , x_n)} \]
  id: totrans-1261
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i | C_k)}{P(x_1,
    \dots , x_n)} \]
- en: We only need the prior, \(P(C_k)\), and a set of conditionals, \(P(x_i | C_k)\),
    for all predictor features, \(i = 1,\ldots,n\) and all categories, \(k = 1,\ldots,K\).
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€è¦å…ˆéªŒæ¦‚ç‡ \(P(C_k)\) å’Œä¸€ç»„æ¡ä»¶æ¦‚ç‡ \(P(x_i | C_k)\)ï¼Œå¯¹äºæ‰€æœ‰é¢„æµ‹ç‰¹å¾ \(i = 1,\ldots,n\) å’Œæ‰€æœ‰ç±»åˆ«
    \(k = 1,\ldots,K\)ã€‚
- en: The evidence term, \(P(x_1, \dots , x_n)\), is only based on the features \(x_1,
    \dots , x_n\); therefore, is a constant over the categories \(k = 1,\ldots,n\).
  id: totrans-1263
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ®é¡¹ \(P(x_1, \dots , x_n)\) ä»…åŸºäºç‰¹å¾ \(x_1, \dots , x_n\)ï¼›å› æ­¤ï¼Œåœ¨ç±»åˆ« \(k = 1,\ldots,n\)
    ä¸Šæ˜¯å¸¸æ•°ã€‚
- en: it ensures closure - probabilities over all categories sum to one
  id: totrans-1264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒç¡®ä¿äº†å°é—­æ€§ - æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œä¸º 1
- en: we simply standardize the numerators to sum to one over the categories
  id: totrans-1265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€å°†åˆ†å­æ ‡å‡†åŒ–ï¼Œä½¿å…¶åœ¨ç±»åˆ«ä¸Šæ±‚å’Œä¸º 1
- en: 'The naive Bayes approach is:'
  id: totrans-1266
  prefs: []
  type: TYPE_NORMAL
  zh: æœ´ç´ è´å¶æ–¯æ–¹æ³•æ˜¯ï¼š
- en: simple to understand, builds on fundamental Bayesian statistics
  id: totrans-1267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®¹æ˜“ç†è§£ï¼Œå»ºç«‹åœ¨åŸºæœ¬çš„è´å¶æ–¯ç»Ÿè®¡åŸºç¡€ä¹‹ä¸Š
- en: practical even with small datasets since with the conditional independence we
    only need to estimate simple conditional distributions
  id: totrans-1268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å³ä½¿æ•°æ®é›†è¾ƒå°ï¼Œä¹Ÿå…·æœ‰å®ç”¨æ€§ï¼Œå› ä¸ºæœ‰äº†æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œæˆ‘ä»¬åªéœ€è¦ä¼°è®¡ç®€å•çš„æ¡ä»¶åˆ†å¸ƒ
- en: '**ndarray**'
  id: totrans-1269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ndarray**'
- en: 'Machine Learning Workflow Construction and Coding: Numpyâ€™s convenient class
    for working with grids, exhaustive, regularly spaced data over 2D or 3D, representing
    maps and models, due to,'
  id: totrans-1270
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šNumpy æä¾›çš„æ–¹ä¾¿ç±»ï¼Œç”¨äºå¤„ç†äºŒç»´æˆ–ä¸‰ç»´ä¸Šçš„ç½‘æ ¼ã€ç©·ä¸¾ã€è§„åˆ™é—´éš”æ•°æ®ï¼Œè¡¨ç¤ºåœ°å›¾å’Œæ¨¡å‹ï¼Œå› ä¸ºï¼Œ
- en: convenient data structure to store, access, manipulate gridded data
  id: totrans-1271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹ä¾¿çš„æ•°æ®ç»“æ„æ¥å­˜å‚¨ã€è®¿é—®ã€æ“ä½œç½‘æ ¼æ•°æ®
- en: built in methods to load from a variety of file types, Python classes
  id: totrans-1272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®ä»å„ç§æ–‡ä»¶ç±»å‹åŠ è½½çš„æ–¹æ³•ï¼ŒPython ç±»
- en: built in methods to calculate multidimensional summary statistics
  id: totrans-1273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®è®¡ç®—å¤šç»´æ±‡æ€»ç»Ÿè®¡çš„æ–¹æ³•
- en: built in methods for data queries, filters
  id: totrans-1274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ•°æ®æŸ¥è¯¢ã€è¿‡æ»¤å™¨æ–¹æ³•
- en: built in methods for data manipulation, cleaning, reformatting
  id: totrans-1275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ•°æ®æ“ä½œã€æ¸…ç†ã€é‡æ–°æ ¼å¼åŒ–æ–¹æ³•
- en: built in attributes to store information about the nD array, for example, size
    and shape
  id: totrans-1276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®å±æ€§ç”¨äºå­˜å‚¨å…³äº nD æ•°ç»„çš„ä¿¡æ¯ï¼Œä¾‹å¦‚å¤§å°å’Œå½¢çŠ¶
- en: '**Nonparametric Model**'
  id: totrans-1277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éå‚æ•°æ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a model that makes
    no assumption about the functional form, shape of the natural setting.'
  id: totrans-1278
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªä¸å‡è®¾è‡ªç„¶è®¾ç½®å‡½æ•°å½¢å¼ã€å½¢çŠ¶çš„æ¨¡å‹ã€‚'
- en: learns the shape from the training data, more flexibility to fit a variety of
    shapes for natural systems
  id: totrans-1279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ å½¢çŠ¶ï¼Œæ›´çµæ´»åœ°é€‚åº”è‡ªç„¶ç³»ç»Ÿçš„å„ç§å½¢çŠ¶
- en: less risk that the model is a poor fit for the natural settings than with parametric
    models
  id: totrans-1280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å‚æ•°æ¨¡å‹ç›¸æ¯”ï¼Œæ¨¡å‹ä¸è‡ªç„¶è®¾ç½®ä¸åŒ¹é…çš„é£é™©æ›´ä½
- en: Typically need a lot more data for an accurate estimate of nonparametric models,
  id: totrans-1281
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸éœ€è¦æ›´å¤šçš„æ•°æ®æ¥å‡†ç¡®ä¼°è®¡éå‚æ•°æ¨¡å‹ï¼Œ
- en: nonparametric often have many trainable parameters, i.e., nonparametric models
    are actually parametric rich!
  id: totrans-1282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éå‚æ•°æ¨¡å‹é€šå¸¸å…·æœ‰è®¸å¤šå¯è®­ç»ƒå‚æ•°ï¼Œå³éå‚æ•°æ¨¡å‹å®é™…ä¸Šæ˜¯å‚æ•°ä¸°å¯Œçš„ï¼
- en: '**Norm**'
  id: totrans-1283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**èŒƒæ•°**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): norm of a vector
    maps vector values to a summary measure \([ğŸ,\infty)\), that indicates size or
    length.'
  id: totrans-1284
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šå‘é‡çš„èŒƒæ•°å°†å‘é‡å€¼æ˜ å°„åˆ°è¡¨ç¤ºå¤§å°æˆ–é•¿åº¦çš„æ±‡æ€»åº¦é‡ \([ğŸ,\infty)\)ï¼Œ'
- en: To train our models to training data, we require a single summary measure of
    mismatch with the training data, training error. The error is observed at each
    training data location,
  id: totrans-1285
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ä»¥è®­ç»ƒæ•°æ®ä¸ºç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå•ä¸€çš„æ€»åº¦é‡æ¥è¡¡é‡ä¸è®­ç»ƒæ•°æ®çš„å¤±é…ï¼Œå³è®­ç»ƒè¯¯å·®ã€‚è¯¯å·®åœ¨æ¯ä¸ªè®­ç»ƒæ•°æ®ä½ç½®è§‚å¯Ÿåˆ°ï¼Œ
- en: \[ \Delta y_i = y_i - \hat{y}_i, \quad \forall \quad i = 1,\ldots,n \]
  id: totrans-1286
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Delta y_i = y_i - \hat{y}_i, \quad \forall \quad i = 1,\ldots,n \]
- en: as an error vector. We need a single value to summarize over all training data,
    that we can minimize!
  id: totrans-1287
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºè¯¯å·®å‘é‡ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå•ä¸€å€¼æ¥æ€»ç»“æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥æœ€å°åŒ–å®ƒï¼
- en: '**Normalization**'
  id: totrans-1288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å½’ä¸€åŒ–**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    distribution rescaling that can be thought of as shifting, and stretching or squeezing
    of a univariate distribution (e.g., *histogram*) to a minimum of 0.0 and a maximum
    of 1.0.'
  id: totrans-1289
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§åˆ†å¸ƒé‡ç¼©æ”¾ï¼Œå¯ä»¥çœ‹ä½œæ˜¯å¹³ç§»ã€æ‹‰ä¼¸æˆ–å‹ç¼©ä¸€å…ƒåˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œ*ç›´æ–¹å›¾*ï¼‰åˆ°æœ€å°å€¼ä¸º
    0.0 å’Œæœ€å¤§å€¼ä¸º 1.0ã€‚'
- en: this is a shift and stretch / squeeze of the original property distribution
    assumes no shape change, rank preserving
  id: totrans-1290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹åŸå§‹å±æ€§åˆ†å¸ƒçš„å¹³ç§»å’Œæ‹‰ä¼¸/å‹ç¼©ï¼Œå‡è®¾æ²¡æœ‰å½¢çŠ¶å˜åŒ–ï¼Œä¿æŒæ’å
- en: \[ y_i = \frac{x_i - min(x)}{max(x) - min(x)}, \quad \forall \quad i, \ldots,
    n \]
  id: totrans-1291
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{x_i - min(x)}{max(x) - min(x)}, \quad \forall \quad i, \ldots,
    n \]
- en: 'Methods that require standardization and min/max normalization:'
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦è¿›è¡Œæ ‡å‡†åŒ–å’Œæœ€å°/æœ€å¤§å½’ä¸€åŒ–çš„æ–¹æ³•ï¼š
- en: k-means clustering, k-nearest neighbour regression
  id: totrans-1293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-means èšç±»ï¼Œk è¿‘é‚»å›å½’
- en: \(\beta\) coefficientâ€™s for feature ranking
  id: totrans-1294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾æ’åºçš„ \(\beta\) ç³»æ•°
- en: artificial neural networks forward transform of predictor features and back
    transform of response features to improve activation function sensitivity
  id: totrans-1295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äººå·¥ç¥ç»ç½‘ç»œå¯¹é¢„æµ‹ç‰¹å¾çš„å‰å‘è½¬æ¢å’Œå¯¹å“åº”ç‰¹å¾çš„åå‘è½¬æ¢ï¼Œä»¥æé«˜æ¿€æ´»å‡½æ•°çš„æ•æ„Ÿæ€§
- en: '**Normalized Histogram**'
  id: totrans-1296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å½’ä¸€åŒ–ç›´æ–¹å›¾**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): is a representation
    of the univariate statistical distribution with a plot of probability over an
    exhaustive set of bins over the range of possible values. These are the steps
    to build a normalized histogram,'
  id: totrans-1297
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šæ˜¯ä½¿ç”¨æ¦‚ç‡å›¾è¡¨ç¤ºå•å˜é‡ç»Ÿè®¡åˆ†å¸ƒï¼Œè¯¥å›¾åœ¨å¯èƒ½çš„å€¼èŒƒå›´å†…å¯¹ç©·ä¸¾é›†çš„æ¯ä¸ªåˆ†ç®±è¿›è¡Œæ¦‚ç‡ç»˜åˆ¶ã€‚è¿™äº›æ˜¯æ„å»ºå½’ä¸€åŒ–ç›´æ–¹å›¾çš„æ­¥éª¤ï¼Œ'
- en: 'Divide the continuous feature range of possible values into \(K\) equal size
    bins, \(\delta x\):'
  id: totrans-1298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å¯èƒ½çš„è¿ç»­ç‰¹å¾å–å€¼èŒƒå›´åˆ’åˆ†ä¸º \(K\) ä¸ªç­‰å¤§å°çš„åˆ†ç®±ï¼Œ\(\delta x\)ï¼š
- en: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
  id: totrans-1299
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
- en: or use available categories for categorical features.
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–ä½¿ç”¨å¯ç”¨çš„ç±»åˆ«å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œåˆ†ç±»ã€‚
- en: Count the number of samples (frequency) in each bin, \(n_k\), \(\forall k=1,\ldots,K\)
    and divide each by the total number of data, \(n\), to calculate the probability
    of each bin,
  id: totrans-1301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯ä¸ªåˆ†ç®±ä¸­æ ·æœ¬çš„æ•°é‡ï¼ˆé¢‘ç‡ï¼‰\(n_k\)ï¼Œ\(\forall k=1,\ldots,K\)ï¼Œå¹¶å°†å…¶é™¤ä»¥æ€»æ•°æ®é‡ \(n\)ï¼Œä»¥è®¡ç®—æ¯ä¸ªåˆ†ç®±çš„æ¦‚ç‡ï¼Œ
- en: \[ p_k = \frac{n_k}{n}, \forall \quad k = 1,\ldots,L \]
  id: totrans-1302
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p_k = \frac{n_k}{n}, \forall \quad k = 1,\ldots,L \]
- en: Plot the probability vs. the bin label (use bin centroid if continuous)
  id: totrans-1303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æ¦‚ç‡ä¸åˆ†ç®±æ ‡ç­¾çš„å…³ç³»å›¾ï¼ˆå¦‚æœè¿ç»­åˆ™ä½¿ç”¨åˆ†ç®±ä¸­å¿ƒç‚¹ï¼‰
- en: Note, normalized histograms are typically plotted as a bar chart.
  id: totrans-1304
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå½’ä¸€åŒ–ç›´æ–¹å›¾é€šå¸¸ä»¥æ¡å½¢å›¾çš„å½¢å¼ç»˜åˆ¶ã€‚
- en: '**One Hot Encoding**'
  id: totrans-1305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‹¬çƒ­ç¼–ç **'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): bin
    the range of the feature into K bins, then for each sample assignment of a value
    of 1 if the sample is within a bin and 0 if outsize the bin'
  id: totrans-1306
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šå°†ç‰¹å¾çš„å–å€¼èŒƒå›´åˆ†ç®±ä¸º K ä¸ªï¼Œç„¶åå¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œå¦‚æœæ ·æœ¬åœ¨åˆ†ç®±å†…åˆ™åˆ†é…å€¼ä¸º
    1ï¼Œå¦‚æœä¸åœ¨åˆ†ç®±å†…åˆ™åˆ†é…å€¼ä¸º 0'
- en: binning strategies include uniform width bins (uniform) and uniform number of
    data in each bin (quantile)
  id: totrans-1307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç®±ç­–ç•¥åŒ…æ‹¬å‡åŒ€å®½åº¦åˆ†ç®±ï¼ˆå‡åŒ€ï¼‰å’Œæ¯ä¸ªåˆ†ç®±ä¸­å‡åŒ€æ•°é‡çš„æ•°æ®ï¼ˆåˆ†ä½æ•°ï¼‰
- en: also known as K bins discretization
  id: totrans-1308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿç§°ä¸º K ä¸ªåˆ†ç®±ç¦»æ•£åŒ–
- en: Methods that require K bins discretization,
  id: totrans-1309
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦è¿›è¡Œ K ä¸ªåˆ†ç®±ç¦»æ•£åŒ–çš„æ–¹æ³•ï¼Œ
- en: basis expansion to work in a higher dimensional space
  id: totrans-1310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ›´é«˜ç»´ç©ºé—´ä¸­è¿›è¡ŒåŸºå‡½æ•°å±•å¼€
- en: discretization of continuous features to categorical features for categorical
    methods such as naive Bayes classifier
  id: totrans-1311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿ç»­ç‰¹å¾çš„å–å€¼èŒƒå›´ç¦»æ•£åŒ–ä¸ºåˆ†ç±»ç‰¹å¾ï¼Œç”¨äºå¦‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ç­‰åˆ†ç±»æ–¹æ³•
- en: histogram construction and Chi-square test for difference in distributions
  id: totrans-1312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºç›´æ–¹å›¾å’Œç”¨äºåˆ†å¸ƒå·®å¼‚çš„å¡æ–¹æ£€éªŒ
- en: mutual information binning
  id: totrans-1313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº’ä¿¡æ¯åˆ†ç®±
- en: '**Out-of-Bag Sample**'
  id: totrans-1314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¢‹å¤–æ ·æœ¬**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): with
    bootstrap resampling of the data, it can be shown that about \(\frac{2}{3}\) of
    the data will be included (in expectation). For bagging-based ensemble prediction
    models,'
  id: totrans-1315
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¢‹è£…æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šé€šè¿‡æ•°æ®é‡é‡‡æ ·ï¼Œå¯ä»¥è¯æ˜å¤§çº¦ \(\frac{2}{3}\)
    çš„æ•°æ®å°†è¢«åŒ…æ‹¬ï¼ˆæœŸæœ›ä¸­ï¼‰ã€‚å¯¹äºåŸºäºè¢‹è£…çš„é›†æˆé¢„æµ‹æ¨¡å‹ï¼Œ'
- en: therefore are \(\frac{1}{3}\) of the data (in expectation) unused in training
    each model realization, these are know as out-of-bag observations
  id: totrans-1316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ¯ä¸ªæ¨¡å‹å®ç°ä¸­å¤§çº¦æœ‰ \(\frac{1}{3}\) çš„æ•°æ®ï¼ˆæœŸæœ›ä¸­ï¼‰æœªç”¨äºè®­ç»ƒï¼Œè¿™äº›è¢«ç§°ä¸ºè¢‹å¤–è§‚æµ‹
- en: for every response feature observation, \(y_{\alpha}\), there are \(\frac{B}{3}\)
    out-of-bag predictions, \(y^{*,b}_{\alpha}\)
  id: totrans-1317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªå“åº”ç‰¹å¾è§‚æµ‹å€¼ \(y_{\alpha}\)ï¼Œæœ‰ \(\frac{B}{3}\) ä¸ªè¢‹å¤–é¢„æµ‹ï¼Œ\(y^{*,b}_{\alpha}\)
- en: we can aggregate this ensemble of prediction realizations, average for regression
    or mode for classification, to calculate a single out-of-bag prediction, \(y^{*}_{\alpha}
    = \sum_{\alpha = 1}^{\frac{B}{3}} y^{*,b}_{\alpha}\)
  id: totrans-1318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ±‡æ€»è¿™äº›é¢„æµ‹å®ç°çš„æ•´ä½“ï¼Œå¯¹äºå›å½’å–å¹³å‡å€¼ï¼Œå¯¹äºåˆ†ç±»å–ä¼—æ•°ï¼Œä»¥è®¡ç®—å•ä¸ªè¢‹å¤–é¢„æµ‹ï¼Œ\(y^{*}_{\alpha} = \sum_{\alpha =
    1}^{\frac{B}{3}} y^{*,b}_{\alpha}\)
- en: from these single out-of-bag predictions over all data, the out-of-bag mean
    square error (MSE) is calculated as,
  id: totrans-1319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ‰€æœ‰æ•°æ®ä¸­çš„è¿™äº›å•ä¸ªè¢‹å¤–é¢„æµ‹ä¸­ï¼Œè®¡ç®—è¢‹å¤–å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œ
- en: \[ MSE_{OOB} = \sum_{\alpha = 1}^{\frac{B}{3}} \left[ y^{*}_{\alpha} - y_{\alpha}
    \right]^2 \]
  id: totrans-1320
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MSE_{OOB} = \sum_{\alpha = 1}^{\frac{B}{3}} \left[ y^{*}_{\alpha} - y_{\alpha}
    \right]^2 \]
- en: For bagging-based ensemble predictive machine learning, there is no need to
    perform training and testing splits, hyperparameter tuning can be applied with
    out-of-bag MSE.
  id: totrans-1321
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåŸºäºè¢‹è£…çš„é›†æˆé¢„æµ‹æœºå™¨å­¦ä¹ ï¼Œä¸éœ€è¦æ‰§è¡Œè®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²ï¼Œå¯ä»¥ä½¿ç”¨è¢‹å¤–å‡æ–¹è¯¯å·®è¿›è¡Œè¶…å‚æ•°è°ƒæ•´ã€‚
- en: this is equivalent to random train and test split that may not be fair, same
    difficulty as the planned use of the model
  id: totrans-1322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç›¸å½“äºéšæœºè®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²ï¼Œå¯èƒ½ä¸å…¬å¹³ï¼Œéš¾åº¦ä¸è®¡åˆ’ä½¿ç”¨æ¨¡å‹ç›¸åŒ
- en: this freezes the test proportion at about \(\frac{1}{3}\)
  id: totrans-1323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™å°†æµ‹è¯•æ¯”ä¾‹å†»ç»“åœ¨å¤§çº¦ \(\frac{1}{3}\)
- en: '**Overfit Model**'
  id: totrans-1324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿‡æ‹Ÿåˆæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a machine learning
    model that is fit to data noise or data idiosyncrasies'
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€‚åˆæ•°æ®å™ªå£°æˆ–æ•°æ®ç‰¹æ®Šæ€§çš„æœºå™¨å­¦ä¹ æ¨¡å‹'
- en: increased complexity will generally decrease error with respect to the training
    dataset but, may result in increase error with testing data
  id: totrans-1326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ çš„å¤æ‚æ€§é€šå¸¸ä¼šåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šé™ä½è¯¯å·®ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´æµ‹è¯•æ•°æ®ä¸Šçš„è¯¯å·®å¢åŠ 
- en: over the region of model complexity with rising testing error and falling training
    error
  id: totrans-1327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¨¡å‹å¤æ‚æ€§ä¸æµ‹è¯•è¯¯å·®ä¸Šå‡ã€è®­ç»ƒè¯¯å·®ä¸‹é™çš„åŒºåŸŸ
- en: Issues of an overfit machine learning model,
  id: totrans-1328
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‡æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„é—®é¢˜ï¼Œ
- en: more model complexity and flexibility than can be justified with the available
    data, data accuracy, frequency and coverage
  id: totrans-1329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹å¤æ‚æ€§å’Œçµæ´»æ€§è¶…è¿‡äº†å¯ç”¨æ•°æ®çš„åˆç†æ€§ï¼Œæ•°æ®å‡†ç¡®æ€§ï¼Œé¢‘ç‡å’Œè¦†ç›–èŒƒå›´
- en: high accuracy in training, but low accuracy in testing representing real-world
    use away from training data cases, indicating poor ability of the model to generalize
  id: totrans-1330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ—¶é«˜ç²¾åº¦ï¼Œä½†åœ¨æµ‹è¯•æ—¶ç²¾åº¦ä½ï¼Œè¡¨ç¤ºæ¨¡å‹åœ¨è¿œç¦»è®­ç»ƒæ•°æ®æ¡ˆä¾‹çš„çœŸå®ä¸–ç•Œä½¿ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®
- en: '**Parameters** (statistics)'
  id: totrans-1331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚æ•°**ï¼ˆç»Ÿè®¡å­¦ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a summary measure
    of a population'
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¯¹æ€»ä½“çš„ä¸€ä¸ªæ¦‚æ‹¬æ€§åº¦é‡'
- en: for example, population mean, population standard deviation
  id: totrans-1333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ€»ä½“å‡å€¼ï¼Œæ€»ä½“æ ‡å‡†å·®
- en: We very rarely have access to actual population parameters, in general we infer
    population parameters with available sample statistics
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾ˆå°‘æœ‰æœºä¼šè®¿é—®å®é™…çš„æ€»ä½“å‚æ•°ï¼Œé€šå¸¸æˆ‘ä»¬ä½¿ç”¨å¯ç”¨çš„æ ·æœ¬ç»Ÿè®¡é‡æ¥æ¨æ–­æ€»ä½“å‚æ•°
- en: '**Parameters** (machine learning)'
  id: totrans-1335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚æ•°**ï¼ˆæœºå™¨å­¦ä¹ ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): trainable coefficients
    for a machine learning model that control the fit to the training data'
  id: totrans-1336
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ç”¨äºæ§åˆ¶å¯¹è®­ç»ƒæ•°æ®æ‹Ÿåˆçš„å¯è®­ç»ƒç³»æ•°'
- en: model parameters are calculated by optimization to minimize error over the training
    data through, analytical solution, or iterative solution, e.g., gradient descent
    optimization
  id: totrans-1337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹å‚æ•°é€šè¿‡ä¼˜åŒ–è®¡ç®—ï¼Œä»¥æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®ï¼Œé€šè¿‡è§£æè§£æˆ–è¿­ä»£è§£ï¼Œä¾‹å¦‚æ¢¯åº¦ä¸‹é™ä¼˜åŒ–
- en: '**Parametric Model**'
  id: totrans-1338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚æ•°æ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a model that makes
    an assumption about the functional form, shape of the natural system.'
  id: totrans-1339
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¯¹è‡ªç„¶ç³»ç»ŸåŠŸèƒ½å½¢å¼ã€å½¢çŠ¶åšå‡ºå‡è®¾çš„æ¨¡å‹'
- en: we gain simplicity and advantage of only a few parameters
  id: totrans-1340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è·å¾—äº†å‚æ•°è¾ƒå°‘çš„ç®€å•æ€§å’Œä¼˜åŠ¿
- en: for is a linear model we only have \(m+1\) model parameters
  id: totrans-1341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºçº¿æ€§æ¨¡å‹ï¼Œæˆ‘ä»¬åªæœ‰ \(m+1\) ä¸ªæ¨¡å‹å‚æ•°
- en: There is a risk that our model is quite different than the natural setting,
    resulting in a poor model, for example, a linear model applied to a nonlinear
    phenomenon.
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨ä¸€ç§é£é™©ï¼Œå³æˆ‘ä»¬çš„æ¨¡å‹ä¸è‡ªç„¶è®¾ç½®å¤§ç›¸å¾„åº­ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³ï¼Œä¾‹å¦‚ï¼Œå°†çº¿æ€§æ¨¡å‹åº”ç”¨äºéçº¿æ€§ç°è±¡ã€‚
- en: '**Partial Correlation Coefficient**'
  id: totrans-1343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åç›¸å…³ç³»æ•°**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): a method
    to calculate the correlation between \(ğ‘¿\) and \(ğ’€\) after controlling for the
    influence of \(ğ’_ğŸ,\ldots,ğ’_(ğ’âˆ’ğŸ)\) other features on both \(ğ‘¿\) and \(ğ‘Œ\). Note,
    I use \(m-2\) to account for \(X\) and \(Y\) removed.'
  id: totrans-1344
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šä¸€ç§åœ¨æ§åˆ¶ \(ğ’_ğŸ,\ldots,ğ’_(ğ’âˆ’ğŸ)\)
    å…¶ä»–ç‰¹å¾å¯¹ \(ğ‘¿\) å’Œ \(ğ‘Œ\) çš„å½±å“åï¼Œè®¡ç®— \(ğ‘¿\) å’Œ \(ğ‘Œ\) ä¹‹é—´ç›¸å…³æ€§çš„æ–¹æ³•ã€‚æ³¨æ„ï¼Œæˆ‘ä½¿ç”¨ \(m-2\) æ¥è€ƒè™‘ \(X\) å’Œ
    \(Y\) è¢«ç§»é™¤ã€‚'
- en: For \(\rho_(ğ‘‹,ğ‘Œ.ğ‘_1,â€¦,ğ‘_(ğ‘šâˆ’2) )\),
  id: totrans-1345
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº \(\rho_(ğ‘‹,ğ‘Œ.ğ‘_1,â€¦,ğ‘_(ğ‘šâˆ’2) )\),
- en: perform linear, least-squares regression to predict \(ğ‘¿\) from \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\).
    \(ğ‘¿\) is regressed on the predictors to calculate the estimate, \(ğ‘¿^âˆ—\).
  id: totrans-1346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œçº¿æ€§ã€æœ€å°äºŒä¹˜å›å½’ï¼Œä» \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\) é¢„æµ‹ \(ğ‘¿\)ã€‚\(ğ‘¿\) é€šè¿‡é¢„æµ‹å˜é‡è¿›è¡Œå›å½’ä»¥è®¡ç®—ä¼°è®¡å€¼ï¼Œ\(ğ‘¿^âˆ—\).
- en: perform linear, least-squares regression to predict \(ğ’€\) from \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\).
    \(ğ’€\) is regressed on the predictors to calculate the estimate, ğ’€^âˆ—
  id: totrans-1347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œçº¿æ€§ã€æœ€å°äºŒä¹˜å›å½’ï¼Œä» \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\) é¢„æµ‹ \(ğ’€\)ã€‚\(ğ’€\) é€šè¿‡é¢„æµ‹å˜é‡è¿›è¡Œå›å½’ä»¥è®¡ç®—ä¼°è®¡å€¼ï¼Œ\(ğ’€^âˆ—\)
- en: 'calculate the residuals in Step #1, \(ğ‘¿ âˆ’ ğ‘¿^âˆ—\), where \(ğ‘¿^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
    linear regression model'
  id: totrans-1348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'åœ¨æ­¥éª¤ #1 ä¸­è®¡ç®—æ®‹å·®ï¼Œ\(ğ‘¿ âˆ’ ğ‘¿^âˆ—\)ï¼Œå…¶ä¸­ \(ğ‘¿^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\)ï¼Œçº¿æ€§å›å½’æ¨¡å‹'
- en: 'calculate the residuals in Step #2, \(ğ’€ âˆ’ ğ’€^âˆ—\), where \(ğ’€^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
    linear regression model'
  id: totrans-1349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'åœ¨æ­¥éª¤ #2 ä¸­è®¡ç®—æ®‹å·®ï¼Œ\(ğ’€ âˆ’ ğ’€^âˆ—\)ï¼Œå…¶ä¸­ \(ğ’€^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\)ï¼Œçº¿æ€§å›å½’æ¨¡å‹'
- en: 'calculate the correlation coefficient between the residuals from Steps #3 and
    #4, \(\rho_{ğ‘¿ âˆ’ğ‘¿^âˆ—,ğ’€ âˆ’ ğ’€^âˆ—}\)'
  id: totrans-1350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'è®¡ç®—æ­¥éª¤ #3 å’Œ #4 çš„æ®‹å·®ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼Œ\(\rho_{ğ‘¿ âˆ’ğ‘¿^âˆ—,ğ’€ âˆ’ ğ’€^âˆ—}\)'
- en: Assumptions of Partial Correlation, for \(ğ†_(ğ‘¿,ğ’€.ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: åç›¸å…³çš„å‡è®¾ï¼Œå¯¹äº \(ğ†_(ğ‘¿,ğ’€.ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
- en: \(ğ‘¿,ğ’€,ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\) have linear relationships, i.e., all pairwise relationships
    are linear
  id: totrans-1352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(ğ‘¿,ğ’€,ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\) ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»ï¼Œå³æ‰€æœ‰æˆå¯¹å…³ç³»éƒ½æ˜¯çº¿æ€§çš„
- en: no outliers for any of the univariate distributions (univariate outliers) and
    pairwise relationships (bivariate outliers). Partial correlation is very sensitive
    to outliers like regular correlation.
  id: totrans-1353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºä»»ä½•å•å˜é‡åˆ†å¸ƒï¼ˆå•å˜é‡å¼‚å¸¸å€¼ï¼‰å’Œæˆå¯¹å…³ç³»ï¼ˆåŒå˜é‡å¼‚å¸¸å€¼ï¼‰éƒ½æ²¡æœ‰å¼‚å¸¸å€¼ã€‚åç›¸å…³å¯¹å¼‚å¸¸å€¼ï¼ˆå¦‚å¸¸è§„ç›¸å…³ï¼‰éå¸¸æ•æ„Ÿã€‚
- en: Gaussian distributed, univariate and pairwise bivariate distributions Gaussian
    distributed. Bivariate should be linearly related and homoscedastic.
  id: totrans-1354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜æ–¯åˆ†å¸ƒï¼Œå•å˜é‡å’Œæˆå¯¹çš„åŒå˜é‡åˆ†å¸ƒéƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒã€‚åŒå˜é‡åº”è¯¥æ˜¯çº¿æ€§ç›¸å…³çš„ï¼Œå¹¶ä¸”åŒæ–¹å·®ã€‚
- en: '**Partitional Clustering**'
  id: totrans-1355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ’åˆ†èšç±»**'
- en: 'Cluster Analysis: all cluster group assignments are determined at once, as
    opposed to an agglomerative hierarchical clustering method that starts with \(n\)
    clusters and then iteratively merges clusters into larger clusters'
  id: totrans-1356
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šæ‰€æœ‰èšç±»ç»„åˆ†é…ä¸€æ¬¡ç¡®å®šï¼Œè€Œä¸æ˜¯åƒå±‚æ¬¡èšç±»æ–¹æ³•é‚£æ ·ä» \(n\) ä¸ªèšç±»å¼€å§‹ï¼Œç„¶åè¿­ä»£åœ°å°†èšç±»åˆå¹¶æˆæ›´å¤§çš„èšç±»
- en: k-means clustering is partitional clustering, while the solution heuristic to
    find the solution is iterative, the solution is actually all at once
  id: totrans-1357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-means èšç±»æ˜¯åˆ’åˆ†èšç±»ï¼Œè€Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„å¯å‘å¼æ–¹æ³•æ˜¯è¿­ä»£çš„ï¼Œä½†å®é™…ä¸Šè§£å†³æ–¹æ¡ˆæ˜¯ä¸€ä¸‹å­å°±å®Œæˆçš„
- en: easy to update, for example, by modifying the prototype locations and recalculating
    the group assignments
  id: totrans-1358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®¹æ˜“æ›´æ–°ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡ä¿®æ”¹åŸå‹ä½ç½®å’Œé‡æ–°è®¡ç®—ç»„åˆ†é…
- en: '**Polygonal Declustering**'
  id: totrans-1359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤šè¾¹å½¢å»èšç±»**'
- en: 'Data Preparation: a declustering method to assign weights to spatial samples
    based on local sampling density, such that the weighted statistics are likely
    more representative of the population. Data weights are assigned so that,'
  id: totrans-1360
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§å»èšç±»æ–¹æ³•ï¼Œæ ¹æ®å±€éƒ¨é‡‡æ ·å¯†åº¦å¯¹ç©ºé—´æ ·æœ¬åˆ†é…æƒé‡ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚ä¸‹ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-1361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¯†é›†é‡‡æ ·åŒºåŸŸé‡‡æ ·çš„æ ·æœ¬æƒé‡è¾ƒä½
- en: samples in sparsely sampled areas receive more weight
  id: totrans-1362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç¨€ç–é‡‡æ ·åŒºåŸŸé‡‡æ ·çš„æ ·æœ¬æƒé‡è¾ƒé«˜
- en: 'Polygonal declustering proceeds as follows:'
  id: totrans-1363
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šè¾¹å½¢å»èšç±»æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š
- en: Split up the area of interest with Voronoi polygons. These are constructed by
    intersected perpendicular bisectors between adjacent data points. The polygons
    group the area of interest by nearest data point
  id: totrans-1364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Voronoi å¤šè¾¹å½¢åˆ’åˆ†æ„Ÿå…´è¶£çš„åŒºåŸŸã€‚è¿™äº›å¤šè¾¹å½¢æ˜¯é€šè¿‡ç›¸é‚»æ•°æ®ç‚¹ä¹‹é—´çš„å‚ç›´å¹³åˆ†çº¿çš„äº¤ç‚¹æ„å»ºçš„ã€‚å¤šè¾¹å½¢é€šè¿‡æœ€è¿‘çš„æ•°æ®ç‚¹å°†æ„Ÿå…´è¶£çš„åŒºåŸŸåˆ†ç»„
- en: Assign weight to each datum proportional to the area of the associated Voronoi
    polygon
  id: totrans-1365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ¯ä¸ªæ•°æ®ç‚¹çš„æƒé‡åˆ†é…ä¸ç›¸å…³ Voronoi å¤šè¾¹å½¢çš„é¢ç§¯æˆæ¯”ä¾‹
- en: \[ w(\bf{u}_j) = n \cdot \frac{A_j}{\sum_{j=1}^n} \]
  id: totrans-1366
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w(\bf{u}_j) = n \cdot \frac{A_j}{\sum_{j=1}^n} \]
- en: where \(w(\bf{u}_j)\) is the weight for the \(j\) data. Note, the sum of the
    weights is \(n\); therefore, \(w(\bf{u}_j)\) is nominal weight of 1.0, sample
    density if the data were equally spaced over the area of interest.
  id: totrans-1367
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(w(\bf{u}_j)\) æ˜¯ \(j\) æ•°æ®çš„æƒé‡ã€‚æ³¨æ„ï¼Œæƒé‡çš„æ€»å’Œæ˜¯ \(n\)ï¼›å› æ­¤ï¼Œ\(w(\bf{u}_j)\) æ˜¯åä¹‰æƒé‡1.0ï¼Œå¦‚æœæ•°æ®åœ¨æ„Ÿå…´è¶£åŒºåŸŸå†…å‡åŒ€åˆ†å¸ƒï¼Œåˆ™æ˜¯æ ·æœ¬å¯†åº¦ã€‚
- en: Here are some highlights for polygonal declustering,
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€äº›å…³äºå¤šè¾¹å½¢å»èšç±»çš„äº®ç‚¹ï¼Œ
- en: polygonal declustering is sensitive to the boundaries of the area of interest;
    therefore, the weights assigned to the data near the boundary of the area of interest
    may change radically as the area of interest is expanded or contracted
  id: totrans-1369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šè¾¹å½¢å»èšç±»å¯¹æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œæ•æ„Ÿï¼›å› æ­¤ï¼Œå½“æ„Ÿå…´è¶£åŒºåŸŸæ‰©å±•æˆ–æ”¶ç¼©æ—¶ï¼Œåˆ†é…ç»™æ„Ÿå…´è¶£åŒºåŸŸè¾¹ç•Œé™„è¿‘æ•°æ®çš„æƒé‡å¯èƒ½ä¼šå‘ç”Ÿæ ¹æœ¬æ€§çš„å˜åŒ–
- en: polygonal declustering is the same as the Theissen polygon method for calculation
    of precipitation averages developed by Afred H. Thiessen in 1911, []
  id: totrans-1370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šè¾¹å½¢å»èšç±»ä¸1911å¹´ç”±é˜¿å°”å¼—é›·å¾·Â·HÂ·å¡æ£®æ–¯ï¼ˆAfred H. Thiessenï¼‰å¼€å‘çš„ç”¨äºè®¡ç®—é™æ°´å¹³å‡å€¼çš„å¡æ£®æ–¯å¤šè¾¹å½¢æ–¹æ³•ç›¸åŒ []
- en: '**Polynomial Regression**'
  id: totrans-1371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤šé¡¹å¼å›å½’**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): application
    of polynomial basis expansion to the predictor features before linear regression,'
  id: totrans-1372
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šåœ¨çº¿æ€§å›å½’ä¹‹å‰å°†å¤šé¡¹å¼åŸºç¡€æ‰©å±•åº”ç”¨äºé¢„æµ‹ç‰¹å¾ï¼Œ'
- en: \[ y = \sum_{l=1}^{k} \sum_{j=1}^{m} \beta_{j,l} h_l (X_j) + \beta_0 \]
  id: totrans-1373
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \sum_{l=1}^{k} \sum_{j=1}^{m} \beta_{j,l} h_l (X_j) + \beta_0 \]
- en: where the h transforms over training data, \(ğ‘–=1,\ldots,n\),
  id: totrans-1374
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(h\) åœ¨è®­ç»ƒæ•°æ®ä¸Šè½¬æ¢ï¼Œ\(ğ‘–=1,\ldots,n\)ï¼Œ
- en: \[ h_1(x_i) = x_i, \quad h_2(x_i) = x_i^2, \quad h_3(x_i) = x_i^3, \quad h_4(x_i)
    = x_i^4, \dots, h_k(x_i) = x_i^k \]
  id: totrans-1375
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_1(x_i) = x_i, \quad h_2(x_i) = x_i^2, \quad h_3(x_i) = x_i^3, \quad h_4(x_i)
    = x_i^4, \dots, h_k(x_i) = x_i^k \]
- en: up to the specified order \(ğ‘˜\).
  id: totrans-1376
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¤šåˆ°æŒ‡å®šçš„é˜¶æ•° \(ğ‘˜\).
- en: For example, with a single predictor feature, \(ğ‘š = 1\), up to the \(4^{th}\)
    order,
  id: totrans-1377
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¯¹äºå•ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œ\(ğ‘š = 1\)ï¼Œæœ€é«˜åˆ° \(4^{th}\) é˜¶ï¼Œ
- en: \[ y = \beta_{1,1} X + \beta_{1,2} X^2 + \beta_{1,3} X^3 + \beta_{1,4} X^4 +
    \beta_0 \]
  id: totrans-1378
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \beta_{1,1} X + \beta_{1,2} X^2 + \beta_{1,3} X^3 + \beta_{1,4} X^4 +
    \beta_0 \]
- en: After the \(ğ’‰_ğ’\), \(ğ‘™=1,\ldots,ğ‘˜\) transforms, over the \(ğ‘—=1,\dots,ğ‘š\) predictor
    features we have the same linear equation and the ability to utilize the previously
    discussed analytical solution.
  id: totrans-1379
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ \(ğ’‰_ğ’\)ï¼Œ\(ğ‘™=1,\ldots,ğ‘˜\) è½¬æ¢ä¹‹åï¼Œåœ¨ \(ğ‘—=1,\dots,ğ‘š\) é¢„æµ‹ç‰¹å¾ä¸Šï¼Œæˆ‘ä»¬æœ‰ç›¸åŒçš„çº¿æ€§æ–¹ç¨‹å’Œåˆ©ç”¨å…ˆå‰è®¨è®ºçš„è§£æè§£çš„èƒ½åŠ›ã€‚
- en: we are assuming linearity after application of our basis expansion.
  id: totrans-1380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡è®¾åœ¨åº”ç”¨æˆ‘ä»¬çš„åŸºç¡€æ‰©å±•ä¹‹åçº¿æ€§ã€‚
- en: Now the model parameters, \(\beta_(ğ’,ğ’Š)\), relate to a transformed version of
    the initial predictor feature, \(ğ’‰_ğ’ (ğ‘¿_ğ’‹)\).
  id: totrans-1381
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¨¡å‹å‚æ•°ï¼Œ\(\beta_(ğ’,ğ’Š)\)ï¼Œä¸åˆå§‹é¢„æµ‹ç‰¹å¾çš„è½¬æ¢ç‰ˆæœ¬ç›¸å…³ï¼Œ\(ğ’‰_ğ’ (ğ‘¿_ğ’‹)\)ã€‚
- en: we lose the ability to interpret the coefficients, for example, what is ğ‘ğ‘’ğ‘Ÿğ‘šğ‘’ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦\(^4\)?
  id: totrans-1382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¤±å»äº†è§£é‡Šç³»æ•°çš„èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼Œä»€ä¹ˆæ˜¯ \(ğ‘ğ‘’ğ‘Ÿğ‘šğ‘’ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦\(^4\)**ï¼Ÿ
- en: generally, significantly higher model variance, i.e., may have unstable interpolation
    and especially extrapolation
  id: totrans-1383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ¨¡å‹æ–¹å·®æ˜¾è‘—æ›´é«˜ï¼Œå³å¯èƒ½å­˜åœ¨ä¸ç¨³å®šçš„æ’å€¼å’Œç‰¹åˆ«æ˜¯å¤–æ¨
- en: Polynomial regression model assumptions,
  id: totrans-1384
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’æ¨¡å‹å‡è®¾ï¼Œ
- en: '*error-free* - predictor features basis expansions are error free, not random
    variables'
  id: totrans-1385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ— è¯¯å·®** - é¢„æµ‹ç‰¹å¾çš„åŸºç¡€æ‰©å±•æ˜¯æ— è¯¯å·®çš„ï¼Œä¸æ˜¯éšæœºå˜é‡'
- en: '*constant variance* - error in response is constant over predictor(s) value'
  id: totrans-1386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¸¸æ•°æ–¹å·®** - å“åº”è¯¯å·®åœ¨é¢„æµ‹å€¼ä¸Šæ˜¯æ’å®šçš„'
- en: '*linearity* - response is linear combination of basis features'
  id: totrans-1387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**çº¿æ€§** - å“åº”æ˜¯åŸºç¡€ç‰¹å¾çš„çº¿æ€§ç»„åˆ'
- en: '*polynomial* - relationships between ğ‘‹ and Y is polynomial'
  id: totrans-1388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤šé¡¹å¼** - \(X\) å’Œ \(Y\) ä¹‹é—´çš„å…³ç³»æ˜¯å¤šé¡¹å¼'
- en: '*independence of error* - error in response are uncorrelated with each other'
  id: totrans-1389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¯¯å·®ç‹¬ç«‹æ€§** - å“åº”è¯¯å·®ä¹‹é—´æ˜¯ä¸ç›¸å…³çš„'
- en: no multicollinearity* - none of the basis feature expansions are linearly redundant
    with other features
  id: totrans-1390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å¤šé‡å…±çº¿æ€§* - åŸºç¡€ç‰¹å¾æ‰©å±•ä¸å…¶å®ƒç‰¹å¾ä¹‹é—´æ²¡æœ‰çº¿æ€§å†—ä½™
- en: '**Population**'
  id: totrans-1391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äººå£**'
- en: '[Probability Concepts](MachineLearning_probability.html): exhaustive, finite
    list of property of interest over area of interest.'
  id: totrans-1392
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåœ¨æ„Ÿå…´è¶£åŒºåŸŸå†…å¯¹æ„Ÿå…´è¶£å±æ€§çš„è¯¦å°½ã€æœ‰é™åˆ—è¡¨ã€‚'
- en: for example, exhaustive set of porosity measures at every location within a
    reservoir
  id: totrans-1393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨å‚¨å±‚å†…æ¯ä¸ªä½ç½®çš„å­”éš™ç‡æµ‹é‡çš„è¯¦å°½é›†åˆ
- en: Generally, the entire population is not generally accessible and we use a limited
    sample to make inference concerning the population
  id: totrans-1394
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ•´ä¸ªæ€»ä½“å¹¶ä¸æ€»æ˜¯å¯è®¿é—®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ‰é™çš„æ ·æœ¬æ¥å¯¹æ€»ä½“è¿›è¡Œæ¨æ–­
- en: '**Power Law Average**'
  id: totrans-1395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¹‚å¾‹å¹³å‡å€¼**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    general form for averaging based scale up, aggregation of smaller scale measures
    in a larger volume into a single value representative of the larger volume'
  id: totrans-1396
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šåŸºäºå¹³å‡çš„é€šç”¨å½¢å¼ï¼Œå°†è¾ƒå°å°ºåº¦åº¦é‡åœ¨è¾ƒå¤§ä½“ç§¯ä¸­çš„èšåˆæ±‡æ€»æˆä¸€ä¸ªä»£è¡¨è¾ƒå¤§ä½“ç§¯çš„å•ä¸€å€¼'
- en: \[ \overline{x}_p = \left(\frac{1}{n}\sum_{i=1}^n x_i^p \right)^{\frac{1}{p}}
    \]
  id: totrans-1397
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{x}_p = \left(\frac{1}{n}\sum_{i=1}^n x_i^p \right)^{\frac{1}{p}}
    \]
- en: useful to calculate effective permeability where flow is not parallel nor perpendicular
    to distinct permeability layers
  id: totrans-1398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰åŠ©äºè®¡ç®—æœ‰æ•ˆæ¸—é€ç‡ï¼Œå…¶ä¸­æµåŠ¨ä¸æ˜¯å¹³è¡Œä¹Ÿä¸æ˜¯å‚ç›´äºä¸åŒçš„æ¸—é€ç‡å±‚
- en: flow simulation may be applied to calibrate (calculate the appropriate power
    for power law averaging)
  id: totrans-1399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµä½“æ¨¡æ‹Ÿå¯ä»¥åº”ç”¨äºæ ¡å‡†ï¼ˆè®¡ç®—å¹‚å¾‹å¹³å‡çš„é€‚å½“åŠŸç‡ï¼‰
- en: '**Precision** (classification accuracy metric)'
  id: totrans-1400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç²¾ç¡®åº¦**ï¼ˆåˆ†ç±»å‡†ç¡®åº¦æŒ‡æ ‡ï¼‰'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a categorical classification
    prediction model measure of accuracy, a single summary metric for each \(k\) category
    from the confusion matrix.'
  id: totrans-1401
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ä¸ªåˆ†ç±»é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®åº¦åº¦é‡ï¼Œæ··æ·†çŸ©é˜µä¸­æ¯ä¸ª \(k\) ç±»åˆ«çš„å•ä¸€æ±‡æ€»æŒ‡æ ‡ã€‚'
- en: the ratio of true positives divided by all positives, true positives + false
    positives
  id: totrans-1402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çœŸæ­£é˜³æ€§ä¸æ‰€æœ‰é˜³æ€§çš„æ¯”ç‡ï¼ŒçœŸæ­£é˜³æ€§ + å‡é˜³æ€§
- en: \[ Precision_k = \frac{ n_{k,\text{true positives}} }{ n_{k,\text{true positives}}
    + n_{k,\text{false positives}}} = \frac{ n_{k,\text{true positives}} }{ n_{k,
    \text{all positives}} } \]
  id: totrans-1403
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Precision_k = \frac{ n_{k,\text{true positives}} }{ n_{k,\text{true positives}}
    + n_{k,\text{false positives}}} = \frac{ n_{k,\text{true positives}} }{ n_{k,
    \text{all positives}} } \]
- en: '**Prediction Interval**'
  id: totrans-1404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹åŒºé—´**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): the uncertainty
    in the next prediction represented as a range, lower and upper bound, based on
    a specified probability interval known as the confidence level.'
  id: totrans-1405
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šä¸‹ä¸€æ¬¡é¢„æµ‹çš„ä¸ç¡®å®šæ€§è¡¨ç¤ºä¸ºä¸€ä¸ªèŒƒå›´ï¼Œä¸‹é™å’Œä¸Šé™ï¼ŒåŸºäºä¸€ä¸ªç§°ä¸ºç½®ä¿¡æ°´å¹³çš„æŒ‡å®šæ¦‚ç‡åŒºé—´ã€‚'
- en: We communicate confidence intervals like this,
  id: totrans-1406
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿™æ ·ä¼ è¾¾ç½®ä¿¡åŒºé—´ï¼Œ
- en: there is a 95% probability (or 19 times out of 20) that the true reservoir NTG
    is between 13% and 17%, given, predictor feature values, \(ğ‘‹_1=ğ‘¥_1,\ldots,ğ‘‹_ğ‘š=ğ‘¥_ğ‘š\).
  id: totrans-1407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç»™å®šé¢„æµ‹ç‰¹å¾å€¼çš„æƒ…å†µä¸‹ï¼Œæœ‰95%çš„æ¦‚ç‡ï¼ˆæˆ–20æ¬¡ä¸­çš„19æ¬¡ï¼‰è¡¨æ˜çœŸå®å‚¨å±‚çš„NTGåœ¨13%åˆ°17%ä¹‹é—´ã€‚
- en: Is the uncertainty in our prediction, for prediction intervals we integrate,
  id: totrans-1408
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯æˆ‘ä»¬é¢„æµ‹çš„ä¸ç¡®å®šæ€§ï¼Œå¯¹äºé¢„æµ‹åŒºé—´ï¼Œæˆ‘ä»¬è¿›è¡Œç§¯åˆ†ï¼Œ
- en: uncertainty in the model \(ğ¸{\hat{ğ‘Œ}|ğ‘‹=ğ‘¥}\)
  id: totrans-1409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹ä¸­çš„ä¸ç¡®å®šæ€§ \(ğ¸{\hat{ğ‘Œ}|ğ‘‹=ğ‘¥}\)
- en: error in the model, conditional distribution \(\hat{Y}|X=x\)
  id: totrans-1410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹ä¸­çš„è¯¯å·®ï¼Œæ¡ä»¶åˆ†å¸ƒ \(\hat{Y}|X=x\)
- en: '**Prediction, Predictive Statistics**'
  id: totrans-1411
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹ï¼Œé¢„æµ‹ç»Ÿè®¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): estimate the next
    sample(s) given assumptions about or a model of the population'
  id: totrans-1412
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ ¹æ®å¯¹æ€»ä½“æˆ–æ€»ä½“æ¨¡å‹çš„å‡è®¾ä¼°è®¡ä¸‹ä¸€ä¸ªæ ·æœ¬ï¼ˆæˆ–å¤šä¸ªæ ·æœ¬ï¼‰'
- en: for example, given our model of the reservoir, predict the next well (pre-drill
    assessment) sample, e.g., porosity, permeability, production rate, etc.
  id: totrans-1413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œç»™å®šæˆ‘ä»¬çš„å‚¨å±‚æ¨¡å‹ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªäº•ï¼ˆé¢„é’»è¯„ä¼°ï¼‰æ ·æœ¬ï¼Œä¾‹å¦‚ï¼Œå­”éš™ç‡ã€æ¸—é€ç‡ã€äº§é‡ç­‰ã€‚
- en: '**Predictor Feature**'
  id: totrans-1414
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the input feature
    for a predictive machine learning model. We can generalize a predictive machine
    learning model as,'
  id: totrans-1415
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å…¥ç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹æ¦‚æ‹¬ä¸ºï¼Œ'
- en: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
  id: totrans-1416
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
- en: where the response feature is \(y\), the predictor features are \(x_1,\ldots,x_m\),
    and \(\epsilon\) is model error
  id: totrans-1417
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­å“åº”ç‰¹å¾æ˜¯ \(y\)ï¼Œé¢„æµ‹ç‰¹å¾æ˜¯ \(x_1,\ldots,x_m\)ï¼Œè€Œ \(\epsilon\) æ˜¯æ¨¡å‹è¯¯å·®
- en: traditional statistics uses the term independent variable
  id: totrans-1418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿç»Ÿè®¡å­¦ä½¿ç”¨æœ¯è¯­ç‹¬ç«‹å˜é‡
- en: '**Predictor Feature Space**'
  id: totrans-1419
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹ç‰¹å¾ç©ºé—´**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): refers to the predictor
    features and does not include the response feature(s), i.e.,'
  id: totrans-1420
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šæŒ‡çš„æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œä¸åŒ…æ‹¬å“åº”ç‰¹å¾ï¼ˆå³ï¼Œ'
- en: all possible combinations of predictor features for which we need to make predictions
  id: totrans-1421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦é¢„æµ‹çš„æ‰€æœ‰é¢„æµ‹ç‰¹å¾çš„ç»„åˆ
- en: may be referred to as predictor feature space.
  id: totrans-1422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½è¢«ç§°ä¸ºé¢„æµ‹ç‰¹å¾ç©ºé—´ã€‚
- en: Typically, we train and test our machinesâ€™ predictions over the predictor feature
    space.
  id: totrans-1423
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šè®­ç»ƒå’Œæµ‹è¯•æœºå™¨çš„é¢„æµ‹ã€‚
- en: the space is typically a hypercuboid with each axis representing a predictor
    feature and extending from the minimum to maximum, over the range of each predictor
    feature
  id: totrans-1424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥ç©ºé—´é€šå¸¸æ˜¯è¶…ç«‹æ–¹ä½“ï¼Œæ¯ä¸ªè½´ä»£è¡¨ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œä»æœ€å°å€¼å»¶ä¼¸åˆ°æœ€å¤§å€¼ï¼Œè¦†ç›–æ¯ä¸ªé¢„æµ‹ç‰¹å¾çš„å–å€¼èŒƒå›´
- en: more complicated shapes of predictor feature space are possible, e.g., we could
    mask or remove subsets with poor data coverage.
  id: totrans-1425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ç©ºé—´çš„å½¢çŠ¶å¯èƒ½æ›´å¤æ‚ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å±è”½æˆ–ç§»é™¤æ•°æ®è¦†ç›–è¾ƒå·®çš„å­é›†ã€‚
- en: '**Primary Data**'
  id: totrans-1426
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸå§‹æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data samples for
    the feature of interest, the target feature for building a model, for example,'
  id: totrans-1427
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ„Ÿå…´è¶£çš„ç‰¹å¾æ•°æ®æ ·æœ¬ï¼Œç”¨äºæ„å»ºæ¨¡å‹çš„ç›®æ ‡ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: porosity measures from cores and logs used to build a full 3D porosity model.
    Any samples of porosity are the primary data
  id: totrans-1428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»å²©å¿ƒå’Œæµ‹äº•æ•°æ®ä¸­å¾—åˆ°çš„å­”éš™ç‡æµ‹é‡å€¼ï¼Œç”¨äºæ„å»ºå®Œæ•´çš„ 3D å­”éš™ç‡æ¨¡å‹ã€‚ä»»ä½•å­”éš™ç‡æ ·æœ¬éƒ½æ˜¯åŸå§‹æ•°æ®
- en: as opposed to secondary feature, e.g., if we have facies data to help predict
    porosity, the facies data are secondary data
  id: totrans-1429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸æ¬¡çº§ç‰¹å¾ç›¸åï¼Œä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ç”¨äºé¢„æµ‹å­”éš™ç‡çš„å²©æ€§æ•°æ®ï¼Œåˆ™å²©æ€§æ•°æ®æ˜¯æ¬¡çº§æ•°æ®
- en: '**Principal Component Analysis**'
  id: totrans-1430
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸»æˆåˆ†åˆ†æ**'
- en: '[Principal Component Analysis](MachineLearning_PCA.html): one of a variety
    of methods for dimensional reduction, transform the data to a lower dimension'
  id: totrans-1431
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸»æˆåˆ†åˆ†æ](MachineLearning_PCA.html)ï¼šå¤šç§é™ç»´æ–¹æ³•ä¹‹ä¸€ï¼Œå°†æ•°æ®è½¬æ¢åˆ°è¾ƒä½ç»´åº¦'
- en: given features, \(ğ‘‹_1,\dots,ğ‘‹_ğ‘š\) we would require \({m \choose 2}=\frac{ğ‘š \cdot
    (ğ‘šâˆ’1)}{2}\) scatter plots to visualize just the two-dimensional scatter plots.
  id: totrans-1432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šç‰¹å¾ \(ğ‘‹_1,\dots,ğ‘‹_ğ‘š\)ï¼Œæˆ‘ä»¬éœ€è¦ \({m \choose 2}=\frac{ğ‘š \cdot (ğ‘šâˆ’1)}{2}\) ä¸ªæ•£ç‚¹å›¾æ¥å¯è§†åŒ–äºŒç»´æ•£ç‚¹å›¾ã€‚
- en: once we have 4 or more variables understanding our data gets very hard.
  id: totrans-1433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰ 4 ä¸ªæˆ–æ›´å¤šå˜é‡ï¼Œç†è§£æ•°æ®å°±å˜å¾—éå¸¸å›°éš¾ã€‚
- en: recall the curse of dimensionality, impact inference, modeling and visualization.
  id: totrans-1434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å¿†ç»´åº¦è¯…å’’ï¼Œå½±å“æ¨ç†ã€å»ºæ¨¡å’Œå¯è§†åŒ–ã€‚
- en: One solution, is to find a good lower dimensional, \(ğ‘\), representation of
    the original dimensions \(ğ‘š\)
  id: totrans-1435
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯æ‰¾åˆ°ä¸€ä¸ªå¥½çš„ä½ç»´ \(ğ‘\) è¡¨ç¤ºï¼Œä»¥è¡¨ç¤ºåŸå§‹ç»´åº¦ \(ğ‘š\)
- en: 'Benefits of Working in a Reduced Dimensional Representation:'
  id: totrans-1436
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é™ç»´è¡¨ç¤ºä¸­çš„å¥½å¤„ï¼š
- en: data storage / Computational Time
  id: totrans-1437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•°æ®å­˜å‚¨/è®¡ç®—æ—¶é—´
- en: easier visualization
  id: totrans-1438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ›´å®¹æ˜“å¯è§†åŒ–
- en: also takes care of multicollinearity
  id: totrans-1439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿˜å¤„ç†å¤šé‡å…±çº¿æ€§é—®é¢˜
- en: Salient points of principal component analysis,
  id: totrans-1440
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»æˆåˆ†åˆ†æçš„ä¸»è¦è§‚ç‚¹ï¼Œ
- en: '*orthogonal transformation* - convert a set of observations into a set of linearly
    uncorrelated variables known as principal components, the transformation retains
    pairwise distance, i.e., is a rotation'
  id: totrans-1441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ­£äº¤å˜æ¢* - å°†ä¸€ç»„è§‚æµ‹å€¼è½¬æ¢ä¸ºä¸€ç»„çº¿æ€§ä¸ç›¸å…³çš„å˜é‡ï¼Œç§°ä¸ºä¸»æˆåˆ†ï¼Œè¿™ç§å˜æ¢ä¿ç•™äº†æˆå¯¹è·ç¦»ï¼Œå³æ˜¯ä¸€ç§æ—‹è½¬'
- en: '*number of principal components (\(k\)) available* - is minâ¡(\(ğ‘›âˆ’1,ğ‘š\)), limited
    by the variables/features, \(ğ‘š\), and the number of data'
  id: totrans-1442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯ç”¨çš„ä¸»æˆåˆ†æ•° (\(k\))* - æ˜¯ minâ¡(\(ğ‘›âˆ’1,ğ‘š\))ï¼Œå—å˜é‡/ç‰¹å¾ \(ğ‘š\) å’Œæ•°æ®æ•°é‡çš„é™åˆ¶'
- en: Components are ordered,
  id: totrans-1443
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„ä»¶æ˜¯æœ‰åºçš„ï¼Œ
- en: first component describes the larges possible variance / accounts for as much
    variability as possible
  id: totrans-1444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æˆåˆ†æè¿°äº†æœ€å¤§çš„å¯èƒ½æ–¹å·® / è§£é‡Šå°½å¯èƒ½å¤šçš„å˜å¼‚æ€§
- en: next component describes the largest possible remaining variance
  id: totrans-1445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªæˆåˆ†æè¿°äº†æœ€å¤§çš„å¯èƒ½å‰©ä½™æ–¹å·®
- en: up to the maximum number of principal components
  id: totrans-1446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤šåˆ°ä¸»æˆåˆ†çš„æœ€å¤§æ•°é‡
- en: Eigenvalues and eigenvectors-based,
  id: totrans-1447
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œ
- en: Calculate the data covariance matrix, the pairwise covariance for the combinatorial
    of features and then calculate the eigenvectors and eigenvalues from the covariance
    matrix,
  id: totrans-1448
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—æ•°æ®åæ–¹å·®çŸ©é˜µï¼Œç‰¹å¾å¯¹çš„åæ–¹å·®ï¼Œç„¶åä»åæ–¹å·®çŸ©é˜µä¸­è®¡ç®—ç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼ï¼Œ
- en: the eigenvalues are the variance explained for each component.
  id: totrans-1449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å€¼æ˜¯æ¯ä¸ªæˆåˆ†è§£é‡Šçš„æ–¹å·®ã€‚
- en: the eigenvectors of the data covariance matrix are the principal components.
  id: totrans-1450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å‘é‡æ˜¯ä¸»æˆåˆ†ã€‚
- en: '**Probability Density Function** (PDF)'
  id: totrans-1451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡å¯†åº¦å‡½æ•°** (PDF)'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): a representation
    of a statistical distribution with a function, \(f(x)\), of probability density
    over the range of all possible feature values, \(x\). These are the concepts for
    PDFs,'
  id: totrans-1452
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šä½¿ç”¨æ¦‚ç‡å¯†åº¦å‡½æ•° \(f(x)\) çš„å‡½æ•°è¡¨ç¤ºç»Ÿè®¡åˆ†å¸ƒï¼Œè¯¥å‡½æ•°åœ¨æ‰€æœ‰å¯èƒ½çš„ç‰¹å¾å€¼èŒƒå›´
    \(x\) ä¸Šï¼Œè¿™äº›æ˜¯ PDF çš„æ¦‚å¿µï¼Œ'
- en: non-negativity constraint, the density cannot be negative,
  id: totrans-1453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éè´Ÿçº¦æŸï¼Œå¯†åº¦ä¸èƒ½ä¸ºè´Ÿï¼Œ
- en: \[ 0.0 \le f(x) \]
  id: totrans-1454
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0.0 \le f(x) \]
- en: for continuous features the density may be > 1.0, because density is a measure
    of likelihood and not of probability
  id: totrans-1455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¿ç»­ç‰¹å¾ï¼Œå¯†åº¦å¯èƒ½å¤§äº 1.0ï¼Œå› ä¸ºå¯†åº¦æ˜¯å¯èƒ½æ€§çš„åº¦é‡ï¼Œè€Œä¸æ˜¯æ¦‚ç‡çš„åº¦é‡
- en: integrate density over a range of \(x\) to calculate probability,
  id: totrans-1456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ \(x\) çš„ä¸€ä¸ªèŒƒå›´å†…ç§¯åˆ†å¯†åº¦ä»¥è®¡ç®—æ¦‚ç‡ï¼Œ
- en: \[ 0 \le \int_a^b f(x) dx = P(a \le x \le b) \le 1.0 \]
  id: totrans-1457
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0 \le \int_a^b f(x) dx = P(a \le x \le b) \le 1.0 \]
- en: probability closure, the sum of the area under the PDF curve is equal to 1.0,
  id: totrans-1458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¦‚ç‡å°é—­ï¼ŒPDF æ›²çº¿ä¸‹æ–¹çš„é¢ç§¯ä¹‹å’Œç­‰äº 1.0ï¼Œ
- en: \[ \int_{-infty}^{\infty} f(x) dx = 1.0 \]
  id: totrans-1459
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \int_{-\infty}^{\infty} f(x) dx = 1.0 \]
- en: Nonparametric PDFs are calculated with kernels (usual a small Gaussian distribution)
    that is summed over all data; therefore, there is an implicitly scale (smoothness)
    parameter when calculating a PDF.
  id: totrans-1460
  prefs: []
  type: TYPE_NORMAL
  zh: éå‚æ•°PDFé€šè¿‡æ ¸å‡½æ•°ï¼ˆé€šå¸¸æ˜¯å°çš„é«˜æ–¯åˆ†å¸ƒï¼‰è®¡ç®—ï¼Œå¯¹æ‰€æœ‰æ•°æ®è¿›è¡Œæ±‚å’Œï¼›å› æ­¤ï¼Œåœ¨è®¡ç®—PDFæ—¶å­˜åœ¨ä¸€ä¸ªéšå«çš„å°ºåº¦ï¼ˆå¹³æ»‘åº¦ï¼‰å‚æ•°ã€‚
- en: To large of kernels will smooth out important information about the univariate
    distribution
  id: totrans-1461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡å¤§çš„æ ¸å‡½æ•°ä¼šå¹³æ»‘æ‰å…³äºå•å˜é‡åˆ†å¸ƒçš„é‡è¦ä¿¡æ¯
- en: Too narrow will result in an overly noisy PDF that is difficult to interpret.
  id: totrans-1462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡çª„ä¼šå¯¼è‡´è¿‡äºå˜ˆæ‚çš„PDFï¼Œéš¾ä»¥è§£é‡Šã€‚
- en: This is analogous to the choice of bin size for a histogram or normalized histogram.
  id: totrans-1463
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç±»ä¼¼äºé€‰æ‹©ç›´æ–¹å›¾æˆ–å½’ä¸€åŒ–ç›´æ–¹å›¾çš„binå¤§å°ã€‚
- en: Parametric PDFs are possible but require model fitting to the data, the steps
    are,
  id: totrans-1464
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°PDFæ˜¯å¯èƒ½çš„ï¼Œä½†éœ€è¦å°†æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®ä¸­ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼Œ
- en: Select a parametric distribution, e.g., Gaussian, log normal, etc.
  id: totrans-1465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªå‚æ•°åˆ†å¸ƒï¼Œä¾‹å¦‚é«˜æ–¯åˆ†å¸ƒã€å¯¹æ•°æ­£æ€åˆ†å¸ƒç­‰ã€‚
- en: Calculate the parameters for the parametric distribution based on the available
    data, by methods such as least squares or maximum likelihood.
  id: totrans-1466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®å¯ç”¨æ•°æ®ï¼Œé€šè¿‡æœ€å°äºŒä¹˜æ³•æˆ–æœ€å¤§ä¼¼ç„¶æ³•ç­‰æ–¹æ³•è®¡ç®—å‚æ•°åˆ†å¸ƒçš„å‚æ•°ã€‚
- en: '**Probability Non-negativity, Normalization**'
  id: totrans-1467
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡éè´Ÿæ€§ï¼Œå½’ä¸€åŒ–**'
- en: 'Probability Concepts: fundamental constraints on probability including,'
  id: totrans-1468
  prefs: []
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ¦‚å¿µï¼šæ¦‚ç‡çš„åŸºæœ¬çº¦æŸåŒ…æ‹¬ï¼Œ
- en: Bounded, \(0.0 \le P(A) \le 1.0\)
  id: totrans-1469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœ‰ç•Œ**ï¼Œ\(0.0 \le P(A) \le 1.0\)'
- en: Closure, \(P(\Omega) = 1.0\)
  id: totrans-1470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é—­åŒ…**ï¼Œ\(P(\Omega) = 1.0\)'
- en: Null Sets, \(P(\emptyset) = 0.0\)
  id: totrans-1471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç©ºé›†**ï¼Œ\(P(\emptyset) = 0.0\)'
- en: '**Probability of Acceptance** (MCMC)'
  id: totrans-1472
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¥å—æ¦‚ç‡**ï¼ˆMCMCï¼‰'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    applied in a rejection sampler as the likelihood of a candidate sample being added
    to the sample.'
  id: totrans-1473
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä½œä¸ºæ‹’ç»æŠ½æ ·ä¸­å€™é€‰æ ·æœ¬è¢«æ·»åŠ åˆ°æ ·æœ¬ä¸­çš„ä¼¼ç„¶åº”ç”¨ã€‚'
- en: conditional acceptance is performed by Monte Carlo simulation,
  id: totrans-1474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ‰§è¡Œæ¡ä»¶æ¥å—ï¼Œ
- en: sequentially sampling from conditional distributions
  id: totrans-1475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾æ¬¡ä»æ¡ä»¶åˆ†å¸ƒä¸­è¿›è¡ŒæŠ½æ ·
- en: The acceptance rule is,
  id: totrans-1476
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥å—è§„åˆ™æ˜¯ï¼Œ
- en: if \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \ge 1\), accept â€“ accept
  id: totrans-1477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœ \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \ge 1\)ï¼Œæ¥å— - æ¥å—
- en: if \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \lt 1\), conditionally accept, draw \(ğ‘ âˆ¼ U[0,1]\), and accept
    if \(ğ‘ \le ğ›¼\)
  id: totrans-1478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœ \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \lt 1\)ï¼Œåˆ™æ¡ä»¶æ¥å—ï¼ŒæŠ½å– \(ğ‘ âˆ¼ U[0,1]\)ï¼Œå¦‚æœ \(ğ‘ \le ğ›¼\) åˆ™æ¥å—
- en: '**Probability Operators**'
  id: totrans-1479
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡ç®—å­**'
- en: '[Probability Concepts](MachineLearning_probability.html): common probability
    operators that are essential to working with probability and uncertainty problems,'
  id: totrans-1480
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šä¸æ¦‚ç‡å’Œä¸ç¡®å®šæ€§é—®é¢˜å·¥ä½œç›¸å…³çš„å¸¸è§æ¦‚ç‡ç®—å­ï¼Œ'
- en: '*Union of Events* - the union of outcomes, the probability of \(A\) or \(B\)
    is calculated with the probability addition rule,'
  id: totrans-1481
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº‹ä»¶çš„å¹¶é›†* - ç»“æœçš„å¹¶é›†ï¼Œ\(A\) æˆ– \(B\) çš„æ¦‚ç‡é€šè¿‡æ¦‚ç‡åŠ æ³•è§„åˆ™è®¡ç®—ï¼Œ'
- en: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
  id: totrans-1482
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
- en: '*Intersection of Events* - the intersection of outcomes, the probability of
    \(A\) and \(B\) is represented as,'
  id: totrans-1483
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº‹ä»¶çš„äº¤é›†* - ç»“æœçš„äº¤é›†ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ'
- en: \[ P(A \cap B) = P(A,B) \]
  id: totrans-1484
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) \]
- en: only under the assumption of independence of \(A\) and \(B\) can it be calculate
    from the probabilities of \(A\) and \(B\) as,
  id: totrans-1485
  prefs: []
  type: TYPE_NORMAL
  zh: åªæœ‰åœ¨å‡è®¾ \(A\) å’Œ \(B\) ç‹¬ç«‹çš„æƒ…å†µä¸‹ï¼Œæ‰èƒ½ä» \(A\) å’Œ \(B\) çš„æ¦‚ç‡ä¸­è®¡ç®—å‡ºå®ƒï¼Œ
- en: \[ P(A,B) = P(A) \cdot P(B) \]
  id: totrans-1486
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = P(A) \cdot P(B) \]
- en: if there is dependence between \(A\) and \(B\) then we need the conditional
    probability, \(P(A|B)\) instead of the marginal, \(P(A)\),
  id: totrans-1487
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(A\) å’Œ \(B\) ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œåˆ™éœ€è¦æ¡ä»¶æ¦‚ç‡ \(P(A|B)\) è€Œä¸æ˜¯è¾¹ç¼˜æ¦‚ç‡ \(P(A)\)ï¼Œ
- en: \[ P(A,B) = P(A|B) \cdot P(B) \]
  id: totrans-1488
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = P(A|B) \cdot P(B) \]
- en: '*Complimentary Events* - is the NOT operator for probability, if we define
    \(A\) then \(A\) compliment, \(A^c\) is not \(A\) and we have this resulting closure
    relationship,'
  id: totrans-1489
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº’è¡¥äº‹ä»¶* - æ˜¯æ¦‚ç‡ä¸­çš„éæ“ä½œç¬¦ï¼Œå¦‚æœæˆ‘ä»¬å®šä¹‰ \(A\)ï¼Œé‚£ä¹ˆ \(A\) çš„è¡¥é›† \(A^c\) å°±ä¸æ˜¯ \(A\)ï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰è¿™ä¸ªç»“æœé—­åŒ…å…³ç³»ï¼Œ'
- en: \[ P(A) + P(A^c) = 1.0 \]
  id: totrans-1490
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) + P(A^c) = 1.0 \]
- en: complimentary events may be considered for beyond univariate problems, for example
    consider this bivariate closure,
  id: totrans-1491
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¶…è¶Šå•å˜é‡é—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘äº’è¡¥äº‹ä»¶ï¼Œä¾‹å¦‚è€ƒè™‘è¿™ä¸ªåŒå˜é‡é—­åŒ…ï¼Œ
- en: \[ P(A|B) + P(A^c|B) = 1.0 \]
  id: totrans-1492
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) + P(A^c|B) = 1.0 \]
- en: Note, the given term must be the same.
  id: totrans-1493
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç»™å®šçš„æœ¯è¯­å¿…é¡»ç›¸åŒã€‚
- en: '*Mutually Exclusive Events* - the events that do not intersect or do not have
    any common outcomes. We represent this with set notation as,'
  id: totrans-1494
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº’æ–¥äº‹ä»¶* - æŒ‡çš„æ˜¯ä¸äº¤å‰æˆ–ä¸å…·æœ‰ä»»ä½•å…±åŒç»“æœçš„äº‹ä»¶ã€‚æˆ‘ä»¬ç”¨é›†åˆç¬¦å·è¡¨ç¤ºä¸ºï¼Œ'
- en: '\[ \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
  id: totrans-1495
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
- en: and the joint probability of \(A\) and \(B\) as,
  id: totrans-1496
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠ \(A\) å’Œ \(B\) çš„è”åˆæ¦‚ç‡ï¼Œ
- en: \[ P(A \cap B) = P(A,B) = 0 \]
  id: totrans-1497
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) = 0 \]
- en: '**Probability Perspectives**'
  id: totrans-1498
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡è§†è§’**'
- en: '[Probability Concepts](MachineLearning_probability.html): the 3 primary perspectives
    for calculating probability:'
  id: totrans-1499
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šè®¡ç®—æ¦‚ç‡çš„3ä¸ªä¸»è¦è§†è§’ï¼š'
- en: '*Long-term frequencies* - probability as ratio of outcomes, requires repeated
    observations of an experiment. The basis for *frequentist probability*.'
  id: totrans-1500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*é•¿æœŸé¢‘ç‡* - æ¦‚ç‡ä½œä¸ºç»“æœçš„æ¯”ç‡ï¼Œéœ€è¦é‡å¤è§‚å¯Ÿå®éªŒã€‚æ˜¯*é¢‘ç‡ä¸»ä¹‰æ¦‚ç‡*çš„åŸºç¡€ã€‚'
- en: '*Physical tendencies or propensities* - probability from knowledge about or
    modeling the system, e.g., we could know the probability of a heads outcome from
    a coin toss without the experiment.'
  id: totrans-1501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç‰©ç†è¶‹åŠ¿æˆ–å€¾å‘æ€§* - ä»å¯¹ç³»ç»Ÿæˆ–å»ºæ¨¡çš„çŸ¥è¯†ä¸­å¾—å‡ºçš„æ¦‚ç‡ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“æŠ›ç¡¬å¸å¾—åˆ°æ­£é¢çš„æ¦‚ç‡ï¼Œè€Œä¸è¿›è¡Œå®éªŒã€‚'
- en: '*Degrees of belief* - reflect our certainty about a result, very flexible,
    assign probability to anything, and updating with new information. The basis for
    *Bayesian probability*.'
  id: totrans-1502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¿¡å¿µåº¦* - åæ˜ æˆ‘ä»¬å¯¹ç»“æœçš„ç¡®å®šæ€§ï¼Œéå¸¸çµæ´»ï¼Œå¯ä»¥å¯¹ä»»ä½•äº‹ç‰©åˆ†é…æ¦‚ç‡ï¼Œå¹¶éšç€æ–°ä¿¡æ¯çš„æ›´æ–°ã€‚æ˜¯*è´å¶æ–¯æ¦‚ç‡*çš„åŸºç¡€ã€‚'
- en: '**Prototype** (clustering)'
  id: totrans-1503
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸå‹**ï¼ˆèšç±»ï¼‰'
- en: 'Cluster Analysis: represent the sample data with set of points in the feature
    space.'
  id: totrans-1504
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šç”¨ç‰¹å¾ç©ºé—´ä¸­çš„ç‚¹é›†è¡¨ç¤ºæ ·æœ¬æ•°æ®ã€‚
- en: prototypes are typically not actual samples
  id: totrans-1505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸå‹é€šå¸¸æ˜¯å®é™…æ ·æœ¬ã€‚
- en: sample data are often assigned to the nearest (Euclidean) distance prototype
  id: totrans-1506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ•°æ®é€šå¸¸è¢«åˆ†é…åˆ°æœ€è¿‘çš„ï¼ˆæ¬§å‡ é‡Œå¾—ï¼‰è·ç¦»åŸå‹ã€‚
- en: '**Qualitative Features**'
  id: totrans-1507
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®šæ€§ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): information about
    quantities that you cannot directly measure, require interpretation of measurement,
    and are described with words (not numbers), for example,'
  id: totrans-1508
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå…³äºæ— æ³•ç›´æ¥æµ‹é‡çš„æ•°é‡ï¼Œéœ€è¦è§£é‡Šæµ‹é‡ï¼Œå¹¶ç”¨æ–‡å­—ï¼ˆè€Œä¸æ˜¯æ•°å­—ï¼‰æè¿°ï¼Œä¾‹å¦‚ï¼Œ'
- en: rock type = sandstone
  id: totrans-1509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å²©çŸ³ç±»å‹ = ç ‚å²©
- en: zonation = bornite-chalcopyrite-gold higher grade copper zone
  id: totrans-1510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å¸¦ = é»„é“œçŸ¿-é»„é“çŸ¿-é‡‘ é«˜çº§é“œçŸ¿å¸¦
- en: '**Quantitative Features**'
  id: totrans-1511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®šé‡ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): features that can
    be measured and represented by numbers, for example,'
  id: totrans-1512
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¯ä»¥æµ‹é‡å¹¶ç”±æ•°å­—è¡¨ç¤ºçš„ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: age = 10 Ma (millions of years)
  id: totrans-1513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹´é¾„ = 10 Maï¼ˆç™¾ä¸‡å¹´ï¼‰
- en: porosity = 0.134 (fraction of volume is void space)
  id: totrans-1514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ = 0.134ï¼ˆä½“ç§¯çš„ç©ºéš™éƒ¨åˆ†ï¼‰
- en: saturation = 80.5% (volume percentage)
  id: totrans-1515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¥±å’Œåº¦ = 80.5%ï¼ˆä½“ç§¯ç™¾åˆ†æ¯”ï¼‰
- en: Like *qualitative features*, there is often the requirement for interpretation,
    for example, total porosity may be measured but should be converted to effective
    porosity through interpretation or a model
  id: totrans-1516
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äº*å®šæ€§ç‰¹å¾*ï¼Œé€šå¸¸éœ€è¦è§£é‡Šï¼Œä¾‹å¦‚ï¼Œæ€»å­”éš™ç‡å¯ä»¥æµ‹é‡ï¼Œä½†åº”é€šè¿‡è§£é‡Šæˆ–æ¨¡å‹è½¬æ¢ä¸ºæœ‰æ•ˆå­”éš™ç‡ã€‚
- en: '**\(r^2\)** (also coefficient of determination)'
  id: totrans-1517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(r^2\)**ï¼ˆä¹Ÿç§°ä¸ºç¡®å®šç³»æ•°ï¼‰'
- en: '[Linear Regression](MachineLearning_linear_regression.html): the proportion
    of variance explained by the model in linear regression'
  id: totrans-1518
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šçº¿æ€§å›å½’ä¸­æ¨¡å‹è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹'
- en: 'This works only for linear models, where:'
  id: totrans-1519
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªé€‚ç”¨äºçº¿æ€§æ¨¡å‹ï¼Œå…¶ä¸­ï¼š
- en: \[ \sigma^2_{tot} = \sigma^2_{reg} + \sigma^2_{res} \]
  id: totrans-1520
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma^2_{tot} = \sigma^2_{reg} + \sigma^2_{res} \]
- en: where \(\sigma^2_{tot}\) is variance of response feature training, \(y_i\),
    \(\sigma^2_{reg}\) is variance of the model predictions, \(\hat{y}_i\), and \(\sigma^2_{res}\)
    is the variance of the errors, \(\Delta y_i\).
  id: totrans-1521
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma^2_{tot}\) æ˜¯å“åº”ç‰¹å¾è®­ç»ƒçš„æ–¹å·®ï¼Œ\(y_i\)ï¼Œ\(\sigma^2_{reg}\) æ˜¯æ¨¡å‹é¢„æµ‹çš„æ–¹å·®ï¼Œ\(\hat{y}_i\)ï¼Œ\(\sigma^2_{res}\)
    æ˜¯è¯¯å·®çš„æ–¹å·®ï¼Œ\(\Delta y_i\)ã€‚
- en: for linear regression, \(r^2 = \left( \rho_{x,y} \right)^2\)
  id: totrans-1522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºçº¿æ€§å›å½’ï¼Œ\(r^2 = \left( \rho_{x,y} \right)^2\)
- en: For nonlinear models this will not likely hold, then \(\frac{\sigma^2_{ğ‘Ÿğ‘’ğ‘”}}{\sigma^2_{ğ‘¡ğ‘œğ‘¡}}\)
    may exceed \([0,1]\), for our nonlinear models regression models we will use more
    robust measures, e.g. mean square error (MSE)
  id: totrans-1523
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºéçº¿æ€§æ¨¡å‹ï¼Œè¿™ä¸å¤ªå¯èƒ½æˆç«‹ï¼Œé‚£ä¹ˆ \(\frac{\sigma^2_{ğ‘Ÿğ‘’ğ‘”}}{\sigma^2_{ğ‘¡ğ‘œğ‘¡}}\) å¯èƒ½è¶…è¿‡ \([0,1]\)ï¼Œå¯¹äºæˆ‘ä»¬çš„éçº¿æ€§æ¨¡å‹å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ›´ç¨³å¥çš„åº¦é‡ï¼Œä¾‹å¦‚å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ã€‚
- en: '**Random Forest**'
  id: totrans-1524
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éšæœºæ£®æ—**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): a ensemble
    prediction model that is based on the standard bagging approach, specifically,'
  id: totrans-1525
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¢‹è£…æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šä¸€ç§åŸºäºæ ‡å‡†è¢‹è£…æ–¹æ³•çš„é›†æˆé¢„æµ‹æ¨¡å‹ï¼Œå…·ä½“æ¥è¯´ï¼Œ'
- en: with decision tree
  id: totrans-1526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å†³ç­–æ ‘
- en: with diversification of the individual trees by restricting each split to consider
    a \(p\) random subset of the \(ğ‘š\) available predictors
  id: totrans-1527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é™åˆ¶æ¯ä¸ªåˆ†å‰²åªè€ƒè™‘ \(m\) ä¸ªå¯ç”¨é¢„æµ‹å› å­ä¸­çš„ \(p\) ä¸ªéšæœºå­é›†æ¥å¤šæ ·åŒ–å•ä¸ªæ ‘ã€‚
- en: There are various methods to calculate \(p\) from \(m\) available features,
  id: totrans-1528
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å¤šç§æ–¹æ³•å¯ä»¥ä» \(m\) ä¸ªå¯ç”¨ç‰¹å¾ä¸­è®¡ç®— \(p\)ï¼Œ
- en: \[ p = \sqrt{m} \]
  id: totrans-1529
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p = \sqrt{m} \]
- en: is common. Note, if \(p = m\) then random forest is tree bagging.
  id: totrans-1530
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯å¸¸è§çš„ã€‚æ³¨æ„ï¼Œå¦‚æœ \(p = m\)ï¼Œåˆ™éšæœºæ£®æ—æ˜¯æ ‘è¢‹æ³•ã€‚
- en: More comments on the benefit of ensemble model diversification,
  id: totrans-1531
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šå…³äºé›†æˆæ¨¡å‹å¤šæ ·æ€§çš„å¥½å¤„è¯„è®ºï¼Œ
- en: the reduction in model variance by ensemble estimation, as represented by standard
    error in the mean,
  id: totrans-1532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é›†æˆä¼°è®¡å‡å°‘æ¨¡å‹æ–¹å·®ï¼Œå¦‚æ ‡å‡†è¯¯å·®æ‰€è¡¨ç¤ºçš„ï¼Œ
- en: \[ \sigma_{\overline{x}}^2 = fracc{\sigma_{s}^2}{n} \]
  id: totrans-1533
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\overline{x}}^2 = \frac{\sigma_{s}^2}{n} \]
- en: is under the assumption that the samples are uncorrelated. One issue with tree
    bagging is the trees in the ensemble may be highly correlated.
  id: totrans-1534
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æ ·æœ¬æ˜¯ä¸ç›¸å…³çš„ã€‚æ ‘è¢‹é›†æˆçš„ä¸€ä¸ªé—®é¢˜æ˜¯é›†æˆä¸­çš„æ ‘å¯èƒ½é«˜åº¦ç›¸å…³ã€‚
- en: this occurs when there is a dominant predictor feature as it will always be
    applied to the top split(s), the result is all the trees in the ensemble are very
    similar (i.e. correlated)
  id: totrans-1535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“å­˜åœ¨ä¸»å¯¼é¢„æµ‹ç‰¹å¾æ—¶ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œå› ä¸ºå®ƒå°†å§‹ç»ˆåº”ç”¨äºé¡¶éƒ¨åˆ†å‰²ï¼ˆsï¼‰ï¼Œç»“æœæ˜¯é›†æˆä¸­çš„æ‰€æœ‰æ ‘éƒ½éå¸¸ç›¸ä¼¼ï¼ˆå³ç›¸å…³ï¼‰
- en: with highly correlated trees, there is significantly less reduction in model
    variance with the ensemble
  id: totrans-1536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºé«˜åº¦ç›¸å…³çš„æ ‘ï¼Œé›†æˆåœ¨å‡å°‘æ¨¡å‹æ–¹å·®æ–¹é¢æ˜¾è‘—è¾ƒå°‘
- en: this forces each tree in the ensemble to evolve in dissimilar, decorrelated,
    manner
  id: totrans-1537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™è¿«ä½¿é›†æˆä¸­çš„æ¯ä¸€æ£µæ ‘ä»¥ä¸åŒã€å»ç›¸å…³çš„æ¨¡å¼è¿›åŒ–
- en: '**Realization**'
  id: totrans-1538
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®ç°**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): an outcome from
    a *random variable* or a joint outcome from a *random function*.'
  id: totrans-1539
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ¥è‡ª *éšæœºå˜é‡* æˆ–æ¥è‡ª *éšæœºå‡½æ•°* çš„è”åˆç»“æœã€‚'
- en: an outcome from a random variable, \(X\), (or joint set of outcomes from a random
    function)
  id: totrans-1540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜¯ä»éšæœºå˜é‡ \(X\)ï¼ˆæˆ–éšæœºå‡½æ•°çš„è”åˆç»“æœï¼‰å¾—å‡ºçš„ç»“æœï¼Œ
- en: represented with lower case, e.g., \(x\)
  id: totrans-1541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨å°å†™è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼Œ\(x\)
- en: for spatial settings it is common to include a location vector, \(\bf{u}\),
    to describe the location, e.g., \(x(\bf{u})\), as \(X(\bf{u})\)
  id: totrans-1542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç©ºé—´è®¾ç½®ï¼Œé€šå¸¸åŒ…æ‹¬ä¸€ä¸ªä½ç½®å‘é‡ \(\bf{u}\)ï¼Œä»¥æè¿°ä½ç½®ï¼Œä¾‹å¦‚ï¼Œ\(x(\bf{u})\)ï¼Œä½œä¸º \(X(\bf{u})\)
- en: resulting from simulation, e.g., Monte Carlo simulation, sequential Gaussian
    simulation, a method to sample (jointly) from the RV (RF)
  id: totrans-1543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥è‡ªæ¨¡æ‹Ÿçš„ç»“æœï¼Œä¾‹å¦‚ï¼Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œé¡ºåºé«˜æ–¯æ¨¡æ‹Ÿï¼Œä» RVï¼ˆRFï¼‰ï¼ˆè”åˆï¼‰é‡‡æ ·çš„æ–¹æ³•
- en: in general, we assume all realizations are equiprobable, i.e., have the same
    probability of occurrence
  id: totrans-1544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬å‡è®¾æ‰€æœ‰å®ç°éƒ½æ˜¯ç­‰æ¦‚ç‡çš„ï¼Œå³å…·æœ‰ç›¸åŒçš„å‡ºç°æ¦‚ç‡
- en: '**Realizations** (uncertainty)'
  id: totrans-1545
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®ç°**ï¼ˆä¸ç¡®å®šæ€§ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): multiple spatial,
    subsurface models calculated by stochastic simulation by holding input parameters
    and model choices constant and only changing the random number seed'
  id: totrans-1546
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€šè¿‡ä¿æŒè¾“å…¥å‚æ•°å’Œæ¨¡å‹é€‰æ‹©ä¸å˜ï¼Œä»…æ”¹å˜éšæœºæ•°ç§å­è¿›è¡Œéšæœºæ¨¡æ‹Ÿçš„å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹'
- en: these models represent spatial uncertainty
  id: totrans-1547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›æ¨¡å‹ä»£è¡¨ç©ºé—´ä¸ç¡®å®šæ€§
- en: for example, hold the porosity mean constant and observe changes in porosity
    away from the wells over multiple realizations
  id: totrans-1548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¿æŒå­”éš™ç‡å¹³å‡å€¼ä¸å˜ï¼Œå¹¶è§‚å¯Ÿå¤šä¸ªå®ç°ä¸­è¿œç¦»äº•çš„å­”éš™ç‡å˜åŒ–
- en: '**Reasons to Learn Some Coding**'
  id: totrans-1549
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å­¦ä¹ ä¸€äº›ç¼–ç çš„ç†ç”±**'
- en: '[Machine Learning Workflow Construction and Coding](MachineLearning_workflow_construction.html):
    Professor Pyrczâ€™s reasons for all scientists and engineers to learn some coding,'
  id: totrans-1550
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ](MachineLearning_workflow_construction.html)ï¼šPyrczæ•™æˆå¯¹æ‰€æœ‰ç§‘å­¦å®¶å’Œå·¥ç¨‹å¸ˆå­¦ä¹ ä¸€äº›ç¼–ç çš„ç†ç”±ï¼Œ'
- en: '*Transparency* â€“ no compiler accepts hand waiving! Coding forces your logic
    to be uncovered for any other scientist or engineer to review.'
  id: totrans-1551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é€æ˜åº¦* â€“ æ²¡æœ‰ç¼–è¯‘å™¨ä¼šæ¥å—æŒ¥æ‰‹ï¼ç¼–ç è¿«ä½¿ä½ çš„é€»è¾‘è¢«ä»»ä½•å…¶ä»–ç§‘å­¦å®¶æˆ–å·¥ç¨‹å¸ˆå®¡æŸ¥ã€‚'
- en: '*Reproducibility* â€“ run it and get an answer, hand it over to a peer, they
    run it and they get the same answer. This is a principle of the scientific method.'
  id: totrans-1552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯é‡å¤æ€§* â€“ è¿è¡Œå®ƒå¹¶å¾—åˆ°ç­”æ¡ˆï¼Œäº¤ç»™ä¸€ä¸ªåŒè¡Œï¼Œä»–ä»¬è¿è¡Œå®ƒå¹¶å¾—åˆ°ç›¸åŒçš„ç­”æ¡ˆã€‚è¿™æ˜¯ç§‘å­¦æ–¹æ³•çš„ä¸€ä¸ªåŸåˆ™ã€‚'
- en: '*Quantification* â€“ programs need numbers and drive us from qualitative to quantitative.
    Feed the program and discover new ways to look at the world.'
  id: totrans-1553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é‡åŒ–* â€“ ç¨‹åºéœ€è¦æ•°å­—ï¼Œå¹¶æ¨åŠ¨æˆ‘ä»¬ä»å®šæ€§åˆ°å®šé‡ã€‚ç»™ç¨‹åºå–‚é£Ÿï¼Œå‘ç°æ–°çš„çœ‹å¾…ä¸–ç•Œçš„æ–¹å¼ã€‚'
- en: '*Open-source* â€“ leverage a world of brilliance. Check out packages, snippets
    and be amazed with what great minds have freely shared.'
  id: totrans-1554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¼€æº* â€“ åˆ©ç”¨å…¨çƒçš„æ™ºæ…§ã€‚æŸ¥çœ‹åŒ…ã€ä»£ç ç‰‡æ®µï¼Œå¹¶æƒŠå¹äºä¼Ÿå¤§æ€æƒ³è€…å…è´¹åˆ†äº«çš„æˆæœã€‚'
- en: '*Break Down Barriers* â€“ donâ€™t throw it over the fence. Sit at the table with
    the developers and share more of your subject matter expertise for a better deployed
    product.'
  id: totrans-1555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ‰“ç ´éšœç¢* â€“ ä¸è¦æŠŠå®ƒæ‰”è¿‡æ …æ ã€‚ä¸å¼€å‘è€…ä¸€èµ·ååœ¨æ¡Œæ—ï¼Œåˆ†äº«æ›´å¤šä½ çš„ä¸“ä¸šçŸ¥è¯†ï¼Œä»¥è·å¾—æ›´å¥½çš„éƒ¨ç½²äº§å“ã€‚'
- en: '*Deployment* â€“ share your code with others and multiply your impact. Performance
    metrics or altruism, your good work benefits many others.'
  id: totrans-1556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*éƒ¨ç½²* â€“ ä¸ä»–äººåˆ†äº«ä½ çš„ä»£ç ï¼Œå¹¶æ‰©å¤§ä½ çš„å½±å“åŠ›ã€‚æ€§èƒ½æŒ‡æ ‡æˆ–åˆ©ä»–ä¸»ä¹‰ï¼Œä½ çš„å¥½å·¥ä½œä½¿è®¸å¤šäººå—ç›Šã€‚'
- en: '*Efficiency* â€“ minimize the boring parts of the job. Build a suite of scripts
    for automation of common tasks and spend more time doing science and engineering!'
  id: totrans-1557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ•ˆç‡* â€“ æœ€å°åŒ–å·¥ä½œä¸­çš„æ— èŠéƒ¨åˆ†ã€‚æ„å»ºä¸€å¥—ç”¨äºè‡ªåŠ¨åŒ–å¸¸è§ä»»åŠ¡çš„è„šæœ¬ï¼Œå¹¶èŠ±æ›´å¤šæ—¶é—´è¿›è¡Œç§‘å­¦å’Œå·¥ç¨‹ï¼'
- en: '*Always Time to Do it Again!* â€“ how many times did you only do it once? It
    probably takes 2-4 times as long to script and automate a workflow. Usually, worth
    it.'
  id: totrans-1558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ°¸è¿œæœ‰å†æ¬¡åšå®ƒçš„æœºä¼š!* â€“ ä½ åªåšäº†ä¸€æ¬¡å—ï¼Ÿç¼–å†™å’Œè‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹å¯èƒ½éœ€è¦2-4å€çš„æ—¶é—´ã€‚é€šå¸¸ï¼Œè¿™æ˜¯å€¼å¾—çš„ã€‚'
- en: Be Like Us â€“ it will change you. Users feel limited, programmers truly harness
    the power of their applications and hardware.
  id: totrans-1559
  prefs: []
  type: TYPE_NORMAL
  zh: åƒæˆ‘ä»¬ä¸€æ · â€“ è¿™å°†æ”¹å˜ä½ ã€‚ç”¨æˆ·ä¼šæ„Ÿåˆ°å—é™ï¼Œç¨‹åºå‘˜çœŸæ­£åˆ©ç”¨äº†ä»–ä»¬çš„åº”ç”¨ç¨‹åºå’Œç¡¬ä»¶çš„åŠ›é‡ã€‚
- en: '**Recall** (classification accuracy metric)'
  id: totrans-1560
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¬å›ç‡**ï¼ˆåˆ†ç±»å‡†ç¡®åº¦æŒ‡æ ‡ï¼‰'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a categorical classification
    prediction model measure of accuracy, a single summary metric for each \(k\) category
    from the confusion matrix.'
  id: totrans-1561
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ç§åˆ†ç±»é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®æ€§åº¦é‡ï¼Œæ··æ·†çŸ©é˜µä¸­æ¯ä¸ª \(k\) ç±»åˆ«çš„å•ä¸€æ±‡æ€»æŒ‡æ ‡ã€‚'
- en: the ratio of true positives divided by all cases of the category in the testing
    dataset
  id: totrans-1562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹è¯•æ•°æ®é›†ä¸­è¯¥ç±»åˆ«çš„æ‰€æœ‰æ¡ˆä¾‹ä¸­çœŸå®æ­£ä¾‹ä¸æ‰€æœ‰æ¡ˆä¾‹çš„æ¯”ç‡
- en: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
  id: totrans-1563
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
- en: '**Recursive Feature Elimination**'
  id: totrans-1564
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é€’å½’ç‰¹å¾æ¶ˆé™¤**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a method works by
    recursively removing features and building a model with the remaining features.'
  id: totrans-1565
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸€ç§é€šè¿‡é€’å½’åˆ é™¤ç‰¹å¾å¹¶ä½¿ç”¨å‰©ä½™ç‰¹å¾æ„å»ºæ¨¡å‹çš„æ–¹æ³•ã€‚'
- en: build a model with all features, calculate a feature ranking metric, e.g., coefficient
    or feature importance, depending on which is available with the modeling method
  id: totrans-1566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ‰€æœ‰ç‰¹å¾æ„å»ºæ¨¡å‹ï¼Œè®¡ç®—ç‰¹å¾æ’åºæŒ‡æ ‡ï¼Œä¾‹å¦‚ç³»æ•°æˆ–ç‰¹å¾é‡è¦æ€§ï¼Œå…·ä½“å–å†³äºå»ºæ¨¡æ–¹æ³•ä¸­å“ªäº›å¯ç”¨
- en: remove the feature with the lowest feature importance and rebuild the model
  id: totrans-1567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ é™¤ç‰¹å¾é‡è¦æ€§æœ€ä½çš„ç‰¹å¾å¹¶é‡æ–°æ„å»ºæ¨¡å‹
- en: repeat the process until only one feature remains
  id: totrans-1568
  prefs: []
  type: TYPE_NORMAL
  zh: é‡å¤æ­¤è¿‡ç¨‹ï¼Œç›´åˆ°åªå‰©ä¸‹ä¸€ä¸ªç‰¹å¾
- en: Any model predictive model could be used,
  id: totrans-1569
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•é¢„æµ‹æ¨¡å‹éƒ½å¯ä»¥ä½¿ç”¨ï¼Œ
- en: the method assigns rank \(1,\ldots,ğ‘š\) for all features as reverse order of
    removal, i.e., last remaining feature is most important and first removed is least
    important
  id: totrans-1570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•ä¸ºæ‰€æœ‰ç‰¹å¾åˆ†é… \(1,\ldots,ğ‘š\) çš„æ’åï¼ŒæŒ‰åˆ é™¤é¡ºåºçš„é€†åºï¼Œå³æœ€åå‰©ä¸‹çš„ç‰¹å¾æœ€é‡è¦ï¼Œæœ€å…ˆåˆ é™¤çš„æœ€ä¸é‡è¦
- en: '**Reservoir Modeling Workflow**'
  id: totrans-1571
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚¨å±‚å»ºæ¨¡å·¥ä½œæµç¨‹**'
- en: '[Machine Learning Workflow Construction and Coding](MachineLearning_workflow_construction.html):
    the following is the common geostatistical reservoir modeling workflow:'
  id: totrans-1572
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ](MachineLearning_workflow_construction.html)ï¼šä»¥ä¸‹ä¸ºå¸¸è§çš„åœ°è´¨ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡å·¥ä½œæµç¨‹ï¼š'
- en: Integrate all available information to build multiple subsurface scenarios and
    realizations to sample the uncertainty space
  id: totrans-1573
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•´åˆæ‰€æœ‰å¯ç”¨ä¿¡æ¯ï¼Œæ„å»ºå¤šä¸ªåœ°ä¸‹åœºæ™¯å’Œå®ç°ï¼Œä»¥é‡‡æ ·ä¸ç¡®å®šæ€§ç©ºé—´
- en: Apply all the models to the transfer function to sample the decision criteria
  id: totrans-1574
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰æ¨¡å‹åº”ç”¨äºä¼ é€’å‡½æ•°ä»¥é‡‡æ ·å†³ç­–æ ‡å‡†
- en: Assemble the distribution of the decision criteria
  id: totrans-1575
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»„è£…å†³ç­–æ ‡å‡†çš„åˆ†å¸ƒ
- en: Make the optimum reservoir development decisions accounting for this uncertainty
    model
  id: totrans-1576
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è€ƒè™‘æ­¤ä¸ç¡®å®šæ€§æ¨¡å‹ï¼Œåšå‡ºæœ€ä½³å‚¨å±‚å¼€å‘å†³ç­–
- en: '**Response Feature**'
  id: totrans-1577
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å“åº”ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): output feature
    for a predictive machine learning model. We can generalize a predictive machine
    learning model as,'
  id: totrans-1578
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å‡ºç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹æ¦‚æ‹¬ä¸ºï¼Œ'
- en: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
  id: totrans-1579
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
- en: where the response feature is \(y\), the predictor features are \(x_1,\ldots,x_m\),
    and \(\epsilon\) is model error
  id: totrans-1580
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­å“åº”ç‰¹å¾æ˜¯ \(y\)ï¼Œé¢„æµ‹ç‰¹å¾æ˜¯ \(x_1,\ldots,x_m\)ï¼Œè€Œ \(\epsilon\) æ˜¯æ¨¡å‹è¯¯å·®
- en: traditional statistics uses the term dependent variable
  id: totrans-1581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿç»Ÿè®¡å­¦ä½¿ç”¨æœ¯è¯­å› å˜é‡
- en: '**Ridge Regression** (Tikhonov Regularization)'
  id: totrans-1582
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å²­å›å½’**ï¼ˆTikhonovæ­£åˆ™åŒ–ï¼‰'
- en: '[Ridge Regression](MachineLearning_ridge_regression.html): a linear, parametric
    prediction model,'
  id: totrans-1583
  prefs: []
  type: TYPE_NORMAL
  zh: '[å²­å›å½’](MachineLearning_ridge_regression.html)ï¼šä¸€ç§çº¿æ€§ã€å‚æ•°åŒ–çš„é¢„æµ‹æ¨¡å‹ï¼Œ'
- en: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
  id: totrans-1584
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
- en: The analytical solution for the model parameters, \(b_1,\ldots,b_m,b_0\), is
    available for the L2 norm loss function, the errors are summed and squared known
    a least squares.
  id: totrans-1585
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºL2èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œæ¨¡å‹å‚æ•° \(b_1,\ldots,b_m,b_0\) çš„è§£æè§£æ˜¯å¯ç”¨çš„ï¼Œè¯¯å·®æ˜¯æ€»å’Œå¹¶å¹³æ–¹çš„å·²çŸ¥æœ€å°äºŒä¹˜ã€‚
- en: 'we minimize a loss function including the error, residual sum of squares (RSS)
    over the training data and a regularization term:'
  id: totrans-1586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€å°åŒ–åŒ…æ‹¬è¯¯å·®ã€è®­ç»ƒæ•°æ®ä¸Šçš„æ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰å’Œæ­£åˆ™åŒ–é¡¹çš„æŸå¤±å‡½æ•°ï¼š
- en: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 + \lambda \sum_{\alpha = 1}^m b_{\alpha}^2 \]
  id: totrans-1587
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 + \lambda \sum_{\alpha = 1}^m b_{\alpha}^2 \]
- en: where \(y_i\) is the actual response feature values and \(\sum_{\alpha = 1}^m
    b_{\alpha} x_{\alpha} + b_0\) are the model predictions, over the \(\alpha = 1,\ldots,n\)
    training data, and \(\lambda \sum_{\alpha = 1}^m b_{\alpha}^2\) is the shrinkage
    penalty.
  id: totrans-1588
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(y_i\) æ˜¯å®é™…å“åº”ç‰¹å¾å€¼ï¼Œ\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\) æ˜¯æ¨¡å‹é¢„æµ‹ï¼Œåœ¨
    \(\alpha = 1,\ldots,n\) çš„è®­ç»ƒæ•°æ®ä¸Šï¼Œ\(\lambda \sum_{\alpha = 1}^m b_{\alpha}^2\) æ˜¯æ”¶ç¼©æƒ©ç½šé¡¹ã€‚
- en: With ridge regression we add a hyperparameter, \(\lambda\), to our minimization,
    with a shrinkage penalty term, \(\sum_{j=1}^m b_{\alpha}^2\).
  id: totrans-1589
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å²­å›å½’ä¸­ï¼Œæˆ‘ä»¬å‘æœ€å°åŒ–ä¸­æ·»åŠ ä¸€ä¸ªè¶…å‚æ•° \(\lambda\)ï¼Œæ”¶ç¼©æƒ©ç½šé¡¹ \(\sum_{j=1}^m b_{\alpha}^2\)ã€‚
- en: As a result, ridge regression training integrates two and often competing goals
    to find the model parameters,
  id: totrans-1590
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå²­å›å½’è®­ç»ƒæ•´åˆäº†ä¸¤ä¸ªç»å¸¸ç›¸äº’ç«äº‰çš„ç›®æ ‡ï¼Œä»¥æ‰¾åˆ°æ¨¡å‹å‚æ•°ï¼Œ
- en: find the model parameters that minimize the error with training data
  id: totrans-1591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ä½¿è®­ç»ƒæ•°æ®è¯¯å·®æœ€å°çš„æ¨¡å‹å‚æ•°
- en: minimize the slope parameters towards zero
  id: totrans-1592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ–œç‡å‚æ•°æœ€å°åŒ–åˆ°é›¶
- en: 'Note: lambda does not include the intercept, \(b_0\).'
  id: totrans-1593
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼šlambda ä¸åŒ…æ‹¬æˆªè·ï¼Œ\(b_0\)ã€‚
- en: The \(\lambda\) is a hyperparameter that controls the degree of fit of the model
    and may be related to the model bias-variance trade-off.
  id: totrans-1594
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lambda\) æ˜¯ä¸€ä¸ªæ§åˆ¶æ¨¡å‹æ‹Ÿåˆç¨‹åº¦çš„è¶…å‚æ•°ï¼Œå¯èƒ½ä¸æ¨¡å‹åå·®-æ–¹å·®æƒè¡¡æœ‰å…³ã€‚
- en: for \(\lambda \rightarrow 0\) the solution approaches linear regression, there
    is no bias (relative to a linear model fit), but the model variance is likely
    higher
  id: totrans-1595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(\lambda \rightarrow 0\) æ—¶ï¼Œè§£è¶‹è¿‘äºçº¿æ€§å›å½’ï¼Œæ²¡æœ‰åå·®ï¼ˆç›¸å¯¹äºçº¿æ€§æ¨¡å‹æ‹Ÿåˆï¼‰ï¼Œä½†æ¨¡å‹æ–¹å·®å¯èƒ½æ›´é«˜
- en: as \(\lambda\) increases the model variance decreases and the model bias increases,
    the model becomes simpler
  id: totrans-1596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€ \(\lambda\) çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å‡å°ï¼Œæ¨¡å‹åå·®å¢åŠ ï¼Œæ¨¡å‹å˜å¾—ç®€å•
- en: for \(\lambda \rightarrow \infty\) the model parameters \(b_1,\ldots,b_m\) shrink
    to 0.0 and the model predictions approaches the training data response feature
    mean
  id: totrans-1597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(\lambda \rightarrow \infty\) æ—¶ï¼Œæ¨¡å‹å‚æ•° \(b_1,\ldots,b_m\) æ”¶ç¼©åˆ° 0.0ï¼Œæ¨¡å‹é¢„æµ‹è¶‹è¿‘äºè®­ç»ƒæ•°æ®å“åº”ç‰¹å¾å‡å€¼
- en: '**Sample**'
  id: totrans-1598
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ·æœ¬**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the set of values,
    locations that have been measured'
  id: totrans-1599
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå·²æµ‹é‡çš„å€¼å’Œä½ç½®çš„é›†åˆ'
- en: for example, 1,000 porosity measures from well-logs over the wells in the reservoir
  id: totrans-1600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ¥è‡ªå‚¨å±‚ä¸­äº•çš„äº•æ—¥å¿—çš„ 1,000 ä¸ªå­”éš™åº¦æµ‹é‡å€¼
- en: or 1,000,000 acoustic impedance measurements over a 1000 x 1000 2D grid for
    a reservoir unit of interest
  id: totrans-1601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ–è€…åœ¨ä¸€ä¸ª 1000 x 1000 çš„ 2D ç½‘æ ¼ä¸Šå¯¹æ„Ÿå…´è¶£å‚¨å±‚å•å…ƒçš„ 1,000,000 ä¸ªå£°æ³¢é˜»æŠ—æµ‹é‡å€¼
- en: '**Scenarios** (uncertainty)'
  id: totrans-1602
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åœºæ™¯**ï¼ˆä¸ç¡®å®šæ€§ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): multiple spatial,
    subsurface models calculated by stochastic simulation by changing the input parameters
    or other modeling choices to represent the uncertainty due to inference of model
    parameters and model choices'
  id: totrans-1603
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€šè¿‡æ”¹å˜è¾“å…¥å‚æ•°æˆ–å…¶ä»–å»ºæ¨¡é€‰æ‹©è¿›è¡Œéšæœºæ¨¡æ‹Ÿè®¡ç®—å‡ºçš„å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹ï¼Œä»¥è¡¨ç¤ºç”±äºæ¨¡å‹å‚æ•°å’Œæ¨¡å‹é€‰æ‹©çš„æ¨æ–­æ‰€å¼•èµ·çš„ä¸ç¡®å®šæ€§'
- en: for example, model three porosity input distribution, porosity mean low, mid
    and high, and vary the input distribution to calculate new subsurface models
  id: totrans-1604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ¨¡å‹ä¸‰ä¸ªå­”éš™åº¦è¾“å…¥åˆ†å¸ƒï¼Œå­”éš™åº¦å‡å€¼ä½ã€ä¸­ã€é«˜ï¼Œå¹¶æ”¹å˜è¾“å…¥åˆ†å¸ƒæ¥è®¡ç®—æ–°çš„åœ°ä¸‹æ¨¡å‹
- en: '**Secondary Data**'
  id: totrans-1605
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¬¡çº§æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data samples for
    another feature, not the feature of interest, the target feature for building
    a model, but are used to improve the prediction of the target feature.'
  id: totrans-1606
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸ºå¦ä¸€ä¸ªç‰¹å¾æä¾›æ•°æ®æ ·æœ¬ï¼Œè€Œä¸æ˜¯æ„Ÿå…´è¶£çš„ç‰¹å¾ï¼Œç”¨äºæ„å»ºæ¨¡å‹çš„ç‰¹å¾ï¼Œä½†ç”¨äºæé«˜ç›®æ ‡ç‰¹å¾çš„é¢„æµ‹ã€‚'
- en: requires a model of the relationship between the primary and secondary data
  id: totrans-1607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éœ€è¦å»ºç«‹ä¸»æ¬¡çº§æ•°æ®ä¹‹é—´å…³ç³»æ¨¡å‹
- en: For example, samples in space of,
  id: totrans-1608
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œç©ºé—´ä¸­çš„æ ·æœ¬ï¼Œ
- en: acoustic impedance (secondary data) to support calculation of a model of porosity,
    the feature of interest
  id: totrans-1609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°æ³¢é˜»æŠ—ï¼ˆæ¬¡çº§æ•°æ®ï¼‰ä»¥æ”¯æŒè®¡ç®—å­”éš™åº¦æ¨¡å‹ï¼Œæ„Ÿå…´è¶£çš„ç‰¹å¾
- en: porosity (secondary data) to support calculation of a model of permeability,
    the feature of interest
  id: totrans-1610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™åº¦ï¼ˆæ¬¡çº§æ•°æ®ï¼‰ä»¥æ”¯æŒè®¡ç®—æ¸—é€ç‡æ¨¡å‹ï¼Œæ„Ÿå…´è¶£çš„ç‰¹å¾
- en: '**Seismic Data**'
  id: totrans-1611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åœ°éœ‡æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): indirect measurement
    with remote sensing, reflection seismic applies acoustic source(s) and receivers
    (geophones) to map acoustic reflections with high coverage and generally low resolution.
    Some more details,'
  id: totrans-1612
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä½¿ç”¨é¥æ„Ÿè¿›è¡Œé—´æ¥æµ‹é‡ï¼Œåå°„åœ°éœ‡ä½¿ç”¨å£°æºï¼ˆå¦‚åœ°éœ‡æ£€æ³¢å™¨ï¼‰å’Œæ¥æ”¶å™¨ï¼ˆå¦‚åœ°éœ‡æ£€æ³¢å™¨ï¼‰æ¥ç»˜åˆ¶é«˜è¦†ç›–ç‡å’Œä¸€èˆ¬ä½åˆ†è¾¨ç‡çš„å£°æ³¢åå°„å›¾ã€‚ä¸€äº›æ›´è¯¦ç»†çš„è¯´æ˜ï¼Œ'
- en: seismic reflections (amplitude) data are inverted to rock properties, e.g.,
    acoustic impedance, consistent with and positionally anchored with well sonic
    logs
  id: totrans-1613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°éœ‡åå°„ï¼ˆæŒ¯å¹…ï¼‰æ•°æ®è¢«åæ¼”ä¸ºå²©çŸ³å±æ€§ï¼Œä¾‹å¦‚å£°é˜»æŠ—ï¼Œä¸äº•å£°æ³¢æµ‹äº•æ•°æ®ä¸€è‡´ä¸”ä½ç½®é”šå®š
- en: provides framework, bounding surfaces for extents and shapes of reservoirs along
    with soft information on reservoir properties, e.g., porosity and facies.
  id: totrans-1614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æä¾›æ¡†æ¶ï¼Œä¸ºå‚¨å±‚èŒƒå›´å’Œå½¢çŠ¶æä¾›è¾¹ç•Œè¡¨é¢ï¼Œä»¥åŠå…³äºå‚¨å±‚å±æ€§ï¼ˆå¦‚å­”éš™åº¦å’Œå²©æ€§ï¼‰çš„è½¯ä¿¡æ¯ã€‚
- en: '**Shapley Value**'
  id: totrans-1615
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Shapleyå€¼**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): model-based, local
    (for a single prediction) and global (over a suit of predictions) feature importance
    by learning contribution of each feature to the prediction.'
  id: totrans-1616
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šåŸºäºæ¨¡å‹ã€å±€éƒ¨ï¼ˆé’ˆå¯¹å•ä¸ªé¢„æµ‹ï¼‰å’Œå…¨å±€ï¼ˆé’ˆå¯¹ä¸€ç³»åˆ—é¢„æµ‹ï¼‰çš„ç‰¹å¾é‡è¦æ€§ï¼Œé€šè¿‡å­¦ä¹ æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®ã€‚'
- en: A explainable machine learning method to support complicated models are often
    required but have low interpretability.
  id: totrans-1617
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦ä¸€ç§å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ–¹æ³•æ¥æ”¯æŒå¤æ‚çš„æ¨¡å‹ï¼Œä½†é€šå¸¸å¯è§£é‡Šæ€§è¾ƒä½ã€‚
- en: Two choices to improve model interpretability,
  id: totrans-1618
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥æé«˜æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œ
- en: reduce the complexity of the models, but may also reduce model accuracy
  id: totrans-1619
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡å°‘æ¨¡å‹çš„å¤æ‚æ€§ï¼Œä½†ä¹Ÿå¯èƒ½é™ä½æ¨¡å‹ç²¾åº¦
- en: develop improved, agnostic (for any model) model diagnostics, i.e., Shapley
    value
  id: totrans-1620
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å‘æ”¹è¿›çš„ã€æ— å·®åˆ«çš„ï¼ˆé€‚ç”¨äºä»»ä½•æ¨¡å‹ï¼‰æ¨¡å‹è¯Šæ–­ï¼Œå³Shapleyå€¼
- en: Shapley value is a cooperative game theory approach that,
  id: totrans-1621
  prefs: []
  type: TYPE_NORMAL
  zh: Shapleyå€¼æ˜¯ä¸€ç§åˆä½œåšå¼ˆè®ºæ–¹æ³•ï¼Œ
- en: for allocating resources between players based on a summarization of marginal
    contributions, i.e., dividing up payment between players
  id: totrans-1622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®å¯¹è¾¹é™…è´¡çŒ®çš„æ€»ç»“æ¥åˆ†é…èµ„æºç»™ç©å®¶ï¼Œå³ï¼Œåœ¨ç©å®¶ä¹‹é—´åˆ†é…ä»˜æ¬¾
- en: calculates the contribution of each predictor feature to push the response prediction
    away from the mean value of the response
  id: totrans-1623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯ä¸ªé¢„æµ‹ç‰¹å¾å¯¹æ¨åŠ¨å“åº”é¢„æµ‹è¿œç¦»å“åº”å‡å€¼è´¡çŒ®çš„å¤§å°
- en: marginal contributions and Shapley values are in units of the response feature
  id: totrans-1624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾¹é™…è´¡çŒ®å’ŒShapleyå€¼ä»¥å“åº”ç‰¹å¾çš„å•ä½è®¡
- en: in the units of the response feature
  id: totrans-1625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥å“åº”ç‰¹å¾çš„å•ä½
- en: '**Simpsonâ€™s Paradox**'
  id: totrans-1626
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¾›æ™®æ£®æ‚–è®º**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): data trend
    reverses or disappears when groups are combined (or separated). Often observed
    in correlation analysis when grouping data, for example,'
  id: totrans-1627
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šå½“ç»„åˆï¼ˆæˆ–åˆ†ç¦»ï¼‰ç»„æ—¶ï¼Œæ•°æ®è¶‹åŠ¿ä¼šé€†è½¬æˆ–æ¶ˆå¤±ã€‚åœ¨åˆ†ç»„æ•°æ®çš„ç›¸å…³åˆ†æä¸­ç»å¸¸è§‚å¯Ÿåˆ°ï¼Œä¾‹å¦‚ï¼Œ'
- en: groups each have a negative correlation, but the whole has a positive correlation
  id: totrans-1628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ç»„ä¹‹é—´éƒ½æœ‰è´Ÿç›¸å…³ï¼Œä½†æ•´ä½“ä¸Šå‘ˆæ­£ç›¸å…³
- en: '**Soft Data**'
  id: totrans-1629
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è½¯æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data that has a
    high degree of uncertainty, such that data uncertainty must be integrated into
    the model'
  id: totrans-1630
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå…·æœ‰é«˜åº¦ä¸ç¡®å®šæ€§çš„æ•°æ®ï¼Œå› æ­¤æ•°æ®ä¸ç¡®å®šæ€§å¿…é¡»æ•´åˆåˆ°æ¨¡å‹ä¸­'
- en: for example, probability density function for local porosity calibrated from
    acoustic impedance
  id: totrans-1631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä»å£°é˜»æŠ—æ ¡å‡†çš„å±€éƒ¨å­”éš™ç‡çš„æ¦‚ç‡å¯†åº¦å‡½æ•°
- en: Soft data integration requires workflows like *indicator kriging*, *indicator
    simulation* and *p-field simulation* or workflows that randomize the data with
    standard simulation methods that assume hard data like *sequential Gaussian simulation*.
  id: totrans-1632
  prefs: []
  type: TYPE_NORMAL
  zh: è½¯æ•°æ®é›†æˆéœ€è¦å¦‚*æŒ‡ç¤ºå…‹é‡Œé‡‘*ã€*æŒ‡ç¤ºæ¨¡æ‹Ÿ*å’Œ*påœºæ¨¡æ‹Ÿ*æˆ–éšæœºåŒ–æ•°æ®çš„æµç¨‹ï¼Œè¿™äº›æµç¨‹ä½¿ç”¨å‡è®¾ç¡¬æ•°æ®çš„æ ‡å‡†æ¨¡æ‹Ÿæ–¹æ³•ï¼Œå¦‚*é¡ºåºé«˜æ–¯æ¨¡æ‹Ÿ*ã€‚
- en: soft data integration is an advanced topic and a focus of ongoing research,
    but is often to done with standard, subsurface modeling software packages
  id: totrans-1633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è½¯æ•°æ®é›†æˆæ˜¯ä¸€ä¸ªé«˜çº§ä¸»é¢˜ï¼Œä¹Ÿæ˜¯å½“å‰ç ”ç©¶çš„çƒ­ç‚¹ï¼Œä½†é€šå¸¸ä½¿ç”¨æ ‡å‡†çš„ã€åœ°ä¸‹å»ºæ¨¡è½¯ä»¶åŒ…æ¥å®Œæˆ
- en: '**Spatial Sampling** (biased)'
  id: totrans-1634
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆæœ‰åï¼‰'
- en: 'Data Preparation: sample such that the sample statistics are not representative
    of the population parameters. For example,'
  id: totrans-1635
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šæ ·æœ¬é€‰æ‹©åº”ç¡®ä¿æ ·æœ¬ç»Ÿè®¡é‡ä¸ä»£è¡¨æ€»ä½“å‚æ•°ã€‚ä¾‹å¦‚ï¼Œ
- en: the sample mean is not the same as the population mean
  id: totrans-1636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬å‡å€¼ä¸æ€»ä½“å‡å€¼ä¸åŒ
- en: the sample variance is not the same as the population variance
  id: totrans-1637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ–¹å·®ä¸æ€»ä½“æ–¹å·®ä¸åŒ
- en: Of course, the population parameters are not accessible, so we cannot directly
    calculate sampling bias, i.e., the difference between the sample statistics and
    the population parameters. Methods we can use to check for biased sampling,
  id: totrans-1638
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œäººå£å‚æ•°æ˜¯ä¸å¯è·å–çš„ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®—æŠ½æ ·åå·®ï¼Œå³æ ·æœ¬ç»Ÿè®¡é‡ä¸æ€»ä½“å‚æ•°ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ¥æ£€æŸ¥æŠ½æ ·åå·®çš„æ–¹æ³•ï¼Œ
- en: evaluate the samples for preferential sampling, clustering, filtering, etc.
  id: totrans-1639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ ·æœ¬ä»¥è¿›è¡Œä¼˜å…ˆæŠ½æ ·ã€èšé›†ã€è¿‡æ»¤ç­‰ã€‚
- en: apply *declustering* and check the results for a major change in the summary
    statistics, this is using declustering diagnostically
  id: totrans-1640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨*å»èšé›†*å¹¶æ£€æŸ¥æ€»ç»“ç»Ÿè®¡é‡æ˜¯å¦æœ‰é‡å¤§å˜åŒ–ï¼Œè¿™æ˜¯ä½¿ç”¨å»èšé›†è¿›è¡Œè¯Šæ–­
- en: '**Spatial Sampling** (clustered)'
  id: totrans-1641
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆèšé›†ï¼‰'
- en: 'Data Preparation: spatial samples with locations preferentially selected, i.e.,
    clustered, resulting in biased statistics,'
  id: totrans-1642
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šç©ºé—´æ ·æœ¬å…·æœ‰ä¼˜å…ˆé€‰æ‹©çš„åœ°ç‚¹ï¼Œå³èšé›†ï¼Œå¯¼è‡´ç»Ÿè®¡åå·®ï¼Œ
- en: typically spatial samples are clustered in locations with higher value samples,
    e.g., high porosity and permeability, good quality shale for unconventional reservoirs,
    low acoustic impedance indicating higher porosity, etc.
  id: totrans-1643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç©ºé—´æ ·æœ¬ä¼šèšé›†åœ¨å…·æœ‰æ›´é«˜ä»·å€¼æ ·æœ¬çš„åœ°ç‚¹ï¼Œä¾‹å¦‚ï¼Œé«˜å­”éš™ç‡å’Œæ¸—é€ç‡ï¼Œä¼˜è´¨é¡µå²©ç”¨äºéå¸¸è§„å‚¨å±‚ï¼Œä½å£°é˜»æŠ—æŒ‡ç¤ºæ›´é«˜çš„å­”éš™ç‡ç­‰ã€‚
- en: Of course, the population parameters are not accessible, so we cannot directly
    calculate sampling bias, i.e., the difference between the sample statistics and
    the population parameters. Methods we can use to check for biased sampling,
  id: totrans-1644
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œäººå£å‚æ•°æ˜¯ä¸å¯è·å–çš„ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®—æŠ½æ ·åå·®ï¼Œå³æ ·æœ¬ç»Ÿè®¡é‡ä¸æ€»ä½“å‚æ•°ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ¥æ£€æŸ¥æŠ½æ ·åå·®çš„æ–¹æ³•ï¼Œ
- en: evaluate the samples for preferential sampling, clustering, filtering, etc.
  id: totrans-1645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ ·æœ¬ä»¥è¿›è¡Œä¼˜å…ˆæŠ½æ ·ã€èšé›†ã€è¿‡æ»¤ç­‰ã€‚
- en: apply *declustering* and check the results for a major change in the summary
    statistics, this is using declustering diagnostically
  id: totrans-1646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨*å»èšé›†*å¹¶æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰é‡å¤§å˜åŒ–ï¼Œè¿™æ˜¯ä½¿ç”¨å»èšé›†è¿›è¡Œè¯Šæ–­
- en: '**Spatial Sampling** (common practice)'
  id: totrans-1647
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆå¸¸è§åšæ³•ï¼‰'
- en: 'Data Preparation: sample locations are selected to,'
  id: totrans-1648
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šæ ·æœ¬åœ°ç‚¹çš„é€‰æ‹©æ˜¯ä¸ºäº†ï¼Œ
- en: '*Reduce uncertainty* - by answering questions, for example,'
  id: totrans-1649
  prefs: []
  type: TYPE_NORMAL
  zh: '*å‡å°‘ä¸ç¡®å®šæ€§*â€”â€”é€šè¿‡å›ç­”é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œ'
- en: how far does the contaminant plume extend? â€“ sample peripheries
  id: totrans-1650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ±¡æŸ“ç¾½æµå»¶ä¼¸å¤šè¿œï¼Ÿâ€”â€”æ ·æœ¬è¾¹ç¼˜
- en: where is the fault? â€“ drill based on seismic interpretation
  id: totrans-1651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°è´¨æ–­å±‚åœ¨å“ªé‡Œï¼Ÿâ€”â€”åŸºäºåœ°éœ‡è§£é‡Šè¿›è¡Œé’»äº•
- en: what is the highest mineral grade? â€“ sample the best part
  id: totrans-1652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€é«˜çŸ¿ç‰©å“ä½æ˜¯å¤šå°‘ï¼Ÿâ€”â€”æ ·æœ¬æœ€ä½³éƒ¨åˆ†
- en: who far does the reservoir extend? â€“ offset drilling
  id: totrans-1653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ°´åº“å»¶ä¼¸å¤šè¿œï¼Ÿâ€”â€”åå¿ƒé’»äº•
- en: '*Directly maximize net present value* - while collecting information, for example,'
  id: totrans-1654
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç›´æ¥æœ€å¤§åŒ–å‡€ç°å€¼*â€”â€”åœ¨æ”¶é›†ä¿¡æ¯æ—¶ï¼Œä¾‹å¦‚ï¼Œ'
- en: maximize production rates
  id: totrans-1655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–ç”Ÿäº§ç‡
- en: maximize tonnage of mineral extracted
  id: totrans-1656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–æå–çš„çŸ¿ç‰©å¨æ•°
- en: In other words, often our samples are dual purpose, e.g., wells that are drilled
    for exploration and appraisal information are subsequently utilized for production.
  id: totrans-1657
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„æ ·æœ¬é€šå¸¸æ˜¯åŒç”¨é€”çš„ï¼Œä¾‹å¦‚ï¼Œä¸ºå‹˜æ¢å’Œè¯„ä¼°ä¿¡æ¯è€Œé’»æ¢çš„äº•éšåç”¨äºç”Ÿäº§ã€‚
- en: '**Spatial Sampling** (representative)'
  id: totrans-1658
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆä»£è¡¨æ€§ï¼‰'
- en: 'Data Preparation: if we are sampling for representativity, i.e., the sample
    set and resulting sample statistics are representative of the population, by sampling
    theory we have 2 options:'
  id: totrans-1659
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šå¦‚æœæˆ‘ä»¬æ˜¯ä¸ºäº†ä»£è¡¨æ€§è¿›è¡ŒæŠ½æ ·ï¼Œå³æ ·æœ¬é›†å’Œç”±æ­¤äº§ç”Ÿçš„æ ·æœ¬ç»Ÿè®¡é‡ä»£è¡¨æ€»ä½“ï¼Œæ ¹æ®æŠ½æ ·ç†è®ºï¼Œæˆ‘ä»¬æœ‰2ç§é€‰æ‹©ï¼š
- en: '*Random sampling* - each potential sample from the population is equally likely
    to be sampled as samples are collected. This includes,'
  id: totrans-1660
  prefs: []
  type: TYPE_NORMAL
  zh: '*éšæœºæŠ½æ ·*â€”â€”ä»æ€»ä½“ä¸­æ”¶é›†çš„æ¯ä¸ªæ½œåœ¨æ ·æœ¬è¢«æŠ½æ ·çš„å¯èƒ½æ€§ç›¸ç­‰ã€‚è¿™åŒ…æ‹¬ï¼Œ'
- en: selecting a specific location has no impact on the selection of subsequent locations.
  id: totrans-1661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ç‰¹å®šä½ç½®ä¸ä¼šå½±å“åç»­ä½ç½®çš„é€‰æ‹©ã€‚
- en: assumption that the population size that is much larger than the sample size;
    therefore, significant correlation between samples is not imposed due to without
    replacement sampling (the constraint that you can only sample a location once).
    Note, generally this is not an issue for the subsurface due to the sparsely sampled
    massive populations
  id: totrans-1662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡è®¾æ€»ä½“å¤§å°è¿œå¤§äºæ ·æœ¬å¤§å°ï¼›å› æ­¤ï¼Œç”±äºä¸é‡å¤æŠ½æ ·ï¼ˆåªèƒ½å¯¹ä½ç½®è¿›è¡Œä¸€æ¬¡æŠ½æ ·çš„çº¦æŸï¼‰ï¼Œæ ·æœ¬ä¹‹é—´æ²¡æœ‰æ˜¾è‘—çš„å…³è”ã€‚æ³¨æ„ï¼Œç”±äºåœ°ä¸‹æ˜¯ç¨€ç–æŠ½æ ·çš„å·¨å¤§æ€»ä½“ï¼Œè¿™é€šå¸¸ä¸æ˜¯é—®é¢˜
- en: '*Regular sampling* - sampling at equal space or time intervals. While random
    sampling is preferred, regular sampling is robust as long as,'
  id: totrans-1663
  prefs: []
  type: TYPE_NORMAL
  zh: '*è§„åˆ™æŠ½æ ·*â€”â€”åœ¨ç›¸ç­‰çš„ç©ºé—´æˆ–æ—¶é—´é—´éš”è¿›è¡ŒæŠ½æ ·ã€‚è™½ç„¶éšæœºæŠ½æ ·æ˜¯é¦–é€‰ï¼Œä½†åªè¦ï¼Œ'
- en: the regular sampling intervals do not align with natural periodicity in the
    data, for example, the crests are systematically samples resulting in biased high
    sample statistics
  id: totrans-1664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸¸è§„é‡‡æ ·é—´éš”ä¸æ•°æ®ä¸­çš„è‡ªç„¶å‘¨æœŸæ€§ä¸ä¸€è‡´ï¼Œä¾‹å¦‚ï¼Œå³°å€¼æ˜¯ç³»ç»Ÿæ€§åœ°é‡‡æ ·ï¼Œå¯¼è‡´æ ·æœ¬ç»Ÿè®¡é‡åé«˜
- en: '**Spectral Clustering**'
  id: totrans-1665
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è°±èšç±»**'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a partitional
    clustering method that utilizes the spectrum, eigenvalues and eigenvectors, of
    a matrix that represents the pairwise relationships between the data.'
  id: totrans-1666
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šä¸€ç§åˆ†åŒºèšç±»æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨è¡¨ç¤ºæ•°æ®æˆå¯¹å…³ç³»çš„çŸ©é˜µçš„è°±ã€ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ã€‚'
- en: dimensionality reduction from data samples pairwise relationships characterized
    by the graph Laplacian matrix
  id: totrans-1667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ•°æ®æ ·æœ¬æˆå¯¹å…³ç³»ï¼ˆç”±å›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µè¡¨å¾ï¼‰è¿›è¡Œé™ç»´
- en: eigenvalues, eigenvectors are equivalent to principal component analysis dimensionality
    reduction by linear, orthogonal feature projection and rotation to best describe
    the variance
  id: totrans-1668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å€¼ï¼Œç‰¹å¾å‘é‡ç­‰åŒäºé€šè¿‡çº¿æ€§ã€æ­£äº¤ç‰¹å¾æŠ•å½±å’Œæ—‹è½¬è¿›è¡Œä¸»æˆåˆ†åˆ†æé™ç»´ï¼Œä»¥æœ€ä½³æè¿°æ–¹å·®
- en: Advantages of spectral clustering,
  id: totrans-1669
  prefs: []
  type: TYPE_NORMAL
  zh: è°±èšç±»çš„ä¼˜ç‚¹ï¼Œ
- en: the ability to encode pairwise relationships, integrate expert knowledge.
  id: totrans-1670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼–ç æˆå¯¹å…³ç³»çš„èƒ½åŠ›ï¼Œæ•´åˆä¸“å®¶çŸ¥è¯†ã€‚
- en: eigenvalues provide useful information on the number of clusters, based on the
    degree of â€˜cuttingâ€™ required to make k clusters
  id: totrans-1671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å€¼æä¾›äº†å…³äºèšç±»æ•°é‡çš„æœ‰ç”¨ä¿¡æ¯ï¼ŒåŸºäºåˆ›å»º k ä¸ªèšç±»æ‰€éœ€çš„â€œåˆ‡å‰²â€ç¨‹åº¦
- en: lower dimensional representation for the sample data pairwise relationships
  id: totrans-1672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ•°æ®æˆå¯¹å…³ç³»çš„ä½ç»´è¡¨ç¤º
- en: the resulting eigenvalues and eigenvectors can be interpreted, eigenvalues describe
    the amount of connection for each number of groups and eigenvectors are grouped
    to form the clusters
  id: totrans-1673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“æœç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡å¯ä»¥è§£é‡Šï¼Œç‰¹å¾å€¼æè¿°äº†æ¯ä¸ªç»„è¿æ¥çš„æ•°é‡ï¼Œè€Œç‰¹å¾å‘é‡è¢«åˆ†ç»„å½¢æˆèšç±»
- en: '**Standardization**'
  id: totrans-1674
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ‡å‡†åŒ–**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    distribution rescaling that can be thought of as shifting, and stretching or squeezing
    of a univariate distribution (e.g., *histogram*) to a mean of 0.0 and a variance
    of 1.0.'
  id: totrans-1675
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§åˆ†å¸ƒç¼©æ”¾ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºå¯¹å•å˜é‡åˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œ*ç›´æ–¹å›¾*ï¼‰çš„å¹³ç§»ã€æ‹‰ä¼¸æˆ–å‹ç¼©ï¼Œä»¥è¾¾åˆ°å‡å€¼ä¸º
    0.0 å’Œæ–¹å·®ä¸º 1.0ã€‚'
- en: \[ y_i = \frac{1}{\sigma_x}(x_i - \overline{x}), \quad \forall \quad i, \ldots,
    n \]
  id: totrans-1676
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{1}{\sigma_x}(x_i - \overline{x}), \quad \forall \quad i, \ldots,
    n \]
- en: where \(\overline{x}\) and \(\sigma_x\) are the original mean and variance.
  id: totrans-1677
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\sigma_x\) æ˜¯åŸå§‹å‡å€¼å’Œæ–¹å·®ã€‚
- en: this is a shift and stretch / squeeze of the original property distribution
  id: totrans-1678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹åŸå§‹å±æ€§åˆ†å¸ƒçš„å¹³ç§»å’Œæ‹‰ä¼¸/å‹ç¼©
- en: assumes no shape change, rank preserving
  id: totrans-1679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡è®¾å½¢çŠ¶ä¸å˜ï¼Œä¿æŒç§©
- en: '**Stochastic Gradient-based Optimization**'
  id: totrans-1680
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºéšæœºæ¢¯åº¦çš„ä¼˜åŒ–**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): a method to solve
    for model parameters by iteratively minimizing the loss function. Stochasticity
    and improve computational efficiency are added to gradient descent through the
    use of batches,'
  id: totrans-1681
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šä¸€ç§é€šè¿‡è¿­ä»£æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥æ±‚è§£æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚é€šè¿‡ä½¿ç”¨æ‰¹æ¬¡ï¼Œå°†éšæœºæ€§å’Œæé«˜è®¡ç®—æ•ˆç‡æ·»åŠ åˆ°æ¢¯åº¦ä¸‹é™ä¸­ï¼Œ'
- en: a batch is a random subset of the training data with specified size, \(n_{batch}\)
  id: totrans-1682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¹æ¬¡æ˜¯å…·æœ‰æŒ‡å®šå¤§å° \(n_{batch}\) çš„è®­ç»ƒæ•°æ®çš„éšæœºå­é›†
- en: resulting in stochastic approximations of the loss function gradient, that are
    faster to calculate
  id: totrans-1683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼è‡´æŸå¤±å‡½æ•°æ¢¯åº¦çš„éšæœºè¿‘ä¼¼ï¼Œè®¡ç®—é€Ÿåº¦æ›´å¿«
- en: batches reduce accuracy in the gradient descent, but speed up the calculation
    and can perform more steps, often faster than gradient descent
  id: totrans-1684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¹æ¬¡å‡å°‘æ¢¯åº¦ä¸‹é™çš„å‡†ç¡®æ€§ï¼Œä½†åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œå¯ä»¥æ‰§è¡Œæ›´å¤šæ­¥éª¤ï¼Œé€šå¸¸æ¯”æ¢¯åº¦ä¸‹é™æ›´å¿«
- en: increase \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\) for more accuracy of gradient estimation, and decrease
    \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\) to speed up the steps
  id: totrans-1685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ  \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\) ä»¥æé«˜æ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå¹¶å‡å°‘ \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\) ä»¥åŠ å¿«æ­¥éª¤
- en: Robbins-Siegmund (1971) Theorem - converge to global minimum for convex loss
    functions and either a global or local minimum for nonconvex loss functions.
  id: totrans-1686
  prefs: []
  type: TYPE_NORMAL
  zh: Robbins-Siegmund (1971) å®šç† - å¯¹äºå‡¸æŸå¤±å‡½æ•°æ”¶æ•›åˆ°å…¨å±€æœ€å°å€¼ï¼Œå¯¹äºéå‡¸æŸå¤±å‡½æ•°æ”¶æ•›åˆ°å…¨å±€æˆ–å±€éƒ¨æœ€å°å€¼ã€‚
- en: The steps include,
  id: totrans-1687
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤åŒ…æ‹¬ï¼Œ
- en: start with random model parameters
  id: totrans-1688
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»éšæœºçš„æ¨¡å‹å‚æ•°å¼€å§‹
- en: select a random subset of training data, \(n_{batch}\)
  id: totrans-1689
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©è®­ç»ƒæ•°æ®çš„éšæœºå­é›†ï¼Œ\(n_{batch}\)
- en: calculate the loss function and loss function gradient for the model parameters
    over the random batch,
  id: totrans-1690
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¨¡å‹å‚æ•°åœ¨éšæœºæ‰¹æ¬¡ä¸Šçš„æŸå¤±å‡½æ•°å’ŒæŸå¤±å‡½æ•°æ¢¯åº¦ï¼Œ
- en: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
  id: totrans-1691
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
- en: update the parameter estimate by stepping down slope / gradient,
  id: totrans-1692
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡æ²¿æ–œå¡/æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°å‚æ•°ä¼°è®¡ï¼Œ
- en: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
  id: totrans-1693
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
- en: where \(r\) is the learning rate/step size, \(\hat{b}(1,ğ‘¡)\), is the current
    model parameter estimate and \(\hat{b}(1,ğ‘¡+1)\) is the updated parameter estimate.
  id: totrans-1694
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(r\) æ˜¯å­¦ä¹ ç‡/æ­¥é•¿ï¼Œ\(\hat{b}(1,ğ‘¡)\) æ˜¯å½“å‰æ¨¡å‹å‚æ•°ä¼°è®¡ï¼Œ\(\hat{b}(1,ğ‘¡+1)\) æ˜¯æ›´æ–°çš„å‚æ•°ä¼°è®¡ã€‚
- en: '**Stochastic Model**'
  id: totrans-1695
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éšæœºæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): system or process
    that is uncertain and is represented by multiple models, *realizations* and *scenarios*
    constrained by statistics,'
  id: totrans-1696
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸ç¡®å®šçš„ç³»ç»Ÿæˆ–è¿‡ç¨‹ï¼Œç”±å¤šä¸ªæ¨¡å‹ã€*å®ç°*å’Œå—ç»Ÿè®¡çº¦æŸçš„*æƒ…æ™¯*è¡¨ç¤ºï¼Œ'
- en: for example, data-driven models that integrate uncertainty like geostatistical
    simulation models
  id: totrans-1697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåƒåœ°ç»Ÿè®¡æ¨¡æ‹Ÿæ¨¡å‹è¿™æ ·çš„æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œå®ƒä»¬æ•´åˆäº†ä¸ç¡®å®šæ€§
- en: 'Advantages:'
  id: totrans-1698
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼š
- en: speed
  id: totrans-1699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€Ÿåº¦
- en: uncertainty assessment
  id: totrans-1700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§è¯„ä¼°
- en: report significance, confidence / prediction intervals
  id: totrans-1701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŠ¥å‘Šæ˜¾è‘—æ€§ã€ç½®ä¿¡/é¢„æµ‹åŒºé—´
- en: honor many types of data
  id: totrans-1702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°Šé‡è®¸å¤šç±»å‹çš„æ•°æ®
- en: data-driven approaches
  id: totrans-1703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®é©±åŠ¨æ–¹æ³•
- en: 'Disadvantages:'
  id: totrans-1704
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼š
- en: limited physics used
  id: totrans-1705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çš„ç‰©ç†æœ‰é™
- en: statistical model assumptions / simplification
  id: totrans-1706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡æ¨¡å‹å‡è®¾/ç®€åŒ–
- en: For the alternative to stochastic models see *deterministic models*.
  id: totrans-1707
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºéšæœºæ¨¡å‹çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¯·å‚é˜… *ç¡®å®šæ€§æ¨¡å‹*ã€‚
- en: '**Statistics** (practice)'
  id: totrans-1708
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»Ÿè®¡å­¦** (å®è·µ)'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the theory and
    practice for collecting, organizing, and interpreting data, as well as drawing
    conclusions and making decisions.'
  id: totrans-1709
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ”¶é›†ã€ç»„ç»‡ã€è§£é‡Šæ•°æ®ä»¥åŠå¾—å‡ºç»“è®ºå’Œåšå‡ºå†³ç­–çš„ç†è®ºå’Œå®è·µã€‚'
- en: '**Statistics** (measurement)'
  id: totrans-1710
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»Ÿè®¡å­¦** (æµ‹é‡)'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): summary measure
    of a sample, for example,'
  id: totrans-1711
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ ·æœ¬çš„æ±‡æ€»åº¦é‡ï¼Œä¾‹å¦‚ï¼Œ'
- en: sample mean - \(\overline{x}\)
  id: totrans-1712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬å‡å€¼ - \(\overline{x}\)
- en: sample standard deviation - \(s\),
  id: totrans-1713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ ‡å‡†å·® - \(s\),
- en: we use statistics as estimates of the model parameters that summarize the population
    (*inference*)
  id: totrans-1714
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡å­¦ä½œä¸ºæ¨¡å‹å‚æ•°çš„ä¼°è®¡ï¼Œè¿™äº›å‚æ•°æ€»ç»“äº†æ€»ä½“(*æ¨æ–­*)
- en: '**Statistical Distribution**'
  id: totrans-1715
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»Ÿè®¡åˆ†å¸ƒ**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): for a feature
    a description of the probability of occurrence over the range of possible values.
    We represent the univariate statistical distribution with,'
  id: totrans-1716
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šå¯¹äºä¸€ä¸ªç‰¹å¾ï¼Œæè¿°å…¶åœ¨å¯èƒ½å€¼èŒƒå›´å†…çš„å‘ç”Ÿæ¦‚ç‡ã€‚æˆ‘ä»¬ç”¨ä»¥ä¸‹æ–¹å¼è¡¨ç¤ºå•å˜é‡ç»Ÿè®¡åˆ†å¸ƒï¼Œ'
- en: '*histogram*'
  id: totrans-1717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç›´æ–¹å›¾*'
- en: '*normalized histogram*'
  id: totrans-1718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å½’ä¸€åŒ–ç›´æ–¹å›¾*'
- en: '*probability density function* (PDF)'
  id: totrans-1719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¦‚ç‡å¯†åº¦å‡½æ•°* (PDF)'
- en: '*cumulative distribution function* (CDF)'
  id: totrans-1720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç´¯ç§¯åˆ†å¸ƒå‡½æ•°* (CDF)'
- en: What do we learn from a statistical distribution? For example,
  id: totrans-1721
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»ç»Ÿè®¡åˆ†å¸ƒä¸­å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿä¾‹å¦‚ï¼Œ
- en: what is the minimum and maximum?
  id: totrans-1722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å°å€¼å’Œæœ€å¤§å€¼æ˜¯ä»€ä¹ˆï¼Ÿ
- en: do we have a lot of low values?
  id: totrans-1723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰å¤§é‡çš„ä½å€¼ï¼Ÿ
- en: do we have a lot of high values?
  id: totrans-1724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰å¤§é‡çš„é«˜å€¼ï¼Ÿ
- en: do we have outliers, and any other values that donâ€™t make sense and need explaining?
  id: totrans-1725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰å¼‚å¸¸å€¼ï¼Œä»¥åŠä»»ä½•å…¶ä»–ä¸åˆç†ä¸”éœ€è¦è§£é‡Šçš„å€¼ï¼Ÿ
- en: '**Support Vector** (support vector machines)'
  id: totrans-1726
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ”¯æŒå‘é‡** (æ”¯æŒå‘é‡æœº)'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): training
    data within the margin or misclassified and update the support vector machines
    classification model.'
  id: totrans-1727
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šä½äºè¾¹ç¼˜æˆ–è¢«é”™è¯¯åˆ†ç±»çš„è®­ç»ƒæ•°æ®æ›´æ–°æ”¯æŒå‘é‡æœºåˆ†ç±»æ¨¡å‹ã€‚'
- en: with a support vector machines model, training data well within the correct
    region, are not support vectors, and have no impact on the model
  id: totrans-1728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ”¯æŒå‘é‡æœºæ¨¡å‹ä¸­ï¼Œè®­ç»ƒæ•°æ®å¾ˆå¥½åœ°ä½äºæ­£ç¡®åŒºåŸŸå†…ï¼Œä¸æ˜¯æ”¯æŒå‘é‡ï¼Œå¯¹æ¨¡å‹æ²¡æœ‰å½±å“
- en: '**Support Vector Machines**'
  id: totrans-1729
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ”¯æŒå‘é‡æœº**'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): a
    predictive, binary classification machine learning method that is a good classification
    method when there is poor separation of groups.'
  id: totrans-1730
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šä¸€ç§é¢„æµ‹æ€§çš„äºŒåˆ†ç±»æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå½“ç»„é—´åˆ†ç¦»è¾ƒå·®æ—¶æ˜¯ä¸€ç§å¥½çš„åˆ†ç±»æ–¹æ³•ã€‚'
- en: projects the original predictor features to higher dimensional space and then
    applies a linear, plane or hyperplane,
  id: totrans-1731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†åŸå§‹é¢„æµ‹ç‰¹å¾æŠ•å½±åˆ°æ›´é«˜ç»´ç©ºé—´ï¼Œç„¶ååº”ç”¨çº¿æ€§ã€å¹³é¢æˆ–è¶…å¹³é¢ï¼Œ
- en: \[ ğ‘“(ğ‘¥) = ğ‘¥^ğ‘‡ \beta +\beta_0 \]
  id: totrans-1732
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘“(ğ‘¥) = ğ‘¥^ğ‘‡ \beta +\beta_0 \]
- en: where \(\beta\) is a vector and together with \(\beta\) are the hyperplane model
    parameters, while \(x\) is the matrix of predictor features, all are in the high
    dimensional space.
  id: totrans-1733
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\beta\) æ˜¯ä¸€ä¸ªå‘é‡ï¼Œä¸ \(\beta\) ä¸€èµ·æ˜¯è¶…å¹³é¢æ¨¡å‹å‚æ•°ï¼Œè€Œ \(x\) æ˜¯é¢„æµ‹ç‰¹å¾çŸ©é˜µï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨é«˜ç»´ç©ºé—´ä¸­ã€‚
- en: \[ ğº(ğ‘¥)=\text{ğ‘ ğ‘–ğ‘”ğ‘›}\left( ğ‘“(ğ‘¥) \right) \]
  id: totrans-1734
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğº(ğ‘¥)=\text{ğ‘ ğ‘–ğ‘”ğ‘›}\left( ğ‘“(ğ‘¥) \right) \]
- en: \(ğ‘“(ğ‘¥)\) is proportional to the signed distance from the decision boundary,
    and \(ğº(ğ‘¥)\) is the side of the decision boundary, \(âˆ’\) one side and \(+\) the
    other, \(f(x) = 0\) is on the decision boundary.
  id: totrans-1735
  prefs: []
  type: TYPE_NORMAL
  zh: \(ğ‘“(ğ‘¥)\) ä¸å†³ç­–è¾¹ç•Œçš„ç¬¦å·è·ç¦»æˆæ­£æ¯”ï¼Œè€Œ \(ğº(ğ‘¥)\) æ˜¯å†³ç­–è¾¹ç•Œçš„ä¾§é¢ï¼Œ\(-\) ä¸€ä¾§å’Œ \(+\) å¦ä¸€ä¾§ï¼Œ\(f(x) = 0\)
    åœ¨å†³ç­–è¾¹ç•Œä¸Šã€‚
- en: We represent the constraint, all data of each category must be on the correct
    side of the boundary, by,
  id: totrans-1736
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ–¹å¼è¡¨ç¤ºçº¦æŸï¼Œæ¯ä¸ªç±»åˆ«çš„æ‰€æœ‰æ•°æ®éƒ½å¿…é¡»åœ¨è¾¹ç•Œçš„æ­£ç¡®ä¸€ä¾§ï¼Œ
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
  id: totrans-1737
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
- en: where this holds if the categories, \(y_i\), are -1 or 1\. We need a model that
    allows for some misclassification,
  id: totrans-1738
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œå¦‚æœç±»åˆ« \(y_i\) ä¸º -1 æˆ– 1ï¼Œåˆ™æ­¤æ¡ä»¶æˆç«‹ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå…è®¸æŸäº›è¯¯åˆ†ç±»çš„æ¨¡å‹ï¼Œ
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
  id: totrans-1739
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
- en: We introduce the concept of a margin, \(ğ‘€\), and a distance from the margin,
    the error as \(\xi_i\). Now we can pose our loss function as,
  id: totrans-1740
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼•å…¥äº†è¾¹ç•Œ \(ğ‘€\) å’Œè¾¹ç•Œè·ç¦»çš„æ¦‚å¿µï¼Œé”™è¯¯ç”¨ \(\xi_i\) è¡¨ç¤ºã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬çš„æŸå¤±å‡½æ•°è¡¨ç¤ºä¸ºï¼Œ
- en: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
  id: totrans-1741
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
- en: subject to, \(\xi_i \geq 0, \quad y_i \left( x_i^T \beta + \beta_0 \right) \geq
    M - \xi_i\).
  id: totrans-1742
  prefs: []
  type: TYPE_NORMAL
  zh: æ¡ä»¶æ˜¯ï¼Œ\(\xi_i \geq 0, \quad y_i \left( x_i^T \beta + \beta_0 \right) \geq M -
    \xi_i\).
- en: This is the support vector machine loss function in the higher dimensional space,
    where ğ›½,ğ›½_0 are the multilinear model parameters.
  id: totrans-1743
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é«˜ç»´ç©ºé—´ä¸­çš„æ”¯æŒå‘é‡æœºæŸå¤±å‡½æ•°ï¼Œå…¶ä¸­ ğ›½,ğ›½_0 æ˜¯å¤šçº¿æ€§æ¨¡å‹å‚æ•°ã€‚
- en: Training the support vector machine, by finding the model parameters of the
    plane to maximize the margin, \(M\), while minimizing the error, \(\sum_{i=1}^N
    \xi_i\)
  id: totrans-1744
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ”¯æŒå‘é‡æœºï¼Œé€šè¿‡æ‰¾åˆ°æœ€å¤§åŒ–è¾¹ç•Œ \(M\) çš„æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶æœ€å°åŒ–é”™è¯¯ \(\sum_{i=1}^N \xi_i\)
- en: \(ğ‘ª\) hyperparameter weights the sum of errors, \(xi_ğ‘–\), higher \(ğ¶\), will
    result in reduced margin, \(M\), and lead to overfit
  id: totrans-1745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(ğ‘ª\) è¶…å‚æ•°åŠ æƒé”™è¯¯ä¹‹å’Œ \(xi_ğ‘–\)ï¼Œè¾ƒé«˜çš„ \(ğ¶\) å°†å¯¼è‡´è¾¹ç•Œ \(M\) å‡å°‘ï¼Œå¹¶å¯¼è‡´è¿‡æ‹Ÿåˆ
- en: smaller margin, fewer data used to constrain the boundary, known as support
    vectors
  id: totrans-1746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾ƒå°çš„è¾¹ç•Œï¼Œä½¿ç”¨è¾ƒå°‘çš„æ•°æ®æ¥çº¦æŸè¾¹ç•Œï¼Œç§°ä¸ºæ”¯æŒå‘é‡
- en: training data well within the correct side of the boundary have no influence
  id: totrans-1747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®åœ¨è¾¹ç•Œçš„æ­£ç¡®ä¸€ä¾§æ²¡æœ‰å½±å“
- en: Here are some key aspects of support vector machines,
  id: totrans-1748
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æ”¯æŒå‘é‡æœºçš„ä¸€äº›å…³é”®æ–¹é¢ï¼Œ
- en: known as support vector machines, and not machine, because with a new kernel
    you get a new machine
  id: totrans-1749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¢«ç§°ä¸ºæ”¯æŒå‘é‡æœºï¼Œè€Œä¸æ˜¯æœºå™¨ï¼Œå› ä¸ºä½¿ç”¨æ–°çš„æ ¸å¯ä»¥å¾—åˆ°æ–°çš„æœºå™¨
- en: there are many kernels available including polynomial and radial basis functions
  id: totrans-1750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰è®¸å¤šæ ¸å¯ç”¨ï¼ŒåŒ…æ‹¬å¤šé¡¹å¼å’Œå¾„å‘åŸºå‡½æ•°
- en: The primary hyperparameter is \(C\), the cost of
  id: totrans-1751
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦è¶…å‚æ•°æ˜¯ \(C\)ï¼Œå…¶æˆæœ¬ä¸º
- en: Hyperparameters are related to the choice of kernel, for example,
  id: totrans-1752
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°ä¸æ ¸çš„é€‰æ‹©æœ‰å…³ï¼Œä¾‹å¦‚ï¼Œ
- en: '*polynomial* - polynomial order'
  id: totrans-1753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šé¡¹å¼* - å¤šé¡¹å¼é˜¶æ•°'
- en: '*radial basis function* - \(\gamma\) inversely proportional to the distance
    influence of the training data'
  id: totrans-1754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¾„å‘åŸºå‡½æ•°* - \(\gamma\) ä¸è®­ç»ƒæ•°æ®çš„è·ç¦»å½±å“æˆåæ¯”'
- en: '**Tabular Data**'
  id: totrans-1755
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¡¨æ ¼æ•°æ®**'
- en: 'Machine Learning Workflow Construction and Coding: data table with rows for
    each sample and columns for each feature'
  id: totrans-1756
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šæ•°æ®è¡¨ï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ªæ ·æœ¬ï¼Œæ¯åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å¾
- en: Pandasâ€™ DataFrames are a convenient class for working with tabular data, due
    to,
  id: totrans-1757
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº Pandas çš„ DataFrame æ˜¯å¤„ç†è¡¨æ ¼æ•°æ®çš„ä¾¿æ·ç±»ï¼Œ
- en: convenient data structure to store, access, manipulate tabular data
  id: totrans-1758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹ä¾¿çš„æ•°æ®ç»“æ„ç”¨äºå­˜å‚¨ã€è®¿é—®å’Œæ“ä½œè¡¨æ ¼æ•°æ®
- en: built-in methods to load data from a variety of file types, Python classes and
    even directly from Excel
  id: totrans-1759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ä»å„ç§æ–‡ä»¶ç±»å‹ã€Python ç±»ç”šè‡³ç›´æ¥ä» Excel åŠ è½½æ•°æ®
- en: built-in methods to calculate summary statistics and visualize data
  id: totrans-1760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºè®¡ç®—æ‘˜è¦ç»Ÿè®¡å’Œå¯è§†åŒ–æ•°æ®
- en: built-in methods for data queries, sort, data filters
  id: totrans-1761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®çš„æ•°æ®æŸ¥è¯¢ã€æ’åºã€æ•°æ®è¿‡æ»¤æ–¹æ³•
- en: built-in methods for data manipulation, cleaning, reformatting
  id: totrans-1762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®çš„æ•°æ®æ“ä½œã€æ¸…ç†å’Œé‡æ–°æ ¼å¼åŒ–æ–¹æ³•
- en: built-in attributes to store information about the data, e.g. size, number nulls
    and null value
  id: totrans-1763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®å±æ€§ç”¨äºå­˜å‚¨æœ‰å…³æ•°æ®çš„ä¿¡æ¯ï¼Œä¾‹å¦‚å¤§å°ã€ç©ºå€¼æ•°é‡å’Œç©ºå€¼
- en: '**Training and Testing Splits**'
  id: totrans-1764
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): for model cross
    validation, prior to predictive model training withhold a proportion of the data
    as testing data.'
  id: totrans-1765
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¯¹äºæ¨¡å‹äº¤å‰éªŒè¯ï¼Œåœ¨é¢„æµ‹æ¨¡å‹è®­ç»ƒä¹‹å‰ï¼Œä¿ç•™ä¸€éƒ¨åˆ†æ•°æ®ä½œä¸ºæµ‹è¯•æ•°æ®ã€‚'
- en: training data are applied to train the model parameters, while withheld testing
    data are applied to tune the model hyperparameter
  id: totrans-1766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®ç”¨äºè®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œè€Œä¿ç•™çš„æµ‹è¯•æ•°æ®ç”¨äºè°ƒæ•´æ¨¡å‹è¶…å‚æ•°
- en: hyperparameter tuning is selecting the hyperparameter combination that minimizes
    the error norm over the withheld testing data
  id: totrans-1767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°è°ƒæ•´æ˜¯é€‰æ‹©è¶…å‚æ•°ç»„åˆï¼Œä»¥æœ€å°åŒ–ä¿ç•™æµ‹è¯•æ•°æ®ä¸Šçš„è¯¯å·®èŒƒæ•°
- en: The most common approach is random selection, this may not be fair testing,
  id: totrans-1768
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¸¸è§çš„æ–¹æ³•æ˜¯éšæœºé€‰æ‹©ï¼Œè¿™å¯èƒ½ä¸æ˜¯å…¬å¹³çš„æµ‹è¯•ï¼Œ
- en: the range of testing difficulty is similar to the real-world use of the model
  id: totrans-1769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹è¯•éš¾åº¦çš„èŒƒå›´ä¸æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ç›¸ä¼¼
- en: too easy â€“ testing cases are the same or almost the same as training cases,
    random sampling is often too easy
  id: totrans-1770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤ªç®€å•äº†â€”â€”æµ‹è¯•æ¡ˆä¾‹ä¸è®­ç»ƒæ¡ˆä¾‹ç›¸åŒæˆ–å‡ ä¹ç›¸åŒï¼ŒéšæœºæŠ½æ ·é€šå¸¸è¿‡äºç®€å•
- en: too hard â€“ testing cases are very different from the training cases, the model
    is expected to severely extrapolate
  id: totrans-1771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤ªéš¾äº†â€”â€”æµ‹è¯•æ¡ˆä¾‹ä¸è®­ç»ƒæ¡ˆä¾‹éå¸¸ä¸åŒï¼Œæ¨¡å‹é¢„è®¡å°†ä¸¥é‡å¤–æ¨
- en: Alternative methods such as k-fold cross validation provide the opportunity
    for testing over all available data but require,
  id: totrans-1772
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚kæŠ˜äº¤å‰éªŒè¯ç­‰æ›¿ä»£æ–¹æ³•æä¾›äº†å¯¹æ‰€æœ‰å¯ç”¨æ•°æ®è¿›è¡Œæµ‹è¯•çš„æœºä¼šï¼Œä½†éœ€è¦ï¼Œ
- en: the training k predictive machine learning models over the hyperparameter combinations
  id: totrans-1773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¶…å‚æ•°ç»„åˆä¸Šè®­ç»ƒkä¸ªé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹
- en: aggregation of the testing error over the k models for selection of the optimum
    hyperparameters, hyperparameter tuning
  id: totrans-1774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹kä¸ªæ¨¡å‹æµ‹è¯•é”™è¯¯çš„èšåˆï¼Œç”¨äºé€‰æ‹©æœ€ä½³è¶…å‚æ•°ï¼Œè¶…å‚æ•°è°ƒæ•´
- en: Also, there are alternative workflow that include, training, validation and
    testing subsets of the data
  id: totrans-1775
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œè¿˜æœ‰åŒ…æ‹¬è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®å­é›†çš„æ›¿ä»£å·¥ä½œæµç¨‹
- en: '**Transfer Function** (reservoir modeling workflow)'
  id: totrans-1776
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è½¬ç§»å‡½æ•°**ï¼ˆå‚¨å±‚å»ºæ¨¡å·¥ä½œæµç¨‹ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): calculation applied
    to the spatial, subsurface model realizations and scenarios to calculate a decision
    criterion, a metric that is used to support decision making representing value,
    and health, environment and safety. Example transfer functions include,'
  id: totrans-1777
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåº”ç”¨äºç©ºé—´ã€åœ°ä¸‹æ¨¡å‹å®ç°å’Œåœºæ™¯çš„è®¡ç®—ï¼Œä»¥è®¡ç®—å†³ç­–æ ‡å‡†ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ”¯æŒå†³ç­–çš„ä»·å€¼ã€å¥åº·ã€ç¯å¢ƒå’Œå®‰å…¨çš„æŒ‡æ ‡ã€‚ä¸€äº›ç¤ºä¾‹è½¬ç§»å‡½æ•°åŒ…æ‹¬ï¼Œ'
- en: '*transport and bioattenuation* - numerical simulation to model soil contaminant
    concentrations over time during a pump and treat operation'
  id: totrans-1778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¿è¾“å’Œç”Ÿç‰©è¡°å‡* - æ•°å€¼æ¨¡æ‹Ÿä»¥æ¨¡æ‹Ÿæ³µå’Œæ²»å¤„ç†æ“ä½œæœŸé—´éšæ—¶é—´æ¨ç§»çš„åœŸå£¤æ±¡æŸ“ç‰©æµ“åº¦'
- en: '*volumetric calculation* - for total oil-in-place to calculate resource in
    place'
  id: totrans-1779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ä½“ç§¯è®¡ç®—* - ç”¨äºè®¡ç®—åŸåœ°æ€»æ²¹é‡ä»¥è®¡ç®—èµ„æº'
- en: '*heterogeneity metric* - as an indicator of recovery factor to estimate reserves
    from resources'
  id: totrans-1780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¼‚è´¨æ€§æŒ‡æ ‡* - ä½œä¸ºé‡‡æ”¶ç‡æŒ‡æ ‡ï¼Œä»èµ„æºä¸­ä¼°è®¡å‚¨é‡'
- en: '*flow simulation* - for pre-drill production forecast for a planned well'
  id: totrans-1781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æµåŠ¨æ¨¡æ‹Ÿ* - ç”¨äºè®¡åˆ’äº•çš„é¢„é’»ç”Ÿäº§é¢„æµ‹'
- en: '*Whittleâ€™s pit optimization* - to calculate mineral resources and ultimate
    pit shell'
  id: totrans-1782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æƒ ç‰¹å°”çš„å‘ä¼˜åŒ–* - ç”¨äºè®¡ç®—çŸ¿äº§èµ„æºæœ€ç»ˆå‘å£³'
- en: '**Uncertainty Modeling**'
  id: totrans-1783
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸ç¡®å®šæ€§å»ºæ¨¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): calculation of
    the range of possible values for a feature at a location or jointly over many
    locations at the sample time. Some considerations,'
  id: totrans-1784
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨æ ·æœ¬æ—¶é—´è®¡ç®—ä¸€ä¸ªç‰¹å¾åœ¨ä½ç½®æˆ–å¤šä¸ªä½ç½®çš„å¯èƒ½çš„å€¼èŒƒå›´ã€‚ä¸€äº›è€ƒè™‘å› ç´ ï¼Œ'
- en: quantification of the limitation in the precision of our samples and model predictions
  id: totrans-1785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹æ ·æœ¬å’Œæ¨¡å‹é¢„æµ‹ç²¾åº¦çš„é™åˆ¶è¿›è¡Œé‡åŒ–
- en: uncertainty is a model, there is no objective uncertainty
  id: totrans-1786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§æ˜¯ä¸€ä¸ªæ¨¡å‹ï¼Œæ²¡æœ‰å®¢è§‚çš„ä¸ç¡®å®šæ€§
- en: uncertainty is caused by our ignorance
  id: totrans-1787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§æ˜¯ç”±æˆ‘ä»¬çš„æ— çŸ¥å¼•èµ·çš„
- en: uncertainty is caused by sparse sampling, measurement error and bias, and heterogeneity
  id: totrans-1788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§æ˜¯ç”±ç¨€ç–é‡‡æ ·ã€æµ‹é‡è¯¯å·®å’Œåå·®ä»¥åŠå¼‚è´¨æ€§å¼•èµ·çš„
- en: 'we represent uncertainty by multiple models, scenarios and realizations:'
  id: totrans-1789
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡å¤šä¸ªæ¨¡å‹ã€åœºæ™¯å’Œå®ç°æ¥è¡¨ç¤ºä¸ç¡®å®šæ€§ï¼š
- en: Scenarios - multiple spatial, subsurface models calculated by stochastic simulation
    by changing the input parameters or other modeling choices to represent the uncertainty
    due to inference of model parameters and model choices
  id: totrans-1790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœºæ™¯ - é€šè¿‡æ”¹å˜è¾“å…¥å‚æ•°æˆ–å…¶ä»–å»ºæ¨¡é€‰æ‹©ï¼Œé€šè¿‡éšæœºæ¨¡æ‹Ÿè®¡ç®—å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹ï¼Œä»¥è¡¨ç¤ºç”±äºæ¨¡å‹å‚æ•°å’Œæ¨¡å‹é€‰æ‹©çš„æ¨æ–­å¼•èµ·çš„ä¸ç¡®å®šæ€§
- en: Realizations - multiple spatial, subsurface models calculated by stochastic
    simulation by holding input parameters and model choices constant and only changing
    the random number seed
  id: totrans-1791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°æ–¹å¼ - é€šè¿‡ä¿æŒè¾“å…¥å‚æ•°å’Œæ¨¡å‹é€‰æ‹©ä¸å˜ï¼Œä»…æ”¹å˜éšæœºæ•°ç§å­ï¼Œé€šè¿‡éšæœºæ¨¡æ‹Ÿè®¡ç®—å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹
- en: '**Underfit Model**'
  id: totrans-1792
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¬ æ‹Ÿåˆæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a machine learning
    model that too simple, too low complexity and flexibility, to fit the natural
    phenomenon resulting in very high model bias.'
  id: totrans-1793
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªè¿‡äºç®€å•ã€å¤æ‚æ€§å’Œçµæ´»æ€§å¤ªä½ã€æ— æ³•æ‹Ÿåˆè‡ªç„¶ç°è±¡çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¯¼è‡´æ¨¡å‹åå·®éå¸¸é«˜ã€‚'
- en: underfit models often approach the response feature global mean
  id: totrans-1794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¬ æ‹Ÿåˆæ¨¡å‹é€šå¸¸æ¥è¿‘å“åº”ç‰¹å¾çš„å…¨çƒå‡å€¼
- en: underfit models have high error over training and testing data
  id: totrans-1795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¬ æ‹Ÿåˆæ¨¡å‹åœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸Šå…·æœ‰é«˜è¯¯å·®
- en: increased complexity will generally decrease error with respect to the training
    and testing dataset
  id: totrans-1796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ çš„å¤æ‚æ€§é€šå¸¸ä¼šåœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä¸Šé™ä½è¯¯å·®
- en: over the region of model complexity with falling training and testing error
  id: totrans-1797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¨¡å‹å¤æ‚åº¦ä¸‹é™çš„è®­ç»ƒå’Œæµ‹è¯•è¯¯å·®åŒºåŸŸ
- en: Issues of an underfit machine learning model,
  id: totrans-1798
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬ æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„é—®é¢˜ï¼Œ
- en: more model complexity and flexibility is insufficient given the available data,
    data accuracy, frequency and coverage
  id: totrans-1799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç»™å®šæ•°æ®ã€æ•°æ®å‡†ç¡®æ€§ã€é¢‘ç‡å’Œè¦†ç›–èŒƒå›´çš„æƒ…å†µä¸‹ï¼Œæ›´å¤šçš„æ¨¡å‹å¤æ‚æ€§å’Œçµæ´»æ€§æ˜¯ä¸å¤Ÿçš„
- en: low accuracy in training and testing representing real-world use away from training
    data cases, indicating poor ability of the model to generalize
  id: totrans-1800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œæµ‹è¯•ä¸­çš„ä½ç²¾åº¦è¡¨ç¤ºè¿œç¦»è®­ç»ƒæ•°æ®æ¡ˆä¾‹çš„å®é™…åº”ç”¨ï¼Œè¡¨æ˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›å·®
- en: '**Union of Events** (probability)'
  id: totrans-1801
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº‹ä»¶è”åˆ**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the union of outcomes,
    the probability of \(A\) or \(B\) is calculated with the probability addition
    rule,'
  id: totrans-1802
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šç»“æœçš„è”åˆï¼Œ\(A\)æˆ–\(B\)çš„æ¦‚ç‡é€šè¿‡æ¦‚ç‡åŠ æ³•è§„åˆ™è®¡ç®—ï¼Œ'
- en: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
  id: totrans-1803
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
- en: '**Univariate Parameters**'
  id: totrans-1804
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å•å˜é‡å‚æ•°**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): summary measures
    based on one feature measured over the population'
  id: totrans-1805
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šåŸºäºå¯¹æ€»ä½“ä¸­ä¸€ä¸ªç‰¹å¾æµ‹é‡çš„æ±‡æ€»åº¦é‡'
- en: '**Univariate Statistics**'
  id: totrans-1806
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å•å˜é‡ç»Ÿè®¡**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): summary measures
    based on one feature measured over the samples'
  id: totrans-1807
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šåŸºäºæ ·æœ¬ä¸­ä¸€ä¸ªç‰¹å¾æµ‹é‡çš„æ±‡æ€»åº¦é‡'
- en: '**Unsupervised Learning**'
  id: totrans-1808
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ— ç›‘ç£å­¦ä¹ **'
- en: 'Cluster Analysis: learning patterns in data from unlabeled data.'
  id: totrans-1809
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šä»æœªæ ‡è®°æ•°æ®ä¸­å­¦ä¹ æ•°æ®æ¨¡å¼
- en: no response features, \(ğ‘Œ\), instead only predictor features, \(ğ‘‹_1,ldots,ğ‘‹_ğ‘š\)
  id: totrans-1810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å“åº”ç‰¹å¾ï¼Œ\(ğ‘Œ\)ï¼Œåªæœ‰é¢„æµ‹ç‰¹å¾ï¼Œ\(ğ‘‹_1,ldots,ğ‘‹_ğ‘š\)
- en: machine learns by mimicry a compact representation of the data
  id: totrans-1811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºå™¨é€šè¿‡æ¨¡ä»¿æ•°æ®çš„ç´§å‡‘è¡¨ç¤ºè¿›è¡Œå­¦ä¹ 
- en: captures patterns as feature projections, group assignments, neural network
    latent features, etc.
  id: totrans-1812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ç‰¹å¾æŠ•å½±ã€åˆ†ç»„åˆ†é…ã€ç¥ç»ç½‘ç»œæ½œåœ¨ç‰¹å¾ç­‰æ•æ‰æ¨¡å¼
- en: focus on inference of the population, the natural system, instead of prediction
    of response features
  id: totrans-1813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸“æ³¨äºå¯¹æ€»ä½“ã€è‡ªç„¶ç³»ç»Ÿçš„æ¨ç†ï¼Œè€Œä¸æ˜¯å¯¹å“åº”ç‰¹å¾çš„é¢„æµ‹
- en: In this course we use the terms inferential and predictive machine learning,
    all the covered inferential machine learning methods are unsupervised.
  id: totrans-1814
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨æ–­å’Œé¢„æµ‹æœºå™¨å­¦ä¹ çš„æœ¯è¯­ï¼Œæ‰€æœ‰æ¶µç›–çš„æ¨æ–­æœºå™¨å­¦ä¹ æ–¹æ³•éƒ½æ˜¯æ— ç›‘ç£çš„ã€‚
- en: '**Variable** (also feature)'
  id: totrans-1815
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å˜é‡**ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): any property measured
    or observed in a study, for example,'
  id: totrans-1816
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨ç ”ç©¶ä¸­æµ‹é‡çš„ä»»ä½•å±æ€§ï¼Œä¾‹å¦‚ï¼Œ'
- en: porosity, permeability, mineral concentrations, saturations, contaminant concentration
  id: totrans-1817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ã€æ¸—é€ç‡ã€çŸ¿ç‰©æµ“åº¦ã€é¥±å’Œåº¦ã€æ±¡æŸ“ç‰©æµ“åº¦
- en: in data mining / machine learning this is known as a *feature*
  id: totrans-1818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®æŒ–æ˜/æœºå™¨å­¦ä¹ ä¸­è¿™è¢«ç§°ä¸º*ç‰¹å¾*
- en: measure often requires significant analysis, interpretation, etc.
  id: totrans-1819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº¦é‡é€šå¸¸éœ€è¦æ˜¾è‘—çš„åˆ†æã€è§£é‡Šç­‰
- en: '**Variance Inflation Factor** (VIF)'
  id: totrans-1820
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ–¹å·®è†¨èƒ€å› å­**ï¼ˆVIFï¼‰'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a measure of linear
    multicollinearity between a predictor feature (\(X_i\)) a nd all other predictor
    features (\(X_j, \forall j \ne i\)).'
  id: totrans-1821
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šè¡¡é‡é¢„æµ‹ç‰¹å¾ï¼ˆ\(X_i\)ï¼‰ä¸æ‰€æœ‰å…¶ä»–é¢„æµ‹ç‰¹å¾ï¼ˆ\(X_j,
    \forall j \ne i\)ï¼‰ä¹‹é—´çš„çº¿æ€§å¤šé‡å…±çº¿æ€§'
- en: First we calculate a linear regression for a predictor feature given all the
    other predictor features.
  id: totrans-1822
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬é’ˆå¯¹æ‰€æœ‰å…¶ä»–é¢„æµ‹ç‰¹å¾è®¡ç®—ç»™å®šé¢„æµ‹ç‰¹å¾çš„çº¿æ€§å›å½’ã€‚
- en: \[ X_i = \sum_{j, j \ne i}^m X_j + \epsilon \]
  id: totrans-1823
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X_i = \sum_{j, j \ne i}^m X_j + \epsilon \]
- en: From this model we determine the coefficient of determination, \(R^2\), known
    as variance explained.
  id: totrans-1824
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ­¤æ¨¡å‹ä¸­æˆ‘ä»¬ç¡®å®šç¡®å®šç³»æ•°ï¼Œ\(R^2\)ï¼Œä¹Ÿç§°ä¸ºè§£é‡Šæ–¹å·®
- en: 'Then we calculate the Variance Inflation Factor as:'
  id: totrans-1825
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è®¡ç®—æ–¹å·®è†¨èƒ€å› å­å¦‚ä¸‹ï¼š
- en: \[ VIF = \frac{1}{1 - R^2} \]
  id: totrans-1826
  prefs: []
  type: TYPE_NORMAL
  zh: \[ VIF = \frac{1}{1 - R^2} \]
- en: '**Volume-Variance Relations**'
  id: totrans-1827
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä½“ç§¯-æ–¹å·®å…³ç³»**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): as
    the *volume support* (scale) increases the variance reduces'
  id: totrans-1828
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šéšç€ *ä½“ç§¯æ”¯æŒ*ï¼ˆå°ºåº¦ï¼‰çš„å¢åŠ ï¼Œæ–¹å·®å‡å°‘'
- en: Predicting volume-variance relations is central to handling multiple scales
    of data and models. Some general observations and assumptions,
  id: totrans-1829
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ä½“ç§¯-æ–¹å·®å…³ç³»æ˜¯å¤„ç†æ•°æ®å’Œå¤šå°ºåº¦æ¨¡å‹å¤šä¸ªå°ºåº¦çš„åŸºç¡€ã€‚ä¸€äº›ä¸€èˆ¬è§‚å¯Ÿå’Œå‡è®¾ï¼Œ
- en: the mean does not change as the volume support, scale changes. Only the variance
    changes
  id: totrans-1830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ä½“ç§¯æ”¯æŒã€å°ºåº¦å˜åŒ–æ—¶ï¼Œå‡å€¼ä¸ä¼šæ”¹å˜ã€‚åªæœ‰æ–¹å·®ä¼šæ”¹å˜
- en: there may be shape change (we will not tackle that here). Best practice is to
    check shape change empirically. It is common to assume no shape change (*affine
    correction*) or to use a shape change model (indirect lognormal correction).
  id: totrans-1831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½ä¼šå‘ç”Ÿå½¢çŠ¶å˜åŒ–ï¼ˆæˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šå¤„ç†è¿™ä¸ªé—®é¢˜ï¼‰ã€‚æœ€ä½³å®è·µæ˜¯ç»éªŒæ€§åœ°æ£€æŸ¥å½¢çŠ¶å˜åŒ–ã€‚é€šå¸¸å‡è®¾æ²¡æœ‰å½¢çŠ¶å˜åŒ–ï¼ˆ*ä»¿å°„æ ¡æ­£*ï¼‰æˆ–ä½¿ç”¨å½¢çŠ¶å˜åŒ–æ¨¡å‹ï¼ˆé—´æ¥å¯¹æ•°æ­£æ€æ ¡æ­£ï¼‰ã€‚
- en: the variance reduction in the distribution is inversely proportional to the
    range of spatial continuity. Variance reduces faster (over smaller volume increase)
    for shorter spatial continuity ranges.
  id: totrans-1832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒä¸­çš„æ–¹å·®å‡å°‘ä¸ç©ºé—´è¿ç»­æ€§çš„èŒƒå›´æˆåæ¯”ã€‚æ–¹å·®å‡å°‘å¾—æ›´å¿«ï¼ˆåœ¨è¾ƒå°çš„ä½“ç§¯å¢åŠ ä¸­ï¼‰å¯¹äºè¾ƒçŸ­çš„ç©ºé—´è¿ç»­æ€§èŒƒå›´ã€‚
- en: Over common changes in scale this impact may be significant; therefore, it is
    not appropriate to ignore volume-variance relations,
  id: totrans-1833
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¸¸è§çš„å°ºåº¦å˜åŒ–ä¸­ï¼Œè¿™ç§å½±å“å¯èƒ½æ˜¯æ˜¾è‘—çš„ï¼›å› æ­¤ï¼Œå¿½ç•¥ä½“ç§¯-æ–¹å·®å…³ç³»æ˜¯ä¸é€‚å½“çš„ï¼Œ
- en: we donâ€™t do this scale up, change in volume support perfectly, and this is why
    it is still called the missing scale. We rarely have enough data to model this
    rigorously
  id: totrans-1834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸è¿›è¡Œè¿™ç§æ”¾å¤§ï¼Œä½“ç§¯æ”¯æŒå˜åŒ–å®Œç¾ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒä»ç„¶è¢«ç§°ä¸ºç¼ºå¤±å°ºåº¦ã€‚æˆ‘ä»¬å¾ˆå°‘æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ä¸¥æ ¼å»ºæ¨¡è¿™ä¸€ç‚¹
- en: we need a model to predict this change in variance with change in volume support
  id: totrans-1835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ä½“ç§¯æ”¯æŒå˜åŒ–å¼•èµ·çš„æ–¹å·®å˜åŒ–
- en: There are some change in volume support, scale models,
  id: totrans-1836
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨ä¸€äº›ä½“ç§¯æ”¯æŒçš„å˜åŒ–ï¼Œå°ºåº¦æ¨¡å‹ï¼Œ
- en: '*Empirical* - build a small scale, high resolution model and scale it up numerically.
    For example, calculate a high resolution model of permeability, apply flow simulation
    to calculate effective permeability over \(v\) scale blocks'
  id: totrans-1837
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç»éªŒæ€§* - å»ºç«‹ä¸€ä¸ªå°è§„æ¨¡ã€é«˜åˆ†è¾¨ç‡æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ•°å€¼æ”¾å¤§ã€‚ä¾‹å¦‚ï¼Œè®¡ç®—æ¸—é€ç‡çš„é«˜åˆ†è¾¨ç‡æ¨¡å‹ï¼Œåº”ç”¨æµä½“æ¨¡æ‹Ÿæ¥è®¡ç®— \(v\) å°ºåº¦å—ä¸Šçš„æœ‰æ•ˆæ¸—é€ç‡'
- en: '*Power Law Averaging* - there is a flexible approach known as power law averaging.'
  id: totrans-1838
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¹‚å¾‹å¹³å‡* - æœ‰ä¸€ç§ç§°ä¸ºå¹‚å¾‹å¹³å‡çš„çµæ´»æ–¹æ³•ã€‚'
- en: \[ z_V = \left[ \frac{1}{n} \sum z_v^{\omega} \right] ^{\frac{1}{\omega}} \]
  id: totrans-1839
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z_V = \left[ \frac{1}{n} \sum z_v^{\omega} \right] ^{\frac{1}{\omega}} \]
- en: 'where \(\omega\) is the power of averaging. For example:'
  id: totrans-1840
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\omega\) æ˜¯å¹³å‡çš„å¹‚ã€‚ä¾‹å¦‚ï¼š
- en: \(\omega = 1\) is a regular linear averaging
  id: totrans-1841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\omega = 1\) æ˜¯å¸¸è§„çº¿æ€§å¹³å‡
- en: \(\omega = -1\) is a harmonic averaging
  id: totrans-1842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\omega = -1\) æ˜¯è°æ³¢å¹³å‡
- en: \(\omega = 0\) is a geometric averaging (this is proved in the limit as \(\omega
    \rightarrow 0\))
  id: totrans-1843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\omega = 0\) æ˜¯å‡ ä½•å¹³å‡ï¼ˆè¿™åœ¨ \(\omega \rightarrow 0\) çš„æé™ä¸­å¾—åˆ°äº†è¯æ˜ï¼‰
- en: How to calculate \(\omega\)?
  id: totrans-1844
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•è®¡ç®— \(\omega\)ï¼Ÿ
- en: for some cases we know from theory the correct \(\omega\) value, for example,
    for flow orthogonal to beds we select \(\omega = -1.0\) to scale up permeability
  id: totrans-1845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæŸäº›æƒ…å†µï¼Œæˆ‘ä»¬ä»ç†è®ºä¸­çŸ¥é“æ­£ç¡®çš„ \(\omega\) å€¼ï¼Œä¾‹å¦‚ï¼Œå¯¹äºä¸åºŠå±‚æ­£äº¤çš„æµåŠ¨ï¼Œæˆ‘ä»¬é€‰æ‹© \(\omega = -1.0\) æ¥æ”¾å¤§æ¸—é€ç‡
- en: flow simulation may be applied to numerically scale up permeability and then
    to back-calculate a calibrated \(\omega\)
  id: totrans-1846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµä½“æ¨¡æ‹Ÿå¯ä»¥åº”ç”¨äºæ•°å€¼æ”¾å¤§æ¸—é€ç‡ï¼Œç„¶ååå‘è®¡ç®—æ ¡å‡†çš„ \(\omega\)
- en: '*Model* - directly adjust the statistics for change in scale. For example,
    under the assumption of linear averaging and a stationary variogram and variance:'
  id: totrans-1847
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹* - ç›´æ¥è°ƒæ•´å°ºåº¦å˜åŒ–çš„ç»Ÿè®¡é‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å‡è®¾çº¿æ€§å¹³å‡å’Œé™æ€å˜å·®å‡½æ•°å’Œæ–¹å·®çš„æƒ…å†µä¸‹ï¼š'
- en: \[ f = 1 - \frac{\overline{\gamma}(v,v)}{\sigma^2} \]
  id: totrans-1848
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f = 1 - \frac{\overline{\gamma}(v,v)}{\sigma^2} \]
- en: where \(f\) is variance reduction factor,
  id: totrans-1849
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(f\) æ˜¯æ–¹å·®å‡å°‘å› å­ï¼Œ
- en: \[ f = \frac{D^2(v,V)}{D^2(\cdot,V)} = \frac{D^2(v,V)}{\sigma^2} \]
  id: totrans-1850
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f = \frac{D^2(v,V)}{D^2(\cdot,V)} = \frac{D^2(v,V)}{\sigma^2} \]
- en: in other words, \(f\) is the ratio of the variance at scale \(v\) to the variance
    at the original data point support scale based on,
  id: totrans-1851
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œ\(f\) æ˜¯åŸºäº \(v\) å°ºåº¦ä¸‹çš„æ–¹å·®ä¸åŸå§‹æ•°æ®ç‚¹æ”¯æŒå°ºåº¦ä¸‹çš„æ–¹å·®çš„æ¯”å€¼ï¼Œ
- en: the variogram model
  id: totrans-1852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å˜å·®å‡½æ•°æ¨¡å‹
- en: the scale of the data, \(\cdot\) and the scale of \(v\)
  id: totrans-1853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®çš„å°ºåº¦ï¼Œ\(\cdot\) å’Œ \(v\) çš„å°ºåº¦
- en: '**Venn Diagrams**'
  id: totrans-1854
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»´æ©å›¾**'
- en: '[Probability Concepts](MachineLearning_probability.html): a plot, visual tool
    for communicating probability. What do we learn from a Venn diagram?'
  id: totrans-1855
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šä¸€ä¸ªå›¾è¡¨ï¼Œç”¨äºä¼ è¾¾æ¦‚ç‡çš„è§†è§‰å·¥å…·ã€‚æˆ‘ä»¬ä»ç»´æ©å›¾ä¸­èƒ½å­¦åˆ°ä»€ä¹ˆï¼Ÿ'
- en: size of regions \(\propto\) probability of occurrence
  id: totrans-1856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒºåŸŸå¤§å° \(\propto\) å‘ç”Ÿæ¦‚ç‡
- en: proportion of \(\Omega\), all possible outcomes represented by a box, i.e.,
    probability of \(1.0\)
  id: totrans-1857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\Omega\) çš„æ¯”ä¾‹ï¼Œæ‰€æœ‰å¯èƒ½çš„ç»“æœç”¨ä¸€ä¸ªæ¡†è¡¨ç¤ºï¼Œå³ \(1.0\) çš„æ¦‚ç‡
- en: overlap \(\propto\) probability of joint occurrence
  id: totrans-1858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å  \(\propto\) è”åˆå‘ç”Ÿæ¦‚ç‡
- en: Venn diagrams are an excellent tool to visualize marginal, joint and conditional
    probability.
  id: totrans-1859
  prefs: []
  type: TYPE_NORMAL
  zh: ç»´æ©å›¾æ˜¯å¯è§†åŒ–è¾¹ç¼˜ã€è”åˆå’Œæ¡ä»¶æ¦‚ç‡çš„ä¸€ä¸ªä¼˜ç§€å·¥å…·ã€‚
- en: '**Well Log Data**'
  id: totrans-1860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº•æ—¥å¿—æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): as a much cheaper
    method to sample wells that does not interrupt drilling operations, well logs
    are very common over the wells. Often all wells have various well logs available.
    For example,'
  id: totrans-1861
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä½œä¸ºä¸€ç§æ›´ä¾¿å®œçš„é‡‡æ ·äº•çš„æ–¹æ³•ï¼Œå®ƒä¸ä¼šä¸­æ–­é’»äº•ä½œä¸šï¼Œäº•æ—¥å¿—åœ¨äº•ä¸Šéå¸¸å¸¸è§ã€‚é€šå¸¸æ‰€æœ‰äº•éƒ½æœ‰å„ç§äº•æ—¥å¿—å¯ç”¨ã€‚ä¾‹å¦‚ï¼Œ'
- en: gamma ray on pilot vertical wells to assess the locations and quality of shales
    for targeting (landing) horizontal wells
  id: totrans-1862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¯•éªŒå‚ç›´äº•ä¸­è¿›è¡Œçš„ä¼½é©¬å°„çº¿æµ‹é‡ä»¥è¯„ä¼°é¡µå²©çš„ä½ç½®å’Œè´¨é‡ï¼Œä»¥é’ˆå¯¹ï¼ˆç€é™†ï¼‰æ°´å¹³äº•
- en: neutron porosity to assess location high porosity reservoir sands
  id: totrans-1863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸­å­å­”éš™ç‡ä»¥è¯„ä¼°é«˜å­”éš™ç‡å‚¨å±‚ç ‚çš„ä½ç½®
- en: gamma ray in drill holes to map thorium mineralization
  id: totrans-1864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é’»å­”ä¸­çš„ä¼½é©¬å°„çº¿ç”¨äºç»˜åˆ¶é’çŸ¿åŒ–
- en: Well log data are critical to support subsurface resource interpretations. Once
    anchored by core data they provide the essential coverage and resolution to model
    the entire reservoir concept / framework for prediction, for example,
  id: totrans-1865
  prefs: []
  type: TYPE_NORMAL
  zh: äº•æ—¥å¿—æ•°æ®å¯¹äºæ”¯æŒåœ°ä¸‹èµ„æºè§£é‡Šè‡³å…³é‡è¦ã€‚ä¸€æ—¦ç”±å²©å¿ƒæ•°æ®é”šå®šï¼Œå®ƒä»¬æä¾›äº†å»ºæ¨¡æ•´ä¸ªå‚¨å±‚æ¦‚å¿µ/æ¡†æ¶ä»¥è¿›è¡Œé¢„æµ‹æ‰€å¿…éœ€çš„è¦†ç›–èŒƒå›´å’Œåˆ†è¾¨ç‡ï¼Œä¾‹å¦‚ï¼Œ
- en: well log data calibrated by core data collocated with well log data are used
    to map the critical stratigraphic layers, including reservoir and seal units
  id: totrans-1866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸äº•æ—¥å¿—æ•°æ®åŒä½å¤„çš„å²©å¿ƒæ•°æ®æ ¡å‡†çš„äº•æ—¥å¿—æ•°æ®ç”¨äºç»˜åˆ¶å…³é”®åœ°å±‚å±‚ä½ï¼ŒåŒ…æ‹¬å‚¨å±‚å’Œå°å µå•å…ƒ
- en: well logs are applied to depth correct features inverted from seismic that have
    location imprecision due to uncertainty in the rock velocity over the volume of
    interest
  id: totrans-1867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•æ—¥å¿—åº”ç”¨äºæ·±åº¦æ ¡æ­£ä»åœ°éœ‡ä¸­åæ¼”å‡ºçš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾ç”±äºæ„Ÿå…´è¶£ä½“ç§¯å†…å²©çŸ³é€Ÿåº¦çš„ä¸ç¡®å®šæ€§è€Œå­˜åœ¨ä½ç½®ç²¾åº¦é—®é¢˜
- en: '**Weak Learner**'
  id: totrans-1868
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¼±å­¦ä¹ å™¨**'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): the prediction
    model performs only marginally better than random'
  id: totrans-1869
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šé¢„æµ‹æ¨¡å‹ä»…ç•¥ä¼˜äºéšæœº'
- en: \[ ğ‘Œ = \hat{f}_ğ‘˜(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š) \]
  id: totrans-1870
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘Œ = \hat{f}_ğ‘˜(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š) \]
- en: where \(\hat{f}_ğ‘˜\) is the \(ğ‘˜^{th}\) weak learner, \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\) are the
    predictor features, \(\hat{Y}\) is the prediction of the response feature.
  id: totrans-1871
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\hat{f}_ğ‘˜\) æ˜¯ç¬¬ \(ğ‘˜\) ä¸ªå¼±å­¦ä¹ å™¨ï¼Œ\(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\) æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œ\(\hat{Y}\) æ˜¯å“åº”ç‰¹å¾çš„é¢„æµ‹ã€‚
- en: The term weak predictor is often used, and specifically the term weak classifier
    for the case of classification models.
  id: totrans-1872
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸ç”¨â€œå¼±é¢„æµ‹å™¨â€è¿™ä¸ªæœ¯è¯­ï¼Œå…·ä½“æ¥è¯´ï¼Œå¯¹äºåˆ†ç±»æ¨¡å‹ï¼Œæœ¯è¯­æ˜¯â€œå¼±åˆ†ç±»å™¨â€ã€‚
- en: '**Well Log Data, Image Logs**'
  id: totrans-1873
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº•æ—¥å¿—æ•°æ®ï¼Œå›¾åƒæ—¥å¿—**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a special case
    of *well logs* where the well logs are repeated at various azimuthal intervals
    within the well bore resulting in a 2D (unwrapped) image instead of a 1D line
    along the well bore. For example, Fullbore formation MicroImager (FMI) with:'
  id: totrans-1874
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šè¿™æ˜¯ä¸€ç§ç‰¹æ®Šçš„**äº•æ—¥å¿—**æƒ…å†µï¼Œå…¶ä¸­äº•æ—¥å¿—åœ¨äº•ç­’å†…ä»¥å„ç§æ–¹ä½è§’é—´éš”é‡å¤ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ªäºŒç»´ï¼ˆå±•å¼€ï¼‰å›¾åƒï¼Œè€Œä¸æ˜¯æ²¿ç€äº•ç­’çš„1Dçº¿ã€‚ä¾‹å¦‚ï¼Œå…¨å­”å¾„åœ°å±‚å¾®æˆåƒå™¨ï¼ˆFMIï¼‰å…·æœ‰ï¼š'
- en: with 80% bore hole coverage
  id: totrans-1875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 80% çš„äº•ç­’è¦†ç›–ç‡
- en: 0.2 inch (0.5 cm) resolution vertical and horizontal
  id: totrans-1876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0.2 è‹±å¯¸ï¼ˆ0.5 å˜ç±³ï¼‰åˆ†è¾¨ç‡å‚ç›´å’Œæ°´å¹³
- en: 30 inch (79 cm) depth of investigation
  id: totrans-1877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30 è‹±å¯¸ï¼ˆ79 å˜ç±³ï¼‰çš„æ¢æµ‹æ·±åº¦
- en: can be applied to observe lithology change, bed dips and sedimentary structures.
  id: totrans-1878
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥åº”ç”¨äºè§‚å¯Ÿå²©æ€§å˜åŒ–ã€å±‚å€¾æ–œå’Œæ²‰ç§¯ç»“æ„ã€‚
- en: Comments
  id: totrans-1879
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ³¨é‡Š
- en: This was a basic introduction to geostatistics. If you would like more on these
    fundamental concepts I recommend the Introduction, Modeling Principles and Modeling
    Prerequisites chapters from my text book, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446){cite}`pyrcz2014â€™.
  id: totrans-1880
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹åœ°ç»Ÿè®¡å­¦çš„åŸºæœ¬ä»‹ç»ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºè¿™äº›åŸºæœ¬æ¦‚å¿µçš„ä¿¡æ¯ï¼Œæˆ‘å»ºè®®æ‚¨é˜…è¯»æˆ‘çš„æ•™ç§‘ä¹¦ã€Šåœ°ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡ã€‹ä¸­çš„ä»‹ç»ã€å»ºæ¨¡åŸç†å’Œå»ºæ¨¡å…ˆå†³æ¡ä»¶ç« èŠ‚ï¼Œ[åœ°ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446){cite}`pyrcz2014â€™ã€‚
- en: I hope this is helpful,
  id: totrans-1881
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™æœ‰åŠ©äºï¼Œ
- en: '*Michael*'
  id: totrans-1882
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: 'The Author:'
  id: totrans-1883
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½œè€…ï¼š
- en: Michael Pyrcz, Professor, The University of Texas at Austin *Novel Data Analytics,
    Geostatistics and Machine Learning Subsurface Solutions*
  id: totrans-1884
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”å¥‡ï¼Œæ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ *æ–°é¢–æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ åœ°ä¸‹è§£å†³æ–¹æ¡ˆ*
- en: With over 17 years of experience in subsurface consulting, research and development,
    Michael has returned to academia driven by his passion for teaching and enthusiasm
    for enhancing engineersâ€™ and geoscientistsâ€™ impact in subsurface resource development.
  id: totrans-1885
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åœ°ä¸‹å’¨è¯¢ã€ç ”ç©¶å’Œå¼€å‘æ–¹é¢æ‹¥æœ‰è¶…è¿‡17å¹´çš„ç»éªŒåï¼Œè¿ˆå…‹å°”å› ä»–å¯¹æ•™å­¦çš„çƒ­æƒ…å’Œå¯¹å¢å¼ºå·¥ç¨‹å¸ˆå’Œåœ°çƒç§‘å­¦å®¶åœ¨åœ°ä¸‹èµ„æºå¼€å‘ä¸­å½±å“çš„çƒ­æƒ…è€Œé‡è¿”å­¦æœ¯ç•Œã€‚
- en: 'For more about Michael check out these links:'
  id: totrans-1886
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ä»¥ä¸‹é“¾æ¥ï¼š
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-1887
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
- en: Want to Work Together?
  id: totrans-1888
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-1889
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›è¿™ä»½å†…å®¹å¯¹é‚£äº›æƒ³è¦äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æä»¥åŠæœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«éƒ½æ¬¢è¿å‚ä¸ã€‚
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  id: totrans-1890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster,
    Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling
    and machine learning theory with practice to develop novel methods and workflows
    to add value. We are solving challenging subsurface problems!
  id: totrans-1891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£åˆä½œã€æ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººåŒ…æ‹¬Fosteræ•™æˆã€Torres-Verdinæ•™æˆå’Œvan Oortæ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶å°†æ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µç›¸ç»“åˆï¼Œä»¥å¼€å‘æ–°çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ï¼Œå¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-1892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)è”ç³»æˆ‘ã€‚
- en: Iâ€™m always happy to discuss,
  id: totrans-1893
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è®¨è®ºï¼Œ
- en: '*Michael*'
  id: totrans-1894
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-1895
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨ï¼Œåšå£«ï¼ŒP.Eng. æ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡Cockrellå·¥ç¨‹å­¦é™¢å’ŒJacksonåœ°çƒç§‘å­¦å­¦é™¢
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-1896
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šèµ„æºå¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
- en: Motivation for Machine Learning Concepts
  id: totrans-1897
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ¦‚å¿µçš„åŠ¨åŠ›
- en: Firstly, why do this? I have received the request for a course glossary from
    the students in my **Subsurface Machine Learning** combined undergraduate and
    graduate course. While I usually dedicate a definition slide in the lecture slide
    decks for salient terms, some of my students have requested course glossary, list
    of terminology for their course review. The e-book provides a great vehicle and
    motivation to finally complete this.
  id: totrans-1898
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼Ÿæˆ‘æ”¶åˆ°äº†æ¥è‡ªæˆ‘çš„**åœ°ä¸‹æœºå™¨å­¦ä¹ **æœ¬ç§‘å’Œç ”ç©¶ç”Ÿè¯¾ç¨‹çš„å­¦ç”Ÿçš„è¯·æ±‚ï¼Œè¦æ±‚æä¾›è¯¾ç¨‹æœ¯è¯­è¡¨ã€‚è™½ç„¶æˆ‘é€šå¸¸åœ¨è®²ä¹‰ä¸­ä¸ºæ˜¾è‘—æœ¯è¯­æä¾›å®šä¹‰å¹»ç¯ç‰‡ï¼Œä½†ä¸€äº›å­¦ç”Ÿè¦æ±‚è¯¾ç¨‹æœ¯è¯­è¡¨ï¼Œå³è¯¾ç¨‹å¤ä¹ çš„æœ¯è¯­åˆ—è¡¨ã€‚è¿™æœ¬ç”µå­ä¹¦æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„è½½ä½“å’ŒåŠ¨åŠ›ï¼Œæœ€ç»ˆå®Œæˆè¿™é¡¹å·¥ä½œã€‚
- en: Let me begin with a confession. There is a [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary)
    written by Google developers. For those seeking the in depth, comprehensive list
    of geostatistical terms please use this book!
  id: totrans-1899
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»ä¸€é¡¹å¦ç™½å¼€å§‹ã€‚æœ‰ä¸€æœ¬ç”±è°·æ­Œå¼€å‘è€…ç¼–å†™çš„[æœºå™¨å­¦ä¹ æœ¯è¯­è¡¨](https://developers.google.com/machine-learning/glossary)ã€‚å¯¹äºé‚£äº›å¯»æ±‚æ·±å…¥ã€å…¨é¢çš„åœ°ç†ç»Ÿè®¡æœ¯è¯­åˆ—è¡¨çš„äººæ¥è¯´ï¼Œè¯·ä½¿ç”¨è¿™æœ¬ä¹¦ï¼
- en: By writing my own glossary I can limit the scope and descriptions to course
    content. I fear that many students would be overwhelmed by the size and mathematical
    notation of a standard machine learning glossary.
  id: totrans-1900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ç¼–å†™è‡ªå·±çš„æœ¯è¯­è¡¨ï¼Œæˆ‘å¯ä»¥å°†èŒƒå›´å’Œæè¿°é™åˆ¶åœ¨è¯¾ç¨‹å†…å®¹å†…ã€‚æˆ‘æ‹…å¿ƒè®¸å¤šå­¦ç”Ÿä¼šå› ä¸ºæ ‡å‡†æœºå™¨å­¦ä¹ æœ¯è¯­è¡¨çš„å¤§å°å’Œæ•°å­¦ç¬¦å·è€Œæ„Ÿåˆ°ä¸çŸ¥æ‰€æªã€‚
- en: Also, by including a glossary in the e-book I can link from glossary entries
    to the chapters in the e-book for convenience. I will eventual populate all the
    chapters with hyperlinks to the glossary to enable moving back and forth between
    the chapters and the glossary.
  id: totrans-1901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œé€šè¿‡åœ¨ç”µå­ä¹¦ä¸­åŒ…å«æœ¯è¯­è¡¨ï¼Œæˆ‘å¯ä»¥ä»æœ¯è¯­è¡¨æ¡ç›®é“¾æ¥åˆ°ç”µå­ä¹¦ä¸­çš„ç« èŠ‚ï¼Œä»¥ä¾¿æ–¹ä¾¿åœ°è®¿é—®ã€‚æˆ‘æœ€ç»ˆå°†æ‰€æœ‰ç« èŠ‚éƒ½æ·»åŠ åˆ°æœ¯è¯­è¡¨çš„è¶…é“¾æ¥ä¸­ï¼Œä»¥ä¾¿åœ¨ç« èŠ‚å’Œæœ¯è¯­è¡¨ä¹‹é—´æ¥å›ç§»åŠ¨ã€‚
- en: Finally, like the rest of the book, I want the glossary to be a evergreen living
    document.
  id: totrans-1902
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå°±åƒæœ¬ä¹¦çš„å…¶ä»–éƒ¨åˆ†ä¸€æ ·ï¼Œæˆ‘å¸Œæœ›æœ¯è¯­è¡¨èƒ½å¤Ÿæˆä¸ºä¸€ä¸ªå¸¸é’çš„æ´»æ–‡æ¡£ã€‚
- en: '**Adjacency Matrix** (spectral clustering)'
  id: totrans-1903
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é‚»æ¥çŸ©é˜µ**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph with the pairwise connections between all pairwise combinations of graph
    nodes, samples.'
  id: totrans-1904
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šè¡¨ç¤ºå›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹æˆå¯¹ç»„åˆä¹‹é—´æˆå¯¹è¿æ¥çš„çŸ©é˜µã€‚'
- en: the values are indicators, 0 if not connected, 1 if connected
  id: totrans-1905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›å€¼æ˜¯æŒ‡æ ‡ï¼Œå¦‚æœä¸è¿æ¥åˆ™ä¸º0ï¼Œå¦‚æœè¿æ¥åˆ™ä¸º1
- en: Note, node self connections are set to 0 in the adjacency matrix
  id: totrans-1906
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨é‚»æ¥çŸ©é˜µä¸­ï¼ŒèŠ‚ç‚¹è‡ªè¿æ¥è¢«è®¾ç½®ä¸º0
- en: '**Addition Rule** (probability)'
  id: totrans-1907
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŠ æ³•è§„åˆ™**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): when we add probabilities
    (the union of outcomes), the probability of \(A\) or \(B\) is calculated with
    the probability addition rule,'
  id: totrans-1908
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šå½“æˆ‘ä»¬æ·»åŠ æ¦‚ç‡ï¼ˆç»“æœçš„å¹¶é›†ï¼‰æ—¶ï¼Œ\(A\) æˆ– \(B\) çš„æ¦‚ç‡æ˜¯æ ¹æ®æ¦‚ç‡åŠ æ³•è§„åˆ™è®¡ç®—çš„ï¼Œ'
- en: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
  id: totrans-1909
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
- en: given mutually exclusive events we can generalize the addition rule as,
  id: totrans-1910
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºäº’æ–¥äº‹ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†åŠ æ³•è§„åˆ™æ¨å¹¿å¦‚ä¸‹ï¼Œ
- en: \[ P\left( \bigcup_{i=1}^k A_i \right) = \sum_{i=1}^k P(A_i) \]
  id: totrans-1911
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P\left( \bigcup_{i=1}^k A_i \right) = \sum_{i=1}^k P(A_i) \]
- en: '**Affine Correction**'
  id: totrans-1912
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä»¿å°„æ ¡æ­£**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    distribution rescaling that can be thought of as shifting, and stretching or squeezing
    of a univariate distribution (e.g., *histogram*). For the case of affine correction
    of \(X\) to \(Y\),'
  id: totrans-1913
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§åˆ†å¸ƒç¼©æ”¾ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºå•å˜é‡åˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œ*ç›´æ–¹å›¾*ï¼‰çš„å¹³ç§»ã€æ‹‰ä¼¸æˆ–å‹ç¼©ã€‚å¯¹äºå°†
    \(X\) ä»¿å°„æ ¡æ­£ä¸º \(Y\) çš„æƒ…å†µï¼Œ'
- en: \[ y_i = \frac{\sigma_y}{\sigma_x}(x_i - \overline{x}) + \overline{y}, \quad
    \forall \quad i, \ldots, n \]
  id: totrans-1914
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{\sigma_y}{\sigma_x}(x_i - \overline{x}) + \overline{y}, \quad
    \forall \quad i, \ldots, n \]
- en: where \(\overline{x}\) and \(\sigma_x\) are the original mean and variance,
    and \(\overline{y}\) and \(\sigma_y\) are the new mean and variance.
  id: totrans-1915
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\sigma_x\) æ˜¯åŸå§‹å‡å€¼å’Œæ–¹å·®ï¼Œ\(\overline{y}\) å’Œ \(\sigma_y\)
    æ˜¯æ–°çš„å‡å€¼å’Œæ–¹å·®ã€‚
- en: We can see above that the affine correlation method first centers the distribution
    (by subtracting the original mean), then rescales the dispersion (distribution
    spread) by the ratio of the new standard deviation to the original standard deviation
    and then shifts the distribution to centered on the new mean.
  id: totrans-1916
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä»ä¸Šé¢çœ‹åˆ°ï¼Œä»¿å°„ç›¸å…³æ–¹æ³•é¦–å…ˆé€šè¿‡å‡å»åŸå§‹å‡å€¼æ¥å¯¹åˆ†å¸ƒè¿›è¡Œä¸­å¿ƒåŒ–ï¼Œç„¶åé€šè¿‡æ–°æ ‡å‡†å·®ä¸åŸå§‹æ ‡å‡†å·®çš„æ¯”ä¾‹æ¥é‡æ–°ç¼©æ”¾åˆ†æ•£åº¦ï¼ˆåˆ†å¸ƒæ‰©æ•£ï¼‰ï¼Œç„¶åå°†åˆ†å¸ƒå¹³ç§»åˆ°æ–°çš„å‡å€¼å¤„ã€‚
- en: there is no shape change for affine correction. For shape change consider *Distribution
    Transformation* like *Gaussian Anamorphosis*.
  id: totrans-1917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¿å°„æ ¡æ­£æ²¡æœ‰å½¢çŠ¶å˜åŒ–ã€‚å¯¹äºå½¢çŠ¶å˜åŒ–ï¼Œè¯·è€ƒè™‘*åˆ†å¸ƒå˜æ¢*ï¼Œå¦‚*é«˜æ–¯ç•¸å˜*ã€‚
- en: '**Affinity Matrix** (spectral clustering)'
  id: totrans-1918
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº²å’ŒçŸ©é˜µ**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph with the degree of pairwise connections between all pairwise combinations
    of graph nodes, samples.'
  id: totrans-1919
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šè¡¨ç¤ºå›¾ä¸­æ‰€æœ‰æˆå¯¹èŠ‚ç‚¹ä¹‹é—´è¿æ¥ç¨‹åº¦çš„çŸ©é˜µï¼Œæ ·æœ¬ã€‚'
- en: values indicate the strength of the connection, unlike adjacency matrix with
    indicators, 0 if not connected, 1 if connected
  id: totrans-1920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å€¼è¡¨ç¤ºè¿æ¥çš„å¼ºåº¦ï¼Œä¸æŒ‡ç¤ºé‚»æ¥çŸ©é˜µä¸åŒï¼Œå¦‚æœä¸è¿æ¥åˆ™ä¸º0ï¼Œå¦‚æœè¿æ¥åˆ™ä¸º1ã€‚
- en: Note, node self connections are set to 0 in the adjacency matrix
  id: totrans-1921
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨é‚»æ¥çŸ©é˜µä¸­ï¼ŒèŠ‚ç‚¹è‡ªè¿æ¥è¢«è®¾ç½®ä¸º0ã€‚
- en: '**Bagging Models**'
  id: totrans-1922
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Baggingæ¨¡å‹**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): the
    application of bootstrap to obtain data realizations,'
  id: totrans-1923
  prefs: []
  type: TYPE_NORMAL
  zh: '[Baggingæ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šä½¿ç”¨è‡ªåŠ©æ³•è·å¾—æ•°æ®å®ç°çš„åº”ç”¨ã€‚'
- en: \[ Y^b, X_1^b, \dots, X_m^b, \quad b = 1, \dots, B \]
  id: totrans-1924
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y^b, X_1^b, \dots, X_m^b, \quad b = 1, \dots, B \]
- en: to train predictive model realizations,
  id: totrans-1925
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®­ç»ƒé¢„æµ‹æ¨¡å‹å®ç°ï¼Œ
- en: \(\hat{Y}^b = \hat{f}^b (X_1^b, \dots, X_m^b)\)
  id: totrans-1926
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{Y}^b = \hat{f}^b (X_1^b, \dots, X_m^b)\)
- en: where,
  id: totrans-1927
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ
- en: \((X_1^b, \dots, X_m^b)\) - the bootstrap predictor features in the \(b^{th}\)
    bootstrapped dataset
  id: totrans-1928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \((X_1^b, \dots, X_m^b)\) - ç¬¬ \(b\) ä¸ªè‡ªåŠ©æ•°æ®é›†ä¸­çš„è‡ªåŠ©é¢„æµ‹ç‰¹å¾
- en: \(\hat{f}^b\) - the \(b^{th}\) bootstrapped model
  id: totrans-1929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{f}^b\) - ç¬¬ \(b\) ä¸ªè‡ªåŠ©æ¨¡å‹
- en: \(\hat{Y}^b\) - predicted value for the model in the \(b^{th}\) bootstrapped
    model
  id: totrans-1930
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{Y}^b\) - ç¬¬ \(b\) ä¸ªè‡ªåŠ©æ¨¡å‹ä¸­çš„æ¨¡å‹é¢„æµ‹å€¼
- en: to calculate prediction realizations. The ensemble of prediction realizations
    are aggregated to reduce model variance. The aggregation includes,
  id: totrans-1931
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®¡ç®—é¢„æµ‹å®ç°ã€‚é¢„æµ‹å®ç°çš„é›†æˆè¢«èšåˆä»¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚èšåˆåŒ…æ‹¬ï¼Œ
- en: '*regression* - the average of the predictions $\( \hat{Y} = \frac{1}{B} \sum_{b=1}^{B}
    \hat{Y}^b \)$'
  id: totrans-1932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å›å½’* - é¢„æµ‹çš„å¹³å‡å€¼ \( \hat{Y} = \frac{1}{B} \sum_{b=1}^{B} \hat{Y}^b \) '
- en: '*classification* - the mode of the predictions'
  id: totrans-1933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ†ç±»* - é¢„æµ‹çš„æ¨¡å¼'
- en: \[ \hat{Y} = \text{argmax}(\hat{Y}^b) \]
  id: totrans-1934
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} = \text{argmax}(\hat{Y}^b) \]
- en: We can perform bagging with any prediction model, in fact the BaggingClassifier
    and BaggingRegressor functions in scikit-learn are wrappers that take the prediction
    model as an input.
  id: totrans-1935
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å¯¹ä»»ä½•é¢„æµ‹æ¨¡å‹æ‰§è¡ŒBaggingï¼Œå®é™…ä¸Šscikit-learnä¸­çš„BaggingClassifierå’ŒBaggingRegressorå‡½æ•°æ˜¯æ¥å—é¢„æµ‹æ¨¡å‹ä½œä¸ºè¾“å…¥çš„åŒ…è£…å™¨ã€‚
- en: '**Basis Expansion**'
  id: totrans-1936
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºå‡½æ•°å±•å¼€**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): to add
    flexibility to our model, for example, to capture non-linearity in our model for
    regression, classification, we expand the features with a set of basis functions'
  id: totrans-1937
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šä¸ºäº†å¢åŠ æˆ‘ä»¬æ¨¡å‹çš„çµæ´»æ€§ï¼Œä¾‹å¦‚ï¼Œä¸ºäº†æ•æ‰å›å½’ã€åˆ†ç±»æ¨¡å‹ä¸­çš„éçº¿æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„åŸºå‡½æ•°æ‰©å±•ç‰¹å¾ã€‚'
- en: in mathematics basis expansion is the approach of representing a more complicated
    function with a linear combination of simpler basis functions that make the problem
    easier to solve
  id: totrans-1938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°å­¦ä¸­ï¼ŒåŸºå‡½æ•°å±•å¼€æ˜¯å°†æ›´å¤æ‚çš„å‡½æ•°è¡¨ç¤ºä¸ºæ›´ç®€å•åŸºå‡½æ•°çš„çº¿æ€§ç»„åˆçš„æ–¹æ³•ï¼Œè¿™ä½¿å¾—é—®é¢˜æ›´å®¹æ˜“è§£å†³ã€‚
- en: with basis expansion we expand the dimensionality of the problem with basis
    functions of the original features, but still use linear methods on the transformed
    features.
  id: totrans-1939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŸºå‡½æ•°å±•å¼€ï¼Œæˆ‘ä»¬é€šè¿‡åŸå§‹ç‰¹å¾çš„åŸºå‡½æ•°æ‰©å±•é—®é¢˜çš„ç»´åº¦ï¼Œä½†ä»ç„¶åœ¨è½¬æ¢åçš„ç‰¹å¾ä¸Šä½¿ç”¨çº¿æ€§æ–¹æ³•ã€‚
- en: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
  id: totrans-1940
  prefs: []
  type: TYPE_NORMAL
  zh: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
- en: 'Here an example of basis expansion, the set of basis functions for polynomial
    basis expansion:'
  id: totrans-1941
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªåŸºå‡½æ•°å±•å¼€çš„ä¾‹å­ï¼Œå¤šé¡¹å¼åŸºå‡½æ•°å±•å¼€çš„åŸºå‡½æ•°é›†åˆï¼š
- en: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
  id: totrans-1942
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
- en: '**Basis Function**'
  id: totrans-1943
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºå‡½æ•°**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): to add
    flexibility to our model, for example, to capture non-linearity in our model for
    regression, classification, we expand the features with a set of basis functions'
  id: totrans-1944
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šä¸ºäº†å¢åŠ æˆ‘ä»¬æ¨¡å‹çš„çµæ´»æ€§ï¼Œä¾‹å¦‚ï¼Œä¸ºäº†æ•æ‰å›å½’ã€åˆ†ç±»æ¨¡å‹ä¸­çš„éçº¿æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç»„åŸºå‡½æ•°æ‰©å±•ç‰¹å¾ã€‚'
- en: in mathematics basis expansion is the approach of representing a more complicated
    function with a linear combination of simpler basis functions that make the problem
    easier to solve
  id: totrans-1945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°å­¦ä¸­ï¼ŒåŸºå‡½æ•°å±•å¼€æ˜¯å°†æ›´å¤æ‚çš„å‡½æ•°è¡¨ç¤ºä¸ºæ›´ç®€å•åŸºå‡½æ•°çš„çº¿æ€§ç»„åˆçš„æ–¹æ³•ï¼Œè¿™ä½¿å¾—é—®é¢˜æ›´å®¹æ˜“è§£å†³ã€‚
- en: with basis expansion we expand the dimensionality of the problem with basis
    functions of the original features, but still use linear methods on the transformed
    features.
  id: totrans-1946
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŸºå‡½æ•°å±•å¼€ï¼Œæˆ‘ä»¬é€šè¿‡åŸå§‹ç‰¹å¾çš„åŸºå‡½æ•°æ‰©å±•é—®é¢˜çš„ç»´åº¦ï¼Œä½†ä»ç„¶åœ¨è½¬æ¢åçš„ç‰¹å¾ä¸Šä½¿ç”¨çº¿æ€§æ–¹æ³•ã€‚
- en: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
  id: totrans-1947
  prefs: []
  type: TYPE_NORMAL
  zh: \[ â„(ğ‘¥_ğ‘– )=\left( â„_1(ğ‘¥_ğ‘– ),â„_2(ğ‘¥_ğ‘– ),\ldots,â„_ğ‘˜(ğ‘¥_ğ‘– ) \right) \]
- en: 'were each of \(h_1\), \ldots, \(h_k\) are basis functions. For example, here
    are the basis functions for polynomial basis expansion:'
  id: totrans-1948
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­æ¯ä¸ª \(h_1\), \ldots, \(h_k\) éƒ½æ˜¯åŸºå‡½æ•°ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæ˜¯ä¸€äº›å¤šé¡¹å¼åŸºå±•å¼€çš„åŸºå‡½æ•°ï¼š
- en: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
  id: totrans-1949
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_{i,1}(x_i) = x_i, \quad h_{i,2}(x_i) = x_i^2, \quad h_{i,3}(x_i) = x_i^3,
    \quad h_{i,4}(x_i) = x_i^4, \dots, \quad h_{i,k}(x_i) = x_i^k \]
- en: '**Bayesâ€™ Theorem** (probability)'
  id: totrans-1950
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è´å¶æ–¯å®šç†**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the mathematical
    model central to Bayesian probability for the Bayesian updating from prior probability,
    with likelihood probability from new information to posterior probability.'
  id: totrans-1951
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šè´å¶æ–¯æ¦‚ç‡çš„æ ¸å¿ƒæ•°å­¦æ¨¡å‹ï¼Œç”¨äºä»å…ˆéªŒæ¦‚ç‡è¿›è¡Œè´å¶æ–¯æ›´æ–°ï¼Œé€šè¿‡æ–°ä¿¡æ¯çš„ä¼¼ç„¶æ¦‚ç‡åˆ°åéªŒæ¦‚ç‡ã€‚'
- en: \[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]
  id: totrans-1952
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \]
- en: where \(P(A)\) is the prior, \(P(B|A)\) is the likelihood, \(P(B)\) is the evidence
    term and \(P(A|B)\) is the posterior. If is convenient to substitute more descriptive
    labels for \(A\) and \(B\) to better conceptualize this approach,
  id: totrans-1953
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(P(A)\) æ˜¯å…ˆéªŒï¼Œ\(P(B|A)\) æ˜¯ä¼¼ç„¶ï¼Œ\(P(B)\) æ˜¯è¯æ®é¡¹ï¼Œ\(P(A|B)\) æ˜¯åéªŒã€‚å¦‚æœç”¨æ›´æè¿°æ€§çš„æ ‡ç­¾æ›¿æ¢ \(A\)
    å’Œ \(B\)ï¼Œå°†æœ‰åŠ©äºæ›´å¥½åœ°ç†è§£è¿™ç§æ–¹æ³•ï¼Œ
- en: \[ P(\text{Model} | \text{New Data}) = \frac{P(\text{New Data} | \text{Model})
    \cdot P(\text{Model})}{P(\text{New Data})} \]
  id: totrans-1954
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\text{Model} | \text{New Data}) = \frac{P(\text{New Data} | \text{Model})
    \cdot P(\text{Model})}{P(\text{New Data})} \]
- en: demonstrating that we are updating our model with new data
  id: totrans-1955
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ˜äº†æˆ‘ä»¬æ­£åœ¨ç”¨æ–°æ•°æ®æ›´æ–°æˆ‘ä»¬çš„æ¨¡å‹
- en: '**Bayesian Probability**'
  id: totrans-1956
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è´å¶æ–¯æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): probabilities based
    on a degree of belief (expert judgement and experience) in the likelihood of an
    event. The general approach,'
  id: totrans-1957
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåŸºäºå¯¹äº‹ä»¶å‘ç”Ÿå¯èƒ½æ€§çš„ä¿¡å¿µç¨‹åº¦ï¼ˆä¸“å®¶åˆ¤æ–­å’Œç»éªŒï¼‰çš„æ¦‚ç‡ã€‚ä¸€èˆ¬æ–¹æ³•ï¼Œ'
- en: start with prior probability, prior to the collection of new information
  id: totrans-1958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»å…ˆéªŒæ¦‚ç‡å¼€å§‹ï¼Œåœ¨æ”¶é›†æ–°ä¿¡æ¯ä¹‹å‰
- en: formulate a likelihood probability, based on new information alone
  id: totrans-1959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»…åŸºäºæ–°ä¿¡æ¯åˆ¶å®šä¼¼ç„¶æ¦‚ç‡
- en: update prior with likelihood to calculate the updated posterior probability
  id: totrans-1960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¼¼ç„¶æ›´æ–°å…ˆéªŒä»¥è®¡ç®—æ›´æ–°çš„åéªŒæ¦‚ç‡
- en: continue to update as new information is available
  id: totrans-1961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æ–°ä¿¡æ¯å¯ç”¨æ—¶ç»§ç»­æ›´æ–°
- en: solve probability problems that we cannot use simple frequencies, i.e., *frequentist
    probability* approach
  id: totrans-1962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§£å†³é‚£äº›æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨ç®€å•é¢‘ç‡è§£å†³çš„é—®é¢˜ï¼Œå³*é¢‘ç‡ä¸»ä¹‰æ¦‚ç‡*æ–¹æ³•
- en: Bayesian updating is modeled with *Bayesâ€™ Theorem*
  id: totrans-1963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è´å¶æ–¯æ›´æ–°é€šè¿‡**è´å¶æ–¯å®šç†**å»ºæ¨¡
- en: '**Bayesian Updating for Classification**'
  id: totrans-1964
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»çš„è´å¶æ–¯æ›´æ–°**'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): this is how we pose the classification
    prediction problem from the perspective of Bayesian updating, based on the conditional
    probability of a category, \(k\), given \(n\) features, \(x_1, \dots , x_n\).'
  id: totrans-1965
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šè¿™æ˜¯ä»è´å¶æ–¯æ›´æ–°çš„è§’åº¦æå‡ºåˆ†ç±»é¢„æµ‹é—®é¢˜ï¼ŒåŸºäºç±»åˆ« \(k\) ç»™å®š
    \(n\) ä¸ªç‰¹å¾ \(x_1, \dots , x_n\) çš„æ¡ä»¶æ¦‚ç‡ã€‚'
- en: \[ P(C_k | x_1, \dots , x_n) \]
  id: totrans-1966
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) \]
- en: we can solve for this posterior with Bayesian updating,
  id: totrans-1967
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç”¨è´å¶æ–¯æ›´æ–°æ±‚è§£è¿™ä¸ªåéªŒæ¦‚ç‡ï¼Œ
- en: \[ P(C_k | x_1, \dots , x_n) = \frac{P(x_1, \dots , x_n | C_k) P(C_k)}{P(x_1,
    \dots , x_n)} \]
  id: totrans-1968
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) = \frac{P(x_1, \dots , x_n | C_k) P(C_k)}{P(x_1,
    \dots , x_n)} \]
- en: letâ€™s combine the likelihood and prior for the moment,
  id: totrans-1969
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æš‚æ—¶å°†ä¼¼ç„¶å’Œå…ˆéªŒç»“åˆèµ·æ¥ï¼Œ
- en: \[ P(x_1, \dots , x_n | C_k) P(C_k) = P(x_1, \dots , x_n, C_k) \]
  id: totrans-1970
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1, \dots , x_n | C_k) P(C_k) = P(x_1, \dots , x_n, C_k) \]
- en: we can expand the full joint distribution recursively as follows,
  id: totrans-1971
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€’å½’åœ°å±•å¼€å®Œæ•´çš„è”åˆåˆ†å¸ƒå¦‚ä¸‹ï¼Œ
- en: \[ P(x_1, \dots , x_n, C_k) \]
  id: totrans-1972
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1, \dots , x_n, C_k) \]
- en: expansion of the joint with the conditional and prior,
  id: totrans-1973
  prefs: []
  type: TYPE_NORMAL
  zh: è”åˆåˆ†å¸ƒä¸æ¡ä»¶åˆ†å¸ƒå’Œå…ˆéªŒåˆ†å¸ƒçš„å±•å¼€ï¼Œ
- en: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2, \dots , x_n, C_k) \]
  id: totrans-1974
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2, \dots , x_n, C_k) \]
- en: continue recursively expanding,
  id: totrans-1975
  prefs: []
  type: TYPE_NORMAL
  zh: ç»§ç»­é€’å½’å±•å¼€ï¼Œ
- en: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3, \dots
    , x_n, C_k) \]
  id: totrans-1976
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3, \dots
    , x_n, C_k) \]
- en: we can generalize as,
  id: totrans-1977
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ¨å¹¿ä¸ºï¼Œ
- en: \[ P(C_k | x_1, \dots , x_n) = P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots
    , x_n, C_k) P(x_3 | x_4, \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n}
    | C_k) P(C_k) \]
  id: totrans-1978
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) = P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots
    , x_n, C_k) P(x_3 | x_4, \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n}
    | C_k) P(C_k) \]
- en: '**Bayesian Linear Regression**'
  id: totrans-1979
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è´å¶æ–¯çº¿æ€§å›å½’**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    the frequentist formulation of the linear regression model is,'
  id: totrans-1980
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šçº¿æ€§å›å½’æ¨¡å‹çš„é¢‘ç‡æ´¾å…¬å¼ä¸ºï¼Œ'
- en: \[ y = b_1 \times x + b_0 + \sigma \]
  id: totrans-1981
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = b_1 \times x + b_0 + \sigma \]
- en: where \(x\) is the predictor feature, \(b_1\) is the slope parameter, \(b_0\)
    is the intercept parameter and \(\sigma\) is the error or noise. There is an analytical
    form for the ordinary least squares solution to fit the available data while minimizing
    the \(L^2\) norm of the data error vector.
  id: totrans-1982
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(x\) æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œ\(b_1\) æ˜¯æ–œç‡å‚æ•°ï¼Œ\(b_0\) æ˜¯æˆªè·å‚æ•°ï¼Œ\(\sigma\) æ˜¯è¯¯å·®æˆ–å™ªå£°ã€‚å­˜åœ¨ä¸€ä¸ªè§£æå½¢å¼ï¼Œç”¨äºæ‹Ÿåˆå¯ç”¨æ•°æ®çš„åŒæ—¶æœ€å°åŒ–æ•°æ®è¯¯å·®å‘é‡çš„
    \(L^2\) èŒƒæ•°ã€‚
- en: 'For the Bayesian formulation of linear regression is we pose the model as a
    prediction of the distribution of the response, \(Y\), now a random variable:'
  id: totrans-1983
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºçº¿æ€§å›å½’çš„è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬å°†æ¨¡å‹è®¾å®šä¸ºå“åº”å˜é‡ \(Y\) çš„åˆ†å¸ƒé¢„æµ‹ï¼Œç°åœ¨æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼š
- en: \[ Y \sim N(\beta^{T}X, \sigma^{2} I) \]
  id: totrans-1984
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y \sim N(\beta^{T}X, \sigma^{2} I) \]
- en: We estimate the model parameter distributions through Bayesian updating for
    inferring the model parameters from a prior and likelihood from training data.
  id: totrans-1985
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡è´å¶æ–¯æ›´æ–°æ¥ä¼°è®¡æ¨¡å‹å‚æ•°åˆ†å¸ƒï¼Œä»¥ä»å…ˆéªŒå’Œè®­ç»ƒæ•°æ®ä¸­çš„ä¼¼ç„¶æ¨æ–­æ¨¡å‹å‚æ•°ã€‚
- en: \[ P(\beta | y, X) = \frac{P(y,X| \beta) P(\beta)}{P(y,X)} \]
  id: totrans-1986
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\beta | y, X) = \frac{P(y,X| \beta) P(\beta)}{P(y,X)} \]
- en: In general for continuous features we are not able to directly calculate the
    posterior and we must use a sampling method, such as Markov chain Monte Carlo
    (McMC) to sample the posterior.
  id: totrans-1987
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸å¯¹äºè¿ç»­ç‰¹å¾ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®—åéªŒï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨é‡‡æ ·æ–¹æ³•ï¼Œä¾‹å¦‚é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ï¼ˆMcMCï¼‰æ¥é‡‡æ ·åéªŒã€‚
- en: '**Big Data**'
  id: totrans-1988
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤§æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): you have big data
    if your data has a combination of these criteria:'
  id: totrans-1989
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¦‚æœä½ çš„æ•°æ®æ»¡è¶³ä»¥ä¸‹æ ‡å‡†ä¹‹ä¸€ï¼Œåˆ™ä½ æœ‰å¤§æ•°æ®ï¼š'
- en: '*Data Volume* - many data samples and features, difficult to store, transmit
    and visualize'
  id: totrans-1990
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®é‡* - è®¸å¤šæ•°æ®æ ·æœ¬å’Œç‰¹å¾ï¼Œéš¾ä»¥å­˜å‚¨ã€ä¼ è¾“å’Œå¯è§†åŒ–'
- en: '*Data Velocity* - high-rate collection, continuous data collection relative
    to decision making cycles, challenges keeping up with the new data while updating
    the models'
  id: totrans-1991
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®é€Ÿåº¦* - é«˜é€Ÿæ”¶é›†ï¼Œç›¸å¯¹äºå†³ç­–å‘¨æœŸè¿›è¡Œè¿ç»­æ•°æ®æ”¶é›†ï¼ŒæŒ‘æˆ˜åœ¨äºåœ¨æ›´æ–°æ¨¡å‹çš„åŒæ—¶è·Ÿä¸Šæ–°çš„æ•°æ®'
- en: '*Data Variety* - data form various sources, with various types of data, types
    of information, and scales'
  id: totrans-1992
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®å¤šæ ·æ€§* - æ•°æ®æ¥è‡ªå„ç§æ¥æºï¼Œå…·æœ‰å„ç§ç±»å‹çš„æ•°æ®ã€ä¿¡æ¯å’Œè§„æ¨¡'
- en: '*Data Variability* - data acquisition changes during the project, even for
    a single feature there may be multiple vintages of data with different scales,
    distributions, and veracity'
  id: totrans-1993
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®å¯å˜æ€§* - æ•°æ®åœ¨é¡¹ç›®æœŸé—´å‘ç”Ÿå˜åŒ–ï¼Œå³ä½¿æ˜¯å•ä¸€ç‰¹å¾ä¹Ÿå¯èƒ½æœ‰å¤šä¸ªä¸åŒè§„æ¨¡ã€åˆ†å¸ƒå’ŒçœŸå®æ€§çš„æ•°æ®ç‰ˆæœ¬'
- en: '*Data Veracity* - data has various levels of accuracy, the data is not certain'
  id: totrans-1994
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ•°æ®çœŸå®æ€§* - æ•°æ®å…·æœ‰å„ç§å‡†ç¡®åº¦çº§åˆ«ï¼Œæ•°æ®å¹¶ä¸ç¡®å®š'
- en: For common subsurface applications most, if not all, of these criteria are met.
    Subsurface engineering and geoscience are often working with big data!
  id: totrans-1995
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤§å¤šæ•°ï¼ˆå¦‚æœä¸æ˜¯æ‰€æœ‰ï¼‰çš„å¸¸è§„åœ°ä¸‹åº”ç”¨ï¼Œè¿™äº›æ ‡å‡†éƒ½å¾—åˆ°äº†æ»¡è¶³ã€‚åœ°ä¸‹å·¥ç¨‹å’Œåœ°çƒç§‘å­¦é€šå¸¸ä¸å¤§æ•°æ®æ‰“äº¤é“ï¼
- en: '**Big Data Analytics**'
  id: totrans-1996
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤§æ•°æ®åˆ†æ**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the process of
    examining large and varied data (*big data*) sets to discover patterns and make
    decisions, the application of statistics to big data.'
  id: totrans-1997
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ£€æŸ¥å¤§å‹å’Œå¤šæ ·åŒ–çš„æ•°æ®é›†ï¼ˆå¤§æ•°æ®ï¼‰ä»¥å‘ç°æ¨¡å¼å’Œåšå‡ºå†³ç­–çš„è¿‡ç¨‹ï¼Œå°†ç»Ÿè®¡å­¦åº”ç”¨äºå¤§æ•°æ®ã€‚'
- en: '**Binary Transform** (also Indicator Transform)'
  id: totrans-1998
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äºŒè¿›åˆ¶è½¬æ¢**ï¼ˆä¹Ÿç§°ä¸ºæŒ‡ç¤ºè½¬æ¢ï¼‰'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): indicator
    coding a random variable to a probability relative to a category or a threshold.'
  id: totrans-1999
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šå°†éšæœºå˜é‡æŒ‡ç¤ºç¼–ç ä¸ºç›¸å¯¹äºç±»åˆ«æˆ–é˜ˆå€¼çš„æ¦‚ç‡ã€‚'
- en: If \(i(\bf{u}:z_k)\) is an indicator for a categorical variable,
  id: totrans-2000
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(i(\bf{u}:z_k)\) æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡çš„æŒ‡ç¤ºç¬¦ï¼Œ
- en: what is the probability of a realization equal to a category?
  id: totrans-2001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°ç­‰äºä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
  id: totrans-2002
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-2003
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_2 = 2\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 2\),
    then \(i(bf{u}_1; z_2) = 1\)
  id: totrans-2004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_2 = 2\)ï¼Œä»¥åŠæ•°æ®åœ¨ \(\bf{u}_1\)ï¼Œ\(z(\bf{u}_1) = 2\)ï¼Œåˆ™ \(i(\bf{u}_1; z_2)
    = 1\)
- en: given threshold, \(z_1 = 1\), and a RV away from data, \(Z(\bf{u}_2)\) then
    is calculated as \(F^{-1}_{\bf{u}_2}(z_1)\) of the RV as \(i(\bf{u}_2; z_1) =
    0.23\)
  id: totrans-2005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 1\)ï¼Œä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ \(Z(\bf{u}_2)\)ï¼Œåˆ™è®¡ç®—ä¸º \(F^{-1}_{\bf{u}_2}(z_1)\)
    çš„éšæœºå˜é‡ï¼Œ\(i(\bf{u}_2; z_1) = 0.23\)
- en: If \(I\{\bf{u}:z_k\}\) is an indicator for a continuous variable,
  id: totrans-2006
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(I\{\bf{u}:z_k\}\) æ˜¯ä¸€ä¸ªè¿ç»­å˜é‡çš„æŒ‡ç¤ºå™¨ï¼Œ
- en: what is the probability of a realization less than or equal to a threshold?
  id: totrans-2007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°å°äºæˆ–ç­‰äºé˜ˆå€¼çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
  id: totrans-2008
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-2009
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_1 = 6\%\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 8\%\),
    then \(i(\bf{u}_1; z_1) = 0\)
  id: totrans-2010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 6\%\)ï¼Œä»¥åŠæ•°æ®åœ¨ \(\bf{u}_1\)ï¼Œ\(z(\bf{u}_1) = 8\%\)ï¼Œåˆ™ \(i(\bf{u}_1;
    z_1) = 0\)
- en: given threshold, \(z_4 = 18\%\), and a RV away from data, \(Z(\bf{u}_2) = N\left[\mu
    = 16\%,\sigma = 3\%\right]\) then \(i(\bf{u}_2; z_4) = 0.75\)
  id: totrans-2011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_4 = 18\%\)ï¼Œä»¥åŠè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ \(Z(\bf{u}_2) = N\left[\mu = 16\%,\sigma = 3\%\right]\)ï¼Œåˆ™
    \(i(\bf{u}_2; z_4) = 0.75\)
- en: The indicator coding may be applied over an entire random function by indicator
    transform of all the random variables at each location.
  id: totrans-2012
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡ç¤ºç¼–ç å¯ä»¥é€šè¿‡åœ¨æ¯ä¸ªä½ç½®çš„éšæœºå˜é‡çš„æŒ‡ç¤ºå˜æ¢åº”ç”¨äºæ•´ä¸ªéšæœºå‡½æ•°ã€‚
- en: '**Boosting Models**'
  id: totrans-2013
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æå‡æ¨¡å‹**'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): addition of multiple
    week learners to build a stronger learner.'
  id: totrans-2014
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šé€šè¿‡æ·»åŠ å¤šä¸ªå¼±å­¦ä¹ å™¨æ¥æ„å»ºæ›´å¼ºçš„å­¦ä¹ å™¨ã€‚'
- en: a weak learner is one that offers predictions just marginally better than random
    selection
  id: totrans-2015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼±å­¦ä¹ å™¨æ˜¯æŒ‡æä¾›é¢„æµ‹ç»“æœä»…ç•¥å¥½äºéšæœºé€‰æ‹©çš„æ¨¡å‹
- en: This is the method in words, and then with equations,
  id: totrans-2016
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ç”¨æ–‡å­—æè¿°çš„æ–¹æ³•ï¼Œç„¶åç”¨æ–¹ç¨‹è¡¨ç¤ºï¼Œ
- en: build a simple model with a high error rate, the model can be quite inaccurate,
    but moves in the correct direction
  id: totrans-2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªè¯¯å·®ç‡é«˜çš„ç®€å•æ¨¡å‹ï¼Œæ¨¡å‹å¯èƒ½éå¸¸ä¸å‡†ç¡®ï¼Œä½†æ–¹å‘æ˜¯æ­£ç¡®çš„
- en: calculate the error from the model
  id: totrans-2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¨¡å‹çš„è¯¯å·®
- en: fit another model to the error
  id: totrans-2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å¦ä¸€ä¸ªæ¨¡å‹æ‹Ÿåˆåˆ°è¯¯å·®
- en: calculate the error from this addition of the first and second model
  id: totrans-2020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªæ¨¡å‹æ·»åŠ çš„è¯¯å·®
- en: repeat until the desired accuracy is obtained or some other stopping criteria
  id: totrans-2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å¤ç›´åˆ°è¾¾åˆ°æ‰€éœ€çš„å‡†ç¡®åº¦æˆ–æ»¡è¶³å…¶ä»–åœæ­¢æ¡ä»¶
- en: Now with equations, the general workflow for predicting \(Y\) from \(X_1,\ldots,X_m\)
    is,
  id: totrans-2022
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æœ‰äº†æ–¹ç¨‹ï¼Œä» \(X_1,\ldots,X_m\) é¢„æµ‹ \(Y\) çš„ä¸€èˆ¬å·¥ä½œæµç¨‹æ˜¯ï¼Œ
- en: build a week learner to predict \(Y\) from \(X_1,\ldots,X_m\), \(\hat{F}_k(X)\)
    from the training data \(x_{i,j}\).
  id: totrans-2023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªå¼±å­¦ä¹ å™¨æ¥ä» \(X_1,\ldots,X_m\) é¢„æµ‹ \(Y\)ï¼Œä»è®­ç»ƒæ•°æ® \(x_{i,j}\) ä¸­é¢„æµ‹ \(\hat{F}_k(X)\)ã€‚
- en: loop over number of desired estimators, \(k = 1,\ldots,K\)
  id: totrans-2024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éå†æ‰€éœ€ä¼°è®¡å™¨çš„æ•°é‡ï¼Œ\(k = 1,\ldots,K\)
- en: calculate the residuals at the training data, \(h_k(x_{i}) = y_i - \hat{F}_k(x_{i})\)
  id: totrans-2025
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—è®­ç»ƒæ•°æ®ä¸­çš„æ®‹å·®ï¼Œ\(h_k(x_{i}) = y_i - \hat{F}_k(x_{i})\)
- en: fit another week learner to predict \(h_k\) from \(X_1,\ldots,X_m\), \(\hat{F}_k(X)\)
    from the training data \(x_{i,j}\).
  id: totrans-2026
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å¦ä¸€ä¸ªå¼±å­¦ä¹ å™¨æ‹Ÿåˆåˆ°é¢„æµ‹ \(h_k\) ä» \(X_1,\ldots,X_m\)ï¼Œä»è®­ç»ƒæ•°æ® \(x_{i,j}\) ä¸­é¢„æµ‹ \(\hat{F}_k(X)\)ã€‚
- en: each model builds on the previous to improve the accuracy
  id: totrans-2027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹éƒ½æ˜¯åŸºäºå‰ä¸€ä¸ªæ¨¡å‹æ¥æé«˜å‡†ç¡®æ€§çš„
- en: The regression estimator is the summation over the \(K\) simple models,
  id: totrans-2028
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’ä¼°è®¡é‡æ˜¯å¯¹ \(K\) ä¸ªç®€å•æ¨¡å‹çš„æ±‚å’Œï¼Œ
- en: \[ \hat{Y} =\sum_{k=1}^{K} F_k(X_1,\ldots,X_m) \]
  id: totrans-2029
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} =\sum_{k=1}^{K} F_k(X_1,\ldots,X_m) \]
- en: '**Bootstrap**'
  id: totrans-2030
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è‡ªä¸¾**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): a statistical
    resampling procedure to calculate uncertainty in a calculated statistic from the
    sample data itself. Some general comments,'
  id: totrans-2031
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¢‹è£…æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šä¸€ç§ç»Ÿè®¡é‡é‡‡æ ·è¿‡ç¨‹ï¼Œç”¨äºä»æ ·æœ¬æ•°æ®æœ¬èº«è®¡ç®—è®¡ç®—ç»Ÿè®¡é‡ä¸­çš„ä¸ç¡®å®šæ€§ã€‚ä¸€äº›ä¸€èˆ¬æ€§è¯„è®ºï¼Œ'
- en: '*sampling with replacement* - \(n\) (number of data samples) *Monte Carlo simulation*s
    from the dataset *cumulative distribution function*, this results in a new realization
    of the data'
  id: totrans-2032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¸¦æ›¿æ¢çš„æŠ½æ ·* - ä»æ•°æ®é›†çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ä¸­è¿›è¡Œ \(n\)ï¼ˆæ•°æ®æ ·æœ¬æ•°ï¼‰*è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ*ï¼Œè¿™å¯¼è‡´æ•°æ®çš„æ–°å®ç°'
- en: '*simulates the data collection process* - the fundamental idea is to simulate
    the original data collection process. Instead of actually collecting new sample
    sets, we randomly select from the data to get data realizations'
  id: totrans-2033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨¡æ‹Ÿæ•°æ®æ”¶é›†è¿‡ç¨‹* - åŸºæœ¬æ€æƒ³æ˜¯æ¨¡æ‹ŸåŸå§‹æ•°æ®æ”¶é›†è¿‡ç¨‹ã€‚è€Œä¸æ˜¯å®é™…æ”¶é›†æ–°çš„æ ·æœ¬é›†ï¼Œæˆ‘ä»¬ä»æ•°æ®ä¸­éšæœºé€‰æ‹©ä»¥è·å–æ•°æ®å®ç°'
- en: '*bootstrap any statistic* - this approach is very flexible as we can calculate
    realizations of any statistics from the data realizations'
  id: totrans-2034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è‡ªä¸¾ä»»ä½•ç»Ÿè®¡é‡* - è¿™ç§æ–¹æ³•éå¸¸çµæ´»ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ä»æ•°æ®å®ç°ä¸­è®¡ç®—ä»»ä½•ç»Ÿè®¡é‡çš„å®ç°'
- en: '*computationally cheap* - repeat this approach to get realizations of the statistic
    to build a complete distribution of uncertainty. Use a large number of realizations,
    \(L\), for a reliable uncertainty model.'
  id: totrans-2035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—æˆæœ¬ä½* - é‡å¤æ­¤æ–¹æ³•ä»¥è·å–ç»Ÿè®¡é‡çš„å®ç°ï¼Œä»è€Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„ä¸ç¡®å®šæ€§åˆ†å¸ƒã€‚ä½¿ç”¨å¤§é‡å®ç°ï¼Œ\(L\)ï¼Œä»¥è·å¾—å¯é çš„ä¸ç¡®å®šæ€§æ¨¡å‹ã€‚'
- en: '*calculates the entire distribution of uncertainty* - for any statistic, you
    calculate any summary statistic for the uncertainty model, e.g., mean, P10 and
    P90 of the uncertainty in the mean'
  id: totrans-2036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—æ•´ä¸ªä¸ç¡®å®šæ€§çš„åˆ†å¸ƒ* - å¯¹äºä»»ä½•ç»Ÿè®¡é‡ï¼Œä½ è®¡ç®—ä¸ç¡®å®šæ€§æ¨¡å‹ä¸­çš„ä»»ä½•æ±‡æ€»ç»Ÿè®¡é‡ï¼Œä¾‹å¦‚ï¼Œå‡å€¼çš„P10å’ŒP90ã€‚'
- en: '*bagging for machine learning* - is the application of bootstrap to obtain
    data realizations to train predictive model realizations to aggregate predictions
    over ensembles of prediction models to reduce model variance'
  id: totrans-2037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœºå™¨å­¦ä¹ ä¸­çš„è¢‹è£…æ³•* - æ˜¯å°†è‡ªåŠ©æ³•åº”ç”¨äºè·å–æ•°æ®å®ç°ï¼Œä»¥è®­ç»ƒé¢„æµ‹æ¨¡å‹å®ç°ï¼Œå¯¹é¢„æµ‹æ¨¡å‹é›†åˆè¿›è¡Œèšåˆé¢„æµ‹ï¼Œä»¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚'
- en: What are the limitations of bootstrap?
  id: totrans-2038
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿ
- en: biased sample data will likely result in a biased bootstrapped uncertainty model,
    you must first debias the samples, e.g., *declustering*
  id: totrans-2039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®çš„æ ·æœ¬æ•°æ®å¯èƒ½å¯¼è‡´åå·®çš„è‡ªåŠ©ä¸ç¡®å®šæ€§æ¨¡å‹ï¼Œä½ å¿…é¡»é¦–å…ˆæ¶ˆé™¤åå·®ï¼Œä¾‹å¦‚ï¼Œ*è§£èš*ã€‚
- en: you must have a sufficient sample size
  id: totrans-2040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¿…é¡»æœ‰è¶³å¤Ÿçš„æ ·æœ¬é‡ã€‚
- en: integrates uncertainty due to sparse samples in space only
  id: totrans-2041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»…æ•´åˆç©ºé—´ä¸­ç¨€ç–æ ·æœ¬çš„ä¸ç¡®å®šæ€§ã€‚
- en: does not account for the spatial context of the data, i.e., sample data locations,
    volume of interest nor the spatial continuity. There is a variant of bootstrap
    called [spatial bootstrap](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Spatial_Bootstrap.ipynb).
  id: totrans-2042
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸è€ƒè™‘æ•°æ®çš„ç©ºé—´èƒŒæ™¯ï¼Œå³æ ·æœ¬æ•°æ®ä½ç½®ã€æ„Ÿå…´è¶£ä½“ç§¯æˆ–ç©ºé—´è¿ç»­æ€§ã€‚æœ‰ä¸€ç§åä¸º[ç©ºé—´è‡ªåŠ©æ³•](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Spatial_Bootstrap.ipynb)çš„è‡ªåŠ©æ³•å˜ä½“ã€‚
- en: '**Categorical Feature**'
  id: totrans-2043
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a feature that
    can only take one of a limited, and usually fixed, number of possible values'
  id: totrans-2044
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªåªèƒ½å–æœ‰é™ä¸”é€šå¸¸å›ºå®šæ•°é‡çš„å¯èƒ½å€¼çš„ç‰¹å¾ã€‚'
- en: '**Categorical Nominal Feature**'
  id: totrans-2045
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»åä¹‰ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *categorical*
    feature without any natural ordering, for example,'
  id: totrans-2046
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªæ²¡æœ‰è‡ªç„¶æ’åºçš„*åˆ†ç±»*ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: facies = {boundstone, wackystone, packstone, brecia}
  id: totrans-2047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç ‚å²© = {ç°å²©ï¼Œç¢å±‘å²©ï¼Œç ‚å±‘å²©ï¼Œæ³¥å²©}
- en: minerals = {quartz, feldspar, calcite}
  id: totrans-2048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çŸ¿ç‰© = {çŸ³è‹±ï¼Œé•¿çŸ³ï¼Œæ–¹è§£çŸ³}
- en: '**Categorical Ordinal Feature**'
  id: totrans-2049
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»æœ‰åºç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *categorical*
    feature with a natural ordering, for example,'
  id: totrans-2050
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªå…·æœ‰è‡ªç„¶æ’åºçš„*åˆ†ç±»*ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: geologic age = {Miocene, Pliocene, Pleistocene} - ordered from older to younger
    rock
  id: totrans-2051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°è´¨å¹´ä»£ = {ä¸­æ–°ä¸–ï¼Œä¸Šæ–°ä¸–ï¼Œæ›´æ–°ä¸–} - ä»è¾ƒè€çš„å²©çŸ³åˆ°è¾ƒæ–°çš„å²©çŸ³æ’åºã€‚
- en: Mohs hardness = \(\{1, 2, \ldots, 10\}\) - ordered from softer to harder rock
  id: totrans-2052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘©æ°ç¡¬åº¦ = \(\{1, 2, \ldots, 10\}\) - ä»è¾ƒè½¯åˆ°è¾ƒç¡¬çš„å²©çŸ³æ’åºã€‚
- en: '**Causation**'
  id: totrans-2053
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å› æœå…³ç³»**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): a relationship
    where a change in one or more feature(s) directly leads to a change in one or
    more other feature(s).'
  id: totrans-2054
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šä¸€ä¸ªå˜åŒ–ç›´æ¥å¯¼è‡´ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–ç‰¹å¾å˜åŒ–çš„å…³ç³»ã€‚'
- en: Some important aspects of causal relationships,
  id: totrans-2055
  prefs: []
  type: TYPE_NORMAL
  zh: å› æœå…³ç³»çš„ä¸€äº›é‡è¦æ–¹é¢ï¼Œ
- en: '*Asymmetry and temporal precedence* - \(A\) is caused by \(B\) does not indicate
    that \(B\) is caused by \(A\)'
  id: totrans-2056
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸å¯¹ç§°å’Œæ—¶é—´ä¼˜å…ˆ* - \(A\) ç”± \(B\) é€ æˆå¹¶ä¸æ„å‘³ç€ \(B\) ç”± \(A\) é€ æˆã€‚'
- en: '*Non-spurious* - not due to random effect or confounding features'
  id: totrans-2057
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*éè™šå‡* - ä¸æ˜¯ç”±äºéšæœºæ•ˆåº”æˆ–æ··æ‚ç‰¹å¾é€ æˆçš„ã€‚'
- en: '*Mechanism and explanation* - a plausible mechanism or process is available
    to explain the relationship'
  id: totrans-2058
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æœºåˆ¶å’Œè§£é‡Š* - æœ‰ä¸€ä¸ªåˆç†çš„æœºåˆ¶æˆ–è¿‡ç¨‹å¯ä»¥è§£é‡Šè¿™ç§å…³ç³»ã€‚'
- en: '*Consistency* - the relationship is observable over a range of conditions,
    times, locations, populations, etc.'
  id: totrans-2059
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸€è‡´æ€§* - è¿™ç§å…³ç³»åœ¨ä¸€ç³»åˆ—æ¡ä»¶ã€æ—¶é—´ã€åœ°ç‚¹ã€äººç¾¤ç­‰æƒ…å†µä¸‹éƒ½æ˜¯å¯è§‚å¯Ÿçš„ã€‚'
- en: '*Strength* - stronger relationships increase the likelihood of causation given
    all the previous 1-5 hold'
  id: totrans-2060
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¼ºåº¦* - æ›´å¼ºçš„å…³ç³»åœ¨æ‰€æœ‰å‰1-5ä¸ªæ¡ä»¶éƒ½æˆç«‹çš„æƒ…å†µä¸‹ï¼Œå¢åŠ äº†å› æœå…³ç³»çš„å¯èƒ½æ€§ã€‚'
- en: Establishing causation is very difficult,
  id: totrans-2061
  prefs: []
  type: TYPE_NORMAL
  zh: å»ºç«‹å› æœå…³ç³»éå¸¸å›°éš¾ï¼Œ
- en: in this course we typically avoid causation and causal analysis, and emphasize
    this with statements such as correlation does not imply causation
  id: totrans-2062
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸é¿å…å› æœå…³ç³»å’Œå› æœåˆ†æï¼Œå¹¶é€šè¿‡è¯¸å¦‚â€œç›¸å…³æ€§ä¸æ„å‘³ç€å› æœå…³ç³»â€ä¹‹ç±»çš„é™ˆè¿°æ¥å¼ºè°ƒè¿™ä¸€ç‚¹ã€‚
- en: '**Cell-based Declustering**'
  id: totrans-2063
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºç»†èƒçš„è§£èš**'
- en: 'Data Preparation: a declustering method to assign weights to spatial samples
    based on local sampling density, such that the weighted statistics are likely
    more representative of the population. Data weights are assigned such that,'
  id: totrans-2064
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§å°†æƒé‡åˆ†é…ç»™ç©ºé—´æ ·æœ¬çš„è§£èšæ–¹æ³•ï¼ŒåŸºäºå±€éƒ¨é‡‡æ ·å¯†åº¦ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚ä¸‹ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-2065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¯†é›†é‡‡æ ·åŒºåŸŸé‡‡æ ·çš„æ ·æœ¬æƒé‡è¾ƒå°ã€‚
- en: samples in sparsely sampled areas receive more weight
  id: totrans-2066
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨€ç–é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬è·å¾—æ›´å¤šæƒé‡ã€‚
- en: The goal of declustering is for the sample statistics to be independent of sample
    locations, e.g., infill drilling or blast hole samples should not change the statistics
    for the area of interest due to increased local sample density.
  id: totrans-2067
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç°‡æ¶ˆé™¤çš„ç›®æ ‡æ˜¯ä½¿æ ·æœ¬ç»Ÿè®¡é‡ç‹¬ç«‹äºæ ·æœ¬ä½ç½®ï¼Œä¾‹å¦‚ï¼Œè¡¥å……é’»æ¢æˆ–çˆ†ç ´å­”æ ·æœ¬ä¸åº”å› å±€éƒ¨æ ·æœ¬å¯†åº¦å¢åŠ è€Œæ”¹å˜æ„Ÿå…´è¶£åŒºåŸŸçš„ç»Ÿè®¡é‡ã€‚
- en: 'Cell-based declustering proceeds as follows:'
  id: totrans-2068
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºå•å…ƒæ ¼çš„åˆ†ç°‡æ¶ˆé™¤è¿‡ç¨‹å¦‚ä¸‹ï¼š
- en: a cell mesh is placed over the spatial data and weights are set as proportional
    to the inverse of the number of samples in the cell
  id: totrans-2069
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ç©ºé—´æ•°æ®ä¸Šæ”¾ç½®å•å…ƒæ ¼ç½‘æ ¼ï¼Œå¹¶å°†æƒé‡è®¾ç½®ä¸ºä¸å•å…ƒæ ¼ä¸­æ ·æœ¬æ•°é‡çš„å€’æ•°æˆæ¯”ä¾‹ã€‚
- en: the cell mesh size is varied, and the cell size that minimizes the declustered
    mean (in the sample mean is biased high) or maximizes the declustered mean (if
    the sample mean is biased low) is selected
  id: totrans-2070
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å•å…ƒç½‘æ ¼å¤§å°æœ‰æ‰€å˜åŒ–ï¼Œé€‰æ‹©æœ€å°åŒ–åˆ†ç°‡åå‡å€¼ï¼ˆæ ·æœ¬å‡å€¼åé«˜ï¼‰æˆ–æœ€å¤§åŒ–åˆ†ç°‡åå‡å€¼ï¼ˆå¦‚æœæ ·æœ¬å‡å€¼åä½ï¼‰çš„å•å…ƒæ ¼å¤§å°ã€‚
- en: to remove the impact of cell mesh position, the cell mesh is randomly moved
    several times and the resulting declustering weights are averaged for each datum
  id: totrans-2071
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¶ˆé™¤å•å…ƒæ ¼ç½‘æ ¼ä½ç½®çš„å½±å“ï¼Œå•å…ƒæ ¼ç½‘æ ¼è¢«éšæœºç§»åŠ¨å‡ æ¬¡ï¼Œå¹¶å¯¹æ¯ä¸ªæ•°æ®ç‚¹å¹³å‡å¾—åˆ°çš„åˆ†ç°‡æ¶ˆé™¤æƒé‡ã€‚
- en: 'The weights are calculated as:'
  id: totrans-2072
  prefs: []
  type: TYPE_NORMAL
  zh: æƒé‡è®¡ç®—å¦‚ä¸‹ï¼š
- en: \[ w(\bf{u}_j) = \frac{1}{n_l} \cdot \frac{n}{L_o} \]
  id: totrans-2073
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w(\bf{u}_j) = \frac{1}{n_l} \cdot \frac{n}{L_o} \]
- en: where \(n_l\) is the number of data in the current cell, \(L_o\) is the number
    of cells with data, and \(n\) is the total number of data.
  id: totrans-2074
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(n_l\) æ˜¯å½“å‰å•å…ƒæ ¼ä¸­çš„æ•°æ®é‡ï¼Œ\(L_o\) æ˜¯æœ‰æ•°æ®çš„å•å…ƒæ ¼æ•°é‡ï¼Œ\(n\) æ˜¯æ•°æ®æ€»æ•°ã€‚
- en: Here are some highlights for cell-based declustering,
  id: totrans-2075
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å…³äºåŸºäºå•å…ƒæ ¼çš„åˆ†ç°‡æ¶ˆé™¤çš„ä¸€äº›äº®ç‚¹ï¼Œ
- en: expert judgement to assign cell size based on the nominal sample spacing (e.g.,
    data spacing before infill drilling) will improve the performance over the automated
    method for cell size selection based on minimum or maximum declustered mean (mentioned
    above)
  id: totrans-2076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®åä¹‰æ ·æœ¬é—´è·ï¼ˆä¾‹å¦‚ï¼Œè¡¥å……é’»æ¢å‰çš„æ•°æ®é—´è·ï¼‰åˆ†é…å•å…ƒæ ¼å¤§å°ï¼Œä¸åŸºäºæœ€å°æˆ–æœ€å¤§åˆ†ç°‡å‡å€¼çš„è‡ªåŠ¨åŒ–å•å…ƒæ ¼å¤§å°é€‰æ‹©æ–¹æ³•ï¼ˆå¦‚ä¸Šæ‰€è¿°ï¼‰ç›¸æ¯”ï¼Œå°†æé«˜æ€§èƒ½ã€‚
- en: cell-based declustering is not aware of the boundaries of the area of interest;
    therefore, data near the boundary of the area of interest may appear to be more
    sparsely sampled and receive more weight
  id: totrans-2077
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºå•å…ƒæ ¼çš„åˆ†ç°‡æ¶ˆé™¤ä¸äº†è§£æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œï¼›å› æ­¤ï¼Œé è¿‘æ„Ÿå…´è¶£åŒºåŸŸè¾¹ç•Œçš„é™„è¿‘æ•°æ®å¯èƒ½çœ‹èµ·æ¥é‡‡æ ·æ›´ç¨€ç–ï¼Œå¹¶è·å¾—æ›´å¤šæƒé‡ã€‚
- en: cell-based was developed by Professor Andre Journel in 1983, []
  id: totrans-2078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºå•å…ƒæ ¼çš„æ–¹æ³•æ˜¯ç”±å®‰å¾·çƒˆÂ·çº¦å°¼å°”æ•™æˆäº1983å¹´å¼€å‘çš„ï¼Œ[]
- en: '**Cognitive Biases**'
  id: totrans-2079
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®¤çŸ¥åå·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): an automated (subconscious)
    thought process used by human brain to simplify information processing from large
    amount of personal experience and learned preferences. While these have been critical
    for our evolution and survival on this planet, they can lead to the following
    issues in data science:'
  id: totrans-2080
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šäººç±»å¤§è„‘ç”¨æ¥ç®€åŒ–ä»å¤§é‡ä¸ªäººç»éªŒå’Œå­¦ä¹ åå¥½ä¸­è·å–çš„ä¿¡æ¯çš„è‡ªåŠ¨åŒ–ï¼ˆæ½œæ„è¯†ï¼‰æ€ç»´è¿‡ç¨‹ã€‚è™½ç„¶è¿™äº›å¯¹äºæˆ‘ä»¬åœ¨åœ°çƒä¸Šçš„è¿›åŒ–å’Œç”Ÿå­˜è‡³å…³é‡è¦ï¼Œä½†å®ƒä»¬å¯èƒ½å¯¼è‡´æ•°æ®ç§‘å­¦ä¸­çš„ä»¥ä¸‹é—®é¢˜ï¼š'
- en: '*Anchoring Bias*, too much emphasis on the first piece of information. Studies
    have shown that the first piece of information could be irrelevant as we are beginning
    to learn about a topic, and often the earliest data in a project has the largest
    uncertainty. Address anchoring bias by curating all data, integrating uncertainty,
    fostering open discussion and debate on your project team.'
  id: totrans-2081
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*é”šå®šåå·®*ï¼Œè¿‡åˆ†å¼ºè°ƒç¬¬ä¸€æ¡ä¿¡æ¯ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå½“æˆ‘ä»¬åˆšå¼€å§‹äº†è§£ä¸€ä¸ªä¸»é¢˜æ—¶ï¼Œç¬¬ä¸€æ¡ä¿¡æ¯å¯èƒ½æ˜¯ä¸ç›¸å…³çš„ï¼Œè€Œä¸”é¡¹ç›®ä¸­æœ€æ—©çš„æ•°æ®å¾€å¾€å…·æœ‰æœ€å¤§çš„ä¸ç¡®å®šæ€§ã€‚é€šè¿‡æ•´ç†æ‰€æœ‰æ•°æ®ï¼Œæ•´åˆä¸ç¡®å®šæ€§ï¼Œä¿ƒè¿›é¡¹ç›®å›¢é˜Ÿä¸­çš„å¼€æ”¾è®¨è®ºå’Œè¾©è®ºï¼Œæ¥åº”å¯¹é”šå®šåå·®ã€‚'
- en: '*Availability Heuristic*, overestimate importance of easily available information,
    for example, grandfather smoked 3 packs a day and lived to 100 years old, i.e.,
    relying on anecdotes. Address availability heuristic by ensuring the project team
    documents all available information and applies quantitative analysis to move
    beyond anecdotes.'
  id: totrans-2082
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¯ç”¨æ€§å¯å‘å¼*ï¼Œé«˜ä¼°æ˜“äºè·å–ä¿¡æ¯çš„ä»·å€¼ï¼Œä¾‹å¦‚ï¼Œç¥–çˆ¶æ¯å¤©æŠ½3åŒ…çƒŸï¼Œå´æ´»åˆ°100å²ï¼Œå³ä¾èµ–äºè½¶äº‹ã€‚é€šè¿‡ç¡®ä¿é¡¹ç›®å›¢é˜Ÿè®°å½•æ‰€æœ‰å¯ç”¨ä¿¡æ¯å¹¶åº”ç”¨å®šé‡åˆ†ææ¥è¶…è¶Šè½¶äº‹ï¼Œæ¥åº”å¯¹å¯ç”¨æ€§å¯å‘å¼ã€‚'
- en: '*Bandwagon Effect*, assessed probability increases with the number of people
    holding the same belief. Watch out for everyone jumping on board or the loudest
    voice influencing all others on your project teams. Encouraging all members of
    the project team to contribute and even separate meetings may be helpful to address
    bandwagon effect.'
  id: totrans-2083
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä»ä¼—æ•ˆåº”*ï¼Œè¯„ä¼°æ¦‚ç‡éšç€æŒæœ‰ç›¸åŒä¿¡å¿µçš„äººæ•°å¢åŠ è€Œå¢åŠ ã€‚æ³¨æ„ä½ çš„é¡¹ç›®å›¢é˜Ÿä¸­æ¯ä¸ªäººéƒ½è·³ä¸ŠåŒä¸€è‰˜èˆ¹æˆ–æœ€å“äº®çš„å£°éŸ³å½±å“æ‰€æœ‰å…¶ä»–äººã€‚é¼“åŠ±é¡¹ç›®å›¢é˜Ÿçš„æ‰€æœ‰æˆå‘˜è´¡çŒ®ï¼Œç”šè‡³å•ç‹¬çš„ä¼šè®®å¯èƒ½æœ‰åŠ©äºè§£å†³ä»ä¼—æ•ˆåº”ã€‚'
- en: '*Blind-spot Effect*, fail to see your own cognitive biases. This is the hardest
    cognitive bias of all. One possible solution is to invite arms length review of
    your project teamâ€™s methods, results and decisions.'
  id: totrans-2084
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç›²ç‚¹æ•ˆåº”*ï¼Œæœªèƒ½çœ‹åˆ°è‡ªå·±çš„è®¤çŸ¥åå·®ã€‚è¿™æ˜¯æ‰€æœ‰è®¤çŸ¥åå·®ä¸­æœ€éš¾çš„ä¸€ä¸ªã€‚ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆæ˜¯é‚€è¯·å¯¹é¡¹ç›®å›¢é˜Ÿçš„æ–¹æ³•ã€ç»“æœå’Œå†³ç­–è¿›è¡Œè¿œç¨‹å®¡æŸ¥ã€‚'
- en: '*Choice-supportive Bias*, probability increases after a commitment, i.e., a
    decision is made. For example, it was good that I bought that car supported by
    focusing on positive information about the car. This is a specific case of confirmation
    bias.'
  id: totrans-2085
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*é€‰æ‹©æ”¯æŒåå·®*ï¼Œåœ¨åšå‡ºæ‰¿è¯ºåæ¦‚ç‡å¢åŠ ï¼Œå³ï¼Œåšå‡ºå†³å®šã€‚ä¾‹å¦‚ï¼Œæˆ‘è´­ä¹°é‚£è¾†è½¦çš„å†³å®šé€šè¿‡å…³æ³¨å…³äºæ±½è½¦çš„æ­£ä¿¡æ¯æ˜¯å¥½çš„ã€‚è¿™æ˜¯ç¡®è®¤åå·®çš„ä¸€ä¸ªç‰¹ä¾‹ã€‚'
- en: '*Clustering Illusion*, seeing patterns in random events. Yes, this heuristic
    helped us stay alive when large predictors hunted us, i.e., false positives are
    much better than false negatives! The solution is to model uncertainty confidence
    intervals and test all data and results against random effect.'
  id: totrans-2086
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*èšç±»é”™è§‰*ï¼Œåœ¨éšæœºäº‹ä»¶ä¸­çœ‹åˆ°æ¨¡å¼ã€‚æ˜¯çš„ï¼Œè¿™ä¸ªå¯å‘å¼æ–¹æ³•åœ¨æˆ‘ä»¬è¢«å¤§å‹é¢„æµ‹è€…è¿½æ•æ—¶å¸®åŠ©æˆ‘ä»¬ç”Ÿå­˜ä¸‹æ¥ï¼Œå³ï¼Œå‡é˜³æ€§æ¯”å‡é˜´æ€§è¦å¥½å¾—å¤šï¼è§£å†³æ–¹æ¡ˆæ˜¯å»ºç«‹ä¸ç¡®å®šæ€§ç½®ä¿¡åŒºé—´ï¼Œå¹¶æµ‹è¯•æ‰€æœ‰æ•°æ®å’Œç»“æœä»¥å¯¹æŠ—éšæœºæ•ˆåº”ã€‚'
- en: '*Confirmation Bias*, only consider new information that supports current model.
    Choice-supportive bias is a specific case of confirmation bias. The solution to
    confirmation bias is to seek out people that you will likely disagree with and
    build skilled project teams that hold diverse technical opinions and have different
    expert experience. My approach is to get nervous if everyone in the room agrees
    with me!'
  id: totrans-2087
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç¡®è®¤åå·®*ï¼Œåªè€ƒè™‘æ”¯æŒå½“å‰æ¨¡å‹çš„æ–°ä¿¡æ¯ã€‚é€‰æ‹©æ”¯æŒåå·®æ˜¯ç¡®è®¤åå·®çš„ä¸€ä¸ªç‰¹ä¾‹ã€‚è§£å†³ç¡®è®¤åå·®çš„æ–¹æ³•æ˜¯å¯»æ‰¾ä½ å¯èƒ½ä¼šä¸åŒæ„çš„äººï¼Œå¹¶ç»„å»ºå…·æœ‰ä¸åŒæŠ€æœ¯è§‚ç‚¹å’Œä¸åŒä¸“å®¶ç»éªŒçš„ç†Ÿç»ƒé¡¹ç›®å›¢é˜Ÿã€‚æˆ‘çš„æ–¹æ³•æ˜¯å¦‚æœæˆ¿é—´é‡Œæ¯ä¸ªäººéƒ½åŒæ„æˆ‘ï¼Œæˆ‘ä¼šæ„Ÿåˆ°ç´§å¼ ï¼'
- en: '*Conservatism Bias*, favor old data to newly collected data. Data curation
    and quantitative analysis are helpful.'
  id: totrans-2088
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¿å®ˆåå·®*ï¼Œå€¾å‘äºæ—§æ•°æ®è€Œä¸æ˜¯æ–°æ”¶é›†çš„æ•°æ®ã€‚æ•°æ®ç®¡ç†å’Œå®šé‡åˆ†ææ˜¯æœ‰å¸®åŠ©çš„ã€‚'
- en: '*Recency Bias*, favor the most recently collected data. Ensure your team documents
    previous data and choices to enhance team memory. Just like conservative bias,
    data curation and quantitative analysis are our first line of defense.'
  id: totrans-2089
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è¿‘æœŸåå·®*ï¼Œå€¾å‘äºæœ€è¿‘æ”¶é›†çš„æ•°æ®ã€‚ç¡®ä¿ä½ çš„å›¢é˜Ÿè®°å½•ä»¥å‰çš„æ•°æ®å’Œé€‰æ‹©ï¼Œä»¥å¢å¼ºå›¢é˜Ÿè®°å¿†ã€‚å°±åƒä¿å®ˆåå·®ä¸€æ ·ï¼Œæ•°æ®ç®¡ç†å’Œå®šé‡åˆ†ææ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€é“é˜²çº¿ã€‚'
- en: '*Survivorship Bias*, focus on success cases only. Check for any possible pre-selection
    or filters on the data available to your team.'
  id: totrans-2090
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¹¸å­˜è€…åå·®*ï¼Œåªå…³æ³¨æˆåŠŸæ¡ˆä¾‹ã€‚æ£€æŸ¥å›¢é˜Ÿå¯ç”¨çš„æ•°æ®ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•å¯èƒ½çš„é¢„é€‰æˆ–ç­›é€‰ã€‚'
- en: Robust use of statistics / data analytics protects use from bias.
  id: totrans-2091
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆåœ°ä½¿ç”¨ç»Ÿè®¡å­¦/æ•°æ®åˆ†æå¯ä»¥ä¿æŠ¤æˆ‘ä»¬å…å—åå·®çš„å½±å“ã€‚
- en: '**Complimentary Events** (probability)'
  id: totrans-2092
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº’è¡¥äº‹ä»¶**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the NOT operator
    for probability, if we define A then A compliment, \(A^c\), is not A and we have
    this resulting closure relationship,'
  id: totrans-2093
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šæ¦‚ç‡çš„NOTè¿ç®—ç¬¦ï¼Œå¦‚æœæˆ‘ä»¬å®šä¹‰Aï¼Œé‚£ä¹ˆAçš„è¡¥é›†ï¼Œ\(A^c\)ï¼Œä¸æ˜¯Aï¼Œå¹¶ä¸”æˆ‘ä»¬å¾—åˆ°è¿™ä¸ªç»“æœé—­åŒ…å…³ç³»ï¼Œ'
- en: \[ P(A) + P(A^c) = 1.0 \]
  id: totrans-2094
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) + P(A^c) = 1.0 \]
- en: complimentary events may be considered for beyond univariate problems, for example
    consider this bivariate closure,
  id: totrans-2095
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šå…ƒé—®é¢˜ä¹‹å¤–ï¼Œå¯ä»¥è€ƒè™‘äº’è¡¥äº‹ä»¶ï¼Œä¾‹å¦‚è€ƒè™‘è¿™ä¸ªäºŒå…ƒé—­åŒ…ï¼Œ
- en: \[ P(A|B) + P(A^c|B) = 1.0 \]
  id: totrans-2096
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) + P(A^c|B) = 1.0 \]
- en: Note, the given term must be the same.
  id: totrans-2097
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç»™å®šçš„æœ¯è¯­å¿…é¡»ç›¸åŒã€‚
- en: '**Computational Complexity**'
  id: totrans-2098
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®¡ç®—å¤æ‚æ€§**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): represents the
    computer resources for a method, we use it in machine learning to understand how
    our machine learning methods scale as we change the dimensionality, number of
    features, and the number of training data, represented by,'
  id: totrans-2099
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šè¡¨ç¤ºæ–¹æ³•æ‰€éœ€çš„è®¡ç®—æœºèµ„æºï¼Œæˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨å®ƒæ¥ç†è§£å½“æ”¹å˜ç»´åº¦ã€ç‰¹å¾æ•°é‡å’Œè®­ç»ƒæ•°æ®æ•°é‡æ—¶ï¼Œæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ–¹æ³•å¦‚ä½•æ‰©å±•ï¼Œè¡¨ç¤ºä¸ºï¼Œ'
- en: \[ ğ‘‚(ğ‘“(ğ‘›)) \]
  id: totrans-2100
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘‚(ğ‘“(ğ‘›)) \]
- en: where \(ğ‘›\) represents size of the problem. There are 2 components of computational
    complexity,
  id: totrans-2101
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(ğ‘›\) ä»£è¡¨é—®é¢˜çš„å¤§å°ã€‚è®¡ç®—å¤æ‚æ€§æœ‰ä¸¤ä¸ªç»„æˆéƒ¨åˆ†ï¼Œ
- en: '*time complexity* - refers to computational time and the scaling of this time
    to the size of the problem for a given algorithm'
  id: totrans-2102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ—¶é—´å¤æ‚åº¦* - æŒ‡çš„æ˜¯è®¡ç®—æ—¶é—´ä»¥åŠç»™å®šç®—æ³•çš„æ—¶é—´å¤æ‚åº¦éšé—®é¢˜è§„æ¨¡çš„å˜åŒ–'
- en: '*space complexity* - refers to computer memory required and the scaling of
    storage to the size of the problem for a given algorithm'
  id: totrans-2103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©ºé—´å¤æ‚åº¦* - æŒ‡çš„æ˜¯è®¡ç®—æœºå†…å­˜éœ€æ±‚ä»¥åŠç»™å®šç®—æ³•çš„å­˜å‚¨éšé—®é¢˜è§„æ¨¡çš„å˜åŒ–'
- en: For example, if time complexity is \(O(n^3)\), where is \(n\) is number of training
    data, then if we double the number of data the run time increases eight times.
  id: totrans-2104
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæ—¶é—´å¤æ‚åº¦æ˜¯ \(O(n^3)\)ï¼Œå…¶ä¸­ \(n\) æ˜¯è®­ç»ƒæ•°æ®æ•°é‡ï¼Œé‚£ä¹ˆå¦‚æœæˆ‘ä»¬åŠ å€æ•°æ®æ•°é‡ï¼Œè¿è¡Œæ—¶é—´å°†å¢åŠ å…«å€ã€‚
- en: Additional salient points about computational complexity,
  id: totrans-2105
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºè®¡ç®—å¤æ‚åº¦çš„å…¶ä»–æ˜¾è‘—ç‚¹ï¼Œ
- en: '*default to worst-case complexity* - the worst case for complexity given a
    specific problem size, provides an upper bound'
  id: totrans-2106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é»˜è®¤ä¸ºæœ€åæƒ…å†µå¤æ‚åº¦* - å¯¹äºç‰¹å®šé—®é¢˜è§„æ¨¡çš„æœ€åæƒ…å†µå¤æ‚åº¦ï¼Œæä¾›äº†ä¸€ä¸ªä¸Šé™'
- en: '*asymptotic complexity* - where \(ğ‘›\) is large. Some algorithms have speed-up
    for small datasets, this is not used'
  id: totrans-2107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¸è¿‘å¤æ‚åº¦* - å…¶ä¸­ \(ğ‘›\) å¾ˆå¤§ã€‚ä¸€äº›ç®—æ³•å¯¹äºå°æ•°æ®é›†æœ‰åŠ é€Ÿï¼Œè¿™ä¸è¢«ä½¿ç”¨'
- en: assumes all steps are required, e.g., data is not presorted, etc.
  id: totrans-2108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡è®¾æ‰€æœ‰æ­¥éª¤éƒ½æ˜¯å¿…éœ€çš„ï¼Œä¾‹å¦‚ï¼Œæ•°æ®æœªé¢„å…ˆæ’åºç­‰ã€‚
- en: Time complexity examples,
  id: totrans-2109
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´å¤æ‚åº¦ç¤ºä¾‹ï¼Œ
- en: '*quadratic time*, \(ğ‘¶(ğ’^ğŸ)\) - for example, integer multiplication, bubble
    sort'
  id: totrans-2110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*äºŒæ¬¡æ—¶é—´*, \(ğ‘¶(ğ’^ğŸ)\) - ä¾‹å¦‚ï¼Œæ•´æ•°ä¹˜æ³•ï¼Œå†’æ³¡æ’åº'
- en: '*linear time*, \(ğ‘¶(ğ’)\) - for example, finding the min or max in an unsorted
    array'
  id: totrans-2111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*çº¿æ€§æ—¶é—´*, \(ğ‘¶(ğ’)\) - ä¾‹å¦‚ï¼Œåœ¨æœªæ’åºçš„æ•°ç»„ä¸­æŸ¥æ‰¾æœ€å°å€¼æˆ–æœ€å¤§å€¼'
- en: '*fractional power*, \(ğ‘¶(ğ’^ğ’„ )\) - where \([0 < c < 1]\), for example, searching
    in a kd-tree, \(ğ‘‚(ğ‘›^(\frac{1}{2}))\)'
  id: totrans-2112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ†æ•°å¹‚*, \(ğ‘¶(ğ’^ğ’„ )\) - å…¶ä¸­ \([0 < c < 1]\)ï¼Œä¾‹å¦‚ï¼Œåœ¨kdæ ‘ä¸­æœç´¢ï¼Œ\(ğ‘‚(ğ‘›^(\frac{1}{2}))\)'
- en: '*exponential Time*, \(ğ‘¶(ğŸ^ğ’)\) - for example, traveling salesman problem with
    dynamic programing'
  id: totrans-2113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æŒ‡æ•°æ—¶é—´*, \(ğ‘¶(ğŸ^ğ’)\) - ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’çš„æ—…è¡Œå•†é—®é¢˜'
- en: '**Conditional Probability**'
  id: totrans-2114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¡ä»¶æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): the probability of
    an event, given another event has occurred,'
  id: totrans-2115
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåœ¨å¦ä¸€ä¸ªäº‹ä»¶å·²ç»å‘ç”Ÿçš„æƒ…å†µä¸‹ï¼Œäº‹ä»¶çš„æ¦‚ç‡ï¼Œ'
- en: \[ P(A|B) = \frac{P(A,B)}{P(A)} \]
  id: totrans-2116
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = \frac{P(A,B)}{P(A)} \]
- en: we read this as the probability of A given B has occurred as the joint divided
    by the marginal. We can extend conditional probabilities to any multivariate case
    by adding joints to either component. For example,
  id: totrans-2117
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å…¶è¯»ä½œåœ¨Bå‘ç”Ÿçš„æƒ…å†µä¸‹Aå‘ç”Ÿçš„æ¦‚ç‡ï¼Œå³è”åˆæ¦‚ç‡é™¤ä»¥è¾¹ç¼˜æ¦‚ç‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘ä»»ä¸€ç»„ä»¶æ·»åŠ è”åˆæ¥æ‰©å±•æ¡ä»¶æ¦‚ç‡åˆ°ä»»ä½•å¤šå…ƒæƒ…å†µã€‚ä¾‹å¦‚ï¼Œ
- en: \[ P(C|B,A) = \frac{P(A,B,C)}{P(B,C)} \]
  id: totrans-2118
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C|B,A) = \frac{P(A,B,C)}{P(B,C)} \]
- en: '**Confidence Interval**'
  id: totrans-2119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç½®ä¿¡åŒºé—´**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): the uncertainty
    in a summary statistic or model parameter represented as a range, lower and upper
    bound, based on a specified probability interval known as the confidence level.'
  id: totrans-2120
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šè¡¨ç¤ºä¸ºèŒƒå›´ã€ä¸‹é™å’Œä¸Šé™çš„æ±‡æ€»ç»Ÿè®¡é‡æˆ–æ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§ï¼ŒåŸºäºæŒ‡å®šçš„æ¦‚ç‡åŒºé—´ï¼Œç§°ä¸ºç½®ä¿¡æ°´å¹³ã€‚'
- en: We communicate confidence intervals like this,
  id: totrans-2121
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿™æ ·ä¼ è¾¾ç½®ä¿¡åŒºé—´ï¼Œ
- en: there is a 95% probability (or 19 times out of 20) that model slope is between
    0.5 and 0.7.
  id: totrans-2122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰95%çš„æ¦‚ç‡ï¼ˆæˆ–20æ¬¡ä¸­çš„19æ¬¡ï¼‰è¡¨æ˜æ¨¡å‹æ–œç‡åœ¨0.5å’Œ0.7ä¹‹é—´ã€‚
- en: Other salient points about confidence intervals,
  id: totrans-2123
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºç½®ä¿¡åŒºé—´çš„å…¶ä»–æ˜¾è‘—ç‚¹ï¼Œ
- en: calculated by analytical methods, when available, or with more general and flexible
    bootstrap
  id: totrans-2124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æœ‰å¯ç”¨æ—¶ï¼Œé€šè¿‡åˆ†ææ–¹æ³•è®¡ç®—ï¼Œæˆ–è€…ä½¿ç”¨æ›´é€šç”¨å’Œçµæ´»çš„bootstrapæ–¹æ³•
- en: for Bayesian methods we refer credibility intervals
  id: totrans-2125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè´å¶æ–¯æ–¹æ³•ï¼Œæˆ‘ä»¬å‚è€ƒå¯ä¿¡åº¦åŒºé—´
- en: '**Confusion Matrix**'
  id: totrans-2126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ··æ·†çŸ©é˜µ**'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a matrix with frequencies
    of predicted (x axis) vs. actual (y axis) categories to visualize the performance
    of a classification model.'
  id: totrans-2127
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ä¸ªçŸ©é˜µï¼Œè¡¨ç¤ºé¢„æµ‹ï¼ˆxè½´ï¼‰ä¸å®é™…ï¼ˆyè½´ï¼‰ç±»åˆ«é¢‘ç‡ï¼Œä»¥å¯è§†åŒ–åˆ†ç±»æ¨¡å‹çš„æ€§èƒ½ã€‚'
- en: visualize and diagnose all the combinations of correct and misclassification
    with the classification model, for example, category 1 is often misclassified
    as category 3.
  id: totrans-2128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ†ç±»æ¨¡å‹å¯è§†åŒ–å¹¶è¯Šæ–­æ‰€æœ‰æ­£ç¡®å’Œé”™è¯¯åˆ†ç±»çš„ç»„åˆï¼Œä¾‹å¦‚ï¼Œç±»åˆ«1ç»å¸¸è¢«é”™è¯¯åˆ†ç±»ä¸ºç±»åˆ«3ã€‚
- en: perfect accuracy is number of each class on the diagonal, category 1 is always
    predicted as category 1, etc.
  id: totrans-2129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®Œç¾å‡†ç¡®åº¦æ˜¯æ¯ä¸ªç±»åˆ«åœ¨å¯¹è§’çº¿ä¸Šçš„æ•°é‡ï¼Œç±»åˆ«1æ€»æ˜¯é¢„æµ‹ä¸ºç±»åˆ«1ï¼Œç­‰ç­‰ã€‚
- en: the classification matrix is applied to calculate a single summary of categorical
    accuracy, for example, precision, recall, etc.
  id: totrans-2130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»çŸ©é˜µç”¨äºè®¡ç®—åˆ†ç±»å‡†ç¡®æ€§çš„å•ä¸ªæ€»ç»“ï¼Œä¾‹å¦‚ï¼Œç²¾ç¡®åº¦ã€å¬å›ç‡ç­‰ã€‚
- en: '**Continuous Feature**'
  id: totrans-2131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a feature that
    can take any value between a lower and upper bound. For example,'
  id: totrans-2132
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªå¯ä»¥å–ä»‹äºä¸‹é™å’Œä¸Šé™ä¹‹é—´ä»»ä½•å€¼çš„ç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œ'
- en: porosity = \(\{13.01\%, 5.23\%, 24.62\%\}\)
  id: totrans-2133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ = \(\{13.01\%, 5.23\%, 24.62\%\}\)
- en: gold grade = \(\{4.56 \text{ g/t}, 8.72 \text{ g/t}, 12.45 \text{ g/t} \}\)
  id: totrans-2134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡‘å“ä½ = \(\{4.56 \text{ g/t}, 8.72 \text{ g/t}, 12.45 \text{ g/t} \}\)
- en: '**Continuous, Interval Feature**'
  id: totrans-2135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­ï¼ŒåŒºé—´ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *continuous feature*
    where the intervals between numbers are equal, for example, the difference between
    1.50 and 2.50 is the same as the difference between 2.50 and 3.50, but the actual
    values do not have an objective, physical reality (exist on an arbitrary scale),
    i.e., do not have a true zero point, for example,'
  id: totrans-2136
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ª *è¿ç»­ç‰¹å¾*ï¼Œå…¶ä¸­æ•°å­—ä¹‹é—´çš„é—´éš”ç›¸ç­‰ï¼Œä¾‹å¦‚ï¼Œ1.50 å’Œ 2.50
    ä¹‹é—´çš„å·®å€¼ä¸ 2.50 å’Œ 3.50 ä¹‹é—´çš„å·®å€¼ç›¸åŒï¼Œä½†å®é™…æ•°å€¼æ²¡æœ‰å®¢è§‚çš„ç‰©ç†ç°å®æ€§ï¼ˆå­˜åœ¨äºä¸€ä¸ªä»»æ„å°ºåº¦ä¸Šï¼‰ï¼Œå³ï¼Œæ²¡æœ‰çœŸå®çš„é›¶ç‚¹ï¼Œä¾‹å¦‚ï¼Œ'
- en: Celsius scale of temperature (an arbitrary scale based on water freezing at
    0 and boiling at 100)
  id: totrans-2137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘„æ°æ¸©åº¦å°ºåº¦ï¼ˆåŸºäºæ°´åœ¨ 0 åº¦ç»“å†°å’Œåœ¨ 100 åº¦æ²¸è…¾çš„ä»»æ„å°ºåº¦ï¼‰
- en: calendar year (there is no true zero year)
  id: totrans-2138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ—¥å†å¹´ä»½ï¼ˆæ²¡æœ‰çœŸæ­£çš„é›¶å¹´ï¼‰
- en: We can use addition and subtraction operations to compare continuous, interval
    features.
  id: totrans-2139
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ æ³•å’Œå‡æ³•è¿ç®—æ¥æ¯”è¾ƒè¿ç»­çš„åŒºé—´ç‰¹å¾ã€‚
- en: '**Continuous, Ratio Feature**'
  id: totrans-2140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­ï¼Œæ¯”ç‡ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *continuous feature*
    where the intervals between numbers are equal, for example, the difference between
    1.50 and 2.50 is the same as the difference between 2.50 and 3.50, but the values
    do have an objective reality (measure an actual physical phenomenon), i.e., do
    have true zero point, for example,'
  id: totrans-2141
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ª *è¿ç»­ç‰¹å¾*ï¼Œå…¶ä¸­æ•°å­—ä¹‹é—´çš„é—´éš”ç›¸ç­‰ï¼Œä¾‹å¦‚ï¼Œ1.50 å’Œ 2.50
    ä¹‹é—´çš„å·®å€¼ä¸ 2.50 å’Œ 3.50 ä¹‹é—´çš„å·®å€¼ç›¸åŒï¼Œä½†æ•°å€¼ç¡®å®å…·æœ‰å®¢è§‚ç°å®æ€§ï¼ˆè¡¡é‡å®é™…ç‰©ç†ç°è±¡ï¼‰ï¼Œå³ï¼Œç¡®å®æœ‰çœŸå®çš„é›¶ç‚¹ï¼Œä¾‹å¦‚ï¼Œ'
- en: Kelvin scale of temperature
  id: totrans-2142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼€å°”æ–‡æ¸©åº¦å°ºåº¦
- en: porosity
  id: totrans-2143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡
- en: permeability
  id: totrans-2144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡
- en: saturation
  id: totrans-2145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¥±å’Œåº¦
- en: Since there is a true zero, continuous, ratio features can be compared with
    multiplication and division mathematical operations (in addition to addition and
    subtraction), e.g., twice as much porosity.
  id: totrans-2146
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå­˜åœ¨çœŸå®çš„é›¶ç‚¹ï¼Œè¿ç»­çš„æ¯”ç‡ç‰¹å¾å¯ä»¥ä½¿ç”¨ä¹˜æ³•å’Œé™¤æ³•æ•°å­¦è¿ç®—ï¼ˆé™¤äº†åŠ æ³•å’Œå‡æ³•ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œä¾‹å¦‚ï¼Œå­”éš™ç‡çš„ä¸¤å€ã€‚
- en: '**Continuously Differentiable**'
  id: totrans-2147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿ç»­å¯å¾®**'
- en: '[Machine Learning Training and Tuning](MachineLearning_training_tuning.html):
    a function is continuously differentiable if it satisfies two key conditions:'
  id: totrans-2148
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ è®­ç»ƒå’Œè°ƒä¼˜](MachineLearning_training_tuning.html)ï¼šå¦‚æœä¸€ä¸ªå‡½æ•°æ»¡è¶³ä¸¤ä¸ªå…³é”®æ¡ä»¶ï¼Œåˆ™å®ƒæ˜¯è¿ç»­å¯å¾®çš„ï¼š'
- en: The function is differentiable, the derivative of the function exists at every
    point in its domain, i.e., the function has a well-defined slope at every possible
    point.
  id: totrans-2149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡½æ•°æ˜¯å¯å¾®çš„ï¼Œå‡½æ•°çš„å¯¼æ•°åœ¨å…¶å®šä¹‰åŸŸçš„æ¯ä¸€ç‚¹ä¸Šéƒ½å­˜åœ¨ï¼Œå³ï¼Œå‡½æ•°åœ¨æ¯ä¸€ä¸ªå¯èƒ½çš„ç‚¹ä¸Šéƒ½æœ‰ä¸€ä¸ªæ˜ç¡®çš„æ–œç‡ã€‚
- en: The derivative is continuous, the derivative of the function does not have any
    jumps, discontinuities, or abrupt changes, i.e, the derivative function itself
    is continuous at every point in its domain.
  id: totrans-2150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¼æ•°æ˜¯è¿ç»­çš„ï¼Œå‡½æ•°çš„å¯¼æ•°åœ¨å…¶å®šä¹‰åŸŸçš„æ¯ä¸€ç‚¹ä¸Šéƒ½æ²¡æœ‰è·³è·ƒã€ä¸è¿ç»­æˆ–çªç„¶å˜åŒ–ï¼Œå³ï¼Œå¯¼æ•°å‡½æ•°åœ¨å…¶å®šä¹‰åŸŸçš„æ¯ä¸€ç‚¹ä¸Šæœ¬èº«æ˜¯è¿ç»­çš„ã€‚
- en: For a machine learning example,
  id: totrans-2151
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€ä¸ªæœºå™¨å­¦ä¹ ç¤ºä¾‹ï¼Œ
- en: the \(L^2\) norm is continuously differentiable and as a result for linear and
    ridge regression we can apply partial derivatives to the loss function to calculate
    a closed form of training the model parameters
  id: totrans-2152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(L^2\) èŒƒæ•°æ˜¯è¿ç»­å¯å¾®çš„ï¼Œå› æ­¤å¯¹äºçº¿æ€§å›å½’å’Œå²­å›å½’ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æŸå¤±å‡½æ•°åº”ç”¨åå¯¼æ•°æ¥è®¡ç®—æ¨¡å‹å‚æ•°è®­ç»ƒçš„é—­å¼è§£
- en: the \(L^1\) norm is not continuously differentiable and as a result for LASSO
    regression we cannot apply partial derivatives to the loss function to calculate
    a closed form of training the model parameters. We must use iterative optimization
    to train the model parameters.
  id: totrans-2153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(L^1\) èŒƒæ•°ä¸å¯è¿ç»­å¯å¾®ï¼Œå› æ­¤å¯¹äº LASSO å›å½’ï¼Œæˆ‘ä»¬æ— æ³•å¯¹æŸå¤±å‡½æ•°åº”ç”¨åå¯¼æ•°æ¥è®¡ç®—æ¨¡å‹å‚æ•°è®­ç»ƒçš„é—­å¼è§£ã€‚æˆ‘ä»¬å¿…é¡»ä½¿ç”¨è¿­ä»£ä¼˜åŒ–æ¥è®­ç»ƒæ¨¡å‹å‚æ•°ã€‚
- en: '**Convolution**'
  id: totrans-2154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å·ç§¯**'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): Integral
    product of two functions, after one is reversed and shifted by \(\Delta\).'
  id: totrans-2155
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šä¸¤ä¸ªå‡½æ•°çš„ç§¯åˆ†ä¹˜ç§¯ï¼Œå…¶ä¸­ä¸€ä¸ªå‡½æ•°ç»è¿‡åè½¬å¹¶å¹³ç§» \(\Delta\)ã€‚'
- en: one interpretation is smoothing a function with weighting function, \(ğ‘“(\Delta)\),
    is applied to calculate the weighted average of function, \(ğ‘”(x)\),
  id: totrans-2156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£é‡Šæ˜¯ä½¿ç”¨åŠ æƒå‡½æ•° \(ğ‘“(\Delta)\) å¯¹å‡½æ•°è¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œä»¥è®¡ç®—å‡½æ•° \(ğ‘”(x)\) çš„åŠ æƒå¹³å‡å€¼ï¼Œ
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
  id: totrans-2157
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
- en: this easily extends into multidimensional
  id: totrans-2158
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå®¹æ˜“æ‰©å±•åˆ°å¤šç»´
- en: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
  id: totrans-2159
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
- en: The choice of which function is shifted before integration does not change the
    result, the convolution operator has commutativity.
  id: totrans-2160
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç§¯åˆ†ä¹‹å‰é€‰æ‹©å“ªä¸ªå‡½æ•°è¢«ç§»åŠ¨ä¸ä¼šæ”¹å˜ç»“æœï¼Œå·ç§¯ç®—å­å…·æœ‰äº¤æ¢æ€§ã€‚
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
  id: totrans-2161
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
- en: if either function is reflected then convolution is equivalent to cross-correlation,
    measure of similarity between 2 signals as a function of displacement.
  id: totrans-2162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä»»ä¸€å‡½æ•°è¢«åæ˜ å‡ºæ¥ï¼Œå·ç§¯å°±ç­‰åŒäºäº’ç›¸å…³ï¼Œå®ƒæ˜¯ä¸¤ä¸ªä¿¡å·ä½œä¸ºä½ç§»å‡½æ•°çš„ç›¸ä¼¼åº¦åº¦é‡ã€‚
- en: '**Core Data**'
  id: totrans-2163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ¸å¿ƒæ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the primary sampling
    method for direct measure for subsurface resources (recovered drill cuttings are
    also direct measures with greater uncertainty and smaller, irregular scale). Comments
    on core data,'
  id: totrans-2164
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šç›´æ¥æµ‹é‡åœ°ä¸‹èµ„æºï¼ˆå›æ”¶çš„é’»å±‘ä¹Ÿæ˜¯ç›´æ¥æµ‹é‡ï¼Œå…·æœ‰æ›´å¤§çš„ä¸ç¡®å®šæ€§å’Œè¾ƒå°çš„ã€ä¸è§„åˆ™çš„å°ºåº¦ï¼‰çš„ä¸»è¦é‡‡æ ·æ–¹æ³•ã€‚å¯¹æ ¸å¿ƒæ•°æ®çš„è¯„è®ºï¼Œ'
- en: expensive / time consuming to collect for oil and gas, interrupt drilling operations,
    sparse and selective (very biased) coverage
  id: totrans-2165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºçŸ³æ²¹å’Œå¤©ç„¶æ°”æ¥è¯´ï¼Œæ”¶é›†æˆæœ¬é«˜æ˜‚/è€—æ—¶ï¼Œä¼šä¸­æ–­é’»æ¢ä½œä¸šï¼Œåˆ†å¸ƒç¨€ç–ä¸”å…·æœ‰é€‰æ‹©æ€§ï¼ˆéå¸¸å…·æœ‰åè§ï¼‰
- en: very common in mining (diamond drill holes) for grade control with regular patterns
    and tight spacing
  id: totrans-2166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é‡‡çŸ¿ï¼ˆé’»çŸ³é’»å­”ï¼‰ä¸­éå¸¸å¸¸è§ï¼Œç”¨äºä»¥è§„åˆ™æ¨¡å¼å’Œç´§å¯†é—´è·è¿›è¡Œå“ä½æ§åˆ¶
- en: gravity, piston, etc. coring are used to sample sediments in lakes and oceans
  id: totrans-2167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡åŠ›ã€æ´»å¡ç­‰å–å¿ƒæ–¹æ³•ç”¨äºåœ¨æ¹–æ³Šå’Œæµ·æ´‹ä¸­å–æ ·æ²‰ç§¯ç‰©
- en: What do we learn from core data?
  id: totrans-2168
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»æ ¸å¿ƒæ•°æ®ä¸­å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ
- en: petrological features (sedimentary structures, mineral grades), petrophysical
    features (porosity, permeability), and mechanical features (elastic modulas, Poissonâ€™s
    ratio)
  id: totrans-2169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å²©çŸ³å­¦ç‰¹å¾ï¼ˆæ²‰ç§¯ç»“æ„ï¼ŒçŸ¿ç‰©ç­‰çº§ï¼‰ï¼Œå²©çŸ³ç‰©ç†ç‰¹å¾ï¼ˆå­”éš™ç‡ï¼Œæ¸—é€ç‡ï¼‰ï¼Œä»¥åŠåŠ›å­¦ç‰¹å¾ï¼ˆå¼¹æ€§æ¨¡é‡ï¼Œæ³Šæ¾æ¯”ï¼‰
- en: stratigraphy and ore body geometry through interpolation between wells and drill
    holes
  id: totrans-2170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡äº•å’Œé’»å­”ä¹‹é—´çš„æ’å€¼æ¥ç ”ç©¶åœ°å±‚å­¦å’ŒçŸ¿ä½“å‡ ä½•å­¦
- en: Core data are critical to support subsurface resource interpretations. They
    anchor the entire reservoir concept and framework for prediction,
  id: totrans-2171
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¸å¿ƒæ•°æ®å¯¹äºæ”¯æŒåœ°ä¸‹èµ„æºè§£é‡Šè‡³å…³é‡è¦ã€‚å®ƒä»¬æ˜¯æ•´ä¸ªå‚¨å±‚æ¦‚å¿µå’Œé¢„æµ‹æ¡†æ¶çš„é”šï¼Œ
- en: for example, core data collocated with well log data are used to calibrate (ground
    truth) facies, porosity from well logs
  id: totrans-2172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸äº•æ—¥å¿—æ•°æ®åŒä½å¤„çš„æ ¸å¿ƒæ•°æ®ç”¨äºæ ¡å‡†ï¼ˆåœ°é¢çœŸå®ï¼‰ç›¸ï¼Œäº•æ—¥å¿—ä¸­çš„å­”éš™ç‡
- en: '**Correlation**'
  id: totrans-2173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›¸å…³æ€§**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): the Pearsonâ€™s
    product-moment correlation coefficient is a measure of the degree of linear relationship,'
  id: totrans-2174
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šçš®å°”é€Šç§¯çŸ©ç›¸å…³ç³»æ•°æ˜¯çº¿æ€§å…³ç³»ç¨‹åº¦çš„åº¦é‡ï¼Œ'
- en: \[ \rho_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)\sigma_x
    \sigma_y} \]
  id: totrans-2175
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)\sigma_x
    \sigma_y} \]
- en: where \(\overline{x}\) and \(\overline{y}\) are the means of features \(x\)
    and \(y\). The measure is bound \(\[-1,1\]\).
  id: totrans-2176
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\overline{y}\) æ˜¯ç‰¹å¾ \(x\) å’Œ \(y\) çš„å¹³å‡å€¼ã€‚è¯¥åº¦é‡æ˜¯ç•Œé™ \(\[-1,1\]\)ã€‚
- en: correlation coefficient is a standardized covariance
  id: totrans-2177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å…³ç³»æ•°æ˜¯æ ‡å‡†åŒ–çš„åæ–¹å·®
- en: The Personâ€™s correlation coefficient is quite sensitive to outliers and departure
    from linear behavior (in the bivariate sense). We have an alternative known as
    the Spearmanâ€™s rank correlations coefficient,
  id: totrans-2178
  prefs: []
  type: TYPE_NORMAL
  zh: çš®å°”é€Šç›¸å…³ç³»æ•°å¯¹å¼‚å¸¸å€¼å’Œåç¦»çº¿æ€§è¡Œä¸ºï¼ˆåœ¨åŒå˜é‡æ„ä¹‰ä¸Šï¼‰éå¸¸æ•æ„Ÿã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªç§°ä¸ºæ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•°çš„æ›¿ä»£æ–¹æ¡ˆï¼Œ
- en: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
  id: totrans-2179
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
- en: The rank correlation applies the rank transform to the data prior to calculating
    the correlation coefficient. To calculate the rank transform simply replace the
    data values with the rank \(R_x = 1,\dots,n\), where \(n\) is the maximum value
    and \(1\) is the minimum value.
  id: totrans-2180
  prefs: []
  type: TYPE_NORMAL
  zh: æ’åºç›¸å…³ç³»æ•°åœ¨è®¡ç®—ç›¸å…³ç³»æ•°ä¹‹å‰å°†æ’åºå˜æ¢åº”ç”¨äºæ•°æ®ã€‚è¦è®¡ç®—æ’åºå˜æ¢ï¼Œåªéœ€å°†æ•°æ®å€¼æ›¿æ¢ä¸ºæ’å \(R_x = 1,\dots,n\)ï¼Œå…¶ä¸­ \(n\) æ˜¯æœ€å¤§å€¼ï¼Œ\(1\)
    æ˜¯æœ€å°å€¼ã€‚
- en: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
  id: totrans-2181
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
- en: '**Covariance**'
  id: totrans-2182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åæ–¹å·®**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): a measure
    of how two features vary together,'
  id: totrans-2183
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šè¡¡é‡ä¸¤ä¸ªç‰¹å¾å¦‚ä½•ä¸€èµ·å˜åŒ–ï¼Œ'
- en: \[ C_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)}
    \]
  id: totrans-2184
  prefs: []
  type: TYPE_NORMAL
  zh: \[ C_{x,y} = \frac{\sum_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})}{(n-1)}
    \]
- en: where \(\overline{x}\) and \(\overline{y}\) are the means of features \(x\)
    and \(y\). The measure is bound \(\[-\sigma_x \cdot \sigm_y,\sigma_x \cdot \sigm_y\]\).
  id: totrans-2185
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}\) å’Œ \(\overline{y}\) æ˜¯ç‰¹å¾ \(x\) å’Œ \(y\) çš„å‡å€¼ã€‚è¯¥åº¦é‡å—é™äº \(\[-\sigma_x
    \cdot \sigm_y,\sigma_x \cdot \sigm_y\]\)ã€‚
- en: correlation coefficient is a standardized covariance
  id: totrans-2186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å…³ç³»æ•°æ˜¯æ ‡å‡†åŒ–çš„åæ–¹å·®
- en: The Personâ€™s correlation coefficient is quite sensitive to outliers and departure
    from linear behavior (in the bivariate sense). We have an alternative known as
    the Spearmanâ€™s rank correlations coefficient,
  id: totrans-2187
  prefs: []
  type: TYPE_NORMAL
  zh: ä½©å°”æ£®ç›¸å…³ç³»æ•°å¯¹å¼‚å¸¸å€¼å’Œåç¦»çº¿æ€§è¡Œä¸ºï¼ˆåœ¨åŒå˜é‡æ„ä¹‰ä¸Šï¼‰éå¸¸æ•æ„Ÿã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªç§°ä¸ºæ–¯çš®å°”æ›¼ç§©ç›¸å…³ç³»æ•°çš„æ›¿ä»£æ–¹æ¡ˆï¼Œ
- en: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
  id: totrans-2188
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho_{R_x R_y} = \frac{\sum_{i=1}^{n} (R_{x_i} - \overline{R_x})(R_{y_i}
    - \overline{R_y})}{(n-1)\sigma_{R_x} \sigma_{R_y}}, \, -1.0 \le \rho_{xy} \le
    1.0 \]
- en: The rank correlation applies the rank transform to the data prior to calculating
    the correlation coefficient. To calculate the rank transform simply replace the
    data values with the rank \(R_x = 1,\dots,n\), where \(n\) is the maximum value
    and \(1\) is the minimum value.
  id: totrans-2189
  prefs: []
  type: TYPE_NORMAL
  zh: æ’åºç›¸å…³ç³»æ•°åœ¨è®¡ç®—ç›¸å…³ç³»æ•°ä¹‹å‰å°†æ•°æ®å€¼è½¬æ¢ä¸ºæ’åå˜æ¢ã€‚è¦è®¡ç®—æ’åå˜æ¢ï¼Œåªéœ€å°†æ•°æ®å€¼æ›¿æ¢ä¸ºæ’å \(R_x = 1,\dots,n\)ï¼Œå…¶ä¸­ \(n\)
    æ˜¯æœ€å¤§å€¼ï¼Œ\(1\) æ˜¯æœ€å°å€¼ã€‚
- en: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
  id: totrans-2190
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_\alpha, \, \forall \alpha = 1,\dots, n, \, | \, x_i \ge x_j \, \forall
    \, i \gt j \]\[ R_{x_i} = i \]
- en: '**Cross Validation**'
  id: totrans-2191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº¤å‰éªŒè¯**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): withholding a portion
    of the data from the model parameter training to test the ability of the model
    to predict for cases not used to train the model'
  id: totrans-2192
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¿ç•™éƒ¨åˆ†æ•°æ®ä¸ç”¨äºæ¨¡å‹å‚æ•°è®­ç»ƒï¼Œä»¥æµ‹è¯•æ¨¡å‹é¢„æµ‹æœªç”¨äºè®­ç»ƒçš„æ¡ˆä¾‹çš„èƒ½åŠ›'
- en: this is typically conducted by a train and test data split, with 15% - 30% of
    data assigned to testing
  id: totrans-2193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™é€šå¸¸é€šè¿‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²è¿›è¡Œï¼Œå…¶ä¸­ 15% - 30% çš„æ•°æ®åˆ†é…ç»™æµ‹è¯•
- en: a dress rehearsal for real-world model use, the train-test split must be fair,
    resulting in similar prediction difficulty to the planned use of the model
  id: totrans-2194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½œä¸ºç°å®ä¸–ç•Œæ¨¡å‹ä½¿ç”¨çš„æ’ç»ƒï¼Œè®­ç»ƒ-æµ‹è¯•åˆ†å‰²å¿…é¡»å…¬å¹³ï¼Œä»¥äº§ç”Ÿä¸è®¡åˆ’ä½¿ç”¨æ¨¡å‹ç›¸ä¼¼çš„é¢„æµ‹éš¾åº¦
- en: there are more complicated designs such as k-fold cross validation that allows
    testing over all data via k-folds each with trained model
  id: totrans-2195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­˜åœ¨æ›´å¤æ‚çš„è®¾è®¡ï¼Œå¦‚ k æŠ˜äº¤å‰éªŒè¯ï¼Œå®ƒå…è®¸é€šè¿‡ k æŠ˜æ¯æŠ˜éƒ½å¸¦æœ‰è®­ç»ƒæ¨¡å‹çš„æµ‹è¯•æ¥æµ‹è¯•æ‰€æœ‰æ•°æ®
- en: cross validation may be applied to check model performance for estimation accuracy
    (most common) and uncertainty model goodness ([Maldonado-Cruz and Pyrcz, 2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343))
  id: totrans-2196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº¤å‰éªŒè¯å¯ä»¥åº”ç”¨äºæ£€æŸ¥æ¨¡å‹æ€§èƒ½ä»¥ä¼°è®¡å‡†ç¡®æ€§ï¼ˆæœ€å¸¸è§ï¼‰å’Œä¸ç¡®å®šæ€§æ¨¡å‹çš„å¥½åï¼ˆ[Maldonado-Cruz å’Œ Pyrczï¼Œ2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343)ï¼‰
- en: '**Cumulative Distribution Function** (CDF)'
  id: totrans-2197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç´¯ç§¯åˆ†å¸ƒå‡½æ•°** (CDF)'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): the sum of
    a discrete PDF or the integral of a continuous PDF. Here are the important concepts,'
  id: totrans-2198
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šç¦»æ•£æ¦‚ç‡å¯†åº¦å‡½æ•°çš„æ€»å’Œæˆ–è¿ç»­æ¦‚ç‡å¯†åº¦å‡½æ•°çš„ç§¯åˆ†ã€‚ä»¥ä¸‹æ˜¯é‡è¦æ¦‚å¿µï¼Œ'
- en: the CDF is stated as \(F_x(x)\), note the PDF is stated as \(f_x(x)\)
  id: totrans-2199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç´¯ç§¯åˆ†å¸ƒå‡½æ•°è¡¨ç¤ºä¸º \(F_x(x)\)ï¼Œæ³¨æ„æ¦‚ç‡å¯†åº¦å‡½æ•°è¡¨ç¤ºä¸º \(f_x(x)\)
- en: is the probability that a random sample, \(X\), is less than or equal to a specific
    value \(x\); therefore, the y axis is cumulative probability
  id: totrans-2200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜¯éšæœºæ ·æœ¬ \(X\) å°äºæˆ–ç­‰äºç‰¹å®šå€¼ \(x\) çš„æ¦‚ç‡ï¼›å› æ­¤ï¼Œy è½´æ˜¯ç´¯ç§¯æ¦‚ç‡
- en: \[ F_x(x) = P(X \le x) = \int_{-infty}^x f(u) du \]
  id: totrans-2201
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_x(x) = P(X \le x) = \int_{-infty}^x f(u) du \]
- en: for CDFs there is no bin assumption; therefore, bins are at the resolution of
    the data.
  id: totrans-2202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ï¼Œæ²¡æœ‰ç®±å‡è®¾ï¼›å› æ­¤ï¼Œç®±çš„åˆ†è¾¨ç‡ä¸æ•°æ®çš„åˆ†è¾¨ç‡ç›¸åŒã€‚
- en: monotonically non-decreasing function, because a negative slope would indicate
    negative probability over an interval.
  id: totrans-2203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•è°ƒä¸å‡å‡½æ•°ï¼Œå› ä¸ºè´Ÿæ–œç‡ä¼šè¡¨æ˜åŒºé—´å†…çš„è´Ÿæ¦‚ç‡ã€‚
- en: The requirements for a valid CDF include,
  id: totrans-2204
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰çš„è¦æ±‚åŒ…æ‹¬ï¼Œ
- en: 'non-negativity constraint:'
  id: totrans-2205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éè´Ÿçº¦æŸï¼š
- en: \[ F_x(x) = P(X \le x) \ge 0.0, \quad \forall x \]
  id: totrans-2206
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_x(x) = P(X \le x) \ge 0.0, \quad \forall x \]
- en: 'valid probability:'
  id: totrans-2207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆæ¦‚ç‡ï¼š
- en: \[ 0.0 \le F_x(x) \le 1.0, \quad \forall x \]
  id: totrans-2208
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0.0 \le F_x(x) \le 1.0, \quad \forall x \]
- en: 'cannot have negative slope:'
  id: totrans-2209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸èƒ½æœ‰è´Ÿæ–œç‡ï¼š
- en: \[ \frac{dF_x(x)}{dx} \ge 0.0, \quad \forall x \]
  id: totrans-2210
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dF_x(x)}{dx} \ge 0.0, \quad \forall x \]
- en: 'minimum and maximum (ensuring probability closure) values:'
  id: totrans-2211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€å°å’Œæœ€å¤§å€¼ï¼ˆç¡®ä¿æ¦‚ç‡é—­åˆï¼‰ï¼š
- en: \[ \text{min}(F_x(x)) = 0.0 \quad \text{max}(F_x(x)) = 1.0 \]
  id: totrans-2212
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{min}(F_x(x)) = 0.0 \quad \text{max}(F_x(x)) = 1.0 \]
- en: '**Curse of Dimensionality**'
  id: totrans-2213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»´åº¦è¯…å’’**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): the suite of challenges
    associated with working with many features, i.e., high dimensional space, including,'
  id: totrans-2214
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸å¤„ç†è®¸å¤šç‰¹å¾ç›¸å…³çš„ä¸€ç³»åˆ—æŒ‘æˆ˜ï¼Œå³é«˜ç»´ç©ºé—´ï¼ŒåŒ…æ‹¬ï¼Œ'
- en: impossible to visualize data and model in high dimensionality space
  id: totrans-2215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é«˜ç»´ç©ºé—´ä¸­æ— æ³•å¯è§†åŒ–æ•°æ®å’Œæ¨¡å‹
- en: usually insufficient sampling for statistical inference in vast high dimensional
    space
  id: totrans-2216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¹¿é˜”çš„é«˜ç»´ç©ºé—´ä¸­è¿›è¡Œç»Ÿè®¡æ¨æ–­é€šå¸¸é‡‡æ ·ä¸è¶³
- en: low coverage of high dimensional predictor feature space
  id: totrans-2217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜ç»´é¢„æµ‹ç‰¹å¾ç©ºé—´çš„ä½è¦†ç›–ç‡
- en: distorted feature space, including warped space dominated by corners and distances
    lose sensitivity
  id: totrans-2218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰­æ›²çš„ç‰¹å¾ç©ºé—´ï¼ŒåŒ…æ‹¬ç”±è§’å’Œè·ç¦»ä¸»å¯¼çš„æ‰­æ›²ç©ºé—´ï¼Œè·ç¦»å¤±å»æ•æ„Ÿæ€§
- en: multicollinearity between features is more likely as the dimensionality increases
  id: totrans-2219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€ç»´åº¦çš„å¢åŠ ï¼Œç‰¹å¾ä¹‹é—´çš„å¤šé‡å…±çº¿æ€§æ›´å¯èƒ½
- en: '**Data** (data aspects)'
  id: totrans-2220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®**ï¼ˆæ•°æ®æ–¹é¢ï¼‰'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): when describing spatial
    dataset these are the fundamental aspects,'
  id: totrans-2221
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šåœ¨æè¿°ç©ºé—´æ•°æ®é›†æ—¶ï¼Œè¿™äº›æ˜¯åŸºæœ¬æ–¹é¢ï¼Œ'
- en: '*Data coverage* - what proportion of the population has been sampled for this?'
  id: totrans-2222
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®è¦†ç›–ç‡* - å¯¹äºè¿™æ¬¡è°ƒæŸ¥ï¼Œæœ‰å¤šå°‘æ¯”ä¾‹çš„äººå£è¢«é‡‡æ ·ï¼Ÿ'
- en: In general, hard data has high resolution (small scale, volume support), but
    with poor data coverage (measure only an extremely small proportion of the population,
    for example,
  id: totrans-2223
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç¡¬æ•°æ®å…·æœ‰é«˜åˆ†è¾¨ç‡ï¼ˆå°å°ºåº¦ï¼Œä½“ç§¯æ”¯æ’‘ï¼‰ï¼Œä½†æ•°æ®è¦†ç›–ç‡è¾ƒå·®ï¼ˆä¾‹å¦‚ï¼Œä»…æµ‹é‡æå°æ¯”ä¾‹çš„äººå£ï¼‰
- en: '*Core coverage deepwater oil and gas* - well core only sample one five hundred
    millionth to one five billionth of a deepwater reservoir, assuming 3 inch diameter
    cores with 10% core coverage in vertical wells with 500 m to 1,500 m spacing'
  id: totrans-2224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–ç‡æ·±æµ·æ²¹æ°”* - äº•å²©å¿ƒä»…å æ·±æµ·å‚¨é‡çš„äº”äº¿åˆ†ä¹‹ä¸€åˆ°äº”åäº¿åˆ†ä¹‹ä¸€ï¼Œå‡è®¾ä½¿ç”¨ç›´å¾„ä¸º3è‹±å¯¸çš„å²©å¿ƒï¼Œåœ¨å‚ç›´äº•ä¸­å®ç°10%çš„å²©å¿ƒè¦†ç›–ç‡ï¼Œäº•é—´è·ä¸º500ç±³åˆ°1500ç±³'
- en: '*Core coverage mining grade control* - diamond drill hole cores sample one
    eight thousandth to one thirty thousandth of ore body, assuming HQ 63.5 mm diameter
    cores with 100% core coverage in vertical drill holes with 5 m to 10 m spacing'
  id: totrans-2225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–ç‡é‡‡çŸ¿çº§æ§åˆ¶* - é’»çŸ³é’»æ¢å­”å²©å¿ƒæ ·æœ¬å çŸ¿çŸ³ä½“ç§¯çš„å…«åƒåˆ†ä¹‹ä¸€åˆ°ä¸‰ä¸‡åˆ†ä¹‹ä¸€ï¼Œå‡è®¾ä½¿ç”¨ç›´å¾„ä¸º63.5æ¯«ç±³çš„å²©å¿ƒï¼Œåœ¨å‚ç›´é’»å­”ä¸­å®ç°100%çš„å²©å¿ƒè¦†ç›–ç‡ï¼Œé’»å­”é—´è·ä¸º5ç±³åˆ°10ç±³'
- en: Soft data tend to have excellent (often complete) coverage, but with low resolution,
  id: totrans-2226
  prefs: []
  type: TYPE_NORMAL
  zh: è½¯æ•°æ®å¾€å¾€å…·æœ‰ä¼˜ç§€ï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„ï¼‰è¦†ç›–ç‡ï¼Œä½†åˆ†è¾¨ç‡ä½ï¼Œ
- en: '*Seismic reflection surveys and gradiometric surveys* - data is generally available
    over the entire volume of interest, but resolution is low and generally decreasing
    with depth'
  id: totrans-2227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åœ°éœ‡åå°„è°ƒæŸ¥å’Œé‡åŠ›æ¢¯åº¦è°ƒæŸ¥* - æ•°æ®é€šå¸¸åœ¨æ•´ä¸ªæ„Ÿå…´è¶£ä½“ç§¯ä¸­å¯ç”¨ï¼Œä½†åˆ†è¾¨ç‡ä½ï¼Œå¹¶ä¸”é€šå¸¸éšç€æ·±åº¦çš„å¢åŠ è€Œé™ä½'
- en: '*Data Scale* (support size) - What is the scale or volume sampled by the individual
    samples? For example,'
  id: totrans-2228
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®è§„æ¨¡*ï¼ˆæ”¯æ’‘å¤§å°ï¼‰- å•ä¸ªæ ·æœ¬é‡‡æ ·çš„è§„æ¨¡æˆ–ä½“ç§¯æ˜¯å¤šå°‘ï¼Ÿä¾‹å¦‚ï¼Œ'
- en: core tomography images of core samples at the pore scale, 1 - 50 \(\mu m\)
  id: totrans-2229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¸å¿ƒæ ·å“åœ¨å­”éš™å°ºåº¦ä¸Šçš„æ–­å±‚æ‰«æå›¾åƒï¼Œ1 - 50 \(\mu m\)
- en: gamma ray well log sampled at 0.3 m intervals with 1 m penetration away from
    the bore hole
  id: totrans-2230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥0.3ç±³é—´éš”é‡‡æ ·çš„ä¼½é©¬å°„çº¿äº•æµ‹äº•ï¼Œä»äº•ç­’å‘å¤–æ¸—é€1ç±³
- en: ground-based gravity gradiometry map with 20 m x 20 m x 100 m resolution
  id: totrans-2231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºåœ°é¢çš„é‡åŠ›æ¢¯åº¦æµ‹é‡å›¾ï¼Œåˆ†è¾¨ç‡ä¸º20 m x 20 m x 100 m
- en: '*Data Information Type* - What does the data tell us about the subsurface?
    For example,'
  id: totrans-2232
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®ä¿¡æ¯ç±»å‹* - æ•°æ®å‘Šè¯‰æˆ‘ä»¬å…³äºåœ°ä¸‹ä»€ä¹ˆä¿¡æ¯ï¼Ÿä¾‹å¦‚ï¼Œ'
- en: grain size distribution that may be applied to calibrate permeability and saturations
  id: totrans-2233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ç”¨äºæ ¡å‡†æ¸—é€ç‡å’Œé¥±å’Œåº¦çš„ç²’åº¦åˆ†å¸ƒ
- en: fluid type to assess the location of the oil water contact
  id: totrans-2234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµä½“ç±»å‹ä»¥è¯„ä¼°æ²¹æ°´æ¥è§¦ç‚¹ä½ç½®
- en: dip and continuity of important reservoir layers to access connectivity
  id: totrans-2235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡è¦çš„å‚¨å±‚å±‚æ®µçš„å€¾è§’å’Œè¿ç»­æ€§ä»¥è·å–è¿é€šæ€§
- en: mineral grade to map high, mid and low grade ore shells for mine planning
  id: totrans-2236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çŸ¿çŸ³å“ä½ä»¥ç»˜åˆ¶é«˜ã€ä¸­ã€ä½å“ä½çŸ¿çŸ³å£³ä½“ä»¥è¿›è¡ŒçŸ¿å±±è§„åˆ’
- en: '**Data Convexity**'
  id: totrans-2237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®å‡¸æ€§**'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    a subset, \(A\), of Euclidean feature space is convex if, for any two points \(ğ‘¥_1\)
    and \(ğ‘¥_2\) within \(ğ´\), the entire line segment connecting these points is within
    \(A\), \(\left[ğ‘¥_1,ğ‘¥_2\right] \in A\).'
  id: totrans-2238
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœæ¬§å‡ é‡Œå¾—ç‰¹å¾ç©ºé—´çš„ä¸€ä¸ªå­é›† \(A\)
    å¯¹äº \(A\) å†…çš„ä»»æ„ä¸¤ç‚¹ \(ğ‘¥_1\) å’Œ \(ğ‘¥_2\)ï¼Œè¿æ¥è¿™äº›ç‚¹çš„æ•´ä¸ªçº¿æ®µéƒ½åœ¨ \(A\) å†…ï¼Œåˆ™ \(A\) æ˜¯å‡¸çš„ï¼Œ\(\left[ğ‘¥_1,ğ‘¥_2\right]
    \in A\)ã€‚'
- en: '**DataFrame**'
  id: totrans-2239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DataFrame**'
- en: 'Machine Learning Workflow Construction and Coding: a convenient Pandas class
    for working with data tables with rows for each sample and columns for each feature,
    due to,'
  id: totrans-2240
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šä¸€ä¸ªæ–¹ä¾¿çš„Pandasç±»ï¼Œç”¨äºå¤„ç†æ•°æ®è¡¨ï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ªæ ·æœ¬ï¼Œæ¯åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å¾ï¼Œå› ä¸ºï¼Œ
- en: convenient data structure to store, access, manipulate tabular data
  id: totrans-2241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹ä¾¿çš„æ•°æ®ç»“æ„æ¥å­˜å‚¨ã€è®¿é—®ã€æ“ä½œè¡¨æ ¼æ•°æ®
- en: built-in methods to load data from a variety of file types, Python classes and
    even directly from Excel
  id: totrans-2242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»å„ç§æ–‡ä»¶ç±»å‹ã€Pythonç±»ç”šè‡³ç›´æ¥ä»ExcelåŠ è½½æ•°æ®çš„å†…ç½®æ–¹æ³•
- en: built-in methods to calculate summary statistics and visualize data
  id: totrans-2243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ±‡æ€»ç»Ÿè®¡å’Œå¯è§†åŒ–æ•°æ®çš„å†…ç½®æ–¹æ³•
- en: built-in methods for data queries, sort, data filters
  id: totrans-2244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®æŸ¥è¯¢ã€æ’åºã€æ•°æ®è¿‡æ»¤çš„å†…ç½®æ–¹æ³•
- en: built-in methods for data manipulation, cleaning, reformatting
  id: totrans-2245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®æ“ä½œã€æ¸…æ´—ã€é‡æ–°æ ¼å¼åŒ–çš„å†…ç½®æ–¹æ³•
- en: built-in attributes to store information about the data, e.g. size, number nulls
    and null value
  id: totrans-2246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­˜å‚¨æ•°æ®ä¿¡æ¯çš„å†…ç½®å±æ€§ï¼Œä¾‹å¦‚å¤§å°ã€ç©ºå€¼æ•°é‡å’Œç©ºå€¼
- en: '**Data Analytics**'
  id: totrans-2247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®åˆ†æ**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the use of statistics
    with visualization to support decision making.'
  id: totrans-2248
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä½¿ç”¨å¯è§†åŒ–ç»Ÿè®¡æ¥æ”¯æŒå†³ç­–ã€‚'
- en: Dr. Pyrcz says that data analytics is the same as statistics.
  id: totrans-2249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pyrczåšå£«è¡¨ç¤ºï¼Œæ•°æ®åˆ†æä¸ç»Ÿè®¡å­¦ç›¸åŒã€‚
- en: '**Data Preparation**'
  id: totrans-2250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ•°æ®å‡†å¤‡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): any workflow steps
    to enhance, improve raw data to be model ready.'
  id: totrans-2251
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä»»ä½•å¢å¼ºã€æ”¹è¿›åŸå§‹æ•°æ®ä»¥å‡†å¤‡æ¨¡å‹çš„å·¥ä½œæµç¨‹æ­¥éª¤ã€‚'
- en: data-driven science needs data, data preparation remains essential
  id: totrans-2252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®é©±åŠ¨ç§‘å­¦éœ€è¦æ•°æ®ï¼Œæ•°æ®å‡†å¤‡ä»ç„¶è‡³å…³é‡è¦
- en: \(\gt >80\%\) of any subsurface study is data preparation and interpretation
  id: totrans-2253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»»ä½•åœ°ä¸‹ç ”ç©¶ä¸­æœ‰è¶…è¿‡80%æ˜¯æ•°æ®å‡†å¤‡å’Œè§£é‡Š
- en: 'We continue to face a challenge with data:'
  id: totrans-2254
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»§ç»­é¢ä¸´æ•°æ®æŒ‘æˆ˜ï¼š
- en: data curation - format standards, version control, storage, transmission, security
    and documentation
  id: totrans-2255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®æ•´ç† - æ ¼å¼æ ‡å‡†ã€ç‰ˆæœ¬æ§åˆ¶ã€å­˜å‚¨ã€ä¼ è¾“ã€å®‰å…¨å’Œæ–‡æ¡£
- en: large volume to manage - visualization, availability and data mining and exploration
  id: totrans-2256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§é‡æ•°æ®ç®¡ç† - å¯è§†åŒ–ã€å¯ç”¨æ€§å’Œæ•°æ®æŒ–æ˜ä¸æ¢ç´¢
- en: large volumes of metadata - lack of platforms, standards and formats
  id: totrans-2257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§é‡çš„å…ƒæ•°æ® - ç¼ºä¹å¹³å°ã€æ ‡å‡†å’Œæ ¼å¼
- en: engineering integration, variety of data, scale, interpretation and uncertainty
  id: totrans-2258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å·¥ç¨‹é›†æˆã€æ•°æ®å¤šæ ·æ€§ã€è§„æ¨¡ã€è§£é‡Šå’Œä¸ç¡®å®šæ€§
- en: Clean databases are prerequisite to all data analytics and machine learning
  id: totrans-2259
  prefs: []
  type: TYPE_NORMAL
  zh: æ¸…æ´æ•°æ®åº“æ˜¯æ‰€æœ‰æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„å‰æ
- en: must start with this foundation
  id: totrans-2260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¿…é¡»ä»è¿™ä¸ªåŸºç¡€å¼€å§‹
- en: garbage in, garbage out
  id: totrans-2261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾“å…¥åƒåœ¾ï¼Œè¾“å‡ºåƒåœ¾
- en: '**Degree Matrix** (spectral clustering)'
  id: totrans-2262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åº¦çŸ©é˜µ**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph with the number of connections for each graph nodes, samples.'
  id: totrans-2263
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šè¡¨ç¤ºå›¾çš„çŸ©é˜µï¼Œæ¯ä¸ªå›¾èŠ‚ç‚¹ã€æ ·æœ¬çš„è¿æ¥æ•°ã€‚'
- en: diagonal matrix with integer for number of connections
  id: totrans-2264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è§’çŸ©é˜µï¼Œç”¨æ•´æ•°è¡¨ç¤ºè¿æ¥æ•°
- en: '**DBSCAN for Density-based Clustering**'
  id: totrans-2265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå¯†åº¦çš„èšç±»DBSCAN**'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    an density-based clustering algorithm, groups are seeded or grown in feature space
    at locations with sufficient point density determined by hyperparameters,'
  id: totrans-2266
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šä¸€ç§åŸºäºå¯†åº¦çš„èšç±»ç®—æ³•ï¼Œç»„åœ¨ç‰¹å¾ç©ºé—´ä¸­ä»¥è¶³å¤Ÿç‚¹å¯†åº¦çš„ä½ç½®æ’­ç§æˆ–å¢é•¿ï¼Œè¯¥ç‚¹å¯†åº¦ç”±è¶…å‚æ•°ç¡®å®šï¼Œ'
- en: \(\epsilon\) â€“ the radius of the local neighbourhood in the metric of normalized
    features. The is the scale / resolution of the clusters. If this values is set
    too small, too many samples are left as outliers and if set too large, all the
    clusters merge to one single cluster.
  id: totrans-2267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\epsilon\) â€“ åœ¨å½’ä¸€åŒ–ç‰¹å¾åº¦é‡çš„å±€éƒ¨é‚»åŸŸåŠå¾„ã€‚è¿™æ˜¯ç°‡çš„å°ºåº¦/åˆ†è¾¨ç‡ã€‚å¦‚æœè¿™ä¸ªå€¼è®¾ç½®å¾—å¤ªå°ï¼Œå¤ªå¤šçš„æ ·æœ¬ä¼šè¢«ç•™ä¸‹ä½œä¸ºå¼‚å¸¸å€¼ï¼›å¦‚æœè®¾ç½®å¾—å¤ªå¤§ï¼Œæ‰€æœ‰çš„ç°‡å°†åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„ç°‡ã€‚
- en: \(min_{Pts}\) â€“ the minimum number of points to assign a core point, where core
    points are applied to initialize or grow a cluster group.
  id: totrans-2268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(min_{Pts}\) â€“ åˆ†é…æ ¸å¿ƒç‚¹æ‰€éœ€çš„æœ€å°ç‚¹æ•°ï¼Œå…¶ä¸­æ ¸å¿ƒç‚¹ç”¨äºåˆå§‹åŒ–æˆ–å¢é•¿ç°‡ç»„ã€‚
- en: Density is quantified by number of samples over a volume, where the volume is
    based on a radius over all dimensions of feature space.
  id: totrans-2269
  prefs: []
  type: TYPE_NORMAL
  zh: å¯†åº¦é€šè¿‡æ ·æœ¬æ•°é‡åœ¨ä½“ç§¯ä¸­çš„æ•°é‡æ¥é‡åŒ–ï¼Œå…¶ä¸­ä½“ç§¯åŸºäºç‰¹å¾ç©ºé—´æ‰€æœ‰ç»´åº¦çš„åŠå¾„ã€‚
- en: Automated or guided \(\epsilon\) parameter estimation is available by k-distance
    graph (in this case is k nearest neighbor).
  id: totrans-2270
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡kè·ç¦»å›¾ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯kæœ€è¿‘é‚»ï¼‰å¯ä»¥è¿›è¡Œè‡ªåŠ¨æˆ–å¼•å¯¼çš„ \(\epsilon\) å‚æ•°ä¼°è®¡ã€‚
- en: Calculate the nearest neighbor distance in normalized feature space for all
    the sample data (1,700 in this case).
  id: totrans-2271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ‰€æœ‰æ ·æœ¬æ•°æ®ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º1,700ï¼‰åœ¨å½’ä¸€åŒ–ç‰¹å¾ç©ºé—´ä¸­çš„æœ€è¿‘é‚»è·ç¦»ã€‚
- en: Sort in ascending order and plot.
  id: totrans-2272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰å‡åºæ’åºå¹¶ç»˜å›¾ã€‚
- en: Select the distance that maximizes the positive curvature (the elbow).
  id: totrans-2273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©æœ€å¤§åŒ–æ­£æ›²ç‡çš„è·ç¦»ï¼ˆæ‹ç‚¹ï¼‰ã€‚
- en: Here is a summary of salient aspects for DBSCAN clustering,
  id: totrans-2274
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯DBSCANèšç±»çš„æ˜¾è‘—æ–¹é¢çš„æ€»ç»“ï¼Œ
- en: '*DBSCAN* - stands for Density-Based Spatial Clustering of Applications with
    Noise (Ester et al.,1996).'
  id: totrans-2275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DBSCAN* - ä»£è¡¨åŸºäºå¯†åº¦çš„ç©ºé—´èšç±»åº”ç”¨å™ªå£°ï¼ˆEsterç­‰ï¼Œ1996å¹´ï¼‰ã€‚'
- en: '*Advantages* - include minimum domain knowledge to estimate hyperparameters,
    the ability to represent any arbitrary shape of cluster groups and efficient to
    apply for large data sets'
  id: totrans-2276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ä¼˜ç‚¹* - åŒ…æ‹¬æœ€å°é¢†åŸŸçŸ¥è¯†æ¥ä¼°è®¡è¶…å‚æ•°ï¼Œèƒ½å¤Ÿè¡¨ç¤ºä»»æ„å½¢çŠ¶çš„èšç±»ç»„ï¼Œå¹¶ä¸”åœ¨å¤§æ•°æ®é›†ä¸Šåº”ç”¨é«˜æ•ˆ'
- en: '*Hierarchical Bottom-up / Agglomerative Clustering* â€“ all data samples start
    as their own group, called â€˜unvisitedâ€™ but practically as outliers until assigned
    to a group, and then the cluster group grow iteratively.'
  id: totrans-2277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è‡ªåº•å‘ä¸Šçš„å±‚æ¬¡èšç±»/èšåˆèšç±»* â€“ æ‰€æœ‰æ•°æ®æ ·æœ¬æœ€åˆéƒ½æ˜¯è‡ªå·±çš„ç»„ï¼Œç§°ä¸ºâ€œæœªè®¿é—®â€ï¼Œä½†å®é™…ä¸Šä½œä¸ºå¼‚å¸¸å€¼ï¼Œç›´åˆ°åˆ†é…åˆ°ç»„ï¼Œç„¶åèšç±»ç»„è¿­ä»£å¢é•¿ã€‚'
- en: '*Mutually Exclusive* â€“ like k-means clustering, all samples may only belong
    to a single cluster group.'
  id: totrans-2278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*äº’æ–¥æ€§* â€“ ç±»ä¼¼äºk-meansèšç±»ï¼Œæ‰€æœ‰æ ·æœ¬å¯èƒ½åªèƒ½å±äºä¸€ä¸ªèšç±»ç»„ã€‚'
- en: \[ P(C_i \cap C_j | i \ne j) = 0.0 \]
  id: totrans-2279
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_i \cap C_j | i \ne j) = 0.0 \]
- en: '*Non-exhaustive* â€“ some samples may be left as unassigned and assumed as outliers
    for the cluster group assignment'
  id: totrans-2280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*éç©·å°½æ€§* â€“ ä¸€äº›æ ·æœ¬å¯èƒ½è¢«ç•™ä¸‹ä½œä¸ºæœªåˆ†é…çš„ï¼Œå¹¶å‡è®¾ä¸ºèšç±»åˆ†ç»„åˆ†é…çš„å¼‚å¸¸å€¼'
- en: \[ P(C_1 \cup C_2 \cup \dots C_k) \le 1.0 \]
  id: totrans-2281
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_1 \cup C_2 \cup \dots C_k) \le 1.0 \]
- en: '**Decision Criteria**'
  id: totrans-2282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å†³ç­–æ ‡å‡†**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a feature that
    is calculated by applying the transfer function to the subsurface model(s) to
    support decision making. The decision criteria represents value, health, environment
    and safety. For example:'
  id: totrans-2283
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€šè¿‡åº”ç”¨è½¬ç§»å‡½æ•°åˆ°åœ°ä¸‹æ¨¡å‹ï¼ˆsï¼‰æ¥è®¡ç®—çš„ç‰¹å¾ï¼Œä»¥æ”¯æŒå†³ç­–ã€‚å†³ç­–æ ‡å‡†ä»£è¡¨ä»·å€¼ã€å¥åº·ã€ç¯å¢ƒå’Œå®‰å…¨ã€‚ä¾‹å¦‚ï¼š'
- en: contaminant recovery rate to support design of a pump and treat soil remediation
    project
  id: totrans-2284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ±¡æŸ“ç‰©å›æ”¶ç‡ä»¥æ”¯æŒæ³µçš„è®¾è®¡å’ŒåœŸå£¤ä¿®å¤é¡¹ç›®çš„å®æ–½
- en: oil-in-place resources to determine if a reservoir should be developed
  id: totrans-2285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸåœ°æ²¹æ°”èµ„æºä»¥ç¡®å®šæ˜¯å¦åº”è¯¥å¼€å‘å‚¨å±‚
- en: Lorenz coefficient heterogeneity measure to classify a reservoir and determine
    mature analogs
  id: totrans-2286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ´›ä¼¦å…¹ç³»æ•°å¼‚è´¨æ€§åº¦é‡ç”¨äºåˆ†ç±»å‚¨å±‚å¹¶ç¡®å®šæˆç†Ÿç±»æ¯”
- en: recovery factor or production rate to schedule production and determine optimum
    facilities
  id: totrans-2287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›æ”¶ç³»æ•°æˆ–äº§é‡ä»¥å®‰æ’ç”Ÿäº§å’Œç¡®å®šæœ€ä½³è®¾æ–½
- en: recovered mineral grade and tonnage to determine economic ultimate pit shell
  id: totrans-2288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¢å¤çš„çŸ¿ç‰©å“ä½å’Œå¨ä½ä»¥ç¡®å®šç»æµæœ€ç»ˆçŸ¿å‘å£³ä½“
- en: '**Decision Tree**'
  id: totrans-2289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å†³ç­–æ ‘**'
- en: '[Decision Tree](MachineLearning_decision_tree.html): a intuitive, regression
    and classification predictive machine learning model that devides the predictor
    space, \(ğ‘‹_1,â€¦,ğ‘‹_ğ‘š\), into \(ğ½\) mutually exclusive, exhaustive regions, \(ğ‘…_ğ‘—\).'
  id: totrans-2290
  prefs: []
  type: TYPE_NORMAL
  zh: '[å†³ç­–æ ‘](MachineLearning_decision_tree.html)ï¼šä¸€ä¸ªç›´è§‚çš„ã€å›å½’å’Œåˆ†ç±»çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå°†é¢„æµ‹ç©ºé—´ \(ğ‘‹_1,â€¦,ğ‘‹_ğ‘š\)
    åˆ’åˆ†ä¸º \(ğ½\) ä¸ªäº’æ–¥ã€ç©·å°½çš„åŒºåŸŸï¼Œ\(ğ‘…_ğ‘—\)ã€‚'
- en: '*mutually exclusive* â€“ any combination of predictors only belongs to a single
    region, \(ğ‘…_ğ‘—\)'
  id: totrans-2291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*äº’æ–¥æ€§* â€“ ä»»ä½•é¢„æµ‹å˜é‡çš„ç»„åˆåªå±äºä¸€ä¸ªåŒºåŸŸï¼Œ\(ğ‘…_ğ‘—\)'
- en: '*exhaustive* â€“ all combinations of predictors belong a region, \(ğ‘…_ğ‘—\), regions
    cover entire feature space, range of the variables being considered'
  id: totrans-2292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©·å°½æ€§* â€“ æ‰€æœ‰é¢„æµ‹å˜é‡çš„ç»„åˆå±äºä¸€ä¸ªåŒºåŸŸï¼Œ\(ğ‘…_ğ‘—\)ï¼ŒåŒºåŸŸè¦†ç›–æ•´ä¸ªç‰¹å¾ç©ºé—´ï¼Œè€ƒè™‘çš„å˜é‡çš„èŒƒå›´'
- en: The same prediction in each region, mean of training data in region, \(\hat{Y}(ğ‘…_ğ‘—)
    = \overline{Y}(ğ‘…_ğ‘—)\)
  id: totrans-2293
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªåŒºåŸŸçš„ç›¸åŒé¢„æµ‹ï¼Œè¯¥åŒºåŸŸçš„è®­ç»ƒæ•°æ®å¹³å‡å€¼ï¼Œ\(\hat{Y}(ğ‘…_ğ‘—) = \overline{Y}(ğ‘…_ğ‘—)\)
- en: for classification the most common, mode-based or argmax operator
  id: totrans-2294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºåˆ†ç±»ï¼Œæœ€å¸¸è§çš„æ˜¯åŸºäºæ¨¡å¼çš„æˆ–argmaxè¿ç®—ç¬¦
- en: Other salient points about decision tree,
  id: totrans-2295
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå†³ç­–æ ‘çš„å…¶å®ƒæ˜¾è‘—ç‚¹ï¼Œ
- en: '*supervised Learning* - the response feature label, \(Y\), is available over
    the training and testing data'
  id: totrans-2296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç›‘ç£å­¦ä¹ * - å“åº”ç‰¹å¾æ ‡ç­¾ \(Y\) åœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸­æ˜¯å¯ç”¨çš„'
- en: '*hierarchical, binary segmentation* - of the predictor feature space, start
    with 1 region and sequentially divide, creating new regions'
  id: totrans-2297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ†å±‚ã€äºŒè¿›åˆ¶åˆ†å‰²* - é¢„æµ‹ç‰¹å¾ç©ºé—´ï¼Œä»1ä¸ªåŒºåŸŸå¼€å§‹ï¼Œç„¶åé¡ºåºåˆ’åˆ†ï¼Œåˆ›å»ºæ–°çš„åŒºåŸŸ'
- en: '*compact, interpretable model* - since the classification is based on a hierarchy
    of binary segmentations of the feature space (one feature at a time) the model
    can be specified in a intuitive manner as a tree with binary branches**, hence
    the name decision tree. The code for the model is nested if statements, for example,'
  id: totrans-2298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç´§å‡‘ã€å¯è§£é‡Šçš„æ¨¡å‹* - ç”±äºåˆ†ç±»æ˜¯åŸºäºç‰¹å¾ç©ºé—´äºŒè¿›åˆ¶åˆ†å‰²çš„å±‚æ¬¡ç»“æ„ï¼ˆæ¯æ¬¡ä¸€ä¸ªç‰¹å¾ï¼‰ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»¥ç›´è§‚çš„æ–¹å¼æŒ‡å®šä¸ºå…·æœ‰äºŒå‰åˆ†æ”¯çš„æ ‘ï¼Œå› æ­¤å¾—åå†³ç­–æ ‘ã€‚è¯¥æ¨¡å‹çš„ä»£ç æ˜¯åµŒå¥—çš„ifè¯­å¥ï¼Œä¾‹å¦‚ï¼Œ'
- en: '[PRE1]'
  id: totrans-2299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The decision tree is constructed from the top down. We begin with a single region
    that covers the entire feature space and then proceed with a sequence of splits,
  id: totrans-2300
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘æ˜¯ä»ä¸Šåˆ°ä¸‹æ„å»ºçš„ã€‚æˆ‘ä»¬ä»ä¸€ä¸ªè¦†ç›–æ•´ä¸ªç‰¹å¾ç©ºé—´çš„å•ä¸€åŒºåŸŸå¼€å§‹ï¼Œç„¶åè¿›è¡Œä¸€ç³»åˆ—åˆ†å‰²ï¼Œ
- en: '*scan all possible splits* - over all regions and over all features.'
  id: totrans-2301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ‰«ææ‰€æœ‰å¯èƒ½çš„åˆ†å‰²* - åœ¨æ‰€æœ‰åŒºåŸŸå’Œæ‰€æœ‰ç‰¹å¾ä¸Šã€‚'
- en: '*greedy optimization* - proceeds by finding the best split in any feature that
    minimizes the residual sum of squares of errors over all the training data \(y_i\)
    over all of the regions \(j = 1,\ldots,J\). There is no other information shared
    between subsequent splits.'
  id: totrans-2302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è´ªå©ªä¼˜åŒ–* - é€šè¿‡åœ¨ä»»æ„ç‰¹å¾ä¸­æ‰¾åˆ°æœ€ä½³åˆ†å‰²ï¼Œæœ€å°åŒ–æ‰€æœ‰è®­ç»ƒæ•°æ® \(y_i\) åœ¨æ‰€æœ‰åŒºåŸŸ \(j = 1,\ldots,J\) ä¸Šçš„æ®‹å·®å¹³æ–¹å’Œã€‚åç»­åˆ†å‰²ä¹‹é—´æ²¡æœ‰å…¶ä»–ä¿¡æ¯å…±äº«ã€‚'
- en: \[ RSS = \sum^{J}_{j=1} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
  id: totrans-2303
  prefs: []
  type: TYPE_NORMAL
  zh: \[ RSS = \sum^{J}_{j=1} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
- en: Hyperparameters include,
  id: totrans-2304
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°åŒ…æ‹¬ï¼Œ
- en: '*number of regions* â€“ very easy to understand, you know what the model will
    be'
  id: totrans-2305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŒºåŸŸæ•°é‡* â€“ éå¸¸å®¹æ˜“ç†è§£ï¼Œä½ çŸ¥é“æ¨¡å‹ä¼šæ˜¯ä»€ä¹ˆæ ·å­'
- en: '*minimum reduction in RSS* â€“ could stop early, e.g., a low reduction in RSS
    split could lead to a subsequent split with a larger reduction in RSS'
  id: totrans-2306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœ€å°åŒ–RSSçš„å‡å°‘* â€“ å¯ä»¥æå‰åœæ­¢ï¼Œä¾‹å¦‚ï¼ŒRSSå‡å°‘è¾ƒå°‘çš„åˆ†å‰²å¯èƒ½å¯¼è‡´åç»­åˆ†å‰²æœ‰æ›´å¤§çš„RSSå‡å°‘'
- en: '*minimum number of training data in each region* â€“ related to the concept of
    accuracy of the region mean prediction, i.e., we need at least ğ‘› data for a reliable
    mean'
  id: totrans-2307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¯ä¸ªåŒºåŸŸä¸­è®­ç»ƒæ•°æ®çš„æœ€ä½æ•°é‡* â€“ ä¸åŒºåŸŸå‡å€¼é¢„æµ‹çš„å‡†ç¡®æ€§æ¦‚å¿µç›¸å…³ï¼Œå³æˆ‘ä»¬éœ€è¦è‡³å°‘ ğ‘› ä¸ªæ•°æ®æ¥è·å¾—å¯é çš„å‡å€¼'
- en: '*maximum number of levels* â€“ forces symmetric trees, similar number of splits
    to get to each region'
  id: totrans-2308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœ€å¤§å±‚æ•°* â€“ å¼ºåˆ¶å¯¹ç§°æ ‘ï¼Œåˆ°è¾¾æ¯ä¸ªåŒºåŸŸæ‰€éœ€çš„åˆ†å‰²æ•°é‡ç›¸ä¼¼'
- en: '**Declustering**'
  id: totrans-2309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†æ•£**'
- en: 'Data Preparation: various methods that assign weights to spatial samples based
    on local sampling density, such that the weighted statistics are likely more representative
    of the population. Data weights are assigned so that,'
  id: totrans-2310
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šæ ¹æ®å±€éƒ¨é‡‡æ ·å¯†åº¦å¯¹ç©ºé—´æ ·æœ¬åˆ†é…æƒé‡çš„å„ç§æ–¹æ³•ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡é‡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚æ­¤ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-2311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å¯†é›†é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬æƒé‡è¾ƒä½
- en: samples in sparsely sampled areas receive more weight
  id: totrans-2312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç¨€ç–é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬æƒé‡è¾ƒé«˜
- en: 'There are various declustering methods:'
  id: totrans-2313
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨å¤šç§åˆ†æ•£æ–¹æ³•ï¼š
- en: '*cell-based declustering*'
  id: totrans-2314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºå•å…ƒæ ¼çš„åˆ†æ•£*'
- en: '*polygonal declustering*'
  id: totrans-2315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šè¾¹å½¢åˆ†æ•£*'
- en: '*kriging-based declustering*'
  id: totrans-2316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºå…‹é‡Œé‡‘çš„åˆ†æ•£*'
- en: It is important to note that no declustering method can prove that for every
    data set the resulting weighted statistics will improve the prediction of the
    population parameters, but in expectation these methods tend to reduce the bias.
  id: totrans-2317
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œæ²¡æœ‰ä»»ä½•åˆ†æ•£æ–¹æ³•å¯ä»¥è¯æ˜å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œç»“æœåŠ æƒç»Ÿè®¡é‡éƒ½ä¼šæé«˜æ€»ä½“å‚æ•°çš„é¢„æµ‹ï¼Œä½†åœ¨æœŸæœ›ä¸­ï¼Œè¿™äº›æ–¹æ³•å€¾å‘äºå‡å°‘åå·®ã€‚
- en: '**Declustering** (statistics)'
  id: totrans-2318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†æ•£**ï¼ˆç»Ÿè®¡å­¦ï¼‰'
- en: 'Data Preparation: once declustering weights are calculated for a spatial dataset,
    then declustered statistics are applied as input for only subsequent analysis
    or modeling. For example,'
  id: totrans-2319
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€æ—¦ä¸ºç©ºé—´æ•°æ®é›†è®¡ç®—äº†åˆ†æ•£æƒé‡ï¼Œåˆ™å°†åˆ†æ•£åçš„ç»Ÿè®¡é‡åº”ç”¨äºåç»­åˆ†ææˆ–å»ºæ¨¡çš„è¾“å…¥ã€‚ä¾‹å¦‚ï¼Œ
- en: the declustered mean is assigned as the stationary, global mean for simple kriging
  id: totrans-2320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†æ•£åçš„å‡å€¼è¢«æŒ‡å®šä¸ºç®€å•å…‹é‡Œé‡‘æ³•çš„ç¨³å®šã€å…¨å±€å‡å€¼
- en: the weighted CDF from all the data with weights are applied to sequential Gaussian
    simulation to ensure the back-transformed realizations approach the declustered
    distribution
  id: totrans-2321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰æ•°æ®çš„åŠ æƒç´¯ç§¯åˆ†å¸ƒå‡½æ•°åº”ç”¨äºé¡ºåºé«˜æ–¯æ¨¡æ‹Ÿï¼Œä»¥ç¡®ä¿åå˜æ¢çš„å®ç°åœ¨è¶‹è¿‘äºåˆ†æ•£åˆ†å¸ƒ
- en: Any statistic can be weighted, including the entire CDF! Here are some examples
    of weighted statistics, given declustering weights, \(w(\bf{u}_j)\), for all data
    \(j=1,\ldots,n\).
  id: totrans-2322
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•ç»Ÿè®¡é‡éƒ½å¯ä»¥åŠ æƒï¼ŒåŒ…æ‹¬æ•´ä¸ªç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ä»¥ä¸‹æ˜¯åŠ æƒç»Ÿè®¡é‡çš„ç¤ºä¾‹ï¼Œç»™å®šåˆ†æ•£æƒé‡ \(w(\bf{u}_j)\)ï¼Œå¯¹äºæ‰€æœ‰æ•°æ® \(j=1,\ldots,n\)ã€‚
- en: weighted sample mean,
  id: totrans-2323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ æƒæ ·æœ¬å‡å€¼ï¼Œ
- en: \[ \overline{x}_{wt} = \frac{\sum_{i=1}^n w(\bf{u}_j) \cdot z(\bf{u}_j)}{\sum_{i=1}^n
    w(\bf{u}_j)} \]
  id: totrans-2324
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{x}_{wt} = \frac{\sum_{i=1}^n w(\bf{u}_j) \cdot z(\bf{u}_j)}{\sum_{i=1}^n
    w(\bf{u}_j)} \]
- en: where \(n\) is the number of data.
  id: totrans-2325
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(n\) æ˜¯æ•°æ®æ•°é‡ã€‚
- en: weighted sample variance,
  id: totrans-2326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ æƒæ ·æœ¬æ–¹å·®ï¼Œ
- en: \[ s^2_{x_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) - 1} \cdot \sum_{i=1}^n
    w(\bf{u}_j) \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right)^2 \]
  id: totrans-2327
  prefs: []
  type: TYPE_NORMAL
  zh: \[ s^2_{x_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) - 1} \cdot \sum_{i=1}^n
    w(\bf{u}_j) \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right)^2 \]
- en: where \(\overline{x}_{wt}\) is the declustered mean.
  id: totrans-2328
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}_{wt}\) æ˜¯å»èšç±»å‡å€¼ã€‚
- en: weighted covariance,
  id: totrans-2329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ æƒåæ–¹å·®ï¼Œ
- en: \[ C_{x,y_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) } \cdot \sum_{i=1}^n w(\bf{u}_j)
    \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right) \cdot \left( y(\bf{u}_j)
    - \overline{y}_{wt} \right) \]
  id: totrans-2330
  prefs: []
  type: TYPE_NORMAL
  zh: \[ C_{x,y_{wt}} = \frac{1}{\sum_{i=1}^n w(\bf{u}_j) } \cdot \sum_{i=1}^n w(\bf{u}_j)
    \cdot \left( x(\bf{u}_j) - \overline{x}_{wt} \right) \cdot \left( y(\bf{u}_j)
    - \overline{y}_{wt} \right) \]
- en: where \(\overline{x}_{wt}\) and \(\overline{y}_{wt}\) are the declustered means
    for features \(X\) and \(Y\).
  id: totrans-2331
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\overline{x}_{wt}\) å’Œ \(\overline{y}_{wt}\) æ˜¯ç‰¹å¾ \(X\) å’Œ \(Y\) çš„å»èšç±»å‡å€¼ã€‚
- en: the entire CDF,
  id: totrans-2332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•´ä¸ªç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ï¼Œ
- en: \[ F_z(z) \approx \sum_{j=1}^{n(Z<z)} w(\bf{u}_j) \]
  id: totrans-2333
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_z(z) \approx \sum_{j=1}^{n(Z<z)} w(\bf{u}_j) \]
- en: where \(n(Z<z)\) is the number of sorted ascending data less than threshold
    \(z\). We show this as approximative as this is simplified and at data resolution
    and without an interpolation model.
  id: totrans-2334
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(n(Z<z)\) æ˜¯å°äºé˜ˆå€¼ \(z\) çš„å‡åºæ’åºæ•°æ®çš„æ•°é‡ã€‚æˆ‘ä»¬å°†å…¶è¡¨ç¤ºä¸ºè¿‘ä¼¼å€¼ï¼Œå› ä¸ºè¿™ç®€åŒ–äº†ï¼Œå¹¶ä¸”æ²¡æœ‰æ’å€¼æ¨¡å‹ï¼Œä¸”åœ¨æ•°æ®åˆ†è¾¨ç‡ä¸Šã€‚
- en: It is important to note that no declustering method can prove that for every
    data set the resulting weighted statistics will improve the prediction of the
    population parameters, but in expectation these methods tend to reduce the bias.
  id: totrans-2335
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œæ²¡æœ‰ä»»ä½•å»èšç±»æ–¹æ³•å¯ä»¥è¯æ˜å¯¹äºæ¯ä¸ªæ•°æ®é›†ï¼Œç»“æœåŠ æƒç»Ÿè®¡é‡å°†æé«˜å¯¹æ€»ä½“å‚æ•°çš„é¢„æµ‹ï¼Œä½†åœ¨æœŸæœ›ä¸­ï¼Œè¿™äº›æ–¹æ³•å€¾å‘äºå‡å°‘åå·®ã€‚
- en: '**Density-Connected** (DBSCAN)'
  id: totrans-2336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯†åº¦è¿æ¥** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    points \(A\) and \(B\) are density-connected if there is a point \(Z\) that is
    density-reachable from both points \(A\) and \(B\).'
  id: totrans-2337
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœå­˜åœ¨ä¸€ä¸ªç‚¹ \(Z\)ï¼Œå®ƒå¯ä»¥ä»ç‚¹
    \(A\) å’Œ \(B\) éƒ½å¯†åº¦å¯è¾¾ï¼Œåˆ™ç‚¹ \(A\) å’Œ \(B\) æ˜¯å¯†åº¦è¿æ¥çš„ã€‚'
- en: '**Density-based Cluster** (DBSCAN)'
  id: totrans-2338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå¯†åº¦çš„èšç±»** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    a nonempty set where all points are density-connected to each other.'
  id: totrans-2339
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šä¸€ä¸ªéç©ºé›†åˆï¼Œå…¶ä¸­æ‰€æœ‰ç‚¹éƒ½ç›¸äº’å¯†åº¦è¿æ¥ã€‚'
- en: '**Density-Reachable** (DBSCAN)'
  id: totrans-2340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯†åº¦å¯è¾¾** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    point \(Y\) is density reachable from \(A\) if \(Y\) belongs to a neighborhood
    of a core point that can reached from \(A\). This would require a chain of core
    points each belonging the previous core points and the last core point including
    point Y.'
  id: totrans-2341
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœ \(Y\) å±äºä¸€ä¸ªå¯ä»¥ä» \(A\)
    åˆ°è¾¾çš„æ ¸å¿ƒç‚¹çš„é‚»åŸŸï¼Œåˆ™ç‚¹ \(Y\) æ˜¯ä» \(A\) å¯†åº¦å¯è¾¾çš„ã€‚è¿™éœ€è¦ä¸€ç³»åˆ—å±äºå…ˆå‰æ ¸å¿ƒç‚¹å¹¶åŒ…æ‹¬ç‚¹ \(Y\) çš„æ ¸å¿ƒç‚¹é“¾ã€‚'
- en: '**Deterministic Model**'
  id: totrans-2342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¡®å®šæ€§æ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a model that assumes
    the system or process that is completely predictable'
  id: totrans-2343
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªå‡è®¾ç³»ç»Ÿæˆ–è¿‡ç¨‹æ˜¯å®Œå…¨å¯é¢„æµ‹çš„æ¨¡å‹'
- en: often-based on engineering and geoscience physics and expert judgement
  id: totrans-2344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸åŸºäºå·¥ç¨‹å’Œåœ°çƒç§‘å­¦ç‰©ç†å­¦ä»¥åŠä¸“å®¶åˆ¤æ–­
- en: for example, numerical flow simulation or stratigraphic bounding surfaces interpreted
    from seismic
  id: totrans-2345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ•°å€¼æµåŠ¨æ¨¡æ‹Ÿæˆ–ä»åœ°éœ‡è§£é‡Šçš„å±‚åºè¾¹ç•Œè¡¨é¢
- en: for this course we also state that data-driven estimation models like
  id: totrans-2346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™é—¨è¯¾ç¨‹ï¼Œæˆ‘ä»¬ä¹Ÿå£°æ˜äº†æ•°æ®é©±åŠ¨ä¼°è®¡æ¨¡å‹ï¼Œä¾‹å¦‚
- en: 'Advantages:'
  id: totrans-2347
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼š
- en: integration of physics and expert knowledge
  id: totrans-2348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰©ç†å­¦å’Œä¸“å®¶çŸ¥è¯†çš„æ•´åˆ
- en: integration of various information sources
  id: totrans-2349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å„ç§ä¿¡æ¯æºçš„æ•´åˆ
- en: 'Disadvantages:'
  id: totrans-2350
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼š
- en: often quite time consuming
  id: totrans-2351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸éå¸¸è€—æ—¶
- en: often no assessment of uncertainty, focus on building one model
  id: totrans-2352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸æ²¡æœ‰ä¸ç¡®å®šæ€§è¯„ä¼°ï¼Œä¸“æ³¨äºæ„å»ºä¸€ä¸ªæ¨¡å‹
- en: '**Dimensionality Reduction**'
  id: totrans-2353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»´åº¦çº¦ç®€**'
- en: '[Principal Component Analysis](MachineLearning_PCA.html): methods to reduce
    the number of features within a data science workflow. There are 2 primary methods,'
  id: totrans-2354
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸»æˆåˆ†åˆ†æ](MachineLearning_PCA.html)ï¼šå‡å°‘æ•°æ®ç§‘å­¦å·¥ä½œæµç¨‹ä¸­ç‰¹å¾æ•°é‡çš„æ–¹æ³•ã€‚æœ‰ä¸¤ç§ä¸»è¦æ–¹æ³•ï¼Œ'
- en: '*features Selection* â€“ find the subset of original features that are most important
    for the problem'
  id: totrans-2355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‰¹å¾é€‰æ‹©* â€“ æ‰¾åˆ°å¯¹é—®é¢˜æœ€é‡è¦çš„åŸå§‹ç‰¹å¾å­é›†'
- en: '*feature projection* â€“ transform the data from a higher to lower dimensional
    space'
  id: totrans-2356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‰¹å¾æŠ•å½±* â€“ å°†æ•°æ®ä»é«˜ç»´ç©ºé—´è½¬æ¢åˆ°ä½ç»´ç©ºé—´'
- en: Known as dimension reduction or dimensionality reduction
  id: totrans-2357
  prefs: []
  type: TYPE_NORMAL
  zh: è¢«ç§°ä¸ºé™ç»´æˆ–ç»´åº¦çº¦ç®€
- en: motivated by the curse of dimensionality and multicollinearity
  id: totrans-2358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å—ç»´åº¦è¯…å’’å’Œå¤šå…±çº¿æ€§å¯å‘
- en: applied in statistics, machine learning and information theory
  id: totrans-2359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨äºç»Ÿè®¡å­¦ã€æœºå™¨å­¦ä¹ å’Œä¿¡æ¯ç†è®º
- en: '**Directly Density Reachable** (DBSCAN)'
  id: totrans-2360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›´æ¥å¯†åº¦å¯è¾¾** (DBSCAN)'
- en: '[Density-based Clustering](MachineLearning_density-based_clustering.html):
    point \(X\) is directly density reachable from \(A\), if \(A\) is a core point
    and \(X\) belongs to the neighborhood, distance \(le \epsilon\) from \(A\).'
  id: totrans-2361
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŸºäºå¯†åº¦çš„èšç±»](MachineLearning_density-based_clustering.html)ï¼šå¦‚æœ\(A\)æ˜¯ä¸€ä¸ªæ ¸å¿ƒç‚¹ä¸”\(X\)å±äº\(A\)çš„é‚»åŸŸï¼Œè·ç¦»\(le
    \epsilon\)ï¼Œåˆ™ç‚¹\(X\)æ˜¯ç›´æ¥å¯†åº¦å¯è¾¾çš„\(A\)ã€‚'
- en: '**Discrete Feature**'
  id: totrans-2362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¦»æ•£ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a *categorical
    feature* or a *continuous feature* that is binned or grouped, for example,'
  id: totrans-2363
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯ä¸€ä¸ªå°†ç‰¹å¾åœ¨æœªé‡‡æ ·ä½ç½®æˆ–æ—¶é—´è¡¨ç¤ºä¸ºå•ä¸ªæœ€ä½³å€¼çš„è¿›ç¨‹ï¼Œæˆ–ä¸€äº›é¢å¤–çš„æ¦‚å¿µï¼Œ'
- en: porosity between 0 and 20% assigned to 10 bins = {0 - 2%, 2% - 4%, \ldots ,20%}
  id: totrans-2364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡åœ¨0åˆ°20%ä¹‹é—´åˆ†é…åˆ°10ä¸ªç®±å­ = {0 - 2%ï¼Œ2% - 4%ï¼Œ...ï¼Œ20%}
- en: Mohs hardness = \(\{1, 2, \ldots, 10\}\) (same at *categorical feature*)
  id: totrans-2365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‘©æ°ç¡¬åº¦ = \(\{1, 2, \ldots, 10\}\)ï¼ˆä¸*åˆ†ç±»ç‰¹å¾*ç›¸åŒï¼‰
- en: '**Distribution Transformations**'
  id: totrans-2366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ†å¸ƒå˜æ¢**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    mapping from one distribution to another distribution through percentile values,
    resulting in a new histogram, PDF, and CDF. We perform distribution transformations
    in geostatistical methods and workflows because,'
  id: totrans-2367
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šé€šè¿‡ç™¾åˆ†ä½æ•°å€¼ä»ä¸€ä¸ªåˆ†å¸ƒæ˜ å°„åˆ°å¦ä¸€ä¸ªåˆ†å¸ƒï¼Œä»è€Œå¾—åˆ°æ–°çš„ç›´æ–¹å›¾ã€PDFå’ŒCDFã€‚æˆ‘ä»¬åœ¨åœ°ç»Ÿè®¡æ–¹æ³•å’Œå·¥ä½œæµç¨‹ä¸­æ‰§è¡Œåˆ†å¸ƒå˜æ¢ï¼Œå› ä¸ºï¼Œ'
- en: '*inference* - to correct a feature distribution to an expected shape, for example,
    correcting for too few or biased data'
  id: totrans-2368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨æ–­* - ä¸ºäº†çº æ­£ç‰¹å¾åˆ†å¸ƒåˆ°é¢„æœŸçš„å½¢çŠ¶ï¼Œä¾‹å¦‚ï¼Œçº æ­£æ•°æ®è¿‡å°‘æˆ–åå·®'
- en: '*theory* - a specific distribution assumption is required for a workflow step,
    for example, Gaussian distribution with mean of 0.0 and variance of 1.0 is required
    for sequential Gaussian simulation'
  id: totrans-2369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç†è®º* - å·¥ä½œæµç¨‹æ­¥éª¤éœ€è¦ç‰¹å®šçš„åˆ†å¸ƒå‡è®¾ï¼Œä¾‹å¦‚ï¼Œå¯¹äºé¡ºåºé«˜æ–¯æ¨¡æ‹Ÿï¼Œéœ€è¦å‡å€¼ä¸º0.0å’Œæ–¹å·®ä¸º1.0çš„é«˜æ–¯åˆ†å¸ƒ'
- en: '*data preparation or cleaning* - to correct for outliers, the transformation
    will map the outlier into the target distribution no longer as an outlier'
  id: totrans-2370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ•°æ®å‡†å¤‡æˆ–æ¸…ç†* - ä¸ºäº†çº æ­£å¼‚å¸¸å€¼ï¼Œå˜æ¢å°†æŠŠå¼‚å¸¸å€¼æ˜ å°„åˆ°ç›®æ ‡åˆ†å¸ƒï¼Œè€Œä¸å†æ˜¯å¼‚å¸¸å€¼'
- en: How do we perform distribution transformations?
  id: totrans-2371
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•æ‰§è¡Œåˆ†å¸ƒå˜æ¢ï¼Ÿ
- en: 'We transform the values from the cumulative distribution function (CDF), \(F_{X}\),
    to a new CDF , \(G_{Y}\). This can be generalized with the quantile - quantile
    transformation applied to all the sample data:'
  id: totrans-2372
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ï¼Œ\(F_{X}\)ï¼Œçš„å€¼è½¬æ¢æˆä¸€ä¸ªæ–°çš„CDFï¼Œ\(G_{Y}\)ã€‚è¿™å¯ä»¥é€šè¿‡å¯¹æ‰€æœ‰æ ·æœ¬æ•°æ®åº”ç”¨åˆ†ä½æ•°-åˆ†ä½æ•°å˜æ¢è¿›è¡Œæ¨å¹¿ï¼š
- en: 'The forward transform:'
  id: totrans-2373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£å‘å˜æ¢ï¼š
- en: \[ Y = G_{Y}^{-1}(F_{X}(X)) \]
  id: totrans-2374
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y = G_{Y}^{-1}(F_{X}(X)) \]
- en: 'The reverse transform:'
  id: totrans-2375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå‘å˜æ¢ï¼š
- en: \[ X = F_{X}^{-1}(G_{Y}(Y)) \]
  id: totrans-2376
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X = F_{X}^{-1}(G_{Y}(Y)) \]
- en: 'This may be applied to any data, including parametric or nonparametric distributions.
    We just need to be able to map from one distribution to another through percentiles,
    so it is a:'
  id: totrans-2377
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥åº”ç”¨äºä»»ä½•æ•°æ®ï¼ŒåŒ…æ‹¬å‚æ•°æˆ–éå‚æ•°åˆ†å¸ƒã€‚æˆ‘ä»¬åªéœ€è¦èƒ½å¤Ÿé€šè¿‡ç™¾åˆ†ä½æ•°å°†ä¸€ä¸ªåˆ†å¸ƒæ˜ å°„åˆ°å¦ä¸€ä¸ªåˆ†å¸ƒï¼Œå› æ­¤å®ƒæ˜¯ä¸€ä¸ªï¼š
- en: rank preserving transform, for example, P25 remains P25 after distribution transformation
  id: totrans-2378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿ç•™æ’åçš„å˜æ¢ï¼Œä¾‹å¦‚ï¼ŒP25åœ¨åˆ†å¸ƒå˜æ¢åä»ç„¶æ˜¯P25
- en: '**Eager Learning**'
  id: totrans-2379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ€¥åˆ‡å­¦ä¹ **'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): Model is
    a generalization of the training data constructed prior to queries'
  id: totrans-2380
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šæ¨¡å‹æ˜¯æŸ¥è¯¢ä¹‹å‰æ„å»ºçš„è®­ç»ƒæ•°æ®çš„æ³›åŒ–'
- en: the model is input-independent after parameter training and hyperparameter tuning,
    i.e., the training data does not need to be available to make new predictions
  id: totrans-2381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹åœ¨å‚æ•°è®­ç»ƒå’Œè¶…å‚æ•°è°ƒæ•´åæ˜¯è¾“å…¥ç‹¬ç«‹çš„ï¼Œå³ï¼Œä¸éœ€è¦è®­ç»ƒæ•°æ®æ¥åšå‡ºæ–°çš„é¢„æµ‹
- en: The opposite is lazy learning.
  id: totrans-2382
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åçš„æ˜¯æ‡’æƒ°å­¦ä¹ ã€‚
- en: '**Estimation**'
  id: totrans-2383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¼°è®¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is process of obtaining
    the single best value to represent a feature at an unsampled location, or time.
    Some additional concepts,'
  id: totrans-2384
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯è·å¾—å•ä¸ªæœ€ä½³å€¼ä»¥è¡¨ç¤ºæœªé‡‡æ ·ä½ç½®æˆ–æ—¶é—´çš„ç‰¹å¾çš„è¿›ç¨‹ã€‚ä¸€äº›é¢å¤–çš„æ¦‚å¿µï¼Œ'
- en: local accuracy takes precedence over global spatial variability
  id: totrans-2385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å±€éƒ¨ç²¾åº¦ä¼˜å…ˆäºå…¨å±€ç©ºé—´å˜å¼‚æ€§
- en: too smooth, not appropriate for any transform function that is sensitive to
    heterogeneity
  id: totrans-2386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡äºå¹³æ»‘ï¼Œä¸é€‚åˆå¯¹å¼‚è´¨æ€§æ•æ„Ÿçš„ä»»ä½•å˜æ¢å‡½æ•°
- en: for example, inverse distance and kriging
  id: totrans-2387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œé€†è·ç¦»å’Œå…‹é‡Œé‡‘æ³•
- en: many predictive machine learning models focus on estimation (e.g., k-nearest
    neighbours, decision tree, random forest, etc.)
  id: totrans-2388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¸å¤šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ä¾§é‡äºä¼°è®¡ï¼ˆä¾‹å¦‚ï¼Œkæœ€è¿‘é‚»ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰ï¼‰
- en: '**f1-score** (classification accuracy metric)'
  id: totrans-2389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**f1åˆ†æ•°**ï¼ˆåˆ†ç±»å‡†ç¡®åº¦æŒ‡æ ‡ï¼‰'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a categorical classification
    prediction model measure of accuracy, a single summary metric for each \(k\) category
    from the confusion matrix.'
  id: totrans-2390
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ä¸ªåˆ†ç±»é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®åº¦åº¦é‡ï¼Œæ··æ·†çŸ©é˜µä¸­æ¯ä¸ª \(k\) ç±»åˆ«çš„å•ä¸€æ±‡æ€»æŒ‡æ ‡ã€‚'
- en: the harmonic mean of recall and precision
  id: totrans-2391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¬å›ç‡å’Œç²¾åº¦çš„è°ƒå’Œå¹³å‡å€¼
- en: \[ f1-score_k = \frac{2} { \frac{1}{Precision_k} + \frac{1}{Recall_k} } \]
  id: totrans-2392
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f1-score_k = \frac{2} { \frac{1}{Precision_k} + \frac{1}{Recall_k} } \]
- en: As a reminder,
  id: totrans-2393
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæé†’ï¼Œ
- en: '*recall* - the ratio of true positives divided by all cases of the category
    in the testing dataset'
  id: totrans-2394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¬å›ç‡* - æµ‹è¯•æ•°æ®é›†ä¸­è¯¥ç±»åˆ«æ‰€æœ‰çœŸå®æ­£ä¾‹ä¸æ‰€æœ‰æ¡ˆä¾‹çš„æ¯”ç‡'
- en: '*precision* - the ratio of true positives divided by all positives, true positives
    + false positives'
  id: totrans-2395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç²¾åº¦* - çœŸå®æ­£ä¾‹ä¸æ‰€æœ‰æ­£ä¾‹ï¼ˆçœŸå®æ­£ä¾‹ + å‡æ­£ä¾‹ï¼‰çš„æ¯”ç‡'
- en: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
  id: totrans-2396
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
- en: '**Feature** (also variable)'
  id: totrans-2397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾**ï¼ˆä¹Ÿç§°ä¸ºå˜é‡ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): any property measured
    or observed in a study'
  id: totrans-2398
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨ç ”ç©¶ä¸­æµ‹é‡çš„æˆ–è§‚å¯Ÿåˆ°çš„ä»»ä½•å±æ€§'
- en: for example, porosity, permeability, mineral concentrations, saturations, contaminant
    concentration, etc.
  id: totrans-2399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå­”éš™ç‡ã€æ¸—é€ç‡ã€çŸ¿ç‰©æµ“åº¦ã€é¥±å’Œåº¦ã€æ±¡æŸ“ç‰©æµ“åº¦ç­‰ã€‚
- en: in data mining / machine learning this is known as a feature, statisticians
    call these variables
  id: totrans-2400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®æŒ–æ˜/æœºå™¨å­¦ä¹ ä¸­ï¼Œè¿™è¢«ç§°ä¸ºç‰¹å¾ï¼Œç»Ÿè®¡å­¦å®¶ç§°è¿™äº›ä¸ºå˜é‡
- en: measure often requires significant analysis, interpretation, etc.
  id: totrans-2401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹é‡é€šå¸¸éœ€è¦å¤§é‡çš„åˆ†æã€è§£é‡Šç­‰ã€‚
- en: when features are modified and combined to improve our models we call this feature
    engineering
  id: totrans-2402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ç‰¹å¾è¢«ä¿®æ”¹å’Œç»„åˆä»¥æé«˜æˆ‘ä»¬çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºç‰¹å¾å·¥ç¨‹
- en: '**Feature Engineering**'
  id: totrans-2403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å·¥ç¨‹**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): using
    domain expertise to extract improved predictor or response features from raw data,'
  id: totrans-2404
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šåˆ©ç”¨é¢†åŸŸä¸“ä¸šçŸ¥è¯†ä»åŸå§‹æ•°æ®ä¸­æå–æ”¹è¿›çš„é¢„æµ‹æˆ–å“åº”ç‰¹å¾ï¼Œ'
- en: improve the performance, accuracy and convergency, of inferential or predictive
    machine learning
  id: totrans-2405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜æ¨ç†æˆ–é¢„æµ‹æœºå™¨å­¦ä¹ çš„æ€§èƒ½ã€å‡†ç¡®æ€§å’Œæ”¶æ•›æ€§
- en: improve model interpretability (or may worsen interpretability if our engineered
    features are in unfamiliar units)
  id: totrans-2406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜æ¨¡å‹å¯è§£é‡Šæ€§ï¼ˆæˆ–è€…å¦‚æœæˆ‘ä»¬çš„å·¥ç¨‹ç‰¹å¾å¤„äºä¸ç†Ÿæ‚‰çš„å•ä½ï¼Œå¯èƒ½ä¼šé™ä½å¯è§£é‡Šæ€§ï¼‰
- en: mitigate outliers & bias, consistency with assumptions such as Gaussianity,
    linearization, dimensional expansion
  id: totrans-2407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼“è§£å¼‚å¸¸å€¼å’Œåå·®ï¼Œä¸é«˜æ–¯æ€§ã€çº¿æ€§åŒ–ã€ç»´åº¦æ‰©å±•ç­‰å‡è®¾çš„ä¸€è‡´æ€§
- en: Feature transformation and feature selection are two forms of feature engineering.
  id: totrans-2408
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾è½¬æ¢å’Œç‰¹å¾é€‰æ‹©æ˜¯ç‰¹å¾å·¥ç¨‹çš„ä¸¤ç§å½¢å¼ã€‚
- en: '**Feature Importance**'
  id: totrans-2409
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾é‡è¦æ€§**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a variety of machine
    learning methods to provide measures for feature ranking, for example decision
    trees summarize the reduction in mean square error through inclusion of each feature
    and is summarized as,'
  id: totrans-2410
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šå„ç§æœºå™¨å­¦ä¹ æ–¹æ³•æä¾›ç‰¹å¾æ’åºçš„åº¦é‡ï¼Œä¾‹å¦‚å†³ç­–æ ‘é€šè¿‡åŒ…å«æ¯ä¸ªç‰¹å¾æ¥æ€»ç»“å‡æ–¹è¯¯å·®çš„å‡å°‘ï¼Œå¹¶æ€»ç»“ä¸ºï¼Œ'
- en: \[ FI(x) = \sum_{t \in T_f} \frac{N_t}{N} \Delta_{MSE_t} \]
  id: totrans-2411
  prefs: []
  type: TYPE_NORMAL
  zh: \[ FI(x) = \sum_{t \in T_f} \frac{N_t}{N} \Delta_{MSE_t} \]
- en: where \(T_f\) are all nodes with feature \(x\) as the split, \(N_t\) is the
    number of training samples reaching node \(t\), \(N\) is the total number of samples
    in the dataset and \(\Delta_{MSE_t}\) is the reduction in MSE with the \(t\) split.
  id: totrans-2412
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(T_f\) æ˜¯æ‰€æœ‰ä»¥ç‰¹å¾ \(x\) ä½œä¸ºåˆ†å‰²çš„èŠ‚ç‚¹ï¼Œ\(N_t\) æ˜¯è¾¾åˆ°èŠ‚ç‚¹ \(t\) çš„è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œ\(N\) æ˜¯æ•°æ®é›†ä¸­æ ·æœ¬çš„æ€»æ•°ï¼Œ\(\Delta_{MSE_t}\)
    æ˜¯ \(t\) åˆ†å‰²æ—¶çš„MSEå‡å°‘é‡ã€‚
- en: Note, feature importance can be calculated in a similar manner to MSE above
    for the case of classification trees with *Gini Impurity*.
  id: totrans-2413
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¯¹äºå…·æœ‰*åŸºå°¼ä¸çº¯åº¦*çš„åˆ†ç±»æ ‘ï¼Œç‰¹å¾é‡è¦æ€§å¯ä»¥ä»¥ä¸ä¸Šè¿°MSEç±»ä¼¼çš„æ–¹å¼è®¡ç®—ã€‚
- en: Feature importance is part of model-based feature ranking,
  id: totrans-2414
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾é‡è¦æ€§æ˜¯æ¨¡å‹ç‰¹å¾æ’åºçš„ä¸€éƒ¨åˆ†ï¼Œ
- en: the accuracy of the feature importance depends on the accuracy of the model,
    i.e., an inaccurate model will likely provide incorrect feature importance
  id: totrans-2415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é‡è¦æ€§çš„å‡†ç¡®æ€§å–å†³äºæ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå³ä¸å‡†ç¡®çš„æ¨¡å‹å¯èƒ½ä¼šæä¾›é”™è¯¯çš„ç‰¹å¾é‡è¦æ€§
- en: '**Feature Imputation**'
  id: totrans-2416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æ’è¡¥**'
- en: '[Feature Imputation](MachineLearning_feature_imputation.html): replacing null
    values in the data table, samples that do not have values for all features with
    plausible values for 2 reasons,'
  id: totrans-2417
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’è¡¥](MachineLearning_feature_imputation.html)ï¼šç”¨åˆç†å€¼æ›¿æ¢æ•°æ®è¡¨ä¸­çš„ç©ºå€¼ï¼Œå¯¹äºæ‰€æœ‰ç‰¹å¾éƒ½æ²¡æœ‰å€¼çš„æ ·æœ¬ï¼Œæœ‰2ä¸ªåŸå› ï¼Œ'
- en: enable statistical calculations and models that require complete data tables,
    i.e., cannot work with missing feature values
  id: totrans-2418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç»Ÿè®¡è®¡ç®—å’Œéœ€è¦å®Œæ•´æ•°æ®è¡¨çš„æ¨¡å‹æˆä¸ºå¯èƒ½ï¼Œå³ï¼Œä¸èƒ½å¤„ç†ç¼ºå¤±ç‰¹å¾å€¼
- en: maximize model accuracy, increasing the number of reliable samples available
    for training and testing the model
  id: totrans-2419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–æ¨¡å‹ç²¾åº¦ï¼Œå¢åŠ å¯ç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ¨¡å‹çš„å¯é æ ·æœ¬æ•°é‡
- en: mitigate model bias that may occur with likewise deletion in feature values
    are not missing at random
  id: totrans-2420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼“è§£å¯èƒ½å› ç‰¹å¾å€¼ä¸­ç±»ä¼¼åˆ é™¤è€Œå‡ºç°çš„æ¨¡å‹åå·®ï¼Œè¿™äº›ç‰¹å¾å€¼ä¸æ˜¯éšæœºç¼ºå¤±çš„
- en: Feature imputation methods include,
  id: totrans-2421
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾æ’è¡¥æ–¹æ³•åŒ…æ‹¬ï¼Œ
- en: '*constant value imputation* - replace null values with feature mean or mode'
  id: totrans-2422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¸¸é‡å€¼æ’è¡¥* - ç”¨ç‰¹å¾å‡å€¼æˆ–ä¼—æ•°æ›¿æ¢ç©ºå€¼'
- en: '*model-based imputation* - replace null values with a prediction of the missing
    feature with available feature values for the same sample'
  id: totrans-2423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºæ¨¡å‹çš„æ’è¡¥* - ç”¨å…·æœ‰ç›¸åŒæ ·æœ¬çš„å¯ç”¨ç‰¹å¾å€¼é¢„æµ‹ç¼ºå¤±ç‰¹å¾æ¥æ›¿æ¢ç©ºå€¼'
- en: There are also an iterative methods that depend on convergence,
  id: totrans-2424
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¾èµ–äºæ”¶æ•›çš„è¿­ä»£æ–¹æ³•ï¼Œ
- en: '*Multiple Imputation by Chained Equations (MICE)* - assign random values and
    then iterate over the missing values predicting new values'
  id: totrans-2425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é“¾å¼æ–¹ç¨‹å¤šé‡æ’è¡¥æ³• (MICE)* - åˆ†é…éšæœºå€¼ï¼Œç„¶åè¿­ä»£å¤„ç†ç¼ºå¤±å€¼ï¼Œé¢„æµ‹æ–°å€¼'
- en: The goal of this method is to obtain reasonable imputed values that account
    for the relationships between all the features and all the available and missing
    values
  id: totrans-2426
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•çš„ç›®æ ‡æ˜¯è·å¾—åˆç†çš„æ’è¡¥å€¼ï¼Œè¿™äº›å€¼è€ƒè™‘äº†æ‰€æœ‰ç‰¹å¾ä¸æ‰€æœ‰å¯ç”¨å’Œç¼ºå¤±å€¼ä¹‹é—´çš„å…³ç³»
- en: '**Feature Projection**'
  id: totrans-2427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æŠ•å½±**'
- en: '[Principal Component Analysis](MachineLearning_PCA.html): a transforms original
    \(m\) features to \(p\) features, where \(p << m\) for dimensionality reduction'
  id: totrans-2428
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸»æˆåˆ†åˆ†æ](MachineLearning_PCA.html)ï¼šå°†åŸå§‹ \(m\) ä¸ªç‰¹å¾è½¬æ¢ä¸º \(p\) ä¸ªç‰¹å¾ï¼Œå…¶ä¸­ \(p << m\)
    ç”¨äºé™ç»´'
- en: given features, \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\) we would require \(\binom{m}{2} = \frac{ğ‘š(ğ‘šâˆ’1)}{2}\)
    scatter plots to visualize just the two-dimensional scatter plots
  id: totrans-2429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šç‰¹å¾ \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\)ï¼Œæˆ‘ä»¬éœ€è¦ \(\binom{m}{2} = \frac{ğ‘š(ğ‘šâˆ’1)}{2}\) ä¸ªæ•£ç‚¹å›¾æ¥å¯è§†åŒ–äºŒç»´æ•£ç‚¹å›¾
- en: these representations would not capture \(> 2\) dimensional structures
  id: totrans-2430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›è¡¨ç¤ºæ— æ³•æ•æ‰ \(> 2\) ç»´ç»“æ„
- en: once we have 4 or more variables understanding our data gets very difficult.
    Recall the curse of dimensionality.
  id: totrans-2431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰4ä¸ªæˆ–æ›´å¤šå˜é‡ï¼Œç†è§£æ•°æ®å°±ä¼šå˜å¾—éå¸¸å›°éš¾ã€‚å›å¿†ç»´åº¦è¯…å’’ã€‚
- en: principal component analysis, multidimensional scaling and random projection
    are examples
  id: totrans-2432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸»æˆåˆ†åˆ†æã€å¤šç»´ç¼©æ”¾å’ŒéšæœºæŠ•å½±æ˜¯ä¾‹å­
- en: feature selection is an alternative method for dimensionality reduction
  id: totrans-2433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é€‰æ‹©æ˜¯é™ç»´çš„å¦ä¸€ç§æ–¹æ³•
- en: '**Feature Space**'
  id: totrans-2434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾ç©ºé—´**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): commonly feature space
    only refers to the predictor features and does not include the response feature(s),
    i.e.,'
  id: totrans-2435
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šé€šå¸¸ç‰¹å¾ç©ºé—´ä»…æŒ‡é¢„æµ‹ç‰¹å¾ï¼Œä¸åŒ…æ‹¬å“åº”ç‰¹å¾ï¼Œå³ï¼Œ'
- en: all possible combinations of predictor features for which we need to make predictions
  id: totrans-2436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦é¢„æµ‹çš„æ‰€æœ‰é¢„æµ‹ç‰¹å¾çš„å¯èƒ½ç»„åˆ
- en: may be referred to as predictor feature space.
  id: totrans-2437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½è¢«ç§°ä¸ºé¢„æµ‹ç‰¹å¾ç©ºé—´ã€‚
- en: Typically, we train and test our machinesâ€™ predictions over the predictor feature
    space.
  id: totrans-2438
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šè®­ç»ƒå’Œæµ‹è¯•æœºå™¨çš„é¢„æµ‹ã€‚
- en: the space is typically a hypercuboid with each axis representing a predictor
    feature and extending from the minimum to maximum, over the range of each predictor
    feature
  id: totrans-2439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥ç©ºé—´é€šå¸¸æ˜¯è¶…ç«‹æ–¹ä½“ï¼Œæ¯ä¸ªè½´ä»£è¡¨ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œä»æ¯ä¸ªé¢„æµ‹ç‰¹å¾çš„æœ€å°å€¼å»¶ä¼¸åˆ°æœ€å¤§å€¼
- en: more complicated shapes of predictor feature space are possible, e.g., we could
    mask or remove subsets with poor data coverage.
  id: totrans-2440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ç©ºé—´çš„æ›´å¤æ‚å½¢çŠ¶æ˜¯å¯èƒ½çš„ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å±è”½æˆ–ç§»é™¤æ•°æ®è¦†ç›–è¾ƒå·®çš„å­é›†ã€‚
- en: '**Feature Ranking**'
  id: totrans-2441
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æ’åº**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): part of feature engineering,
    feature ranking is a set of methods that assign relative importance or value to
    each feature with respect to information contained for inference and importance
    in predicting a response feature.'
  id: totrans-2442
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šç‰¹å¾å·¥ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œç‰¹å¾æ’åºæ˜¯ä¸€ç»„æ–¹æ³•ï¼Œæ ¹æ®æ¯ä¸ªç‰¹å¾å¯¹æ¨ç†ä¸­åŒ…å«çš„ä¿¡æ¯å’Œé¢„æµ‹å“åº”ç‰¹å¾çš„é‡è¦æ€§æˆ–ä»·å€¼åˆ†é…ç›¸å¯¹é‡è¦æ€§ã€‚'
- en: There are a wide variety of possible methods to accomplish this. My recommendation
    is a wide-array approach with multiple metric, while understanding the assumptions
    and limitations of each method.
  id: totrans-2443
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆæ­¤ä»»åŠ¡çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ã€‚æˆ‘çš„å»ºè®®æ˜¯é‡‡ç”¨å¤šç§åº¦é‡æŒ‡æ ‡çš„æ–¹æ³•ï¼ŒåŒæ—¶ç†è§£æ¯ç§æ–¹æ³•çš„å‡è®¾å’Œå±€é™æ€§ã€‚
- en: 'Hereâ€™s the general types of metrics that we will consider for feature ranking:'
  id: totrans-2444
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å°†è€ƒè™‘çš„ç‰¹å¾æ’åºçš„ä¸€èˆ¬ç±»å‹æŒ‡æ ‡ï¼š
- en: '*Visual Inspection* - including data distributions, scatter plots and violin
    plots'
  id: totrans-2445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è§†è§‰æ£€æŸ¥* - åŒ…æ‹¬æ•°æ®åˆ†å¸ƒã€æ•£ç‚¹å›¾å’Œå°æç´å›¾'
- en: '*Statistical Summaries* - correlation analysis, mutual information'
  id: totrans-2446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç»Ÿè®¡æ‘˜è¦* - ç›¸å…³æ€§åˆ†æï¼Œäº’ä¿¡æ¯'
- en: '*Model-based* - including model parameters, feature importance scores and global
    Shapley values'
  id: totrans-2447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸºäºæ¨¡å‹* - åŒ…æ‹¬æ¨¡å‹å‚æ•°ã€ç‰¹å¾é‡è¦æ€§åˆ†æ•°å’Œå…¨å±€ Shapley å€¼'
- en: '*Recursive feature elimination* - and other methods that perform trail and
    error to find optimum parameters sets through withheld testing data cross validation'
  id: totrans-2448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é€’å½’ç‰¹å¾æ¶ˆé™¤* - ä»¥åŠå…¶ä»–é€šè¿‡ä¿ç•™æµ‹è¯•æ•°æ®äº¤å‰éªŒè¯è¿›è¡Œè¯•é”™ä»¥æ‰¾åˆ°æœ€ä½³å‚æ•°é›†çš„æ–¹æ³•'
- en: Feature ranking is primarily motivated by the curse of dimensionality, i.e.,
    work with the fewest, most informative predictor features.
  id: totrans-2449
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾æ’åºä¸»è¦å—ç»´åº¦è¯…å’’çš„é©±åŠ¨ï¼Œå³ä½¿ç”¨æœ€å°‘ã€æœ€æœ‰ä¿¡æ¯é‡çš„é¢„æµ‹ç‰¹å¾ã€‚
- en: '**Feature Transformations**'
  id: totrans-2450
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å˜æ¢**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    type of feature engineering involving mathematical operation applied to a feature
    to improve the value of the feature in a workflow. For example,'
  id: totrans-2451
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§æ¶‰åŠå¯¹ç‰¹å¾åº”ç”¨æ•°å­¦è¿ç®—ä»¥æ”¹è¿›å·¥ä½œæµç¨‹ä¸­ç‰¹å¾ä»·å€¼çš„ç‰¹å¾å·¥ç¨‹ç±»å‹ã€‚ä¾‹å¦‚ï¼Œ'
- en: feature truncation
  id: totrans-2452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾æˆªæ–­
- en: feature normalization or standardization
  id: totrans-2453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å½’ä¸€åŒ–æˆ–æ ‡å‡†åŒ–
- en: feature distribution transformation
  id: totrans-2454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾åˆ†å¸ƒå˜æ¢
- en: There are many reasons that we may want to perform feature transformations.
  id: totrans-2455
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰è®¸å¤šåŸå› æƒ³è¦æ‰§è¡Œç‰¹å¾å˜æ¢ã€‚
- en: the make the features consistent for visualization and comparison
  id: totrans-2456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç‰¹å¾ä¸€è‡´ä»¥ä¾¿äºå¯è§†åŒ–å’Œæ¯”è¾ƒ
- en: to avoid bias or impose feature weighting for methods (e.g. k nearest neighbours
    regression) that rely on distances calculated in predictor feature space
  id: totrans-2457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…åå·®æˆ–ä¸ºä¾èµ–äºé¢„æµ‹ç‰¹å¾ç©ºé—´ä¸­è®¡ç®—çš„è·ç¦»çš„æ–¹æ³•ï¼ˆä¾‹å¦‚ k è¿‘é‚»å›å½’ï¼‰æ–½åŠ ç‰¹å¾æƒé‡
- en: 'the method requires the variables to have a specific range or distribution:'
  id: totrans-2458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•è¦æ±‚å˜é‡å…·æœ‰ç‰¹å®šçš„èŒƒå›´æˆ–åˆ†å¸ƒï¼š
- en: artificial neural networks may require all features to range from [-1,1]
  id: totrans-2459
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: äººå·¥ç¥ç»ç½‘ç»œå¯èƒ½éœ€è¦æ‰€æœ‰ç‰¹å¾çš„èŒƒå›´åœ¨ [-1,1] ä¹‹é—´
- en: partial correlation coefficients require a Gaussian distribution.
  id: totrans-2460
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: éƒ¨åˆ†ç›¸å…³ç³»æ•°éœ€è¦é«˜æ–¯åˆ†å¸ƒã€‚
- en: statistical tests may require a specific distribution
  id: totrans-2461
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡æµ‹è¯•å¯èƒ½éœ€è¦ç‰¹å®šçš„åˆ†å¸ƒ
- en: geostatistical sequential simulation requires an indicator or Gaussian transform
  id: totrans-2462
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°ç»Ÿè®¡å­¦é¡ºåºæ¨¡æ‹Ÿéœ€è¦æŒ‡ç¤ºç¬¦æˆ–é«˜æ–¯å˜æ¢
- en: Feature transformations is a common basic building blocks in many machine learning
    workflows.
  id: totrans-2463
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾å˜æ¢æ˜¯è®¸å¤šæœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸­çš„å¸¸è§åŸºæœ¬æ„å»ºå—ã€‚
- en: '**Fourth Paradigm**'
  id: totrans-2464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¬¬å››èŒƒå¼**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the data-driven
    paradigm for scientific discovery building from the,'
  id: totrans-2465
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä»æ•°æ®é©±åŠ¨çš„èŒƒå¼æ„å»ºç§‘å­¦å‘ç°çš„ï¼Œ'
- en: First Paradigm - empirical science - experiments and observations
  id: totrans-2466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªèŒƒå¼ - ç»éªŒç§‘å­¦ - å®éªŒ å’Œ è§‚å¯Ÿ
- en: Second Paradigm - theoretical science - analytical expressions
  id: totrans-2467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªèŒƒå¼ - ç†è®ºç§‘å­¦ - åˆ†æè¡¨è¾¾å¼
- en: Third Paradigm - computation science - numeric simulation
  id: totrans-2468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰ä¸ªèŒƒå¼ - è®¡ç®—ç§‘å­¦ - æ•°å€¼æ¨¡æ‹Ÿ
- en: We augment with new scientific paradigms, we donâ€™t replace older paradigms.
    Each of the previous paradigm are supported by the previous paradigms, for example,
  id: totrans-2469
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡å¢åŠ æ–°çš„ç§‘å­¦èŒƒå¼ï¼Œè€Œä¸æ˜¯å–ä»£æ—§èŒƒå¼ã€‚æ¯ä¸ªå…ˆå‰çš„èŒƒå¼éƒ½ç”±å…ˆå‰çš„èŒƒå¼æ”¯æŒï¼Œä¾‹å¦‚ï¼Œ
- en: theoretical science is build on empirical science
  id: totrans-2470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç†è®ºç§‘å­¦å»ºç«‹åœ¨ç»éªŒç§‘å­¦ä¹‹ä¸Š
- en: numerical simulations integrate analytical expressions and calibrated equations
    from experiment
  id: totrans-2471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°å€¼æ¨¡æ‹Ÿæ•´åˆäº†å®éªŒä¸­çš„åˆ†æè¡¨è¾¾å¼å’Œæ ¡å‡†æ–¹ç¨‹
- en: '**Frequentist Probability**'
  id: totrans-2472
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢‘ç‡ä¸»ä¹‰æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): measure of the likelihood
    that an event will occur based on frequencies observed from an experiment. For
    random experiments and well-defined settings (such as coin tosses),'
  id: totrans-2473
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåŸºäºä»å®éªŒä¸­è§‚å¯Ÿåˆ°çš„é¢‘ç‡æ¥è¡¡é‡äº‹ä»¶å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚å¯¹äºéšæœºå®éªŒå’Œå®šä¹‰è‰¯å¥½çš„è®¾ç½®ï¼ˆä¾‹å¦‚æŠ›ç¡¬å¸ï¼‰ï¼Œ'
- en: \[ \text{Prob}(A) = P(A) = \lim_{n \to \infty} \frac{n(A)}{n} \]
  id: totrans-2474
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Prob}(A) = P(A) = \lim_{n \to \infty} \frac{n(A)}{n} \]
- en: 'where:'
  id: totrans-2475
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼š
- en: \(n(A)\) = number of times event \(A\) occurred \(n\) = number of trails
  id: totrans-2476
  prefs: []
  type: TYPE_NORMAL
  zh: \(n(A)\) = äº‹ä»¶ \(A\) å‘ç”Ÿçš„æ¬¡æ•° \(n\) = è¯•éªŒæ¬¡æ•°
- en: For example, possibility of drilling a dry hole for the next well, encountering
    sandstone at a location (\(\bf{u}_{\alpha}\)), exceeding a rock porosity of \(15
    \%\) at a location (\(\bf{u}_{\alpha}\)).
  id: totrans-2477
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œé’»æ¢ä¸‹ä¸€ä¸ªæ²¹äº•å¯èƒ½é‡åˆ°å¹²äº•çš„å¯èƒ½æ€§ï¼Œåœ¨ä½ç½® (\(\bf{u}_{\alpha}\)) é‡åˆ°ç ‚å²©ï¼Œåœ¨ä½ç½® (\(\bf{u}_{\alpha}\))
    è¶…è¿‡ \(15 \%\) çš„å²©çŸ³å­”éš™ç‡ã€‚
- en: '**Gaussian Anamorphosis**'
  id: totrans-2478
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é«˜æ–¯ç•¸å˜**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    quantile transformation to a Gaussian distribution.'
  id: totrans-2479
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šåˆ°é«˜æ–¯åˆ†å¸ƒçš„é‡æ•°å˜æ¢ã€‚'
- en: Mapping feature values through their cumulative probabilities.
  id: totrans-2480
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å®ƒä»¬çš„ç´¯ç§¯æ¦‚ç‡æ˜ å°„ç‰¹å¾å€¼ã€‚
- en: \[ y = G_y^{-1}\left( F_x(x)\right) \]
  id: totrans-2481
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = G_y^{-1}\left( F_x(x)\right) \]
- en: where \(ğ¹_ğ‘¥\) is the original feature cumulative distribution function (CDF)
    and \(ğº_ğ‘¦\) is the Gaussian CDF probability density function
  id: totrans-2482
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(ğ¹_ğ‘¥\) æ˜¯åŸå§‹ç‰¹å¾ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰å’Œ \(ğº_ğ‘¦\) æ˜¯é«˜æ–¯CDFæ¦‚ç‡å¯†åº¦å‡½æ•°
- en: \[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp \left[-1 \frac{1}{2} \left(\frac{x-\mu}{\sigma}
    \right)^2 \right] \]
  id: totrans-2483
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp \left[-1 \frac{1}{2} \left(\frac{x-\mu}{\sigma}
    \right)^2 \right] \]
- en: shorthand for a normal distribution is
  id: totrans-2484
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£æ€åˆ†å¸ƒçš„ç®€ç§°æ˜¯
- en: \[ N[\mu,\sigma^2] \]
  id: totrans-2485
  prefs: []
  type: TYPE_NORMAL
  zh: \[ N[\mu,\sigma^2] \]
- en: for example \(N[0,1]\) is standard normal
  id: totrans-2486
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ \(N[0,1]\) æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒ
- en: much of natural variation or measurement error is Gaussian
  id: totrans-2487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§éƒ¨åˆ†è‡ªç„¶å˜å¼‚æˆ–æµ‹é‡è¯¯å·®æ˜¯é«˜æ–¯åˆ†å¸ƒ
- en: parameterized fully by mean, variance and correlation coefficient (if multivariate)
  id: totrans-2488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®Œå…¨ç”±å‡å€¼ã€æ–¹å·®å’Œåæ–¹å·®ç³»æ•°ï¼ˆå¦‚æœå¤šå…ƒï¼‰å‚æ•°åŒ–
- en: distribution is unbounded, no min nor max, extremes are very unlikely, some
    type of truncation is often applied
  id: totrans-2489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒæ˜¯æ— ç•Œçš„ï¼Œæ²¡æœ‰æœ€å°å€¼ä¹Ÿæ²¡æœ‰æœ€å¤§å€¼ï¼Œæå€¼éå¸¸ä¸å¯èƒ½å‘ç”Ÿï¼Œé€šå¸¸åº”ç”¨æŸç§æˆªæ–­
- en: Warning, many workflows apply univariate Gaussian anamorphosis and then assume
    bivariate or multivariate Gaussian, this is not correct, but it is generally too
    difficult to transform our data to multivariate Gaussian.
  id: totrans-2490
  prefs: []
  type: TYPE_NORMAL
  zh: è­¦å‘Šï¼Œè®¸å¤šå·¥ä½œæµç¨‹åº”ç”¨å•å˜é‡é«˜æ–¯å˜å½¢ç„¶åå‡è®¾äºŒå…ƒæˆ–å¤šå…ƒé«˜æ–¯ï¼Œè¿™æ˜¯ä¸æ­£ç¡®çš„ï¼Œä½†é€šå¸¸å¾ˆéš¾å°†æˆ‘ä»¬çš„æ•°æ®è½¬æ¢ä¸ºå¤šå…ƒé«˜æ–¯ã€‚
- en: Methods that require a Gaussian distribution,
  id: totrans-2491
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦é«˜æ–¯åˆ†å¸ƒçš„æ–¹æ³•ï¼Œ
- en: Pearson product-moment correlation coefficients completely characterize multivariate
    relationships when data are multivariate Gaussian
  id: totrans-2492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çš®å°”é€Šç§¯çŸ©ç›¸å…³ç³»æ•°åœ¨æ•°æ®æ˜¯å¤šå…ƒé«˜æ–¯æ—¶å®Œå…¨æè¿°äº†å¤šå…ƒå…³ç³»
- en: partial correlations require bivariate Gaussian
  id: totrans-2493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éƒ¨åˆ†ç›¸å…³éœ€è¦äºŒå…ƒé«˜æ–¯
- en: sequential simulation (geostatistics) assumes Gaussian to reproduce the global
    distribution
  id: totrans-2494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¡ºåºæ¨¡æ‹Ÿï¼ˆåœ°ç»Ÿè®¡å­¦ï¼‰å‡è®¾é«˜æ–¯åˆ†å¸ƒä»¥å†ç°å…¨å±€åˆ†å¸ƒ
- en: Studentâ€™s t test for difference in means
  id: totrans-2495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦ç”Ÿtæ£€éªŒç”¨äºå‡å€¼å·®å¼‚
- en: Chi-square distributions is derived from sum of squares of Gaussian distributed
    random variables
  id: totrans-2496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¡æ–¹åˆ†å¸ƒæ˜¯ä»é«˜æ–¯åˆ†å¸ƒéšæœºå˜é‡çš„å¹³æ–¹å’Œå¯¼å‡ºçš„
- en: Gaussian naive Bayes classification assumes Gaussian conditionals
  id: totrans-2497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å‡è®¾é«˜æ–¯æ¡ä»¶
- en: '**Gibbs Sampler** (MCMC)'
  id: totrans-2498
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‰å¸ƒæ–¯é‡‡æ ·å™¨**ï¼ˆMCMCï¼‰'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a set of algorithms to sample from a probability distribution such that the samples
    match the distribution statistics, based on,'
  id: totrans-2499
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€å¥—ä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·çš„ç®—æ³•ï¼Œä½¿å¾—æ ·æœ¬åŒ¹é…åˆ†å¸ƒç»Ÿè®¡é‡ï¼ŒåŸºäºï¼Œ'
- en: sequentially sampling from conditional distributions
  id: totrans-2500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾æ¬¡ä»æ¡ä»¶åˆ†å¸ƒä¸­é‡‡æ ·
- en: Since only the conditional probability density functions are required, the system
    is simplified as the full joint probability density function is not needed
  id: totrans-2501
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåªéœ€è¦æ¡ä»¶æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œç³»ç»Ÿç®€åŒ–ä¸ºä¸éœ€è¦å®Œæ•´çš„è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°
- en: Hereâ€™s the basic steps of the Gibbs MCMC Sampler for a bivariate case,
  id: totrans-2502
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯äºŒå…ƒæƒ…å†µçš„å‰å¸ƒæ–¯MCMCé‡‡æ ·å™¨çš„åŸºæœ¬æ­¥éª¤ï¼Œ
- en: Assign random values for \(ğ‘‹(0)\), \(ğ‘Œ(0)\)
  id: totrans-2503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸º \(ğ‘‹(0)\)ã€\(ğ‘Œ(0)\) åˆ†é…éšæœºå€¼
- en: Sample from \(ğ‘“(ğ‘‹|ğ‘Œ(0))\) to get \(ğ‘‹(1)\)
  id: totrans-2504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä» \(ğ‘“(ğ‘‹|ğ‘Œ(0))\) ä¸­é‡‡æ ·ä»¥è·å¾— \(ğ‘‹(1)\)
- en: Sample from \(ğ‘“(ğ‘Œ|ğ‘‹(1))\) to get \(ğ‘Œ(1)\)
  id: totrans-2505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä» \(ğ‘“(ğ‘Œ|ğ‘‹(1))\) ä¸­é‡‡æ ·ä»¥è·å¾— \(ğ‘Œ(1)\)
- en: Repeat for the next steps for samples, \(\ell = 1,\ldots,ğ¿\)
  id: totrans-2506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹æ ·æœ¬é‡å¤ä¸‹ä¸€æ­¥ï¼Œ\(\ell = 1,\ldots,ğ¿\)
- en: The resulting samples will have the correct joint distribution,
  id: totrans-2507
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ ·æœ¬å°†å…·æœ‰æ­£ç¡®çš„è”åˆåˆ†å¸ƒï¼Œ
- en: \[ ğ‘“(ğ‘‹,ğ‘Œ) \]
  id: totrans-2508
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘“(ğ‘‹,ğ‘Œ) \]
- en: '**Gradient Boosting Models**'
  id: totrans-2509
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¢¯åº¦æå‡æ¨¡å‹**'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): a prediction model
    that results from posing a boosting model as gradient descent problem'
  id: totrans-2510
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šå°†æå‡æ¨¡å‹ä½œä¸ºæ¢¯åº¦ä¸‹é™é—®é¢˜æå‡ºçš„ç»“æœé¢„æµ‹æ¨¡å‹'
- en: At each step, \(k\), a model is being fit, then the error is calculated, \(h_k(X_1,\ldots,X_m)\).
  id: totrans-2511
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸€æ­¥ï¼Œ\(k\)ï¼Œæ­£åœ¨æ‹Ÿåˆä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åè®¡ç®—è¯¯å·®ï¼Œ\(h_k(X_1,\ldots,X_m)\)ã€‚
- en: We can assign a loss function,
  id: totrans-2512
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ†é…ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œ
- en: \[ L\left(y,F(X)\right) = \frac{\left(y - F(X)\right)^2}{2} \]
  id: totrans-2513
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L\left(y,F(X)\right) = \frac{\left(y - F(X)\right)^2}{2} \]
- en: 'So we want to minimize the \(\ell2\) loss function:'
  id: totrans-2514
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬æƒ³è¦æœ€å°åŒ– \(\ell2\) æŸå¤±å‡½æ•°ï¼š
- en: \[ J = \sum_{i=1}^{n} L\left(y_i, F_k(X) \right) \]
  id: totrans-2515
  prefs: []
  type: TYPE_NORMAL
  zh: \[ J = \sum_{i=1}^{n} L\left(y_i, F_k(X) \right) \]
- en: by adjusting our model result over our training data \(F(x_1), F(x_2),\ldots,F(x_n)\).
  id: totrans-2516
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è°ƒæ•´æˆ‘ä»¬çš„æ¨¡å‹ç»“æœæ¥é€‚åº”æˆ‘ä»¬çš„è®­ç»ƒæ•°æ® \(F(x_1), F(x_2),\ldots,F(x_n)\)ã€‚
- en: We can take the partial derivative of the error vs. our model,
  id: totrans-2517
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å–è¯¯å·®ç›¸å¯¹äºæˆ‘ä»¬æ¨¡å‹çš„åå¯¼æ•°ï¼Œ
- en: \[ \frac{\partial J}{\partial F(x_i)} = F(x_i) - y_i \]
  id: totrans-2518
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial J}{\partial F(x_i)} = F(x_i) - y_i \]
- en: We can interpret the residuals as negative gradients.
  id: totrans-2519
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†æ®‹å·®è§£é‡Šä¸ºè´Ÿæ¢¯åº¦ã€‚
- en: \[ y_i - F(x_i) = -1 \frac{\partial J}{\partial F(x_i)} \]
  id: totrans-2520
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i - F(x_i) = -1 \frac{\partial J}{\partial F(x_i)} \]
- en: 'So now we have a gradient descent problem:'
  id: totrans-2521
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªæ¢¯åº¦ä¸‹é™é—®é¢˜ï¼š
- en: \[ F_{k+1}(X_i) = F_k(X_i) + h(X_i) \]\[ F_{k+1}(X_i) = F_k(X_i) + y_i - F_k(X_i)
    \]\[ F_{k+1}(X_i) = F_k(X_i) - 1 \frac{\partial J}{\partial F_k(X_i)} \]
  id: totrans-2522
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_{k+1}(X_i) = F_k(X_i) + h(X_i) \]\[ F_{k+1}(X_i) = F_k(X_i) + y_i - F_k(X_i)
    \]\[ F_{k+1}(X_i) = F_k(X_i) - 1 \frac{\partial J}{\partial F_k(X_i)} \]
- en: 'Of the general form:'
  id: totrans-2523
  prefs: []
  type: TYPE_NORMAL
  zh: é€šç”¨å½¢å¼ä¸ºï¼š
- en: \[ \phi_{k+1} = \phi_k - \rho \frac{\partial J}{\partial \phi_k} \]
  id: totrans-2524
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi_{k+1} = \phi_k - \rho \frac{\partial J}{\partial \phi_k} \]
- en: where \(phi_k\) is the current state, \(\rho\) is the learning rate, \(J\) is
    the loss function, and \(\phi_{k+1}\) is the next state of our estimator.
  id: totrans-2525
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(phi_k\) æ˜¯å½“å‰çŠ¶æ€ï¼Œ\(\rho\) æ˜¯å­¦ä¹ ç‡ï¼Œ\(J\) æ˜¯æŸå¤±å‡½æ•°ï¼Œè€Œ \(\phi_{k+1}\) æ˜¯ä¼°è®¡å™¨çš„ä¸‹ä¸€ä¸ªçŠ¶æ€ã€‚
- en: The error residual at training data is the gradient, then we are performing
    gradient descent,
  id: totrans-2526
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®ä¸­çš„è¯¯å·®æ®‹å·®æ˜¯æ¢¯åº¦ï¼Œç„¶åæˆ‘ä»¬è¿›è¡Œæ¢¯åº¦ä¸‹é™ï¼Œ
- en: fitting a series of models to negative gradients
  id: totrans-2527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†ä¸€ç³»åˆ—æ¨¡å‹æ‹Ÿåˆåˆ°è´Ÿæ¢¯åº¦
- en: By approaching the problem as a gradient decent problem we are able to apply
    a variety of loss functions,
  id: totrans-2528
  prefs: []
  type: TYPE_NORMAL
  zh: å°†é—®é¢˜ä½œä¸ºæ¢¯åº¦ä¸‹é™é—®é¢˜æ¥å¤„ç†ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåº”ç”¨å„ç§æŸå¤±å‡½æ•°ï¼Œ
- en: \(\ell2\) is our \(\frac{\left(y - F(X)\right)^2}{2}\) is practical, but is
    not robust with outliers
  id: totrans-2529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\ell2\) æ˜¯æˆ‘ä»¬çš„ \(\frac{\left(y - F(X)\right)^2}{2}\)ï¼Œåœ¨å¤„ç†å®é™…é—®é¢˜æ—¶æ˜¯å¯è¡Œçš„ï¼Œä½†å¯¹å¤–éƒ¨å¼‚å¸¸å€¼ä¸å¤Ÿç¨³å¥
- en: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = y_i - F_k(X_i) \]
  id: totrans-2530
  prefs: []
  type: TYPE_NORMAL
  zh: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = y_i - F_k(X_i) \]
- en: \(\ell1\) is our \(|y - F(X)|\) is more robust with outliers
  id: totrans-2531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\ell1\) æ˜¯æˆ‘ä»¬çš„ \(|y - F(X)|\)ï¼Œå¯¹å¤–éƒ¨å¼‚å¸¸å€¼æ›´åŠ ç¨³å¥
- en: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = sign(y_i - F_k(X_i)) \]
  id: totrans-2532
  prefs: []
  type: TYPE_NORMAL
  zh: \[ - 1 \frac{\partial J}{\partial F_k(X_i)} = sign(y_i - F_k(X_i)) \]
- en: there are others like Huber Loss
  id: totrans-2533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿˜æœ‰å…¶ä»–ç±»ä¼¼Huber Loss
- en: '**Graph Laplacian** (spectral clustering)'
  id: totrans-2534
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å›¾æ‹‰æ™®æ‹‰æ–¯ç®—å­**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a matrix representing
    a graph by integrating connections between graph nodes, samples, number of connections
    for each graph nodes, samples. Calculated as degree matrix minus adjacency matrix.
    Where,'
  id: totrans-2535
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šé€šè¿‡æ•´åˆå›¾èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥æ¥è¡¨ç¤ºå›¾çš„çŸ©é˜µï¼ŒåŒ…æ‹¬æ¯ä¸ªå›¾èŠ‚ç‚¹å’Œæ ·æœ¬çš„è¿æ¥æ•°ã€‚è®¡ç®—ä¸ºåº¦çŸ©é˜µå‡å»é‚»æ¥çŸ©é˜µã€‚å…¶ä¸­ï¼Œ'
- en: '*degree matrix*, \(ğ·\) - degree of connection for each node'
  id: totrans-2536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åº¦çŸ©é˜µ* \(ğ·\) - æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥åº¦'
- en: adjacency matrix, \(ğ´\) - specific connections between nodes
  id: totrans-2537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‚»æ¥çŸ©é˜µï¼Œ\(ğ´\) - èŠ‚ç‚¹ä¹‹é—´çš„ç‰¹å®šè¿æ¥
- en: '**Geostatistics**'
  id: totrans-2538
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åœ°ç»Ÿè®¡å­¦**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a branch of applied
    statistics that integrates:'
  id: totrans-2539
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåº”ç”¨ç»Ÿè®¡å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒæ•´åˆäº†ï¼š'
- en: the spatial (geological) context
  id: totrans-2540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç©ºé—´ï¼ˆåœ°è´¨ï¼‰èƒŒæ™¯
- en: the spatial relationship
  id: totrans-2541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç©ºé—´å…³ç³»
- en: volumetric support / scale
  id: totrans-2542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½“ç§¯æ”¯æŒ/å°ºåº¦
- en: uncertainty
  id: totrans-2543
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§
- en: I include all spatial statistics with geostatistics, some disagree with me on
    this. From my experience, any useful statistical method for modeling spatial phenomenon
    is adopted and added to the geostatistics toolkit! Geostatistics is an expanding
    and evolving field of study.
  id: totrans-2544
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æ‰€æœ‰ç©ºé—´ç»Ÿè®¡ï¼ŒåŒ…æ‹¬åœ°ç»Ÿè®¡å­¦éƒ½åŒ…å«åœ¨å†…ï¼Œæœ‰äº›äººä¸åŒæ„æˆ‘çš„è§‚ç‚¹ã€‚æ ¹æ®æˆ‘çš„ç»éªŒï¼Œä»»ä½•æœ‰ç”¨çš„ç©ºé—´ç°è±¡å»ºæ¨¡ç»Ÿè®¡æ–¹æ³•éƒ½è¢«é‡‡ç”¨å¹¶æ·»åŠ åˆ°åœ°ç»Ÿè®¡å­¦å·¥å…·åŒ…ä¸­ï¼åœ°ç»Ÿè®¡å­¦æ˜¯ä¸€ä¸ªä¸æ–­å‘å±•å’Œæ¼”å˜çš„ç ”ç©¶é¢†åŸŸã€‚
- en: '**Gradient-based Optimization**'
  id: totrans-2545
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): a method to solve
    for model parameters by iteratively minimizing the loss function. The steps include,'
  id: totrans-2546
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šé€šè¿‡è¿­ä»£æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥æ±‚è§£æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚æ­¥éª¤åŒ…æ‹¬ï¼Œ'
- en: start with random model parameters
  id: totrans-2547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»éšæœºçš„æ¨¡å‹å‚æ•°å¼€å§‹
- en: calculate the loss function for the model parameters
  id: totrans-2548
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¨¡å‹å‚æ•°çš„æŸå¤±å‡½æ•°
- en: calculate the loss function gradient, generally donâ€™t have an equation for the
    loss function, sampling with numerical calculation of the local loss function
    derivative,
  id: totrans-2549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œé€šå¸¸æ²¡æœ‰æŸå¤±å‡½æ•°çš„æ–¹ç¨‹ï¼Œé€šè¿‡æ•°å€¼è®¡ç®—å±€éƒ¨æŸå¤±å‡½æ•°çš„å¯¼æ•°è¿›è¡Œé‡‡æ ·ï¼Œ
- en: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
  id: totrans-2550
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
- en: update the parameter estimate by stepping down slope / gradient,
  id: totrans-2551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡å‘ä¸‹æ­¥è¿›/æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ä¼°è®¡
- en: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
  id: totrans-2552
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
- en: where \(r\) is the learning rate/step size, \(\hat{b}(1,ğ‘¡)\), is the current
    model parameter estimate and \(\hat{b}(1,ğ‘¡+1)\) is the updated parameter estimate.
  id: totrans-2553
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(r\) æ˜¯å­¦ä¹ ç‡/æ­¥é•¿ï¼Œ\(\hat{b}(1,ğ‘¡)\) æ˜¯å½“å‰æ¨¡å‹å‚æ•°ä¼°è®¡ï¼Œè€Œ \(\hat{b}(1,ğ‘¡+1)\) æ˜¯æ›´æ–°çš„å‚æ•°ä¼°è®¡ã€‚
- en: Some important comments about gradient-based optimization,
  id: totrans-2554
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–çš„ä¸€äº›é‡è¦è¯„è®ºï¼Œ
- en: '*gradient search convergence* - the method will find a local or global minimum'
  id: totrans-2555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¢¯åº¦æœç´¢æ”¶æ•›* - è¯¥æ–¹æ³•å°†æ‰¾åˆ°ä¸€ä¸ªå±€éƒ¨æˆ–å…¨å±€æœ€å°å€¼'
- en: '*gradient search step size* - impact of step size, \(r\) too small, takes too
    long to converge to a solution and \(r\) too large, the solution may skip over/miss
    a global minimum or diverge'
  id: totrans-2556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¢¯åº¦æœç´¢æ­¥é•¿* - æ­¥é•¿çš„å½±å“ï¼Œ\(r\) å¤ªå°ï¼Œéœ€è¦å¤ªé•¿æ—¶é—´æ”¶æ•›åˆ°è§£ï¼Œè€Œ \(r\) å¤ªå¤§ï¼Œè§£å¯èƒ½ä¼šè·³è¿‡/é”™è¿‡å…¨å±€æœ€å°å€¼æˆ–å‘æ•£'
- en: '*multiple model parameters* - calculate and decompose the gradient over multiple
    model parameters, with a vector representation.'
  id: totrans-2557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šä¸ªæ¨¡å‹å‚æ•°* - åœ¨å¤šä¸ªæ¨¡å‹å‚æ•°ä¸Šè®¡ç®—å’Œåˆ†è§£æ¢¯åº¦ï¼Œä»¥å‘é‡å½¢å¼è¡¨ç¤ºã€‚'
- en: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1, b_2)) = \left[ \begin{matrix} \nabla
    L(y_{\alpha}, F(X_{\alpha}, b_1)) & \nabla L(y_{\alpha}, F(X_{\alpha}, b_2)) \end{matrix}
    \right] \]
  id: totrans-2558
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1, b_2)) = \left[ \begin{matrix} \nabla
    L(y_{\alpha}, F(X_{\alpha}, b_1)) & \nabla L(y_{\alpha}, F(X_{\alpha}, b_2)) \end{matrix}
    \right] \]
- en: '*exploration of parameter space* - optimization for training machine learning
    model parameters is exploration of a high dimensional model parameter space'
  id: totrans-2559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å‚æ•°ç©ºé—´æ¢ç´¢* - è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–æ˜¯æ¢ç´¢é«˜ç»´æ¨¡å‹å‚æ•°ç©ºé—´'
- en: '**Graph** (spectral clustering)'
  id: totrans-2560
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å›¾**ï¼ˆè°±èšç±»ï¼‰'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a diagram
    that represents data in an organized manner, each sample as a node with vertices
    indicating pairwise relationships between samples.'
  id: totrans-2561
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šä»¥æœ‰ç»„ç»‡çš„æ–¹å¼è¡¨ç¤ºæ•°æ®çš„å›¾è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬ä½œä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œé¡¶ç‚¹è¡¨ç¤ºæ ·æœ¬ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚'
- en: for an undirected graph, vertices are bidirectional, i.e., the connection is
    symmetric, both ways with the same strength
  id: totrans-2562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ— å‘å›¾ï¼Œé¡¶ç‚¹æ˜¯åŒå‘çš„ï¼Œå³è¿æ¥æ˜¯å¯¹ç§°çš„ï¼Œä¸¤ä¸ªæ–¹å‘å…·æœ‰ç›¸åŒçš„å¼ºåº¦
- en: '**Gridded Data**'
  id: totrans-2563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç½‘æ ¼æ•°æ®**'
- en: 'Machine Learning Workflow Construction and Coding: generally exhaustive, regularly
    spaced data over 2D or 3D, representing maps and models'
  id: totrans-2564
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šé€šå¸¸åœ¨ 2D æˆ– 3D ä¸Šå…·æœ‰è¯¦å°½ä¸”å‡åŒ€åˆ†å¸ƒçš„æ•°æ®ï¼Œä»£è¡¨åœ°å›¾å’Œæ¨¡å‹
- en: stored as a .csv comma delimited file, with \(ğ‘›_ğ‘¦\) rows and \(ğ‘›_ğ‘¥\) columns
  id: totrans-2565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥é€—å·åˆ†éš”çš„ .csv æ–‡ä»¶å½¢å¼å­˜å‚¨ï¼Œæœ‰ \(ğ‘›_ğ‘¦\) è¡Œå’Œ \(ğ‘›_ğ‘¥\) åˆ—
- en: may also be saved/loaded as also binary for a more compact, but not human readable
    file.
  id: totrans-2566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿå¯ä»¥ä¿å­˜/åŠ è½½ä¸ºäºŒè¿›åˆ¶æ ¼å¼ï¼Œä»¥æ›´ç´§å‡‘ï¼Œä½†ä¸æ˜¯äººç±»å¯è¯»çš„æ–‡ä»¶ã€‚
- en: commonly visualized directly, for example, matplotlibâ€™s imshow function, or
    as contour maps
  id: totrans-2567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ç›´æ¥å¯è§†åŒ–ï¼Œä¾‹å¦‚ï¼Œmatplotlib çš„ imshow å‡½æ•°ï¼Œæˆ–ä½œä¸ºç­‰é«˜çº¿å›¾
- en: '**Hard Data**'
  id: totrans-2568
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¡¬æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data that has a
    high degree of certainty, usually from a direct measurement from the rock'
  id: totrans-2569
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå…·æœ‰é«˜åº¦ç¡®å®šæ€§çš„æ•°æ®ï¼Œé€šå¸¸æ¥è‡ªå²©çŸ³çš„ç›´æ¥æµ‹é‡ã€‚'
- en: for example, well core-based and well log-based porosity and lithofacies
  id: totrans-2570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼ŒåŸºäºå²©å¿ƒå’ŒåŸºäºæµ‹äº•çš„å­”éš™åº¦å’Œå²©æ€§
- en: In general, hard data has high resolution (small scale, volume support), but
    with poor coverage (measure only an extremely small proportion of the population,
    for example,
  id: totrans-2571
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç¡¬æ•°æ®å…·æœ‰é«˜åˆ†è¾¨ç‡ï¼ˆå°å°ºåº¦ã€ä½“ç§¯æ”¯æŒï¼‰ï¼Œä½†è¦†ç›–ç‡è¾ƒå·®ï¼ˆä»…æµ‹é‡äººå£ä¸­çš„æå°æ¯”ä¾‹ï¼Œä¾‹å¦‚ï¼Œ
- en: '*Core coverage deepwater oil and gas* - well core only sample one five hundred
    millionth to one five billionth of a deepwater reservoir, assuming 3 inch diameter
    cores with 10% core coverage in vertical wells with 500 m to 1,500 m spacing'
  id: totrans-2572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–ç‡æ·±æµ·æ²¹æ°”* - å²©å¿ƒä»…é‡‡æ ·æ·±æµ·å‚¨é‡çš„äº”äº¿åˆ†ä¹‹ä¸€åˆ°äº”åäº¿åˆ†ä¹‹ä¸€ï¼Œå‡è®¾ 3 è‹±å¯¸ç›´å¾„å²©å¿ƒåœ¨å‚ç›´äº•ä¸­å…·æœ‰ 10% çš„å²©å¿ƒè¦†ç›–ç‡ï¼Œé—´è·ä¸º 500
    ç±³åˆ° 1500 ç±³'
- en: '*Core coverage mining grade control* - diamond drill hole cores sample one
    eight thousandth to one thirty thousandth of ore body, assuming HQ 63.5 mm diameter
    cores with 100% core coverage in vertical drill holes with 5 m to 10 m spacing'
  id: totrans-2573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ ¸å¿ƒè¦†ç›–ç‡é‡‡çŸ¿è´¨é‡æ§åˆ¶* - é’»å­”å²©å¿ƒæ ·æœ¬å çŸ¿çŸ³ä½“ç§¯çš„å…«åƒåˆ†ä¹‹ä¸€åˆ°ä¸‰ä¸‡åˆ†ä¹‹ä¸€ï¼Œå‡è®¾ HQ 63.5 æ¯«ç±³ç›´å¾„å²©å¿ƒåœ¨å‚ç›´é’»å­”ä¸­å…·æœ‰ 100% çš„å²©å¿ƒè¦†ç›–ç‡ï¼Œé—´è·ä¸º
    5 ç±³åˆ° 10 ç±³'
- en: '**Hermite Polynomials**'
  id: totrans-2574
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Hermite å¤šé¡¹å¼**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): a family
    of orthogonal polynomials on the real number line.'
  id: totrans-2575
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šåœ¨å®æ•°çº¿ä¸Šçš„æ­£äº¤å¤šé¡¹å¼æ—ã€‚'
- en: '| Order | Hermite Polynomial \(H_e(x)\) |'
  id: totrans-2576
  prefs: []
  type: TYPE_TB
  zh: '| é˜¶æ•° | Hermite å¤šé¡¹å¼ \(H_e(x)\) |'
- en: '| --- | --- |'
  id: totrans-2577
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0th Order | \(H_{e_0}(x) = 1\) |'
  id: totrans-2578
  prefs: []
  type: TYPE_TB
  zh: '| é›¶é˜¶ | \(H_{e_0}(x) = 1\) |'
- en: '| 1st Order | \(H_{e_1}(x) = x\) |'
  id: totrans-2579
  prefs: []
  type: TYPE_TB
  zh: '| ä¸€é˜¶ | \(H_{e_1}(x) = x\) |'
- en: '| 2nd Order | \(H_{e_2}(x) = x^2 - 1\) |'
  id: totrans-2580
  prefs: []
  type: TYPE_TB
  zh: '| äºŒé˜¶ | \(H_{e_2}(x) = x^2 - 1\) |'
- en: '| 3rd Order | \(H_{e_3}(x) = x^3 - 3x\) |'
  id: totrans-2581
  prefs: []
  type: TYPE_TB
  zh: '| ä¸‰é˜¶ | \(H_{e_3}(x) = x^3 - 3x\) |'
- en: '| 4th Order | \(H_{e_4}(x) = x^4 - 6x^2 + 3\) |'
  id: totrans-2582
  prefs: []
  type: TYPE_TB
  zh: '| å››é˜¶ | \(H_{e_4}(x) = x^4 - 6x^2 + 3\) |'
- en: These polynomials are orthogonal with respect to a weighting function,
  id: totrans-2583
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤šé¡¹å¼ç›¸å¯¹äºåŠ æƒå‡½æ•°æ˜¯æ­£äº¤çš„ï¼Œ
- en: \[ ğ‘¤(ğ‘¥)=ğ‘’^{âˆ’\frac{ğ‘¥^2}{2}} \]
  id: totrans-2584
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘¤(ğ‘¥)=ğ‘’^{âˆ’\frac{ğ‘¥^2}{2}} \]
- en: this is the standard Gaussian probability density function without the scaler,
    \(\frac{1}{\sqrt{2\pi}}\). The definition of orthogonality is stated as,
  id: totrans-2585
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ ‡å‡†é«˜æ–¯æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæ²¡æœ‰ç¼©æ”¾å› å­ï¼Œ\(\frac{1}{\sqrt{2\pi}}\)ã€‚æ­£äº¤æ€§çš„å®šä¹‰å¦‚ä¸‹ï¼Œ
- en: \[ \int_{-\infty}^{\infty} H_m(x) H_n(x) w(x) \, dx = 0 \]
  id: totrans-2586
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \int_{-\infty}^{\infty} H_m(x) H_n(x) w(x) \, dx = 0 \]
- en: The Hermite polynomials are orthogonal over the interval \([âˆ’\infty,\infty]\)
    for the standard normal probability distribution.
  id: totrans-2587
  prefs: []
  type: TYPE_NORMAL
  zh: åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼åœ¨æ ‡å‡†æ­£æ€æ¦‚ç‡åˆ†å¸ƒçš„åŒºé—´ \([âˆ’\infty,\infty]\) ä¸Šæ˜¯æ­£äº¤çš„ã€‚
- en: By applying hermite polynomials instead of regular polynomials for polynomial
    basis expansion in polynomial regression were remove the multicollinearity between
    the predictor features,
  id: totrans-2588
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šé¡¹å¼å›å½’ä¸­ï¼Œé€šè¿‡ä½¿ç”¨åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼è€Œä¸æ˜¯å¸¸è§„å¤šé¡¹å¼è¿›è¡Œå¤šé¡¹å¼åŸºæ‰©å±•ï¼Œæˆ‘ä»¬æ¶ˆé™¤äº†é¢„æµ‹ç‰¹å¾ä¹‹é—´çš„å¤šé‡å…±çº¿æ€§ï¼Œ
- en: recall, independence of the predictor features is an assumption of the linear
    system applied in polynomial regression with the polynomial basis expansion
  id: totrans-2589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å¿†ï¼Œé¢„æµ‹ç‰¹å¾ä¹‹é—´çš„ç‹¬ç«‹æ€§æ˜¯å¤šé¡¹å¼å›å½’ä¸­åº”ç”¨å¤šé¡¹å¼åŸºæ‰©å±•çš„çº¿æ€§ç³»ç»Ÿçš„ä¸€ä¸ªå‡è®¾
- en: '**Heuristic Algorithm**'
  id: totrans-2590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯å‘å¼ç®—æ³•**'
- en: 'Cluster Analysis: a shortcut solution to solve a difficult problem a compromise
    of optimality and accuracy for speed and practicality.'
  id: totrans-2591
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šè§£å†³å›°éš¾é—®é¢˜çš„å¿«æ·æ–¹æ³•ï¼Œåœ¨é€Ÿåº¦å’Œå®ç”¨æ€§æ–¹é¢å¯¹æœ€ä¼˜æ€§å’Œå‡†ç¡®æ€§åšå‡ºå¦¥åã€‚
- en: this general approach is common in machine learning, computer science and mathematical
    optimization, for example, the solution for k-mean clustering a \(k^n\) solution
    space is practically solved with an heuristic algorithm.
  id: totrans-2592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç§é€šç”¨æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ ã€è®¡ç®—æœºç§‘å­¦å’Œæ•°å­¦ä¼˜åŒ–ä¸­å¾ˆå¸¸è§ï¼Œä¾‹å¦‚ï¼Œkå‡å€¼èšç±»çš„ \(k^n\) è§£ç©ºé—´å®é™…ä¸Šæ˜¯é€šè¿‡å¯å‘å¼ç®—æ³•æ¥è§£å†³çš„ã€‚
- en: '**Hierarchical Clustering**'
  id: totrans-2593
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å±‚æ¬¡èšç±»**'
- en: 'Cluster Analysis: all cluster group assignments are determined iteratively,
    as opposed to an partitional clustering method that determine cluster groups all
    at once. Including,'
  id: totrans-2594
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šæ‰€æœ‰èšç±»åˆ†ç»„åˆ†é…éƒ½æ˜¯è¿­ä»£ç¡®å®šçš„ï¼Œä¸ä¸€æ¬¡ç¡®å®šæ‰€æœ‰èšç±»åˆ†ç»„çš„åˆ’åˆ†èšç±»æ–¹æ³•ç›¸åã€‚åŒ…æ‹¬ï¼Œ
- en: '*agglomerative hierarchical clustering* - start with \(n\) clusters, each data
    sample in its own cluster, and then iteratively merges clusters into larger clusters'
  id: totrans-2595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*èšåˆå±‚æ¬¡èšç±»* - ä» \(n\) ä¸ªèšç±»å¼€å§‹ï¼Œæ¯ä¸ªæ•°æ®æ ·æœ¬åœ¨å…¶è‡ªå·±çš„èšç±»ä¸­ï¼Œç„¶åè¿­ä»£åœ°å°†èšç±»åˆå¹¶æˆæ›´å¤§çš„èšç±»'
- en: '*divisive hierarchical clustering* - start with all data in one cluster, and
    then iteratively divide off new clusters'
  id: totrans-2596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åˆ’åˆ†å±‚æ¬¡èšç±»* - ä»ä¸€ä¸ªåŒ…å«æ‰€æœ‰æ•°æ®çš„å•ä¸ªèšç±»å¼€å§‹ï¼Œç„¶åè¿­ä»£åœ°åˆ’åˆ†å‡ºæ–°çš„èšç±»'
- en: k-means clustering is partitional clustering, while the solution heuristic to
    find the solution is iterative, the solution is actually all at once
  id: totrans-2597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kå‡å€¼èšç±»æ˜¯åˆ’åˆ†èšç±»ï¼Œè€Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„å¯å‘å¼æ–¹æ³•æ˜¯è¿­ä»£çš„ï¼Œä½†å®é™…ä¸Šè§£å†³æ–¹æ¡ˆæ˜¯ä¸€æ¬¡æ€§å®Œæˆçš„
- en: difficult to update, once a series of splits or mergers are made it is difficult
    to go back and modify the model
  id: totrans-2598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¾ˆéš¾æ›´æ–°ï¼Œä¸€æ—¦è¿›è¡Œäº†ä¸€ç³»åˆ—çš„åˆ†å‰²æˆ–åˆå¹¶ï¼Œå°±å¾ˆéš¾è¿”å›å¹¶ä¿®æ”¹æ¨¡å‹
- en: '**Histogram**'
  id: totrans-2599
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç›´æ–¹å›¾**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): a representation
    of the univariate statistical distribution with a plot of frequency over an exhaustive
    set of bins over the range of possible values. These are the steps to build a
    histogram,'
  id: totrans-2600
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šé€šè¿‡åœ¨å¯èƒ½å€¼çš„èŒƒå›´å†…å¯¹ä¸€ç³»åˆ—ç®±å­çš„é¢‘ç‡è¿›è¡Œç»˜åˆ¶æ¥è¡¨ç¤ºå•å˜é‡ç»Ÿè®¡åˆ†å¸ƒã€‚æ„å»ºç›´æ–¹å›¾çš„æ­¥éª¤å¦‚ä¸‹ï¼Œ'
- en: 'Divide the continuous feature range of possible values into \(K\) equal size
    bins, \(\delta x\):'
  id: totrans-2601
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å°†å¯èƒ½å€¼çš„è¿ç»­ç‰¹å¾èŒƒå›´åˆ’åˆ†ä¸º \(K\) ä¸ªç›¸ç­‰å¤§å°çš„ç®±å­ï¼Œ\(\delta x\):'
- en: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
  id: totrans-2602
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
- en: or use available category labels for categorical features.
  id: totrans-2603
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ä½¿ç”¨å¯ç”¨çš„ç±»åˆ«æ ‡ç­¾è¿›è¡Œåˆ†ç±»ç‰¹å¾ã€‚
- en: Count the number of samples (frequency) in each bin, \(n_k\), \quad \(\forall
    \quad k=1,\ldots,K\).
  id: totrans-2604
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯ä¸ªç®±å­ä¸­çš„æ ·æœ¬æ•°ï¼ˆé¢‘ç‡ï¼‰ï¼Œ\(n_k\)ï¼Œ \quad \(\forall \quad k=1,\ldots,K\).
- en: Plot the frequency vs. the bin label (use bin centroid if continuous)
  id: totrans-2605
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶é¢‘ç‡ä¸ç®±æ ‡ç­¾çš„å…³ç³»å›¾ï¼ˆå¦‚æœè¿ç»­ï¼Œåˆ™ä½¿ç”¨ç®±ä¸­å¿ƒç‚¹ï¼‰
- en: Note, histograms are typically plotted as a bar chart.
  id: totrans-2606
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç›´æ–¹å›¾é€šå¸¸ä»¥æŸ±çŠ¶å›¾çš„å½¢å¼ç»˜åˆ¶ã€‚
- en: '**Hybrid Model**'
  id: totrans-2607
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ··åˆæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): system or process
    that includes a combination of both *deterministic model* and *stochastic model*'
  id: totrans-2608
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåŒ…æ‹¬ç¡®å®šæ€§æ¨¡å‹å’Œéšæœºæ¨¡å‹ç»„åˆçš„ç³»ç»Ÿæˆ–è¿‡ç¨‹'
- en: most geostatistical models are hybrid models
  id: totrans-2609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°åœ°ç»Ÿè®¡æ¨¡å‹éƒ½æ˜¯æ··åˆæ¨¡å‹
- en: for example, additive deterministic trend models and stochastic residual models
  id: totrans-2610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼ŒåŠ æ€§ç¡®å®šæ€§è¶‹åŠ¿æ¨¡å‹å’Œéšæœºæ®‹å·®æ¨¡å‹
- en: '**Independence** (probability)'
  id: totrans-2611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‹¬ç«‹æ€§**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): events \(A\) and
    \(B\) are independent if and only if the following relations are true,'
  id: totrans-2612
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šäº‹ä»¶ \(A\) å’Œ \(B\) ç‹¬ç«‹å½“ä¸”ä»…å½“ä»¥ä¸‹å…³ç³»æˆç«‹ï¼Œ'
- en: \(P(A \cap B) = P(A) \cdot P(B)\)
  id: totrans-2613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(P(A \cap B) = P(A) \cdot P(B)\)
- en: \(P(A|B) = P(A)\)
  id: totrans-2614
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(P(A|B) = P(A)\)
- en: \(P(B|A) = P(B)\)
  id: totrans-2615
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(P(B|A) = P(B)\)
- en: If any of these are violated we suspect that there exists some form of relationship.
  id: totrans-2616
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå…¶ä¸­ä»»ä½•ä¸€é¡¹è¿åï¼Œæˆ‘ä»¬æ€€ç–‘å­˜åœ¨æŸç§å½¢å¼çš„å…³ç³»ã€‚
- en: '**Indicator Transform** (also Binary Transform)'
  id: totrans-2617
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŒ‡ç¤ºå˜æ¢**ï¼ˆä¹Ÿç§°ä¸ºäºŒå€¼å˜æ¢ï¼‰'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): indicator
    coding a random variable to a probability relative to a category or a threshold.'
  id: totrans-2618
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šå°†éšæœºå˜é‡æŒ‡ç¤ºç¼–ç ä¸ºç›¸å¯¹äºç±»åˆ«æˆ–é˜ˆå€¼çš„æ¦‚ç‡ã€‚'
- en: If \(i(\bf{u}:z_k)\) is an indicator for a categorical variable,
  id: totrans-2619
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(i(\bf{u}:z_k)\) æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡çš„æŒ‡ç¤ºç¬¦ï¼Œ
- en: what is the probability of a realization equal to a category?
  id: totrans-2620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°ç­‰äºç±»åˆ«çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
  id: totrans-2621
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) = z_k
    \\ 0, & \text{if } Z(\bf{u}) \ne z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-2622
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_2 = 2\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 2\),
    then \(i(bf{u}_1; z_2) = 1\)
  id: totrans-2623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_2 = 2\%\)ï¼Œä»¥åŠæ•°æ®åœ¨ \(\bf{u}_1\) å¤„ï¼Œ\(z(\bf{u}_1) = 2\%\)ï¼Œåˆ™ \(i(\bf{u}_1;
    z_2) = 1\)
- en: given threshold, \(z_1 = 1\), and a RV away from data, \(Z(\bf{u}_2)\) then
    is calculated as \(F^{-1}_{\bf{u}_2}(z_1)\) of the RV as \(i(\bf{u}_2; z_1) =
    0.23\)
  id: totrans-2624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 1\%\)ï¼Œä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ \(Z(\bf{u}_2)\)ï¼Œåˆ™è®¡ç®—ä¸º \(F^{-1}_{\bf{u}_2}(z_1)\)
    çš„éšæœºå˜é‡ï¼Œ\(i(\bf{u}_2; z_1) = 0.23\)
- en: If \(i(\bf{u}:z_k)\) is an indicator for a continuous variable,
  id: totrans-2625
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(i(\bf{u}:z_k)\) æ˜¯ä¸€ä¸ªè¿ç»­å˜é‡çš„æŒ‡ç¤ºç¬¦ï¼Œ
- en: what is the probability of a realization less than or equal to a threshold?
  id: totrans-2626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç°å°äºæˆ–ç­‰äºé˜ˆå€¼çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
  id: totrans-2627
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} i(\bf{u}; z_k) = \begin{cases} 1, & \text{if } Z(\bf{u}) \le
    z_k \\ 0, & \text{if } Z(\bf{u}) > z_k \end{cases} \end{split}\]
- en: for example,
  id: totrans-2628
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ
- en: given threshold, \(z_1 = 6\%\), and data at \(\bf{u}_1\), \(z(\bf{u}_1) = 8\%\),
    then \(i(\bf{u}_1; z_1) = 0\)
  id: totrans-2629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_1 = 6\%\)ï¼Œä»¥åŠæ•°æ®åœ¨ \(\bf{u}_1\) å¤„ï¼Œ\(z(\bf{u}_1) = 8\%\)ï¼Œåˆ™ \(i(\bf{u}_1;
    z_1) = 0\)
- en: given threshold, \(z_4 = 18\%\), and a RV away from data, \(Z(\bf{u}_2) = N\left[\mu
    = 16\%,\sigma = 3\%\right]\) then \(i(\bf{u}_2; z_4) = 0.75\)
  id: totrans-2630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé˜ˆå€¼ï¼Œ\(z_4 = 18\%\)ï¼Œä»¥åŠä¸€ä¸ªè¿œç¦»æ•°æ®çš„éšæœºå˜é‡ï¼Œ\(Z(\bf{u}_2) = N\left[\mu = 16\%,\sigma =
    3\%\right]\)ï¼Œåˆ™ \(i(\bf{u}_2; z_4) = 0.75\)
- en: The indicator coding may be applied over an entire random function by indicator
    transform of all the random variables at each location.
  id: totrans-2631
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡ç¤ºç¼–ç å¯ä»¥é€šè¿‡åœ¨æ¯ä¸ªä½ç½®çš„éšæœºå˜é‡çš„æŒ‡ç¤ºå˜æ¢åº”ç”¨äºæ•´ä¸ªéšæœºå‡½æ•°ã€‚
- en: '**Indicator Variogram**'
  id: totrans-2632
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŒ‡ç¤ºå˜å¼‚å›¾**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): varogramâ€™s
    calculated and modelled from the *indicator transform* of spatial data and used
    for indicator kriging. The indicator variogram is,'
  id: totrans-2633
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä»ç©ºé—´æ•°æ®çš„æŒ‡ç¤ºå˜æ¢ä¸­è®¡ç®—å’Œå»ºæ¨¡çš„å˜å¼‚å›¾ï¼Œç”¨äºæŒ‡ç¤ºå…‹ç«‹æ ¼ã€‚æŒ‡ç¤ºå˜å¼‚å›¾æ˜¯ï¼Œ'
- en: \[ \gamma_i(\mathbf{h}; z_k) = \frac{1}{2N(\mathbf{h})} \sum_{\alpha=1}^{N(\mathbf{h})}
    \left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h}; z_k) \right]^2
    \]
  id: totrans-2634
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \gamma_i(\mathbf{h}; z_k) = \frac{1}{2N(\mathbf{h})} \sum_{\alpha=1}^{N(\mathbf{h})}
    \left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h}; z_k) \right]^2
    \]
- en: where \(i(\mathbf{u}_\alpha; z_k)\) and \(i(\mathbf{u}_\alpha + \mathbf{h};
    z_k)\) are the indicator transforms for the \(z_k\) threshold at the tail location
    \(\mathbf{u}_\alpha\) and head location \(\mathbf{u}_\alpha + \mathbf{h}\) respectively.
  id: totrans-2635
  prefs: []
  type: TYPE_NORMAL
  zh: \(i(\mathbf{u}_\alpha; z_k)\) å’Œ \(i(\mathbf{u}_\alpha + \mathbf{h}; z_k)\) åˆ†åˆ«æ˜¯å°¾éƒ¨ä½ç½®
    \(\mathbf{u}_\alpha\) å’Œå¤´éƒ¨ä½ç½® \(\mathbf{u}_\alpha + \mathbf{h}\) å¤„çš„ \(z_k\) é˜ˆå€¼çš„æŒ‡ç¤ºå˜æ¢ã€‚
- en: for hard data the indicator transform \(i(\bf{u},z_k)\) is either 0 or 1, in
    which case the \(\left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha + \mathbf{h};
    z_k) \right]^2\) is equal to 0 when the values at head and tail are both \(\le
    z_k\) (for continuous features) or \(= z_k\) (for categorical features), the same
    relative to the threshold, or 1 when they are different.
  id: totrans-2636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç¡¬æ•°æ®ï¼ŒæŒ‡ç¤ºå˜æ¢ \(i(\bf{u},z_k)\) è¦ä¹ˆæ˜¯ 0 è¦ä¹ˆæ˜¯ 1ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“å¤´éƒ¨å’Œå°¾éƒ¨çš„å€¼éƒ½ \(\le z_k\)ï¼ˆå¯¹äºè¿ç»­ç‰¹å¾ï¼‰æˆ–
    \(= z_k\)ï¼ˆå¯¹äºåˆ†ç±»ç‰¹å¾ï¼‰æ—¶ï¼Œ\(\left[ i(\mathbf{u}_\alpha; z_k) - i(\mathbf{u}_\alpha +
    \mathbf{h}; z_k) \right]^2\) ç­‰äº 0ï¼Œç›¸å¯¹äºé˜ˆå€¼ç›¸åŒï¼Œæˆ–è€…å½“å®ƒä»¬ä¸åŒæ—¶ä¸º 1ã€‚
- en: therefore, the indicator variogram is \(\frac{1}{2}\) the proportion of pairs
    that change! The indicator variogram can be related to probability of change over
    a lag distance, \(h\).
  id: totrans-2637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒæŒ‡ç¤ºå˜å¼‚å›¾æ˜¯å˜åŒ–å¯¹çš„æ¯”ä¾‹çš„ä¸€åŠï¼æŒ‡ç¤ºå˜å¼‚å›¾å¯ä»¥ä¸æ»åè·ç¦» \(h\) ä¸Šå˜åŒ–çš„æ¦‚ç‡ç›¸å…³ã€‚
- en: the sill of an indicator variogram is the indicator variance calculated as,
  id: totrans-2638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒ‡ç¤ºå˜å¼‚å›¾çš„åŸºå°æ˜¯æŒ‰ç…§ä»¥ä¸‹æ–¹å¼è®¡ç®—çš„æŒ‡ç¤ºæ–¹å·®ï¼Œ
- en: \[ \sigma_i^2 = p \cdot (1 - p) \]
  id: totrans-2639
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_i^2 = p \cdot (1 - p) \]
- en: where \(p\) is the proportion of 1â€™s (or zeros as the function is symmetric
    over proportion)
  id: totrans-2640
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(p\) æ˜¯ 1 çš„æ¯”ä¾‹ï¼ˆæˆ–é›¶ï¼Œå› ä¸ºå‡½æ•°åœ¨æ¯”ä¾‹ä¸Šæ˜¯å¯¹ç§°çš„ï¼‰
- en: '**Inference, Inferential Statistics**'
  id: totrans-2641
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨ç†ï¼Œæ¨æ–­ç»Ÿè®¡å­¦**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): this is a big topic,
    but for the course I provide this simplified, functional definition, given a random
    sample from a population, describe the population, for example,'
  id: totrans-2642
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šè¿™æ˜¯ä¸€ä¸ªå¤§ä¸»é¢˜ï¼Œä½†ä¸ºäº†è¯¾ç¨‹ï¼Œæˆ‘æä¾›äº†è¿™ä¸ªç®€åŒ–çš„ã€åŠŸèƒ½æ€§çš„å®šä¹‰ï¼Œç»™å®šæ¥è‡ªæ€»ä½“çš„éšæœºæ ·æœ¬ï¼Œæè¿°æ€»ä½“ï¼Œä¾‹å¦‚ï¼Œ'
- en: given the well samples, describe the reservoir
  id: totrans-2643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šäº•æ ·ï¼Œæè¿°å‚¨å±‚
- en: given the drill hole samples, describe the ore body
  id: totrans-2644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé’»å­”æ ·æœ¬ï¼Œæè¿°çŸ¿çŸ³ä½“
- en: '**Inlier**'
  id: totrans-2645
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å†…ç‚¹**'
- en: a regression model accuracy metric, the proportion of testing data within a
    margin, \(\epsilon\), of the model predictions, \(\hat{y}_i\),
  id: totrans-2646
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå›å½’æ¨¡å‹å‡†ç¡®åº¦æŒ‡æ ‡ï¼Œè¡¨ç¤ºåœ¨æ¨¡å‹é¢„æµ‹ \(\hat{y}_i\) çš„ \(\epsilon\) è¾¹ç•Œå†…çš„æµ‹è¯•æ•°æ®æ¯”ä¾‹ï¼Œ
- en: \[ I_R = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} I(y_i, \hat{y}_i)
    \]
  id: totrans-2647
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I_R = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} I(y_i, \hat{y}_i)
    \]
- en: given the indicator transform,
  id: totrans-2648
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šæŒ‡ç¤ºå˜æ¢ï¼Œ
- en: \[\begin{split} I(y_i, \hat{y}_i) = \begin{cases} 1, & \text{if } |y_i - \hat{y}_i|
    \leq \epsilon \\ 0, & \text{otherwise} \end{cases} \end{split}\]
  id: totrans-2649
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} I(y_i, \hat{y}_i) = \begin{cases} 1, & \text{if } |y_i - \hat{y}_i|
    \leq \epsilon \\ 0, & \text{otherwise} \end{cases} \end{split}\]
- en: This is a useful, intuitive measure of accuracy, the proportion of training
    or testing data with predictions that are good enough.
  id: totrans-2650
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ç›´è§‚å‡†ç¡®åº¦åº¦é‡ï¼Œè¡¨ç¤ºå…·æœ‰è¶³å¤Ÿå¥½çš„é¢„æµ‹çš„è®­ç»ƒæˆ–æµ‹è¯•æ•°æ®æ¯”ä¾‹ã€‚
- en: but, there is a choice of the size of the margin, \(\epsilon\), that could be
    related to the accuracy required for the specific application
  id: totrans-2651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œå­˜åœ¨é€‰æ‹©è¾¹ç•Œå¤§å° \(\epsilon\) çš„é€‰æ‹©ï¼Œè¿™å¯èƒ½ä¸ç‰¹å®šåº”ç”¨çš„å‡†ç¡®åº¦è¦æ±‚æœ‰å…³
- en: '**Instance-based Learning**'
  id: totrans-2652
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå®ä¾‹çš„å­¦ä¹ **'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): also known
    as memory-based learning, compares new prediction problems (as set of predictors,
    \(ğ‘¥_1,\ldots,ğ‘¥_ğ‘š\)) with the cases observed in the training data.'
  id: totrans-2653
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šä¹Ÿç§°ä¸ºåŸºäºè®°å¿†çš„å­¦ä¹ ï¼Œæ¯”è¾ƒæ–°çš„é¢„æµ‹é—®é¢˜ï¼ˆä½œä¸ºé¢„æµ‹å™¨é›†åˆï¼Œ\(ğ‘¥_1,\ldots,ğ‘¥_ğ‘š\))ä¸è®­ç»ƒæ•°æ®ä¸­è§‚å¯Ÿåˆ°çš„æ¡ˆä¾‹ã€‚'
- en: model requires access to the training data, acting as a library of observations
  id: totrans-2654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹éœ€è¦è®¿é—®è®­ç»ƒæ•°æ®ï¼Œå……å½“è§‚å¯Ÿçš„åº“
- en: prediction directly from the training data
  id: totrans-2655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´æ¥ä»è®­ç»ƒæ•°æ®ä¸­è¿›è¡Œé¢„æµ‹
- en: prediction complexity grows with the number of training data, \(ğ‘›\), number
    of neighbors, \(ğ‘˜\), and number of features, \(ğ‘š\).
  id: totrans-2656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹å¤æ‚æ€§éšç€è®­ç»ƒæ•°æ®æ•°é‡ \(ğ‘›\)ã€é‚»å±…æ•°é‡ \(ğ‘˜\) å’Œç‰¹å¾æ•°é‡ \(ğ‘š\) çš„å¢åŠ è€Œå¢é•¿ã€‚
- en: a specific case of lazy learning
  id: totrans-2657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‡’æƒ°å­¦ä¹ çš„ç‰¹å®šæƒ…å†µ
- en: '**Intersection of Events** (probability)'
  id: totrans-2658
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº‹ä»¶äº¤é›†**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the intersection
    of outcomes, the probability of \(A\) and \(B\) is represented as,'
  id: totrans-2659
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šç»“æœçš„äº¤é›†ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ'
- en: \[ P(A \cap B) = P(A,B) \]
  id: totrans-2660
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) \]
- en: under the assumption of independence of \(A\) and \(B\) the probability of \(A\)
    and \(B\) is,
  id: totrans-2661
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ \(A\) å’Œ \(B\) ç‹¬ç«‹æ€§çš„å‡è®¾ä¸‹ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡æ˜¯ï¼Œ
- en: \[ P(A,B) = P(A) \cdot P(B) \]
  id: totrans-2662
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = P(A) \cdot P(B) \]
- en: '**Irreducible Error**'
  id: totrans-2663
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸å¯å‡å°‘è¯¯å·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is error due to
    data limitations, including missing features and missing samples, for example,
    the full predictor feature space is not adequately sampled'
  id: totrans-2664
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯ç”±äºæ•°æ®é™åˆ¶é€ æˆçš„é”™è¯¯ï¼ŒåŒ…æ‹¬ç¼ºå¤±ç‰¹å¾å’Œç¼ºå¤±æ ·æœ¬ï¼Œä¾‹å¦‚ï¼Œå®Œæ•´çš„é¢„æµ‹ç‰¹å¾ç©ºé—´æ²¡æœ‰å¾—åˆ°å……åˆ†çš„é‡‡æ ·'
- en: irreducible error is not impacted by model complexity, it is a limitation of
    the data
  id: totrans-2665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å¯å‡å°‘è¯¯å·®ä¸å—æ¨¡å‹å¤æ‚æ€§çš„å½±å“ï¼Œå®ƒæ˜¯æ•°æ®çš„ä¸€ä¸ªé™åˆ¶
- en: one of the three components of expected test square error, including model variance,
    model bias and irreducible error
  id: totrans-2666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æ¨¡å‹æ–¹å·®ã€æ¨¡å‹åå·®å’Œä¸å¯å‡å°‘è¯¯å·®
- en: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
  id: totrans-2667
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \] \[
    E \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
- en: where \(\sigma_e^2\) is irreducible error.
  id: totrans-2668
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma_e^2\) æ˜¯ä¸å¯å‡å°‘è¯¯å·®ã€‚
- en: '**Inertia** (clustering)'
  id: totrans-2669
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æƒ¯æ€§**ï¼ˆèšç±»ï¼‰'
- en: 'Cluster Analysis: the k-means clustering loss function summarizing the difference
    between samples within the same group over all the groups,'
  id: totrans-2670
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šk-å‡å€¼èšç±»æŸå¤±å‡½æ•°æ€»ç»“äº†æ‰€æœ‰ç»„å†…æ ·æœ¬ä¹‹é—´çš„å·®å¼‚ï¼Œ
- en: \[ I = \sum_{i=1}^{K} \sum_{x_j \in C_i} \| x_j - \mu_i \|^2 \]
  id: totrans-2671
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I = \sum_{i=1}^{K} \sum_{x_j \in C_i} \| x_j - \mu_i \|^2 \]
- en: where \(K\) is the total number of clusters, \(C_i\) represents the set of samples
    in the \(i^{th}\) cluster, \(x_j\) represents a data sample in cluster, \(C_i\),
    \(mu_i\) is the prototype of cluster \(C_i\),\(\| x_j - \mu_i \|^2\) is the squared
    Euclidean distance between sample \(x_j\) and the cluster prototype \(\mu_i \).
    The samples and prototypes and distance calculations in mD space, with \(1,\ldots,m\)
    features.
  id: totrans-2672
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(K\) æ˜¯ç°‡çš„æ€»æ•°ï¼Œ\(C_i\) ä»£è¡¨ç¬¬ \(i\) ä¸ªç°‡ä¸­çš„æ ·æœ¬é›†ï¼Œ\(x_j\) ä»£è¡¨ç°‡ \(C_i\) ä¸­çš„æ•°æ®æ ·æœ¬ï¼Œ\(\mu_i\)
    æ˜¯ç°‡ \(C_i\) çš„åŸå‹ï¼Œ\(\| x_j - \mu_i \|^2\) æ˜¯æ ·æœ¬ \(x_j\) ä¸ç°‡åŸå‹ \(\mu_i\) ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»çš„å¹³æ–¹ã€‚åœ¨
    mD ç©ºé—´ä¸­ï¼Œå¯¹æ ·æœ¬å’ŒåŸå‹ä»¥åŠè·ç¦»è¿›è¡Œè®¡ç®—ï¼Œå…·æœ‰ \(1,\ldots,m\) ä¸ªç‰¹å¾ã€‚
- en: by minimizing inertia k-means clusters minimizes difference within groups while
    maximizing difference between groups
  id: totrans-2673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡æœ€å°åŒ–æƒ¯æ€§ï¼Œk-means ç°‡æœ€å°åŒ–ç»„å†…å·®å¼‚ï¼ŒåŒæ—¶æœ€å¤§åŒ–ç»„é—´å·®å¼‚
- en: '**Joint Probability**'
  id: totrans-2674
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è”åˆæ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): probability that
    considers more than one event occurring together, the probability of \(A\) and
    \(B\) is represented as,'
  id: totrans-2675
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šè€ƒè™‘å¤šä¸ªäº‹ä»¶åŒæ—¶å‘ç”Ÿçš„æ¦‚ç‡ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ'
- en: \[ P(A \cap B) = P(A,B) \]
  id: totrans-2676
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) \]
- en: or the probability of \(A\), \(B\) and \(C\) is represented as,
  id: totrans-2677
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€… \(A\)ã€\(B\) å’Œ \(C\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ
- en: \[ P(A \cap B \cap C) = P(A,B,C) \]
  id: totrans-2678
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B \cap C) = P(A,B,C) \]
- en: under the assumption of independence of \(A\), \(B\) and \(C\) the joint probability
    may be calculated as,
  id: totrans-2679
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡è®¾ \(A\)ã€\(B\) å’Œ \(C\) ç‹¬ç«‹çš„æƒ…å†µä¸‹ï¼Œè”åˆæ¦‚ç‡å¯ä»¥è®¡ç®—ä¸ºï¼Œ
- en: \[ P(A,B,C) = P(A) \cdot P(B) \cdot P(C) \]
  id: totrans-2680
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B,C) = P(A) \cdot P(B) \cdot P(C) \]
- en: '**K Bins Discretization**'
  id: totrans-2681
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**K ä¸ªåŒºé—´ç¦»æ•£åŒ–**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): bin
    the range of the feature into K bins, then for each sample assignment of a value
    of 1 if the sample is within a bin and 0 if outsize the bin'
  id: totrans-2682
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šå°†ç‰¹å¾çš„å–å€¼èŒƒå›´åˆ’åˆ†ä¸º K ä¸ªåŒºé—´ï¼Œç„¶åå¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œå¦‚æœæ ·æœ¬ä½äºåŒºé—´å†…åˆ™åˆ†é…å€¼ä¸º
    1ï¼Œå¦‚æœä¸åœ¨åŒºé—´å†…åˆ™åˆ†é…å€¼ä¸º 0'
- en: binning strategies include uniform width bins (uniform) and uniform number of
    data in each bin (quantile)
  id: totrans-2683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç®±ç­–ç•¥åŒ…æ‹¬å‡åŒ€å®½åº¦åˆ†ç®±ï¼ˆå‡åŒ€ï¼‰å’Œæ¯ä¸ªåˆ†ç®±ä¸­å‡åŒ€æ•°é‡çš„æ•°æ®ï¼ˆåˆ†ä½æ•°ï¼‰
- en: also known as one hot encoding
  id: totrans-2684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿç§°ä¸ºç‹¬çƒ­ç¼–ç 
- en: Methods that require K bins discretization,
  id: totrans-2685
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦Kä¸ªåŒºé—´ç¦»æ•£åŒ–çš„æ–¹æ³•ï¼Œ
- en: basis expansion to work in a higher dimensional space
  id: totrans-2686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºç¡€æ‰©å±•ä»¥åœ¨æ›´é«˜ç»´ç©ºé—´ä¸­å·¥ä½œ
- en: discretization of continuous features to categorical features for categorical
    methods such as naive Bayes classifier
  id: totrans-2687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºåˆ†ç±»ç‰¹å¾ï¼Œç”¨äºåˆ†ç±»æ–¹æ³•ï¼Œå¦‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
- en: histogram construction and Chi-square test for difference in distributions
  id: totrans-2688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„å»ºç›´æ–¹å›¾å’Œå¡æ–¹æ£€éªŒä»¥æ¯”è¾ƒåˆ†å¸ƒå·®å¼‚
- en: mutual information binning
  id: totrans-2689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº’ä¿¡æ¯åˆ†ç®±
- en: '**K-fold Cross Validation**'
  id: totrans-2690
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**K é‡äº¤å‰éªŒè¯**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): partitioning the
    data into K folds, and looping over the folds training the model with reminder
    of the data and testing the model with the data in the fold. Then aggregating
    the testing accuracy over all the folds.'
  id: totrans-2691
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå°†æ•°æ®åˆ’åˆ†ä¸º K ä¸ªæŠ˜å ï¼Œå¹¶åœ¨æŠ˜å ä¸Šå¾ªç¯è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨å‰©ä½™æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨æŠ˜å ä¸­çš„æ•°æ®ä¸Šæµ‹è¯•æ¨¡å‹ã€‚ç„¶åæ±‡æ€»æ‰€æœ‰æŠ˜å çš„æµ‹è¯•å‡†ç¡®æ€§ã€‚'
- en: the train and test data split is based on K, for example, K = 4, is 25% testing
    for each fold and K = 5, is 20% testing for each fold
  id: totrans-2692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„åˆ’åˆ†åŸºäº Kï¼Œä¾‹å¦‚ï¼ŒK = 4 æ—¶ï¼Œæ¯ä¸ªæŠ˜å çš„æµ‹è¯•æ•°æ®ä¸º 25%ï¼ŒK = 5 æ—¶ï¼Œæ¯ä¸ªæŠ˜å çš„æµ‹è¯•æ•°æ®ä¸º 20%
- en: this is an improvement over cross validation that only applies one train and
    test split to build a single model. The K-fold approach allows testing of all
    data and the aggregation of accuracy over all the folds tends to smooth the accuracy
    vs. hyperparameter plot for more reliable hyperparameter tuning
  id: totrans-2693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹ä»…åº”ç”¨ä¸€ä¸ªè®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²æ¥æ„å»ºå•ä¸ªæ¨¡å‹çš„äº¤å‰éªŒè¯çš„æ”¹è¿›ã€‚K é‡æ–¹æ³•å…è®¸æµ‹è¯•æ‰€æœ‰æ•°æ®ï¼Œå¹¶ä¸”æ±‡æ€»æ‰€æœ‰æŠ˜å çš„å‡†ç¡®æ€§å¾€å¾€å¯ä»¥å¹³æ»‘å‡†ç¡®æ€§ä¸è¶…å‚æ•°çš„å›¾è¡¨ï¼Œä»è€Œè¿›è¡Œæ›´å¯é çš„è¶…å‚æ•°è°ƒæ•´
- en: k-fold cross validation may be applied to check model performance for estimation
    accuracy (most common) and uncertainty model goodness ([Maldonado-Cruz and Pyrcz,
    2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343))
  id: totrans-2694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k é‡äº¤å‰éªŒè¯å¯ä»¥åº”ç”¨äºæ£€æŸ¥æ¨¡å‹æ€§èƒ½ä»¥ä¼°è®¡å‡†ç¡®æ€§ï¼ˆæœ€å¸¸è§ï¼‰å’Œæ¨¡å‹ä¸ç¡®å®šæ€§ï¼ˆ[Maldonado-Cruz å’Œ Pyrczï¼Œ2021](https://www.sciencedirect.com/science/article/pii/S0920410521006343)ï¼‰
- en: '**k-Means Clustering**'
  id: totrans-2695
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**k-Means èšç±»**'
- en: 'Cluster Analysis: an unsupervised machine learning method for partitional clustering,
    group assignment to unlabeled data, where dissimilarity within clustered groups
    is mini minimized. The loss function that is minimized is,'
  id: totrans-2696
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šä¸€ç§æ— ç›‘ç£çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºåˆ†åŒºèšç±»ï¼Œå°†æœªæ ‡è®°æ•°æ®åˆ†ç»„ï¼Œå…¶ä¸­èšç±»ç»„å†…çš„å·®å¼‚æœ€å°åŒ–ã€‚æœ€å°åŒ–çš„æŸå¤±å‡½æ•°æ˜¯ï¼Œ
- en: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} || X_{\alpha} - \mu_i || \]
  id: totrans-2697
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} || X_{\alpha} - \mu_i || \]
- en: where \(i\) is the cluster index, \(\alpha\) is the data sample index, \(X\)
    is the data sample and \(\mu_i\) is the \(i\) cluster prototype, \(k\) is the
    total number of clusters, and \(|| X_m - \mu_m ||\) is the Euclidean distance
    from a sample to the cluster prototype in \(M\) dimensional space calculated as,
  id: totrans-2698
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(i\) æ˜¯èšç±»ç´¢å¼•ï¼Œ\(\alpha\) æ˜¯æ•°æ®æ ·æœ¬ç´¢å¼•ï¼Œ\(X\) æ˜¯æ•°æ®æ ·æœ¬ï¼Œ\(\mu_i\) æ˜¯ \(i\) èšç±»åŸå‹ï¼Œ\(k\) æ˜¯èšç±»æ€»æ•°ï¼Œ\(||
    X_m - \mu_m ||\) æ˜¯åœ¨ \(M\) ç»´ç©ºé—´ä¸­ä»æ ·æœ¬åˆ°èšç±»åŸå‹çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œè®¡ç®—å¦‚ä¸‹ï¼Œ\[ || X_{m,\alpha} - \mu_i
    || = \sqrt{ \sum_m^M \left( X_{m,\alpha} - \mu_{m,i} \right)^2 } \]
- en: \[ || X_{m,\alpha} - \mu_i || = \sqrt{ \sum_m^M \left( X_{m,\alpha} - \mu_{m,i}
    \right)^2 } \]
  id: totrans-2699
  prefs: []
  type: TYPE_NORMAL
  zh: \[ || X_{m,\alpha} - \mu_i || = \sqrt{ \sum_m^M \left( X_{m,\alpha} - \mu_{m,i}
    \right)^2 } \]
- en: Here is a summary of import aspects for k-means clustering,
  id: totrans-2700
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯k-meansèšç±»çš„å…³é”®æ–¹é¢æ€»ç»“ï¼Œ
- en: '*k* - is given as a model hyperparameter'
  id: totrans-2701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k* - ä½œä¸ºæ¨¡å‹è¶…å‚æ•°ç»™å‡º'
- en: '*exhaustive and mutually exclusive groups* - all data assigned to a single
    group'
  id: totrans-2702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©·å°½ä¸”äº’æ–¥çš„ç»„* - æ‰€æœ‰æ•°æ®åˆ†é…åˆ°å•ä¸ªç»„'
- en: '*prototype method* - represents the training data with number of synthetic
    cases in the features space. For K-means clustering we assign and iteratively
    update \(K\) prototypes.'
  id: totrans-2703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸå‹æ–¹æ³•* - åœ¨ç‰¹å¾ç©ºé—´ä¸­ç”¨åˆæˆæ¡ˆä¾‹çš„æ•°é‡è¡¨ç¤ºè®­ç»ƒæ•°æ®ã€‚å¯¹äºK-meansèšç±»ï¼Œæˆ‘ä»¬åˆ†é…å¹¶è¿­ä»£æ›´æ–° \(K\) ä¸ªåŸå‹ã€‚'
- en: '*iterative solution* - the initial prototypes are assigned randomly in the
    feature space, the labels for each training sample are updated to the nearest
    prototype, then the prototypes are adjusted to the centroid of their assigned
    training data, repeat until there is no further update to the training data assignments.'
  id: totrans-2704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¿­ä»£è§£æ³•* - åˆå§‹åŸå‹åœ¨ç‰¹å¾ç©ºé—´ä¸­éšæœºåˆ†é…ï¼Œæ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„æ ‡ç­¾æ›´æ–°ä¸ºæœ€è¿‘çš„åŸå‹ï¼Œç„¶ååŸå‹è°ƒæ•´åˆ°å…¶åˆ†é…çš„è®­ç»ƒæ•°æ®è´¨å¿ƒï¼Œé‡å¤è¿›è¡Œï¼Œç›´åˆ°è®­ç»ƒæ•°æ®åˆ†é…æ²¡æœ‰è¿›ä¸€æ­¥æ›´æ–°ã€‚'
- en: '*unsupervised learning* - the training data are not labeled and are assigned
    \(K\) labels based on their proximity to the prototypes in the feature space.
    The idea is that similar things, proximity in feature space, should belong to
    the same cluster group.'
  id: totrans-2705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— ç›‘ç£å­¦ä¹ * - è®­ç»ƒæ•°æ®æœªæ ‡è®°ï¼Œå¹¶æ ¹æ®å…¶åœ¨ç‰¹å¾ç©ºé—´ä¸­ä¸åŸå‹çš„æ¥è¿‘ç¨‹åº¦åˆ†é… \(K\) ä¸ªæ ‡ç­¾ã€‚å…¶æƒ³æ³•æ˜¯ç›¸ä¼¼çš„äº‹ç‰©ï¼Œåœ¨ç‰¹å¾ç©ºé—´ä¸­çš„æ¥è¿‘åº¦ï¼Œåº”å±äºåŒä¸€èšç±»ç»„ã€‚'
- en: '*feature weighting* - the procedure depends on the Euclidian distance between
    training samples and prototypes in feature space. Distance is treated as the â€˜inverseâ€™
    of similarity. If the features have significantly different magnitudes, the feature(s)
    with the largest magnitudes and ranges will dominate the loss function and cluster
    groups will become anisotropic aligned orthogonal to the high range feature(s).
    While the common approach is to standardize / normalize the variables, by-feature
    weighting may be applied through unequal variances. Note, in this demonstration
    we normalize the features to range from 0.0 to 1.0.'
  id: totrans-2706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç‰¹å¾åŠ æƒ* - è¯¥è¿‡ç¨‹å–å†³äºè®­ç»ƒæ ·æœ¬å’ŒåŸå‹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚è·ç¦»è¢«è§†ä¸ºç›¸ä¼¼æ€§çš„â€œå€’æ•°â€ã€‚å¦‚æœç‰¹å¾å…·æœ‰æ˜¾è‘—ä¸åŒçš„å¹…åº¦ï¼Œå¹…åº¦å’ŒèŒƒå›´æœ€å¤§çš„ç‰¹å¾å°†ä¸»å¯¼æŸå¤±å‡½æ•°ï¼Œèšç±»ç»„å°†å˜å¾—å„å‘å¼‚æ€§ï¼Œä¸é«˜èŒƒå›´ç‰¹å¾å‚ç›´å¯¹é½ã€‚è™½ç„¶å¸¸è§çš„åšæ³•æ˜¯å¯¹å˜é‡è¿›è¡Œæ ‡å‡†åŒ–/å½’ä¸€åŒ–ï¼Œä½†å¯ä»¥é€šè¿‡ä¸ç­‰æ–¹å·®åº”ç”¨æŒ‰ç‰¹å¾åŠ æƒã€‚æ³¨æ„ï¼Œåœ¨æœ¬æ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å°†ç‰¹å¾å½’ä¸€åŒ–åˆ°0.0åˆ°1.0çš„èŒƒå›´ã€‚'
- en: '**k-Nearest Neighbours**'
  id: totrans-2707
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**k-æœ€è¿‘é‚»**'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): a simple,
    interpretable and flexible, nonparametric predictive machine learning model based
    on a local weighting window applied to \(k\) nearest training data'
  id: totrans-2708
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šä¸€ç§ç®€å•ã€å¯è§£é‡Šä¸”çµæ´»çš„éå‚æ•°é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ŒåŸºäºå±€éƒ¨åŠ æƒçª—å£åº”ç”¨äº
    \(k\) ä¸ªæœ€è¿‘è®­ç»ƒæ•°æ®'
- en: The k-nearest neighbours approach is similar to a convolution approach for spatial
    interpolation. Convolution is the integral product of two functions, after one
    is reversed and shifted by \(\Delta\).
  id: totrans-2709
  prefs: []
  type: TYPE_NORMAL
  zh: k-æœ€è¿‘é‚»æ–¹æ³•ç±»ä¼¼äºç©ºé—´æ’å€¼çš„å·ç§¯æ–¹æ³•ã€‚å·ç§¯æ˜¯ä¸¤ä¸ªå‡½æ•°çš„ç§¯åˆ†ä¹˜ç§¯ï¼Œå…¶ä¸­ä¸€ä¸ªå‡½æ•°ç»è¿‡åè½¬å¹¶æ²¿ \(\Delta\) å¹³ç§»ã€‚
- en: one interpretation is smoothing a function with weighting function, \(ğ‘“(\Delta)\),
    is applied to calculate the weighted average of function, \(ğ‘”(x)\),
  id: totrans-2710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£é‡Šæ˜¯ä½¿ç”¨åŠ æƒå‡½æ•° \(ğ‘“(\Delta)\) å¯¹å‡½æ•°è¿›è¡Œå¹³æ»‘ï¼Œä»¥è®¡ç®—å‡½æ•° \(ğ‘”(x)\) çš„åŠ æƒå¹³å‡å€¼ï¼Œ
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
  id: totrans-2711
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]
- en: this easily extends into multidimensional
  id: totrans-2712
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå®¹æ˜“æ‰©å±•åˆ°å¤šç»´
- en: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
  id: totrans-2713
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
    f(\Delta_x, \Delta_y, \Delta_z) g(x - \Delta_x, y - \Delta_y, z - \Delta_z) \,
    d\Delta_x \, d\Delta_y \, d\Delta_z \]
- en: The choice of which function is shifted before integration does not change the
    result, the convolution operator has commutativity.
  id: totrans-2714
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç§¯åˆ†ä¹‹å‰ç§»åŠ¨å“ªä¸ªå‡½æ•°çš„é€‰æ‹©ä¸ä¼šæ”¹å˜ç»“æœï¼Œå·ç§¯ç®—å­å…·æœ‰äº¤æ¢æ€§ã€‚
- en: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
  id: totrans-2715
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (f * g)(x) = \int_{-\infty}^{\infty} f(\Delta) g(x - \Delta) \, d\Delta \]\[
    (f * g)(x) = \int_{-\infty}^{\infty} f(x - \Delta) g(\Delta) \, d\Delta \]
- en: if either function is reflected then convolution is equivalent to cross-correlation,
    measure of similarity between 2 signals as a function of displacement.
  id: totrans-2716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä»»ä¸€å‡½æ•°è¢«åå°„ï¼Œåˆ™å·ç§¯ç­‰åŒäºäº¤å‰ç›¸å…³ï¼Œä½œä¸ºä½ç§»å‡½æ•°çš„ä¿¡å·ç›¸ä¼¼åº¦åº¦é‡ã€‚
- en: for k-nearest neighbours the use of \(k\) results in a locally adaptive window
    size, different from standard convolution
  id: totrans-2717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äº k ä¸ªæœ€è¿‘é‚»ï¼Œä½¿ç”¨ \(k\) ç»“æœæ˜¯ä¸€ä¸ªå±€éƒ¨è‡ªé€‚åº”çª—å£å¤§å°ï¼Œä¸åŒäºæ ‡å‡†å·ç§¯
- en: K-nearest neighbours is an instance-based, lazy learning method, the model training
    is postponed until prediction is required, no precalculation of the model. i.e.,
    prediction requires access to the data.
  id: totrans-2718
  prefs: []
  type: TYPE_NORMAL
  zh: K ä¸ªæœ€è¿‘é‚»æ˜¯ä¸€ç§åŸºäºå®ä¾‹çš„æ‡’æƒ°å­¦ä¹ æ–¹æ³•ï¼Œæ¨¡å‹è®­ç»ƒè¢«æ¨è¿Ÿåˆ°éœ€è¦é¢„æµ‹æ—¶ï¼Œä¸éœ€è¦é¢„å…ˆè®¡ç®—æ¨¡å‹ã€‚å³ï¼Œé¢„æµ‹éœ€è¦è®¿é—®æ•°æ®ã€‚
- en: to make new predictions that training data must be available
  id: totrans-2719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¦è¿›è¡Œæ–°çš„é¢„æµ‹ï¼Œå¿…é¡»æä¾›è®­ç»ƒæ•°æ®
- en: The hyperparameters include,
  id: totrans-2720
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°åŒ…æ‹¬ï¼Œ
- en: '*k number of nearest data* to utilize for prediction'
  id: totrans-2721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k ä¸ªæœ€è¿‘çš„æ•°æ®ç‚¹*ç”¨äºé¢„æµ‹'
- en: '*data weighting*, for example uniform weighting with the local training data
    average, or inverse distance weighting'
  id: totrans-2722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ•°æ®åŠ æƒ*ï¼Œä¾‹å¦‚ä½¿ç”¨å±€éƒ¨è®­ç»ƒæ•°æ®å¹³å‡å€¼çš„å‡åŒ€åŠ æƒï¼Œæˆ–é€†è·ç¦»åŠ æƒ'
- en: Note, for the case of inverse distance weighting, the method is analogous to
    inverse distance weighted interpolation with a maximum number of local data constraint
    commonly applied for spatial interpolation.
  id: totrans-2723
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¯¹äºé€†è·ç¦»åŠ æƒçš„æƒ…å½¢ï¼Œè¯¥æ–¹æ³•ç±»ä¼¼äºé€†è·ç¦»åŠ æƒæ’å€¼ï¼Œé€šå¸¸åº”ç”¨äºç©ºé—´æ’å€¼ï¼Œå¹¶æ–½åŠ æœ€å¤§å±€éƒ¨æ•°æ®æ•°é‡çº¦æŸã€‚
- en: inverse distance is available in GeostatsPy for spatial mapping.
  id: totrans-2724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GeostatsPy ä¸­æä¾›äº†é€†è·ç¦»ç”¨äºç©ºé—´æ˜ å°„ã€‚
- en: Too find the k-nearest data a distance metric is needed,
  id: totrans-2725
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰¾åˆ° k ä¸ªæœ€è¿‘çš„æ•°æ®ç‚¹ï¼Œéœ€è¦ä¸€ä¸ªè·ç¦»åº¦é‡ï¼Œ
- en: training data within the predictor feature space are ranked by distance (closest
    to farthest)
  id: totrans-2726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ç©ºé—´å†…çš„è®­ç»ƒæ•°æ®æŒ‰è·ç¦»æ’åºï¼ˆä»è¿‘åˆ°è¿œï¼‰
- en: 'a variety of distance metrics may be applied, including:'
  id: totrans-2727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ä»¥åº”ç”¨å„ç§è·ç¦»åº¦é‡ï¼ŒåŒ…æ‹¬ï¼š
- en: Euclidian distance
  id: totrans-2728
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¬§å‡ é‡Œå¾—è·ç¦»
- en: \begin{equation}
  id: totrans-2729
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{equation}
- en: d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
    \end{equation}
  id: totrans-2730
  prefs: []
  type: TYPE_NORMAL
  zh: d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
    \end{equation}
- en: Minkowski Distance - a general expression for distance with well-known Manhattan
    and Euclidean distances are special cases,
  id: totrans-2731
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Minkowski è·ç¦» - è·ç¦»çš„é€šç”¨è¡¨è¾¾å¼ï¼Œå…¶ä¸­å·²çŸ¥çš„æ›¼å“ˆé¡¿å’Œæ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œ
- en: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
  id: totrans-2732
  prefs: []
  type: TYPE_NORMAL
  zh: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
- en: when \(p=2\), this becomes the Euclidean distance
  id: totrans-2733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(p=2\) æ—¶ï¼Œè¿™æˆä¸ºæ¬§å‡ é‡Œå¾—è·ç¦»
- en: when \(p=1\) it becomes the Manhattan distance
  id: totrans-2734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(p=1\) æ—¶ï¼Œå®ƒæˆä¸ºæ›¼å“ˆé¡¿è·ç¦»
- en: '**Kernel Trick** (support vector machines)'
  id: totrans-2735
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ¸æŠ€å·§**ï¼ˆæ”¯æŒå‘é‡æœºï¼‰'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): we
    can incorporate our basis expansion in our method without ever needing to transform
    the training data to this higher dimensional space,'
  id: totrans-2736
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šæˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­åŒ…å«åŸºç¡€æ‰©å±•ï¼Œè€Œæ— éœ€å°†è®­ç»ƒæ•°æ®è½¬æ¢ä¸ºè¿™ä¸ªæ›´é«˜ç»´åº¦çš„ç©ºé—´ï¼Œ'
- en: \[ h(x) \]
  id: totrans-2737
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h(x) \]
- en: We only need the inner product over the predictor features,
  id: totrans-2738
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€è¦é¢„æµ‹ç‰¹å¾ä¸Šçš„å†…ç§¯ï¼Œ
- en: \[ h(x) \left( h(x') \right)^T = \langle h(x), h(x') \rangle \]
  id: totrans-2739
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h(x) \left( h(x') \right)^T = \langle h(x), h(x') \rangle \]
- en: Instead of the actual values in the transformed space, we just need the â€˜similarityâ€™
    between all available training data in that transformed space!
  id: totrans-2740
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸æ˜¯å˜æ¢ç©ºé—´ä¸­çš„å®é™…å€¼ï¼Œæˆ‘ä»¬åªéœ€è¦è¯¥å˜æ¢ç©ºé—´ä¸­æ‰€æœ‰å¯ç”¨è®­ç»ƒæ•°æ®ä¹‹é—´çš„â€˜ç›¸ä¼¼æ€§â€™ï¼
- en: we training our support vector machines with only a similarity matrix between
    training data that will be projected to the higher dimensional space
  id: totrans-2741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»…ä½¿ç”¨è®­ç»ƒæ•°æ®ä¹‹é—´çš„ç›¸ä¼¼æ€§çŸ©é˜µæ¥è®­ç»ƒæ”¯æŒå‘é‡æœºï¼Œè¿™äº›æ•°æ®å°†è¢«æŠ•å½±åˆ°æ›´é«˜ç»´åº¦çš„ç©ºé—´
- en: we never actually need to calculate the training data values in the higher dimensional
    space
  id: totrans-2742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®é™…ä¸Šæ°¸è¿œä¸éœ€è¦è®¡ç®—æ›´é«˜ç»´ç©ºé—´ä¸­çš„è®­ç»ƒæ•°æ®å€¼
- en: '**Kriging**'
  id: totrans-2743
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å…‹é‡Œé‡‘æ³•**'
- en: 'Data Preparation: spatial estimation approach that relies on linear weights
    that account for spatial continuity, data closeness and redundancy. The kriging
    estimate is,'
  id: totrans-2744
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§ä¾èµ–äºçº¿æ€§æƒé‡çš„ç©ºé—´ä¼°è®¡æ–¹æ³•ï¼Œè¿™äº›æƒé‡è€ƒè™‘äº†ç©ºé—´è¿ç»­æ€§ã€æ•°æ®æ¥è¿‘æ€§å’Œå†—ä½™ã€‚å…‹é‡Œé‡‘ä¼°è®¡ä¸ºï¼Œ
- en: \[ z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha})
    + \left( 1.0 - \sum_{\alpha=1}^n \lambda_{\alpha} \right) \cdot m_z \]
  id: totrans-2745
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot z(\bf{u}_{\alpha})
    + \left( 1.0 - \sum_{\alpha=1}^n \lambda_{\alpha} \right) \cdot m_z \]
- en: the right term is the unbiasedness constraint, one minus the sum of the weights
    is applied to the global mean.
  id: totrans-2746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£ç¡®çš„æœ¯è¯­æ˜¯ä¸åæ€§çº¦æŸï¼Œå°†æƒé‡ä¹‹å’Œçš„å€’æ•°åº”ç”¨äºå…¨å±€å‡å€¼ã€‚
- en: In the case where the trend, \(t(\bf{u})\), is removed, we now have a residual,
    \(y(\bf{u})\),
  id: totrans-2747
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å»é™¤è¶‹åŠ¿ \(t(\bf{u})\) çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªæ®‹å·®ï¼Œ\(y(\bf{u})\)ï¼Œ
- en: \[ y(\bf{u}) = z(\bf{u}) - t(\bf{u}) \]
  id: totrans-2748
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y(\bf{u}) = z(\bf{u}) - t(\bf{u}) \]
- en: the residual mean is zero so we can simplify our kriging estimate as,
  id: totrans-2749
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä½™å‡å€¼ä¸ºé›¶ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç®€åŒ–æˆ‘ä»¬çš„å…‹é‡Œé‡‘ä¼°è®¡ä¸ºï¼Œ
- en: \[ y^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot y(\bf{u}_{\alpha})
    \]
  id: totrans-2750
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y^*(\bf{u}) = \sum_{\alpha = 1}^{n} \lambda_{\alpha} \cdot y(\bf{u}_{\alpha})
    \]
- en: The simple kriging weights are calculated by solving a linear system of equations,
  id: totrans-2751
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•å…‹é‡Œé‡‘æƒé‡æ˜¯é€šè¿‡æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„æ¥è®¡ç®—çš„ï¼Œ
- en: \[ \sum_{j=1}^n \lambda_j C(\bf{u}_i,\bf{u}_j) = C(\bf{u},\bf{u}_i), \quad i=1,\ldots,n
    \]
  id: totrans-2752
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{j=1}^n \lambda_j C(\bf{u}_i,\bf{u}_j) = C(\bf{u},\bf{u}_i), \quad i=1,\ldots,n
    \]
- en: that may be represented with matrix notation as,
  id: totrans-2753
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥ç”¨çŸ©é˜µè¡¨ç¤ºï¼Œ
- en: \[\begin{split} \begin{bmatrix} C(\bf{u}_1,\bf{u}_1) & C(\bf{u}_1,\bf{u}_2)
    & \dots & C(\bf{u}_1,\bf{u}_n) \\ C(\bf{u}_2,\bf{u}_1) & C(\bf{u}_2,\bf{u}_2)
    & \dots & C(\bf{u}_2,\bf{u}_n) \\ \vdots & \vdots & \ddots & \vdots \\ C(\bf{u}_n,\bf{u}_1)
    & C(\bf{u}_n,\bf{u}_2) & \dots & C(\bf{u}_n,\bf{u}_n) \\ \end{bmatrix} \cdot \begin{bmatrix}
    \lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\ \end{bmatrix} = \begin{bmatrix}
    C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u}) \\ \vdots \\ C(\bf{u}_n,\bf{u}) \\ \end{bmatrix}
    \end{split}\]
  id: totrans-2754
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} C(\bf{u}_1,\bf{u}_1) & C(\bf{u}_1,\bf{u}_2)
    & \dots & C(\bf{u}_1,\bf{u}_n) \\ C(\bf{u}_2,\bf{u}_1) & C(\bf{u}_2,\bf{u}_2)
    & \dots & C(\bf{u}_2,\bf{u}_n) \\ \vdots & \vdots & \ddots & \vdots \\ C(\bf{u}_n,\bf{u}_1)
    & C(\bf{u}_n,\bf{u}_2) & \dots & C(\bf{u}_n,\bf{u}_n) \\ \end{bmatrix} \cdot \begin{bmatrix}
    \lambda_1 \\ \lambda_2 \\ \vdots \\ \lambda_n \\ \end{bmatrix} = \begin{bmatrix}
    C(\bf{u}_1,\bf{u}) \\ C(\bf{u}_2,\bf{u}) \\ \vdots \\ C(\bf{u}_n,\bf{u}) \\ \end{bmatrix}
    \end{split}\]
- en: This system may be derived by substituting the equation for kriging estimates
    into the equation for estimation variance, and then setting the partial derivative
    with respect to the weights to zero.
  id: totrans-2755
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†å…‹é‡Œé‡‘ä¼°è®¡çš„æ–¹ç¨‹ä»£å…¥ä¼°è®¡æ–¹å·®çš„æ–¹ç¨‹ï¼Œç„¶åè®¾ç½®å…³äºæƒé‡çš„åå¯¼æ•°ä¸ºé›¶ï¼Œå¯ä»¥æ¨å¯¼å‡ºè¿™ä¸ªç³»ç»Ÿã€‚
- en: we are optimizing the weights to minimize the estimation variance
  id: totrans-2756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ä¼˜åŒ–æƒé‡ä»¥æœ€å°åŒ–ä¼°è®¡æ–¹å·®
- en: this system integrates the,
  id: totrans-2757
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç³»ç»Ÿç»¼åˆäº†ï¼Œ
- en: '*spatial continuity* as quantified by the variogram (and covariance function
    to calculate the covariance, \(C\), values)'
  id: totrans-2758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡å˜å¼‚å‡½æ•°ï¼ˆä»¥åŠåæ–¹å·®å‡½æ•°æ¥è®¡ç®—åæ–¹å·®å€¼ \(C\)ï¼‰é‡åŒ–çš„ *ç©ºé—´è¿ç»­æ€§*
- en: '*redundancy* the degree of spatial continuity between all of the available
    data with themselves, \(C(\bf{u}_i,\bf{u}_j)\)'
  id: totrans-2759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å†—ä½™* - æ‰€æœ‰å¯ç”¨æ•°æ®ä¸å…¶è‡ªèº«ä¹‹é—´çš„ç©ºé—´è¿ç»­æ€§ç¨‹åº¦ï¼Œ\(C(\bf{u}_i,\bf{u}_j)\)'
- en: '*closeness* the degree of spatial continuity between the available data and
    the estimation location, \(C(\bf{u}_i,\bf{u})\)'
  id: totrans-2760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¥è¿‘æ€§* - å¯ç”¨æ•°æ®ä¸ä¼°è®¡ä½ç½®ä¹‹é—´çš„ç©ºé—´è¿ç»­æ€§ç¨‹åº¦ï¼Œ\(C(\bf{u}_i,\bf{u})\)'
- en: Kriging provides a measure of estimation accuracy known as kriging variance
    (a specific case of estimation variance).
  id: totrans-2761
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹é‡Œé‡‘æä¾›äº†ä¸€ä¸ªç§°ä¸ºå…‹é‡Œé‡‘æ–¹å·®çš„ä¼°è®¡ç²¾åº¦åº¦é‡ï¼ˆä¼°è®¡æ–¹å·®çš„ä¸€ä¸ªç‰¹ä¾‹ï¼‰ã€‚
- en: \[ \sigma^{2}_{E}(\bf{u}) = C(0) - \sum^{n}_{\alpha = 1} \lambda_{\alpha} C(\bf{u}_0
    - \bf{u}_{\alpha}) \]
  id: totrans-2762
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma^{2}_{E}(\bf{u}) = C(0) - \sum^{n}_{\alpha = 1} \lambda_{\alpha} C(\bf{u}_0
    - \bf{u}_{\alpha}) \]
- en: Kriging estimates are best in that they minimize the above estimation variance.
  id: totrans-2763
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹é‡Œé‡‘ä¼°è®¡ä¹‹æ‰€ä»¥æœ€ä½³ï¼Œæ˜¯å› ä¸ºå®ƒä»¬æœ€å°åŒ–äº†ä¸Šè¿°ä¼°è®¡æ–¹å·®ã€‚
- en: Properties of kriging estimates include,
  id: totrans-2764
  prefs: []
  type: TYPE_NORMAL
  zh: å…‹é‡Œé‡‘ä¼°è®¡çš„æ€§è´¨åŒ…æ‹¬ï¼Œ
- en: '*Exact interpolator* - kriging estimates with the data values at the data locations'
  id: totrans-2765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç²¾ç¡®æ’å€¼å™¨* - åœ¨æ•°æ®ä½ç½®å¤„çš„å…‹é‡Œé‡‘ä¼°è®¡ä¸æ•°æ®å€¼'
- en: '*Kriging variance* - a measure of uncertainty in a kriging estimate. Can be
    calculated before getting the sample information, as the kriging estimation variance
    is not dependent on the values of the data nor the kriging estimate, i.e. the
    kriging estimator is homoscedastic.'
  id: totrans-2766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å…‹é‡Œé‡‘æ–¹å·®* - å…‹é‡Œé‡‘ä¼°è®¡ä¸­çš„ä¸ç¡®å®šæ€§åº¦é‡ã€‚å¯ä»¥åœ¨è·å–æ ·æœ¬ä¿¡æ¯ä¹‹å‰è®¡ç®—ï¼Œå› ä¸ºå…‹é‡Œé‡‘ä¼°è®¡æ–¹å·®ä¸ä¾èµ–äºæ•°æ®çš„å€¼æˆ–å…‹é‡Œé‡‘ä¼°è®¡ï¼Œå³å…‹é‡Œé‡‘ä¼°è®¡é‡æ˜¯åŒæ–¹å·®æ€§çš„ã€‚'
- en: '*Spatial context* - kriging takes integrates spatial continuity, closeness
    and redundancy; therefore, kriging accounts for the configuration of the data
    and structural continuity of the feature being estimated.'
  id: totrans-2767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç©ºé—´ä¸Šä¸‹æ–‡* - å…‹é‡Œé‡‘ç»¼åˆäº†ç©ºé—´è¿ç»­æ€§ã€é‚»è¿‘æ€§å’Œå†—ä½™æ€§ï¼›å› æ­¤ï¼Œå…‹é‡Œé‡‘è€ƒè™‘äº†æ•°æ®çš„é…ç½®å’Œè¢«ä¼°è®¡ç‰¹å¾çš„è¿ç»­æ€§ç»“æ„ã€‚'
- en: '*Scale* - kriging by default assumes the estimate and data are at the same
    point support, i.e., mathematically represented as points in space with zero volume.
    Kriging may be generalized to account for the support volume of the data and estimate,'
  id: totrans-2768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å°ºåº¦* - é»˜è®¤æƒ…å†µä¸‹ï¼Œå…‹é‡Œé‡‘å‡è®¾ä¼°è®¡å’Œæ•°æ®ä½äºç›¸åŒçš„æ”¯æŒç‚¹ï¼Œå³æ•°å­¦ä¸Šè¡¨ç¤ºä¸ºç©ºé—´ä¸­çš„é›¶ä½“ç§¯çš„ç‚¹ã€‚å…‹é‡Œé‡‘å¯ä»¥æ¨å¹¿ä»¥è€ƒè™‘æ•°æ®å’Œä¼°è®¡çš„æ”¯æŒä½“ç§¯ï¼Œ'
- en: '*Multivariate* - kriging may be generalized to account for multiple secondary
    data in the spatial estimate with the cokriging system. We will cover this later.'
  id: totrans-2769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šå…ƒ* - å…‹é‡Œé‡‘å¯ä»¥é€šè¿‡å…±å…‹é‡Œé‡‘ç³»ç»Ÿæ¨å¹¿ï¼Œä»¥è€ƒè™‘ç©ºé—´ä¼°è®¡ä¸­çš„å¤šä¸ªæ¬¡çº§æ•°æ®ã€‚æˆ‘ä»¬å°†åœ¨åé¢ä»‹ç»è¿™ä¸€ç‚¹ã€‚'
- en: '*Smoothing effect* - of kriging can be forecasted as the missing variance.
    The missing variance over local estimates is the kriging variance.'
  id: totrans-2770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¹³æ»‘æ•ˆåº”* - å…‹é‡Œé‡‘æ³•å¯ä»¥é¢„æµ‹ä¸ºç¼ºå¤±æ–¹å·®ã€‚å±€éƒ¨ä¼°è®¡çš„ç¼ºå¤±æ–¹å·®æ˜¯å…‹é‡Œé‡‘æ–¹å·®ã€‚'
- en: '**Kriging-based Declustering**'
  id: totrans-2771
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºå…‹é‡Œé‡‘çš„å»èšç±»**'
- en: 'Data Preparation: a declustering method to assign weights to spatial samples
    based on local sampling density, such that the weighted statistics are likely
    more representative of the population. Data weights are assigned so that,'
  id: totrans-2772
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§å»èšç±»æ–¹æ³•ï¼Œæ ¹æ®å±€éƒ¨é‡‡æ ·å¯†åº¦å¯¹ç©ºé—´æ ·æœ¬åˆ†é…æƒé‡ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚ä¸‹ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-2773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨ å¯†é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬è·å¾—è¾ƒå°‘æƒé‡
- en: samples in sparsely sampled areas receive more weight
  id: totrans-2774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨€ç–é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬è·å¾—æ›´å¤šæƒé‡
- en: 'Kriging-based declustering proceeds as follows:'
  id: totrans-2775
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºå…‹é‡Œé‡‘çš„å»èšç±»è¿‡ç¨‹å¦‚ä¸‹ï¼š
- en: calculate and model the experimental variogram
  id: totrans-2776
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—å¹¶å»ºæ¨¡å®éªŒå˜å¼‚å‡½æ•°
- en: apply kriging to calculate estimates over a high-resolution grid covering the
    area of interest
  id: totrans-2777
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨å…‹é‡Œé‡‘è®¡ç®—è¦†ç›–æ„Ÿå…´è¶£åŒºåŸŸçš„é«˜åˆ†è¾¨ç‡ç½‘æ ¼ä¸Šçš„ä¼°è®¡
- en: calculate the sum of the weights assigned to each data
  id: totrans-2778
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—åˆ†é…ç»™æ¯ä¸ªæ•°æ®çš„æƒé‡æ€»å’Œ
- en: assign data weights proportional to this sum of weights
  id: totrans-2779
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†é…ä¸è¯¥æƒé‡æ€»å’Œæˆæ¯”ä¾‹çš„æ•°æ®æƒé‡
- en: 'The weights are calculated as:'
  id: totrans-2780
  prefs: []
  type: TYPE_NORMAL
  zh: æƒé‡è®¡ç®—å¦‚ä¸‹ï¼š
- en: \[ w(\bf{u}_j) = n \cdot \frac{\sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_j}{\sum_{i=1}^n
    \left[ \sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_{j,ix,iy} \right]} \]
  id: totrans-2781
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w(\bf{u}_j) = n \cdot \frac{\sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_j}{\sum_{i=1}^n
    \left[ \sum_{iy}^{ny} \sum_{ix}^{nx} \lambda_{j,ix,iy} \right]} \]
- en: where \(nx\) and \(ny\) are the number of cells in the grid, \(n\) is the number
    of data, and \(\lambda_{j,ix,iy}\) is the weight assigned to the \(j\) data at
    the \(ix,iy\) grid cell.
  id: totrans-2782
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(nx\) å’Œ \(ny\) æ˜¯ç½‘æ ¼ä¸­çš„å•å…ƒæ ¼æ•°é‡ï¼Œ\(n\) æ˜¯æ•°æ®æ•°é‡ï¼Œ\(\lambda_{j,ix,iy}\) æ˜¯åˆ†é…ç»™ \(ix,iy\)
    ç½‘æ ¼å•å…ƒæ ¼ä¸­ \(j\) æ•°æ®çš„æƒé‡ã€‚
- en: Here is an important point for kriging-based declustering,
  id: totrans-2783
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å…³äºåŸºäºå…‹é‡Œé‡‘å»èšç±»çš„ä¸€ä¸ªé‡è¦è§‚ç‚¹ï¼Œ
- en: like polygonal declustering, kriging-based declustering is sensitive to the
    boundaries of the area of interest; therefore, the weights assigned to the data
    near the boundary of the area of interest may change radically as the area of
    interest is expanded or contracted
  id: totrans-2784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºå¤šè¾¹å½¢å»èšç±»ï¼ŒåŸºäºå…‹é‡Œé‡‘çš„å»èšç±»å¯¹æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œæ•æ„Ÿï¼›å› æ­¤ï¼Œå½“æ„Ÿå…´è¶£åŒºåŸŸæ‰©å±•æˆ–æ”¶ç¼©æ—¶ï¼Œåˆ†é…ç»™è¾¹ç•Œé™„è¿‘æ•°æ®çš„æƒé‡å¯èƒ½ä¼šå‘ç”Ÿæ ¹æœ¬æ€§çš„å˜åŒ–ã€‚
- en: Also, kriging-based declustering integrates the spatial continuity model from
    variogram model. Consider the following possible impacts of the variogram model
    on the declustering weights,
  id: totrans-2785
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼ŒåŸºäºå…‹é‡Œé‡‘çš„å»èšç±»è¿˜ç»¼åˆäº†å˜å¼‚å‡½æ•°æ¨¡å‹çš„ç©ºé—´è¿ç»­æ€§æ¨¡å‹ã€‚è€ƒè™‘ä»¥ä¸‹å˜å¼‚å‡½æ•°æ¨¡å‹å¯¹å»èšç±»æƒé‡å¯èƒ½äº§ç”Ÿçš„å½±å“ï¼Œ
- en: if there is 100% relative nugget effect, there is no spatial continuity and
    therefore, all data receives equal weight. Note for the equation above this results
    in a divide by 0.0 error that must be checked for in the code.
  id: totrans-2786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæœ‰ 100% çš„ç›¸å¯¹å—çŠ¶æ•ˆåº”ï¼Œåˆ™æ²¡æœ‰ç©ºé—´è¿ç»­æ€§ï¼Œå› æ­¤ï¼Œæ‰€æœ‰æ•°æ®éƒ½è·å¾—ç›¸ç­‰çš„æƒé‡ã€‚æ³¨æ„ï¼Œå¯¹äºä¸Šé¢çš„æ–¹ç¨‹ï¼Œè¿™ä¼šå¯¼è‡´é™¤ä»¥ 0.0 çš„é”™è¯¯ï¼Œå¿…é¡»åœ¨ä»£ç ä¸­è¿›è¡Œæ£€æŸ¥ã€‚
- en: geometric anisotropy may significantly impact the weights as data aligned over
    specific azimuths are assessed as closer or further in terms of covariance
  id: totrans-2787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡ ä½•å„å‘å¼‚æ€§å¯èƒ½ä¼šæ˜¾è‘—å½±å“æƒé‡ï¼Œå› ä¸ºæ²¿ç‰¹å®šæ–¹ä½å¯¹é½çš„æ•°æ®åœ¨åæ–¹å·®æ–¹é¢è¢«è§†ä¸ºæ›´æ¥è¿‘æˆ–æ›´è¿œã€‚
- en: '**Kolmogorovâ€™s 3 Probability Axioms**'
  id: totrans-2788
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŸ¯å°”è«å“¥æ´›å¤«çš„ 3 ä¸ªæ¦‚ç‡å…¬ç†**'
- en: 'Probability Concepts: these are Kolmogorovâ€™s 3 axioms for valid probabilities,'
  id: totrans-2789
  prefs: []
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ¦‚å¿µï¼šè¿™äº›æ˜¯æŸ¯å°”è«å“¥æ´›å¤«å¯¹æœ‰æ•ˆæ¦‚ç‡çš„ 3 ä¸ªå…¬ç†ï¼Œ
- en: Probability of an event is a non-negative number.
  id: totrans-2790
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡æ˜¯ä¸€ä¸ªéè´Ÿæ•°ã€‚
- en: \[ P(ğ´) \ge 0 \]
  id: totrans-2791
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(ğ´) \ge 0 \]
- en: Probability of the entire sample space, all possible outcomes, \(\Omega\), is
    one (unity), also known as probability closure.
  id: totrans-2792
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•´ä¸ªæ ·æœ¬ç©ºé—´ï¼ˆæ‰€æœ‰å¯èƒ½çš„ç»“æœï¼‰çš„æ¦‚ç‡ \(\Omega\) ä¸ºä¸€ï¼ˆå•ä½ï¼‰ï¼Œä¹Ÿç§°ä¸ºæ¦‚ç‡å°é—­ã€‚
- en: \[ P(\Omega) = 1 \]
  id: totrans-2793
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\Omega) = 1 \]
- en: Additivity of mutually exclusive events for unions.
  id: totrans-2794
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº’æ–¥äº‹ä»¶çš„å¹¶é›†çš„åŠ æ³•æ€§ã€‚
- en: \[ P\left(â‹ƒ_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \]
  id: totrans-2795
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P\left(â‹ƒ_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \]
- en: e.g., probability of \(A_1\) and \(A_2\) mutual exclusive events is, \(P(A_1
    + A_2) = P(A_1) + P(A_2)\)
  id: totrans-2796
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ\(A_1\) å’Œ \(A_2\) äº’æ–¥äº‹ä»¶çš„æ¦‚ç‡æ˜¯ï¼Œ\(P(A_1 + A_2) = P(A_1) + P(A_2)\)
- en: '**\(L^1\) Norm**'
  id: totrans-2797
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^1\) èŒƒæ•°**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): known as Manhattan
    norm or sum of absolute residual (SAR),'
  id: totrans-2798
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šç§°ä¸ºæ›¼å“ˆé¡¿èŒƒæ•°æˆ–ç»å¯¹æ®‹å·®å’Œï¼ˆSARï¼‰ï¼Œ'
- en: \[ \sum_{i=1}^n |\Delta y_i | \]
  id: totrans-2799
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n |\Delta y_i | \]
- en: also expressed as the mean absolute error (MAE),
  id: totrans-2800
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè¡¨ç¤ºä¸ºå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ï¼Œ
- en: \[ \frac{1}{n} \sum_{i=1}^n |\Delta y_i | \]
  id: totrans-2801
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n |\Delta y_i | \]
- en: Minimization with \(L^1\) norm is known as minimum absolute difference.
  id: totrans-2802
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(L^1\) èŒƒæ•°è¿›è¡Œæœ€å°åŒ–ç§°ä¸ºæœ€å°ç»å¯¹å·®å¼‚ã€‚
- en: '**\(L^2\) Norm**'
  id: totrans-2803
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^2\) èŒƒæ•°**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): known as sum of
    square residual (SSR),'
  id: totrans-2804
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šç§°ä¸ºå¹³æ–¹æ®‹å·®å’Œï¼ˆSSRï¼‰ï¼Œ'
- en: \[ \sum_{i=1}^n \sqrt{\Delta y_i} \]
  id: totrans-2805
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \sqrt{\Delta y_i} \]
- en: also expressed as the mean square error (MSE),
  id: totrans-2806
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè¡¨ç¤ºä¸ºå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œ
- en: \[ \frac{1}{n} \sum_{i=1}^n \left( \Delta y_i \right)^2 \]
  id: totrans-2807
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n \left( \Delta y_i \right)^2 \]
- en: and the Euclidian norm,
  id: totrans-2808
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠæ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼Œ
- en: \[ \sqrt{ \sum_{i=1}^n \sqrt{\Delta y_i} } \]
  id: totrans-2809
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sqrt{ \sum_{i=1}^n \sqrt{\Delta y_i} } \]
- en: Minimization with \(L^2\) norm is known as the method of least squares.
  id: totrans-2810
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(L^2\) èŒƒæ•°è¿›è¡Œæœ€å°åŒ–ç§°ä¸ºæœ€å°äºŒä¹˜æ³•ã€‚
- en: '**\(L^1\) vs. \(L^2\) Norm**'
  id: totrans-2811
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^1\) ä¸ \(L^2\) èŒƒæ•°**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): the choice of \(L^1\)
    and \(L^2\) norm is important in machine learning. To explain this letâ€™s compare
    the performance of \(L^1\) and \(L^2\) norms in loss functions while training
    model parameters.'
  id: totrans-2812
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œ\(L^1\) å’Œ \(L^2\)
    èŒƒæ•°çš„é€‰æ‹©å¾ˆé‡è¦ã€‚ä¸ºäº†è§£é‡Šè¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒåœ¨è®­ç»ƒæ¨¡å‹å‚æ•°æ—¶ \(L^1\) å’Œ \(L^2\) èŒƒæ•°åœ¨æŸå¤±å‡½æ•°ä¸­çš„æ€§èƒ½ã€‚'
- en: '| Property | Least Absolute Deviations (L1) | Least Squares (L2) |'
  id: totrans-2813
  prefs: []
  type: TYPE_TB
  zh: '| å±æ€§ | æœ€å°ç»å¯¹åå·®ï¼ˆL1ï¼‰ | æœ€å°äºŒä¹˜ï¼ˆL2ï¼‰ |'
- en: '| --- | --- | --- |'
  id: totrans-2814
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Robustness* | Robust | Not very robust |'
  id: totrans-2815
  prefs: []
  type: TYPE_TB
  zh: '| é²æ£’æ€§* | é²æ£’ | éå¸¸ä¸é²æ£’ |'
- en: '| Solution Stability | Unstable solution | Stable solution |'
  id: totrans-2816
  prefs: []
  type: TYPE_TB
  zh: '| è§£çš„ç¨³å®šæ€§ | ä¸ç¨³å®šè§£ | ç¨³å®šè§£ |'
- en: '| Number of Solutions | Possibly multiple solutions | Always one solution |'
  id: totrans-2817
  prefs: []
  type: TYPE_TB
  zh: '| è§£çš„æ•°é‡ | å¯èƒ½å­˜åœ¨å¤šä¸ªè§£ | æ€»æ˜¯åªæœ‰ä¸€ä¸ªè§£ |'
- en: '| Feature Selection | Built-in feature selection | No feature selection |'
  id: totrans-2818
  prefs: []
  type: TYPE_TB
  zh: '| ç‰¹å¾é€‰æ‹© | å†…ç½®ç‰¹å¾é€‰æ‹© | æ— ç‰¹å¾é€‰æ‹© |'
- en: '| Output Sparsity | Sparse outputs | Non-sparse outputs |'
  id: totrans-2819
  prefs: []
  type: TYPE_TB
  zh: '| è¾“å‡ºç¨€ç–æ€§ | ç¨€ç–è¾“å‡º | éç¨€ç–è¾“å‡º |'
- en: '| Analytical Solutions | No analytical solutions | Analytical solutions |'
  id: totrans-2820
  prefs: []
  type: TYPE_TB
  zh: '| è§£æè§£ | æ— è§£æè§£ | è§£æè§£ |'
- en: Hereâ€™s some important points,
  id: totrans-2821
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›é‡è¦çš„è¦ç‚¹ï¼Œ
- en: '*robust* - resistant to outliers'
  id: totrans-2822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é²æ£’* - å¯¹å¼‚å¸¸å€¼æœ‰æŠµæŠ—åŠ›'
- en: '*unstable* - for small changes in training the trained model predictions may
    jump'
  id: totrans-2823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ä¸ç¨³å®š* - å¯¹äºè®­ç»ƒæ¨¡å‹çš„å¾®å°å˜åŒ–ï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¼šè·³è·ƒ'
- en: '*multiple solutions* - different solution have similar or the same loss, resulting
    in solutions jumping with small changes to the training data'
  id: totrans-2824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šé‡è§£* - ä¸åŒçš„è§£å…·æœ‰ç›¸ä¼¼æˆ–ç›¸åŒçš„æŸå¤±ï¼Œå¯¼è‡´è§£åœ¨è®­ç»ƒæ•°æ®å¾®å°å˜åŒ–æ—¶è·³è·ƒ'
- en: '*output sparsity* and *feature selection* - model parameters tend to 0.0'
  id: totrans-2825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¾“å‡ºç¨€ç–æ€§* å’Œ *ç‰¹å¾é€‰æ‹©* - æ¨¡å‹å‚æ•°è¶‹å‘äº 0.0'
- en: '*analytical solutions* - an analytical solution is available to solve for the
    optimum model parameters'
  id: totrans-2826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è§£æè§£* - å¯ç”¨è§£æè§£æ±‚è§£æœ€ä¼˜æ¨¡å‹å‚æ•°'
- en: '**\(L^1\) or \(L^2\) Normalizer**'
  id: totrans-2827
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(L^1\) æˆ– \(L^2\) æ­£åˆ™åŒ–å™¨**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): is
    performed across features over individual samples to constrain the sum'
  id: totrans-2828
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šåœ¨å•ä¸ªæ ·æœ¬çš„ç‰¹å¾ä¸Šæ‰§è¡Œä»¥çº¦æŸæ€»å’Œ'
- en: The L1 Norm has the following constraint across samples,
  id: totrans-2829
  prefs: []
  type: TYPE_NORMAL
  zh: L1 èŒƒæ•°åœ¨æ ·æœ¬é—´æœ‰ä»¥ä¸‹çº¦æŸï¼Œ
- en: \[ \sum_{\alpha = 1}^m x^{\prime}_{i,\alpha} = 1.0, \quad i = 1, \ldots, n \]
  id: totrans-2830
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{\alpha = 1}^m x^{\prime}_{i,\alpha} = 1.0, \quad i = 1, \ldots, n \]
- en: The L1 normalizer transform,
  id: totrans-2831
  prefs: []
  type: TYPE_NORMAL
  zh: L1 æ­£åˆ™åŒ–å˜æ¢ï¼Œ
- en: \[ x^{\prime}_{i,\alpha} = \frac{x_{i,\alpha}}{\sum_{\alpha=1}^m x_{i,\alpha}}
    \]
  id: totrans-2832
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x^{\prime}_{i,\alpha} = \frac{x_{i,\alpha}}{\sum_{\alpha=1}^m x_{i,\alpha}}
    \]
- en: The L2 Norm has the following constraint across samples,
  id: totrans-2833
  prefs: []
  type: TYPE_NORMAL
  zh: L2 èŒƒæ•°åœ¨æ ·æœ¬é—´æœ‰ä»¥ä¸‹çº¦æŸï¼Œ
- en: \[ \sum_{\alpha = 1}^m \left( x^{\prime}_{i,\alpha} \right)^2 = 1.0, \quad i
    = 1, \ldots, n \]
  id: totrans-2834
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{\alpha = 1}^m \left( x^{\prime}_{i,\alpha} \right)^2 = 1.0, \quad i
    = 1, \ldots, n \]
- en: The L2 normalizer transform,
  id: totrans-2835
  prefs: []
  type: TYPE_NORMAL
  zh: L2 æ­£åˆ™åŒ–å˜æ¢ï¼Œ
- en: \[ x^{\prime}_{i,\alpha} = \sqrt{\frac{(x_{i,\alpha})^2}{\sum_{\alpha=1}^m (x_{i,\alpha})^2}}
    \]
  id: totrans-2836
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x^{\prime}_{i,\alpha} = \sqrt{\frac{(x_{i,\alpha})^2}{\sum_{\alpha=1}^m (x_{i,\alpha})^2}}
    \]
- en: Example, applied in text classification and clustering, and L1 for compositional
    data (sum 1.0 constraint)
  id: totrans-2837
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåº”ç”¨äºæ–‡æœ¬åˆ†ç±»å’Œèšç±»ï¼Œä»¥åŠç”¨äºç»„åˆæ•°æ®çš„L1ï¼ˆæ±‚å’Œçº¦æŸä¸º1.0ï¼‰
- en: '**LASSO Regression**'
  id: totrans-2838
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**LASSOå›å½’**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): linear regression
    with \(L^1\) regularization term and regularization hyperparameter \(\lambda\),'
  id: totrans-2839
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSOå›å½’](MachineLearning_LASSO_regression.html)ï¼šå…·æœ‰\(L^1\)æ­£åˆ™åŒ–é¡¹å’Œæ­£åˆ™åŒ–è¶…å‚æ•°Î»çš„çº¿æ€§å›å½’ï¼Œ'
- en: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
  id: totrans-2840
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
- en: As a result, LASSO regression training integrates two and often competing goals
    to find the model parameters,
  id: totrans-2841
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒLASSOå›å½’è®­ç»ƒæ•´åˆäº†ä¸¤ä¸ªç»å¸¸ç«äº‰çš„ç›®æ ‡æ¥å¯»æ‰¾æ¨¡å‹å‚æ•°ï¼Œ
- en: find the model parameters that minimize the error with training data
  id: totrans-2842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°æ¨¡å‹å‚æ•°ä»¥æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸­çš„è¯¯å·®
- en: minimize the slope parameters towards zero
  id: totrans-2843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ–œç‡å‚æ•°æœ€å°åŒ–åˆ°é›¶
- en: 'The only difference between LASSO and ridge regression is:'
  id: totrans-2844
  prefs: []
  type: TYPE_NORMAL
  zh: LASSOå’Œå²­å›å½’ä¹‹é—´çš„å”¯ä¸€åŒºåˆ«æ˜¯ï¼š
- en: for LASSO the shrinkage term is posed as an \(\ell_1\) penalty,
  id: totrans-2845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºLASSOï¼Œæ”¶ç¼©é¡¹è¢«è¡¨ç¤ºä¸º\(\ell_1\)æƒ©ç½šï¼Œ
- en: \[ \lambda \sum_{\alpha=1}^m |b_{\alpha}| \]
  id: totrans-2846
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda \sum_{\alpha=1}^m |b_{\alpha}| \]
- en: for ridge regression the shrinkage term is posed as an \(\ell_2\) penalty,
  id: totrans-2847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºå²­å›å½’ï¼Œæ”¶ç¼©é¡¹è¢«è¡¨ç¤ºä¸º\(\ell_2\)æƒ©ç½šï¼Œ
- en: \[ \lambda \sum_{\alpha=1}^m \left(b_{\alpha}\right)^2 \]
  id: totrans-2848
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda \sum_{\alpha=1}^m \left(b_{\alpha}\right)^2 \]
- en: 'While both ridge regression and the LASSO shrink the model parameters (\(b_{\alpha},
    \alpha = 1,\ldots,m\)) towards zero:'
  id: totrans-2849
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å²­å›å½’å’ŒLASSOéƒ½å°†æ¨¡å‹å‚æ•°(\(b_{\alpha}, \alpha = 1,\ldots,m\))æ”¶ç¼©åˆ°é›¶æ—¶ï¼š
- en: LASSO parameters reach zero at different rates for each predictor feature as
    the lambda, \(\lambda\), hyperparameter increases.
  id: totrans-2850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æ­£åˆ™åŒ–è¶…å‚æ•°Î»å¢åŠ æ—¶ï¼ŒLASSOå‚æ•°ä»¥ä¸åŒçš„é€Ÿç‡è¾¾åˆ°é›¶ï¼Œå¯¹äºæ¯ä¸ªé¢„æµ‹ç‰¹å¾ã€‚
- en: as a result LASSO provides a method for feature ranking and selection!
  id: totrans-2851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒLASSOæä¾›äº†ä¸€ç§ç‰¹å¾æ’åºå’Œé€‰æ‹©çš„æ–¹æ³•ï¼
- en: The lambda, \(\lambda\), hyperparameter controls the degree of fit of the model
    and may be related to the model bias-variance trade-off.
  id: totrans-2852
  prefs: []
  type: TYPE_NORMAL
  zh: Î»è¶…å‚æ•°æ§åˆ¶æ¨¡å‹çš„æ‹Ÿåˆç¨‹åº¦ï¼Œå¯èƒ½ä¸æ¨¡å‹çš„åå·®-æ–¹å·®æƒè¡¡æœ‰å…³ã€‚
- en: for \(\lambda \rightarrow 0\) the prediction model approaches linear regression,
    there is lower model bias, but the model variance is higher
  id: totrans-2853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“\(\lambda \rightarrow 0\)æ—¶ï¼Œé¢„æµ‹æ¨¡å‹è¶‹è¿‘äºçº¿æ€§å›å½’ï¼Œæ¨¡å‹åå·®è¾ƒä½ï¼Œä½†æ¨¡å‹æ–¹å·®è¾ƒé«˜
- en: as \(\lambda\) increases the model variance decreases and the model bias increases
  id: totrans-2854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“Î»å¢åŠ æ—¶ï¼Œæ¨¡å‹æ–¹å·®é™ä½ï¼Œæ¨¡å‹åå·®å¢åŠ 
- en: for \(\lambda \rightarrow \infty\) the coefficients all become 0.0 and the model
    is the training data response feature mean
  id: totrans-2855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“\(\lambda \rightarrow \infty\)æ—¶ï¼Œæ‰€æœ‰ç³»æ•°éƒ½å˜ä¸º0.0ï¼Œæ¨¡å‹æ˜¯è®­ç»ƒæ•°æ®å“åº”ç‰¹å¾çš„å¹³å‡å€¼
- en: '**Lazy Learning**'
  id: totrans-2856
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ‡’æƒ°å­¦ä¹ **'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): model is
    a generalization of the training data and calculation is delayed until query is
    made of the model'
  id: totrans-2857
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šæ¨¡å‹æ˜¯è®­ç»ƒæ•°æ®çš„ä¸€èˆ¬åŒ–ï¼Œè®¡ç®—åœ¨æŸ¥è¯¢æ¨¡å‹æ—¶æ‰è¿›è¡Œ'
- en: the model is the training data and selected hyperparameters, to make new predictions
    the training data must be available
  id: totrans-2858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ˜¯è®­ç»ƒæ•°æ®å’Œé€‰å®šçš„è¶…å‚æ•°ï¼Œè¦åšå‡ºæ–°çš„é¢„æµ‹ï¼Œå¿…é¡»æä¾›è®­ç»ƒæ•°æ®
- en: The opposite is eager learning.
  id: totrans-2859
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åçš„æ˜¯æ€¥åˆ‡å­¦ä¹ ã€‚
- en: '**Learning Rate** (gradient boosting)'
  id: totrans-2860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å­¦ä¹ ç‡**ï¼ˆæ¢¯åº¦æå‡ï¼‰'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): controls the rate
    of updating with each new model.'
  id: totrans-2861
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šæ§åˆ¶æ¯ä¸ªæ–°æ¨¡å‹æ›´æ–°çš„é€Ÿç‡ã€‚'
- en: \[ f_m = f_{m-1} - \rho_m \frac{\partial L(y_\alpha, F(X_\alpha))}{\partial
    F(X_\alpha)} \]
  id: totrans-2862
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f_m = f_{m-1} - \rho_m \frac{\partial L(y_\alpha, F(X_\alpha))}{\partial
    F(X_\alpha)} \]
- en: where \(\rho_m\) is the learning rate, \frac{\partial L(y_\alpha, F(X_\alpha))}{\partial
    F(X_\alpha)} is the gradient, error, \(f_{m-1}\) is the previous estimate, and
    \(f_m\) is the new estimate.
  id: totrans-2863
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­\(\rho_m\)æ˜¯å­¦ä¹ ç‡ï¼Œ\(\frac{\partial L(y_\alpha, F(X_\alpha))}{\partial F(X_\alpha)}\)æ˜¯æ¢¯åº¦ï¼Œè¯¯å·®ï¼Œ\(f_{m-1}\)æ˜¯å‰ä¸€ä¸ªä¼°è®¡ï¼Œ\(f_m\)æ˜¯æ–°çš„ä¼°è®¡ã€‚
- en: Some salient points about learning rate,
  id: totrans-2864
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå­¦ä¹ ç‡çš„ä¸€äº›æ˜¾è‘—ç‚¹ï¼Œ
- en: without learning rate, the boosting models learn too quickly and will have too
    high model variance
  id: totrans-2865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å­¦ä¹ ç‡ï¼Œæå‡æ¨¡å‹å­¦ä¹ å¾—å¤ªå¿«ï¼Œæ¨¡å‹æ–¹å·®ä¼šè¿‡é«˜
- en: slow down learning for a more robust model, balanced to ensure good performance,
    too small rate will require very large number of models to reach convergence
  id: totrans-2866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡ç¼“å­¦ä¹ é€Ÿåº¦ä»¥è·å¾—æ›´ç¨³å¥çš„æ¨¡å‹ï¼Œå¹³è¡¡ä»¥ç¡®ä¿è‰¯å¥½çš„æ€§èƒ½ï¼Œè¿‡å°çš„é€Ÿç‡å°†éœ€è¦éå¸¸å¤§çš„æ¨¡å‹æ•°é‡æ‰èƒ½è¾¾åˆ°æ”¶æ•›
- en: '**Likewise Deletion** (MRMR)'
  id: totrans-2867
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç±»ä¼¼åˆ é™¤**ï¼ˆMRMRï¼‰'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): removal of any sample
    with any missing feature values'
  id: totrans-2868
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šç§»é™¤ä»»ä½•å…·æœ‰ä»»ä½•ç¼ºå¤±ç‰¹å¾å€¼çš„æ ·æœ¬'
- en: if missing feature values are not missing at random (MAR) this may impart a
    bias in the data
  id: totrans-2869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœç¼ºå¤±çš„ç‰¹å¾å€¼ä¸æ˜¯éšæœºç¼ºå¤±ï¼ˆMARï¼‰ï¼Œè¿™å¯èƒ½ä¼šåœ¨æ•°æ®ä¸­å¼•å…¥åå·®
- en: will result in a decrease in the effective data size and increase in model uncertainty
  id: totrans-2870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å¯¼è‡´æœ‰æ•ˆæ•°æ®é‡å‡å°‘å’Œæ¨¡å‹ä¸ç¡®å®šæ€§å¢åŠ 
- en: '**Linear Regression**'
  id: totrans-2871
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çº¿æ€§å›å½’**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): a linear, parametric
    prediction model,'
  id: totrans-2872
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šä¸€ä¸ªçº¿æ€§ã€å‚æ•°åŒ–çš„é¢„æµ‹æ¨¡å‹ï¼Œ'
- en: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
  id: totrans-2873
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
- en: The analytical solution for the model parameters, \(b_1,\ldots,b_m,b_0\), is
    available for the L2 norm loss function, the errors are summed and squared known
    a least squares.
  id: totrans-2874
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºL2èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œæ¨¡å‹å‚æ•°\(b_1,\ldots,b_m,b_0\)çš„è§£æè§£æ˜¯å¯ç”¨çš„ï¼Œè¯¯å·®æ˜¯æ±‚å’Œå¹¶å¹³æ–¹çš„ï¼Œå·²çŸ¥ä¸ºæœ€å°äºŒä¹˜æ³•ã€‚
- en: 'we minimize the error, residual sum of squares (RSS) over the training data:'
  id: totrans-2875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®ï¼Œå³æ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰ï¼š
- en: \[ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0) \right)^2 \]
  id: totrans-2876
  prefs: []
  type: TYPE_NORMAL
  zh: \[ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0) \right)^2 \]
- en: where \(y_i\) is the actual response feature values and \(\sum_{\alpha = 1}^m
    b_{\alpha} x_{\alpha} + b_0\) are the model predictions, over the \(\alpha = 1,\ldots,n\)
    training data.
  id: totrans-2877
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­\(y_i\)æ˜¯å®é™…å“åº”ç‰¹å¾å€¼ï¼Œ\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\)æ˜¯æ¨¡å‹é¢„æµ‹ï¼Œåœ¨\(\alpha
    = 1,\ldots,n\)çš„è®­ç»ƒæ•°æ®ä¸Šã€‚
- en: this may be simplified as the sum of square error over the training data,
  id: totrans-2878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥ç®€åŒ–ä¸ºè®­ç»ƒæ•°æ®ä¸Šçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼Œ
- en: \[ \sum_{i=1}^n (\Delta y_i)^2 \]
  id: totrans-2879
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n (\Delta y_i)^2 \]
- en: where \(\Delta y_i\) is actual response feature observation \(y_i\) minus the
    model prediction \(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\), over the
    \(i = 1,\ldots,n\) training data.
  id: totrans-2880
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­\(\Delta y_i\)æ˜¯å®é™…å“åº”ç‰¹å¾è§‚æµ‹å€¼\(y_i\)å‡å»æ¨¡å‹é¢„æµ‹\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha}
    + b_0\)ï¼Œåœ¨\(i = 1,\ldots,n\)çš„è®­ç»ƒæ•°æ®ä¸Šã€‚
- en: There are important assumption with our linear regression model,
  id: totrans-2881
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„çº¿æ€§å›å½’æ¨¡å‹æœ‰ä¸€äº›é‡è¦çš„å‡è®¾ï¼Œ
- en: '*Error-free* - predictor variables are error free, not random variables'
  id: totrans-2882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— è¯¯å·®* - é¢„æµ‹å˜é‡æ— è¯¯å·®ï¼Œä¸æ˜¯éšæœºå˜é‡'
- en: '*Linearity* - response is linear combination of feature(s)'
  id: totrans-2883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*çº¿æ€§* - å“åº”æ˜¯ç‰¹å¾ï¼ˆsï¼‰çš„çº¿æ€§ç»„åˆ'
- en: '*Constant Variance* - error in response is constant over predictor(s) value'
  id: totrans-2884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¸¸æ•°æ–¹å·®* - å“åº”è¯¯å·®åœ¨é¢„æµ‹å€¼ä¸Šæ˜¯æ’å®šçš„'
- en: '*Independence of Error* - error in response are uncorrelated with each other'
  id: totrans-2885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¯¯å·®ç‹¬ç«‹æ€§* - å“åº”è¯¯å·®å½¼æ­¤ä¸ç›¸å…³'
- en: '*No multicollinearity* - none of the features are redundant with other features'
  id: totrans-2886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— å¤šé‡å…±çº¿æ€§* - æ²¡æœ‰ç‰¹å¾ä¸å…¶ä»–ç‰¹å¾å†—ä½™'
- en: '**Location Map**'
  id: totrans-2887
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä½ç½®å›¾**'
- en: '[Loading and Plotting Data and Models](MachineLearning_plotting_data_models.html):
    a data plot where the 2 axes are locations, e.g., \(X\) and \(Y\), Easting and
    Northing, Latitude and Longitude, etc., to show the locations and magnitudes of
    the spatial data.'
  id: totrans-2888
  prefs: []
  type: TYPE_NORMAL
  zh: '[åŠ è½½æ•°æ®å’Œç»˜å›¾æ¨¡å‹](MachineLearning_plotting_data_models.html)ï¼šä¸€ä¸ªæ•°æ®å›¾ï¼Œå…¶ä¸­ä¸¤ä¸ªè½´æ˜¯ä½ç½®ï¼Œä¾‹å¦‚\(X\)å’Œ\(Y\)ï¼Œä¸œè¥¿æ–¹å‘å’Œå—åŒ—æ–¹å‘ï¼Œçº¬åº¦å’Œç»åº¦ç­‰ï¼Œä»¥æ˜¾ç¤ºç©ºé—´æ•°æ®çš„ä½ç½®å’Œå¤§å°ã€‚'
- en: often the data points are colored to represent the scale of feature to visualize
    the sampled feature over the area or volume of interest
  id: totrans-2889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»å¸¸å°†æ•°æ®ç‚¹ç€è‰²ä»¥è¡¨ç¤ºç‰¹å¾çš„æ¯”ä¾‹ï¼Œä»¥ä¾¿åœ¨æ„Ÿå…´è¶£çš„åŒºåŸŸæˆ–ä½“ç§¯ä¸Šå¯è§†åŒ–é‡‡æ ·ç‰¹å¾
- en: advantage, visualize the data without any model that may bias our impression
    of the data
  id: totrans-2890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼Œå¯è§†åŒ–æ•°æ®è€Œä¸éœ€è¦ä»»ä½•å¯èƒ½å½±å“æˆ‘ä»¬å¯¹æ•°æ®å°è±¡çš„æ¨¡å‹
- en: disadvantage, may be difficult to visualize large datasets and data in 3D
  id: totrans-2891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼Œå¯èƒ½éš¾ä»¥å¯è§†åŒ–å¤§å‹æ•°æ®é›†å’Œä¸‰ç»´æ•°æ®
- en: '**Loss Function**'
  id: totrans-2892
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æŸå¤±å‡½æ•°**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): the equation that
    is minimized to train the model parameters. For example, the loss function for
    linear regression includes residual sum of square, the \(L^2\) error norm,'
  id: totrans-2893
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSOå›å½’](MachineLearning_LASSO_regression.html)ï¼šç”¨äºè®­ç»ƒæ¨¡å‹å‚æ•°çš„æœ€å°åŒ–æ–¹ç¨‹ã€‚ä¾‹å¦‚ï¼Œçº¿æ€§å›å½’çš„æŸå¤±å‡½æ•°åŒ…æ‹¬æ®‹å·®å¹³æ–¹å’Œã€\(L^2\)è¯¯å·®èŒƒæ•°ï¼Œ'
- en: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 \]
  id: totrans-2894
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 \]
- en: for LASSO regression the loss function includes residual sum of square, the
    \(L^2\) error norm, plus a \(L^1\) regularization term,
  id: totrans-2895
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºLASSOå›å½’ï¼ŒæŸå¤±å‡½æ•°åŒ…æ‹¬æ®‹å·®å¹³æ–¹å’Œã€\(L^2\)è¯¯å·®èŒƒæ•°ï¼Œä»¥åŠä¸€ä¸ª\(L^1\)æ­£åˆ™åŒ–é¡¹ï¼Œ
- en: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
  id: totrans-2896
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m |b_{\alpha}| \]
- en: for k-means clustering the loss function is,
  id: totrans-2897
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºk-meansèšç±»ï¼ŒæŸå¤±å‡½æ•°æ˜¯ï¼Œ
- en: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} \sqrt{ \sum_{j = 1}^m X_{\alpha,m}
    - \mu_{i,m} } \]
  id: totrans-2898
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I = \sum^k_{i=1} \sum_{\alpha \in C_i} \sqrt{ \sum_{j = 1}^m X_{\alpha,m}
    - \mu_{i,m} } \]
- en: The method to minimize loss functions depends on the type of norm,
  id: totrans-2899
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å°åŒ–æŸå¤±å‡½æ•°çš„æ–¹æ³•å–å†³äºèŒƒæ•°çš„ç±»å‹ï¼Œ
- en: with \(L^2\) norms we apply differentiation to the loss function with respect
    to the model parameter and set it equal to zero
  id: totrans-2900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(L^2\) èŒƒæ•°ï¼Œæˆ‘ä»¬å¯¹æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å‚æ•°è¿›è¡Œå¾®åˆ†ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºç­‰äºé›¶
- en: with \(L^1\) norms in our loss functions we lose access to an analytical solution
    and use iterative optimization, e.g., steepest descent
  id: totrans-2901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨ \(L^1\) èŒƒæ•°æ—¶ï¼Œæˆ‘ä»¬å¤±å»äº†åˆ†æè§£çš„è®¿é—®æƒé™ï¼Œå¹¶ä½¿ç”¨è¿­ä»£ä¼˜åŒ–ï¼Œä¾‹å¦‚æœ€é€Ÿä¸‹é™æ³•
- en: '**Machine Learning Workflow Design**'
  id: totrans-2902
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹è®¾è®¡**'
- en: 'Machine Learning Workflow Construction and Coding: is based on the following
    steps,'
  id: totrans-2903
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šåŸºäºä»¥ä¸‹æ­¥éª¤ï¼Œ
- en: '*Specify the Goals* - for example,'
  id: totrans-2904
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æŒ‡å®šç›®æ ‡* - ä¾‹å¦‚ï¼Œ'
- en: build a numerical model
  id: totrans-2905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å»ºç«‹æ•°å€¼æ¨¡å‹
- en: evaluate different recovery processes
  id: totrans-2906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯„ä¼°ä¸åŒçš„æ¢å¤è¿‡ç¨‹
- en: '*Specify the Data* - what is available and what is missing?'
  id: totrans-2907
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æŒ‡å®šæ•°æ®* - å¯ç”¨çš„æ˜¯ä»€ä¹ˆï¼Œç¼ºå°‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ'
- en: '*Design a Set of Steps to Accomplish the Goal* - common steps include,'
  id: totrans-2908
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®¾è®¡ä¸€ç»„æ­¥éª¤ä»¥å®ç°ç›®æ ‡* - å¸¸è§æ­¥éª¤åŒ…æ‹¬ï¼Œ'
- en: load data
  id: totrans-2909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®
- en: format, check and clean data
  id: totrans-2910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¼å¼åŒ–ã€æ£€æŸ¥å’Œæ¸…ç†æ•°æ®
- en: run operation, including, statistical calculation, model or visualization
  id: totrans-2911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿è¡Œæ“ä½œï¼ŒåŒ…æ‹¬ç»Ÿè®¡è®¡ç®—ã€æ¨¡å‹æˆ–å¯è§†åŒ–
- en: transfer function
  id: totrans-2912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è½¬æ¢å‡½æ•°
- en: '*Develop Documentation* - including implementation details, defense of decisions,
    metadata, limitations and future work'
  id: totrans-2913
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¼€å‘æ–‡æ¡£* - åŒ…æ‹¬å®ç°ç»†èŠ‚ã€å†³ç­–çš„è¾©æŠ¤ã€å…ƒæ•°æ®ã€é™åˆ¶å’Œæœªæ¥å·¥ä½œ'
- en: '*Flow* - data and information flow, learning while modeling with branches and
    loop backs'
  id: totrans-2914
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æµç¨‹* - æ•°æ®å’Œä¿¡æ¯æµï¼Œåœ¨å»ºæ¨¡æ—¶ä½¿ç”¨åˆ†æ”¯å’Œå›ç¯è¿›è¡Œå­¦ä¹ '
- en: '*Uncertainty* - summarize all uncertainty sources, include methods to integrate
    uncertainty, defend the uncertainty models and aspects deemed certain'
  id: totrans-2915
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸ç¡®å®šæ€§* - æ€»ç»“æ‰€æœ‰ä¸ç¡®å®šæ€§æ¥æºï¼ŒåŒ…æ‹¬é›†æˆä¸ç¡®å®šæ€§çš„æ–¹æ³•ï¼Œè¾©æŠ¤ä¸ç¡®å®šæ€§æ¨¡å‹å’Œè¢«è®¤ä¸ºç¡®å®šçš„å› ç´ '
- en: '**Margin** (support vector machines)'
  id: totrans-2916
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¾¹ç¼˜**ï¼ˆæ”¯æŒå‘é‡æœºï¼‰'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): when
    the training data include overlapping categories it would not be possible, nor
    desirable, to develop a decision boundary that perfectly separates the categories
    for which this condition would hold,'
  id: totrans-2917
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šå½“è®­ç»ƒæ•°æ®åŒ…æ‹¬é‡å ç±»åˆ«æ—¶ï¼Œä¸å¯èƒ½ä¹Ÿä¸å¸Œæœ›å¼€å‘ä¸€ä¸ªå®Œç¾åˆ†ç¦»è¿™äº›ç±»åˆ«çš„å†³ç­–è¾¹ç•Œï¼Œå¯¹äºè¿™ä¸ªæ¡ä»¶å°†æˆç«‹ï¼Œ'
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
  id: totrans-2918
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
- en: We need a model that allows for some misclassification.
  id: totrans-2919
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå…è®¸æŸäº›è¯¯åˆ†ç±»çš„æ¨¡å‹ã€‚
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
  id: totrans-2920
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
- en: We introduce the concept of a margin, \(ğ‘€\), and a distance from the margin
    (error, ğœ‰_ğ‘–).
  id: totrans-2921
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼•å…¥äº†è¾¹ç¼˜çš„æ¦‚å¿µ \(ğ‘€\) å’Œè¾¹ç¼˜çš„è·ç¦»ï¼ˆè¯¯å·®ï¼Œ\(ğœ‰_ğ‘–\)ï¼‰ã€‚
- en: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
  id: totrans-2922
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
- en: The loss function includes the margin term, \(M\), and hence attempts to minimize
    margin while minimizing classification error weighted by hyperparameter, \(C\).
  id: totrans-2923
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°åŒ…æ‹¬è¾¹ç¼˜é¡¹ \(M\)ï¼Œå› æ­¤è¯•å›¾åœ¨æœ€å°åŒ–åˆ†ç±»é”™è¯¯çš„åŒæ—¶æœ€å°åŒ–è¾¹ç¼˜ï¼Œè€Œåˆ†ç±»é”™è¯¯ç”±è¶…å‚æ•° \(C\) åŠ æƒã€‚
- en: '**Marginal Probability**'
  id: totrans-2924
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¾¹ç¼˜æ¦‚ç‡**'
- en: '[Probability Concepts](MachineLearning_probability.html): probability that
    considers only one event occurring, the probability of \(A\),'
  id: totrans-2925
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåªè€ƒè™‘ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ï¼Œå³ \(A\) çš„æ¦‚ç‡ï¼Œ'
- en: \[ P(A) \]
  id: totrans-2926
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) \]
- en: marginal probabilities may be calculated from joint probabilities through the
    process of marginalization,
  id: totrans-2927
  prefs: []
  type: TYPE_NORMAL
  zh: è¾¹ç¼˜æ¦‚ç‡å¯ä»¥é€šè¿‡è¾¹ç¼˜åŒ–è¿‡ç¨‹ä»è”åˆæ¦‚ç‡ä¸­è®¡ç®—å¾—å‡ºï¼Œ
- en: \[ P(A) = \int_{-\infty}^{\infty} P(A,B) dB \]
  id: totrans-2928
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) = \int_{-\infty}^{\infty} P(A,B) dB \]
- en: where we integrate over all cases of the other event, \(B\), to remove its influence.
    Given discrete possible cases of event \(B\) we can simply sum the probabilities
    over all possible cases of \(B\),
  id: totrans-2929
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯¹å…¶ä»–äº‹ä»¶çš„æ‰€æœ‰æƒ…å†µ \(B\) è¿›è¡Œç§¯åˆ†ï¼Œä»¥æ¶ˆé™¤å…¶å½±å“ã€‚å¯¹äºäº‹ä»¶ \(B\) çš„ç¦»æ•£å¯èƒ½æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°å¯¹æ‰€æœ‰å¯èƒ½çš„ \(B\) çš„æƒ…å†µæ±‚å’Œæ¦‚ç‡ï¼Œ
- en: \[ P(A) = \sum_{i=1}^{k_B} P(A,B) dB \]
  id: totrans-2930
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) = \sum_{i=1}^{k_B} P(A,B) dB \]
- en: '**Matrix Scatter Plots**'
  id: totrans-2931
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**çŸ©é˜µæ•£ç‚¹å›¾**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): composite
    plot including the combinatorial of all pair-wise scatter plots for all features.'
  id: totrans-2932
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šåŒ…æ‹¬æ‰€æœ‰ç‰¹å¾çš„æ‰€æœ‰æˆå¯¹æ•£ç‚¹å›¾çš„ç»„åˆå›¾ã€‚'
- en: given \(m\) features, there are \(m \times m\) scatter plots
  id: totrans-2933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®š \(m\) ä¸ªç‰¹å¾ï¼Œæœ‰ \(m \times m\) ä¸ªæ•£ç‚¹å›¾
- en: the scatter plots are ordered, y-axis feature from \(X_1,\ldots,X_m\) over the
    rows and x-axis feature from \(X_1,\ldots,X_m\) over the columns
  id: totrans-2934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•£ç‚¹å›¾æ˜¯æœ‰åºçš„ï¼Œyè½´ç‰¹å¾ä» \(X_1,\ldots,X_m\) åˆ°è¡Œï¼Œxè½´ç‰¹å¾ä» \(X_1,\ldots,X_m\) åˆ°åˆ—
- en: the diagonal is the features plotted with themselves and are often replaced
    with feature histograms or probability density functions
  id: totrans-2935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹è§’çº¿æ˜¯ç‰¹å¾ä¸å…¶è‡ªèº«ç»˜åˆ¶çš„ï¼Œé€šå¸¸è¢«ç‰¹å¾ç›´æ–¹å›¾æˆ–æ¦‚ç‡å¯†åº¦å‡½æ•°æ‰€å–ä»£
- en: We use matrix scatter plots to,
  id: totrans-2936
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨çŸ©é˜µæ•£ç‚¹å›¾æ¥ï¼Œ
- en: look for bivariate linear or nonlinear structures
  id: totrans-2937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾äºŒå…ƒçº¿æ€§æˆ–éçº¿æ€§ç»“æ„
- en: look for bivariate homoscedasticity (constant conditional variance) and heteroscedasticity
    (conditional variance changes with value)
  id: totrans-2938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾äºŒå…ƒåŒæ–¹å·®ï¼ˆæ¡ä»¶æ–¹å·®æ’å®šï¼‰å’Œå¼‚æ–¹å·®ï¼ˆæ¡ä»¶æ–¹å·®éšå€¼å˜åŒ–ï¼‰
- en: look for bivariate constraints, such as sum constraints with compositional data
  id: totrans-2939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯»æ‰¾äºŒå…ƒçº¦æŸï¼Œä¾‹å¦‚ï¼Œå…·æœ‰æˆåˆ†æ•°æ®çš„æ±‚å’Œçº¦æŸ
- en: Remember, the other features are marginalized, this is not a full m-D visualization.
  id: totrans-2940
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œå…¶ä»–ç‰¹å¾è¢«è¾¹ç¼˜åŒ–ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„ m-D å¯è§†åŒ–ã€‚
- en: '**Maximum Relevance Minimum Redundancy** (MRMR)'
  id: totrans-2941
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æœ€å¤§ç›¸å…³æ€§æœ€å°å†—ä½™** (MRMR)'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a mutual information-based
    approach for feature ranking that accounts for feature relevance and redundancy.'
  id: totrans-2942
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸€ç§åŸºäºäº’ä¿¡æ¯çš„ç‰¹å¾æ’åºæ–¹æ³•ï¼Œè€ƒè™‘äº†ç‰¹å¾çš„ç›¸å…³æ€§å’Œå†—ä½™ã€‚'
- en: one example is a relevance minus redundancy summary,
  id: totrans-2943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¾‹å­æ˜¯ç›¸å…³æ€§å‡å»å†—ä½™çš„æ€»ç»“ï¼Œ
- en: \[ MRMR = max \left[ frac{1}{|S|} \sum_{X_i \in S} I(X_i,Y) - \frac{1}{|S|^2}
    \sum_{X_i \in S} \sum_{X_j, i \ne j} I(X_i,X_j) \right] \]
  id: totrans-2944
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MRMR = max \left[ frac{1}{|S|} \sum_{X_i \in S} I(X_i,Y) - \frac{1}{|S|^2}
    \sum_{X_i \in S} \sum_{X_j, i \ne j} I(X_i,X_j) \right] \]
- en: where \(ğ‘†\) is the predictor feature subset and \(|ğ‘†|\) is the number of features
    in the subset \(ğ‘†\).
  id: totrans-2945
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(ğ‘†\) æ˜¯é¢„æµ‹ç‰¹å¾å­é›†ï¼Œè€Œ \(|ğ‘†|\) æ˜¯å­é›† \(ğ‘†\) ä¸­çš„ç‰¹å¾æ•°é‡ã€‚
- en: '**Metropolis-Hastings MCMC Sampler**'
  id: totrans-2946
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Metropolis-Hastings MCMC æ ·æœ¬å™¨**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    The basic steps of the Metropolis-Hastings MCMC Sampler:'
  id: totrans-2947
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šMetropolis-Hastings
    MCMC æ ·æœ¬å™¨çš„åŸºæœ¬æ­¥éª¤ï¼š'
- en: 'For \(\ell = 1, \ldots, L\):'
  id: totrans-2948
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¯¹äº \(\ell = 1, \ldots, L\):'
- en: Assign random values for the initial sample of model parameters, \(\beta(\ell
    = 1) = b_1(\ell = 1)\), \(b_0(\ell = 1)\) and \(\sigma^2(\ell = 1)\).
  id: totrans-2949
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¨¡å‹å‚æ•°çš„åˆå§‹æ ·æœ¬åˆ†é…éšæœºå€¼ï¼Œ\(\beta(\ell = 1) = b_1(\ell = 1)\)ï¼Œ\(b_0(\ell = 1)\) å’Œ \(\sigma^2(\ell
    = 1)\)ã€‚
- en: Propose new model parameters based on a proposal function, \(\beta^{\prime}
    = b_1\), \(b_0\) and \(\sigma^2\).
  id: totrans-2950
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®æè®®å‡½æ•°æå‡ºæ–°çš„æ¨¡å‹å‚æ•°ï¼Œ\(\beta^{\prime} = b_1\)ï¼Œ\(b_0\) å’Œ \(\sigma^2\).
- en: Calculate probability of acceptance of the new proposal, as the ratio of the
    posterior probability of the new model parameters given the data to the previous
    model parameters given the data multiplied by the probability of the old step
    given the new step divided by the probability of the new step given the old.
  id: totrans-2951
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–°æè®®çš„æ¥å—æ¦‚ç‡ï¼Œå³æ–°æ¨¡å‹å‚æ•°åœ¨ç»™å®šæ•°æ®ä¸‹çš„åéªŒæ¦‚ç‡ä¸æ—§æ¨¡å‹å‚æ•°åœ¨ç»™å®šæ•°æ®ä¸‹çš„åéªŒæ¦‚ç‡çš„æ¯”å€¼ï¼Œä¹˜ä»¥æ—§æ­¥éª¤åœ¨ç»™å®šæ–°æ­¥éª¤ä¸‹çš„æ¦‚ç‡é™¤ä»¥æ–°æ­¥éª¤åœ¨ç»™å®šæ—§æ­¥éª¤ä¸‹çš„æ¦‚ç‡ã€‚
- en: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
  id: totrans-2952
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
- en: Apply Monte Carlo simulation to conditionally accept the proposal, if accepted,
    \(\ell = \ell + 1\), and sample \(\beta(\ell) = \beta^{\prime}\)
  id: totrans-2953
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ¥æ¡ä»¶æ€§åœ°æ¥å—æè®®ï¼Œå¦‚æœè¢«æ¥å—ï¼Œ\(\ell = \ell + 1\)ï¼Œå¹¶é‡‡æ · \(\beta(\ell) = \beta^{\prime}\)
- en: Go to step 2.
  id: totrans-2954
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è½¬åˆ°æ­¥éª¤ 2ã€‚
- en: '**Minkowski Distance**'
  id: totrans-2955
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Minkowski è·ç¦»**'
- en: '[k-Nearest Neighbours](MachineLearning_knearest_neighbours.html): a general
    expression for distance with well-known Manhattan and Euclidean distances are
    special cases,'
  id: totrans-2956
  prefs: []
  type: TYPE_NORMAL
  zh: '[k-æœ€è¿‘é‚»](MachineLearning_knearest_neighbours.html)ï¼šè·ç¦»çš„ä¸€èˆ¬è¡¨è¾¾å¼ï¼Œå…¶ä¸­å·²çŸ¥çš„æ›¼å“ˆé¡¿å’Œæ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œ'
- en: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
  id: totrans-2957
  prefs: []
  type: TYPE_NORMAL
  zh: \[ d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p
    \right)^{\frac{1}{p}} \]
- en: when \(p=2\), this becomes the Euclidean distance
  id: totrans-2958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(p=2\) æ—¶ï¼Œè¿™å˜ä¸ºæ¬§å‡ é‡Œå¾—è·ç¦»
- en: when \(p=1\) it becomes the Manhattan distance
  id: totrans-2959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(p=1\) æ—¶ï¼Œå®ƒå˜ä¸ºæ›¼å“ˆé¡¿è·ç¦»
- en: '**Missing Feature Values**'
  id: totrans-2960
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¼ºå¤±ç‰¹å¾å€¼**'
- en: '[Feature Imputation](MachineLearning_feature_imputation.html): null values
    in the data table, samples that do not have values for all features'
  id: totrans-2961
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’è¡¥](MachineLearning_feature_imputation.html)ï¼šæ•°æ®è¡¨ä¸­çš„ç©ºå€¼ï¼Œæ²¡æœ‰æ‰€æœ‰ç‰¹å¾å€¼çš„æ ·æœ¬'
- en: There are many causes of missing feature values, for example,
  id: totrans-2962
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±ç‰¹å¾å€¼çš„åŸå› æœ‰å¾ˆå¤šï¼Œä¾‹å¦‚ï¼Œ
- en: sampling cost, e.g., low permeability test takes too long
  id: totrans-2963
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡‡æ ·æˆæœ¬ï¼Œä¾‹å¦‚ï¼Œä½æ¸—é€ç‡æµ‹è¯•è€—æ—¶è¿‡é•¿
- en: rock rheology sample filter, e.g., canâ€™t recover the mudstone samples
  id: totrans-2964
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å²©çŸ³æµå˜å­¦æ ·æœ¬è¿‡æ»¤å™¨ï¼Œä¾‹å¦‚ï¼Œæ— æ³•æ¢å¤æ³¥å²©æ ·æœ¬
- en: sampling to reduce uncertainty and maximize profitability instead of statistical
    representativity, dual purpose samples for information and production
  id: totrans-2965
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡é‡‡æ ·å‡å°‘ä¸ç¡®å®šæ€§å¹¶æœ€å¤§åŒ–ç›ˆåˆ©æ€§ï¼Œè€Œä¸æ˜¯ç»Ÿè®¡ä»£è¡¨æ€§ï¼ŒåŒé‡ç”¨é€”æ ·å“ç”¨äºä¿¡æ¯å’Œç”Ÿäº§
- en: Missing data consequences, more than reducing the amount of training and testing
    data, missing data, if not completely at random may result in,
  id: totrans-2966
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±æ•°æ®åæœï¼Œä¸ä»…ä»…æ˜¯å‡å°‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é‡ï¼Œå¦‚æœç¼ºå¤±æ•°æ®ä¸æ˜¯å®Œå…¨éšæœºï¼Œå¯èƒ½ä¼šäº§ç”Ÿï¼Œ
- en: biased sample statistics resulting in biased model training and testing
  id: totrans-2967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ ·æœ¬ç»Ÿè®¡å¯¼è‡´æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•åå·®
- en: biased models with biased predictions with potentially no indication of the
    bias
  id: totrans-2968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ¨¡å‹å…·æœ‰åå·®é¢„æµ‹ï¼Œå¯èƒ½æ²¡æœ‰åå·®çš„æŒ‡ç¤º
- en: '**Missing at Random** (MAR)'
  id: totrans-2969
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éšæœºç¼ºå¤±** (MAR)'
- en: '[Feature Imputation](MachineLearning_feature_imputation.html): missing feature
    values are distributed randomly, uniform coverage over the predictor feature space,
    i.e., all values have likelihood to be missing, and no correlation between missing
    feature values.'
  id: totrans-2970
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’è¡¥](MachineLearning_feature_imputation.html)ï¼šç¼ºå¤±ç‰¹å¾å€¼æ˜¯éšæœºåˆ†å¸ƒçš„ï¼Œåœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸­å‡åŒ€è¦†ç›–ï¼Œå³æ‰€æœ‰å€¼éƒ½æœ‰å¯èƒ½ç¼ºå¤±ï¼Œå¹¶ä¸”ç¼ºå¤±ç‰¹å¾å€¼ä¹‹é—´æ²¡æœ‰ç›¸å…³æ€§ã€‚'
- en: This is typically not the case as missing data often has a confounding feature,
    for example,
  id: totrans-2971
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é€šå¸¸ä¸æ˜¯æƒ…å†µï¼Œå› ä¸ºç¼ºå¤±æ•°æ®é€šå¸¸å…·æœ‰æ··æ‚ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ
- en: sampling cost, e.g., low permeability test takes too long
  id: totrans-2972
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡‡æ ·æˆæœ¬ï¼Œä¾‹å¦‚ï¼Œä½æ¸—é€ç‡æµ‹è¯•è€—æ—¶è¿‡é•¿
- en: rock rheology sample filter, e.g., canâ€™t recover the mudstone samples
  id: totrans-2973
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å²©çŸ³æµå˜å­¦æ ·å“è¿‡æ»¤å™¨ï¼Œä¾‹å¦‚ï¼Œæ— æ³•æ¢å¤æ³¥å²©æ ·å“
- en: sampling to reduce uncertainty and maximize profitability instead of statistical
    representativity, dual purpose samples for information and production
  id: totrans-2974
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡é‡‡æ ·å‡å°‘ä¸ç¡®å®šæ€§å¹¶æœ€å¤§åŒ–ç›ˆåˆ©æ€§ï¼Œè€Œä¸æ˜¯ç»Ÿè®¡ä»£è¡¨æ€§ï¼ŒåŒé‡ç”¨é€”æ ·å“ç”¨äºä¿¡æ¯å’Œç”Ÿäº§
- en: Missing data consequences, more than reducing the amount of training and testing
    data, missing data, if not completely at random may result in,
  id: totrans-2975
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±æ•°æ®åæœï¼Œä¸ä»…ä»…æ˜¯å‡å°‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é‡ï¼Œå¦‚æœç¼ºå¤±æ•°æ®ä¸æ˜¯å®Œå…¨éšæœºï¼Œå¯èƒ½ä¼šäº§ç”Ÿï¼Œ
- en: biased sample statistics resulting in biased model training and testing
  id: totrans-2976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ ·æœ¬ç»Ÿè®¡å¯¼è‡´æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•åå·®
- en: biased models with biased predictions with potentially no indication of the
    bias
  id: totrans-2977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®æ¨¡å‹å…·æœ‰åå·®é¢„æµ‹ï¼Œå¯èƒ½æ²¡æœ‰åå·®çš„æŒ‡ç¤º
- en: '**Model Bias**'
  id: totrans-2978
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åå·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is error due to
    insufficient complexity and flexibility to fit the natural setting'
  id: totrans-2979
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯ç”±äºæ¨¡å‹å¤æ‚æ€§å’Œçµæ´»æ€§ä¸è¶³ï¼Œæ— æ³•é€‚åº”è‡ªç„¶è®¾ç½®è€Œäº§ç”Ÿçš„é”™è¯¯'
- en: increasing model complexity usually results in decreasing model bias
  id: totrans-2980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ æ¨¡å‹å¤æ‚åº¦é€šå¸¸ä¼šå¯¼è‡´æ¨¡å‹åå·®å‡å°‘
- en: '*model bias variance trade-off* - as complexity increases, model variance increases
    and model bias decreases'
  id: totrans-2981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹åå·®æ–¹å·®æƒè¡¡* - éšç€å¤æ‚æ€§çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å¢åŠ ï¼Œæ¨¡å‹åå·®å‡å°‘'
- en: one of the three components of expected test square error, including model variance,
    model bias and irreducible error
  id: totrans-2982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æ¨¡å‹æ–¹å·®ã€æ¨¡å‹åå·®å’Œä¸å¯å‡å°‘è¯¯å·®
- en: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
  id: totrans-2983
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
- en: where \(\left(E [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0)
    \right)^2\) is model bias.
  id: totrans-2984
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\left(E [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2\)
    æ˜¯æ¨¡å‹åå·®ã€‚
- en: '**Model-Bias Variance Trade-off**'
  id: totrans-2985
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åå·®æ–¹å·®æƒè¡¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): as complexity increases,
    model variance increases and model bias decreases.'
  id: totrans-2986
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šéšç€å¤æ‚æ€§çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å¢åŠ ï¼Œæ¨¡å‹åå·®å‡å°‘ã€‚'
- en: as model variance and model bias are both components of expected test square
    error, the balancing of model bias and model variance results in an optimum level
    of complexity to minimize the testing error
  id: totrans-2987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæ¨¡å‹æ–¹å·®å’Œæ¨¡å‹åå·®éƒ½æ˜¯é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ç»„æˆéƒ¨åˆ†ï¼Œå› æ­¤æ¨¡å‹åå·®å’Œæ¨¡å‹æ–¹å·®çš„å¹³è¡¡å¯¼è‡´äº†ä¸€ä¸ªæœ€ä½³å¤æ‚åº¦æ°´å¹³ï¼Œä»¥æœ€å°åŒ–æµ‹è¯•è¯¯å·®
- en: '**Model Checking**'
  id: totrans-2988
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ£€æŸ¥**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is a critical last
    step for any spatial modeling workflow. Here are the critical aspects of model
    checking,'
  id: totrans-2989
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯ä»»ä½•ç©ºé—´å»ºæ¨¡å·¥ä½œæµç¨‹çš„å…³é”®æœ€åä¸€æ­¥ã€‚ä»¥ä¸‹æ˜¯æ¨¡å‹æ£€æŸ¥çš„å…³é”®æ–¹é¢ï¼Œ'
- en: '*Model Inputs* - data and statistics integration'
  id: totrans-2990
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹è¾“å…¥* - æ•°æ®å’Œç»Ÿè®¡æ•´åˆ'
- en: check the model to ensure the model inputs are honored in the models, generally
    checked over all the realizations, for example, the output histograms and matches
    the input histogram over the realizations
  id: totrans-2991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ¨¡å‹ä»¥ç¡®ä¿æ¨¡å‹è¾“å…¥åœ¨æ¨¡å‹ä¸­å¾—åˆ°å°Šé‡ï¼Œé€šå¸¸å¯¹æ‰€æœ‰å®ç°è¿›è¡Œæ£€æŸ¥ï¼Œä¾‹å¦‚ï¼Œè¾“å‡ºç›´æ–¹å›¾ä¸å®ç°ä¸­çš„è¾“å…¥ç›´æ–¹å›¾ç›¸åŒ¹é…
- en: '*Accurate Spatial Estimates* - ability of the model to accurately predict away
    from the available sample data, over a variety of configurations, with accuracy'
  id: totrans-2992
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç²¾ç¡®ç©ºé—´ä¼°è®¡* - æ¨¡å‹åœ¨å¯ç”¨æ ·æœ¬æ•°æ®ä¹‹å¤–ï¼Œåœ¨å„ç§é…ç½®ä¸‹ï¼Œä»¥ç²¾åº¦é¢„æµ‹çš„èƒ½åŠ›'
- en: by cross validation, withholding some of the data, check the modelâ€™s ability
    to predict
  id: totrans-2993
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡äº¤å‰éªŒè¯ï¼Œä¿ç•™éƒ¨åˆ†æ•°æ®ï¼Œæ£€æŸ¥æ¨¡å‹é¢„æµ‹çš„èƒ½åŠ›
- en: generally, summarized with a truth vs. predicted cross plot and measures such
    as mean square error
  id: totrans-2994
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç”¨çœŸå®å€¼ä¸é¢„æµ‹äº¤å‰å›¾å’Œå‡æ–¹è¯¯å·®ç­‰æŒ‡æ ‡æ¥æ€»ç»“
- en: \[ MSE = \frac{1}{n} \sum_{\alpha = 1}^{n} \left(z^{*}(\bf{u}_{\alpha}) - z(\bf{u}_{\alpha})
    \right)^2 \]
  id: totrans-2995
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MSE = \frac{1}{n} \sum_{\alpha = 1}^{n} \left(z^{*}(\bf{u}_{\alpha}) - z(\bf{u}_{\alpha})
    \right)^2 \]
- en: '*Accurate and Precise Uncertainty Models* - uncertainty model is fair given
    the amount of information available and various sources of uncertainty'
  id: totrans-2996
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç²¾ç¡®å’Œç²¾ç¡®çš„ä¸ç¡®å®šæ€§æ¨¡å‹* - åœ¨ç»™å®šä¿¡æ¯é‡å’Œå„ç§ä¸ç¡®å®šæ€§æ¥æºçš„æƒ…å†µä¸‹ï¼Œä¸ç¡®å®šæ€§æ¨¡å‹æ˜¯å…¬å¹³çš„'
- en: also checked through cross validation, withholding some of the data, but by
    checking the proportion of the data in specific probability intervals
  id: totrans-2997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿé€šè¿‡äº¤å‰éªŒè¯ï¼Œä¿ç•™éƒ¨åˆ†æ•°æ®ï¼Œä½†é€šè¿‡æ£€æŸ¥ç‰¹å®šæ¦‚ç‡åŒºé—´ä¸­çš„æ•°æ®æ¯”ä¾‹
- en: summarized with a proportion of withheld data in interval vs. the probability
    interval
  id: totrans-2998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨ä¿ç•™æ•°æ®çš„æ¯”ä¾‹åœ¨åŒºé—´ä¸æ¦‚ç‡åŒºé—´ä¹‹é—´çš„æ¯”ä¾‹æ¥æ€»ç»“
- en: points on the 45 degree line indicate accurate and precise uncertainty model
  id: totrans-2999
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨45åº¦çº¿ä¸Šçš„ç‚¹è¡¨ç¤ºç²¾ç¡®å’Œç²¾ç¡®çš„ä¸ç¡®å®šæ€§æ¨¡å‹
- en: points above the 45 degree line indicate accurate and imprecise uncertainty
    model, uncertainty is too wide
  id: totrans-3000
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨45åº¦çº¿ä»¥ä¸Šçš„ç‚¹è¡¨ç¤ºç²¾ç¡®å’Œä¸ç²¾ç¡®çš„ä¸ç¡®å®šæ€§æ¨¡å‹ï¼Œä¸ç¡®å®šæ€§å¤ªå®½
- en: points below the 45 degree line indicate inaccurate uncertainty model, uncertainty
    is too narrow or model is biased
  id: totrans-3001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨45åº¦çº¿ä»¥ä¸‹çš„ç‚¹è¡¨ç¤ºä¸ç²¾ç¡®çš„ä¸ç¡®å®šæ€§æ¨¡å‹ï¼Œä¸ç¡®å®šæ€§å¤ªçª„æˆ–æ¨¡å‹å­˜åœ¨åå·®
- en: '**Model Complexity or Flexibility**'
  id: totrans-3002
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å¤æ‚åº¦æˆ–çµæ´»æ€§**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the ability of
    a model to fit to data and to be interpreted.'
  id: totrans-3003
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ¨¡å‹æ‹Ÿåˆæ•°æ®å’Œå¯è§£é‡Šçš„èƒ½åŠ›ã€‚'
- en: A variety of concepts may be used to describe model complexity,
  id: totrans-3004
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥ä½¿ç”¨å„ç§æ¦‚å¿µæ¥æè¿°æ¨¡å‹å¤æ‚åº¦ï¼Œ
- en: the number of features, predictor variables are in the model, dimensionality
    of the model, usually resulting in more model parameters
  id: totrans-3005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹ä¸­çš„ç‰¹å¾æ•°é‡ã€é¢„æµ‹å˜é‡ï¼Œæ¨¡å‹çš„ç»´åº¦ï¼Œé€šå¸¸å¯¼è‡´æ›´å¤šçš„æ¨¡å‹å‚æ•°
- en: the number of parameters, the order applied for each term, e.g. linear, quadratic,
    thresholds
  id: totrans-3006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚æ•°çš„æ•°é‡ï¼Œæ¯ä¸ªé¡¹åº”ç”¨çš„é¡ºåºï¼Œä¾‹å¦‚çº¿æ€§ã€äºŒæ¬¡ã€é˜ˆå€¼
- en: the format of the model, i.e., a compact equation with polynomial regression
    vs. nested conditional statements with decision tree vs. thousands of weights
    and bias model parameters for a neural network
  id: totrans-3007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„æ ¼å¼ï¼Œå³å¤šé¡¹å¼å›å½’çš„ç´§å‡‘æ–¹ç¨‹ä¸å†³ç­–æ ‘åµŒå¥—æ¡ä»¶è¯­å¥ç›¸æ¯”ï¼Œä¸ç¥ç»ç½‘ç»œæˆåƒä¸Šä¸‡çš„æƒé‡å’Œåå·®æ¨¡å‹å‚æ•°ç›¸æ¯”
- en: For example, more complexity with a high order polynomial, larger decision trees
    etc.
  id: totrans-3008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ›´é«˜é˜¶çš„å¤šé¡¹å¼ã€æ›´å¤§çš„å†³ç­–æ ‘ç­‰æ›´å¤æ‚
- en: In general, more complicated or flexible models are more difficult to interpret,
  id: totrans-3009
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ›´å¤æ‚æˆ–çµæ´»çš„æ¨¡å‹æ›´éš¾ä»¥è§£é‡Šï¼Œ
- en: linear regression and the associated model parameters can be analyzed and even
    applied for feature ranking, while support vector machines with radial basis functions
    are a linear model in the nD high dimensional space
  id: totrans-3010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’åŠå…¶ç›¸å…³æ¨¡å‹å‚æ•°å¯ä»¥è¿›è¡Œåˆ†æå’Œç”šè‡³åº”ç”¨äºç‰¹å¾æ’åºï¼Œè€Œå…·æœ‰å¾„å‘åŸºå‡½æ•°çš„æ”¯æŒå‘é‡æœºåœ¨nDé«˜ç»´ç©ºé—´ä¸­æ˜¯ä¸€ä¸ªçº¿æ€§æ¨¡å‹
- en: '**Model Generalization**'
  id: totrans-3011
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ³›åŒ–**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the ability of
    a model to predict away from training data.'
  id: totrans-3012
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¹‹å¤–é¢„æµ‹çš„èƒ½åŠ›ã€‚'
- en: the model learns the structure in the data and does not just memorize the training
    data
  id: totrans-3013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹å­¦ä¹ æ•°æ®ä¸­çš„ç»“æ„ï¼Œè€Œä¸ä»…ä»…æ˜¯è®°ä½è®­ç»ƒæ•°æ®
- en: Models that do not generalize well,
  id: totrans-3014
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸ä½³ï¼Œ
- en: overfit models have high accuracy at training data and low accuracy away from
    training data, demonstrated with low testing accuracy
  id: totrans-3015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡æ‹Ÿåˆæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šå…·æœ‰é«˜ç²¾åº¦ï¼Œè€Œåœ¨è®­ç»ƒæ•°æ®ä¹‹å¤–çš„æ•°æ®ä¸Šç²¾åº¦è¾ƒä½ï¼Œè¿™é€šè¿‡ä½æµ‹è¯•ç²¾åº¦å¾—åˆ°ä½“ç°
- en: underfit models are too simple or inflexible for the natural phenomenon and
    have low training and testing accuracy
  id: totrans-3016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¬ æ‹Ÿåˆæ¨¡å‹å¯¹äºè‡ªç„¶ç°è±¡æ¥è¯´è¿‡äºç®€å•æˆ–ä¸çµæ´»ï¼Œå…·æœ‰ä½è®­ç»ƒå’Œæµ‹è¯•ç²¾åº¦
- en: '**Model Hyperparameters**'
  id: totrans-3017
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹è¶…å‚æ•°**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): constrain the model
    complexity. Hyperparameters are tuned to maximize accuracy with the withheld testing
    data to prevent model overfit.'
  id: totrans-3018
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šçº¦æŸæ¨¡å‹å¤æ‚åº¦ã€‚è¶…å‚æ•°è°ƒæ•´ä»¥æœ€å¤§åŒ–ä¿ç•™æµ‹è¯•æ•°æ®ä¸Šçš„å‡†ç¡®æ€§ï¼Œä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚'
- en: For a set of polynomial models from \(4^{th}\) to \(1^{st}\) order,
  id: totrans-3019
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä» \(4^{th}\) åˆ° \(1^{st}\) æ¬¡çš„å¤šé¡¹å¼æ¨¡å‹é›†ï¼Œ
- en: \[ y = b_4 \cdot x^4 + b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[
    y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[ y = b_2 \cdot x^2 +
    b_1 \cdot x + b_0 \]\[ y = b_1 \cdot x + b_0 \]
  id: totrans-3020
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = b_4 \cdot x^4 + b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[
    y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]\[ y = b_2 \cdot x^2 +
    b_1 \cdot x + b_0 \]\[ y = b_1 \cdot x + b_0 \]
- en: the choice of polynomial order is the hyperparameter, i.e., the first order
    model is most simple and the fourth order model is most complicated.
  id: totrans-3021
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼é˜¶æ•°çš„é€‰æ‹©æ˜¯è¶…å‚æ•°ï¼Œå³ï¼Œä¸€é˜¶æ¨¡å‹æœ€ç®€å•ï¼Œå››é˜¶æ¨¡å‹æœ€å¤æ‚ã€‚
- en: '**Model Parameters**'
  id: totrans-3022
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å‚æ•°**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): trainable coefficients
    for a machine learning model that control the fit to the training data.'
  id: totrans-3023
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒç³»æ•°ï¼Œç”¨äºæ§åˆ¶å¯¹è®­ç»ƒæ•°æ®çš„æ‹Ÿåˆã€‚'
- en: For a polynomial model,
  id: totrans-3024
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€ä¸ªå¤šé¡¹å¼æ¨¡å‹ï¼Œ
- en: \[ y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]
  id: totrans-3025
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = b_3 \cdot x^3 + b_2 \cdot x^2 + b_1 \cdot x + b_0 \]
- en: \(b_3\), \(b_2\), \(b_1\), and \(b_0\) are model parameters.
  id: totrans-3026
  prefs: []
  type: TYPE_NORMAL
  zh: \(b_3\), \(b_2\), \(b_1\) å’Œ \(b_0\) æ˜¯æ¨¡å‹å‚æ•°ã€‚
- en: '*training model parameters* - model parameters are calculated by optimization
    to minimize error and regularization terms over the training data through analytical
    solution or iterative solution, e.g., gradient descent optimization'
  id: totrans-3027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è®­ç»ƒæ¨¡å‹å‚æ•°* - æ¨¡å‹å‚æ•°é€šè¿‡ä¼˜åŒ–è®¡ç®—ï¼Œä»¥æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®å’Œæ­£åˆ™åŒ–é¡¹ï¼Œé€šè¿‡è§£æè§£æˆ–è¿­ä»£è§£ï¼Œä¾‹å¦‚æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ã€‚'
- en: Model Regularization
  id: totrans-3028
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ­£åˆ™åŒ–
- en: '[Ridge Regression](MachineLearning_ridge_regression.html): adding information
    to prevent overfit (or underfit), improve model generalization.'
  id: totrans-3029
  prefs: []
  type: TYPE_NORMAL
  zh: '[å²­å›å½’](MachineLearning_ridge_regression.html)ï¼šæ·»åŠ ä¿¡æ¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼ˆæˆ–æ¬ æ‹Ÿåˆï¼‰ï¼Œæé«˜æ¨¡å‹æ³›åŒ–ã€‚'
- en: this information is known as a regularization term
  id: totrans-3030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä¿¡æ¯è¢«ç§°ä¸ºæ­£åˆ™åŒ–é¡¹
- en: this represents a penalty for complexity that is tuned with a regularization
    hyperparameter
  id: totrans-3031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä»£è¡¨äº†ä¸€ä¸ªä¸æ­£åˆ™åŒ–è¶…å‚æ•°è°ƒæ•´çš„å¤æ‚åº¦æƒ©ç½š
- en: Consider the ridge regression loss function,
  id: totrans-3032
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘å²­å›å½’æŸå¤±å‡½æ•°ï¼Œ
- en: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m b_{\alpha}^2 \]
  id: totrans-3033
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i}
    + b_0 \right) \right)^2 + \lambda \sum_{j=1}^m b_{\alpha}^2 \]
- en: where \(\lambda \sum_{j=1}^m b_{\alpha}^2\) is the regularization term and \(\lambda\)
    is the regularization hyperparameter.
  id: totrans-3034
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\lambda \sum_{j=1}^m b_{\alpha}^2\) æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œè€Œ \(\lambda\) æ˜¯æ­£åˆ™åŒ–è¶…å‚æ•°ã€‚
- en: The concept of regularization is quite general and choices in machine learning
    architecture, such as,
  id: totrans-3035
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–çš„æ¦‚å¿µç›¸å½“æ™®éï¼Œæœºå™¨å­¦ä¹ æ¶æ„ä¸­çš„é€‰æ‹©ï¼Œä¾‹å¦‚ï¼Œ
- en: use of receptive fields for convolutional neural networks (CNNs)
  id: totrans-3036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰ä¸­æ„Ÿå—é‡çš„ä½¿ç”¨
- en: the choice to limit decision trees to a maximum number of levels.
  id: totrans-3037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™åˆ¶å†³ç­–æ ‘æœ€å¤§å±‚æ•°çš„é€‰æ‹©ã€‚
- en: There are a couple of useful perspectives on model regularization,
  id: totrans-3038
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ä¸ªæœ‰ç”¨çš„è§†è§’å…³äºæ¨¡å‹æ­£åˆ™åŒ–ï¼Œ
- en: '*Occamâ€™s razor* - regularization tunes model complexity to the simplest effective
    solution'
  id: totrans-3039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™* - æ­£åˆ™åŒ–å°†æ¨¡å‹å¤æ‚åº¦è°ƒæ•´åˆ°æœ€ç®€å•çš„æœ‰æ•ˆè§£ã€‚'
- en: '*Bayesian perspective* - regularization is imposing a prior on the solution.'
  id: totrans-3040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è´å¶æ–¯è§†è§’* - æ­£åˆ™åŒ–æ˜¯å¯¹è§£æ–½åŠ å…ˆéªŒã€‚'
- en: '**Model Variance**'
  id: totrans-3041
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ–¹å·®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): is error due to
    sensitivity to the dataset'
  id: totrans-3042
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ˜¯å› å¯¹æ•°æ®é›†æ•æ„Ÿè€Œäº§ç”Ÿçš„è¯¯å·®'
- en: increasing model complexity usually results in increasing model variance
  id: totrans-3043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ æ¨¡å‹å¤æ‚åº¦é€šå¸¸ä¼šå¯¼è‡´æ¨¡å‹æ–¹å·®å¢åŠ 
- en: ensemble machine learning, for example, model bagging reduce model variance
    by averaging over multiple estimators trained on bootstrap realizations of the
    dataset
  id: totrans-3044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œé›†æˆæœºå™¨å­¦ä¹ ï¼Œæ¨¡å‹è¢‹è£…é€šè¿‡åœ¨æ•°æ®é›†çš„å¼•å¯¼å®ç°ä¸Šå¹³å‡å¤šä¸ªä¼°è®¡é‡æ¥å‡å°‘æ¨¡å‹æ–¹å·®
- en: '*model bias variance trade-off* - as complexity increases, model variance increases
    and model bias decreases'
  id: totrans-3045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹åå·®ä¸æ–¹å·®æƒè¡¡* - éšç€å¤æ‚åº¦çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å¢åŠ ï¼Œæ¨¡å‹åå·®å‡å°‘'
- en: one of the three components of expected test square error, including model variance,
    model bias and irreducible error
  id: totrans-3046
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æœŸæµ‹è¯•å¹³æ–¹è¯¯å·®çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æ¨¡å‹æ–¹å·®ã€æ¨¡å‹åå·®å’Œä¸å¯å‡å°‘è¯¯å·®
- en: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
  id: totrans-3047
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E \left[ \left(y_0 - \hat{f}(x_1^0, \ldots, x_m,^0 \right)^2 \right] = \left(E
    [\hat{f}(x_1^0, \ldots, x_m,^0)] - f(x_1^0, \ldots, x_m,^0) \right)^2 + \]\[ E
    \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[ \hat{f}(x_1^0,
    \ldots, x_m,^0) \right] \right)^2 \right] + \sigma_e^2 \]
- en: where \(E \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[
    \hat{f}(x_1^0, \ldots, x_m,^0) \right] \right)^2 \right]\) is model variance.
  id: totrans-3048
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(E \left[ \left( \hat{f} \left(x_1^0, \ldots, x_m,^0 \right) - E \left[
    \hat{f}(x_1^0, \ldots, x_m,^0) \right] \right)^2 \right]\) æ˜¯æ¨¡å‹æ–¹å·®ã€‚
- en: '**Momentum** (optimization)'
  id: totrans-3049
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŠ¨é‡** (ä¼˜åŒ–)'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): update the previous
    step with the new step, momentum, \(\lambda\), is the weight applied to the previous
    step while \(1 - \lambda\) is the weight applied to the current step,'
  id: totrans-3050
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSOå›å½’](MachineLearning_LASSO_regression.html)ï¼šæ›´æ–°å‰ä¸€æ­¥éª¤ï¼ŒåŠ¨é‡ï¼Œ\(\lambda\)ï¼Œæ˜¯åº”ç”¨äºå‰ä¸€æ­¥éª¤çš„æƒé‡ï¼Œè€Œ
    \(1 - \lambda\) æ˜¯åº”ç”¨äºå½“å‰æ­¥éª¤çš„æƒé‡ï¼Œ'
- en: \[ \left( \left( r \cdot \nabla L \right)_{t-1} \right)^m = \lambda \cdot r
    \cdot \nabla L_{t-2} + (1 - \lambda) \cdot r \cdot \nabla L_{t-1} \]
  id: totrans-3051
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left( \left( r \cdot \nabla L \right)_{t-1} \right)^m = \lambda \cdot r
    \cdot \nabla L_{t-2} + (1 - \lambda) \cdot r \cdot \nabla L_{t-1} \]
- en: the gradients calculated from the partial derivatives of the loss function for
    each model parameter have noise. Momentum smooths out, reduces the impact of this
    noise.
  id: totrans-3052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ¯ä¸ªæ¨¡å‹å‚æ•°çš„æŸå¤±å‡½æ•°åå¯¼æ•°è®¡ç®—å‡ºçš„æ¢¯åº¦å­˜åœ¨å™ªå£°ã€‚åŠ¨é‡å¹³æ»‘å¯ä»¥å‡å°‘è¿™ç§å™ªå£°çš„å½±å“ã€‚
- en: momentum helps the solution proceed down the general slope of the loss function,
    rather than oscillating in local ravines or dimples
  id: totrans-3053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ¨é‡æœ‰åŠ©äºè§£å†³æ–¹æ¡ˆæ²¿ç€æŸå¤±å‡½æ•°çš„ä¸€èˆ¬æ–œç‡å‰è¿›ï¼Œè€Œä¸æ˜¯åœ¨å±€éƒ¨å³¡è°·æˆ–å‡¹æ§½ä¸­æŒ¯è¡
- en: '**Markov Chain Monte Carlo** (MCMC)'
  id: totrans-3054
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›** (MCMC)'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a set of algorithms to sample from a probability distribution such that the samples
    match the distribution statistics.'
  id: totrans-3055
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€ç»„ç®—æ³•ï¼Œç”¨äºä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œä½¿å¾—æ ·æœ¬åŒ¹é…åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯ã€‚'
- en: '*Markov* - screening assumption, the next sample is only dependent on the previous
    sample'
  id: totrans-3056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é©¬å°”å¯å¤«* - å±è”½å‡è®¾ï¼Œä¸‹ä¸€ä¸ªæ ·æœ¬åªä¾èµ–äºå‰ä¸€ä¸ªæ ·æœ¬'
- en: '*Chain* - the samples form a sequence often demonstrating a transition from
    burn-in chain with inaccurate statistics and equilibrium chain with accurate statistics'
  id: totrans-3057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é“¾* - æ ·æœ¬å½¢æˆä¸€ä¸ªåºåˆ—ï¼Œé€šå¸¸æ˜¾ç¤ºå‡ºä»å…·æœ‰ä¸å‡†ç¡®ç»Ÿè®¡ä¿¡æ¯çš„çƒ§æ¯é“¾åˆ°å…·æœ‰å‡†ç¡®ç»Ÿè®¡ä¿¡æ¯çš„å¹³è¡¡é“¾çš„è¿‡æ¸¡'
- en: '*Monte Carlo* - use of Monte Carlo simulation, random sampling from a statistical
    distribution'
  id: totrans-3058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›* - ä½¿ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œä»ç»Ÿè®¡åˆ†å¸ƒä¸­è¿›è¡Œéšæœºé‡‡æ ·'
- en: Why is this useful?
  id: totrans-3059
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ‰ä»€ä¹ˆç”¨ï¼Ÿ
- en: we often donâ€™t have the target distribution, it is unknown
  id: totrans-3060
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šå¸¸æ²¡æœ‰ç›®æ ‡åˆ†å¸ƒï¼Œå®ƒæ˜¯æœªçŸ¥çš„
- en: but we can sample with the correct frequencies with other form of information
    such as conditional probability density functions, Gibbs sampler, or the likelihood
    ratios of the candidate next sample and the current sample, Metropolis-Hastings
  id: totrans-3061
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡å…¶ä»–å½¢å¼çš„ä¿¡æ¯ï¼Œå¦‚æ¡ä»¶æ¦‚ç‡å¯†åº¦å‡½æ•°ã€Gibbsé‡‡æ ·æˆ–å€™é€‰ä¸‹ä¸€æ ·æœ¬å’Œå½“å‰æ ·æœ¬çš„ä¼¼ç„¶æ¯”ï¼Œä»¥æ­£ç¡®çš„é¢‘ç‡è¿›è¡Œé‡‡æ ·ï¼ŒMetropolis-Hastings
- en: '**Metropolis-Hastings Sampling** (MCMC)'
  id: totrans-3062
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Metropolis-Hastingsé‡‡æ ·** (MCMC)'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a set of algorithms to sample from a probability distribution such that the samples
    match the distribution statistics, based on,'
  id: totrans-3063
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€ç»„ç®—æ³•ï¼Œç”¨äºä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œä½¿å¾—æ ·æœ¬åŒ¹é…åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯ï¼ŒåŸºäºï¼Œ'
- en: the likelihood ratios of the candidate next sample and the current sample
  id: totrans-3064
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å€™é€‰ä¸‹ä¸€æ ·æœ¬å’Œå½“å‰æ ·æœ¬çš„ä¼¼ç„¶æ¯”
- en: a rejection sampler based on this likelihood ratio
  id: totrans-3065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºè¿™ä¸ªä¼¼ç„¶æ¯”çš„åå‘é‡‡æ ·å™¨
- en: Since only the ratio of likelihood is required, the system is simplified as
    the evidence term cancels out from the Bayesian probability
  id: totrans-3066
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºåªéœ€è¦ä¼¼ç„¶æ¯”çš„æ¯”ç‡ï¼Œç³»ç»Ÿç®€åŒ–ä¸ºè¯æ®é¡¹ä»è´å¶æ–¯æ¦‚ç‡ä¸­å–æ¶ˆ
- en: 'Hereâ€™s the basic steps of the Metropolis-Hastings MCMC Sampler:'
  id: totrans-3067
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯Metropolis-Hastings MCMCé‡‡æ ·å™¨çš„åŸºæœ¬æ­¥éª¤ï¼š
- en: 'For \(\ell = 1, \ldots, L\):'
  id: totrans-3068
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¯¹äº \(\ell = 1, \ldots, L\):'
- en: Assign random values for the initial sample of model parameters, \(\beta(\ell
    = 1) = b_1(\ell = 1)\), \(b_0(\ell = 1)\) and \(\sigma^2(\ell = 1)\).
  id: totrans-3069
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¨¡å‹å‚æ•°çš„åˆå§‹æ ·æœ¬åˆ†é…éšæœºå€¼ï¼Œ\(\beta(\ell = 1) = b_1(\ell = 1)\)ï¼Œ\(b_0(\ell = 1)\) å’Œ \(\sigma^2(\ell
    = 1)\)ã€‚
- en: Propose new model parameters based on a proposal function, \(\beta^{\prime}
    = b_1\), \(b_0\) and \(\sigma^2\).
  id: totrans-3070
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®å»ºè®®å‡½æ•°æå‡ºæ–°çš„æ¨¡å‹å‚æ•°ï¼Œ\(\beta^{\prime} = b_1\)ï¼Œ\(b_0\) å’Œ \(\sigma^2\)ã€‚
- en: Calculate probability of acceptance of the new proposal, as the ratio of the
    posterior probability of the new model parameters given the data to the previous
    model parameters given the data multiplied by the probability of the old step
    given the new step divided by the probability of the new step given the old.
  id: totrans-3071
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–°æè®®çš„æ¥å—æ¦‚ç‡ï¼Œå³æ–°æ¨¡å‹å‚æ•°åœ¨ç»™å®šæ•°æ®ä¸‹çš„åéªŒæ¦‚ç‡ä¸æ—§æ¨¡å‹å‚æ•°åœ¨ç»™å®šæ•°æ®ä¸‹çš„åéªŒæ¦‚ç‡çš„æ¯”å€¼ï¼Œä¹˜ä»¥æ—§æ­¥éª¤åœ¨ç»™å®šæ–°æ­¥éª¤ä¸‹çš„æ¦‚ç‡é™¤ä»¥æ–°æ­¥éª¤åœ¨ç»™å®šæ—§æ­¥éª¤ä¸‹çš„æ¦‚ç‡ã€‚
- en: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
  id: totrans-3072
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\beta \rightarrow \beta^{\prime}) = min\left(\frac{P(\beta^{\prime}|y,X)
    }{ P(\beta | y,X)} \cdot \frac{P(\beta^{\prime}|\beta) }{ P(\beta | \beta^{\prime})},1\right)
    \]
- en: Apply Monte Carlo simulation to conditionally accept the proposal, if accepted,
    \(\ell = \ell + 1\), and sample \(\beta(\ell) = \beta^{\prime}\)
  id: totrans-3073
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºæ¡ä»¶æ¥å—æè®®ï¼Œå¦‚æœæ¥å—ï¼Œ\(\ell = \ell + 1\)ï¼Œå¹¶é‡‡æ · \(\beta(\ell) = \beta^{\prime}\)
- en: Go to step 2.
  id: totrans-3074
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿”å›æ­¥éª¤2ã€‚
- en: '**Monte Carlo Simulation (MCS)**'
  id: totrans-3075
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼ˆMCS**ï¼‰'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a random sample from a statistical distribution, random variable. The steps for
    MCS are:'
  id: totrans-3076
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä»ç»Ÿè®¡åˆ†å¸ƒä¸­æŠ½å–çš„éšæœºæ ·æœ¬ï¼Œéšæœºå˜é‡ã€‚è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼ˆMCSï¼‰çš„æ­¥éª¤å¦‚ä¸‹ï¼š'
- en: model the feature cumulative distribution function, \(F_x(x)\)
  id: totrans-3077
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å»ºç«‹ç‰¹å¾ç´¯ç§¯åˆ†å¸ƒå‡½æ•°æ¨¡å‹ï¼Œ\(F_x(x)\)
- en: draw random value from a uniform [0,1] distribution, this is a random cumulative
    probability value, known as a p-value, \(p^{\ell}\)
  id: totrans-3078
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»å‡åŒ€åˆ†å¸ƒ[0,1]ä¸­æŠ½å–éšæœºå€¼ï¼Œè¿™æ˜¯ä¸€ä¸ªéšæœºç´¯ç§¯æ¦‚ç‡å€¼ï¼Œç§°ä¸ºpå€¼ï¼Œ\(p^{\ell}\)
- en: apply the inverse of the cumulative distribution function to calculate the associated
    realization
  id: totrans-3079
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„é€†æ¥è®¡ç®—ç›¸å…³çš„å®ç°
- en: \[ x^{\ell} = F_x^{-1} (p^{\ell}) \]
  id: totrans-3080
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x^{\ell} = F_x^{-1} (p^{\ell}) \]
- en: repeat to calculate enough realizations for the subsequent analysis
  id: totrans-3081
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤è®¡ç®—ï¼Œä»¥è·å¾—è¶³å¤Ÿå¤šçš„å®ç°ç”¨äºåç»­åˆ†æ
- en: Monte Carlo simulation is the basic building block of stochastic simulation
    workflows, for example,
  id: totrans-3082
  prefs: []
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ˜¯éšæœºæ¨¡æ‹Ÿå·¥ä½œæµç¨‹çš„åŸºæœ¬æ„å»ºå—ï¼Œä¾‹å¦‚ï¼Œ
- en: '*Monte Carlo simulation workflows* - apply Monte Carlo simulation many over
    all features to the transfer function to calculate a realization of the decision
    criteria, repeated for many realizations, to propagate uncertainty through a transfer
    function'
  id: totrans-3083
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå·¥ä½œæµç¨‹* - å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºæ‰€æœ‰ç‰¹å¾åˆ°ä¼ é€’å‡½æ•°ï¼Œä»¥è®¡ç®—å†³ç­–æ ‡å‡†çš„å®ç°ï¼Œé‡å¤å¤šæ¬¡ä»¥é€šè¿‡ä¼ é€’å‡½æ•°ä¼ æ’­ä¸ç¡®å®šæ€§'
- en: '*Bootstrap* - applies Monte Carlo simulation to acquire realizations of the
    data to calculate uncertainty in sample statistics or ensembles of prediction
    models for ensemble-based machine learning'
  id: totrans-3084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è‡ªåŠ©æ³•* - å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºè·å–æ•°æ®çš„å®ç°ï¼Œä»¥è®¡ç®—æ ·æœ¬ç»Ÿè®¡é‡æˆ–åŸºäºé›†æˆé¢„æµ‹æ¨¡å‹çš„é›†æˆçš„ä¸ç¡®å®šæ€§'
- en: '*Monte Carlo methods* - applies Monte Carlo simulation to speed up an expensive
    calculation with a limited random sample that converges on the solution as the
    number of random samples increases'
  id: totrans-3085
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›æ–¹æ³•* - å°†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåº”ç”¨äºä½¿ç”¨æœ‰é™éšæœºæ ·æœ¬åŠ é€Ÿæ˜‚è´µè®¡ç®—ï¼Œéšç€éšæœºæ ·æœ¬æ•°é‡çš„å¢åŠ ï¼Œè¿™äº›æ ·æœ¬æ”¶æ•›åˆ°è§£'
- en: '**Monte Carlo Simulation Workflow**'
  id: totrans-3086
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå·¥ä½œæµç¨‹**'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    a convenient stochastic workflow for propagating uncertainty through a transfer
    function through sampling with Monte Carlo Simulation (MCS). The workflow includes
    the following steps,'
  id: totrans-3087
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šä¸€ç§æ–¹ä¾¿çš„éšæœºå·¥ä½œæµç¨‹ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼ˆMCSï¼‰è¿›è¡Œé‡‡æ ·æ¥ä¼ æ’­é€šè¿‡ä¼ é€’å‡½æ•°çš„ä¸ç¡®å®šæ€§ã€‚è¯¥å·¥ä½œæµç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼Œ'
- en: Model all the input featuresâ€™ distributions, cumulative distribution functions,
  id: totrans-3088
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å»ºç«‹æ‰€æœ‰è¾“å…¥ç‰¹å¾çš„åˆ†å¸ƒï¼Œç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼Œ
- en: \[ F_{x_1}(x_1), \quad F_{x_2}(x_2), \quad \dots \quad , F_{x_m}(x_m) \]
  id: totrans-3089
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_{x_1}(x_1), \quad F_{x_2}(x_2), \quad \dots \quad , F_{x_m}(x_m) \]
- en: Monte Carlo simulate a realizations for all the inputs,
  id: totrans-3090
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹æ‰€æœ‰è¾“å…¥è¿›è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä»¥è·å¾—å®ç°ï¼Œ
- en: \[ x_1^{\ell}, \quad x_2^{\ell}, \quad \ldots \quad , x_m^{\ell} \]
  id: totrans-3091
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_1^{\ell}, \quad x_2^{\ell}, \quad \ldots \quad , x_m^{\ell} \]
- en: Apply to the transfer function to get a realization of the transfer function
    output, often the *decision criteria*
  id: totrans-3092
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å…¶åº”ç”¨äºä¼ é€’å‡½æ•°ä»¥è·å¾—ä¼ é€’å‡½æ•°è¾“å‡ºçš„å®ç°ï¼Œé€šå¸¸æ˜¯*å†³ç­–æ ‡å‡†*
- en: \[ y^{\ell} = f \left(x_1^{\ell},x_2^{\ell}, \quad \ldots \quad, x_m^{\ell}
    \right) \]
  id: totrans-3093
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y^{\ell} = f \left(x_1^{\ell},x_2^{\ell}, \quad \ldots \quad, x_m^{\ell}
    \right) \]
- en: Repeat steps 1-3 to calculate enough realizations to model the transfer function
    output distribution.
  id: totrans-3094
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤æ­¥éª¤1-3ï¼Œä»¥è®¡ç®—è¶³å¤Ÿå¤šçš„å®ç°æ¥æ¨¡æ‹Ÿä¼ é€’å‡½æ•°è¾“å‡ºåˆ†å¸ƒã€‚
- en: \[ F_y(y) \]
  id: totrans-3095
  prefs: []
  type: TYPE_NORMAL
  zh: \[ F_y(y) \]
- en: '**Multiplication Rule** (probability)'
  id: totrans-3096
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¹˜æ³•æ³•åˆ™**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): we can calculate
    the joint probability of \(A\) and \(B\) as the product of the conditional probability
    of \(B\) given \(A\) with the marginal probability of \(A\),'
  id: totrans-3097
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šæˆ‘ä»¬å¯ä»¥é€šè¿‡ \(A\) ç»™å®š \(B\) çš„æ¡ä»¶æ¦‚ç‡ä¸ \(A\)
    çš„è¾¹ç¼˜æ¦‚ç‡çš„ä¹˜ç§¯æ¥è®¡ç®— \(A\) å’Œ \(B\) çš„è”åˆæ¦‚ç‡ï¼Œ'
- en: \[ P(A \cup B) = P(A,B) = P(B|A) \cdot P(A) \]
  id: totrans-3098
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A,B) = P(B|A) \cdot P(A) \]
- en: The multiplication rule is derived as a simple manipulation of the definition
    of conditional probability, in this case,
  id: totrans-3099
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹˜æ³•è§„åˆ™æ˜¯é€šè¿‡æ¡ä»¶æ¦‚ç‡å®šä¹‰çš„ç®€å•æ“ä½œæ¨å¯¼å‡ºæ¥çš„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ
- en: \[ P(B|A) = \frac{P(A,B)}{P(A)} \]
  id: totrans-3100
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A,B)}{P(A)} \]
- en: '**Mutual Information**'
  id: totrans-3101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº’ä¿¡æ¯**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a generalized approach
    that quantifies the mutual dependence between two features.'
  id: totrans-3102
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šä¸€ç§é‡åŒ–ä¸¤ä¸ªç‰¹å¾ä¹‹é—´ç›¸äº’ä¾èµ–æ€§çš„é€šç”¨æ–¹æ³•ã€‚'
- en: quantifies the amount of information gained from observing one feature about
    the other
  id: totrans-3103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡åŒ–ä»è§‚å¯Ÿä¸€ä¸ªç‰¹å¾ä¸­è·å–å…³äºå¦ä¸€ä¸ªç‰¹å¾çš„ä¿¡æ¯é‡
- en: avoids any assumption about the form of the relationship (e.g. no assumption
    of linear relationship)
  id: totrans-3104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…å¯¹å…³ç³»çš„å½¢çŠ¶åšå‡ºä»»ä½•å‡è®¾ï¼ˆä¾‹å¦‚ï¼Œæ²¡æœ‰çº¿æ€§å…³ç³»çš„å‡è®¾ï¼‰
- en: units are Shannons or bits
  id: totrans-3105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å•ä½æ˜¯é¦™å†œæˆ–æ¯”ç‰¹
- en: compares the joint probabilities to the product of the marginal probabilities
  id: totrans-3106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è”åˆæ¦‚ç‡ä¸è¾¹ç¼˜æ¦‚ç‡çš„ä¹˜ç§¯è¿›è¡Œæ¯”è¾ƒ
- en: summarizes the difference between the joint \(P(x,y)\) and the product of the
    marginals \(P(x)\cdot P(y)\), integrated over all \(x \in ğ‘‹\) and \(y \in Y\),
  id: totrans-3107
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€»ç»“äº†è”åˆ \(P(x,y)\) ä¸è¾¹ç¼˜ \(P(x)\cdot P(y)\) ä¹˜ç§¯ä¹‹é—´çš„å·®å¼‚ï¼Œç§¯åˆ†éå†æ‰€æœ‰ \(x \in ğ‘‹\) å’Œ \(y \in
    Y\)ï¼Œ
- en: 'For discrete or binned continuous features \(X\) and \(Y\), mutual information
    is calculated as:'
  id: totrans-3108
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¦»æ•£æˆ–åˆ†ç®±çš„è¿ç»­ç‰¹å¾ \(X\) å’Œ \(Y\)ï¼Œäº’ä¿¡æ¯è®¡ç®—å¦‚ä¸‹ï¼š
- en: \[ I(X;Y) = \sum_{y \in Y} \sum_{x \in X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) \]
  id: totrans-3109
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I(X;Y) = \sum_{y \in Y} \sum_{x \in X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) \]
- en: 'recall, given independence between \(X\) and \(Y\):'
  id: totrans-3110
  prefs: []
  type: TYPE_NORMAL
  zh: å›æƒ³ä¸€ä¸‹ï¼Œç»™å®š \(X\) å’Œ \(Y\) ä¹‹é—´çš„ç‹¬ç«‹æ€§ï¼š
- en: \[ P_{X,Y}(x,y) = P_X(x) \cdot P_Y(y) \]
  id: totrans-3111
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P_{X,Y}(x,y) = P_X(x) \cdot P_Y(y) \]
- en: therefore if the two features are independent then the \(log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) = 0\)
  id: totrans-3112
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¦‚æœä¸¤ä¸ªç‰¹å¾æ˜¯ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆ \(log \left( \frac{P_{X,Y}(x,y)}{P_X(x) \cdot P_Y(y)} \right)
    = 0\)
- en: The joint probability \(P_{X,Y}(x,y)\) is a weighting term on the sum and enforces
    closure.
  id: totrans-3113
  prefs: []
  type: TYPE_NORMAL
  zh: è”åˆæ¦‚ç‡ \(P_{X,Y}(x,y)\) æ˜¯æ€»å’Œä¸Šçš„åŠ æƒé¡¹ï¼Œå¹¶å¼ºåˆ¶å°é—­ã€‚
- en: parts of the joint distribution with greater density have greater impact on
    the mutual information metric
  id: totrans-3114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è”åˆåˆ†å¸ƒä¸­å¯†åº¦æ›´å¤§çš„éƒ¨åˆ†å¯¹äº’ä¿¡æ¯åº¦é‡æœ‰æ›´å¤§çš„å½±å“
- en: For continuous (and nonbinned) features we can applied the integral form.
  id: totrans-3115
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿ç»­ï¼ˆå’Œéåˆ†ç®±ï¼‰ç‰¹å¾ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ç§¯åˆ†å½¢å¼ã€‚
- en: \[ I(X;Y) = \int_{Y} \int_{X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) dx dy \]
  id: totrans-3116
  prefs: []
  type: TYPE_NORMAL
  zh: \[ I(X;Y) = \int_{Y} \int_{X}P_{X,Y}(x,y) log \left( \frac{P_{X,Y}(x,y)}{P_X(x)
    \cdot P_Y(y)} \right) dx dy \]
- en: '**Mutually Exclusive Events** (probability)'
  id: totrans-3117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº’æ–¥äº‹ä»¶**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the events do not
    intersect, i.e., do not have any common outcomes. We represent this as,'
  id: totrans-3118
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šäº‹ä»¶ä¸ç›¸äº¤ï¼Œå³æ²¡æœ‰å…±åŒçš„ç»“æœã€‚æˆ‘ä»¬ç”¨ä»¥ä¸‹æ–¹å¼è¡¨ç¤ºï¼Œ'
- en: using set notation, we state events \(A\) and \(B\) are mutually exclusive as,
  id: totrans-3119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é›†åˆè¡¨ç¤ºæ³•ï¼Œæˆ‘ä»¬è¡¨ç¤ºäº‹ä»¶ \(A\) å’Œ \(B\) æ˜¯äº’æ–¥çš„ï¼Œå¦‚ä¸‹ï¼Œ
- en: '\[ A \cap B = \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
  id: totrans-3120
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ A \cap B = \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
- en: and the probability for mutually exclusive as,
  id: totrans-3121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹¶ä¸”ï¼Œäº’æ–¥äº‹ä»¶çš„æ¦‚ç‡ä¸ºï¼Œ
- en: \[ P(A,B) = 0.0 \]
  id: totrans-3122
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = 0.0 \]
- en: '**Multidimensional Scaling**'
  id: totrans-3123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤šç»´å°ºåº¦**'
- en: '[Multidimensional Scaling](MachineLearning_multidimensional_scaling.html):
    a method in inferential statistics / information visualization for exploring /
    visualizing the similarity (conversely the difference) between individual samples
    from a high dimensional dataset in a low dimensional space.'
  id: totrans-3124
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šç»´å°ºåº¦](MachineLearning_multidimensional_scaling.html)ï¼šä¸€ç§åœ¨ä¿¡æ¯å¯è§†åŒ–ä¸­ç”¨äºæ¢ç´¢/å¯è§†åŒ–é«˜ç»´æ•°æ®é›†ä¸­ä¸ªä½“æ ·æœ¬ä¹‹é—´ç›¸ä¼¼æ€§ï¼ˆæˆ–ç›¸åçš„å·®å¼‚ï¼‰çš„æ¨æ–­ç»Ÿè®¡æ–¹æ³•ã€‚'
- en: Multidimensional scaling (MDS) projects the \(m\) dimensional data to \(p\)
    dimensions such that \(p << m\).
  id: totrans-3125
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šç»´å°ºåº¦ï¼ˆMDSï¼‰å°† \(m\) ç»´æ•°æ®æŠ•å½±åˆ° \(p\) ç»´ï¼Œä½¿å¾— \(p << m\)ã€‚
- en: while attempting to preserve the pairwise dissimilarity between the data samples
  id: totrans-3126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å°è¯•ä¿ç•™æ•°æ®æ ·æœ¬ä¹‹é—´çš„æˆå¯¹å·®å¼‚çš„åŒæ—¶
- en: ideally we are able to project to \(p=2\) to easily explore the relationships
    between the samples
  id: totrans-3127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå°† \(p=2\) æŠ•å½±å‡ºæ¥ï¼Œä»¥ä¾¿è½»æ¾æ¢ç´¢æ ·æœ¬ä¹‹é—´çš„å…³ç³»
- en: While principal component analysis (PCA) operates with the covariance matrix,
    multidimensional scaling operates with the distance or dissimilarity matrix. For
    multidimensional scaling,
  id: totrans-3128
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ä½¿ç”¨åæ–¹å·®çŸ©é˜µè¿›è¡Œæ“ä½œï¼Œå¤šç»´å°ºåº¦åˆ†æåˆ™ä½¿ç”¨è·ç¦»æˆ–ç›¸ä¼¼æ€§çŸ©é˜µã€‚å¯¹äºå¤šç»´å°ºåº¦åˆ†æï¼Œ
- en: you donâ€™t need to know the actual feature values, just the distance or dissimilarity
    between the samples
  id: totrans-3129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ ä¸éœ€è¦çŸ¥é“å®é™…çš„ç‰¹å¾å€¼ï¼Œåªéœ€è¦çŸ¥é“æ ·æœ¬ä¹‹é—´çš„è·ç¦»æˆ–ç›¸ä¼¼æ€§
- en: as with any distance in feature space, we consider feature standardization to
    ensure that features with larger variance do not dominate the calculation
  id: totrans-3130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°±åƒç‰¹å¾ç©ºé—´ä¸­çš„ä»»ä½•è·ç¦»ä¸€æ ·ï¼Œæˆ‘ä»¬è€ƒè™‘ç‰¹å¾æ ‡å‡†åŒ–ä»¥ç¡®ä¿å…·æœ‰æ›´å¤§æ–¹å·®çš„ç‰¹å¾ä¸ä¼šä¸»å¯¼è®¡ç®—
- en: we may work with a variety of dissimilarity measures
  id: totrans-3131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å„ç§ç›¸ä¼¼æ€§åº¦é‡
- en: Comparison between multidimensional scaling and principal component analysis,
  id: totrans-3132
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šç»´å°ºåº¦åˆ†æä¸ä¸»æˆåˆ†åˆ†æçš„æ¯”è¾ƒï¼Œ
- en: principal component analysis takes the covariance matrix (\(m \times m\)) between
    all the features and finds the linear, orthogonal rotation such that the *variance
    is maximized* over the ordered principle components
  id: totrans-3133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸»æˆåˆ†åˆ†æé€šè¿‡æ‰€æœ‰ç‰¹å¾ä¹‹é—´çš„åæ–¹å·®çŸ©é˜µ (\(m \times m\)) æ‰¾åˆ°çº¿æ€§æ­£äº¤æ—‹è½¬ï¼Œä½¿å¾—åœ¨æœ‰åºçš„ä¸»æˆåˆ†ä¸Š *æ–¹å·®æœ€å¤§åŒ–*
- en: multidimensional scaling takes the matrix of the pairwise distances (\(n \times
    n\)) between all the samples in feature space and finds the nonlinear projection
    such that the *error in the pairwise distances is minimized*
  id: totrans-3134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šç»´å°ºåº¦åˆ†æé€šè¿‡ç‰¹å¾ç©ºé—´ä¸­æ‰€æœ‰æ ·æœ¬ä¹‹é—´çš„æˆå¯¹è·ç¦»çŸ©é˜µ (\(n \times n\)) å¹¶æ‰¾åˆ°éçº¿æ€§æŠ•å½±ï¼Œä½¿å¾— *æˆå¯¹è·ç¦»è¯¯å·®æœ€å°åŒ–*
- en: Some have suggest that visualizing data or models in a multidimensional scaling
    space is visualizing the space of uncertainty.
  id: totrans-3135
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº›äººè®¤ä¸ºåœ¨å¤šç»´å°ºåº¦ç©ºé—´ä¸­å¯è§†åŒ–æ•°æ®æˆ–æ¨¡å‹æ˜¯å¯è§†åŒ–ä¸ç¡®å®šæ€§ç©ºé—´ã€‚
- en: '**Naive Bayes**'
  id: totrans-3136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æœ´ç´ è´å¶æ–¯**'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): the application of the assumption
    of conditional independence to simplify the classification prediction problem
    from the perspective of Bayesian updating, based on the conditional probability
    of a category, \(k\), given \(n\) features, \(x_1, \dots , x_n\),'
  id: totrans-3137
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä»è´å¶æ–¯æ›´æ–°çš„è§’åº¦ï¼Œå°†æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾åº”ç”¨äºç®€åŒ–åˆ†ç±»é¢„æµ‹é—®é¢˜ï¼ŒåŸºäºç»™å®š
    \(n\) ä¸ªç‰¹å¾ \(x_1, \dots , x_n\) çš„ç±»åˆ« \(k\) çš„æ¡ä»¶æ¦‚ç‡ï¼Œ'
- en: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3 | x_4,
    \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n} | C_k) P(C_k) \]
  id: totrans-3138
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_1 | x_2, \dots , x_n, C_k) P(x_2 | x_3, \dots , x_n, C_k) P(x_3 | x_4,
    \dots , x_n, C_k) \ldots P(x_{n-1} | x_n, C_k) (x_{n} | C_k) P(C_k) \]
- en: The likelihood, conditional probability with the joint conditional is difficult,
    likely impossible to calculate. It requires information about the joint relationship
    between \(x_1, \dots , x_n\) features. As \(n\) increases this requires a lot
    of data to inform the joint distribution.
  id: totrans-3139
  prefs: []
  type: TYPE_NORMAL
  zh: è”åˆæ¡ä»¶æ¦‚ç‡çš„ä¼¼ç„¶ï¼Œä»è”åˆæ¡ä»¶æ¦‚ç‡çš„è§’åº¦çœ‹æ˜¯å›°éš¾çš„ï¼Œå¯èƒ½æ˜¯ä¸å¯èƒ½çš„ã€‚å®ƒéœ€è¦å…³äº \(x_1, \dots , x_n\) ç‰¹å¾ä¹‹é—´è”åˆå…³ç³»çš„ä¿¡æ¯ã€‚éšç€
    \(n\) çš„å¢åŠ ï¼Œè¿™éœ€è¦å¤§é‡æ•°æ®æ¥å‘ŠçŸ¥è”åˆåˆ†å¸ƒã€‚
- en: With the naive Bayes approach we make the â€˜naiveâ€™ assumption that the features
    are all *conditionally independent**. This entails,
  id: totrans-3140
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ´ç´ è´å¶æ–¯æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬åšå‡ºâ€œæœ´ç´ â€çš„å‡è®¾ï¼Œå³ç‰¹å¾éƒ½æ˜¯ *æ¡ä»¶ç‹¬ç«‹çš„**ã€‚è¿™åŒ…æ‹¬ï¼Œ
- en: \[ P(x_i | x_{i+1}, \ldots , x_n, C_k) = P(x_i | C_k) \]
  id: totrans-3141
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x_i | x_{i+1}, \ldots , x_n, C_k) = P(x_i | C_k) \]
- en: for all \(i = 1, \ldots, n\) features.
  id: totrans-3142
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰ \(i = 1, \ldots, n\) ç‰¹å¾ã€‚
- en: 'We can now solve for the needed conditional probability as:'
  id: totrans-3143
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥è§£å‡ºæ‰€éœ€çš„æ¡ä»¶æ¦‚ç‡å¦‚ä¸‹ï¼š
- en: \[ P(C_k | x_1, \dots , x_n) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i | C_k)}{P(x_1,
    \dots , x_n)} \]
  id: totrans-3144
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(C_k | x_1, \dots , x_n) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i | C_k)}{P(x_1,
    \dots , x_n)} \]
- en: We only need the prior, \(P(C_k)\), and a set of conditionals, \(P(x_i | C_k)\),
    for all predictor features, \(i = 1,\ldots,n\) and all categories, \(k = 1,\ldots,K\).
  id: totrans-3145
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€è¦å…ˆéªŒæ¦‚ç‡ \(P(C_k)\) å’Œæ‰€æœ‰é¢„æµ‹ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡é›†ï¼Œ\(P(x_i | C_k)\)ï¼Œå¯¹äºæ‰€æœ‰é¢„æµ‹ç‰¹å¾ \(i = 1,\ldots,n\)
    å’Œæ‰€æœ‰ç±»åˆ« \(k = 1,\ldots,K\)ã€‚
- en: The evidence term, \(P(x_1, \dots , x_n)\), is only based on the features \(x_1,
    \dots , x_n\); therefore, is a constant over the categories \(k = 1,\ldots,n\).
  id: totrans-3146
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ®é¡¹ \(P(x_1, \dots , x_n)\) ä»…åŸºäºç‰¹å¾ \(x_1, \dots , x_n\)ï¼›å› æ­¤ï¼Œåœ¨ç±»åˆ« \(k = 1,\ldots,n\)
    ä¸Šæ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚
- en: it ensures closure - probabilities over all categories sum to one
  id: totrans-3147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒç¡®ä¿äº†å°é—­æ€§ - æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œä¸º1
- en: we simply standardize the numerators to sum to one over the categories
  id: totrans-3148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªæ˜¯å°†åˆ†å­æ ‡å‡†åŒ–ï¼Œä½¿å…¶åœ¨ç±»åˆ«ä¸Šæ±‚å’Œä¸º1
- en: 'The naive Bayes approach is:'
  id: totrans-3149
  prefs: []
  type: TYPE_NORMAL
  zh: æœ´ç´ è´å¶æ–¯æ–¹æ³•å¦‚ä¸‹ï¼š
- en: simple to understand, builds on fundamental Bayesian statistics
  id: totrans-3150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®¹æ˜“ç†è§£ï¼Œå»ºç«‹åœ¨åŸºæœ¬çš„è´å¶æ–¯ç»Ÿè®¡åŸºç¡€ä¹‹ä¸Š
- en: practical even with small datasets since with the conditional independence we
    only need to estimate simple conditional distributions
  id: totrans-3151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å³ä½¿æ•°æ®é›†å¾ˆå°ï¼Œä¹Ÿæ˜¯å®ç”¨çš„ï¼Œå› ä¸ºæœ‰äº†æ¡ä»¶ç‹¬ç«‹æ€§ï¼Œæˆ‘ä»¬åªéœ€è¦ä¼°è®¡ç®€å•çš„æ¡ä»¶åˆ†å¸ƒ
- en: '**ndarray**'
  id: totrans-3152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ndarray**'
- en: 'Machine Learning Workflow Construction and Coding: Numpyâ€™s convenient class
    for working with grids, exhaustive, regularly spaced data over 2D or 3D, representing
    maps and models, due to,'
  id: totrans-3153
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šNumpyçš„ä¾¿æ·ç±»ï¼Œç”¨äºå¤„ç†2Dæˆ–3Dä¸Šçš„ç½‘æ ¼ã€è¯¦å°½ã€è§„åˆ™é—´éš”çš„æ•°æ®ï¼Œè¡¨ç¤ºåœ°å›¾å’Œæ¨¡å‹ï¼Œå› ä¸ºï¼Œ
- en: convenient data structure to store, access, manipulate gridded data
  id: totrans-3154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾¿äºå­˜å‚¨ã€è®¿é—®ã€æ“ä½œç½‘æ ¼æ•°æ®çš„ä¾¿æ·æ•°æ®ç»“æ„
- en: built in methods to load from a variety of file types, Python classes
  id: totrans-3155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ä»å„ç§æ–‡ä»¶ç±»å‹ä¸­åŠ è½½ï¼ŒPythonç±»
- en: built in methods to calculate multidimensional summary statistics
  id: totrans-3156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºè®¡ç®—å¤šç»´æ±‡æ€»ç»Ÿè®¡é‡
- en: built in methods for data queries, filters
  id: totrans-3157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºæ•°æ®æŸ¥è¯¢ã€ç­›é€‰
- en: built in methods for data manipulation, cleaning, reformatting
  id: totrans-3158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºæ•°æ®å¤„ç†ã€æ¸…ç†ã€é‡æ–°æ ¼å¼åŒ–
- en: built in attributes to store information about the nD array, for example, size
    and shape
  id: totrans-3159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®å±æ€§ä»¥å­˜å‚¨å…³äºnDæ•°ç»„çš„ä¿¡æ¯ï¼Œä¾‹å¦‚å¤§å°å’Œå½¢çŠ¶
- en: '**Nonparametric Model**'
  id: totrans-3160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éå‚æ•°æ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a model that makes
    no assumption about the functional form, shape of the natural setting.'
  id: totrans-3161
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªä¸å‡è®¾è‡ªç„¶è®¾ç½®ä¸­å‡½æ•°å½¢å¼ã€å½¢çŠ¶çš„æ¨¡å‹ã€‚'
- en: learns the shape from the training data, more flexibility to fit a variety of
    shapes for natural systems
  id: totrans-3162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ å½¢çŠ¶ï¼Œä»¥é€‚åº”è‡ªç„¶ç³»ç»Ÿçš„å„ç§å½¢çŠ¶å…·æœ‰æ›´å¤šçµæ´»æ€§
- en: less risk that the model is a poor fit for the natural settings than with parametric
    models
  id: totrans-3163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å‚æ•°æ¨¡å‹ç›¸æ¯”ï¼Œæ¨¡å‹å¯¹è‡ªç„¶è®¾ç½®çš„æ‹Ÿåˆé£é™©æ›´ä½
- en: Typically need a lot more data for an accurate estimate of nonparametric models,
  id: totrans-3164
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸éœ€è¦æ›´å¤šçš„æ•°æ®æ¥å‡†ç¡®ä¼°è®¡éå‚æ•°æ¨¡å‹ï¼Œ
- en: nonparametric often have many trainable parameters, i.e., nonparametric models
    are actually parametric rich!
  id: totrans-3165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éå‚æ•°æ¨¡å‹é€šå¸¸å…·æœ‰è®¸å¤šå¯è®­ç»ƒçš„å‚æ•°ï¼Œå³éå‚æ•°æ¨¡å‹å®é™…ä¸Šæ˜¯å‚æ•°ä¸°å¯Œçš„ï¼
- en: '**Norm**'
  id: totrans-3166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**èŒƒæ•°**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): norm of a vector
    maps vector values to a summary measure \([ğŸ,\infty)\), that indicates size or
    length.'
  id: totrans-3167
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šå‘é‡çš„èŒƒæ•°å°†å‘é‡å€¼æ˜ å°„åˆ°è¡¨ç¤ºå¤§å°æˆ–é•¿åº¦çš„åº¦é‡\([ğŸ,\infty)\)ã€‚'
- en: To train our models to training data, we require a single summary measure of
    mismatch with the training data, training error. The error is observed at each
    training data location,
  id: totrans-3168
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ä»¥è®­ç»ƒæ•°æ®ä¸ºç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå•ä¸€çš„ä¸åŒ¹é…åº¦é‡ï¼Œå³è®­ç»ƒè¯¯å·®ã€‚è¯¯å·®åœ¨æ¯ä¸ªè®­ç»ƒæ•°æ®ä½ç½®è§‚å¯Ÿåˆ°ï¼Œ
- en: \[ \Delta y_i = y_i - \hat{y}_i, \quad \forall \quad i = 1,\ldots,n \]
  id: totrans-3169
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Delta y_i = y_i - \hat{y}_i, \quad \forall \quad i = 1,\ldots,n \]
- en: as an error vector. We need a single value to summarize over all training data,
    that we can minimize!
  id: totrans-3170
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºé”™è¯¯å‘é‡ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå•ä¸€å€¼æ¥æ€»ç»“æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥æœ€å°åŒ–å®ƒï¼
- en: '**Normalization**'
  id: totrans-3171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è§„èŒƒåŒ–**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    distribution rescaling that can be thought of as shifting, and stretching or squeezing
    of a univariate distribution (e.g., *histogram*) to a minimum of 0.0 and a maximum
    of 1.0.'
  id: totrans-3172
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾è½¬æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§åˆ†å¸ƒç¼©æ”¾ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºå¹³ç§»ã€æ‹‰ä¼¸æˆ–å‹ç¼©ä¸€å…ƒåˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œ*ç›´æ–¹å›¾*ï¼‰åˆ°æœ€å°ä¸º0.0å’Œæœ€å¤§ä¸º1.0ã€‚'
- en: this is a shift and stretch / squeeze of the original property distribution
    assumes no shape change, rank preserving
  id: totrans-3173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹åŸå§‹å±æ€§åˆ†å¸ƒçš„å¹³ç§»å’Œæ‹‰ä¼¸/å‹ç¼©ï¼Œå‡è®¾æ²¡æœ‰å½¢çŠ¶å˜åŒ–ï¼Œä¿æŒç­‰çº§
- en: \[ y_i = \frac{x_i - min(x)}{max(x) - min(x)}, \quad \forall \quad i, \ldots,
    n \]
  id: totrans-3174
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{x_i - min(x)}{max(x) - min(x)}, \quad \forall \quad i, \ldots,
    n \]
- en: 'Methods that require standardization and min/max normalization:'
  id: totrans-3175
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦æ ‡å‡†åŒ–å’Œæœ€å°/æœ€å¤§å½’ä¸€åŒ–çš„æ–¹æ³•ï¼š
- en: k-means clustering, k-nearest neighbour regression
  id: totrans-3176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-meansèšç±»ã€k-æœ€è¿‘é‚»å›å½’
- en: \(\beta\) coefficientâ€™s for feature ranking
  id: totrans-3177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\beta\)ç³»æ•°ç”¨äºç‰¹å¾æ’åº
- en: artificial neural networks forward transform of predictor features and back
    transform of response features to improve activation function sensitivity
  id: totrans-3178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äººå·¥ç¥ç»ç½‘ç»œçš„å‰å‘è½¬æ¢é¢„æµ‹ç‰¹å¾å’Œåå‘è½¬æ¢å“åº”ç‰¹å¾ä»¥æ”¹å–„æ¿€æ´»å‡½æ•°çš„æ•æ„Ÿæ€§
- en: '**Normalized Histogram**'
  id: totrans-3179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å½’ä¸€åŒ–ç›´æ–¹å›¾**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): is a representation
    of the univariate statistical distribution with a plot of probability over an
    exhaustive set of bins over the range of possible values. These are the steps
    to build a normalized histogram,'
  id: totrans-3180
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šæ˜¯ä½¿ç”¨åœ¨å¯èƒ½å€¼èŒƒå›´å†…çš„ä¸€ä¸ªå®Œæ•´é›†åˆçš„binä¸Šçš„æ¦‚ç‡å›¾æ¥è¡¨ç¤ºå•å˜é‡ç»Ÿè®¡åˆ†å¸ƒã€‚'
- en: 'Divide the continuous feature range of possible values into \(K\) equal size
    bins, \(\delta x\):'
  id: totrans-3181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å¯èƒ½å€¼çš„è¿ç»­ç‰¹å¾èŒƒå›´åˆ’åˆ†ä¸º\(K\)ä¸ªç­‰å¤§å°çš„åŒºé—´ï¼Œ\(\delta x\)ï¼š
- en: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
  id: totrans-3182
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Delta x = \left( \frac{x_{max} - x_{min}}{K} \right) \]
- en: or use available categories for categorical features.
  id: totrans-3183
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ä½¿ç”¨å¯ç”¨çš„ç±»åˆ«ä½œä¸ºåˆ†ç±»ç‰¹å¾çš„ç±»åˆ«ã€‚
- en: Count the number of samples (frequency) in each bin, \(n_k\), \(\forall k=1,\ldots,K\)
    and divide each by the total number of data, \(n\), to calculate the probability
    of each bin,
  id: totrans-3184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯ä¸ªç®±ä¸­æ ·æœ¬çš„æ•°é‡ï¼ˆé¢‘ç‡ï¼‰ï¼Œ\(n_k\)ï¼Œ\(\forall k=1,\ldots,K\)ï¼Œå¹¶å°†æ¯ä¸ªé™¤ä»¥æ•°æ®æ€»æ•°ï¼Œ\(n\)ï¼Œä»¥è®¡ç®—æ¯ä¸ªç®±çš„æ¦‚ç‡ï¼Œ
- en: \[ p_k = \frac{n_k}{n}, \forall \quad k = 1,\ldots,L \]
  id: totrans-3185
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p_k = \frac{n_k}{n}, \forall \quad k = 1,\ldots,L \]
- en: Plot the probability vs. the bin label (use bin centroid if continuous)
  id: totrans-3186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æ¦‚ç‡ä¸ç®±æ ‡ç­¾çš„å…³ç³»å›¾ï¼ˆå¦‚æœè¿ç»­ï¼Œåˆ™ä½¿ç”¨ç®±ä¸­å¿ƒï¼‰
- en: Note, normalized histograms are typically plotted as a bar chart.
  id: totrans-3187
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå½’ä¸€åŒ–ç›´æ–¹å›¾é€šå¸¸ä»¥æŸ±çŠ¶å›¾çš„å½¢å¼ç»˜åˆ¶ã€‚
- en: '**One Hot Encoding**'
  id: totrans-3188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç‹¬çƒ­ç¼–ç **'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): bin
    the range of the feature into K bins, then for each sample assignment of a value
    of 1 if the sample is within a bin and 0 if outsize the bin'
  id: totrans-3189
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šå°†ç‰¹å¾çš„å–å€¼èŒƒå›´åˆ’åˆ†ä¸ºKä¸ªç®±ï¼Œç„¶åå¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œå¦‚æœæ ·æœ¬åœ¨ç®±å†…ï¼Œåˆ™åˆ†é…å€¼ä¸º1ï¼Œå¦‚æœä¸åœ¨ç®±å†…ï¼Œåˆ™åˆ†é…å€¼ä¸º0'
- en: binning strategies include uniform width bins (uniform) and uniform number of
    data in each bin (quantile)
  id: totrans-3190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®±åˆ’åˆ†ç­–ç•¥åŒ…æ‹¬å‡åŒ€å®½åº¦ç®±ï¼ˆå‡åŒ€ï¼‰å’Œæ¯ä¸ªç®±ä¸­å‡åŒ€æ•°é‡çš„æ•°æ®ï¼ˆåˆ†ä½æ•°ï¼‰
- en: also known as K bins discretization
  id: totrans-3191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹Ÿç§°ä¸ºKç®±ç¦»æ•£åŒ–
- en: Methods that require K bins discretization,
  id: totrans-3192
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦Kç®±ç¦»æ•£åŒ–çš„æ–¹æ³•ï¼Œ
- en: basis expansion to work in a higher dimensional space
  id: totrans-3193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºç¡€æ‰©å±•ä»¥åœ¨æ›´é«˜ç»´ç©ºé—´ä¸­å·¥ä½œ
- en: discretization of continuous features to categorical features for categorical
    methods such as naive Bayes classifier
  id: totrans-3194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºåˆ†ç±»ç‰¹å¾ï¼Œç”¨äºåˆ†ç±»æ–¹æ³•ï¼Œå¦‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
- en: histogram construction and Chi-square test for difference in distributions
  id: totrans-3195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´æ–¹å›¾æ„å»ºå’Œåˆ†å¸ƒå·®å¼‚çš„å¡æ–¹æ£€éªŒ
- en: mutual information binning
  id: totrans-3196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº’ä¿¡æ¯ç®±åˆ’åˆ†
- en: '**Out-of-Bag Sample**'
  id: totrans-3197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¢‹å¤–æ ·æœ¬**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): with
    bootstrap resampling of the data, it can be shown that about \(\frac{2}{3}\) of
    the data will be included (in expectation). For bagging-based ensemble prediction
    models,'
  id: totrans-3198
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¢‹è£…æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šé€šè¿‡æ•°æ®é‡é‡‡æ ·ï¼Œå¯ä»¥è¯æ˜å¤§çº¦ \(\frac{2}{3}\)
    çš„æ•°æ®å°†è¢«åŒ…æ‹¬ï¼ˆåœ¨æœŸæœ›ä¸­ï¼‰ã€‚å¯¹äºåŸºäºè¢‹è£…çš„é›†æˆé¢„æµ‹æ¨¡å‹ï¼Œ'
- en: therefore are \(\frac{1}{3}\) of the data (in expectation) unused in training
    each model realization, these are know as out-of-bag observations
  id: totrans-3199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ¯ä¸ªæ¨¡å‹å®ç°ä¸­ï¼Œæœ‰ \(\frac{1}{3}\) çš„æ•°æ®ï¼ˆåœ¨æœŸæœ›ä¸­ï¼‰æœªè¢«ç”¨äºè®­ç»ƒï¼Œè¿™äº›è¢«ç§°ä¸ºè¢‹å¤–è§‚æµ‹å€¼
- en: for every response feature observation, \(y_{\alpha}\), there are \(\frac{B}{3}\)
    out-of-bag predictions, \(y^{*,b}_{\alpha}\)
  id: totrans-3200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªå“åº”ç‰¹å¾è§‚æµ‹å€¼ï¼Œ\(y_{\alpha}\)ï¼Œæœ‰ \(\frac{B}{3}\) ä¸ªè¢‹å¤–é¢„æµ‹ï¼Œ\(y^{*,b}_{\alpha}\)
- en: we can aggregate this ensemble of prediction realizations, average for regression
    or mode for classification, to calculate a single out-of-bag prediction, \(y^{*}_{\alpha}
    = \sum_{\alpha = 1}^{\frac{B}{3}} y^{*,b}_{\alpha}\)
  id: totrans-3201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ±‡æ€»è¿™ä¸ªé¢„æµ‹å®ç°çš„é›†æˆï¼Œå¯¹äºå›å½’å–å¹³å‡å€¼æˆ–å¯¹äºåˆ†ç±»å–ä¼—æ•°ï¼Œä»¥è®¡ç®—å•ä¸ªè¢‹å¤–é¢„æµ‹ï¼Œ\(y^{*}_{\alpha} = \sum_{\alpha =
    1}^{\frac{B}{3}} y^{*,b}_{\alpha}\)
- en: from these single out-of-bag predictions over all data, the out-of-bag mean
    square error (MSE) is calculated as,
  id: totrans-3202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ‰€æœ‰æ•°æ®ä¸­çš„å•ä¸ªè¢‹å¤–é¢„æµ‹ä¸­ï¼Œè®¡ç®—è¢‹å¤–å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å¦‚ä¸‹ï¼Œ
- en: \[ MSE_{OOB} = \sum_{\alpha = 1}^{\frac{B}{3}} \left[ y^{*}_{\alpha} - y_{\alpha}
    \right]^2 \]
  id: totrans-3203
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MSE_{OOB} = \sum_{\alpha = 1}^{\frac{B}{3}} \left[ y^{*}_{\alpha} - y_{\alpha}
    \right]^2 \]
- en: For bagging-based ensemble predictive machine learning, there is no need to
    perform training and testing splits, hyperparameter tuning can be applied with
    out-of-bag MSE.
  id: totrans-3204
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåŸºäºè¢‹è£…çš„é›†æˆé¢„æµ‹æœºå™¨å­¦ä¹ ï¼Œä¸éœ€è¦æ‰§è¡Œè®­ç»ƒå’Œæµ‹è¯•åˆ’åˆ†ï¼Œå¯ä»¥ä½¿ç”¨è¢‹å¤–å‡æ–¹è¯¯å·®è¿›è¡Œè¶…å‚æ•°è°ƒæ•´ã€‚
- en: this is equivalent to random train and test split that may not be fair, same
    difficulty as the planned use of the model
  id: totrans-3205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç›¸å½“äºéšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¯èƒ½ä¸å…¬å¹³ï¼Œéš¾åº¦ä¸è®¡åˆ’ä½¿ç”¨æ¨¡å‹ç›¸åŒ
- en: this freezes the test proportion at about \(\frac{1}{3}\)
  id: totrans-3206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™å°†æµ‹è¯•æ¯”ä¾‹å†»ç»“åœ¨å¤§çº¦ \(\frac{1}{3}\)
- en: '**Overfit Model**'
  id: totrans-3207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¿‡æ‹Ÿåˆæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a machine learning
    model that is fit to data noise or data idiosyncrasies'
  id: totrans-3208
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªé€‚åˆæ•°æ®å™ªå£°æˆ–æ•°æ®ç‰¹æ®Šæ€§çš„æœºå™¨å­¦ä¹ æ¨¡å‹'
- en: increased complexity will generally decrease error with respect to the training
    dataset but, may result in increase error with testing data
  id: totrans-3209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ çš„å¤æ‚æ€§é€šå¸¸ä¼šåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šé™ä½è¯¯å·®ï¼Œä½†å¯èƒ½ä¼šåœ¨æµ‹è¯•æ•°æ®ä¸Šå¢åŠ è¯¯å·®
- en: over the region of model complexity with rising testing error and falling training
    error
  id: totrans-3210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¨¡å‹å¤æ‚åº¦ä¸Šå‡çš„æµ‹è¯•è¯¯å·®å’Œä¸‹é™çš„è®­ç»ƒè¯¯å·®çš„åŒºåŸŸ
- en: Issues of an overfit machine learning model,
  id: totrans-3211
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‡æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„é—®é¢˜ï¼Œ
- en: more model complexity and flexibility than can be justified with the available
    data, data accuracy, frequency and coverage
  id: totrans-3212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹å¤æ‚æ€§å’Œçµæ´»æ€§æ¯”å¯ç”¨æ•°æ®ã€æ•°æ®å‡†ç¡®æ€§ã€é¢‘ç‡å’Œè¦†ç›–èŒƒå›´æ‰€è¯æ˜çš„æ›´å¤š
- en: high accuracy in training, but low accuracy in testing representing real-world
    use away from training data cases, indicating poor ability of the model to generalize
  id: totrans-3213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ—¶é«˜ç²¾åº¦ï¼Œä½†åœ¨æµ‹è¯•æ—¶ç²¾åº¦ä½ï¼Œè¡¨ç¤ºæ¨¡å‹åœ¨è¿œç¦»è®­ç»ƒæ•°æ®æ¡ˆä¾‹çš„çœŸå®ä¸–ç•Œä½¿ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®
- en: '**Parameters** (statistics)'
  id: totrans-3214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚æ•°**ï¼ˆç»Ÿè®¡å­¦ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a summary measure
    of a population'
  id: totrans-3215
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ€»ä½“çš„ä¸€ç§æ¦‚æ‹¬æ€§åº¦é‡'
- en: for example, population mean, population standard deviation
  id: totrans-3216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ€»ä½“å‡å€¼ï¼Œæ€»ä½“æ ‡å‡†å·®
- en: We very rarely have access to actual population parameters, in general we infer
    population parameters with available sample statistics
  id: totrans-3217
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾ˆå°‘æœ‰æœºä¼šæ¥è§¦åˆ°å®é™…çš„æ€»ä½“å‚æ•°ï¼Œé€šå¸¸æˆ‘ä»¬ä½¿ç”¨å¯ç”¨çš„æ ·æœ¬ç»Ÿè®¡é‡æ¥æ¨æ–­æ€»ä½“å‚æ•°
- en: '**Parameters** (machine learning)'
  id: totrans-3218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚æ•°**ï¼ˆæœºå™¨å­¦ä¹ ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): trainable coefficients
    for a machine learning model that control the fit to the training data'
  id: totrans-3219
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒç³»æ•°ï¼Œç”¨äºæ§åˆ¶å¯¹è®­ç»ƒæ•°æ®çš„æ‹Ÿåˆ'
- en: model parameters are calculated by optimization to minimize error over the training
    data through, analytical solution, or iterative solution, e.g., gradient descent
    optimization
  id: totrans-3220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹å‚æ•°é€šè¿‡ä¼˜åŒ–è®¡ç®—ï¼Œä»¥æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®ï¼Œä¾‹å¦‚é€šè¿‡è§£æè§£æˆ–è¿­ä»£è§£ï¼Œå¦‚æ¢¯åº¦ä¸‹é™ä¼˜åŒ–
- en: '**Parametric Model**'
  id: totrans-3221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚æ•°æ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a model that makes
    an assumption about the functional form, shape of the natural system.'
  id: totrans-3222
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¯¹è‡ªç„¶ç³»ç»Ÿçš„å‡½æ•°å½¢å¼ã€å½¢çŠ¶åšå‡ºå‡è®¾çš„æ¨¡å‹ã€‚'
- en: we gain simplicity and advantage of only a few parameters
  id: totrans-3223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è·å¾—ç®€å•æ€§å’Œåªæœ‰å°‘æ•°å‚æ•°çš„ä¼˜åŠ¿
- en: for is a linear model we only have \(m+1\) model parameters
  id: totrans-3224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºçº¿æ€§æ¨¡å‹ï¼Œæˆ‘ä»¬åªæœ‰ \(m+1\) ä¸ªæ¨¡å‹å‚æ•°
- en: There is a risk that our model is quite different than the natural setting,
    resulting in a poor model, for example, a linear model applied to a nonlinear
    phenomenon.
  id: totrans-3225
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨ä¸€ç§é£é™©ï¼Œå³æˆ‘ä»¬çš„æ¨¡å‹ä¸è‡ªç„¶è®¾ç½®å¤§ç›¸å¾„åº­ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³ï¼Œä¾‹å¦‚ï¼Œå°†çº¿æ€§æ¨¡å‹åº”ç”¨äºéçº¿æ€§ç°è±¡ã€‚
- en: '**Partial Correlation Coefficient**'
  id: totrans-3226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éƒ¨åˆ†ç›¸å…³ç³»æ•°**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): a method
    to calculate the correlation between \(ğ‘¿\) and \(ğ’€\) after controlling for the
    influence of \(ğ’_ğŸ,\ldots,ğ’_(ğ’âˆ’ğŸ)\) other features on both \(ğ‘¿\) and \(ğ‘Œ\). Note,
    I use \(m-2\) to account for \(X\) and \(Y\) removed.'
  id: totrans-3227
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šä¸€ç§è®¡ç®— \(ğ‘¿\) å’Œ \(ğ’€\) ä¹‹é—´ç›¸å…³æ€§çš„æ–¹æ³•ï¼Œåœ¨æ§åˆ¶
    \(ğ’_ğŸ,\ldots,ğ’_(ğ’âˆ’ğŸ)\) å…¶ä»–ç‰¹å¾å¯¹ \(ğ‘¿\) å’Œ \(ğ‘Œ\) çš„å½±å“åã€‚æ³¨æ„ï¼Œæˆ‘ä½¿ç”¨ \(m-2\) æ¥è€ƒè™‘ \(X\) å’Œ \(Y\)
    è¢«ç§»é™¤ã€‚'
- en: For \(\rho_(ğ‘‹,ğ‘Œ.ğ‘_1,â€¦,ğ‘_(ğ‘šâˆ’2) )\),
  id: totrans-3228
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº \(\rho_(ğ‘‹,ğ‘Œ.ğ‘_1,â€¦,ğ‘_(ğ‘šâˆ’2) )\)ï¼Œ
- en: perform linear, least-squares regression to predict \(ğ‘¿\) from \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\).
    \(ğ‘¿\) is regressed on the predictors to calculate the estimate, \(ğ‘¿^âˆ—\).
  id: totrans-3229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œçº¿æ€§ã€æœ€å°äºŒä¹˜å›å½’æ¥é¢„æµ‹ \(ğ‘¿\) ä» \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\)ã€‚\(ğ‘¿\) é€šè¿‡é¢„æµ‹å› å­è¿›è¡Œå›å½’ä»¥è®¡ç®—ä¼°è®¡å€¼ï¼Œ\(ğ‘¿^âˆ—\)ã€‚
- en: perform linear, least-squares regression to predict \(ğ’€\) from \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\).
    \(ğ’€\) is regressed on the predictors to calculate the estimate, ğ’€^âˆ—
  id: totrans-3230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œçº¿æ€§ã€æœ€å°äºŒä¹˜å›å½’æ¥é¢„æµ‹ \(ğ’€\) ä» \(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\)ã€‚\(ğ’€\) é€šè¿‡é¢„æµ‹å› å­è¿›è¡Œå›å½’ä»¥è®¡ç®—ä¼°è®¡å€¼ï¼Œ\(ğ’€^âˆ—\)
- en: 'calculate the residuals in Step #1, \(ğ‘¿ âˆ’ ğ‘¿^âˆ—\), where \(ğ‘¿^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
    linear regression model'
  id: totrans-3231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'åœ¨æ­¥éª¤ #1 ä¸­è®¡ç®—æ®‹å·®ï¼Œ\(ğ‘¿ âˆ’ ğ‘¿^âˆ—\)ï¼Œå…¶ä¸­ \(ğ‘¿^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\)ï¼Œçº¿æ€§å›å½’æ¨¡å‹'
- en: 'calculate the residuals in Step #2, \(ğ’€ âˆ’ ğ’€^âˆ—\), where \(ğ’€^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
    linear regression model'
  id: totrans-3232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'åœ¨æ­¥éª¤ #2 ä¸­è®¡ç®—æ®‹å·®ï¼Œ\(ğ’€ âˆ’ ğ’€^âˆ—\)ï¼Œå…¶ä¸­ \(ğ’€^âˆ—=ğ’‡(ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\)ï¼Œçº¿æ€§å›å½’æ¨¡å‹'
- en: 'calculate the correlation coefficient between the residuals from Steps #3 and
    #4, \(\rho_{ğ‘¿ âˆ’ğ‘¿^âˆ—,ğ’€ âˆ’ ğ’€^âˆ—}\)'
  id: totrans-3233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'è®¡ç®—æ­¥éª¤ #3 å’Œ #4 ä¸­æ®‹å·®ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼Œ\(\rho_{ğ‘¿ âˆ’ğ‘¿^âˆ—,ğ’€ âˆ’ ğ’€^âˆ—}\)'
- en: Assumptions of Partial Correlation, for \(ğ†_(ğ‘¿,ğ’€.ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\),
  id: totrans-3234
  prefs: []
  type: TYPE_NORMAL
  zh: éƒ¨åˆ†ç›¸å…³æ€§çš„å‡è®¾ï¼Œå¯¹äº \(ğ†_(ğ‘¿,ğ’€.ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ})\)ï¼Œ
- en: \(ğ‘¿,ğ’€,ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\) have linear relationships, i.e., all pairwise relationships
    are linear
  id: totrans-3235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(ğ‘¿,ğ’€,ğ’_ğŸ,\ldots,ğ’_{ğ’âˆ’ğŸ}\) å­˜åœ¨çº¿æ€§å…³ç³»ï¼Œå³æ‰€æœ‰æˆå¯¹å…³ç³»éƒ½æ˜¯çº¿æ€§çš„
- en: no outliers for any of the univariate distributions (univariate outliers) and
    pairwise relationships (bivariate outliers). Partial correlation is very sensitive
    to outliers like regular correlation.
  id: totrans-3236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºä»»ä½•å•å˜é‡åˆ†å¸ƒï¼ˆå•å˜é‡å¼‚å¸¸å€¼ï¼‰å’Œæˆå¯¹å…³ç³»ï¼ˆåŒå˜é‡å¼‚å¸¸å€¼ï¼‰éƒ½æ²¡æœ‰å¼‚å¸¸å€¼ã€‚éƒ¨åˆ†ç›¸å…³æ€§å¯¹å¼‚å¸¸å€¼åƒå¸¸è§„ç›¸å…³æ€§ä¸€æ ·æ•æ„Ÿã€‚
- en: Gaussian distributed, univariate and pairwise bivariate distributions Gaussian
    distributed. Bivariate should be linearly related and homoscedastic.
  id: totrans-3237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜æ–¯åˆ†å¸ƒï¼Œå•å˜é‡å’Œæˆå¯¹çš„åŒå˜é‡åˆ†å¸ƒéƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒã€‚åŒå˜é‡åº”è¯¥æ˜¯çº¿æ€§ç›¸å…³çš„ï¼Œå¹¶ä¸”åŒæ–¹å·®ã€‚
- en: '**Partitional Clustering**'
  id: totrans-3238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åˆ’åˆ†èšç±»**'
- en: 'Cluster Analysis: all cluster group assignments are determined at once, as
    opposed to an agglomerative hierarchical clustering method that starts with \(n\)
    clusters and then iteratively merges clusters into larger clusters'
  id: totrans-3239
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šæ‰€æœ‰èšç±»åˆ†ç»„åˆ†é…ä¸€æ¬¡ç¡®å®šï¼Œä¸ä» \(n\) ä¸ªèšç±»å¼€å§‹å¹¶è¿­ä»£åˆå¹¶èšç±»åˆ°æ›´å¤§èšç±»çš„å±‚æ¬¡èšç±»æ–¹æ³•ç›¸å
- en: k-means clustering is partitional clustering, while the solution heuristic to
    find the solution is iterative, the solution is actually all at once
  id: totrans-3240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-means èšç±»æ˜¯åˆ’åˆ†èšç±»ï¼Œè€Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆçš„å¯å‘å¼æ–¹æ³•æ˜¯è¿­ä»£çš„ï¼Œä½†å®é™…ä¸Šè§£å†³æ–¹æ¡ˆæ˜¯ä¸€æ¬¡æ€§ç¡®å®šçš„ã€‚
- en: easy to update, for example, by modifying the prototype locations and recalculating
    the group assignments
  id: totrans-3241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®¹æ˜“æ›´æ–°ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡ä¿®æ”¹åŸå‹ä½ç½®å¹¶é‡æ–°è®¡ç®—åˆ†ç»„åˆ†é…
- en: '**Polygonal Declustering**'
  id: totrans-3242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤šè¾¹å½¢å»èšç±»**'
- en: 'Data Preparation: a declustering method to assign weights to spatial samples
    based on local sampling density, such that the weighted statistics are likely
    more representative of the population. Data weights are assigned so that,'
  id: totrans-3243
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¸€ç§å»èšç±»æ–¹æ³•ï¼Œæ ¹æ®å±€éƒ¨é‡‡æ ·å¯†åº¦å¯¹ç©ºé—´æ ·æœ¬åˆ†é…æƒé‡ï¼Œä½¿å¾—åŠ æƒç»Ÿè®¡æ›´æœ‰å¯èƒ½ä»£è¡¨æ€»ä½“ã€‚æ•°æ®æƒé‡åˆ†é…å¦‚ä¸‹ï¼Œ
- en: samples in densely sampled areas receive less weight
  id: totrans-3244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨ å¯†é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬è·å¾—è¾ƒå°‘æƒé‡
- en: samples in sparsely sampled areas receive more weight
  id: totrans-3245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨€ç–é‡‡æ ·åŒºåŸŸä¸­çš„æ ·æœ¬è·å¾—æ›´å¤šæƒé‡
- en: 'Polygonal declustering proceeds as follows:'
  id: totrans-3246
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šè¾¹å½¢å»èšç±»æŒ‰ä»¥ä¸‹æ–¹å¼è¿›è¡Œï¼š
- en: Split up the area of interest with Voronoi polygons. These are constructed by
    intersected perpendicular bisectors between adjacent data points. The polygons
    group the area of interest by nearest data point
  id: totrans-3247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Voronoi å¤šè¾¹å½¢åˆ’åˆ†æ„Ÿå…´è¶£åŒºåŸŸã€‚è¿™äº›å¤šè¾¹å½¢æ˜¯é€šè¿‡ç›¸é‚»æ•°æ®ç‚¹ä¹‹é—´çš„ç›¸äº¤å‚ç›´å¹³åˆ†çº¿æ„å»ºçš„ã€‚å¤šè¾¹å½¢é€šè¿‡æœ€è¿‘çš„æ•°æ®ç‚¹å°†æ„Ÿå…´è¶£åŒºåŸŸåˆ†ç»„
- en: Assign weight to each datum proportional to the area of the associated Voronoi
    polygon
  id: totrans-3248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®ç›¸å…³ Voronoi å¤šè¾¹å½¢çš„é¢ç§¯æŒ‰æ¯”ä¾‹åˆ†é…æ¯ä¸ªæ•°æ®çš„æƒé‡
- en: \[ w(\bf{u}_j) = n \cdot \frac{A_j}{\sum_{j=1}^n} \]
  id: totrans-3249
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w(\bf{u}_j) = n \cdot \frac{A_j}{\sum_{j=1}^n} \]
- en: where \(w(\bf{u}_j)\) is the weight for the \(j\) data. Note, the sum of the
    weights is \(n\); therefore, \(w(\bf{u}_j)\) is nominal weight of 1.0, sample
    density if the data were equally spaced over the area of interest.
  id: totrans-3250
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(w(\bf{u}_j)\) æ˜¯ \(j\) æ•°æ®çš„æƒé‡ã€‚æ³¨æ„ï¼Œæƒé‡çš„æ€»å’Œæ˜¯ \(n\)ï¼›å› æ­¤ï¼Œ\(w(\bf{u}_j)\) æ˜¯åä¹‰æƒé‡ 1.0ï¼Œå¦‚æœæ•°æ®åœ¨æ„Ÿå…´è¶£åŒºåŸŸçš„é¢ç§¯ä¸Šå‡åŒ€åˆ†å¸ƒï¼Œåˆ™è¡¨ç¤ºæ ·æœ¬å¯†åº¦ã€‚
- en: Here are some highlights for polygonal declustering,
  id: totrans-3251
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€äº›å…³äºå¤šè¾¹å½¢å»èšç±»çš„äº®ç‚¹ï¼Œ
- en: polygonal declustering is sensitive to the boundaries of the area of interest;
    therefore, the weights assigned to the data near the boundary of the area of interest
    may change radically as the area of interest is expanded or contracted
  id: totrans-3252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šè¾¹å½¢å»èšç±»å¯¹æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œæ•æ„Ÿï¼›å› æ­¤ï¼Œå½“æ„Ÿå…´è¶£åŒºåŸŸæ‰©å±•æˆ–æ”¶ç¼©æ—¶ï¼Œåˆ†é…ç»™æ„Ÿå…´è¶£åŒºåŸŸè¾¹ç•Œé™„è¿‘çš„æ•°æ®çš„æƒé‡å¯èƒ½ä¼šå‘ç”Ÿæ ¹æœ¬æ€§å˜åŒ–
- en: polygonal declustering is the same as the Theissen polygon method for calculation
    of precipitation averages developed by Afred H. Thiessen in 1911, []
  id: totrans-3253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šè¾¹å½¢å»èšç±»ä¸ Alfred H. Thiessen åœ¨ 1911 å¹´å¼€å‘çš„ç”¨äºè®¡ç®—é™æ°´å¹³å‡å€¼çš„ Theissen å¤šè¾¹å½¢æ–¹æ³•ç›¸åŒ []
- en: '**Polynomial Regression**'
  id: totrans-3254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¤šé¡¹å¼å›å½’**'
- en: '[Polynomial Regression](MachineLearning_polynomial_regression.html): application
    of polynomial basis expansion to the predictor features before linear regression,'
  id: totrans-3255
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šé¡¹å¼å›å½’](MachineLearning_polynomial_regression.html)ï¼šåœ¨çº¿æ€§å›å½’ä¹‹å‰å°†å¤šé¡¹å¼åŸºå±•å¼€åº”ç”¨äºé¢„æµ‹ç‰¹å¾ï¼Œ'
- en: \[ y = \sum_{l=1}^{k} \sum_{j=1}^{m} \beta_{j,l} h_l (X_j) + \beta_0 \]
  id: totrans-3256
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \sum_{l=1}^{k} \sum_{j=1}^{m} \beta_{j,l} h_l (X_j) + \beta_0 \]
- en: where the h transforms over training data, \(ğ‘–=1,\ldots,n\),
  id: totrans-3257
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ h å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œè½¬æ¢ï¼Œ\(ğ‘–=1,\ldots,n\),
- en: \[ h_1(x_i) = x_i, \quad h_2(x_i) = x_i^2, \quad h_3(x_i) = x_i^3, \quad h_4(x_i)
    = x_i^4, \dots, h_k(x_i) = x_i^k \]
  id: totrans-3258
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_1(x_i) = x_i, \quad h_2(x_i) = x_i^2, \quad h_3(x_i) = x_i^3, \quad h_4(x_i)
    = x_i^4, \dots, h_k(x_i) = x_i^k \]
- en: up to the specified order \(ğ‘˜\).
  id: totrans-3259
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€é«˜åˆ°æŒ‡å®šçš„ \(ğ‘˜\) é˜¶ã€‚
- en: For example, with a single predictor feature, \(ğ‘š = 1\), up to the \(4^{th}\)
    order,
  id: totrans-3260
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¯¹äºå•ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œ\(ğ‘š = 1\)ï¼Œæœ€é«˜åˆ° \(4^{th}\) é˜¶ï¼Œ
- en: \[ y = \beta_{1,1} X + \beta_{1,2} X^2 + \beta_{1,3} X^3 + \beta_{1,4} X^4 +
    \beta_0 \]
  id: totrans-3261
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \beta_{1,1} X + \beta_{1,2} X^2 + \beta_{1,3} X^3 + \beta_{1,4} X^4 +
    \beta_0 \]
- en: After the \(ğ’‰_ğ’\), \(ğ‘™=1,\ldots,ğ‘˜\) transforms, over the \(ğ‘—=1,\dots,ğ‘š\) predictor
    features we have the same linear equation and the ability to utilize the previously
    discussed analytical solution.
  id: totrans-3262
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ \(ğ‘—=1,\dots,ğ‘š\) ä¸ªé¢„æµ‹ç‰¹å¾ä¸Šï¼Œç»è¿‡ \(ğ‘™=1,\ldots,ğ‘˜\) çš„ \(ğ‘™\) è½¬æ¢åï¼Œæˆ‘ä»¬æœ‰ç›¸åŒçš„çº¿æ€§æ–¹ç¨‹å’Œåˆ©ç”¨å…ˆå‰è®¨è®ºçš„è§£æè§£çš„èƒ½åŠ›ã€‚
- en: we are assuming linearity after application of our basis expansion.
  id: totrans-3263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡è®¾åœ¨åº”ç”¨åŸºå±•å¼€åæ˜¯çº¿æ€§çš„ã€‚
- en: Now the model parameters, \(\beta_(ğ’,ğ’Š)\), relate to a transformed version of
    the initial predictor feature, \(ğ’‰_ğ’ (ğ‘¿_ğ’‹)\).
  id: totrans-3264
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¨¡å‹å‚æ•°ï¼Œ\(\beta_(ğ’,ğ’Š)\)ï¼Œä¸åˆå§‹é¢„æµ‹ç‰¹å¾è½¬æ¢åçš„ç‰ˆæœ¬ç›¸å…³ï¼Œ\(ğ’‰_ğ’ (ğ‘¿_ğ’‹)\)ã€‚
- en: we lose the ability to interpret the coefficients, for example, what is ğ‘ğ‘’ğ‘Ÿğ‘šğ‘’ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦\(^4\)?
  id: totrans-3265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¤±å»äº†è§£é‡Šç³»æ•°çš„èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼Œ\(ğ‘ğ‘’ğ‘Ÿğ‘šğ‘’ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦\(^4\)) æ˜¯ä»€ä¹ˆï¼Ÿ
- en: generally, significantly higher model variance, i.e., may have unstable interpolation
    and especially extrapolation
  id: totrans-3266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ¨¡å‹æ–¹å·®æ˜¾è‘—æ›´é«˜ï¼Œå³å¯èƒ½æœ‰ä¸ç¨³å®šçš„æ’å€¼å’Œç‰¹åˆ«æ˜¯å¤–æ¨
- en: Polynomial regression model assumptions,
  id: totrans-3267
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’æ¨¡å‹å‡è®¾ï¼Œ
- en: '*error-free* - predictor features basis expansions are error free, not random
    variables'
  id: totrans-3268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— è¯¯å·®* - é¢„æµ‹ç‰¹å¾åŸºå‡½æ•°æ‰©å±•æ˜¯æ— è¯¯å·®çš„ï¼Œä¸æ˜¯éšæœºå˜é‡'
- en: '*constant variance* - error in response is constant over predictor(s) value'
  id: totrans-3269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ–¹å·®æ’å®š* - å“åº”è¯¯å·®åœ¨é¢„æµ‹å€¼ä¸Šæ’å®š'
- en: '*linearity* - response is linear combination of basis features'
  id: totrans-3270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*çº¿æ€§* - å“åº”æ˜¯åŸºç‰¹å¾çš„ç»„åˆ'
- en: '*polynomial* - relationships between ğ‘‹ and Y is polynomial'
  id: totrans-3271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šé¡¹å¼* - Xå’ŒYä¹‹é—´çš„å…³ç³»æ˜¯å¤šé¡¹å¼'
- en: '*independence of error* - error in response are uncorrelated with each other'
  id: totrans-3272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¯¯å·®ç‹¬ç«‹æ€§* - å“åº”è¯¯å·®ä¹‹é—´ç›¸äº’ä¸ç›¸å…³'
- en: no multicollinearity* - none of the basis feature expansions are linearly redundant
    with other features
  id: totrans-3273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ— å¤šé‡å…±çº¿æ€§* - åŸºç‰¹å¾æ‰©å±•ä¸­æ²¡æœ‰ä»»ä½•ä¸€ä¸ªä¸å…¶ä»–ç‰¹å¾çº¿æ€§å†—ä½™'
- en: '**Population**'
  id: totrans-3274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ€»ä½“**'
- en: '[Probability Concepts](MachineLearning_probability.html): exhaustive, finite
    list of property of interest over area of interest.'
  id: totrans-3275
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šåœ¨æ„Ÿå…´è¶£åŒºåŸŸå†…å¯¹æ„Ÿå…´è¶£å±æ€§çš„è¯¦å°½ã€æœ‰é™åˆ—è¡¨ã€‚'
- en: for example, exhaustive set of porosity measures at every location within a
    reservoir
  id: totrans-3276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨å‚¨å±‚å†…æ¯ä¸ªä½ç½®çš„å­”éš™ç‡åº¦é‡çš„è¯¦å°½é›†åˆ
- en: Generally, the entire population is not generally accessible and we use a limited
    sample to make inference concerning the population
  id: totrans-3277
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ•´ä¸ªæ€»ä½“é€šå¸¸ä¸å¯è®¿é—®ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ‰é™çš„æ ·æœ¬æ¥å¯¹æ€»ä½“è¿›è¡Œæ¨æ–­
- en: '**Power Law Average**'
  id: totrans-3278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¹‚å¾‹å¹³å‡**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    general form for averaging based scale up, aggregation of smaller scale measures
    in a larger volume into a single value representative of the larger volume'
  id: totrans-3279
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šåŸºäºå°ºåº¦æ”¾å¤§çš„ä¸€èˆ¬å½¢å¼ï¼Œå°†è¾ƒå¤§ä½“ç§¯ä¸­çš„è¾ƒå°å°ºåº¦åº¦é‡èšåˆä¸ºè¡¨ç¤ºè¾ƒå¤§ä½“ç§¯çš„å•ä¸ªå€¼'
- en: \[ \overline{x}_p = \left(\frac{1}{n}\sum_{i=1}^n x_i^p \right)^{\frac{1}{p}}
    \]
  id: totrans-3280
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{x}_p = \left(\frac{1}{n}\sum_{i=1}^n x_i^p \right)^{\frac{1}{p}}
    \]
- en: useful to calculate effective permeability where flow is not parallel nor perpendicular
    to distinct permeability layers
  id: totrans-3281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰åŠ©äºè®¡ç®—éå¹³è¡Œä¹Ÿä¸å‚ç›´äºä¸åŒæ¸—é€ç‡å±‚çš„æœ‰æ•ˆæ¸—é€ç‡
- en: flow simulation may be applied to calibrate (calculate the appropriate power
    for power law averaging)
  id: totrans-3282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµä½“æ¨¡æ‹Ÿå¯ä»¥åº”ç”¨äºæ ¡å‡†ï¼ˆè®¡ç®—å¹‚å¾‹å¹³å‡çš„é€‚å½“åŠŸç‡ï¼‰
- en: '**Precision** (classification accuracy metric)'
  id: totrans-3283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç²¾åº¦**ï¼ˆåˆ†ç±»å‡†ç¡®åº¦æŒ‡æ ‡ï¼‰'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a categorical classification
    prediction model measure of accuracy, a single summary metric for each \(k\) category
    from the confusion matrix.'
  id: totrans-3284
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ä¸ªåˆ†ç±»é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®åº¦åº¦é‡ï¼Œæ··æ·†çŸ©é˜µä¸­æ¯ä¸ª \(k\) ç±»åˆ«çš„å•ä¸ªæ±‡æ€»æŒ‡æ ‡ã€‚'
- en: the ratio of true positives divided by all positives, true positives + false
    positives
  id: totrans-3285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çœŸæ­£é˜³æ€§ä¸æ‰€æœ‰é˜³æ€§çš„æ¯”ç‡ï¼ŒçœŸæ­£é˜³æ€§ + å‡é˜³æ€§
- en: \[ Precision_k = \frac{ n_{k,\text{true positives}} }{ n_{k,\text{true positives}}
    + n_{k,\text{false positives}}} = \frac{ n_{k,\text{true positives}} }{ n_{k,
    \text{all positives}} } \]
  id: totrans-3286
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Precision_k = \frac{ n_{k,\text{true positives}} }{ n_{k,\text{true positives}}
    + n_{k,\text{false positives}}} = \frac{ n_{k,\text{true positives}} }{ n_{k,
    \text{all positives}} } \]
- en: '**Prediction Interval**'
  id: totrans-3287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹åŒºé—´**'
- en: '[Linear Regression](MachineLearning_linear_regression.html): the uncertainty
    in the next prediction represented as a range, lower and upper bound, based on
    a specified probability interval known as the confidence level.'
  id: totrans-3288
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šä¸‹ä¸€æ¬¡é¢„æµ‹çš„ä¸ç¡®å®šæ€§è¡¨ç¤ºä¸ºä¸€ä¸ªèŒƒå›´ï¼Œä¸‹é™å’Œä¸Šé™ï¼ŒåŸºäºä¸€ä¸ªç§°ä¸ºç½®ä¿¡æ°´å¹³çš„æŒ‡å®šæ¦‚ç‡åŒºé—´ã€‚'
- en: We communicate confidence intervals like this,
  id: totrans-3289
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿™æ ·ä¼ è¾¾ç½®ä¿¡åŒºé—´ï¼Œ
- en: there is a 95% probability (or 19 times out of 20) that the true reservoir NTG
    is between 13% and 17%, given, predictor feature values, \(ğ‘‹_1=ğ‘¥_1,\ldots,ğ‘‹_ğ‘š=ğ‘¥_ğ‘š\).
  id: totrans-3290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»™å®šé¢„æµ‹ç‰¹å¾å€¼ï¼Œ\(ğ‘‹_1=ğ‘¥_1,\ldots,ğ‘‹_ğ‘š=ğ‘¥_ğ‘š\)ï¼Œæœ‰95%çš„æ¦‚ç‡ï¼ˆæˆ–20æ¬¡ä¸­çš„19æ¬¡ï¼‰è¡¨æ˜çœŸæ­£å‚¨å±‚NTGåœ¨13%åˆ°17%ä¹‹é—´ã€‚
- en: Is the uncertainty in our prediction, for prediction intervals we integrate,
  id: totrans-3291
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œå¯¹äºé¢„æµ‹åŒºé—´ï¼Œæˆ‘ä»¬è¿›è¡Œç§¯åˆ†ï¼Œ
- en: uncertainty in the model \(ğ¸{\hat{ğ‘Œ}|ğ‘‹=ğ‘¥}\)
  id: totrans-3292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹ \(ğ¸{\hat{ğ‘Œ}|ğ‘‹=ğ‘¥}\) çš„ä¸ç¡®å®šæ€§
- en: error in the model, conditional distribution \(\hat{Y}|X=x\)
  id: totrans-3293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„è¯¯å·®ï¼Œæ¡ä»¶åˆ†å¸ƒ \(\hat{Y}|X=x\)
- en: '**Prediction, Predictive Statistics**'
  id: totrans-3294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹ï¼Œé¢„æµ‹ç»Ÿè®¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): estimate the next
    sample(s) given assumptions about or a model of the population'
  id: totrans-3295
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ ¹æ®å¯¹æ€»ä½“æˆ–æ€»ä½“æ¨¡å‹çš„å‡è®¾æ¥ä¼°è®¡ä¸‹ä¸€ä¸ªæ ·æœ¬ï¼ˆæ ·æœ¬ï¼‰'
- en: for example, given our model of the reservoir, predict the next well (pre-drill
    assessment) sample, e.g., porosity, permeability, production rate, etc.
  id: totrans-3296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œç»™å®šæˆ‘ä»¬çš„å‚¨å±‚æ¨¡å‹ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªäº•ï¼ˆé¢„é’»è¯„ä¼°ï¼‰æ ·æœ¬ï¼Œä¾‹å¦‚ï¼Œå­”éš™ç‡ã€æ¸—é€ç‡ã€äº§é‡ç­‰ã€‚
- en: '**Predictor Feature**'
  id: totrans-3297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the input feature
    for a predictive machine learning model. We can generalize a predictive machine
    learning model as,'
  id: totrans-3298
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å…¥ç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹æ¦‚æ‹¬ä¸ºï¼Œ'
- en: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
  id: totrans-3299
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
- en: where the response feature is \(y\), the predictor features are \(x_1,\ldots,x_m\),
    and \(\epsilon\) is model error
  id: totrans-3300
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­å“åº”ç‰¹å¾æ˜¯ \(y\)ï¼Œé¢„æµ‹ç‰¹å¾æ˜¯ \(x_1,\ldots,x_m\)ï¼Œè€Œ \(\epsilon\) æ˜¯æ¨¡å‹è¯¯å·®
- en: traditional statistics uses the term independent variable
  id: totrans-3301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿç»Ÿè®¡å­¦ä½¿ç”¨ç‹¬ç«‹å˜é‡çš„æœ¯è¯­
- en: '**Predictor Feature Space**'
  id: totrans-3302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹ç‰¹å¾ç©ºé—´**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): refers to the predictor
    features and does not include the response feature(s), i.e.,'
  id: totrans-3303
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šæŒ‡çš„æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œä¸åŒ…æ‹¬å“åº”ç‰¹å¾ï¼Œå³ï¼Œ'
- en: all possible combinations of predictor features for which we need to make predictions
  id: totrans-3304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åšå‡ºé¢„æµ‹çš„æ‰€æœ‰é¢„æµ‹ç‰¹å¾çš„å¯èƒ½ç»„åˆ
- en: may be referred to as predictor feature space.
  id: totrans-3305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½è¢«ç§°ä¸ºé¢„æµ‹ç‰¹å¾ç©ºé—´ã€‚
- en: Typically, we train and test our machinesâ€™ predictions over the predictor feature
    space.
  id: totrans-3306
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šè®­ç»ƒå’Œæµ‹è¯•æˆ‘ä»¬æœºå™¨çš„é¢„æµ‹ã€‚
- en: the space is typically a hypercuboid with each axis representing a predictor
    feature and extending from the minimum to maximum, over the range of each predictor
    feature
  id: totrans-3307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥ç©ºé—´é€šå¸¸æ˜¯è¶…ç«‹æ–¹ä½“ï¼Œæ¯ä¸ªè½´ä»£è¡¨ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œä»æ¯ä¸ªé¢„æµ‹ç‰¹å¾çš„æœ€å°å€¼å»¶ä¼¸åˆ°æœ€å¤§å€¼
- en: more complicated shapes of predictor feature space are possible, e.g., we could
    mask or remove subsets with poor data coverage.
  id: totrans-3308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½å­˜åœ¨æ›´å¤æ‚çš„é¢„æµ‹ç‰¹å¾ç©ºé—´å½¢çŠ¶ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å±è”½æˆ–ç§»é™¤æ•°æ®è¦†ç›–è¾ƒå·®çš„å­é›†ã€‚
- en: '**Primary Data**'
  id: totrans-3309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸå§‹æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data samples for
    the feature of interest, the target feature for building a model, for example,'
  id: totrans-3310
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ„Ÿå…´è¶£ç‰¹å¾çš„æ•°æ®æ ·æœ¬ï¼Œç”¨äºæ„å»ºæ¨¡å‹çš„ç›®æ ‡ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: porosity measures from cores and logs used to build a full 3D porosity model.
    Any samples of porosity are the primary data
  id: totrans-3311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»å²©å¿ƒå’Œæµ‹äº•æ•°æ®ä¸­æµ‹å¾—çš„å­”éš™ç‡ï¼Œç”¨äºæ„å»ºå®Œæ•´çš„3Då­”éš™ç‡æ¨¡å‹ã€‚ä»»ä½•å­”éš™ç‡æ ·æœ¬éƒ½æ˜¯åŸå§‹æ•°æ®
- en: as opposed to secondary feature, e.g., if we have facies data to help predict
    porosity, the facies data are secondary data
  id: totrans-3312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸æ¬¡çº§ç‰¹å¾ç›¸åï¼Œä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰å²©æ€§æ•°æ®æ¥å¸®åŠ©é¢„æµ‹å­”éš™ç‡ï¼Œåˆ™å²©æ€§æ•°æ®æ˜¯æ¬¡çº§æ•°æ®
- en: '**Principal Component Analysis**'
  id: totrans-3313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸»æˆåˆ†åˆ†æ**'
- en: '[Principal Component Analysis](MachineLearning_PCA.html): one of a variety
    of methods for dimensional reduction, transform the data to a lower dimension'
  id: totrans-3314
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸»æˆåˆ†åˆ†æ](MachineLearning_PCA.html)ï¼šé™ç»´çš„å¤šç§æ–¹æ³•ä¹‹ä¸€ï¼Œå°†æ•°æ®è½¬æ¢åˆ°ä½ç»´'
- en: given features, \(ğ‘‹_1,\dots,ğ‘‹_ğ‘š\) we would require \({m \choose 2}=\frac{ğ‘š \cdot
    (ğ‘šâˆ’1)}{2}\) scatter plots to visualize just the two-dimensional scatter plots.
  id: totrans-3315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç»™å®šçš„ç‰¹å¾ \(ğ‘‹_1,\dots,ğ‘‹_ğ‘š\)ï¼Œæˆ‘ä»¬éœ€è¦ \({m \choose 2}=\frac{ğ‘š \cdot (ğ‘šâˆ’1)}{2}\) ä¸ªæ•£ç‚¹å›¾æ¥å¯è§†åŒ–äºŒç»´æ•£ç‚¹å›¾ã€‚
- en: once we have 4 or more variables understanding our data gets very hard.
  id: totrans-3316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰4ä¸ªæˆ–æ›´å¤šå˜é‡ï¼Œç†è§£æ•°æ®å°±å˜å¾—éå¸¸å›°éš¾ã€‚
- en: recall the curse of dimensionality, impact inference, modeling and visualization.
  id: totrans-3317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å¿†ç»´åº¦è¯…å’’ï¼Œå½±å“æ¨ç†ã€å»ºæ¨¡å’Œå¯è§†åŒ–ã€‚
- en: One solution, is to find a good lower dimensional, \(ğ‘\), representation of
    the original dimensions \(ğ‘š\)
  id: totrans-3318
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯æ‰¾åˆ°ä¸€ä¸ªå¥½çš„ä½ç»´ \(ğ‘\) è¡¨ç¤ºï¼Œä»¥è¡¨ç¤ºåŸå§‹ç»´åº¦ \(ğ‘š\)
- en: 'Benefits of Working in a Reduced Dimensional Representation:'
  id: totrans-3319
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é™ç»´è¡¨ç¤ºä¸­å·¥ä½œçš„å¥½å¤„ï¼š
- en: data storage / Computational Time
  id: totrans-3320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•°æ®å­˜å‚¨/è®¡ç®—æ—¶é—´
- en: easier visualization
  id: totrans-3321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ›´å®¹æ˜“å¯è§†åŒ–
- en: also takes care of multicollinearity
  id: totrans-3322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿˜è¦æ³¨æ„å¤šé‡å…±çº¿æ€§
- en: Salient points of principal component analysis,
  id: totrans-3323
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»æˆåˆ†åˆ†æçš„ä¸»è¦è§‚ç‚¹ï¼Œ
- en: '*orthogonal transformation* - convert a set of observations into a set of linearly
    uncorrelated variables known as principal components, the transformation retains
    pairwise distance, i.e., is a rotation'
  id: totrans-3324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ­£äº¤å˜æ¢* - å°†ä¸€ç»„è§‚æµ‹å€¼è½¬æ¢ä¸ºä¸€ç»„çº¿æ€§ä¸ç›¸å…³çš„å˜é‡ï¼Œç§°ä¸ºä¸»æˆåˆ†ï¼Œè¿™ç§å˜æ¢ä¿ç•™äº†æˆå¯¹è·ç¦»ï¼Œå³æ˜¯ä¸€ç§æ—‹è½¬'
- en: '*number of principal components (\(k\)) available* - is minâ¡(\(ğ‘›âˆ’1,ğ‘š\)), limited
    by the variables/features, \(ğ‘š\), and the number of data'
  id: totrans-3325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯ç”¨çš„ä¸»æˆåˆ†æ•° (\(k\)) - æ˜¯ minâ¡(\(ğ‘›âˆ’1,ğ‘š\))ï¼Œå—å˜é‡/ç‰¹å¾ \(ğ‘š\) å’Œæ•°æ®æ•°é‡çš„é™åˆ¶'
- en: Components are ordered,
  id: totrans-3326
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„ä»¶æ˜¯æœ‰åºçš„ï¼Œ
- en: first component describes the larges possible variance / accounts for as much
    variability as possible
  id: totrans-3327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æˆåˆ†æè¿°äº†æœ€å¤§çš„å¯èƒ½æ–¹å·® / å°½å¯èƒ½è§£é‡Šäº†æœ€å¤§çš„å¯å˜æ€§
- en: next component describes the largest possible remaining variance
  id: totrans-3328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªæˆåˆ†æè¿°äº†å¯èƒ½å‰©ä½™çš„æœ€å¤§æ–¹å·®
- en: up to the maximum number of principal components
  id: totrans-3329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´åˆ°æœ€å¤§ä¸»æˆåˆ†æ•°
- en: Eigenvalues and eigenvectors-based,
  id: totrans-3330
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œ
- en: Calculate the data covariance matrix, the pairwise covariance for the combinatorial
    of features and then calculate the eigenvectors and eigenvalues from the covariance
    matrix,
  id: totrans-3331
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—æ•°æ®åæ–¹å·®çŸ©é˜µï¼Œç‰¹å¾å¯¹çš„åæ–¹å·®ï¼Œç„¶åä»åæ–¹å·®çŸ©é˜µä¸­è®¡ç®—ç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼ï¼Œ
- en: the eigenvalues are the variance explained for each component.
  id: totrans-3332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å€¼æ˜¯æ¯ä¸ªæˆåˆ†çš„è§£é‡Šæ–¹å·®ã€‚
- en: the eigenvectors of the data covariance matrix are the principal components.
  id: totrans-3333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å‘é‡æ˜¯ä¸»æˆåˆ†ã€‚
- en: '**Probability Density Function** (PDF)'
  id: totrans-3334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡å¯†åº¦å‡½æ•°** (PDF)'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): a representation
    of a statistical distribution with a function, \(f(x)\), of probability density
    over the range of all possible feature values, \(x\). These are the concepts for
    PDFs,'
  id: totrans-3335
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šä½¿ç”¨æ¦‚ç‡å¯†åº¦å‡½æ•° \(f(x)\) çš„å‡½æ•° \(f(x)\)
    è¡¨ç¤ºç»Ÿè®¡åˆ†å¸ƒï¼Œè¯¥å‡½æ•°åœ¨æ‰€æœ‰å¯èƒ½çš„ç‰¹å¾å€¼èŒƒå›´ \(x\) ä¸Šï¼Œè¿™äº›æ˜¯PDFçš„æ¦‚å¿µï¼Œ'
- en: non-negativity constraint, the density cannot be negative,
  id: totrans-3336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éè´Ÿæ€§çº¦æŸï¼Œå¯†åº¦ä¸èƒ½ä¸ºè´Ÿï¼Œ
- en: \[ 0.0 \le f(x) \]
  id: totrans-3337
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0.0 \le f(x) \]
- en: for continuous features the density may be > 1.0, because density is a measure
    of likelihood and not of probability
  id: totrans-3338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºè¿ç»­ç‰¹å¾ï¼Œå¯†åº¦å¯èƒ½å¤§äº1.0ï¼Œå› ä¸ºå¯†åº¦æ˜¯ä¼¼ç„¶åº¦çš„åº¦é‡ï¼Œè€Œä¸æ˜¯æ¦‚ç‡çš„åº¦é‡
- en: integrate density over a range of \(x\) to calculate probability,
  id: totrans-3339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨\(x\)çš„èŒƒå›´å†…å¯¹å¯†åº¦è¿›è¡Œç§¯åˆ†ä»¥è®¡ç®—æ¦‚ç‡ï¼Œ
- en: \[ 0 \le \int_a^b f(x) dx = P(a \le x \le b) \le 1.0 \]
  id: totrans-3340
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0 \le \int_a^b f(x) dx = P(a \le x \le b) \le 1.0 \]
- en: probability closure, the sum of the area under the PDF curve is equal to 1.0,
  id: totrans-3341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¦‚ç‡å°é—­ï¼ŒPDFæ›²çº¿ä¸‹é¢ç§¯çš„æ€»å’Œç­‰äº1.0ï¼Œ
- en: \[ \int_{-infty}^{\infty} f(x) dx = 1.0 \]
  id: totrans-3342
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \int_{-infty}^{\infty} f(x) dx = 1.0 \]
- en: Nonparametric PDFs are calculated with kernels (usual a small Gaussian distribution)
    that is summed over all data; therefore, there is an implicitly scale (smoothness)
    parameter when calculating a PDF.
  id: totrans-3343
  prefs: []
  type: TYPE_NORMAL
  zh: éå‚æ•°æ¦‚ç‡å¯†åº¦å‡½æ•°é€šè¿‡æ ¸å‡½æ•°ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªå°çš„é«˜æ–¯åˆ†å¸ƒï¼‰è®¡ç®—ï¼Œè¯¥æ ¸å‡½æ•°å¯¹æ‰€æœ‰æ•°æ®è¿›è¡Œæ±‚å’Œï¼›å› æ­¤ï¼Œåœ¨è®¡ç®—æ¦‚ç‡å¯†åº¦å‡½æ•°æ—¶å­˜åœ¨ä¸€ä¸ªéšå«çš„å°ºåº¦ï¼ˆå¹³æ»‘åº¦ï¼‰å‚æ•°ã€‚
- en: To large of kernels will smooth out important information about the univariate
    distribution
  id: totrans-3344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¸å‡½æ•°å¤ªå¤§å°†å¹³æ»‘æ‰å…³äºå•å˜é‡åˆ†å¸ƒçš„é‡è¦ä¿¡æ¯
- en: Too narrow will result in an overly noisy PDF that is difficult to interpret.
  id: totrans-3345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡çª„ä¼šå¯¼è‡´è¿‡äºå˜ˆæ‚çš„PDFæ–‡ä»¶ï¼Œéš¾ä»¥è§£è¯»ã€‚
- en: This is analogous to the choice of bin size for a histogram or normalized histogram.
  id: totrans-3346
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç±»ä¼¼äºé€‰æ‹©ç›´æ–¹å›¾æˆ–å½’ä¸€åŒ–ç›´æ–¹å›¾çš„ç®±å¤§å°ã€‚
- en: Parametric PDFs are possible but require model fitting to the data, the steps
    are,
  id: totrans-3347
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°æ¦‚ç‡å¯†åº¦å‡½æ•°æ˜¯å¯èƒ½çš„ï¼Œä½†éœ€è¦å°†æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®ï¼Œæ­¥éª¤åŒ…æ‹¬ï¼Œ
- en: Select a parametric distribution, e.g., Gaussian, log normal, etc.
  id: totrans-3348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªå‚æ•°åˆ†å¸ƒï¼Œä¾‹å¦‚é«˜æ–¯åˆ†å¸ƒã€å¯¹æ•°æ­£æ€åˆ†å¸ƒç­‰ã€‚
- en: Calculate the parameters for the parametric distribution based on the available
    data, by methods such as least squares or maximum likelihood.
  id: totrans-3349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®å¯ç”¨æ•°æ®è®¡ç®—å‚æ•°åˆ†å¸ƒçš„å‚æ•°ï¼Œä½¿ç”¨å¦‚æœ€å°äºŒä¹˜æ³•æˆ–æœ€å¤§ä¼¼ç„¶æ³•ç­‰æ–¹æ³•ã€‚
- en: '**Probability Non-negativity, Normalization**'
  id: totrans-3350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡éè´Ÿæ€§ï¼Œå½’ä¸€åŒ–**'
- en: 'Probability Concepts: fundamental constraints on probability including,'
  id: totrans-3351
  prefs: []
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ¦‚å¿µï¼šæ¦‚ç‡çš„åŸºæœ¬çº¦æŸï¼ŒåŒ…æ‹¬ï¼Œ
- en: Bounded, \(0.0 \le P(A) \le 1.0\)
  id: totrans-3352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ‰ç•Œï¼Œ\(0.0 \le P(A) \le 1.0\)
- en: Closure, \(P(\Omega) = 1.0\)
  id: totrans-3353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°é—­ï¼Œ\(P(\Omega) = 1.0\)
- en: Null Sets, \(P(\emptyset) = 0.0\)
  id: totrans-3354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç©ºé›†ï¼Œ\(P(\emptyset) = 0.0\)
- en: '**Probability of Acceptance** (MCMC)'
  id: totrans-3355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¥å—æ¦‚ç‡** (MCMC)'
- en: '[Bayesian Linear Regression](MachineLearning_Bayesian_linear_regression.html):
    applied in a rejection sampler as the likelihood of a candidate sample being added
    to the sample.'
  id: totrans-3356
  prefs: []
  type: TYPE_NORMAL
  zh: '[è´å¶æ–¯çº¿æ€§å›å½’](MachineLearning_Bayesian_linear_regression.html)ï¼šåœ¨æ‹’ç»é‡‡æ ·ä¸­ä½œä¸ºå€™é€‰æ ·æœ¬è¢«æ·»åŠ åˆ°æ ·æœ¬ä¸­çš„ä¼¼ç„¶ã€‚'
- en: conditional acceptance is performed by Monte Carlo simulation,
  id: totrans-3357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿè¿›è¡Œæ¡ä»¶æ¥å—ï¼Œ
- en: sequentially sampling from conditional distributions
  id: totrans-3358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾æ¬¡ä»æ¡ä»¶åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·
- en: The acceptance rule is,
  id: totrans-3359
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥å—è§„åˆ™æ˜¯ï¼Œ
- en: if \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \ge 1\), accept â€“ accept
  id: totrans-3360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœ \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \ge 1\)ï¼Œæ¥å— â€“ æ¥å—
- en: if \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \lt 1\), conditionally accept, draw \(ğ‘ âˆ¼ U[0,1]\), and accept
    if \(ğ‘ \le ğ›¼\)
  id: totrans-3361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœ \(ğ‘ƒ(ğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘¡) \lt 1\)ï¼Œæ¡ä»¶æ¥å—ï¼ŒæŠ½å– \(ğ‘ âˆ¼ U[0,1]\)ï¼Œå¦‚æœ \(ğ‘ \le ğ›¼\) åˆ™æ¥å—
- en: '**Probability Operators**'
  id: totrans-3362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡ç®—å­**'
- en: '[Probability Concepts](MachineLearning_probability.html): common probability
    operators that are essential to working with probability and uncertainty problems,'
  id: totrans-3363
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šä¸æ¦‚ç‡å’Œä¸ç¡®å®šæ€§é—®é¢˜å·¥ä½œç›¸å…³çš„å¸¸è§æ¦‚ç‡ç®—å­ï¼Œ'
- en: '*Union of Events* - the union of outcomes, the probability of \(A\) or \(B\)
    is calculated with the probability addition rule,'
  id: totrans-3364
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº‹ä»¶å¹¶é›†* - ç»“æœçš„å¹¶é›†ï¼Œ\(A\) æˆ– \(B\) çš„æ¦‚ç‡é€šè¿‡æ¦‚ç‡åŠ æ³•è§„åˆ™è®¡ç®—ï¼Œ'
- en: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
  id: totrans-3365
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
- en: '*Intersection of Events* - the intersection of outcomes, the probability of
    \(A\) and \(B\) is represented as,'
  id: totrans-3366
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº‹ä»¶äº¤é›†* - ç»“æœçš„äº¤é›†ï¼Œ\(A\) å’Œ \(B\) çš„æ¦‚ç‡è¡¨ç¤ºä¸ºï¼Œ'
- en: \[ P(A \cap B) = P(A,B) \]
  id: totrans-3367
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) \]
- en: only under the assumption of independence of \(A\) and \(B\) can it be calculate
    from the probabilities of \(A\) and \(B\) as,
  id: totrans-3368
  prefs: []
  type: TYPE_NORMAL
  zh: åªæœ‰åœ¨ \(A\) å’Œ \(B\) ç‹¬ç«‹çš„å‰æä¸‹ï¼Œæ‰èƒ½ä» \(A\) å’Œ \(B\) çš„æ¦‚ç‡ä¸­è®¡ç®—å‡ºå®ƒï¼Œ
- en: \[ P(A,B) = P(A) \cdot P(B) \]
  id: totrans-3369
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = P(A) \cdot P(B) \]
- en: if there is dependence between \(A\) and \(B\) then we need the conditional
    probability, \(P(A|B)\) instead of the marginal, \(P(A)\),
  id: totrans-3370
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ \(A\) å’Œ \(B\) ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦æ¡ä»¶æ¦‚ç‡ \(P(A|B)\)ï¼Œè€Œä¸æ˜¯è¾¹ç¼˜æ¦‚ç‡ \(P(A)\)ï¼Œ
- en: \[ P(A,B) = P(A|B) \cdot P(B) \]
  id: totrans-3371
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A,B) = P(A|B) \cdot P(B) \]
- en: '*Complimentary Events* - is the NOT operator for probability, if we define
    \(A\) then \(A\) compliment, \(A^c\) is not \(A\) and we have this resulting closure
    relationship,'
  id: totrans-3372
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº’è¡¥äº‹ä»¶* - æ˜¯æ¦‚ç‡ä¸­çš„ NOT æ“ä½œç¬¦ï¼Œå¦‚æœæˆ‘ä»¬å®šä¹‰ \(A\)ï¼Œé‚£ä¹ˆ \(A\) çš„è¡¥é›† \(A^c\) å°±ä¸æ˜¯ \(A\)ï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰è¿™ä¸ªç»“æœé—­åŒ…å…³ç³»ï¼Œ'
- en: \[ P(A) + P(A^c) = 1.0 \]
  id: totrans-3373
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) + P(A^c) = 1.0 \]
- en: complimentary events may be considered for beyond univariate problems, for example
    consider this bivariate closure,
  id: totrans-3374
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¶…è¶Šå•å˜é‡é—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘äº’è¡¥äº‹ä»¶ï¼Œä¾‹å¦‚è€ƒè™‘è¿™ä¸ªåŒå˜é‡é—­åŒ…ï¼Œ
- en: \[ P(A|B) + P(A^c|B) = 1.0 \]
  id: totrans-3375
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) + P(A^c|B) = 1.0 \]
- en: Note, the given term must be the same.
  id: totrans-3376
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç»™å®šçš„æœ¯è¯­å¿…é¡»ç›¸åŒã€‚
- en: '*Mutually Exclusive Events* - the events that do not intersect or do not have
    any common outcomes. We represent this with set notation as,'
  id: totrans-3377
  prefs: []
  type: TYPE_NORMAL
  zh: '*äº’æ–¥äº‹ä»¶* - ä¸ç›¸äº¤æˆ–æ²¡æœ‰å…±åŒç»“æœçš„äº‹ä»¶ã€‚æˆ‘ä»¬ç”¨é›†åˆè¡¨ç¤ºæ³•è¡¨ç¤ºè¿™ä¸€ç‚¹ï¼Œ'
- en: '\[ \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
  id: totrans-3378
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \{x: x \in A \text{ and } x \in B \} = \emptyset \]'
- en: and the joint probability of \(A\) and \(B\) as,
  id: totrans-3379
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠ \(A\) å’Œ \(B\) çš„è”åˆæ¦‚ç‡ä¸ºï¼Œ
- en: \[ P(A \cap B) = P(A,B) = 0 \]
  id: totrans-3380
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A,B) = 0 \]
- en: '**Probability Perspectives**'
  id: totrans-3381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¦‚ç‡è§†è§’**'
- en: '[Probability Concepts](MachineLearning_probability.html): the 3 primary perspectives
    for calculating probability:'
  id: totrans-3382
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šè®¡ç®—æ¦‚ç‡çš„ 3 ä¸ªä¸»è¦è§†è§’ï¼š'
- en: '*Long-term frequencies* - probability as ratio of outcomes, requires repeated
    observations of an experiment. The basis for *frequentist probability*.'
  id: totrans-3383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*é•¿æœŸé¢‘ç‡* - æ¦‚ç‡ä½œä¸ºç»“æœçš„æ¯”ç‡ï¼Œéœ€è¦é‡å¤è§‚å¯Ÿå®éªŒã€‚è¿™æ˜¯ *é¢‘ç‡ä¸»ä¹‰æ¦‚ç‡* çš„åŸºç¡€ã€‚'
- en: '*Physical tendencies or propensities* - probability from knowledge about or
    modeling the system, e.g., we could know the probability of a heads outcome from
    a coin toss without the experiment.'
  id: totrans-3384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç‰©ç†è¶‹åŠ¿æˆ–å€¾å‘* - ä»å¯¹ç³»ç»Ÿäº†è§£æˆ–å»ºæ¨¡ä¸­å¾—åˆ°çš„æ¦‚ç‡ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“æŠ›ç¡¬å¸å¾—åˆ°æ­£é¢çš„æ¦‚ç‡ï¼Œè€Œä¸éœ€è¦å®éªŒã€‚'
- en: '*Degrees of belief* - reflect our certainty about a result, very flexible,
    assign probability to anything, and updating with new information. The basis for
    *Bayesian probability*.'
  id: totrans-3385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¿¡å¿µç¨‹åº¦* - åæ˜ æˆ‘ä»¬å¯¹ç»“æœçš„ç¡®å®šæ€§ï¼Œéå¸¸çµæ´»ï¼Œå¯ä»¥å¯¹ä»»ä½•äº‹ç‰©åˆ†é…æ¦‚ç‡ï¼Œå¹¶éšç€æ–°ä¿¡æ¯çš„æ›´æ–°ã€‚è¿™æ˜¯ *è´å¶æ–¯æ¦‚ç‡* çš„åŸºç¡€ã€‚'
- en: '**Prototype** (clustering)'
  id: totrans-3386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸå‹**ï¼ˆèšç±»ï¼‰'
- en: 'Cluster Analysis: represent the sample data with set of points in the feature
    space.'
  id: totrans-3387
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šç”¨ç‰¹å¾ç©ºé—´ä¸­çš„ç‚¹é›†è¡¨ç¤ºæ ·æœ¬æ•°æ®ã€‚
- en: prototypes are typically not actual samples
  id: totrans-3388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸå‹é€šå¸¸æ˜¯å®é™…æ ·æœ¬
- en: sample data are often assigned to the nearest (Euclidean) distance prototype
  id: totrans-3389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ•°æ®é€šå¸¸è¢«åˆ†é…åˆ°æœ€è¿‘çš„ï¼ˆæ¬§å‡ é‡Œå¾—ï¼‰è·ç¦»åŸå‹
- en: '**Qualitative Features**'
  id: totrans-3390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®šæ€§ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): information about
    quantities that you cannot directly measure, require interpretation of measurement,
    and are described with words (not numbers), for example,'
  id: totrans-3391
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå…³äºæ— æ³•ç›´æ¥æµ‹é‡çš„æ•°é‡ä¿¡æ¯ï¼Œéœ€è¦è§£é‡Šæµ‹é‡ï¼Œå¹¶ç”¨æ–‡å­—ï¼ˆè€Œä¸æ˜¯æ•°å­—ï¼‰æè¿°ï¼Œä¾‹å¦‚ï¼Œ'
- en: rock type = sandstone
  id: totrans-3392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å²©çŸ³ç±»å‹ = ç ‚å²©
- en: zonation = bornite-chalcopyrite-gold higher grade copper zone
  id: totrans-3393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸¦çŠ¶åˆ†å¸ƒ = é’´é“œçŸ¿-é»„é“œçŸ¿-é‡‘ é«˜çº§é“œçŸ¿å¸¦
- en: '**Quantitative Features**'
  id: totrans-3394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®šé‡ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): features that can
    be measured and represented by numbers, for example,'
  id: totrans-3395
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå¯ä»¥æµ‹é‡å¹¶ç”±æ•°å­—è¡¨ç¤ºçš„ç‰¹å¾ï¼Œä¾‹å¦‚ï¼Œ'
- en: age = 10 Ma (millions of years)
  id: totrans-3396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹´é¾„ = 10 Maï¼ˆç™¾ä¸‡å¹´ï¼‰
- en: porosity = 0.134 (fraction of volume is void space)
  id: totrans-3397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ = 0.134ï¼ˆä½“ç§¯ä¸­ç©ºéš™çš„åˆ†æ•°ï¼‰
- en: saturation = 80.5% (volume percentage)
  id: totrans-3398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¥±å’Œåº¦ = 80.5%ï¼ˆä½“ç§¯ç™¾åˆ†æ¯”ï¼‰
- en: Like *qualitative features*, there is often the requirement for interpretation,
    for example, total porosity may be measured but should be converted to effective
    porosity through interpretation or a model
  id: totrans-3399
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ *å®šæ€§ç‰¹å¾* ä¸€æ ·ï¼Œé€šå¸¸éœ€è¦è§£é‡Šï¼Œä¾‹å¦‚ï¼Œæ€»å­”éš™ç‡å¯ä»¥æµ‹é‡ï¼Œä½†åº”é€šè¿‡è§£é‡Šæˆ–æ¨¡å‹è½¬æ¢ä¸ºæœ‰æ•ˆå­”éš™ç‡
- en: '**\(r^2\)** (also coefficient of determination)'
  id: totrans-3400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**\(r^2\)**ï¼ˆä¹Ÿç§°ä¸ºç¡®å®šç³»æ•°ï¼‰'
- en: '[Linear Regression](MachineLearning_linear_regression.html): the proportion
    of variance explained by the model in linear regression'
  id: totrans-3401
  prefs: []
  type: TYPE_NORMAL
  zh: '[çº¿æ€§å›å½’](MachineLearning_linear_regression.html)ï¼šåœ¨çº¿æ€§å›å½’ä¸­æ¨¡å‹è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹'
- en: 'This works only for linear models, where:'
  id: totrans-3402
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªé€‚ç”¨äºçº¿æ€§æ¨¡å‹ï¼Œå…¶ä¸­ï¼š
- en: \[ \sigma^2_{tot} = \sigma^2_{reg} + \sigma^2_{res} \]
  id: totrans-3403
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma^2_{tot} = \sigma^2_{reg} + \sigma^2_{res} \]
- en: where \(\sigma^2_{tot}\) is variance of response feature training, \(y_i\),
    \(\sigma^2_{reg}\) is variance of the model predictions, \(\hat{y}_i\), and \(\sigma^2_{res}\)
    is the variance of the errors, \(\Delta y_i\).
  id: totrans-3404
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma^2_{tot}\) æ˜¯å“åº”ç‰¹å¾è®­ç»ƒçš„æ–¹å·®ï¼Œ\(y_i\)ï¼Œ\(\sigma^2_{reg}\) æ˜¯æ¨¡å‹é¢„æµ‹çš„æ–¹å·®ï¼Œ\(\hat{y}_i\)ï¼Œå’Œ
    \(\sigma^2_{res}\) æ˜¯è¯¯å·®çš„æ–¹å·®ï¼Œ\(\Delta y_i\)ã€‚
- en: for linear regression, \(r^2 = \left( \rho_{x,y} \right)^2\)
  id: totrans-3405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºçº¿æ€§å›å½’ï¼Œ\(r^2 = (\rho_{x,y})^2\)
- en: For nonlinear models this will not likely hold, then \(\frac{\sigma^2_{ğ‘Ÿğ‘’ğ‘”}}{\sigma^2_{ğ‘¡ğ‘œğ‘¡}}\)
    may exceed \([0,1]\), for our nonlinear models regression models we will use more
    robust measures, e.g. mean square error (MSE)
  id: totrans-3406
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºéçº¿æ€§æ¨¡å‹ï¼Œè¿™ä¸å¤ªå¯èƒ½æˆç«‹ï¼Œé‚£ä¹ˆ \(\frac{\sigma^2_{ğ‘Ÿğ‘’ğ‘”}}{\sigma^2_{ğ‘¡ğ‘œğ‘¡}}\) å¯èƒ½è¶…è¿‡ \([0,1]\)ï¼Œå¯¹äºæˆ‘ä»¬çš„éçº¿æ€§å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ›´ç¨³å¥çš„åº¦é‡ï¼Œä¾‹å¦‚å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
- en: '**Random Forest**'
  id: totrans-3407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éšæœºæ£®æ—**'
- en: '[Bagging Tree and Random Forest](MachineLearning_ensemble_trees.html): a ensemble
    prediction model that is based on the standard bagging approach, specifically,'
  id: totrans-3408
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¢‹è£…æ ‘å’Œéšæœºæ£®æ—](MachineLearning_ensemble_trees.html)ï¼šåŸºäºæ ‡å‡†è¢‹è£…æ–¹æ³•çš„é›†æˆé¢„æµ‹æ¨¡å‹ï¼Œå…·ä½“æ¥è¯´ï¼Œ'
- en: with decision tree
  id: totrans-3409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å†³ç­–æ ‘
- en: with diversification of the individual trees by restricting each split to consider
    a \(p\) random subset of the \(ğ‘š\) available predictors
  id: totrans-3410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é™åˆ¶æ¯ä¸ªåˆ†å‰²åªè€ƒè™‘ \(ğ‘š\) ä¸ªå¯ç”¨é¢„æµ‹å› å­ä¸­çš„ \(p\) ä¸ªéšæœºå­é›†æ¥å¤šæ ·åŒ–å•ä¸ªæ ‘
- en: There are various methods to calculate \(p\) from \(m\) available features,
  id: totrans-3411
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å„ç§æ–¹æ³•å¯ä»¥ä» \(m\) ä¸ªå¯ç”¨ç‰¹å¾ä¸­è®¡ç®— \(p\)ï¼Œ
- en: \[ p = \sqrt{m} \]
  id: totrans-3412
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p = \sqrt{m} \]
- en: is common. Note, if \(p = m\) then random forest is tree bagging.
  id: totrans-3413
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯å¸¸è§çš„ã€‚æ³¨æ„ï¼Œå¦‚æœ \(p = m\)ï¼Œåˆ™éšæœºæ£®æ—æ˜¯æ ‘è¢‹æ³•ã€‚
- en: More comments on the benefit of ensemble model diversification,
  id: totrans-3414
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šå…³äºé›†æˆæ¨¡å‹å¤šæ ·åŒ–çš„ç›Šå¤„çš„è¯„è®ºï¼Œ
- en: the reduction in model variance by ensemble estimation, as represented by standard
    error in the mean,
  id: totrans-3415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é›†æˆä¼°è®¡é™ä½æ¨¡å‹æ–¹å·®ï¼Œå¦‚æ ‡å‡†è¯¯å·®æ‰€è¡¨ç¤ºçš„ï¼Œ
- en: \[ \sigma_{\overline{x}}^2 = fracc{\sigma_{s}^2}{n} \]
  id: totrans-3416
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\overline{x}}^2 = \frac{\sigma_{s}^2}{n} \]
- en: is under the assumption that the samples are uncorrelated. One issue with tree
    bagging is the trees in the ensemble may be highly correlated.
  id: totrans-3417
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æ ·æœ¬æ˜¯ä¸ç›¸å…³çš„ã€‚æ ‘è¢‹æ³•çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œé›†æˆä¸­çš„æ ‘å¯èƒ½é«˜åº¦ç›¸å…³ã€‚
- en: this occurs when there is a dominant predictor feature as it will always be
    applied to the top split(s), the result is all the trees in the ensemble are very
    similar (i.e. correlated)
  id: totrans-3418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“å­˜åœ¨ä¸€ä¸ªå ä¸»å¯¼åœ°ä½çš„é¢„æµ‹ç‰¹å¾æ—¶ï¼Œè¿™ç§æƒ…å†µä¼šå‘ç”Ÿï¼Œå› ä¸ºå®ƒå°†å§‹ç»ˆåº”ç”¨äºé¡¶éƒ¨åˆ†å‰²ï¼ˆsï¼‰ï¼Œç»“æœæ˜¯é›†æˆä¸­çš„æ‰€æœ‰æ ‘éƒ½éå¸¸ç›¸ä¼¼ï¼ˆå³ç›¸å…³ï¼‰
- en: with highly correlated trees, there is significantly less reduction in model
    variance with the ensemble
  id: totrans-3419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºé«˜åº¦ç›¸å…³çš„æ ‘ï¼Œé›†æˆä¸­çš„æ¨¡å‹æ–¹å·®å‡å°‘æ˜¾è‘—è¾ƒå°‘
- en: this forces each tree in the ensemble to evolve in dissimilar, decorrelated,
    manner
  id: totrans-3420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™è¿«ä½¿é›†æˆä¸­çš„æ¯æ£µæ ‘ä»¥ä¸åŒã€å»ç›¸å…³çš„æ¨¡å¼è¿›åŒ–
- en: '**Realization**'
  id: totrans-3421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®ç°**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): an outcome from
    a *random variable* or a joint outcome from a *random function*.'
  id: totrans-3422
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ¥è‡ªä¸€ä¸ª**éšæœºå˜é‡**çš„ç»“æœæˆ–æ¥è‡ªä¸€ä¸ª**éšæœºå‡½æ•°**çš„è”åˆç»“æœã€‚'
- en: an outcome from a random variable, \(X\), (or joint set of outcomes from a random
    function)
  id: totrans-3423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥è‡ªéšæœºå˜é‡ \(X\) çš„ç»“æœï¼ˆæˆ–æ¥è‡ªéšæœºå‡½æ•°çš„è”åˆç»“æœé›†ï¼‰
- en: represented with lower case, e.g., \(x\)
  id: totrans-3424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨å°å†™è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼Œ\(x\)
- en: for spatial settings it is common to include a location vector, \(\bf{u}\),
    to describe the location, e.g., \(x(\bf{u})\), as \(X(\bf{u})\)
  id: totrans-3425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºç©ºé—´è®¾ç½®ï¼Œé€šå¸¸åŒ…æ‹¬ä¸€ä¸ªä½ç½®å‘é‡ \(\bf{u}\)ï¼Œä»¥æè¿°ä½ç½®ï¼Œä¾‹å¦‚ï¼Œ\(x(\bf{u})\)ï¼Œä½œä¸º \(X(\bf{u})\)
- en: resulting from simulation, e.g., Monte Carlo simulation, sequential Gaussian
    simulation, a method to sample (jointly) from the RV (RF)
  id: totrans-3426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥è‡ªæ¨¡æ‹Ÿçš„ç»“æœï¼Œä¾‹å¦‚ï¼Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œé¡ºåºé«˜æ–¯æ¨¡æ‹Ÿï¼Œä» RVï¼ˆRFï¼‰ä¸­ï¼ˆå…±åŒï¼‰é‡‡æ ·çš„æ–¹æ³•
- en: in general, we assume all realizations are equiprobable, i.e., have the same
    probability of occurrence
  id: totrans-3427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬å‡è®¾æ‰€æœ‰å®ç°éƒ½æ˜¯ç­‰æ¦‚ç‡çš„ï¼Œå³å…·æœ‰ç›¸åŒçš„å‡ºç°æ¦‚ç‡
- en: '**Realizations** (uncertainty)'
  id: totrans-3428
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®ç°**ï¼ˆä¸ç¡®å®šæ€§ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): multiple spatial,
    subsurface models calculated by stochastic simulation by holding input parameters
    and model choices constant and only changing the random number seed'
  id: totrans-3429
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€šè¿‡ä¿æŒè¾“å…¥å‚æ•°å’Œæ¨¡å‹é€‰æ‹©ä¸å˜ï¼Œä»…æ”¹å˜éšæœºæ•°ç§å­ï¼Œé€šè¿‡éšæœºæ¨¡æ‹Ÿè®¡ç®—å‡ºçš„å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹ã€‚'
- en: these models represent spatial uncertainty
  id: totrans-3430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›æ¨¡å‹è¡¨ç¤ºç©ºé—´ä¸ç¡®å®šæ€§
- en: for example, hold the porosity mean constant and observe changes in porosity
    away from the wells over multiple realizations
  id: totrans-3431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¿æŒå­”éš™ç‡å¹³å‡å€¼ä¸å˜ï¼Œå¹¶è§‚å¯Ÿè¿œç¦»äº•çš„å¤šæ¬¡å®ç°ä¸­å­”éš™ç‡çš„å˜åŒ–
- en: '**Reasons to Learn Some Coding**'
  id: totrans-3432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å­¦ä¹ ä¸€äº›ç¼–ç çš„åŸå› **'
- en: '[Machine Learning Workflow Construction and Coding](MachineLearning_workflow_construction.html):
    Professor Pyrczâ€™s reasons for all scientists and engineers to learn some coding,'
  id: totrans-3433
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºä¸ç¼–ç ](MachineLearning_workflow_construction.html)ï¼šPyrczæ•™æˆè§£é‡Šäº†æ‰€æœ‰ç§‘å­¦å®¶å’Œå·¥ç¨‹å¸ˆå­¦ä¹ ä¸€äº›ç¼–ç çš„åŸå› ï¼Œ'
- en: '*Transparency* â€“ no compiler accepts hand waiving! Coding forces your logic
    to be uncovered for any other scientist or engineer to review.'
  id: totrans-3434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é€æ˜åº¦* â€“ æ²¡æœ‰ç¼–è¯‘å™¨ä¼šæ¥å—æŒ¥æ‰‹ï¼ç¼–ç è¿«ä½¿ä½ çš„é€»è¾‘è¢«æ­éœ²ï¼Œä»¥ä¾¿ä»»ä½•å…¶ä»–ç§‘å­¦å®¶æˆ–å·¥ç¨‹å¸ˆè¿›è¡Œå®¡æŸ¥ã€‚'
- en: '*Reproducibility* â€“ run it and get an answer, hand it over to a peer, they
    run it and they get the same answer. This is a principle of the scientific method.'
  id: totrans-3435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¯é‡å¤æ€§* â€“ è¿è¡Œå®ƒå¹¶å¾—åˆ°ç­”æ¡ˆï¼Œå°†å…¶äº¤ç»™åŒè¡Œï¼Œä»–ä»¬è¿è¡Œå®ƒå¹¶å¾—åˆ°ç›¸åŒçš„ç­”æ¡ˆã€‚è¿™æ˜¯ç§‘å­¦æ–¹æ³•çš„ä¸€ä¸ªåŸåˆ™ã€‚'
- en: '*Quantification* â€“ programs need numbers and drive us from qualitative to quantitative.
    Feed the program and discover new ways to look at the world.'
  id: totrans-3436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*é‡åŒ–* â€“ ç¨‹åºéœ€è¦æ•°å­—ï¼Œå¹¶æ¨åŠ¨æˆ‘ä»¬ä»å®šæ€§åˆ°å®šé‡ã€‚ç»™ç¨‹åºå–‚é£Ÿï¼Œå‘ç°æ–°çš„çœ‹å¾…ä¸–ç•Œçš„æ–¹å¼ã€‚'
- en: '*Open-source* â€“ leverage a world of brilliance. Check out packages, snippets
    and be amazed with what great minds have freely shared.'
  id: totrans-3437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¼€æº* â€“ åˆ©ç”¨ä¸–ç•Œä¸Šçš„æ™ºæ…§ã€‚æŸ¥çœ‹åŒ…ã€ç‰‡æ®µï¼Œå¹¶æƒŠå¹äºä¼Ÿå¤§æ€æƒ³è€…å…è´¹åˆ†äº«çš„å†…å®¹ã€‚'
- en: '*Break Down Barriers* â€“ donâ€™t throw it over the fence. Sit at the table with
    the developers and share more of your subject matter expertise for a better deployed
    product.'
  id: totrans-3438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ‰“ç ´å£å’* â€“ ä¸è¦æŠŠå®ƒæ‰”è¿‡æ …æ ã€‚å’Œå¼€å‘è€…ååœ¨ä¸€èµ·ï¼Œåˆ†äº«æ›´å¤šä½ çš„ä¸“ä¸šçŸ¥è¯†ï¼Œä»¥è·å¾—æ›´å¥½çš„éƒ¨ç½²äº§å“ã€‚'
- en: '*Deployment* â€“ share your code with others and multiply your impact. Performance
    metrics or altruism, your good work benefits many others.'
  id: totrans-3439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*éƒ¨ç½²* â€“ ä¸ä»–äººåˆ†äº«ä½ çš„ä»£ç ï¼Œæ‰©å¤§ä½ çš„å½±å“åŠ›ã€‚æ€§èƒ½æŒ‡æ ‡æˆ–åˆ©ä»–ä¸»ä¹‰ï¼Œä½ çš„å¥½å·¥ä½œä½¿è®¸å¤šäººå—ç›Šã€‚'
- en: '*Efficiency* â€“ minimize the boring parts of the job. Build a suite of scripts
    for automation of common tasks and spend more time doing science and engineering!'
  id: totrans-3440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ•ˆç‡* â€“ æœ€å°åŒ–å·¥ä½œä¸­æ— èŠçš„éƒ¨åˆ†ã€‚æ„å»ºä¸€å¥—è„šæœ¬æ¥è‡ªåŠ¨åŒ–å¸¸è§ä»»åŠ¡ï¼Œå¹¶èŠ±æ›´å¤šæ—¶é—´è¿›è¡Œç§‘å­¦å’Œå·¥ç¨‹ï¼'
- en: '*Always Time to Do it Again!* â€“ how many times did you only do it once? It
    probably takes 2-4 times as long to script and automate a workflow. Usually, worth
    it.'
  id: totrans-3441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ°¸è¿œéƒ½æœ‰æ—¶é—´å†åšä¸€æ¬¡!* â€“ ä½ åªåšäº†ä¸€æ¬¡å—ï¼Ÿè„šæœ¬å’Œè‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹å¯èƒ½éœ€è¦2-4å€çš„æ—¶é—´ã€‚é€šå¸¸ï¼Œè¿™æ˜¯å€¼å¾—çš„ã€‚'
- en: Be Like Us â€“ it will change you. Users feel limited, programmers truly harness
    the power of their applications and hardware.
  id: totrans-3442
  prefs: []
  type: TYPE_NORMAL
  zh: åƒæˆ‘ä»¬ä¸€æ · â€“ è¿™å°†æ”¹å˜ä½ ã€‚ç”¨æˆ·æ„Ÿåˆ°å—é™ï¼Œç¨‹åºå‘˜çœŸæ­£åˆ©ç”¨äº†ä»–ä»¬çš„åº”ç”¨ç¨‹åºå’Œç¡¬ä»¶çš„åŠ›é‡ã€‚
- en: '**Recall** (classification accuracy metric)'
  id: totrans-3443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¬å›ç‡**ï¼ˆåˆ†ç±»å‡†ç¡®ç‡æŒ‡æ ‡ï¼‰'
- en: '[Naive Bayes](MachineLearning_naive_Bayes.html): a categorical classification
    prediction model measure of accuracy, a single summary metric for each \(k\) category
    from the confusion matrix.'
  id: totrans-3444
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœ´ç´ è´å¶æ–¯](MachineLearning_naive_Bayes.html)ï¼šä¸€ä¸ªåˆ†ç±»é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®æ€§åº¦é‡ï¼Œæ··æ·†çŸ©é˜µä¸­æ¯ä¸ª \(k\) ç±»åˆ«çš„å•ä¸€æ±‡æ€»æŒ‡æ ‡ã€‚'
- en: the ratio of true positives divided by all cases of the category in the testing
    dataset
  id: totrans-3445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹è¯•æ•°æ®é›†ä¸­è¯¥ç±»åˆ«æ‰€æœ‰æ¡ˆä¾‹ä¸­çœŸå®æ­£ä¾‹ä¸æ‰€æœ‰æ¡ˆä¾‹çš„æ¯”ç‡
- en: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
  id: totrans-3446
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Recall_k = \frac{ n_{k, \text{true positives}} }{n_k} \]
- en: '**Recursive Feature Elimination**'
  id: totrans-3447
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é€’å½’ç‰¹å¾æ¶ˆé™¤**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a method works by
    recursively removing features and building a model with the remaining features.'
  id: totrans-3448
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’å](MachineLearning_feature_ranking.html)ï¼šè¯¥æ–¹æ³•é€šè¿‡é€’å½’ç§»é™¤ç‰¹å¾å¹¶ä½¿ç”¨å‰©ä½™ç‰¹å¾æ„å»ºæ¨¡å‹æ¥å·¥ä½œã€‚'
- en: build a model with all features, calculate a feature ranking metric, e.g., coefficient
    or feature importance, depending on which is available with the modeling method
  id: totrans-3449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ‰€æœ‰ç‰¹å¾æ„å»ºæ¨¡å‹ï¼Œè®¡ç®—ç‰¹å¾æ’åæŒ‡æ ‡ï¼Œä¾‹å¦‚ç³»æ•°æˆ–ç‰¹å¾é‡è¦æ€§ï¼Œå…·ä½“å–å†³äºå»ºæ¨¡æ–¹æ³•ä¸­å“ªäº›å¯ç”¨
- en: remove the feature with the lowest feature importance and rebuild the model
  id: totrans-3450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç§»é™¤ç‰¹å¾é‡è¦æ€§æœ€ä½çš„ç‰¹å¾å¹¶é‡æ–°æ„å»ºæ¨¡å‹
- en: repeat the process until only one feature remains
  id: totrans-3451
  prefs: []
  type: TYPE_NORMAL
  zh: é‡å¤æ­¤è¿‡ç¨‹ï¼Œç›´åˆ°åªå‰©ä¸‹ä¸€ä¸ªç‰¹å¾
- en: Any model predictive model could be used,
  id: totrans-3452
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•é¢„æµ‹æ¨¡å‹éƒ½å¯ä»¥ä½¿ç”¨ï¼Œ
- en: the method assigns rank \(1,\ldots,ğ‘š\) for all features as reverse order of
    removal, i.e., last remaining feature is most important and first removed is least
    important
  id: totrans-3453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•ä¸ºæ‰€æœ‰ç‰¹å¾åˆ†é… \(1,\ldots,ğ‘š\) çš„æ’åï¼ŒæŒ‰ç§»é™¤çš„é€†åºï¼Œå³æœ€åä¸€ä¸ªå‰©ä½™çš„ç‰¹å¾æ˜¯æœ€é‡è¦çš„ï¼Œç¬¬ä¸€ä¸ªç§»é™¤çš„æ˜¯æœ€ä¸é‡è¦çš„
- en: '**Reservoir Modeling Workflow**'
  id: totrans-3454
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å‚¨å±‚å»ºæ¨¡å·¥ä½œæµç¨‹**'
- en: '[Machine Learning Workflow Construction and Coding](MachineLearning_workflow_construction.html):
    the following is the common geostatistical reservoir modeling workflow:'
  id: totrans-3455
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºä¸ç¼–ç ](MachineLearning_workflow_construction.html)ï¼šä»¥ä¸‹æ˜¯ä¸€ä¸ªå¸¸è§çš„åœ°è´¨ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡å·¥ä½œæµç¨‹ï¼š'
- en: Integrate all available information to build multiple subsurface scenarios and
    realizations to sample the uncertainty space
  id: totrans-3456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•´åˆæ‰€æœ‰å¯ç”¨ä¿¡æ¯ï¼Œæ„å»ºå¤šä¸ªåœ°ä¸‹åœºæ™¯å’Œå®ç°ï¼Œä»¥é‡‡æ ·ä¸ç¡®å®šæ€§ç©ºé—´
- en: Apply all the models to the transfer function to sample the decision criteria
  id: totrans-3457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰æ¨¡å‹åº”ç”¨äºä¼ é€’å‡½æ•°ä»¥é‡‡æ ·å†³ç­–å‡†åˆ™
- en: Assemble the distribution of the decision criteria
  id: totrans-3458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»„è£…å†³ç­–å‡†åˆ™çš„åˆ†å¸ƒ
- en: Make the optimum reservoir development decisions accounting for this uncertainty
    model
  id: totrans-3459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è€ƒè™‘æ­¤ä¸ç¡®å®šæ€§æ¨¡å‹ï¼Œåšå‡ºæœ€ä½³å‚¨å±‚å¼€å‘å†³ç­–
- en: '**Response Feature**'
  id: totrans-3460
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å“åº”ç‰¹å¾**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): output feature
    for a predictive machine learning model. We can generalize a predictive machine
    learning model as,'
  id: totrans-3461
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å‡ºç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹æ¦‚æ‹¬ä¸ºï¼Œ'
- en: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
  id: totrans-3462
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \hat{f}(x_1,\ldots,x_m) + \epsilon \]
- en: where the response feature is \(y\), the predictor features are \(x_1,\ldots,x_m\),
    and \(\epsilon\) is model error
  id: totrans-3463
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­å“åº”ç‰¹å¾æ˜¯ \(y\)ï¼Œé¢„æµ‹ç‰¹å¾æ˜¯ \(x_1,\ldots,x_m\)ï¼Œè€Œ \(\epsilon\) æ˜¯æ¨¡å‹è¯¯å·®
- en: traditional statistics uses the term dependent variable
  id: totrans-3464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿç»Ÿè®¡å­¦ä½¿ç”¨æœ¯è¯­å› å˜é‡
- en: '**Ridge Regression** (Tikhonov Regularization)'
  id: totrans-3465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å²­å›å½’**ï¼ˆTikhonov æ­£åˆ™åŒ–ï¼‰'
- en: '[Ridge Regression](MachineLearning_ridge_regression.html): a linear, parametric
    prediction model,'
  id: totrans-3466
  prefs: []
  type: TYPE_NORMAL
  zh: '[å²­å›å½’](MachineLearning_ridge_regression.html)ï¼šä¸€ä¸ªçº¿æ€§ã€å‚æ•°åŒ–çš„é¢„æµ‹æ¨¡å‹ï¼Œ'
- en: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
  id: totrans-3467
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 \]
- en: The analytical solution for the model parameters, \(b_1,\ldots,b_m,b_0\), is
    available for the L2 norm loss function, the errors are summed and squared known
    a least squares.
  id: totrans-3468
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº L2 èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œæ¨¡å‹å‚æ•° \(b_1,\ldots,b_m,b_0\) çš„è§£æè§£æ˜¯å¯ç”¨çš„ï¼Œè¯¯å·®æ˜¯æ€»å’Œå¹¶å¹³æ–¹ï¼Œå·²çŸ¥ä¸ºæœ€å°äºŒä¹˜æ³•ã€‚
- en: 'we minimize a loss function including the error, residual sum of squares (RSS)
    over the training data and a regularization term:'
  id: totrans-3469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€å°åŒ–ä¸€ä¸ªåŒ…å«è¯¯å·®ã€è®­ç»ƒæ•°æ®ä¸Šçš„æ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰å’Œæ­£åˆ™åŒ–é¡¹çš„æŸå¤±å‡½æ•°ï¼š
- en: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 + \lambda \sum_{\alpha = 1}^m b_{\alpha}^2 \]
  id: totrans-3470
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0)
    \right)^2 + \lambda \sum_{\alpha = 1}^m b_{\alpha}^2 \]
- en: where \(y_i\) is the actual response feature values and \(\sum_{\alpha = 1}^m
    b_{\alpha} x_{\alpha} + b_0\) are the model predictions, over the \(\alpha = 1,\ldots,n\)
    training data, and \(\lambda \sum_{\alpha = 1}^m b_{\alpha}^2\) is the shrinkage
    penalty.
  id: totrans-3471
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(y_i\) æ˜¯å®é™…å“åº”ç‰¹å¾å€¼ï¼Œ\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\) æ˜¯æ¨¡å‹é¢„æµ‹ï¼Œåœ¨
    \(\alpha = 1,\ldots,n\) çš„è®­ç»ƒæ•°æ®ä¸Šï¼Œè€Œ \(\lambda \sum_{\alpha = 1}^m b_{\alpha}^2\)
    æ˜¯æ”¶ç¼©æƒ©ç½šé¡¹ã€‚
- en: With ridge regression we add a hyperparameter, \(\lambda\), to our minimization,
    with a shrinkage penalty term, \(\sum_{j=1}^m b_{\alpha}^2\).
  id: totrans-3472
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å²­å›å½’ä¸­ï¼Œæˆ‘ä»¬å‘æœ€å°åŒ–ä¸­æ·»åŠ ä¸€ä¸ªè¶…å‚æ•° \(\lambda\)ï¼Œå…·æœ‰æ”¶ç¼©æƒ©ç½šé¡¹ \(\sum_{j=1}^m b_{\alpha}^2\)ã€‚
- en: As a result, ridge regression training integrates two and often competing goals
    to find the model parameters,
  id: totrans-3473
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå²­å›å½’è®­ç»ƒé›†æˆäº†ä¸¤ä¸ªé€šå¸¸ç›¸äº’ç«äº‰çš„ç›®æ ‡ï¼Œä»¥æ‰¾åˆ°æ¨¡å‹å‚æ•°ï¼Œ
- en: find the model parameters that minimize the error with training data
  id: totrans-3474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ä½¿è®­ç»ƒæ•°æ®è¯¯å·®æœ€å°çš„æ¨¡å‹å‚æ•°
- en: minimize the slope parameters towards zero
  id: totrans-3475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ–œç‡å‚æ•°æœ€å°åŒ–åˆ°é›¶
- en: 'Note: lambda does not include the intercept, \(b_0\).'
  id: totrans-3476
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼šlambda ä¸åŒ…æ‹¬æˆªè·ï¼Œ\(b_0\)ã€‚
- en: The \(\lambda\) is a hyperparameter that controls the degree of fit of the model
    and may be related to the model bias-variance trade-off.
  id: totrans-3477
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lambda\) æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå®ƒæ§åˆ¶æ¨¡å‹çš„æ‹Ÿåˆç¨‹åº¦ï¼Œå¯èƒ½ä¸æ¨¡å‹çš„åå·®-æ–¹å·®æƒè¡¡æœ‰å…³ã€‚
- en: for \(\lambda \rightarrow 0\) the solution approaches linear regression, there
    is no bias (relative to a linear model fit), but the model variance is likely
    higher
  id: totrans-3478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(\lambda \rightarrow 0\) æ—¶ï¼Œè§£è¶‹è¿‘äºçº¿æ€§å›å½’ï¼Œæ²¡æœ‰åå·®ï¼ˆç›¸å¯¹äºçº¿æ€§æ¨¡å‹æ‹Ÿåˆï¼‰ï¼Œä½†æ¨¡å‹æ–¹å·®å¯èƒ½æ›´é«˜
- en: as \(\lambda\) increases the model variance decreases and the model bias increases,
    the model becomes simpler
  id: totrans-3479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éšç€ \(\lambda\) çš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å‡å°ï¼Œæ¨¡å‹åå·®å¢åŠ ï¼Œæ¨¡å‹å˜å¾—ç®€å•
- en: for \(\lambda \rightarrow \infty\) the model parameters \(b_1,\ldots,b_m\) shrink
    to 0.0 and the model predictions approaches the training data response feature
    mean
  id: totrans-3480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ \(\lambda \rightarrow \infty\) æ—¶ï¼Œæ¨¡å‹å‚æ•° \(b_1,\ldots,b_m\) æ”¶ç¼©åˆ° 0.0ï¼Œæ¨¡å‹é¢„æµ‹è¶‹è¿‘äºè®­ç»ƒæ•°æ®å“åº”ç‰¹å¾å‡å€¼
- en: '**Sample**'
  id: totrans-3481
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ·æœ¬**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the set of values,
    locations that have been measured'
  id: totrans-3482
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå·²æµ‹é‡çš„å€¼å’Œä½ç½®çš„é›†åˆ'
- en: for example, 1,000 porosity measures from well-logs over the wells in the reservoir
  id: totrans-3483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ¥è‡ªå‚¨å±‚ä¸­äº•çš„ 1,000 ä¸ªå­”éš™åº¦æµ‹é‡å€¼
- en: or 1,000,000 acoustic impedance measurements over a 1000 x 1000 2D grid for
    a reservoir unit of interest
  id: totrans-3484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ–è€…åœ¨ä¸€ä¸ª 1000 x 1000 2D ç½‘æ ¼ä¸Šå¯¹æ„Ÿå…´è¶£çš„å‚¨å±‚å•å…ƒè¿›è¡Œ 1,000,000 ä¸ªå£°é˜»æŠ—æµ‹é‡
- en: '**Scenarios** (uncertainty)'
  id: totrans-3485
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åœºæ™¯**ï¼ˆä¸ç¡®å®šæ€§ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): multiple spatial,
    subsurface models calculated by stochastic simulation by changing the input parameters
    or other modeling choices to represent the uncertainty due to inference of model
    parameters and model choices'
  id: totrans-3486
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé€šè¿‡æ”¹å˜è¾“å…¥å‚æ•°æˆ–å…¶ä»–å»ºæ¨¡é€‰æ‹©è¿›è¡Œéšæœºæ¨¡æ‹Ÿï¼Œè®¡ç®—å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹ï¼Œä»¥è¡¨ç¤ºæ¨¡å‹å‚æ•°å’Œæ¨¡å‹é€‰æ‹©çš„æ¨æ–­ä¸ç¡®å®šæ€§'
- en: for example, model three porosity input distribution, porosity mean low, mid
    and high, and vary the input distribution to calculate new subsurface models
  id: totrans-3487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæ¨¡å‹ä¸‰ä¸ªå­”éš™ç‡è¾“å…¥åˆ†å¸ƒï¼Œå­”éš™ç‡å¹³å‡å€¼ä½ã€ä¸­ã€é«˜ï¼Œå¹¶æ”¹å˜è¾“å…¥åˆ†å¸ƒæ¥è®¡ç®—æ–°çš„åœ°ä¸‹æ¨¡å‹
- en: '**Secondary Data**'
  id: totrans-3488
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¬¡çº§æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data samples for
    another feature, not the feature of interest, the target feature for building
    a model, but are used to improve the prediction of the target feature.'
  id: totrans-3489
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸ºå¦ä¸€ä¸ªç‰¹å¾çš„æ•°æ®æ ·æœ¬ï¼Œè€Œä¸æ˜¯æ„Ÿå…´è¶£çš„ç‰¹å¾ï¼Œä¸ºæ„å»ºæ¨¡å‹çš„ç›®æ ‡ç‰¹å¾ï¼Œä½†ç”¨äºæé«˜ç›®æ ‡ç‰¹å¾çš„é¢„æµ‹'
- en: requires a model of the relationship between the primary and secondary data
  id: totrans-3490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éœ€è¦ä¸€ä¸ªä¸»æ¬¡çº§æ•°æ®ä¹‹é—´å…³ç³»æ¨¡å‹
- en: For example, samples in space of,
  id: totrans-3491
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œç©ºé—´ä¸­çš„æ ·æœ¬ï¼Œ
- en: acoustic impedance (secondary data) to support calculation of a model of porosity,
    the feature of interest
  id: totrans-3492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ—ï¼ˆæ¬¡çº§æ•°æ®ï¼‰ç”¨äºæ”¯æŒå­”éš™ç‡æ¨¡å‹çš„è®¡ç®—ï¼Œè¿™æ˜¯æ„Ÿå…´è¶£çš„ç‰¹å¾
- en: porosity (secondary data) to support calculation of a model of permeability,
    the feature of interest
  id: totrans-3493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ï¼ˆæ¬¡çº§æ•°æ®ï¼‰ç”¨äºæ”¯æŒæ¸—é€ç‡æ¨¡å‹çš„è®¡ç®—ï¼Œè¿™æ˜¯æ„Ÿå…´è¶£çš„ç‰¹å¾
- en: '**Seismic Data**'
  id: totrans-3494
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åœ°éœ‡æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): indirect measurement
    with remote sensing, reflection seismic applies acoustic source(s) and receivers
    (geophones) to map acoustic reflections with high coverage and generally low resolution.
    Some more details,'
  id: totrans-3495
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šé¥æ„Ÿé—´æ¥æµ‹é‡ï¼Œåå°„åœ°éœ‡ä½¿ç”¨å£°æºï¼ˆsï¼‰å’Œæ¥æ”¶å™¨ï¼ˆåœ°éœ‡æ£€æ³¢å™¨ï¼‰æ¥ç»˜åˆ¶é«˜è¦†ç›–ç‡å’Œä¸€èˆ¬ä½åˆ†è¾¨ç‡çš„å£°æ³¢åå°„å›¾ã€‚ä¸€äº›æ›´è¯¦ç»†çš„è¯´æ˜ï¼Œ'
- en: seismic reflections (amplitude) data are inverted to rock properties, e.g.,
    acoustic impedance, consistent with and positionally anchored with well sonic
    logs
  id: totrans-3496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°éœ‡åå°„ï¼ˆæŒ¯å¹…ï¼‰æ•°æ®è¢«åæ¼”ä¸ºå²©çŸ³å±æ€§ï¼Œä¾‹å¦‚ï¼Œå£°é˜»æŠ—ï¼Œä¸äº•å£°æ³¢æµ‹äº•ä¸€è‡´å¹¶åœ¨ä½ç½®ä¸Šé”šå®š
- en: provides framework, bounding surfaces for extents and shapes of reservoirs along
    with soft information on reservoir properties, e.g., porosity and facies.
  id: totrans-3497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æä¾›æ¡†æ¶ã€è¾¹ç•Œè¡¨é¢ï¼Œä»¥åŠå…³äºå‚¨å±‚å±æ€§ï¼ˆä¾‹å¦‚ï¼Œå­”éš™ç‡å’Œå²©æ€§ï¼‰çš„è½¯ä¿¡æ¯
- en: '**Shapley Value**'
  id: totrans-3498
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Shapleyå€¼**'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): model-based, local
    (for a single prediction) and global (over a suit of predictions) feature importance
    by learning contribution of each feature to the prediction.'
  id: totrans-3499
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šåŸºäºå­¦ä¹ æ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®ï¼Œè¿›è¡ŒåŸºäºæ¨¡å‹ã€å±€éƒ¨ï¼ˆé’ˆå¯¹å•ä¸ªé¢„æµ‹ï¼‰å’Œå…¨å±€ï¼ˆé’ˆå¯¹ä¸€ç³»åˆ—é¢„æµ‹ï¼‰çš„ç‰¹å¾é‡è¦æ€§'
- en: A explainable machine learning method to support complicated models are often
    required but have low interpretability.
  id: totrans-3500
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦ä¸€ç§å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ–¹æ³•æ¥æ”¯æŒå¤æ‚çš„æ¨¡å‹ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸å…·æœ‰è¾ƒä½çš„å¯è§£é‡Šæ€§
- en: Two choices to improve model interpretability,
  id: totrans-3501
  prefs: []
  type: TYPE_NORMAL
  zh: æé«˜æ¨¡å‹å¯è§£é‡Šæ€§çš„ä¸¤ç§é€‰æ‹©ï¼Œ
- en: reduce the complexity of the models, but may also reduce model accuracy
  id: totrans-3502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡å°‘æ¨¡å‹çš„å¤æ‚æ€§ï¼Œä½†å¯èƒ½ä¼šé™ä½æ¨¡å‹ç²¾åº¦
- en: develop improved, agnostic (for any model) model diagnostics, i.e., Shapley
    value
  id: totrans-3503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å‘æ”¹è¿›çš„ã€æ— å·®åˆ«çš„ï¼ˆé€‚ç”¨äºä»»ä½•æ¨¡å‹ï¼‰æ¨¡å‹è¯Šæ–­ï¼Œå³Shapleyå€¼
- en: Shapley value is a cooperative game theory approach that,
  id: totrans-3504
  prefs: []
  type: TYPE_NORMAL
  zh: Shapleyå€¼æ˜¯åˆä½œåšå¼ˆè®ºæ–¹æ³•ï¼Œ
- en: for allocating resources between players based on a summarization of marginal
    contributions, i.e., dividing up payment between players
  id: totrans-3505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºæ ¹æ®è¾¹é™…è´¡çŒ®çš„æ±‡æ€»æ¥åˆ†é…èµ„æºç»™ç©å®¶ï¼Œå³åˆ†é…ç»™ç©å®¶çš„ä»˜æ¬¾
- en: calculates the contribution of each predictor feature to push the response prediction
    away from the mean value of the response
  id: totrans-3506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯ä¸ªé¢„æµ‹ç‰¹å¾å¯¹æ¨åŠ¨å“åº”é¢„æµ‹è¿œç¦»å“åº”å¹³å‡å€¼è´¡çŒ®çš„å¤§å°
- en: marginal contributions and Shapley values are in units of the response feature
  id: totrans-3507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾¹é™…è´¡çŒ®å’ŒShapleyå€¼ä»¥å“åº”ç‰¹å¾çš„å•ä½è¡¨ç¤º
- en: in the units of the response feature
  id: totrans-3508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å“åº”ç‰¹å¾çš„å•ä½ä¸­
- en: '**Simpsonâ€™s Paradox**'
  id: totrans-3509
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¾›æ™®æ£®æ‚–è®º**'
- en: '[Multivariate Analysis](MachineLearning_multivariate_analysis.html): data trend
    reverses or disappears when groups are combined (or separated). Often observed
    in correlation analysis when grouping data, for example,'
  id: totrans-3510
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¤šå…ƒåˆ†æ](MachineLearning_multivariate_analysis.html)ï¼šå½“ç»„åˆï¼ˆæˆ–åˆ†ç¦»ï¼‰ç»„æ—¶ï¼Œæ•°æ®è¶‹åŠ¿åè½¬æˆ–æ¶ˆå¤±ã€‚åœ¨åˆ†ç»„æ•°æ®çš„ç›¸å…³åˆ†æä¸­ç»å¸¸è§‚å¯Ÿåˆ°ï¼Œä¾‹å¦‚ï¼Œ'
- en: groups each have a negative correlation, but the whole has a positive correlation
  id: totrans-3511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ç»„éƒ½æœ‰è´Ÿç›¸å…³ï¼Œä½†æ•´ä½“æœ‰æ­£ç›¸å…³
- en: '**Soft Data**'
  id: totrans-3512
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è½¯æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): data that has a
    high degree of uncertainty, such that data uncertainty must be integrated into
    the model'
  id: totrans-3513
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šå…·æœ‰é«˜åº¦ä¸ç¡®å®šæ€§çš„æ•°æ®ï¼Œå› æ­¤æ•°æ®ä¸ç¡®å®šæ€§å¿…é¡»é›†æˆåˆ°æ¨¡å‹ä¸­'
- en: for example, probability density function for local porosity calibrated from
    acoustic impedance
  id: totrans-3514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä»å£°é˜»æŠ—æ ¡å‡†çš„å±€éƒ¨å­”éš™ç‡æ¦‚ç‡å¯†åº¦å‡½æ•°
- en: Soft data integration requires workflows like *indicator kriging*, *indicator
    simulation* and *p-field simulation* or workflows that randomize the data with
    standard simulation methods that assume hard data like *sequential Gaussian simulation*.
  id: totrans-3515
  prefs: []
  type: TYPE_NORMAL
  zh: è½¯æ•°æ®é›†æˆéœ€è¦åƒ *æŒ‡ç¤ºå…‹é‡Œé‡‘*ã€*æŒ‡ç¤ºæ¨¡æ‹Ÿ* å’Œ *påœºæ¨¡æ‹Ÿ* æˆ–ä½¿ç”¨å‡è®¾ç¡¬æ•°æ®çš„æ ‡å‡†æ¨¡æ‹Ÿæ–¹æ³•éšæœºåŒ–æ•°æ®çš„æµç¨‹ï¼Œå¦‚ *é¡ºåºé«˜æ–¯æ¨¡æ‹Ÿ*ã€‚
- en: soft data integration is an advanced topic and a focus of ongoing research,
    but is often to done with standard, subsurface modeling software packages
  id: totrans-3516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è½¯æ•°æ®é›†æˆæ˜¯ä¸€ä¸ªé«˜çº§ä¸»é¢˜ï¼Œä¹Ÿæ˜¯å½“å‰ç ”ç©¶çš„çƒ­ç‚¹ï¼Œä½†é€šå¸¸ä½¿ç”¨æ ‡å‡†çš„ã€åœ°ä¸‹å»ºæ¨¡è½¯ä»¶åŒ…æ¥å®Œæˆ
- en: '**Spatial Sampling** (biased)'
  id: totrans-3517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆæœ‰åå·®ï¼‰'
- en: 'Data Preparation: sample such that the sample statistics are not representative
    of the population parameters. For example,'
  id: totrans-3518
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šæ ·æœ¬ä»¥ä½¿æ ·æœ¬ç»Ÿè®¡é‡ä¸ä»£è¡¨æ€»ä½“å‚æ•°ã€‚ä¾‹å¦‚ï¼Œ
- en: the sample mean is not the same as the population mean
  id: totrans-3519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬å‡å€¼ä¸æ€»ä½“å‡å€¼ä¸åŒ
- en: the sample variance is not the same as the population variance
  id: totrans-3520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ–¹å·®ä¸æ€»ä½“æ–¹å·®ä¸åŒ
- en: Of course, the population parameters are not accessible, so we cannot directly
    calculate sampling bias, i.e., the difference between the sample statistics and
    the population parameters. Methods we can use to check for biased sampling,
  id: totrans-3521
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œäººå£å‚æ•°æ˜¯ä¸å¯è®¿é—®çš„ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®—æŠ½æ ·åå·®ï¼Œå³æ ·æœ¬ç»Ÿè®¡é‡ä¸äººå£å‚æ•°ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ¥æ£€æŸ¥æŠ½æ ·åå·®çš„æ–¹æ³•ï¼Œ
- en: evaluate the samples for preferential sampling, clustering, filtering, etc.
  id: totrans-3522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ ·æœ¬çš„ä¼˜å…ˆæŠ½æ ·ã€èšé›†ã€è¿‡æ»¤ç­‰
- en: apply *declustering* and check the results for a major change in the summary
    statistics, this is using declustering diagnostically
  id: totrans-3523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨ *å»èšé›†* å¹¶æ£€æŸ¥ç»“æœåœ¨æ±‡æ€»ç»Ÿè®¡ä¸­çš„é‡å¤§å˜åŒ–ï¼Œè¿™æ˜¯ä½¿ç”¨å»èšé›†è¿›è¡Œè¯Šæ–­
- en: '**Spatial Sampling** (clustered)'
  id: totrans-3524
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆèšé›†ï¼‰'
- en: 'Data Preparation: spatial samples with locations preferentially selected, i.e.,
    clustered, resulting in biased statistics,'
  id: totrans-3525
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šä¼˜å…ˆé€‰æ‹©ä½ç½®çš„ç©ºé—´æ ·æœ¬ï¼Œå³èšé›†ï¼Œå¯¼è‡´ç»Ÿè®¡åå·®ï¼Œ
- en: typically spatial samples are clustered in locations with higher value samples,
    e.g., high porosity and permeability, good quality shale for unconventional reservoirs,
    low acoustic impedance indicating higher porosity, etc.
  id: totrans-3526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç©ºé—´æ ·æœ¬åœ¨å…·æœ‰æ›´é«˜ä»·å€¼æ ·æœ¬çš„ä½ç½®èšé›†ï¼Œä¾‹å¦‚ï¼Œé«˜å­”éš™ç‡å’Œæ¸—é€ç‡ï¼Œä¼˜è´¨é¡µå²©ç”¨äºéå¸¸è§„å‚¨å±‚ï¼Œä½å£°é˜»æŠ—æŒ‡ç¤ºæ›´é«˜çš„å­”éš™ç‡ç­‰ã€‚
- en: Of course, the population parameters are not accessible, so we cannot directly
    calculate sampling bias, i.e., the difference between the sample statistics and
    the population parameters. Methods we can use to check for biased sampling,
  id: totrans-3527
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œäººå£å‚æ•°æ˜¯ä¸å¯è®¿é—®çš„ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•ç›´æ¥è®¡ç®—æŠ½æ ·åå·®ï¼Œå³æ ·æœ¬ç»Ÿè®¡é‡ä¸äººå£å‚æ•°ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ¥æ£€æŸ¥æŠ½æ ·åå·®çš„æ–¹æ³•ï¼Œ
- en: evaluate the samples for preferential sampling, clustering, filtering, etc.
  id: totrans-3528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ ·æœ¬çš„ä¼˜å…ˆæŠ½æ ·ã€èšé›†ã€è¿‡æ»¤ç­‰
- en: apply *declustering* and check the results for a major change in the summary
    statistics, this is using declustering diagnostically
  id: totrans-3529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åº”ç”¨ *å»èšé›†* å¹¶æ£€æŸ¥ç»“æœåœ¨æ±‡æ€»ç»Ÿè®¡ä¸­çš„é‡å¤§å˜åŒ–ï¼Œè¿™æ˜¯ä½¿ç”¨å»èšé›†è¿›è¡Œè¯Šæ–­
- en: '**Spatial Sampling** (common practice)'
  id: totrans-3530
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆå¸¸è§åšæ³•ï¼‰'
- en: 'Data Preparation: sample locations are selected to,'
  id: totrans-3531
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šé€‰æ‹©æ ·æœ¬ä½ç½®ä»¥ï¼Œ
- en: '*Reduce uncertainty* - by answering questions, for example,'
  id: totrans-3532
  prefs: []
  type: TYPE_NORMAL
  zh: '*å‡å°‘ä¸ç¡®å®šæ€§* - é€šè¿‡å›ç­”é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œ'
- en: how far does the contaminant plume extend? â€“ sample peripheries
  id: totrans-3533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ±¡æŸ“ç¾½æµå»¶ä¼¸å¤šè¿œï¼Ÿ â€“ æ ·æœ¬å¤–å›´
- en: where is the fault? â€“ drill based on seismic interpretation
  id: totrans-3534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–­å±‚åœ¨å“ªé‡Œï¼Ÿ â€“ æ ¹æ®åœ°éœ‡è§£é‡Šè¿›è¡Œé’»æ¢
- en: what is the highest mineral grade? â€“ sample the best part
  id: totrans-3535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€é«˜çŸ¿ç‰©å“ä½æ˜¯å¤šå°‘ï¼Ÿ â€“ æ ·æœ¬æœ€ä½³éƒ¨åˆ†
- en: who far does the reservoir extend? â€“ offset drilling
  id: totrans-3536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚¨å±‚å»¶ä¼¸å¤šè¿œï¼Ÿ â€“ åç§»é’»æ¢
- en: '*Directly maximize net present value* - while collecting information, for example,'
  id: totrans-3537
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç›´æ¥æœ€å¤§åŒ–å‡€ç°å€¼* - åœ¨æ”¶é›†ä¿¡æ¯æ—¶ï¼Œä¾‹å¦‚ï¼Œ'
- en: maximize production rates
  id: totrans-3538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–ç”Ÿäº§ç‡
- en: maximize tonnage of mineral extracted
  id: totrans-3539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å¤§åŒ–æå–çš„çŸ¿ç‰©å¨æ•°
- en: In other words, often our samples are dual purpose, e.g., wells that are drilled
    for exploration and appraisal information are subsequently utilized for production.
  id: totrans-3540
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„æ ·æœ¬é€šå¸¸æ˜¯åŒç”¨é€”çš„ï¼Œä¾‹å¦‚ï¼Œä¸ºå‹˜æ¢å’Œè¯„ä¼°ä¿¡æ¯è€Œé’»æ¢çš„äº•éšåè¢«ç”¨äºç”Ÿäº§ã€‚
- en: '**Spatial Sampling** (representative)'
  id: totrans-3541
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç©ºé—´æŠ½æ ·**ï¼ˆä»£è¡¨æ€§ï¼‰'
- en: 'Data Preparation: if we are sampling for representativity, i.e., the sample
    set and resulting sample statistics are representative of the population, by sampling
    theory we have 2 options:'
  id: totrans-3542
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡†å¤‡ï¼šå¦‚æœæˆ‘ä»¬æ˜¯ä¸ºäº†ä»£è¡¨æ€§è¿›è¡Œé‡‡æ ·ï¼Œå³æ ·æœ¬é›†å’Œç»“æœæ ·æœ¬ç»Ÿè®¡é‡ä»£è¡¨æ€»ä½“ï¼Œæ ¹æ®é‡‡æ ·ç†è®ºï¼Œæˆ‘ä»¬æœ‰2ç§é€‰æ‹©ï¼š
- en: '*Random sampling* - each potential sample from the population is equally likely
    to be sampled as samples are collected. This includes,'
  id: totrans-3543
  prefs: []
  type: TYPE_NORMAL
  zh: '*éšæœºé‡‡æ ·* - ä»æ€»ä½“ä¸­æ¯ä¸ªæ½œåœ¨çš„æ ·æœ¬è¢«é‡‡æ ·çš„å¯èƒ½æ€§ç›¸ç­‰ã€‚è¿™åŒ…æ‹¬ï¼Œ'
- en: selecting a specific location has no impact on the selection of subsequent locations.
  id: totrans-3544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ç‰¹å®šä½ç½®ä¸ä¼šå½±å“åç»­ä½ç½®çš„é€‰æ‹©ã€‚
- en: assumption that the population size that is much larger than the sample size;
    therefore, significant correlation between samples is not imposed due to without
    replacement sampling (the constraint that you can only sample a location once).
    Note, generally this is not an issue for the subsurface due to the sparsely sampled
    massive populations
  id: totrans-3545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡è®¾æ€»ä½“å¤§å°è¿œå¤§äºæ ·æœ¬å¤§å°ï¼›å› æ­¤ï¼Œç”±äºä¸æ”¾å›é‡‡æ ·ï¼ˆåªèƒ½é‡‡æ ·ä¸€ä¸ªä½ç½®çš„çº¦æŸï¼‰ï¼Œæ ·æœ¬ä¹‹é—´ä¸å­˜åœ¨æ˜¾è‘—çš„å…³è”ã€‚æ³¨æ„ï¼Œç”±äºåœ°ä¸‹é‡‡æ ·å¯†é›†çš„æ€»ä½“ï¼Œè¿™é€šå¸¸ä¸æ˜¯é—®é¢˜
- en: '*Regular sampling* - sampling at equal space or time intervals. While random
    sampling is preferred, regular sampling is robust as long as,'
  id: totrans-3546
  prefs: []
  type: TYPE_NORMAL
  zh: '*è§„åˆ™é‡‡æ ·* - åœ¨ç­‰é—´éš”çš„ç©ºé—´æˆ–æ—¶é—´è¿›è¡Œé‡‡æ ·ã€‚è™½ç„¶éšæœºé‡‡æ ·æ›´å—æ¬¢è¿ï¼Œä½†åªè¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼Œè§„åˆ™é‡‡æ ·å°±è¶³å¤Ÿç¨³å¥ï¼Œ'
- en: the regular sampling intervals do not align with natural periodicity in the
    data, for example, the crests are systematically samples resulting in biased high
    sample statistics
  id: totrans-3547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§„åˆ™é‡‡æ ·é—´éš”ä¸æ•°æ®ä¸­çš„è‡ªç„¶å‘¨æœŸæ€§ä¸ä¸€è‡´ï¼Œä¾‹å¦‚ï¼Œé¡¶å³°è¢«ç³»ç»Ÿåœ°é‡‡æ ·ï¼Œå¯¼è‡´æ ·æœ¬ç»Ÿè®¡é‡åé«˜
- en: '**Spectral Clustering**'
  id: totrans-3548
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è°±èšç±»**'
- en: '[Spectral Clustering](MachineLearning_spectral_clustering.html): a partitional
    clustering method that utilizes the spectrum, eigenvalues and eigenvectors, of
    a matrix that represents the pairwise relationships between the data.'
  id: totrans-3549
  prefs: []
  type: TYPE_NORMAL
  zh: '[è°±èšç±»](MachineLearning_spectral_clustering.html)ï¼šä¸€ç§åˆ©ç”¨è¡¨ç¤ºæ•°æ®æˆå¯¹å…³ç³»çš„çŸ©é˜µçš„è°±ã€ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„åˆ’åˆ†èšç±»æ–¹æ³•ã€‚'
- en: dimensionality reduction from data samples pairwise relationships characterized
    by the graph Laplacian matrix
  id: totrans-3550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ•°æ®æ ·æœ¬çš„æˆå¯¹å…³ç³»ä¸­é€šè¿‡å›¾æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µè¿›è¡Œé™ç»´
- en: eigenvalues, eigenvectors are equivalent to principal component analysis dimensionality
    reduction by linear, orthogonal feature projection and rotation to best describe
    the variance
  id: totrans-3551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ç­‰åŒäºé€šè¿‡çº¿æ€§ã€æ­£äº¤ç‰¹å¾æŠ•å½±å’Œæ—‹è½¬è¿›è¡Œçš„ä¸»æˆåˆ†åˆ†æé™ç»´ï¼Œä»¥æœ€å¥½åœ°æè¿°æ–¹å·®
- en: Advantages of spectral clustering,
  id: totrans-3552
  prefs: []
  type: TYPE_NORMAL
  zh: è°±èšç±»çš„ä¼˜åŠ¿ï¼Œ
- en: the ability to encode pairwise relationships, integrate expert knowledge.
  id: totrans-3553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èƒ½å¤Ÿç¼–ç æˆå¯¹å…³ç³»ï¼Œæ•´åˆä¸“å®¶çŸ¥è¯†ã€‚
- en: eigenvalues provide useful information on the number of clusters, based on the
    degree of â€˜cuttingâ€™ required to make k clusters
  id: totrans-3554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾å€¼æä¾›äº†å…³äºèšç±»æ•°é‡çš„æœ‰ç”¨ä¿¡æ¯ï¼ŒåŸºäºå½¢æˆkä¸ªèšç±»æ‰€éœ€çš„â€œåˆ‡å‰²â€ç¨‹åº¦
- en: lower dimensional representation for the sample data pairwise relationships
  id: totrans-3555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ•°æ®æˆå¯¹å…³ç³»çš„ä½ç»´è¡¨ç¤º
- en: the resulting eigenvalues and eigenvectors can be interpreted, eigenvalues describe
    the amount of connection for each number of groups and eigenvectors are grouped
    to form the clusters
  id: totrans-3556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“æœçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡å¯ä»¥è§£é‡Šï¼Œç‰¹å¾å€¼æè¿°äº†æ¯ä¸ªç»„æ•°ä¹‹é—´çš„è¿æ¥é‡ï¼Œè€Œç‰¹å¾å‘é‡è¢«åˆ†ç»„å½¢æˆèšç±»
- en: '**Standardization**'
  id: totrans-3557
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ ‡å‡†åŒ–**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): a
    distribution rescaling that can be thought of as shifting, and stretching or squeezing
    of a univariate distribution (e.g., *histogram*) to a mean of 0.0 and a variance
    of 1.0.'
  id: totrans-3558
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šä¸€ç§åˆ†å¸ƒç¼©æ”¾ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºå¹³ç§»ã€æ‹‰ä¼¸æˆ–å‹ç¼©å•å˜é‡åˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œ*ç›´æ–¹å›¾*ï¼‰åˆ°å‡å€¼ä¸º0.0å’Œæ–¹å·®ä¸º1.0ã€‚'
- en: \[ y_i = \frac{1}{\sigma_x}(x_i - \overline{x}), \quad \forall \quad i, \ldots,
    n \]
  id: totrans-3559
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{1}{\sigma_x}(x_i - \overline{x}), \quad \forall \quad i, \ldots,
    n \]
- en: where \(\overline{x}\) and \(\sigma_x\) are the original mean and variance.
  id: totrans-3560
  prefs: []
  type: TYPE_NORMAL
  zh: \(\overline{x}\) å’Œ \(\sigma_x\) åˆ†åˆ«æ˜¯åŸå§‹å‡å€¼å’Œæ–¹å·®ã€‚
- en: this is a shift and stretch / squeeze of the original property distribution
  id: totrans-3561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹åŸå§‹å±æ€§åˆ†å¸ƒçš„å¹³ç§»å’Œæ‹‰ä¼¸/å‹ç¼©
- en: assumes no shape change, rank preserving
  id: totrans-3562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡è®¾æ²¡æœ‰å½¢çŠ¶å˜åŒ–ï¼Œä¿æŒç§©ä¸å˜
- en: '**Stochastic Gradient-based Optimization**'
  id: totrans-3563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**åŸºäºéšæœºæ¢¯åº¦çš„ä¼˜åŒ–**'
- en: '[LASSO Regression](MachineLearning_LASSO_regression.html): a method to solve
    for model parameters by iteratively minimizing the loss function. Stochasticity
    and improve computational efficiency are added to gradient descent through the
    use of batches,'
  id: totrans-3564
  prefs: []
  type: TYPE_NORMAL
  zh: '[LASSO å›å½’](MachineLearning_LASSO_regression.html)ï¼šé€šè¿‡è¿­ä»£æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥æ±‚è§£æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚é€šè¿‡ä½¿ç”¨æ‰¹é‡ï¼Œå°†éšæœºæ€§å’Œæé«˜è®¡ç®—æ•ˆç‡æ·»åŠ åˆ°æ¢¯åº¦ä¸‹é™ä¸­ï¼Œ'
- en: a batch is a random subset of the training data with specified size, \(n_{batch}\)
  id: totrans-3565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¹é‡æ˜¯å…·æœ‰æŒ‡å®šå¤§å° \(n_{batch}\) çš„è®­ç»ƒæ•°æ®çš„éšæœºå­é›†
- en: resulting in stochastic approximations of the loss function gradient, that are
    faster to calculate
  id: totrans-3566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼è‡´æŸå¤±å‡½æ•°æ¢¯åº¦çš„éšæœºè¿‘ä¼¼ï¼Œè®¡ç®—é€Ÿåº¦æ›´å¿«
- en: batches reduce accuracy in the gradient descent, but speed up the calculation
    and can perform more steps, often faster than gradient descent
  id: totrans-3567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¹é‡åœ¨æ¢¯åº¦ä¸‹é™ä¸­é™ä½äº†å‡†ç¡®æ€§ï¼Œä½†åŠ å¿«äº†è®¡ç®—é€Ÿåº¦ï¼Œå¯ä»¥æ‰§è¡Œæ›´å¤šæ­¥éª¤ï¼Œé€šå¸¸æ¯”æ¢¯åº¦ä¸‹é™æ›´å¿«
- en: increase \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\) for more accuracy of gradient estimation, and decrease
    \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\) to speed up the steps
  id: totrans-3568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†æé«˜æ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå¢åŠ  \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\)ï¼Œä¸ºäº†åŠ å¿«æ­¥éª¤ï¼Œå‡å°‘ \(ğ‘›_{ğ‘ğ‘ğ‘¡ğ‘â„}\)
- en: Robbins-Siegmund (1971) Theorem - converge to global minimum for convex loss
    functions and either a global or local minimum for nonconvex loss functions.
  id: totrans-3569
  prefs: []
  type: TYPE_NORMAL
  zh: Robbins-Siegmund (1971) å®šç† - å¯¹äºå‡¸æŸå¤±å‡½æ•°æ”¶æ•›åˆ°å…¨å±€æœ€å°å€¼ï¼Œå¯¹äºéå‡¸æŸå¤±å‡½æ•°æ”¶æ•›åˆ°å…¨å±€æˆ–å±€éƒ¨æœ€å°å€¼ã€‚
- en: The steps include,
  id: totrans-3570
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤åŒ…æ‹¬ï¼Œ
- en: start with random model parameters
  id: totrans-3571
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»éšæœºçš„æ¨¡å‹å‚æ•°å¼€å§‹
- en: select a random subset of training data, \(n_{batch}\)
  id: totrans-3572
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªéšæœºå­é›†çš„è®­ç»ƒæ•°æ®ï¼Œ\(n_{batch}\)
- en: calculate the loss function and loss function gradient for the model parameters
    over the random batch,
  id: totrans-3573
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¨¡å‹å‚æ•°åœ¨éšæœºæ‰¹é‡ä¸Šçš„æŸå¤±å‡½æ•°å’ŒæŸå¤±å‡½æ•°æ¢¯åº¦
- en: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
  id: totrans-3574
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla L(y_{\alpha}, F(X_{\alpha}, b_1)) = \frac{L(y_{\alpha}, F(X_{\alpha},
    b_1 - \epsilon)) - L(y_{\alpha}, F(X_{\alpha}, b_1 + \epsilon))}{2\epsilon} \]
- en: update the parameter estimate by stepping down slope / gradient,
  id: totrans-3575
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡æ²¿æ–œå¡/æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°å‚æ•°ä¼°è®¡
- en: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
  id: totrans-3576
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{b}_{1,t+1} = \hat{b}_{1,t} - r \nabla L(y_{\alpha}, F(X_{\alpha}, b_1))
    \]
- en: where \(r\) is the learning rate/step size, \(\hat{b}(1,ğ‘¡)\), is the current
    model parameter estimate and \(\hat{b}(1,ğ‘¡+1)\) is the updated parameter estimate.
  id: totrans-3577
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(r\) æ˜¯å­¦ä¹ ç‡/æ­¥é•¿ï¼Œ\(\hat{b}(1,ğ‘¡)\) æ˜¯å½“å‰æ¨¡å‹å‚æ•°ä¼°è®¡ï¼Œ\(\hat{b}(1,ğ‘¡+1)\) æ˜¯æ›´æ–°çš„å‚æ•°ä¼°è®¡ã€‚
- en: '**Stochastic Model**'
  id: totrans-3578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**éšæœºæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): system or process
    that is uncertain and is represented by multiple models, *realizations* and *scenarios*
    constrained by statistics,'
  id: totrans-3579
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸ç¡®å®šçš„ç³»ç»Ÿæˆ–è¿‡ç¨‹ï¼Œç”±å¤šä¸ªæ¨¡å‹ã€*å®ç°*å’Œå—ç»Ÿè®¡çº¦æŸçš„*æƒ…æ™¯*è¡¨ç¤ºï¼Œ'
- en: for example, data-driven models that integrate uncertainty like geostatistical
    simulation models
  id: totrans-3580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåƒåœ°è´¨ç»Ÿè®¡æ¨¡æ‹Ÿæ¨¡å‹è¿™æ ·çš„æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œå®ƒä»¬æ•´åˆäº†ä¸ç¡®å®šæ€§
- en: 'Advantages:'
  id: totrans-3581
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼š
- en: speed
  id: totrans-3582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€Ÿåº¦
- en: uncertainty assessment
  id: totrans-3583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§è¯„ä¼°
- en: report significance, confidence / prediction intervals
  id: totrans-3584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŠ¥å‘Šæ˜¾è‘—æ€§ã€ç½®ä¿¡/é¢„æµ‹åŒºé—´
- en: honor many types of data
  id: totrans-3585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°Šé‡è®¸å¤šç±»å‹çš„æ•°æ®
- en: data-driven approaches
  id: totrans-3586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®é©±åŠ¨æ–¹æ³•
- en: 'Disadvantages:'
  id: totrans-3587
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼š
- en: limited physics used
  id: totrans-3588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çš„ç‰©ç†é™åˆ¶
- en: statistical model assumptions / simplification
  id: totrans-3589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡æ¨¡å‹å‡è®¾/ç®€åŒ–
- en: For the alternative to stochastic models see *deterministic models*.
  id: totrans-3590
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºéšæœºæ¨¡å‹çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¯·å‚é˜…*ç¡®å®šæ€§æ¨¡å‹*ã€‚
- en: '**Statistics** (practice)'
  id: totrans-3591
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»Ÿè®¡å­¦**ï¼ˆå®è·µï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): the theory and
    practice for collecting, organizing, and interpreting data, as well as drawing
    conclusions and making decisions.'
  id: totrans-3592
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ”¶é›†ã€ç»„ç»‡ã€è§£é‡Šæ•°æ®ä»¥åŠå¾—å‡ºç»“è®ºå’Œåšå‡ºå†³ç­–çš„ç†è®ºå’Œå®è·µã€‚'
- en: '**Statistics** (measurement)'
  id: totrans-3593
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»Ÿè®¡å­¦**ï¼ˆæµ‹é‡ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): summary measure
    of a sample, for example,'
  id: totrans-3594
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šæ ·æœ¬çš„æ±‡æ€»åº¦é‡ï¼Œä¾‹å¦‚ï¼Œ'
- en: sample mean - \(\overline{x}\)
  id: totrans-3595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬å‡å€¼ - \(\overline{x}\)
- en: sample standard deviation - \(s\),
  id: totrans-3596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ·æœ¬æ ‡å‡†å·® - \(s\),
- en: we use statistics as estimates of the model parameters that summarize the population
    (*inference*)
  id: totrans-3597
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡ä½œä¸ºæ¨¡å‹å‚æ•°çš„ä¼°è®¡ï¼Œè¿™äº›ä¼°è®¡æ€»ç»“äº†æ€»ä½“ï¼ˆ*æ¨æ–­*ï¼‰
- en: '**Statistical Distribution**'
  id: totrans-3598
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»Ÿè®¡åˆ†å¸ƒ**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): for a feature
    a description of the probability of occurrence over the range of possible values.
    We represent the univariate statistical distribution with,'
  id: totrans-3599
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šå¯¹äºä¸€ä¸ªç‰¹å¾ï¼Œæè¿°å…¶åœ¨å¯èƒ½å€¼èŒƒå›´å†…çš„å‘ç”Ÿæ¦‚ç‡ã€‚æˆ‘ä»¬ç”¨ä»¥ä¸‹æ–¹å¼è¡¨ç¤ºå•å˜é‡ç»Ÿè®¡åˆ†å¸ƒï¼Œ'
- en: '*histogram*'
  id: totrans-3600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç›´æ–¹å›¾*'
- en: '*normalized histogram*'
  id: totrans-3601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å½’ä¸€åŒ–ç›´æ–¹å›¾*'
- en: '*probability density function* (PDF)'
  id: totrans-3602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æ¦‚ç‡å¯†åº¦å‡½æ•°* (PDF)'
- en: '*cumulative distribution function* (CDF)'
  id: totrans-3603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç´¯ç§¯åˆ†å¸ƒå‡½æ•°* (CDF)'
- en: What do we learn from a statistical distribution? For example,
  id: totrans-3604
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»ç»Ÿè®¡åˆ†å¸ƒä¸­å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿä¾‹å¦‚ï¼Œ
- en: what is the minimum and maximum?
  id: totrans-3605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å°å€¼å’Œæœ€å¤§å€¼æ˜¯ä»€ä¹ˆï¼Ÿ
- en: do we have a lot of low values?
  id: totrans-3606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰å¤§é‡çš„ä½å€¼ï¼Ÿ
- en: do we have a lot of high values?
  id: totrans-3607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰å¤§é‡çš„é«˜å€¼ï¼Ÿ
- en: do we have outliers, and any other values that donâ€™t make sense and need explaining?
  id: totrans-3608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ˜¯å¦æœ‰å¼‚å¸¸å€¼ï¼Œä»¥åŠä»»ä½•å…¶ä»–ä¸åˆç†ä¸”éœ€è¦è§£é‡Šçš„å€¼ï¼Ÿ
- en: '**Support Vector** (support vector machines)'
  id: totrans-3609
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ”¯æŒå‘é‡** (æ”¯æŒå‘é‡æœº)'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): training
    data within the margin or misclassified and update the support vector machines
    classification model.'
  id: totrans-3610
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šåœ¨è¾¹ç¼˜å†…çš„è®­ç»ƒæ•°æ®æˆ–è¢«é”™è¯¯åˆ†ç±»ï¼Œå¹¶æ›´æ–°æ”¯æŒå‘é‡æœºåˆ†ç±»æ¨¡å‹ã€‚'
- en: with a support vector machines model, training data well within the correct
    region, are not support vectors, and have no impact on the model
  id: totrans-3611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ”¯æŒå‘é‡æœºæ¨¡å‹ä¸­ï¼Œè®­ç»ƒæ•°æ®å¾ˆå¥½åœ°ä½äºæ­£ç¡®åŒºåŸŸï¼Œä¸æ˜¯æ”¯æŒå‘é‡ï¼Œå¯¹æ¨¡å‹æ²¡æœ‰å½±å“
- en: '**Support Vector Machines**'
  id: totrans-3612
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ”¯æŒå‘é‡æœº**'
- en: '[Support Vector Machines](MachineLearning_support_vector_machines.html): a
    predictive, binary classification machine learning method that is a good classification
    method when there is poor separation of groups.'
  id: totrans-3613
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ”¯æŒå‘é‡æœº](MachineLearning_support_vector_machines.html)ï¼šä¸€ç§é¢„æµ‹æ€§çš„äºŒåˆ†ç±»æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå½“ç»„åˆ«åˆ†ç¦»ä¸è‰¯æ—¶æ˜¯ä¸€ç§å¾ˆå¥½çš„åˆ†ç±»æ–¹æ³•ã€‚'
- en: projects the original predictor features to higher dimensional space and then
    applies a linear, plane or hyperplane,
  id: totrans-3614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†åŸå§‹é¢„æµ‹ç‰¹å¾æŠ•å½±åˆ°é«˜ç»´ç©ºé—´ï¼Œç„¶ååº”ç”¨çº¿æ€§ã€å¹³é¢æˆ–è¶…å¹³é¢ï¼Œ
- en: \[ ğ‘“(ğ‘¥) = ğ‘¥^ğ‘‡ \beta +\beta_0 \]
  id: totrans-3615
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘“(ğ‘¥) = ğ‘¥^ğ‘‡ \beta +\beta_0 \]
- en: where \(\beta\) is a vector and together with \(\beta\) are the hyperplane model
    parameters, while \(x\) is the matrix of predictor features, all are in the high
    dimensional space.
  id: totrans-3616
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\beta\) æ˜¯ä¸€ä¸ªå‘é‡ï¼Œä¸ \(\beta\) ä¸€èµ·æ˜¯è¶…å¹³é¢æ¨¡å‹å‚æ•°ï¼Œè€Œ \(x\) æ˜¯é¢„æµ‹ç‰¹å¾çŸ©é˜µï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨é«˜ç»´ç©ºé—´ä¸­ã€‚
- en: \[ ğº(ğ‘¥)=\text{ğ‘ ğ‘–ğ‘”ğ‘›}\left( ğ‘“(ğ‘¥) \right) \]
  id: totrans-3617
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğº(ğ‘¥)=\text{ğ‘ ğ‘–ğ‘”ğ‘›}\left( ğ‘“(ğ‘¥) \right) \]
- en: \(ğ‘“(ğ‘¥)\) is proportional to the signed distance from the decision boundary,
    and \(ğº(ğ‘¥)\) is the side of the decision boundary, \(âˆ’\) one side and \(+\) the
    other, \(f(x) = 0\) is on the decision boundary.
  id: totrans-3618
  prefs: []
  type: TYPE_NORMAL
  zh: \(ğ‘“(ğ‘¥)\) ä¸å†³ç­–è¾¹ç•Œçš„ç¬¦å·è·ç¦»æˆæ­£æ¯”ï¼Œè€Œ \(ğº(ğ‘¥)\) æ˜¯å†³ç­–è¾¹ç•Œçš„ä¾§é¢ï¼Œ\(-\) ä¸€ä¾§å’Œ \(+\) å¦ä¸€ä¾§ï¼Œ\(f(x) = 0\)
    åœ¨å†³ç­–è¾¹ç•Œä¸Šã€‚
- en: We represent the constraint, all data of each category must be on the correct
    side of the boundary, by,
  id: totrans-3619
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ–¹å¼è¡¨ç¤ºçº¦æŸï¼Œæ¯ä¸ªç±»åˆ«çš„æ‰€æœ‰æ•°æ®éƒ½å¿…é¡»ä½äºè¾¹ç•Œçš„æ­£ç¡®ä¸€ä¾§ï¼Œ
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
  id: totrans-3620
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq 0 \]
- en: where this holds if the categories, \(y_i\), are -1 or 1\. We need a model that
    allows for some misclassification,
  id: totrans-3621
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­å¦‚æœç±»åˆ« \(y_i\) æ˜¯ -1 æˆ– 1ï¼Œåˆ™æ­¤æ¡ä»¶æˆç«‹ã€‚æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå…è®¸æŸäº›é”™è¯¯åˆ†ç±»çš„æ¨¡å‹ï¼Œ
- en: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
  id: totrans-3622
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i \]
- en: We introduce the concept of a margin, \(ğ‘€\), and a distance from the margin,
    the error as \(\xi_i\). Now we can pose our loss function as,
  id: totrans-3623
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼•å…¥äº†è¾¹ç¼˜çš„æ¦‚å¿µ \(ğ‘€\) å’Œä»è¾¹ç¼˜çš„è·ç¦»ï¼Œè¯¯å·®ä¸º \(\xi_i\)ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬çš„æŸå¤±å‡½æ•°è¡¨ç¤ºä¸ºï¼Œ
- en: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
  id: totrans-3624
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N
    \xi_i \right) \]
- en: subject to, \(\xi_i \geq 0, \quad y_i \left( x_i^T \beta + \beta_0 \right) \geq
    M - \xi_i\).
  id: totrans-3625
  prefs: []
  type: TYPE_NORMAL
  zh: å—é™äºï¼Œ\(\xi_i \geq 0, \quad y_i \left( x_i^T \beta + \beta_0 \right) \geq M -
    \xi_i\)ã€‚
- en: This is the support vector machine loss function in the higher dimensional space,
    where ğ›½,ğ›½_0 are the multilinear model parameters.
  id: totrans-3626
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯åœ¨é«˜ç»´ç©ºé—´ä¸­çš„æ”¯æŒå‘é‡æœºæŸå¤±å‡½æ•°ï¼Œå…¶ä¸­ ğ›½,ğ›½_0 æ˜¯å¤šçº¿æ€§æ¨¡å‹å‚æ•°ã€‚
- en: Training the support vector machine, by finding the model parameters of the
    plane to maximize the margin, \(M\), while minimizing the error, \(\sum_{i=1}^N
    \xi_i\)
  id: totrans-3627
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ‰¾åˆ°æœ€å¤§åŒ–è¾¹ç¼˜ \(M\) å¹¶æœ€å°åŒ–è¯¯å·® \(\sum_{i=1}^N \xi_i\) çš„æ¨¡å‹å‚æ•°æ¥è®­ç»ƒæ”¯æŒå‘é‡æœºã€‚
- en: \(ğ‘ª\) hyperparameter weights the sum of errors, \(xi_ğ‘–\), higher \(ğ¶\), will
    result in reduced margin, \(M\), and lead to overfit
  id: totrans-3628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(ğ‘ª\) è¶…å‚æ•°åŠ æƒè¯¯å·®æ€»å’Œ \(xi_ğ‘–\)ï¼Œæ›´é«˜çš„ \(ğ¶\) å°†å¯¼è‡´è¾ƒå°çš„è¾¹ç¼˜ \(M\)ï¼Œå¹¶å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
- en: smaller margin, fewer data used to constrain the boundary, known as support
    vectors
  id: totrans-3629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¾ƒå°çš„è¾¹ç¼˜ï¼Œä½¿ç”¨è¾ƒå°‘çš„æ•°æ®æ¥çº¦æŸè¾¹ç•Œï¼Œç§°ä¸ºæ”¯æŒå‘é‡
- en: training data well within the correct side of the boundary have no influence
  id: totrans-3630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¾¹ç•Œæ­£ç¡®ä¸€ä¾§çš„è®­ç»ƒæ•°æ®æ²¡æœ‰å½±å“
- en: Here are some key aspects of support vector machines,
  id: totrans-3631
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æ”¯æŒå‘é‡æœºçš„å‡ ä¸ªå…³é”®æ–¹é¢ï¼Œ
- en: known as support vector machines, and not machine, because with a new kernel
    you get a new machine
  id: totrans-3632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¢«ç§°ä¸ºæ”¯æŒå‘é‡æœºï¼Œè€Œä¸æ˜¯æœºå™¨ï¼Œå› ä¸ºä½¿ç”¨æ–°çš„æ ¸å¯ä»¥å¾—åˆ°ä¸€ä¸ªæ–°çš„æœºå™¨
- en: there are many kernels available including polynomial and radial basis functions
  id: totrans-3633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰è®¸å¤šæ ¸å¯ç”¨ï¼ŒåŒ…æ‹¬å¤šé¡¹å¼å’Œå¾„å‘åŸºå‡½æ•°
- en: The primary hyperparameter is \(C\), the cost of
  id: totrans-3634
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦è¶…å‚æ•°æ˜¯ \(C\)ï¼Œå…¶æˆæœ¬ä¸º
- en: Hyperparameters are related to the choice of kernel, for example,
  id: totrans-3635
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°ä¸æ ¸çš„é€‰æ‹©æœ‰å…³ï¼Œä¾‹å¦‚ï¼Œ
- en: '*polynomial* - polynomial order'
  id: totrans-3636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¤šé¡¹å¼* - å¤šé¡¹å¼é˜¶æ•°'
- en: '*radial basis function* - \(\gamma\) inversely proportional to the distance
    influence of the training data'
  id: totrans-3637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¾„å‘åŸºå‡½æ•°* - \(\gamma\) ä¸è®­ç»ƒæ•°æ®çš„è·ç¦»å½±å“æˆåæ¯”'
- en: '**Tabular Data**'
  id: totrans-3638
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è¡¨æ ¼æ•°æ®**'
- en: 'Machine Learning Workflow Construction and Coding: data table with rows for
    each sample and columns for each feature'
  id: totrans-3639
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ„å»ºå’Œç¼–ç ï¼šå…·æœ‰æ¯è¡Œä»£è¡¨æ¯ä¸ªæ ·æœ¬å’Œæ¯åˆ—ä»£è¡¨æ¯ä¸ªç‰¹å¾çš„è¡¨æ ¼æ•°æ®
- en: Pandasâ€™ DataFrames are a convenient class for working with tabular data, due
    to,
  id: totrans-3640
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº Pandas çš„ DataFrame æ˜¯å¤„ç†è¡¨æ ¼æ•°æ®çš„ä¾¿æ·ç±»ï¼Œ
- en: convenient data structure to store, access, manipulate tabular data
  id: totrans-3641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹ä¾¿çš„æ•°æ®ç»“æ„ç”¨äºå­˜å‚¨ã€è®¿é—®ã€æ“ä½œè¡¨æ ¼æ•°æ®
- en: built-in methods to load data from a variety of file types, Python classes and
    even directly from Excel
  id: totrans-3642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºä»å„ç§æ–‡ä»¶ç±»å‹ã€Python ç±»ç”šè‡³ç›´æ¥ä» Excel åŠ è½½æ•°æ®
- en: built-in methods to calculate summary statistics and visualize data
  id: totrans-3643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºè®¡ç®—æ±‡æ€»ç»Ÿè®¡å’Œå¯è§†åŒ–æ•°æ®
- en: built-in methods for data queries, sort, data filters
  id: totrans-3644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºæ•°æ®æŸ¥è¯¢ã€æ’åºã€æ•°æ®ç­›é€‰
- en: built-in methods for data manipulation, cleaning, reformatting
  id: totrans-3645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®æ–¹æ³•ç”¨äºæ•°æ®å¤„ç†ã€æ¸…ç†ã€é‡æ–°æ ¼å¼åŒ–
- en: built-in attributes to store information about the data, e.g. size, number nulls
    and null value
  id: totrans-3646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†…ç½®å±æ€§ç”¨äºå­˜å‚¨æœ‰å…³æ•°æ®çš„ä¿¡æ¯ï¼Œä¾‹å¦‚å¤§å°ã€ç©ºå€¼æ•°é‡å’Œç©ºå€¼
- en: '**Training and Testing Splits**'
  id: totrans-3647
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): for model cross
    validation, prior to predictive model training withhold a proportion of the data
    as testing data.'
  id: totrans-3648
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨é¢„æµ‹æ¨¡å‹è®­ç»ƒä¹‹å‰ï¼Œä¸ºæ¨¡å‹äº¤å‰éªŒè¯ä¿ç•™ä¸€éƒ¨åˆ†æ•°æ®ä½œä¸ºæµ‹è¯•æ•°æ®ã€‚'
- en: training data are applied to train the model parameters, while withheld testing
    data are applied to tune the model hyperparameter
  id: totrans-3649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ•°æ®ç”¨äºè®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œè€Œä¿ç•™çš„æµ‹è¯•æ•°æ®ç”¨äºè°ƒæ•´æ¨¡å‹è¶…å‚æ•°
- en: hyperparameter tuning is selecting the hyperparameter combination that minimizes
    the error norm over the withheld testing data
  id: totrans-3650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°è°ƒæ•´æ˜¯é€‰æ‹©æœ€å°åŒ–ä¿ç•™æµ‹è¯•æ•°æ®ä¸Šè¯¯å·®èŒƒæ•°çš„è¶…å‚æ•°ç»„åˆ
- en: The most common approach is random selection, this may not be fair testing,
  id: totrans-3651
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¸¸è§çš„æ–¹æ³•æ˜¯éšæœºé€‰æ‹©ï¼Œè¿™å¯èƒ½ä¸æ˜¯å…¬å¹³çš„æµ‹è¯•ï¼Œ
- en: the range of testing difficulty is similar to the real-world use of the model
  id: totrans-3652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹è¯•éš¾åº¦çš„èŒƒå›´ä¸æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ç›¸ä¼¼
- en: too easy â€“ testing cases are the same or almost the same as training cases,
    random sampling is often too easy
  id: totrans-3653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤ªç®€å•äº† - æµ‹è¯•æ¡ˆä¾‹ä¸è®­ç»ƒæ¡ˆä¾‹ç›¸åŒæˆ–å‡ ä¹ç›¸åŒï¼ŒéšæœºæŠ½æ ·é€šå¸¸å¤ªç®€å•
- en: too hard â€“ testing cases are very different from the training cases, the model
    is expected to severely extrapolate
  id: totrans-3654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤ªéš¾äº† - æµ‹è¯•æ¡ˆä¾‹ä¸è®­ç»ƒæ¡ˆä¾‹éå¸¸ä¸åŒï¼Œæ¨¡å‹é¢„è®¡å°†ä¸¥é‡å¤–æ¨
- en: Alternative methods such as k-fold cross validation provide the opportunity
    for testing over all available data but require,
  id: totrans-3655
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ k æŠ˜äº¤å‰éªŒè¯ç­‰æ›¿ä»£æ–¹æ³•æä¾›äº†å¯¹æ‰€æœ‰å¯ç”¨æ•°æ®è¿›è¡Œæµ‹è¯•çš„æœºä¼šï¼Œä½†éœ€è¦ï¼Œ
- en: the training k predictive machine learning models over the hyperparameter combinations
  id: totrans-3656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¶…å‚æ•°ç»„åˆä¸Šè®­ç»ƒ k ä¸ªé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹
- en: aggregation of the testing error over the k models for selection of the optimum
    hyperparameters, hyperparameter tuning
  id: totrans-3657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹ k ä¸ªæ¨¡å‹çš„æµ‹è¯•é”™è¯¯è¿›è¡Œèšåˆï¼Œä»¥é€‰æ‹©æœ€ä½³è¶…å‚æ•°ï¼Œè¶…å‚æ•°è°ƒæ•´
- en: Also, there are alternative workflow that include, training, validation and
    testing subsets of the data
  id: totrans-3658
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œè¿˜æœ‰åŒ…æ‹¬è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®å­é›†çš„æ›¿ä»£å·¥ä½œæµç¨‹
- en: '**Transfer Function** (reservoir modeling workflow)'
  id: totrans-3659
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**è½¬ç§»å‡½æ•°**ï¼ˆå‚¨å±‚å»ºæ¨¡å·¥ä½œæµç¨‹ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): calculation applied
    to the spatial, subsurface model realizations and scenarios to calculate a decision
    criterion, a metric that is used to support decision making representing value,
    and health, environment and safety. Example transfer functions include,'
  id: totrans-3660
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåº”ç”¨äºç©ºé—´ã€åœ°ä¸‹æ¨¡å‹å®ç°å’Œåœºæ™¯çš„è®¡ç®—ï¼Œä»¥è®¡ç®—å†³ç­–æ ‡å‡†ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ”¯æŒå†³ç­–ã€è¡¨ç¤ºä»·å€¼å’Œå¥åº·ã€ç¯å¢ƒå’Œå®‰å…¨çš„æŒ‡æ ‡ã€‚ä¸€äº›ç¤ºä¾‹è½¬ç§»å‡½æ•°åŒ…æ‹¬ï¼Œ'
- en: '*transport and bioattenuation* - numerical simulation to model soil contaminant
    concentrations over time during a pump and treat operation'
  id: totrans-3661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è¿è¾“å’Œç”Ÿç‰©è¡°å‡* - æ•°å€¼æ¨¡æ‹Ÿä»¥æ¨¡æ‹Ÿæ³µå’Œæ²»å¤„ç†æ“ä½œæœŸé—´éšæ—¶é—´æ¨ç§»çš„åœŸå£¤æ±¡æŸ“ç‰©æµ“åº¦'
- en: '*volumetric calculation* - for total oil-in-place to calculate resource in
    place'
  id: totrans-3662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ä½“ç§¯è®¡ç®—* - ç”¨äºè®¡ç®—åŸåœ°æ€»æ²¹é‡ä»¥è®¡ç®—åŸåœ°èµ„æº'
- en: '*heterogeneity metric* - as an indicator of recovery factor to estimate reserves
    from resources'
  id: totrans-3663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å¼‚è´¨æ€§æŒ‡æ ‡* - ä½œä¸ºé‡‡æ”¶ç‡æŒ‡æ ‡ï¼Œç”¨äºä»èµ„æºä¼°è®¡å‚¨é‡'
- en: '*flow simulation* - for pre-drill production forecast for a planned well'
  id: totrans-3664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æµåŠ¨æ¨¡æ‹Ÿ* - ç”¨äºè®¡åˆ’äº•çš„é¢„é’»ç”Ÿäº§é¢„æµ‹'
- en: '*Whittleâ€™s pit optimization* - to calculate mineral resources and ultimate
    pit shell'
  id: totrans-3665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æƒ ç‰¹å°”çš„çŸ¿å‘ä¼˜åŒ–* - ç”¨äºè®¡ç®—çŸ¿äº§èµ„æºåŠå…¶æœ€ç»ˆçŸ¿å‘å£³ä½“'
- en: '**Uncertainty Modeling**'
  id: totrans-3666
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸ç¡®å®šæ€§å»ºæ¨¡**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): calculation of
    the range of possible values for a feature at a location or jointly over many
    locations at the sample time. Some considerations,'
  id: totrans-3667
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨æ ·æœ¬æ—¶é—´å¯¹ä½ç½®æˆ–å¤šä¸ªä½ç½®çš„å¯èƒ½çš„ç‰¹å¾å€¼èŒƒå›´çš„è®¡ç®—ã€‚ä¸€äº›è€ƒè™‘å› ç´ ï¼Œ'
- en: quantification of the limitation in the precision of our samples and model predictions
  id: totrans-3668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æˆ‘ä»¬çš„æ ·æœ¬å’Œæ¨¡å‹é¢„æµ‹ç²¾åº¦çš„é™åˆ¶è¿›è¡Œé‡åŒ–
- en: uncertainty is a model, there is no objective uncertainty
  id: totrans-3669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§æ˜¯ä¸€ä¸ªæ¨¡å‹ï¼Œæ²¡æœ‰å®¢è§‚çš„ä¸ç¡®å®šæ€§
- en: uncertainty is caused by our ignorance
  id: totrans-3670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§æ˜¯ç”±æˆ‘ä»¬çš„æ— çŸ¥å¼•èµ·çš„
- en: uncertainty is caused by sparse sampling, measurement error and bias, and heterogeneity
  id: totrans-3671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§æ˜¯ç”±ç¨€ç–é‡‡æ ·ã€æµ‹é‡è¯¯å·®å’Œåå·®ä»¥åŠå¼‚è´¨æ€§å¼•èµ·çš„
- en: 'we represent uncertainty by multiple models, scenarios and realizations:'
  id: totrans-3672
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡å¤šä¸ªæ¨¡å‹ã€åœºæ™¯å’Œå®ç°æ¥è¡¨ç¤ºä¸ç¡®å®šæ€§ï¼š
- en: Scenarios - multiple spatial, subsurface models calculated by stochastic simulation
    by changing the input parameters or other modeling choices to represent the uncertainty
    due to inference of model parameters and model choices
  id: totrans-3673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœºæ™¯ - é€šè¿‡æ”¹å˜è¾“å…¥å‚æ•°æˆ–å…¶ä»–å»ºæ¨¡é€‰æ‹©ï¼Œé€šè¿‡éšæœºæ¨¡æ‹Ÿè®¡ç®—å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹æ¥è¡¨ç¤ºç”±äºæ¨¡å‹å‚æ•°å’Œæ¨¡å‹é€‰æ‹©çš„æ¨æ–­å¼•èµ·çš„ä¸ç¡®å®šæ€§
- en: Realizations - multiple spatial, subsurface models calculated by stochastic
    simulation by holding input parameters and model choices constant and only changing
    the random number seed
  id: totrans-3674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ç° - é€šè¿‡ä¿æŒè¾“å…¥å‚æ•°å’Œæ¨¡å‹é€‰æ‹©ä¸å˜ï¼Œä»…æ”¹å˜éšæœºæ•°ç§å­æ¥è®¡ç®—å¤šä¸ªç©ºé—´ã€åœ°ä¸‹æ¨¡å‹
- en: '**Underfit Model**'
  id: totrans-3675
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¬ æ‹Ÿåˆæ¨¡å‹**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a machine learning
    model that too simple, too low complexity and flexibility, to fit the natural
    phenomenon resulting in very high model bias.'
  id: totrans-3676
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä¸€ä¸ªè¿‡äºç®€å•ã€å¤æ‚æ€§å’Œçµæ´»æ€§å¤ªä½ï¼Œæ— æ³•æ‹Ÿåˆè‡ªç„¶ç°è±¡çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¯¼è‡´æ¨¡å‹åå·®éå¸¸é«˜ã€‚'
- en: underfit models often approach the response feature global mean
  id: totrans-3677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¬ æ‹Ÿåˆæ¨¡å‹é€šå¸¸æ¥è¿‘å“åº”ç‰¹å¾çš„å…¨çƒå‡å€¼
- en: underfit models have high error over training and testing data
  id: totrans-3678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿‡æ‹Ÿåˆæ¨¡å‹åœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸Šå…·æœ‰é«˜è¯¯å·®
- en: increased complexity will generally decrease error with respect to the training
    and testing dataset
  id: totrans-3679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¢åŠ çš„å¤æ‚æ€§é€šå¸¸ä¼šåœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä¸Šé™ä½é”™è¯¯
- en: over the region of model complexity with falling training and testing error
  id: totrans-3680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¨¡å‹å¤æ‚åº¦ä¸‹é™çš„è®­ç»ƒå’Œæµ‹è¯•é”™è¯¯åŒºåŸŸ
- en: Issues of an underfit machine learning model,
  id: totrans-3681
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‡æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„é—®é¢˜ï¼Œ
- en: more model complexity and flexibility is insufficient given the available data,
    data accuracy, frequency and coverage
  id: totrans-3682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç»™å®šçš„æ•°æ®ã€æ•°æ®ç²¾åº¦ã€é¢‘ç‡å’Œè¦†ç›–èŒƒå›´ä¸‹ï¼Œæ›´å¤šçš„æ¨¡å‹å¤æ‚æ€§å’Œçµæ´»æ€§æ˜¯ä¸å¤Ÿçš„
- en: low accuracy in training and testing representing real-world use away from training
    data cases, indicating poor ability of the model to generalize
  id: totrans-3683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œæµ‹è¯•ä¸­çš„ä½ç²¾åº¦è¡¨ç¤ºè¿œç¦»è®­ç»ƒæ•°æ®æ¡ˆä¾‹çš„ç°å®ä¸–ç•Œä½¿ç”¨ï¼Œè¡¨æ˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›å·®
- en: '**Union of Events** (probability)'
  id: totrans-3684
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**äº‹ä»¶çš„å¹¶é›†**ï¼ˆæ¦‚ç‡ï¼‰'
- en: '[Probability Concepts](MachineLearning_probability.html): the union of outcomes,
    the probability of \(A\) or \(B\) is calculated with the probability addition
    rule,'
  id: totrans-3685
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šç»“æœçš„å¹¶é›†ï¼Œ\(A\) æˆ– \(B\) çš„æ¦‚ç‡é€šè¿‡æ¦‚ç‡åŠ æ³•è§„åˆ™è®¡ç®—ï¼Œ'
- en: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
  id: totrans-3686
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A,B) \]
- en: '**Univariate Parameters**'
  id: totrans-3687
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å•å˜é‡å‚æ•°**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): summary measures
    based on one feature measured over the population'
  id: totrans-3688
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šåŸºäºå¯¹æ€»ä½“ä¸­ä¸€ä¸ªç‰¹å¾æµ‹é‡çš„æ±‡æ€»åº¦é‡'
- en: '**Univariate Statistics**'
  id: totrans-3689
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å•å˜é‡ç»Ÿè®¡**'
- en: '[Univariate Analysis](MachineLearning_univariate_analysis.html): summary measures
    based on one feature measured over the samples'
  id: totrans-3690
  prefs: []
  type: TYPE_NORMAL
  zh: '[å•å˜é‡åˆ†æ](MachineLearning_univariate_analysis.html)ï¼šåŸºäºå¯¹æ ·æœ¬ä¸­ä¸€ä¸ªç‰¹å¾æµ‹é‡çš„æ±‡æ€»åº¦é‡'
- en: '**Unsupervised Learning**'
  id: totrans-3691
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ— ç›‘ç£å­¦ä¹ **'
- en: 'Cluster Analysis: learning patterns in data from unlabeled data.'
  id: totrans-3692
  prefs: []
  type: TYPE_NORMAL
  zh: èšç±»åˆ†æï¼šä»æœªæ ‡è®°æ•°æ®ä¸­å­¦ä¹ æ•°æ®æ¨¡å¼ã€‚
- en: no response features, \(ğ‘Œ\), instead only predictor features, \(ğ‘‹_1,ldots,ğ‘‹_ğ‘š\)
  id: totrans-3693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰å“åº”ç‰¹å¾ \(ğ‘Œ\)ï¼Œè€Œæ˜¯åªæœ‰é¢„æµ‹ç‰¹å¾ \(ğ‘‹_1,ldots,ğ‘‹_ğ‘š\)
- en: machine learns by mimicry a compact representation of the data
  id: totrans-3694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœºå™¨é€šè¿‡æ¨¡ä»¿æ•°æ®çš„ç´§å‡‘è¡¨ç¤ºæ¥å­¦ä¹ 
- en: captures patterns as feature projections, group assignments, neural network
    latent features, etc.
  id: totrans-3695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ¨¡å¼æ•æ‰ä¸ºç‰¹å¾æŠ•å½±ã€åˆ†ç»„åˆ†é…ã€ç¥ç»ç½‘ç»œæ½œåœ¨ç‰¹å¾ç­‰ã€‚
- en: focus on inference of the population, the natural system, instead of prediction
    of response features
  id: totrans-3696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸“æ³¨äºå¯¹æ€»ä½“ã€è‡ªç„¶ç³»ç»Ÿçš„æ¨æ–­ï¼Œè€Œä¸æ˜¯å“åº”ç‰¹å¾çš„é¢„æµ‹
- en: In this course we use the terms inferential and predictive machine learning,
    all the covered inferential machine learning methods are unsupervised.
  id: totrans-3697
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨æ–­å’Œé¢„æµ‹æœºå™¨å­¦ä¹ çš„æœ¯è¯­ï¼Œæ‰€æœ‰æ¶µç›–çš„æ¨æ–­æœºå™¨å­¦ä¹ æ–¹æ³•éƒ½æ˜¯æ— ç›‘ç£çš„ã€‚
- en: '**Variable** (also feature)'
  id: totrans-3698
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å˜é‡**ï¼ˆä¹Ÿç§°ä¸ºç‰¹å¾ï¼‰'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): any property measured
    or observed in a study, for example,'
  id: totrans-3699
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šåœ¨ç ”ç©¶ä¸­æµ‹é‡æˆ–è§‚å¯Ÿåˆ°çš„ä»»ä½•å±æ€§ï¼Œä¾‹å¦‚ï¼Œ'
- en: porosity, permeability, mineral concentrations, saturations, contaminant concentration
  id: totrans-3700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ã€æ¸—é€ç‡ã€çŸ¿ç‰©æµ“åº¦ã€é¥±å’Œåº¦ã€æ±¡æŸ“ç‰©æµ“åº¦
- en: in data mining / machine learning this is known as a *feature*
  id: totrans-3701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®æŒ–æ˜/æœºå™¨å­¦ä¹ ä¸­ï¼Œè¿™è¢«ç§°ä¸º *ç‰¹å¾*
- en: measure often requires significant analysis, interpretation, etc.
  id: totrans-3702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹é‡é€šå¸¸éœ€è¦å¤§é‡çš„åˆ†æã€è§£é‡Šç­‰ã€‚
- en: '**Variance Inflation Factor** (VIF)'
  id: totrans-3703
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ–¹å·®è†¨èƒ€å› å­** (VIF)'
- en: '[Feature Ranking](MachineLearning_feature_ranking.html): a measure of linear
    multicollinearity between a predictor feature (\(X_i\)) a nd all other predictor
    features (\(X_j, \forall j \ne i\)).'
  id: totrans-3704
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾æ’åº](MachineLearning_feature_ranking.html)ï¼šè¡¡é‡é¢„æµ‹ç‰¹å¾ï¼ˆ\(X_i\)ï¼‰ä¸æ‰€æœ‰å…¶ä»–é¢„æµ‹ç‰¹å¾ï¼ˆ\(X_j,
    \forall j \ne i\)ï¼‰ä¹‹é—´çš„çº¿æ€§å¤šé‡å…±çº¿æ€§ã€‚'
- en: First we calculate a linear regression for a predictor feature given all the
    other predictor features.
  id: totrans-3705
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬é’ˆå¯¹æ‰€æœ‰å…¶ä»–é¢„æµ‹ç‰¹å¾è®¡ç®—ç»™å®šé¢„æµ‹ç‰¹å¾çš„çº¿æ€§å›å½’ã€‚
- en: \[ X_i = \sum_{j, j \ne i}^m X_j + \epsilon \]
  id: totrans-3706
  prefs: []
  type: TYPE_NORMAL
  zh: \[ X_i = \sum_{j, j \ne i}^m X_j + \epsilon \]
- en: From this model we determine the coefficient of determination, \(R^2\), known
    as variance explained.
  id: totrans-3707
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬ç¡®å®šç¡®å®šç³»æ•° \(R^2\)ï¼Œç§°ä¸ºæ–¹å·®è§£é‡Šã€‚
- en: 'Then we calculate the Variance Inflation Factor as:'
  id: totrans-3708
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è®¡ç®—æ–¹å·®è†¨èƒ€å› å­ï¼ˆVIFï¼‰å¦‚ä¸‹ï¼š
- en: \[ VIF = \frac{1}{1 - R^2} \]
  id: totrans-3709
  prefs: []
  type: TYPE_NORMAL
  zh: \[ VIF = \frac{1}{1 - R^2} \]
- en: '**Volume-Variance Relations**'
  id: totrans-3710
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä½“ç§¯-æ–¹å·®å…³ç³»**'
- en: '[Feature Transformations](MachineLearning_feature_transformations.html): as
    the *volume support* (scale) increases the variance reduces'
  id: totrans-3711
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç‰¹å¾å˜æ¢](MachineLearning_feature_transformations.html)ï¼šå½“ *ä½“ç§¯æ”¯æ’‘*ï¼ˆå°ºåº¦ï¼‰å¢åŠ æ—¶ï¼Œæ–¹å·®å‡å°‘'
- en: Predicting volume-variance relations is central to handling multiple scales
    of data and models. Some general observations and assumptions,
  id: totrans-3712
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ä½“ç§¯-æ–¹å·®å…³ç³»æ˜¯å¤„ç†æ•°æ®å’Œå¤šå°ºåº¦æ¨¡å‹çš„å…³é”®ã€‚ä¸€äº›ä¸€èˆ¬è§‚å¯Ÿå’Œå‡è®¾ï¼Œ
- en: the mean does not change as the volume support, scale changes. Only the variance
    changes
  id: totrans-3713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ä½“ç§¯æ”¯æ’‘ã€å°ºåº¦å˜åŒ–æ—¶ï¼Œå‡å€¼ä¸ä¼šæ”¹å˜ã€‚åªæœ‰æ–¹å·®ä¼šæ”¹å˜
- en: there may be shape change (we will not tackle that here). Best practice is to
    check shape change empirically. It is common to assume no shape change (*affine
    correction*) or to use a shape change model (indirect lognormal correction).
  id: totrans-3714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯èƒ½ä¼šæœ‰å½¢çŠ¶å˜åŒ–ï¼ˆæˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šå¤„ç†è¿™ä¸€ç‚¹ï¼‰ã€‚æœ€ä½³å®è·µæ˜¯ç»éªŒæ€§åœ°æ£€æŸ¥å½¢çŠ¶å˜åŒ–ã€‚é€šå¸¸å‡è®¾æ²¡æœ‰å½¢çŠ¶å˜åŒ–ï¼ˆ*ä»¿å°„æ ¡æ­£*ï¼‰æˆ–ä½¿ç”¨å½¢çŠ¶å˜åŒ–æ¨¡å‹ï¼ˆé—´æ¥å¯¹æ•°æ­£æ€æ ¡æ­£ï¼‰ã€‚
- en: the variance reduction in the distribution is inversely proportional to the
    range of spatial continuity. Variance reduces faster (over smaller volume increase)
    for shorter spatial continuity ranges.
  id: totrans-3715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒä¸­çš„æ–¹å·®å‡å°‘ä¸ç©ºé—´è¿ç»­æ€§çš„èŒƒå›´æˆåæ¯”ã€‚å¯¹äºè¾ƒçŸ­çš„ç©ºé—´è¿ç»­æ€§èŒƒå›´ï¼Œæ–¹å·®å‡å°‘å¾—æ›´å¿«ï¼ˆåœ¨è¾ƒå°çš„ä½“ç§¯å¢åŠ ä¸Šï¼‰ã€‚
- en: Over common changes in scale this impact may be significant; therefore, it is
    not appropriate to ignore volume-variance relations,
  id: totrans-3716
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¸¸è§çš„å°ºåº¦å˜åŒ–ä¸­ï¼Œè¿™ç§å½±å“å¯èƒ½æ˜¯æ˜¾è‘—çš„ï¼›å› æ­¤ï¼Œå¿½ç•¥ä½“ç§¯-æ–¹å·®å…³ç³»æ˜¯ä¸åˆé€‚çš„ï¼Œ
- en: we donâ€™t do this scale up, change in volume support perfectly, and this is why
    it is still called the missing scale. We rarely have enough data to model this
    rigorously
  id: totrans-3717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸è¿›è¡Œè¿™ç§å°ºåº¦æ”¾å¤§ï¼Œä½“ç§¯æ”¯æ’‘çš„å˜åŒ–å®Œç¾æ— ç¼ºï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒä»ç„¶è¢«ç§°ä¸ºç¼ºå¤±å°ºåº¦ã€‚æˆ‘ä»¬å¾ˆå°‘æ‹¥æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ä¸¥æ ¼åœ°æ¨¡æ‹Ÿè¿™ä¸€ç‚¹
- en: we need a model to predict this change in variance with change in volume support
  id: totrans-3718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹è¿™ç§æ–¹å·®éšä½“ç§¯æ”¯æ’‘å˜åŒ–çš„å˜åŒ–
- en: There are some change in volume support, scale models,
  id: totrans-3719
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨ä¸€äº›ä½“ç§¯æ”¯æ’‘ã€å°ºåº¦æ¨¡å‹çš„å˜åŒ–ï¼Œ
- en: '*Empirical* - build a small scale, high resolution model and scale it up numerically.
    For example, calculate a high resolution model of permeability, apply flow simulation
    to calculate effective permeability over \(v\) scale blocks'
  id: totrans-3720
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç»éªŒæ€§* - å»ºç«‹ä¸€ä¸ªå°å°ºåº¦ã€é«˜åˆ†è¾¨ç‡æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ•°å€¼æ”¾å¤§ã€‚ä¾‹å¦‚ï¼Œè®¡ç®—æ¸—é€ç‡çš„é«˜åˆ†è¾¨ç‡æ¨¡å‹ï¼Œåº”ç”¨æµåŠ¨æ¨¡æ‹Ÿæ¥è®¡ç®— \(v\) å°ºåº¦å—ä¸Šçš„æœ‰æ•ˆæ¸—é€ç‡'
- en: '*Power Law Averaging* - there is a flexible approach known as power law averaging.'
  id: totrans-3721
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¹‚å¾‹å¹³å‡* - æœ‰ä¸€ç§ç§°ä¸ºå¹‚å¾‹å¹³å‡çš„çµæ´»æ–¹æ³•ã€‚'
- en: \[ z_V = \left[ \frac{1}{n} \sum z_v^{\omega} \right] ^{\frac{1}{\omega}} \]
  id: totrans-3722
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z_V = \left[ \frac{1}{n} \sum z_v^{\omega} \right] ^{\frac{1}{\omega}} \]
- en: 'where \(\omega\) is the power of averaging. For example:'
  id: totrans-3723
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\omega\) æ˜¯å¹³å‡çš„å¹‚ã€‚ä¾‹å¦‚ï¼š
- en: \(\omega = 1\) is a regular linear averaging
  id: totrans-3724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\omega = 1\) æ˜¯å¸¸è§„çº¿æ€§å¹³å‡
- en: \(\omega = -1\) is a harmonic averaging
  id: totrans-3725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\omega = -1\) æ˜¯è°æ³¢å¹³å‡
- en: \(\omega = 0\) is a geometric averaging (this is proved in the limit as \(\omega
    \rightarrow 0\))
  id: totrans-3726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\omega = 0\) æ˜¯å‡ ä½•å¹³å‡ï¼ˆè¿™å·²åœ¨ \(\omega \rightarrow 0\) çš„æé™ä¸­å¾—åˆ°è¯æ˜ï¼‰
- en: How to calculate \(\omega\)?
  id: totrans-3727
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•è®¡ç®— \(\omega\)ï¼Ÿ
- en: for some cases we know from theory the correct \(\omega\) value, for example,
    for flow orthogonal to beds we select \(\omega = -1.0\) to scale up permeability
  id: totrans-3728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæŸäº›æƒ…å†µï¼Œæˆ‘ä»¬ä»ç†è®ºä¸­çŸ¥é“æ­£ç¡®çš„ \(\omega\) å€¼ï¼Œä¾‹å¦‚ï¼Œå¯¹äºä¸åºŠå±‚æ­£äº¤çš„æµåŠ¨ï¼Œæˆ‘ä»¬é€‰æ‹© \(\omega = -1.0\) æ¥æ”¾å¤§æ¸—é€ç‡
- en: flow simulation may be applied to numerically scale up permeability and then
    to back-calculate a calibrated \(\omega\)
  id: totrans-3729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµåŠ¨æ¨¡æ‹Ÿå¯ä»¥åº”ç”¨äºæ•°å€¼æ”¾å¤§æ¸—é€ç‡ï¼Œç„¶ååå‘è®¡ç®—æ ¡å‡†çš„ \(\omega\)
- en: '*Model* - directly adjust the statistics for change in scale. For example,
    under the assumption of linear averaging and a stationary variogram and variance:'
  id: totrans-3730
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ¨¡å‹* - ç›´æ¥è°ƒæ•´ç»Ÿè®¡é‡ä»¥æ”¹å˜å°ºåº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨å‡è®¾çº¿æ€§å¹³å‡å’Œé™æ€å˜å·®å‡½æ•°åŠæ–¹å·®çš„æƒ…å†µä¸‹ï¼š'
- en: \[ f = 1 - \frac{\overline{\gamma}(v,v)}{\sigma^2} \]
  id: totrans-3731
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f = 1 - \frac{\overline{\gamma}(v,v)}{\sigma^2} \]
- en: where \(f\) is variance reduction factor,
  id: totrans-3732
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(f\) æ˜¯æ–¹å·®å‡å°‘å› å­ï¼Œ
- en: \[ f = \frac{D^2(v,V)}{D^2(\cdot,V)} = \frac{D^2(v,V)}{\sigma^2} \]
  id: totrans-3733
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f = \frac{D^2(v,V)}{D^2(\cdot,V)} = \frac{D^2(v,V)}{\sigma^2} \]
- en: in other words, \(f\) is the ratio of the variance at scale \(v\) to the variance
    at the original data point support scale based on,
  id: totrans-3734
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œ\(f\) æ˜¯åœ¨ \(v\) å°ºåº¦ä¸Šçš„æ–¹å·®ä¸åŸºäºåŸå§‹æ•°æ®ç‚¹æ”¯æŒå°ºåº¦çš„åŸå§‹æ•°æ®æ–¹å·®ä¹‹æ¯”
- en: the variogram model
  id: totrans-3735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å˜å·®å‡½æ•°æ¨¡å‹
- en: the scale of the data, \(\cdot\) and the scale of \(v\)
  id: totrans-3736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®çš„å°ºåº¦ï¼Œ\(\cdot\) å’Œ \(v\) çš„å°ºåº¦
- en: '**Venn Diagrams**'
  id: totrans-3737
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç»´æ©å›¾**'
- en: '[Probability Concepts](MachineLearning_probability.html): a plot, visual tool
    for communicating probability. What do we learn from a Venn diagram?'
  id: totrans-3738
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¦‚ç‡æ¦‚å¿µ](MachineLearning_probability.html)ï¼šä¸€ç§å›¾è¡¨ï¼Œç”¨äºä¼ è¾¾æ¦‚ç‡çš„è§†è§‰å·¥å…·ã€‚æˆ‘ä»¬ä»ç»´æ©å›¾ä¸­èƒ½å­¦åˆ°ä»€ä¹ˆï¼Ÿ'
- en: size of regions \(\propto\) probability of occurrence
  id: totrans-3739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŒºåŸŸçš„å¤§å° \(\propto\) å‘ç”Ÿçš„æ¦‚ç‡
- en: proportion of \(\Omega\), all possible outcomes represented by a box, i.e.,
    probability of \(1.0\)
  id: totrans-3740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\Omega\) çš„æ¯”ä¾‹ï¼Œæ‰€æœ‰å¯èƒ½çš„ç»“æœéƒ½ç”±ä¸€ä¸ªæ–¹æ¡†è¡¨ç¤ºï¼Œå³ \(1.0\) çš„æ¦‚ç‡
- en: overlap \(\propto\) probability of joint occurrence
  id: totrans-3741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é‡å  \(\propto\) è”åˆå‘ç”Ÿçš„æ¦‚ç‡
- en: Venn diagrams are an excellent tool to visualize marginal, joint and conditional
    probability.
  id: totrans-3742
  prefs: []
  type: TYPE_NORMAL
  zh: ç»´æ©å›¾æ˜¯å¯è§†åŒ–è¾¹ç¼˜ã€è”åˆå’Œæ¡ä»¶æ¦‚ç‡çš„ä¸€ä¸ªä¼˜ç§€å·¥å…·ã€‚
- en: '**Well Log Data**'
  id: totrans-3743
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æµ‹äº•æ•°æ®**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): as a much cheaper
    method to sample wells that does not interrupt drilling operations, well logs
    are very common over the wells. Often all wells have various well logs available.
    For example,'
  id: totrans-3744
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼šä½œä¸ºä¸€ç§æ›´ä¾¿å®œçš„é‡‡æ ·äº•çš„æ–¹æ³•ï¼Œå®ƒä¸ä¼šä¸­æ–­é’»äº•ä½œä¸šï¼Œæµ‹äº•æ•°æ®åœ¨äº•ä¸­éå¸¸å¸¸è§ã€‚é€šå¸¸æ‰€æœ‰äº•éƒ½æœ‰å„ç§æµ‹äº•æ•°æ®å¯ç”¨ã€‚ä¾‹å¦‚ï¼Œ'
- en: gamma ray on pilot vertical wells to assess the locations and quality of shales
    for targeting (landing) horizontal wells
  id: totrans-3745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è¯•éªŒå‚ç›´äº•ä¸­çš„ä¼½é©¬å°„çº¿ç”¨äºè¯„ä¼°é¡µå²©çš„ä½ç½®å’Œè´¨é‡ï¼Œä»¥å®šä½ï¼ˆç€é™†ï¼‰æ°´å¹³äº•
- en: neutron porosity to assess location high porosity reservoir sands
  id: totrans-3746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸­å­å­”éš™ç‡ç”¨äºè¯„ä¼°é«˜å­”éš™ç‡å‚¨å±‚ç ‚å²©çš„ä½ç½®
- en: gamma ray in drill holes to map thorium mineralization
  id: totrans-3747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é’»å­”ä¸­çš„ä¼½é©¬å°„çº¿ç”¨äºç»˜åˆ¶é’çŸ¿åŒ–
- en: Well log data are critical to support subsurface resource interpretations. Once
    anchored by core data they provide the essential coverage and resolution to model
    the entire reservoir concept / framework for prediction, for example,
  id: totrans-3748
  prefs: []
  type: TYPE_NORMAL
  zh: å²©å¿ƒæµ‹äº•æ•°æ®å¯¹äºæ”¯æŒåœ°ä¸‹èµ„æºè§£é‡Šè‡³å…³é‡è¦ã€‚ä¸€æ—¦ç”±å²©å¿ƒæ•°æ®é”šå®šï¼Œå®ƒä»¬æä¾›äº†å»ºæ¨¡æ•´ä¸ªå‚¨å±‚æ¦‚å¿µ/æ¡†æ¶è¿›è¡Œé¢„æµ‹æ‰€å¿…éœ€çš„è¦†ç›–èŒƒå›´å’Œåˆ†è¾¨ç‡ï¼Œä¾‹å¦‚ï¼Œ
- en: well log data calibrated by core data collocated with well log data are used
    to map the critical stratigraphic layers, including reservoir and seal units
  id: totrans-3749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸æµ‹äº•æ•°æ®åŒä½æ ¡å‡†çš„å²©å¿ƒæ•°æ®ç”¨äºç»˜åˆ¶å…³é”®çš„åœ°å±‚å±‚ä½ï¼ŒåŒ…æ‹¬å‚¨å±‚å’Œå°å µå•å…ƒ
- en: well logs are applied to depth correct features inverted from seismic that have
    location imprecision due to uncertainty in the rock velocity over the volume of
    interest
  id: totrans-3750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æµ‹äº•æ•°æ®åº”ç”¨äºæ·±åº¦æ ¡æ­£ç”±äºåœ¨æ„Ÿå…´è¶£ä½“ç§¯å†…å²©çŸ³é€Ÿåº¦çš„ä¸ç¡®å®šæ€§è€Œä½ç½®ä¸ç²¾ç¡®çš„åœ°éœ‡åæ¼”ç‰¹å¾
- en: '**Weak Learner**'
  id: totrans-3751
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¼±å­¦ä¹ å™¨**'
- en: '[Gradient Boosting](MachineLearning_gradient_boosting.html): the prediction
    model performs only marginally better than random'
  id: totrans-3752
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](MachineLearning_gradient_boosting.html)ï¼šé¢„æµ‹æ¨¡å‹çš„è¡¨ç°ä»…ç•¥å¥½äºéšæœº'
- en: \[ ğ‘Œ = \hat{f}_ğ‘˜(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š) \]
  id: totrans-3753
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ğ‘Œ = \hat{f}_ğ‘˜(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š) \]
- en: where \(\hat{f}_ğ‘˜\) is the \(ğ‘˜^{th}\) weak learner, \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\) are the
    predictor features, \(\hat{Y}\) is the prediction of the response feature.
  id: totrans-3754
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\hat{f}_ğ‘˜\) æ˜¯ç¬¬ \(ğ‘˜\) ä¸ªå¼±å­¦ä¹ å™¨ï¼Œ\(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\) æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œ\(\hat{Y}\) æ˜¯å“åº”ç‰¹å¾çš„é¢„æµ‹ã€‚
- en: The term weak predictor is often used, and specifically the term weak classifier
    for the case of classification models.
  id: totrans-3755
  prefs: []
  type: TYPE_NORMAL
  zh: å¼±é¢„æµ‹å™¨è¿™ä¸ªæœ¯è¯­ç»å¸¸è¢«ä½¿ç”¨ï¼Œå¹¶ä¸”å…·ä½“æ¥è¯´ï¼Œå¯¹äºåˆ†ç±»æ¨¡å‹çš„æƒ…å†µï¼Œæœ¯è¯­æ˜¯å¼±åˆ†ç±»å™¨ã€‚
- en: '**Well Log Data, Image Logs**'
  id: totrans-3756
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æµ‹äº•æ•°æ®ï¼Œå›¾åƒæµ‹äº•**'
- en: '[Machine Learning Concepts](MachineLearning_concepts.html): a special case
    of *well logs* where the well logs are repeated at various azimuthal intervals
    within the well bore resulting in a 2D (unwrapped) image instead of a 1D line
    along the well bore. For example, Fullbore formation MicroImager (FMI) with:'
  id: totrans-3757
  prefs: []
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ æ¦‚å¿µ](MachineLearning_concepts.html)ï¼š*æµ‹äº•æ•°æ®*çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œå…¶ä¸­æµ‹äº•æ•°æ®åœ¨äº•å­”å†…çš„å„ç§æ–¹ä½è§’é—´éš”å†…é‡å¤ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ªäºŒç»´ï¼ˆå±•å¼€ï¼‰å›¾åƒï¼Œè€Œä¸æ˜¯æ²¿äº•å­”çš„
    1D çº¿ã€‚ä¾‹å¦‚ï¼Œå…¨å­”å¾„åœ°å±‚å¾®æˆåƒä»ªï¼ˆFMIï¼‰å…·æœ‰ï¼š'
- en: with 80% bore hole coverage
  id: totrans-3758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥ 80% çš„é’»å­”è¦†ç›–ç‡
- en: 0.2 inch (0.5 cm) resolution vertical and horizontal
  id: totrans-3759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0.2 è‹±å¯¸ï¼ˆ0.5 å˜ç±³ï¼‰çš„å‚ç›´å’Œæ°´å¹³åˆ†è¾¨ç‡
- en: 30 inch (79 cm) depth of investigation
  id: totrans-3760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30 è‹±å¯¸ï¼ˆ79 å˜ç±³ï¼‰çš„æ¢æµ‹æ·±åº¦
- en: can be applied to observe lithology change, bed dips and sedimentary structures.
  id: totrans-3761
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥åº”ç”¨äºè§‚å¯Ÿå²©æ€§å˜åŒ–ã€å±‚å€¾è§’å’Œæ²‰ç§¯ç»“æ„ã€‚
- en: Comments
  id: totrans-3762
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„è®º
- en: This was a basic introduction to geostatistics. If you would like more on these
    fundamental concepts I recommend the Introduction, Modeling Principles and Modeling
    Prerequisites chapters from my text book, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446){cite}`pyrcz2014â€™.
  id: totrans-3763
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯¹åœ°ç»Ÿè®¡å­¦çš„åŸºæœ¬ä»‹ç»ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºè¿™äº›åŸºæœ¬æ¦‚å¿µï¼Œæˆ‘å»ºè®®æ‚¨é˜…è¯»æˆ‘çš„æ•™ç§‘ä¹¦ã€Šåœ°ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡ã€‹ä¸­çš„ä»‹ç»ã€å»ºæ¨¡åŸç†å’Œå»ºæ¨¡å…ˆå†³æ¡ä»¶ç« èŠ‚ã€‚[Geostatistical
    Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446){cite}`pyrcz2014â€™ã€‚
- en: I hope this is helpful,
  id: totrans-3764
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™æœ‰æ‰€å¸®åŠ©ï¼Œ
- en: '*Michael*'
  id: totrans-3765
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: 'The Author:'
  id: totrans-3766
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½œè€…ï¼š
- en: Michael Pyrcz, Professor, The University of Texas at Austin *Novel Data Analytics,
    Geostatistics and Machine Learning Subsurface Solutions*
  id: totrans-3767
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”å¥‡ï¼ˆMichael Pyrczï¼‰ï¼Œæ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ *æ–°å‹æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ åœ°ä¸‹è§£å†³æ–¹æ¡ˆ*
- en: With over 17 years of experience in subsurface consulting, research and development,
    Michael has returned to academia driven by his passion for teaching and enthusiasm
    for enhancing engineersâ€™ and geoscientistsâ€™ impact in subsurface resource development.
  id: totrans-3768
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åœ°ä¸‹å’¨è¯¢ã€ç ”ç©¶å’Œå¼€å‘é¢†åŸŸæ‹¥æœ‰è¶…è¿‡17å¹´ç»éªŒï¼Œè¿ˆå…‹å°”ï¼ˆMichaelï¼‰å› å¯¹æ•™å­¦çš„çƒ­æƒ…å’Œå¯¹å¢å¼ºå·¥ç¨‹å¸ˆå’Œåœ°çƒç§‘å­¦å®¶åœ¨åœ°ä¸‹èµ„æºå¼€å‘ä¸­å½±å“åŠ›çš„çƒ­æƒ…ï¼Œé‡è¿”å­¦æœ¯ç•Œã€‚
- en: 'For more about Michael check out these links:'
  id: totrans-3769
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šå…³äºè¿ˆå…‹å°”çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ä»¥ä¸‹é“¾æ¥ï¼š
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-3770
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
- en: Want to Work Together?
  id: totrans-3771
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-3772
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™äº›å†…å®¹å¯¹é‚£äº›æƒ³äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«éƒ½æ¬¢è¿å‚åŠ ã€‚
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  id: totrans-3773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster,
    Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling
    and machine learning theory with practice to develop novel methods and workflows
    to add value. We are solving challenging subsurface problems!
  id: totrans-3774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£åˆä½œã€æ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººåŒ…æ‹¬Fosteræ•™æˆã€Torres-Verdinæ•™æˆå’Œvan Oortæ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶å°†æ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µç›¸ç»“åˆï¼Œä»¥å¼€å‘æ–°çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ï¼Œå¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-3775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)è”ç³»æˆ‘ã€‚
- en: Iâ€™m always happy to discuss,
  id: totrans-3776
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯ä¹äºè®¨è®ºï¼Œ
- en: '*Michael*'
  id: totrans-3777
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-3778
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”å¥‡ï¼Œåšå£«ï¼ŒP.Eng. æ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ Cockrellå·¥ç¨‹å­¦é™¢å’ŒJacksonåœ°çƒç§‘å­¦å­¦é™¢
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-3779
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šèµ„æºå¯åœ¨ä»¥ä¸‹é“¾æ¥æ‰¾åˆ°ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
