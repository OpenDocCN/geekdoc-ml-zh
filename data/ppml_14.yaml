- en: Chapter 8 Documenting Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 记录管道
- en: 原文：[https://ppml.dev/documenting-code.html](https://ppml.dev/documenting-code.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ppml.dev/documenting-code.html](https://ppml.dev/documenting-code.html)
- en: 'Ideally, the code we write should be self-explanatory: everyone should be able
    to understand how it works and why it was implemented the way it was just by reading
    it. In practice, this aspiration is impossible to achieve for real-world codebases
    of any significant size even if we put effort into making code as clear as possible
    (Chapter [6](writing-code.html#writing-code)). Hence we need *documentation*:
    a living, natural-language explanation of the machine learning systems and of
    the pipeline that evolves along with them.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们编写的代码应该是自我解释的：每个人都应该能够仅通过阅读就能理解其工作原理以及为什么以这种方式实现。在实践中，即使我们尽力使代码尽可能清晰（第[6](writing-code.html#writing-code)章），对于任何具有一定规模的现实世界代码库来说，实现这一目标也是不可能的。因此，我们需要*文档*：对机器学习系统和与其一起演变的管道的活生生的、自然语言解释。
- en: 'Documentation is not a single entity, but rather a collection of information
    with different scopes, levels of detail, technical levels and audiences: comments
    explaining the “whats” and especially the “whys” of different chunks of code (Section
    [8.1](documenting-code.html#comments)); documents describing the public interface
    of each module and how to use it (Section [8.2](documenting-code.html#apidocs));
    a holistic description of how the pipeline is structured and of how its parts
    fit together (Section [8.3](documenting-code.html#designdocs)); white papers detailing
    what machine learning models have been implemented and why, and what business
    or academic needs they address (Section [8.4](documenting-code.html#domaindocs)).
    To complement these pieces of information, we should showcase how we envisage
    the machine learning pipeline will be used in practical day-to-day operations
    (Section [8.5](documenting-code.html#usecases)).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 文档不是一个单一实体，而是一系列具有不同范围、详细程度、技术水平和受众的信息集合：注释解释代码的不同部分“是什么”以及特别是“为什么”（第[8.1](documenting-code.html#comments)节）；描述每个模块的公共接口及其使用方法的文档（第[8.2](documenting-code.html#apidocs)节）；对管道的整体结构和其部分如何相互配合的描述（第[8.3](documenting-code.html#designdocs)节）；详细说明已经实现哪些机器学习模型以及为什么实现，以及它们解决的业务或学术需求（第[8.4](documenting-code.html#domaindocs)节）。为了补充这些信息，我们应该展示我们如何设想机器学习管道将在实际日常操作中应用（第[8.5](documenting-code.html#usecases)节）。
- en: 8.1 Comments
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 注释
- en: There is no consensus among software engineers about the need to include comments
    in the code, nor about their frequency and contents. Some argue that “comments
    are, at best, a necessary evil […] to compensate for our failure to express ourselves
    in code” (Martin [2008](#ref-cleancode)); some that “too many comments are as
    bad as too few, and you can achieve a middle ground economically” (McConnell [2004](#ref-codecomplete));
    and others that “good code has lots of comments […] keep the low-level knowledge
    in the code, where it belongs, and reserve the comments for other, high-level
    explanations” (Thomas and Hunt [2019](#ref-pragpro)). The only things that everybody
    agrees on are that comments can easily become out-of-date as the code they refer
    to changes over time, and that comments that do not provide any additional information
    over the code itself are redundant.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程师们对于在代码中包含注释的需求、注释的频率和内容并没有达成共识。有些人认为“注释充其量是必要的恶……用以弥补我们在代码中表达自己的失败”（马丁[2008](#ref-cleancode)）；有些人认为“注释过多和过少一样糟糕，你可以通过经济的方式达到一个中间地带”（麦康奈尔[2004](#ref-codecomplete)）；还有其他人认为“好的代码有很多注释……将低级知识保留在代码中，它属于的地方，并将注释留给其他，高级的解释”（托马斯和亨特[2019](#ref-pragpro)）。唯一大家一致认同的是，注释可能会随着时间的推移而变得过时，因为它们所引用的代码会发生变化，以及那些不提供任何额外信息的注释是多余的。
- en: 'Machine learning pipelines can be reasoned about from three different perspectives
    (Section [5.3.1](design-code.html#scoping-pipeline)): the domain they operate
    in, such as the business operation or the academic field that generates the data
    it will process; the software architecture, that is, the engineering effort of
    organising the software in separate modules that can be worked on efficiently
    and that have a well-defined purpose; and the models that power them with their
    probabilistic properties. The interplay between these perspectives determines
    both low-level and high-level design decisions in ways that are extremely difficult
    to represent in the code. We choose machine learning models considering the characteristics
    of the data they will process; performance optimisations (Sections [2.2](hardware.html#hardware-using)
    and [2.4](hardware.html#hardware-choice)) may (or may not) be worthwhile depending
    on the combination of models and compute systems; and our efforts to structure
    the software into modules (Section [5.3](design-code.html#processing-pipeline))
    and data structures (Sections [3.3](types-structures.html#right-variables) and
    [3.4](types-structures.html#right-data-structures)) must reconcile the conflicting
    goals of representing abstract mathematical concepts and real-world domain concepts
    at the same time.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道可以从三个不同的角度进行推理（第[5.3.1](design-code.html#scoping-pipeline)节）：它们操作的领域，例如生成要处理的数据的商业运营或学术领域；软件架构，即组织软件为独立的模块的工程努力，这些模块可以高效地工作，并且具有明确的目的；以及通过它们的概率属性为它们提供动力的模型。这些角度之间的相互作用决定了低级和高级设计决策，这些决策在代码中很难表示。我们选择机器学习模型时考虑它们将要处理的数据的特征；性能优化（第[2.2](hardware.html#hardware-using)节和[2.4](hardware.html#hardware-choice)节）可能（或可能不）值得，这取决于模型和计算系统的组合；并且我们努力将软件结构化为模块（第[5.3](design-code.html#processing-pipeline)节）和数据结构（第[3.3](types-structures.html#right-variables)节和[3.4](types-structures.html#right-data-structures)节）的努力必须协调表示抽象数学概念和现实世界领域概念的冲突目标。
- en: 'As a result, the idea that comments should focus on complementing code by stating
    the “whys” (say, the rationales for particular design decisions and how non-obvious
    low-level optimisations work and why they are needed) and that they should leave
    the code itself to illustrate the “whats” (say, the sequence of steps that produces
    the outputs of a function) is much more nuanced than it is in either enterprise
    or academic software. In both these settings, modern development practices ensure
    that domain experts and software engineers have a shared conceptual model of the
    key domain concepts and, in doing so, establish a *ubiquitous language* (Evans
    [2003](#ref-domain-driven)) to identify and discuss them. This language is used
    throughout all documentation and in the code (to name classes, methods and variables),
    so that all the people involved have a common understanding of the “whats” and
    the “whys” of what the code is doing. However, it is difficult to establish such
    a ubiquitous language in the context of machine learning software (Section [6.2](writing-code.html#naming))
    because the backgrounds of the people involved are more varied: it is rare for
    any single person to have a broad enough background to be able to understand the
    machine learning systems and software well from a domain, software and machine
    learning perspectives at any given time. The rise of professional figures such
    as domain (data) analysts (domain + machine learning) and machine learning engineers
    (software engineering + machine learning) who can work on pipelines from two different
    perspectives is partly a response to this issue.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关于注释应该专注于通过说明“为什么”（例如，特定设计决策的理由以及非显而易见的低级优化如何工作以及为什么需要它们）来补充代码，而代码本身应该用来说明“是什么”（例如，产生函数输出的步骤序列）的想法，在企业和学术软件中都要比这更加微妙。在这两种情况下，现代开发实践确保领域专家和软件工程师对关键领域概念有一个共享的概念模型，并在这样做的过程中，建立一个*通用语言*（Evans
    [2003](#ref-domain-driven))来识别和讨论它们。这种语言贯穿于所有文档和代码（命名类、方法和变量）中，以便所有相关人员都能对代码所做之事的“是什么”和“为什么”有一个共同的理解。然而，在机器学习软件的背景下建立这样的通用语言是困难的（第[6.2](writing-code.html#naming)节），因为涉及人员的背景更加多样化：在任何给定时间，很少有人有足够广泛的背景，能够从领域、软件和机器学习角度很好地理解机器学习系统和软件。领域（数据）分析师（领域
    + 机器学习）和机器学习工程师（软件工程 + 机器学习）等专业人物的出现，可以从两个不同的角度工作，部分是对这一问题的回应。
- en: 'Therefore, we believe that there is value in annotating code with comments
    describing both the “whats” and the “whys” but that do so from a perspective that
    is different from the one the code is written from. Code implementing models (Section
    [5.3.4](design-code.html#model-pipeline)) should be structured well enough for
    a machine learning engineer to understand its behaviour clearly: comments should
    focus on how the parameters of the model and its outputs map to domain concepts,
    and they can also state how optimising the model for a compute system’s hardware
    led to the use of specific data structures. Code that pre-processes inputs to
    a machine learning pipeline (Section [5.3.3](design-code.html#data-pipeline))
    and post-processes its outputs for consumption by third parties (Sections [5.3.5](design-code.html#production-pipeline)
    and [5.3.6](design-code.html#monitoring-pipeline)) should be clear to domain experts,
    since it is just encoding domain concepts into data structures and vice versa;
    but it is worthwhile to comment on the statistical properties we expect those
    inputs and outputs to have, and to relate them to the machine learning models
    they are produced from or fed to. Finally, code that orchestrates the modules
    in the pipeline (either directly or by configuring a third-party MLOps solution,
    see Section [5.3](design-code.html#processing-pipeline)) should be clear from
    both domain and machine learning perspectives because it is linking different
    models in a data processing pipeline designed after domain workflows. However,
    the algorithmic complexity of particular models and the hardware characteristics
    of the compute systems the models run on can influence how the code is organised
    into modules and how the modules are connected to each other in ways that should
    be documented because they may not be readily apparent.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们认为在代码中添加注释，描述“是什么”和“为什么”，虽然是从与代码编写不同的角度出发，但这样做是有价值的。实现模型的代码（第[5.3.4](design-code.html#model-pipeline)节）应该结构良好，以便机器学习工程师能够清楚地理解其行为：注释应侧重于模型的参数及其输出如何映射到领域概念，并且也可以说明为了优化模型以适应计算系统的硬件而使用特定数据结构的原因。预处理机器学习管道输入的代码（第[5.3.3](design-code.html#data-pipeline)节）和为第三方消费其输出的后处理代码（第[5.3.5](design-code.html#production-pipeline)节和第[5.3.6](design-code.html#monitoring-pipeline)节）应该对领域专家来说是清晰的，因为这只是将领域概念编码到数据结构中，反之亦然；但值得注释的是，我们期望这些输入和输出具有的统计特性，并将它们与它们产生的或输入到其中的机器学习模型联系起来。最后，协调管道中模块的代码（无论是直接还是通过配置第三方MLOps解决方案，见第[5.3](design-code.html#processing-pipeline)节）应从领域和机器学习两个角度都是清晰的，因为它是在领域工作流程之后设计的用于数据处理管道中连接不同模型。然而，特定模型的算法复杂性和运行模型的计算系统的硬件特性可能会影响代码如何组织成模块以及模块之间如何相互连接，这些应该被记录下来，因为它们可能并不明显。
- en: 'Other than that, the advice in (Ousterhout [2018](#ref-philo); Fowler [2018](#ref-refactoring);
    Thomas and Hunt [2019](#ref-pragpro); Evans [2003](#ref-domain-driven)) on how
    to write comments applies well to machine learning software. The goal of comments
    is to ensure that the structure and the behaviour of the software is obvious to
    the readers: other developers, so that they can modify the code quickly and with
    confidence, and users, so that they can understand it and use it appropriately.
    The readers could eventually deduce such information by reading the code, but
    the process would be time-consuming and error-prone: especially when they are
    approaching the code from a different perspective than the one from which the
    code was written. Comments should be concise and located close to the code: for
    instance, prefacing a block of code performing a particular task with a description
    of the implementation issues that were considered and the probability results
    that shaped it. (This may also help in relating tests to the code, see Section
    [9.4.2](troubleshooting-code.html#testing-what). Additional information that does
    not belong in any single place in the code may be found in commit messages as
    discussed in Section [6.5](writing-code.html#versioning).) They should be written
    just before or at the same time as the code to ensure that they are written in
    the first place and that any design issues are still fresh in the developer’s
    minds. For the same reason, they should be updated along with the code whenever
    the code is modified. This approach may also help in refining the architecture
    of the code early on (Sections [5.3.1](design-code.html#scoping-pipeline) and
    [5.3.2](design-code.html#baseline-pipeline)) by making it easier to discuss pros
    and cons of different designs and by allowing domain experts to look into the
    implementation of key domain concepts to some extent. Finally, expressing the
    same idea twice, in the code and in the comments, and from different perspectives
    can have similar benefits to code review (Section [6.6](writing-code.html#code-review))
    because it forces developers to rethink what they are doing from the point of
    view of a user of the software.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些，关于如何编写注释的建议（Ousterhout [2018](#ref-philo)；Fowler [2018](#ref-refactoring)；Thomas
    and Hunt [2019](#ref-pragpro)；Evans [2003](#ref-domain-driven)）同样适用于机器学习软件。注释的目标是确保软件的结构和行为对读者来说是显而易见的：其他开发者，以便他们可以快速且自信地修改代码，以及用户，以便他们可以理解并适当地使用它。读者最终可以通过阅读代码来推断这样的信息，但这个过程会耗费时间且容易出错：尤其是当他们从与代码编写者不同的角度接近代码时。注释应该简短且靠近代码：例如，在执行特定任务的代码块前加上对考虑的实现问题和塑造它的概率结果的描述。（这也有助于将测试与代码联系起来，见第[9.4.2](troubleshooting-code.html#testing-what)节。）不属于代码中任何单一位置的信息可能可以在提交信息中找到，如第[6.5](writing-code.html#versioning)节所述。它们应该在代码之前或与代码同时编写，以确保它们首先被编写，并且任何设计问题都仍然在开发者的脑海中是新鲜的。出于同样的原因，每当代码被修改时，它们应该与代码一起更新。这种方法也可能有助于在早期就完善代码架构（见[5.3.1](design-code.html#scoping-pipeline)和[5.3.2](design-code.html#baseline-pipeline)节），通过使讨论不同设计的优缺点变得更容易，并允许领域专家在一定程度上查看关键领域概念的实现。最后，在代码和注释中从不同角度表达相同的思想，可以带来与代码审查（见[6.6](writing-code.html#code-review)节）相似的好处，因为它迫使开发者从软件用户的角度重新思考他们正在做的事情。
- en: 8.2 Documenting Public Interfaces
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 记录公共接口
- en: 'In addition to augmenting blocks of code inside functions and modules, we should
    use comments to document module interfaces, their methods and their general behaviour.
    In particular, each module should come with a high-level description of what it
    does and of the situations in which it makes sense to use it. Both should be written
    from the point of view of a prospective user: in the spirit of abstracting away
    complexity and reducing cognitive load, users should be able to use the module
    without reading its implementation (Ousterhout [2018](#ref-philo)). As discussed
    earlier, people working on and using machine learning pipelines will come from
    a variety of backgrounds, and many may struggle to read code written from a perspective
    far from their own. Therefore, comments prefacing module interfaces should describe
    them from all relevant perspectives to make them approachable in the same way
    as other comments (Section [8.1](documenting-code.html#comments)). These descriptions,
    together with the method signatures, should provide all the essential information
    on the modules: the meaning of the methods and of their arguments as well as any
    constraints, side effects and preconditions they may have. If we find it difficult
    to put such information in writing in a clear and concise way, it may well be
    that the interface is not a good abstraction and that the module should be refactored
    (Section [6.7](writing-code.html#refactoring)) to give it a better sense of purpose.
    The documentation that describes it should be changed at the same time to remain
    up-to-date.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 除了增强函数和模块内部的代码块外，我们还应该使用注释来记录模块接口、它们的方法以及它们的一般行为。特别是，每个模块都应该包含一个高级描述，说明它做什么以及何时使用它是合理的。这两者都应该从潜在用户的角度来写：在抽象复杂性和减少认知负担的精神下，用户应该能够在不阅读其实施细节的情况下使用该模块（Ousterhout
    [2018](#ref-philo)）。如前所述，从事和使用机器学习管道工作的人来自各种背景，许多人可能难以阅读与他们自身视角相差甚远的代码。因此，模块接口前面的注释应该从所有相关角度描述它们，以便它们像其他注释一样易于接近（第[8.1](documenting-code.html#comments)节）。这些描述，连同方法签名，应该提供有关模块的所有必要信息：方法及其参数的含义，以及它们可能具有的任何约束、副作用和先决条件。如果我们发现很难以清晰简洁的方式将这些信息写成文字，那么可能是因为接口不是一个好的抽象，该模块应该被重构（第[6.7](writing-code.html#refactoring)节）以赋予它更好的目的感。描述它的文档也应同时更改，以保持最新。
- en: Documenting individual functions in a similar way may make sense for those few
    functions that are not completely encapsulated inside a single module. Other functions
    are either not visible to the module users, so they only need to be documented
    to the extent that is required by the developers of that module; or they are visible
    to the module users, and they should be documented among its methods.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以类似的方式记录单个函数可能对那些不完全封装在单个模块内的少数函数有意义。其他函数要么对模块用户不可见，因此它们只需要按照该模块的开发者所需的方式进行记录；要么对模块用户可见，并且它们应该在其方法中记录。
- en: In order to keep this type of documentation close to the code it refers to,
    so that it is easier to keep the two in sync, we can annotate each module with
    a long-form comment covering the information above. These comments should be structured
    in a standard format, possibly with additional in-house conventions, to ensure
    consistency and to make it more straightforward to write them. Tools such as Doxygen
    (van Heesch [2022](#ref-doxygen)) can enforce comment formats for all programming
    languages typically found in machine learning pipelines (namely, C, , R and Python),
    which is convenient because different modules may be implemented in different
    languages (Section [6.1](writing-code.html#programming-language)). They can also
    generate documents in common formats such as HTML, PDF and DOCX from the comments.
    This is especially convenient for keeping documentation up to date as interfaces
    change, because we can just update the comments along with the code and regenerate
    those documents as needed. We can also use language-specific tools such as Roxygen
    (Wickham, Danenberg, et al. [2022](#ref-roxygen2)) in R or Sphinx (Brandl and
    the Sphinx Team [2022](#ref-sphinx)) in Python if either language is dominant
    in the machine learning pipeline.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使此类文档与所引用的代码保持紧密，以便更容易保持两者同步，我们可以为每个模块添加一个包含上述信息的长格式注释。这些注释应采用标准格式，可能还有额外的内部约定，以确保一致性并使编写它们更加直接。例如，Doxygen（van
    Heesch [2022](#ref-doxygen)）可以强制所有在机器学习管道中通常找到的编程语言的注释格式（即C、R和Python），这很方便，因为不同的模块可能用不同的语言实现（第[6.1](writing-code.html#programming-language)节）。它们还可以从注释生成常见的格式文档，如HTML、PDF和DOCX。这对于在接口更改时保持文档更新特别方便，因为我们只需更新注释和代码，并在需要时重新生成这些文档。如果机器学习管道中任一语言占主导地位，我们还可以使用特定语言的工具，如R中的Roxygen（Wickham,
    Danenberg, et al. [2022](#ref-roxygen2)）或Python中的Sphinx（Brandl and the Sphinx
    Team [2022](#ref-sphinx)）。
- en: What should we write in these long-form comments in practice?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上我们应该在这些长格式注释中写些什么？
- en: 'What we can expect from the module: the signatures of the methods, its semantics
    and its behaviour in both success and failure scenarios. These include the meaning
    and the data types of exported variables as well as a list of all the possible
    error conditions and how they are handled.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以期待从模块中获得什么：方法的签名、其语义以及在成功和失败场景中的行为。这包括导出变量的含义和数据类型，以及所有可能的错误条件及其处理方式。
- en: What problem the module solves, and a brief summary of why it was designed the
    way it was. This might include a discussion of alternative solutions that have
    been evaluated and discarded (Section [5.3.1](design-code.html#scoping-pipeline))
    to avoid re-evaluating them unless we are changing the module in a fundamental
    way. However, such decisions typically span across module boundaries and are better
    documented in the architecture documentation (Section [8.3](documenting-code.html#designdocs)).
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模块解决了什么问题，以及为什么以这种方式设计它的简要概述。这可能包括对已评估和舍弃的替代解决方案的讨论（第[5.3.1](design-code.html#scoping-pipeline)节），以避免在除非我们以根本方式更改模块的情况下重新评估它们。然而，此类决策通常跨越模块边界，并在架构文档（第[8.3](documenting-code.html#designdocs)节）中更好地记录。
- en: Short examples of how the module is used, possibly in combination with other
    modules, are also nice to have.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模块的使用简例，可能与其他模块结合使用，也是很有用的。
- en: Pointers to the relevant sections of the technical documentation (Section [8.4](documenting-code.html#domaindocs))
    and to books or papers that describe the algorithms used in the module.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指向技术文档相关部分的链接（第[8.4](documenting-code.html#domaindocs)节）以及描述模块中使用的算法的书籍或论文。
- en: Popular open-source machine learning software provides many examples of how
    to do this well. Take, for instance, Scikit-learn. We can access the documentation
    of its module interfaces from the landing page of its website (Scikit-learn Developers
    [2022](#ref-sklearn)) via a link labelled “API”. All modules are listed in alphabetical
    order, from `sklearn.base` all the way to `sklearn.utils`. For each of them, we
    have a short description summarising what algorithms, models or general functionality
    it implements, links to long-form documentation that gives further details and
    shows typical usage patterns, and a list of all the attributes and the functions
    it exports. The page documenting each class further details its methods and their
    arguments as well as any variables it exports. All this documentation is generated
    by Sphinx from comments in the Scikit-learn code. The source files in which the
    comments appear are linked from each page, making it easy to explore the code
    the page describes.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 流行的开源机器学习软件提供了许多如何做好这件事的示例。以Scikit-learn为例。我们可以通过其网站首页上的一个标记为“API”的链接访问其模块接口的文档（Scikit-learn
    Developers [2022](#ref-sklearn)）。所有模块都按字母顺序列出，从`sklearn.base`一直到`sklearn.utils`。对于每一个模块，我们都有一个简短的描述，总结它实现了哪些算法、模型或通用功能，提供了指向详细文档的链接，这些文档提供了更多细节并展示了典型的使用模式，以及它导出的所有属性和函数的列表。每个类的文档页面进一步详细说明了其方法和它们的参数，以及它导出的任何变量。所有这些文档都是由Sphinx从Scikit-learn代码中的注释生成的。包含注释的源文件链接在每个页面上，这使得探索页面描述的代码变得容易。
- en: '![An abridged version of the online documentation generated by Sphinx from
    the comments in the DBSCAN module of Scikit-learn.](../Images/259eef0937fcf1ecc0ddef18f04139b6.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![Sphinx从Scikit-learn的DBSCAN模块注释中生成的在线文档的简略版](../Images/259eef0937fcf1ecc0ddef18f04139b6.png)'
- en: 'Figure 8.1: An abridged version of the online documentation generated by Sphinx
    from the comments in the DBSCAN module of Scikit-learn.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：Sphinx从Scikit-learn的DBSCAN模块注释中生成的在线文档的简略版。
- en: For example, consider the documentation of the module implementing the DBSCAN
    clustering algorithm (Schubert et al. [2017](#ref-dbscan)). The online documentation
    is shown in Figure [8.1](documenting-code.html#fig:dbscan-documentation). The
    Sphinx comment the module description is generated from appears just before its
    declaration and it is enclosed in triple double-quotes (`"""`). Section headers
    are marked by ten dashes (`-----------`) and the lists of parameters and attributes
    are formatted using indentation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑实现DBSCAN聚类算法的模块的文档（Schubert等[2017](#ref-dbscan)）。在线文档如图[8.1](documenting-code.html#fig:dbscan-documentation)所示。模块描述由Sphinx生成的注释出现在其声明之前，并用三重双引号（`"""`）包围。部分标题由十个短横线（`-----------`）标记，参数和属性的列表使用缩进来格式化。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The “Notes” section links further examples and illustrates the computational
    complexity (Chapter [4](algorithms.html#algorithms)) of DBSCAN, complementing
    the pointers to similar functionality in the OPTICS module and the layman’s explanation
    of how DBSCAN works in the User Guide.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: “注释”部分提供了更多示例，并说明了DBSCAN的计算复杂性（第[4](algorithms.html#algorithms)章），补充了指向OPTICS模块中类似功能的指针以及用户指南中对DBSCAN工作原理的通俗解释。
- en: In addition, the documentation of DBSCAN provides a list of all the exported
    methods along with a short description of what each of them implements, of its
    arguments (including their types and default values) and of its return value.
    The comment generating the documentation of the `fit()` method, for instance,
    is the following.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，DBSCAN的文档提供了一个所有导出方法的列表，以及每个方法实现的内容的简短描述，它的参数（包括它们的类型和默认值）以及它的返回值。例如，生成`fit()`方法文档的注释如下。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Unfortunately, the comment conflates function arguments with the parameters
    of the underlying models and algorithms: this is not ideal because it implies
    that they can be reasoned about interchangeably (which is not true, for instance,
    for floating point variables, see Section [3.1.2](types-structures.html#floating-point))
    and because it suggests that function arguments should map one-to-one to parameters
    (which depends entirely on how the machine learning pipeline is structured, see
    in particular Sections [5.2.3](design-code.html#architecture-debt), [5.2.4](design-code.html#code-debt)
    and [5.3.4](design-code.html#model-pipeline)). On the good side, however, it specifies
    what is the expected type for all arguments, which is a useful detail for module
    users to have in a dynamically-typed language like Python. Types can be enforced
    using a type checker such as mypy (The mypy Project [2014](#ref-mypy)), effectively
    turning Python into a statically-typed language for any function with type annotations.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，注释将函数参数与底层模型和算法的参数混淆：这并不理想，因为它暗示它们可以相互替换地推理（例如，对于浮点变量来说这不是真的，参见第[3.1.2](types-structures.html#floating-point)节），并且因为它暗示函数参数应该一对一地映射到参数（这完全取决于机器学习管道的结构，特别是参见第[5.2.3](design-code.html#architecture-debt)、[5.2.4](design-code.html#code-debt)和[5.3.4](design-code.html#model-pipeline)节）。然而，从好的方面来看，它指定了所有参数的预期类型，这对于Python这样的动态类型语言中的模块用户来说是一个有用的细节。可以使用类型检查器（如mypy[2014](#ref-mypy)）强制执行类型，从而有效地将Python转换为具有类型注解的静态类型语言。
- en: 'Another example of documenting interfaces at scale is the infrastructure that
    CRAN (CRAN Team [2022](#ref-cran)) uses to distribute and enforce quality standards
    on R packages. Each package has a dedicated web page on CRAN’s website, which
    includes a short description of the functionality provided by the package and
    links to its Changelog, to relevant web pages and to its reference manual. Its
    entries follow a structured “R Documentation” format, based on a subset of LaTeX,
    with predefined sections (“Description”, “Arguments”, “Details”, “Examples”, “References”)
    that package authors are required to fill for each function they export from the
    package. R Documentation files can be generated by including comments in the Doxygen
    format in the code and processing them with Roxygen: CRAN does not require that,
    but cross-checks that function names and arguments are consistent between the
    code and the documentation, and it executes all the examples to make sure they
    run. Furthermore, CRAN reports the status of any tests shipped with the package
    on its web page. The package’s web page also links long-form documentation that
    provides further details on relevant algorithms and models and that showcases
    them with comprehensive examples. These long-form documents, known as *vignettes*,
    are notebooks interleaving R code with Markdown or LaTeX prose whose sources are
    part of the package. CRAN will compile them to make them available alongside the
    package sources.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模文档接口的一个例子是CRAN（CRAN团队[2022](#ref-cran)）用于分发和执行R包质量标准的架构。每个包在CRAN网站上都有一个专门的网页，其中包括该包提供的功能的简要描述，以及指向其变更日志、相关网页和参考手册的链接。其条目遵循基于LaTeX子集的“R文档”格式，具有预定义的章节（“描述”、“参数”、“细节”、“示例”、“参考文献”），包作者必须为从包中导出的每个函数填写这些章节。R文档文件可以通过在代码中包含Doxygen格式的注释并使用Roxygen进行处理来生成：CRAN不要求这样做，但它会交叉检查函数名称和参数在代码和文档之间的一致性，并执行所有示例以确保它们可以运行。此外，CRAN在其网页上报告了与包一起分发的任何测试的状态。包的网页还链接到长篇文档，这些文档提供了有关相关算法和模型的更多详细信息，并通过综合示例展示它们。这些长篇文档被称为*vignettes*，它们是混合了R代码和Markdown或LaTeX文本的笔记本，其源代码是包的一部分。CRAN将编译它们，以便与包源代码一起提供。
- en: A popular R package that contains all these types of documentation is rstanarm
    (Muth, Oravecz, and Gabry [2018](#ref-rstanarm)), which implements a suite of
    Bayesian regression models on top of Stan (Carpenter et al. [2017](#ref-stan)).
    The authors provide both the reference manual and a set of vignettes illustrating
    how to use it. Its web page on CRAN links the GitHub repository with the package’s
    source code where we can easily see the Doxygen comments the reference manual
    is created from. For instance, the comment prefacing the `stan_mvmer()` function
    looks as follows.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 包含所有这些类型文档的流行R包是rstanarm（Muth, Oravecz和Gabry [2018](#ref-rstanarm)），它实现了在Stan（Carpenter等人
    [2017](#ref-stan)）之上的贝叶斯回归模型集。作者提供了参考手册和一系列示例说明如何使用它。它在CRAN上的网页链接了GitHub仓库，我们可以轻松地看到参考手册是从中创建的Doxygen注释。例如，`stan_mvmer()`函数前的注释如下。
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The Doxygen comment is identified by the fact that each line starts with a single
    quote. The first paragraph gives the title of the entry in the reference manual
    for the function, which is declared to be public by the `@export`. The second
    paragraph is the “Description”, the `@params` are the “Arguments”, and the `@return`
    describes the return value of the function. The text that follows the `@details`
    ends up in the “Details” section, and the code after the `@examples` provides
    short examples.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Doxygen注释可以通过每个行首的单引号来识别。第一段给出了参考手册中该函数条目的标题，该标题被`@export`声明为公共的。第二段是“描述”，`@params`是“参数”，而`@return`描述了函数的返回值。在`@details`之后的文本最终会出现在“详细信息”部分，而`@examples`之后的代码提供了简短的示例。
- en: 'Longer examples and technical discussions that are too cumbersome to include
    in the reference manual are shipped as a set of vignettes, which in the case of
    rstanarm are R Markdown documents. Unlike the reference manual, vignettes can
    include figures and mathematical equations typeset in LaTeX, and they can easily
    be converted to PDF, HTML and DOCX documents using the knitr package (Xie [2015](#ref-knitr)).
    The R Markdown format differs from plain Markdown only in its YAML header, which
    tells knitr the type of document the file should be compiled into and some of
    its metadata. For instance, in `glmer.Rmd`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 长篇示例和过于繁琐而无法包含在参考手册中的技术讨论以一系列示例的形式提供，对于rstanarm来说，这些示例是R Markdown文档。与参考手册不同，示例可以包含LaTeX排版的图表和数学公式，并且可以使用knitr包（Xie
    [2015](#ref-knitr)）轻松地将它们转换为PDF、HTML和DOCX文档。R Markdown格式与纯Markdown的不同之处仅在于其YAML标题，它告诉knitr文件应该编译成哪种类型的文档以及一些元数据。例如，在`glmer.Rmd`中：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Code chunks are delimited by triple backticks, followed by the language label
    (R in this case) and by a list of options that will be evaluated by knitr when
    compiling the document.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块由三个反引号分隔，后跟语言标签（在这种情况下是R）以及knitr在编译文档时将评估的选项列表。
- en: '[PRE4]{r, results = "hide"}\n'','
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE4]{r, results = "hide"}\n'','
- en: post1 <- stan_nlmer(circumference ~ SSlogis(age, Asym, xmid, scal)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: post1 <- stan_nlmer(circumference ~ SSlogis(age, Asym, xmid, scal)
- en: ~ Asym|Tree,
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ~ Asym|Tree,
- en: data = Orange, cores = 2, seed = 12345, init_r = 0.5)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: data = Orange, cores = 2, seed = 12345, init_r = 0.5)
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that, by default, knitr executes all code every time the document is compiled,
    in the order in which it appears. Therefore, we cannot have the issues with out-of-order
    execution and inconsistent state that affect Jupyter notebooks (Project Jupyter
    [2022](#ref-jupyter)) (Section [10.2.2](development-tools.html#notebooks)).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，knitr在每次编译文档时都会执行所有代码，按照它们出现的顺序。因此，我们不会遇到影响Jupyter笔记本（Project Jupyter
    [2022](#ref-jupyter)）（第[10.2.2](development-tools.html#notebooks)节）的执行顺序不一致和状态不一致的问题。
- en: 8.3 Documenting Architecture and Design
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 记录架构和设计
- en: 'Architecture documentation binds together the public interface documentation
    of the individual modules to give an overall view of how the machine learning
    systems and the pipeline are structured as a whole. It summarises the rationale
    of the decisions made when designing them, the properties of their (hardware and
    software) components and their interactions, and how they relate to the requirements
    for the pipeline (Clements et al. [2011](#ref-clements)) (Section [5.3.1](design-code.html#scoping-pipeline)).
    All this should be written in the same ubiquitous language as the comments and
    the module interfaces documentation, and for the same reasons: the architecture
    is the primary means of evaluating how the pipeline and the underlying systems
    work, whether they can be modified in specific ways, and whether they meet current
    or new requirements we may have. These activities necessarily involve discussions
    among domain experts, software engineers and machine learning specialists that
    greatly benefit from the clarity brought by the ubiquitous language. In particular,
    architecture documentation should document all those cross-module design decisions
    that do not belong in any single module interface documentation: a prime example
    is the design and workings of glue code (Sections [5.2.3](design-code.html#architecture-debt)
    and [9.2.4](troubleshooting-code.html#troubleshooting-pipelines)), which is often
    the least documented part of a machine learning pipeline.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 架构文档将各个模块的公共接口文档结合起来，从而提供一个整体视图，展示机器学习系统和流水线是如何作为一个整体来构建的。它总结了在设计时所做的决策的合理性，它们的（硬件和软件）组件的性质及其相互作用，以及它们如何与流水线的要求（Clements
    等人 [2011](#ref-clements))（第 [5.3.1](design-code.html#scoping-pipeline) 节）相关。所有这些都应该用与注释和模块接口文档相同的通用语言来编写，并且出于相同的原因：架构是评估流水线和底层系统工作方式、它们是否可以以特定方式修改以及它们是否满足当前或新要求的首要手段。这些活动必然涉及领域专家、软件工程师和机器学习专家之间的讨论，而这些讨论从通用语言带来的清晰性中受益匪浅。特别是，架构文档应该记录所有那些不属于任何单个模块接口文档的跨模块设计决策：一个典型的例子是胶水代码的设计和工作原理（第
    [5.2.3](design-code.html#architecture-debt) 节和 [9.2.4](troubleshooting-code.html#troubleshooting-pipelines)
    节），这通常是机器学习流水线中最少文档化的部分。
- en: A natural starting point to document the architecture and the design of a machine
    learning pipeline is the DAG that describes its paths of execution (Section [5.3](design-code.html#processing-pipeline)).
    The nodes in the DAG represent the modules that implement the different processing
    stages the data go through, and an explanation of their roles in the pipeline
    should be linked to the documentation of the respective interfaces. The presence
    of arcs linking the nodes suggests that the corresponding modules have been designed
    to be interoperable, and the design decisions that make it possible should also
    be documented. Furthermore, arcs determine the temporal sequence of the processing
    stages and may be associated with event triggers (say, pull updated models for
    serving as they become available), scheduled tasks (say, retrain a model after
    a certain amount of new data becomes available) or human inputs (say, for model
    validation). Accommodating future needs that are not yet made explicit in the
    form of arcs in the DAG may have influenced the design of module interfaces, and
    such considerations should be documented as well.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 记录机器学习流水线的架构和设计的一个自然起点是描述其执行路径的 DAG（第 [5.3](design-code.html#processing-pipeline)
    节）。DAG 中的节点代表实现数据经过的不同处理阶段的模块，它们在流水线中的角色解释应该链接到相应的接口文档。节点之间存在的弧线表明相应的模块已被设计为可互操作的，使其成为可能的设计决策也应予以记录。此外，弧线确定了处理阶段的时序，可能与事件触发器（例如，当模型可用时拉取更新模型）、计划任务（例如，在获得一定量的新数据后重新训练模型）或人工输入（例如，用于模型验证）相关联。适应尚未以
    DAG 中弧线形式明确表达的未来需求可能影响了模块接口的设计，这些考虑也应予以记录。
- en: This is, however, just one possible perspective from which we can describe a
    machine learning pipeline. Its design is likely to be influenced by the combination
    of the local and remote compute systems it runs on or it may run on in the future
    because individual modules will have different requirements (Section [2.4](hardware.html#hardware-choice)).
    How the overall functionality of the pipeline is structured into modules may be
    influenced by the domain or the business it operates in. For instance, a machine
    learning pipeline that uses computer vision for supporting clinicians in diagnosing
    diseases from medical images (like the use case example in Section [8.5](documenting-code.html#usecases))
    may have the DAG patterned after the tasks performed by different specialists
    and after the progression of clinical information in the diagnostic process. Or,
    in a business context, different parts of the pipeline may be under the supervision
    of different units within the company, with clear boundaries to avoid overlaps
    for personnel and budget reasons. The interplay of the models and of various algorithms
    at a probabilistic level provides one more view of the machine learning pipeline
    as an overarching, hierarchical model whose components may or may not be related
    to how the code is organised into modules.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这只是我们可以描述机器学习管道的可能视角之一。其设计可能受到它运行的本地和远程计算系统的组合的影响，或者它可能在未来运行，因为各个模块将有不同的需求（第[2.4](hardware.html#hardware-choice)节）。管道的整体功能如何结构化成模块可能受到其运营的领域或业务的影响。例如，一个使用计算机视觉来支持临床医生从医学图像中诊断疾病（如第[8.5](documenting-code.html#usecases)节中的用例示例）的机器学习管道可能具有类似于不同专家执行的任务和诊断过程中的临床信息进展的DAG模式。或者，在商业环境中，管道的不同部分可能由公司内部的不同部门监督，有明确的边界以避免因人员和预算原因而重叠。模型和各种算法在概率层面的相互作用为机器学习管道提供了一个更全面的视角，作为一个总体上、层次化的模型，其组件可能与代码组织成模块的方式有关或无关。
- en: 'Thorough documentation of the architecture and of the design decisions behind
    a machine learning pipeline and the underlying systems will naturally comprise
    a set of documents written from different perspectives to provide different conceptual
    views. Using the ubiquitous language (Section [8.1](documenting-code.html#comments))
    across all documents will help cross-referencing them and make them accessible
    to all the people working on or using different modules. Cross-referencing the
    documents with each other and with the interface documentation of each module
    will allow readers to navigate them and to jump from one document to another to
    view related pieces of information. Describing a real-world pipeline and the systems
    it runs on in a single document is not practical: the result would be unwieldy
    and difficult to keep up to date.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对机器学习管道的架构及其背后的设计决策进行彻底的文档记录将自然地包括一系列从不同角度撰写的文档，以提供不同的概念视图。在所有文档中使用普遍语言（第[8.1](documenting-code.html#comments)节）将有助于交叉引用它们，并使所有在开发或使用不同模块的人员都能访问它们。将文档相互之间以及与每个模块的接口文档进行交叉引用将允许读者导航它们，并从一个文档跳转到另一个文档以查看相关信息。在单个文档中描述一个真实世界的管道及其运行的系统是不切实际的：结果将难以管理且难以保持更新。
- en: 'Overall, the DAG can provide a suitable outline of the structure of the whole
    documentation for the machine learning pipeline and a map to navigate it. A systems
    diagram like Figure [2.1](hardware.html#fig:schematic) can serve a similar purpose
    for documenting the machine learning systems. Domain concepts can then be organised
    informally with a diagram of some sort; it will rarely be worthwhile to use a
    formal graphical specification such as UML (Fowler [2003](#ref-uml)). Ideally,
    all these graphical representations will share some similarities and will be meaningful
    to all of domain experts, machine learning experts and software engineers. If
    the domain experts do not understand the architecture of the system, there may
    be something wrong with it: they can communicate any issues they may have using
    the ubiquitous language, and discuss them while we iterate project scoping (Section
    [5.3.1](design-code.html#scoping-pipeline)) and prototyping (Section [5.3.2](design-code.html#baseline-pipeline))
    until everybody is comfortable with the design.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，DAG可以提供一个适合整个机器学习流程文档结构的概要以及导航它的地图。类似于图[2.1](hardware.html#fig:schematic)的系统图可以用于记录机器学习系统，起到类似的作用。领域概念可以通过某种类型的图表非正式地组织起来；很少有必要使用如UML（Fowler
    [2003](#ref-uml)）这样的正式图形规范。理想情况下，所有这些图形表示应具有一些相似之处，并对所有领域专家、机器学习专家和软件工程师都有意义。如果领域专家不理解系统的架构，那么可能存在问题：他们可以使用通用的语言来沟通任何问题，并在我们迭代项目范围（第[5.3.1](design-code.html#scoping-pipeline)节）和原型设计（第[5.3.2](design-code.html#baseline-pipeline)节）时讨论这些问题，直到每个人都对设计感到满意。
- en: For obvious reasons, it is difficult to find public, detailed examples of design
    documentation because companies consider their machine learning pipelines to be
    valuable assets that give them a competitive advantage. Much of that information,
    however, is available on the engineering blogs of companies like Uber (Uber Technologies
    [2022](#ref-uber-blog)) and Spotify (Spotify [2022](#ref-spotify-blog)[b](#ref-spotify-blog)).
    We will use them as sources to outline an example of how design documentation
    and mission statements (Section [8.4](documenting-code.html#domaindocs)) should
    be organised.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 由于明显的原因，很难找到公开的、详细的文档设计示例，因为公司认为他们的机器学习流程是宝贵的资产，可以给他们带来竞争优势。然而，大量此类信息可在Uber（Uber
    Technologies [2022](#ref-uber-blog)）和Spotify（Spotify [2022](#ref-spotify-blog)[b](#ref-spotify-blog)）等公司的工程博客上找到。我们将使用它们作为来源，概述设计文档和使命宣言（第[8.4](documenting-code.html#domaindocs)节）应该如何组织。
- en: '![Uber''s machine learning pipeline for early fraud detection, based on \cite{uber-fraud}:
    the domain DAG (top), the machine learning DAG (middle) and the software architecture
    DAG (bottom).](../Images/860a9e5c01568e080ccd724dce2c664d.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![基于\cite{uber-fraud}的Uber早期欺诈检测机器学习流程，包括领域DAG（顶部）、机器学习DAG（中部）和软件架构DAG（底部）](../Images/860a9e5c01568e080ccd724dce2c664d.png)'
- en: 'Figure 8.2: Uber’s machine learning pipeline for early fraud detection, based
    on : the domain DAG (top), the machine learning DAG (middle) and the software
    architecture DAG (bottom).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2：基于以下内容的Uber早期欺诈检测机器学习流程：领域DAG（顶部）、机器学习DAG（中部）和软件架构DAG（底部）。
- en: 'Consider the machine learning pipeline for early fraud detection at Uber (Zelvenskiy
    et al. [2022](#ref-uber-fraud)). After briefly describing what business problem
    the pipeline is solving, the blog post illustrates the pipeline from each of the
    domain, machine learning and software architecture perspectives. We show each
    of them in Figure [8.2](documenting-code.html#fig:uber-design):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑Uber（Zelvenskiy等人[2022](#ref-uber-fraud)）早期欺诈检测的机器学习流程。在简要描述该流程解决的业务问题后，博客文章从领域、机器学习和软件架构的视角分别阐述了该流程。我们在图[8.2](documenting-code.html#fig:uber-design)中展示了它们：
- en: 'The domain perspective (top panel): Uber receives from its customers a constant
    stream of orders which will be initially screened by a machine learning model
    for frauds. If found to be suspicious, they will be passed to a human expert for
    manual validation and either approved or rejected (Section [5.3.6](design-code.html#monitoring-pipeline)).
    The decisions made by the human experts are then fed back into the machine learning
    model doing the automatic screening to improve its performance over time and to
    prevent issues with data drift (see Sections [5.2.1](design-code.html#data-debt)
    and [9.1.3](troubleshooting-code.html#troubleshooting-dynamic-data)).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域视角（顶部面板）：Uber从其客户那里接收一个持续不断的订单流，这些订单最初将由机器学习模型进行欺诈筛查。如果发现可疑，它们将被传递给人类专家进行人工验证，并批准或拒绝（见第[5.3.6节](design-code.html#monitoring-pipeline)）。然后，人类专家做出的决策将被反馈到进行自动筛查的机器学习模型中，以随着时间的推移提高其性能并防止数据漂移问题（参见第[5.2.1节](design-code.html#data-debt)和第[9.1.3节](troubleshooting-code.html#troubleshooting-dynamic-data)）。
- en: 'The machine learning perspective (middle panel): the data flows through different
    pre-processing algorithms, including feature selection, to the models tasked to
    detect suspicious transactions. The same models will prioritise such transactions
    and schedule them for manual review.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习视角（中间面板）：数据流经不同的预处理算法，包括特征选择，然后传递给负责检测可疑交易的模型。这些相同的模型将优先处理此类交易，并安排它们进行人工审核。
- en: 'The software architecture perspective (bottom panel): each node in the DAG
    is a piece of software (possibly running on specific hardware) implementing the
    algorithms and the models found in the previous pipeline, storing data, or moving
    information around.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件架构视角（底部面板）：DAG中的每个节点都是一段软件（可能运行在特定的硬件上），它实现了在前一个流程中找到的算法和模型，存储数据或移动信息。
- en: 'Each of these pipelines will be easier to reason about for people with different
    backgrounds, and it can be used to provide pointers to more detailed information
    on the data processing steps, the models or the modules associated with the individual
    nodes. All pipelines span the same four stages (data ingestion and preparation,
    automatic screening, manual screening, outcome) but provide very different views
    and insights on how fraud detection is implemented. For instance, the second and
    the third pipelines highlight the feedback loop tying model retraining to manual
    review, which doubles as a data labelling step, and to the statistical distribution
    of the relevant features in the data. However, looking at the pipelines side by
    side makes it possible to relate the different perspectives they come from as
    well as the relationships between the nodes that appear in the same stage but
    in different DAGs. In a sense, the DAGs provide a visual representation of the
    conceptual model behind the ubiquitous language. Their main limitation is the
    inability to describe the semantic meaning of the arcs effectively, as is the
    case for UML: this information is what the various documents in the architecture
    documentation provide, complementing what we can see from the DAGs.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有不同背景的人来说，这些流程将更容易理解，并且可以用来提供有关数据处理步骤、模型或与单个节点关联的模块的更详细信息。所有流程都跨越相同的四个阶段（数据摄取和准备、自动筛查、人工筛查、结果），但提供了关于如何实施欺诈检测的非常不同的视角和见解。例如，第二个和第三个流程突出了将模型重新训练与人工审核联系起来的反馈循环，这既是数据标注步骤，也是数据中相关特征统计分布的统计分布。然而，并排查看这些流程使得可以关联它们的不同视角以及在不同DAG中出现在同一阶段但节点不同的关系。从某种意义上说，DAGs提供了无处不在的语言背后的概念模型的视觉表示。它们的主要局限性是无法有效地描述弧的语义意义，就像UML的情况一样：这些信息就是架构文档中各种文档提供的信息，补充了我们从DAGs中可以看到的内容。
- en: 8.4 Documenting Algorithms and Business Cases
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 记录算法和业务案例
- en: 'The documentation of individual modules and of how they work together in the
    machine learning pipeline should be supplemented by two other documents:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 单个模块的文档以及它们在机器学习流程中如何协同工作的文档，应该由另外两个文档来补充：
- en: a *technical report* detailing the relevant probabilistic and statistical properties
    of the machine learning models; and
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一份*技术报告*，详细说明了机器学习模型的相关概率和统计特性；以及
- en: a *mission statement* describing, at a high level, what is the goal of the machine
    learning pipeline from a domain or business perspective.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一份*使命宣言*，从领域或业务的角度，高层次地描述机器学习流程的目标。
- en: 'There are several reasons for preparing a technical report covering the relevant
    facts about the algorithms and the models. Firstly, we can establish a coherent
    mathematical notation that agrees with the ubiquitous language (Section [8.1](documenting-code.html#comments))
    and with the variable naming scheme used by our modules (Section [6.2](writing-code.html#naming)),
    and that can be related to that of any external libraries we may be using. Different
    parts of the scientific literature have different notation practices: the same
    concepts may be expressed with different notation or have different definitions,
    or the same notation may have different meanings. This is likely to cause some
    confusion because of the variety of approaches involved in a real-world machine
    learning pipeline. Secondly, a technical report will reduce the need to access
    the academic literature, which can become difficult over time because journal
    papers, conference proceedings and their supplementary materials can be locked
    behind paywalls or simply vanish from the Internet when their authors change employers.
    Thirdly, we can limit ourselves to the properties of the models and of the algorithms
    that are relevant to us, and we can concentrate on documenting those properties
    well and in an approachable way. (It is not common for the canonical reference
    for a model to be its clearest illustration, especially in machine learning where
    8-page conference papers represent a fair share of the literature!) In particular,
    we can focus on the pros and cons of any models and algorithms we evaluate for
    use in the pipeline with respect to the specific domain that is relevant to us.
    This will be more informative than most benchmarking efforts based on reference
    data sets from the literature. Finally, we can easily cross-reference the technical
    report with both module interface (Section [8.2](documenting-code.html#apidocs))
    and design documentation (Section [8.3](documenting-code.html#designdocs)).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 准备一份技术报告，涵盖算法和模型的相关事实，有几个原因。首先，我们可以建立一个连贯的数学符号体系，它符合无处不在的语言（第[8.1](documenting-code.html#comments)节）以及我们模块使用的变量命名方案（第[6.2](writing-code.html#naming)节），并且可以与任何我们可能使用的第三方库的符号体系相关联。科学文献的不同部分有不同的符号习惯：相同的概念可能用不同的符号表达，或者有不同的定义，或者相同的符号可能有不同的含义。这可能会因为涉及现实世界机器学习管道的各种方法而引起一些混淆。其次，技术报告将减少访问学术文献的需求，随着时间的推移，这可能变得困难，因为期刊论文、会议论文及其补充材料可能被付费墙锁定，或者当作者更换雇主时简单地从互联网上消失。第三，我们可以限制自己只关注与我们相关的模型和算法的性质，并且我们可以专注于以易于理解的方式详细记录这些性质。（对于模型的规范参考通常是它最清晰的说明，这在机器学习中尤其如此，因为8页的会议论文在文献中占有一席之地！）特别是，我们可以专注于我们评估的任何模型和算法在特定领域内的优缺点，这个领域与我们相关。这将比基于文献中的参考数据集的大多数基准测试工作更有信息量。最后，我们可以轻松地将技术报告与模块接口（第[8.2](documenting-code.html#apidocs)节）和设计文档（第[8.3](documenting-code.html#designdocs)节）进行交叉引用。
- en: 'A mission statement, which (Clements et al. [2011](#ref-clements)) calls a
    “domain vision statement”, is a brief document of 1–2 pages identifying the core
    domain of the machine learning pipeline and its aims as established during project
    scoping (Section [5.3.1](design-code.html#scoping-pipeline)). It serves two purposes:
    evaluating whether the pipeline is fit for its intended purpose and guiding its
    evolution at a strategic level. By stating its purpose, the mission statement
    tells us what outcome we should judge. In turn, this allows us to define a scale
    of measurement ranging from “bad performance” to “good performance” according
    to how effectively and efficiently the pipeline fulfils its purpose. At the same
    time, it can serve as a high-level guideline for evolving it. The compute systems,
    the machine learning models and the domain concepts the pipeline is built upon
    will inevitably change over time. With each change, we can plan at the tactical
    level how to evolve it by pinpointing which components we should update and how.
    However, all these local changes should be consistent with a long-term strategy
    that ensures that the pipeline evolves coherently as a whole over time as its
    intended purpose changes. In other words, the mission statement is the “aspirational”
    counterpart of the more technical design documentation (Section [8.3](documenting-code.html#designdocs))
    and of the more practical use cases (Section [8.5](documenting-code.html#usecases)).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 任务声明，Clements等人（[2011](#ref-clements)）称之为“领域愿景声明”，是一份1-2页的简短文档，用于确定机器学习管道的核心领域及其在项目范围规划（第[5.3.1](design-code.html#scoping-pipeline)节）期间确立的目标。它有两个目的：评估管道是否适合其预期用途，并在战略层面指导其演变。通过陈述其目的，任务声明告诉我们应该评估什么样的结果。反过来，这使我们能够根据管道如何有效地和高效地实现其目的，定义一个从“表现不佳”到“表现良好”的测量范围。同时，它还可以作为其演变的指导方针。构建管道的计算系统、机器学习模型以及其基于的领域概念将不可避免地随时间而变化。每次变化时，我们都可以在战术层面制定计划，通过确定哪些组件需要更新以及如何更新来演变它。然而，所有这些局部变化都应该与确保管道随着时间的推移作为一个整体连贯演变的长期战略保持一致。换句话说，任务声明是更技术性的设计文档（第[8.3](documenting-code.html#designdocs)节）和更实际的使用案例（第[8.5](documenting-code.html#usecases)节）的“理想”对应物。
- en: 'For example, consider the mission statement behind the machine learning pipeline
    powering Spotify’s home screen (Edmundson [2021](#ref-spotify-ml)). Firstly:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑Spotify首页背后推动机器学习管道的任务声明（Edmundson [2021](#ref-spotify-ml)）。首先：
- en: “At Spotify, our goal is to connect listeners with creators, and one way we
    do that is by recommending quality music and podcasts on the Home page. Machine
    learning is central to how we personalize the Home page user experience and connect
    listeners to the creators that are most relevant to them.”
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在Spotify，我们的目标是连接听众与创作者，我们实现这一目标的一种方式是在首页推荐高质量的音乐和播客。机器学习是我们个性化首页用户体验并将听众与最相关的创作者连接起来的核心。”
- en: 'The pipeline is a recommender system that matches users with contents. This
    requires tracking the users’ listening data and Spotify’s catalogue of music and
    podcasts, which has implications in terms of hardware, data ingestion and data
    processing capabilities in the pipeline. Both user data and the catalogue will
    change over time, as will their features: hence the models predicting which music
    and which podcasts the users may like should be updated at regular intervals.
    How often will depend on how quickly the catalogue changes, on how quickly the
    size of the users’ listening data grows and on what models we will use, so it
    is not appropriate nor possible to recommend a schedule for the updates. For the
    same reason, what features of the data will be used to provide the recommendations
    is left unstated. Furthermore, the exact definition of “quality” and “relevant”
    will depend on the specific technical criteria putting them into numbers, on how
    engagement will be measured, on the models, and on how their accuracy metrics
    relate to revenue.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道是一个推荐系统，将用户与内容相匹配。这需要跟踪用户的收听数据和Spotify的音乐和播客目录，这在管道中的硬件、数据摄取和数据处理能力方面有影响。用户数据和目录都将随时间而变化，它们的功能也是如此：因此，预测用户可能喜欢哪些音乐和哪些播客的模型应该定期更新。更新的频率将取决于目录的变化速度、用户收听数据规模的增长速度以及我们将使用的模型，因此不适宜也不可能为更新制定一个时间表。同样地，用于提供推荐的数据特征也没有明确说明。此外，“质量”和“相关”的确切定义将取决于将它们转化为数字的具体技术标准，取决于如何衡量参与度，取决于模型以及它们的准确度指标如何与收入相关。
- en: 'Secondly, the two final outputs of the pipeline are introduced in domain terms:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，以领域术语介绍管道的两个最终输出：
- en: '“Stage 1: Candidate generation: The best albums, playlists, artists, and podcasts
    are selected for each listener. Stage 2: Ranking: Candidates are ranked in the
    best order for each listener.”'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “第一阶段：候选人生成：为每位听众选择最佳的专辑、播放列表、艺术家和播客。第二阶段：排名：为每位听众按最佳顺序排列候选人。”
- en: 'The pipeline is expected to present the users with recommendations ranked in
    terms of (predicted) preference. Again, details such as how many items are recommended
    and how they are ranked are implementation details that are bound to change over
    time and thus do not belong in the mission statement. The outputs are then described
    in more detail:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 预期管道将向用户提供按（预测）偏好排序的推荐。再次，诸如推荐多少项以及如何排序等细节是实施细节，这些细节随着时间的推移可能会发生变化，因此不属于使命声明。然后更详细地描述输出：
- en: '“The Podcast Model: Predicts podcasts a listener is likely to listen to in
    the ‘Shows you might like’ shelf. The Shortcuts Model: Predicts the listener’s
    next familiar listen in the Shortcuts feature. The Playlists Model: Predicts the
    playlists a new listener is likely to listen to in the ‘Try something else’ shelf.”'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “播客模型：预测听众可能在‘你可能喜欢的节目’架子上收听的播客。快捷方式模型：预测听众在快捷方式功能中的下一次熟悉的收听。播放列表模型：预测新听众可能在‘尝试其他内容’架子上收听的播放列表。”
- en: 'The statement does not specify which models will be used, nor how many. It
    does not even state that they will be machine learning models: in fact, it later
    says that “some content is generated via heuristics and rules and some content
    is manually curated by editors.” Which models or heuristics are appropriate will
    depend on what features will be available in the data, on what state-of-the-art
    models will be available from the literature, and on what software and hardware
    will be needed to provide recommendations in real time.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该声明没有指定将使用哪些模型，也没有说明数量。甚至没有声明它们将是机器学习模型：实际上，它后来表示“一些内容是通过启发式和规则生成的，一些内容是由编辑手动策划的。”哪些模型或启发式方法合适将取决于数据中可用的哪些特征，从文献中可获得的哪些最先进模型，以及提供实时推荐所需的软件和硬件。
- en: 'Thirdly, how the outputs of the pipeline are presented to the users:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，如何向用户展示管道的输出：
- en: “The Home page consists of cards — the square items that represent an album,
    playlist, etc. — and shelves — the horizontal rows that contain multiple cards.”
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “主页由卡片组成——代表专辑、播放列表等的方形项目——以及货架——包含多个卡片的水平行。”
- en: 'Note how the statement introduces the metaphor the user interface will be based
    on, but without describing any implementation details. It would not be appropriate
    to do it here: we will want to change the interface over time in response to any
    insights from usability studies and from usage patterns collected by telemetry.
    Furthermore, different platforms and operating systems will have different capabilities
    and will require at least some levels of customisation. For instance, it is often
    impossible to design a user interface with good ergonomics on both mobile and
    desktop systems.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意声明如何引入用户界面将基于的隐喻，但没有描述任何实现细节。在这里这样做是不合适的：我们希望随着时间的推移根据任何来自可用性研究和由遥测收集的使用模式获得的见解来改变界面。此外，不同的平台和操作系统将具有不同的功能，并且至少需要一些级别的定制。例如，在移动和桌面系统中设计具有良好人体工程学的用户界面通常是不可行的。
- en: 8.5 Illustrating Practical Use Cases
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 展示实际应用案例
- en: 'Last but not least, topical examples showcasing the machine learning pipeline
    in action can be very valuable. Pipelines are built to address some need like
    automating and speeding up analyses or improving products: the best way to motivate
    their development, use and maintenance is to show that they can address that need
    effectively and efficiently in the context of the domain or of the business line
    of the prospective users. Users will then be able to relate to the problems the
    machine learning pipeline is tackling and they will be in a position to appreciate
    the advantages of using it. The types of documentation presented in the previous
    sections are either too technical, too abstract or too focused on the inner workings
    of the pipeline for this purpose.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，展示机器学习流程实际应用的典型案例可以非常有价值。流程是为了满足某些需求而构建的，比如自动化和加速分析或改进产品：最好的方式是展示它们能够有效地、高效地在目标用户所在的领域或业务线中满足这些需求。这样，用户就能与机器学习流程所解决的问题产生共鸣，并且能够欣赏使用它的优势。前几节中展示的文档类型要么过于技术化，要么过于抽象，要么过于关注流程的内部运作，不适合这个目的。
- en: An example of a very effective use case is the InnerEye project (Microsoft Research
    Cambridge [2022](#ref-innereye)) from Microsoft Research Cambridge (UK), which
    aims to develop machine learning pipelines for medical imaging. The video linked
    in the reference talks about the specific application of performing image segmentation
    in 3D medical images taken from cancer patients scheduled to be treated with radiotherapy.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常有效的用例示例是来自微软研究剑桥（英国）的InnerEye项目（[2022](#ref-innereye)），该项目旨在开发用于医学成像的机器学习流程。参考中链接的视频讨论了在计划接受放射疗法的癌症患者身上进行3D医学图像分割的具体应用。
- en: '*It states the need in clinical terms*: speeding up the segmentation in magnetic
    resonance (MR) and computerised tomography (CT) scans while retaining a sufficient
    degree of accuracy.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*它以临床术语说明了需求*：在磁共振（MR）和计算机断层扫描（CT）中加快分割速度，同时保持足够的精度。'
- en: '*It states the problem in a way prospective users can relate to*: radiologists
    do segmentation manually, outlining the tumour in a sequence of dozens of cross-section
    images with a visual tool to obtain a 3D contour. This is a slow process, and
    the precision of the contour is limited. It takes hours of preparation to map
    tumours and healthy tissues to target treatment for the former and to limit exposure
    for the latter.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*它以潜在用户能够理解的方式陈述了问题*：放射科医生手动进行分割，使用视觉工具在一系列数十个横截面图像中勾勒出肿瘤的轮廓。这是一个缓慢的过程，轮廓的精度有限。将肿瘤和健康组织映射到目标治疗以及限制后者暴露需要数小时准备。'
- en: '*It states how the machine learning pipeline can address the need from the
    perspective of the user*: automatic or human-assisted segmentation. The video
    shows the user interface that would be used by the radiologists, to give them
    a feeling of how it would fit in their everyday work. This makes it possible to
    contrast, live, the time it takes for manual, automatic and human-assisted segmentation
    as well as the level of detail and precision of the segmentation.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*它从用户的角度说明了机器学习流程如何满足需求*：自动或人工辅助的分割。视频展示了放射科医生将使用的用户界面，让他们感受到它将如何融入他们的日常工作。这使得能够实时对比手动、自动和人工辅助分割所需的时间以及分割的详细程度和精度。'
- en: '*It states the value of the solution to the user*: it takes minutes instead
    of hours to prepare a treatment plan for a patient with the desired accuracy.
    Furthermore, the same tools can be used to track how cancer is responding to therapy.
    These improvements will lead to better treatments and better outcomes.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*它向用户说明了解决方案的价值*：为患者准备一个具有所需精度的治疗方案只需几分钟，而不是数小时。此外，相同的工具还可以用来跟踪癌症对治疗的反应。这些改进将导致更好的治疗和更好的结果。'
- en: Note that the video does not make any quantitative statements about running
    times nor about the statistical accuracy of the segmentation as neither would
    be easily interpretable for radiologists. Instead, the InnerEye project has a
    web page linking all the scientific publications where we can find these numbers.
    Machine learning engineers can use them to evaluate the pipeline from the perspective
    of their own discipline. Furthermore, the InnerEye project news page highlights
    that the machine learning pipeline has been deployed and is currently used on
    actual patients at Addenbrooke’s Hospital in Cambridge. The implication that it
    obtained regulatory approval and that a radiology department finds it worthwhile
    to use it are strong indications that the machine learning pipeline is not an
    academic endeavour but something that provides value in real-world clinical practice.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，视频没有就运行时间或分割的统计准确性做出任何定量陈述，因为这两者对放射科医生来说都不容易解释。相反，InnerEye 项目有一个网页链接所有科学出版物，我们可以从中找到这些数字。机器学习工程师可以使用它们从自己学科的角度评估管道。此外，InnerEye
    项目的新闻页面强调，机器学习管道已被部署，并且目前在剑桥的 Addenbrooke 医院的实际患者中使用。它获得了监管批准，并且放射科部门认为它值得使用，这些都是强有力的迹象，表明机器学习管道不是一个学术项目，而是一个在现实世界临床实践中提供价值的实体。
- en: Finally, we would like to point out that practical use cases may also be instrumental
    in gathering feedback from prospective users. Illustrating them will provide a
    natural venue for users to discuss how the machine learning pipeline would be
    useful (or not) and what their strong (weak) points appear to be from their perspective.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们想指出，实际用例也可能在收集潜在用户的反馈方面起到重要作用。展示这些用例将为用户提供一个自然的环境来讨论机器学习管道的实用性（或不实用性）以及从他们的角度来看，其优点（或缺点）似乎是什么。
- en: References
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Brandl, G., and the Sphinx Team. 2022\. *Sphinx: Python Documentation Generator*.
    [https://www.sphinx-doc.org/en/master/](https://www.sphinx-doc.org/en/master/).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 'Brandl, G., and the Sphinx Team. 2022\. *Sphinx: Python Documentation Generator*.
    [https://www.sphinx-doc.org/en/master/](https://www.sphinx-doc.org/en/master/).'
- en: 'Carpenter, B., A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt,
    M. Brubaker, J. Guo, P. Li, and A. Riddell. 2017\. “Stan: A Probabilistic Programming
    Language.” *Journal of Statistical Software* 76 (1): 1–32.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 'Carpenter, B., A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt,
    M. Brubaker, J. Guo, P. Li, and A. Riddell. 2017\. “Stan: A Probabilistic Programming
    Language.” *Journal of Statistical Software* 76 (1): 1–32.'
- en: 'Clements, P., F. Bachmann, L. Bass, D. Garlan, J. Ivers, R. Little, P. Merson,
    R. Nord, and J. Stafford. 2011\. *Documenting Software Architectures: Views and
    Beyond*. 2nd ed. Addison-Wesley.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'Clements, P., F. Bachmann, L. Bass, D. Garlan, J. Ivers, R. Little, P. Merson,
    R. Nord, and J. Stafford. 2011\. *Documenting Software Architectures: Views and
    Beyond*. 2nd ed. Addison-Wesley.'
- en: CRAN Team. 2022\. *The Comprehensive R Archive Network*. [https://cran.r-project.org/](https://cran.r-project.org/).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: CRAN Team. 2022\. *The Comprehensive R Archive Network*. [https://cran.r-project.org/](https://cran.r-project.org/).
- en: Edmundson, A. 2021\. *The Rise (and Lessons Learned) of ML Models to Personalize
    Content on Home*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Edmundson, A. 2021\. *The Rise (and Lessons Learned) of ML Models to Personalize
    Content on Home*.
- en: 'Evans, E. 2003\. *Domain-Driven Design: Tackling Complexity in the Heart of
    Software*. Addison-Wesley.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 'Evans, E. 2003\. *Domain-Driven Design: Tackling Complexity in the Heart of
    Software*. Addison-Wesley.'
- en: Fowler, M. 2003\. *UML Distilled*. 3rd ed. Addison-Wesley.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Fowler, M. 2003\. *UML Distilled*. 3rd ed. Addison-Wesley.
- en: 'Fowler, M. 2018\. *Refactoring: Improving the Design of Existing Code*. 2nd
    ed. Addison-Wesley.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 'Fowler, M. 2018\. *Refactoring: Improving the Design of Existing Code*. 2nd
    ed. Addison-Wesley.'
- en: Martin, R. C. 2008\. *Clean Code*. Prentice Hall.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Martin, R. C. 2008\. *Clean Code*. Prentice Hall.
- en: McConnell, S. 2004\. *Code Complete*. 2nd ed. Microsoft Press.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: McConnell, S. 2004\. *Code Complete*. 2nd ed. Microsoft Press.
- en: Microsoft Research Cambridge. 2022\. *Project InnerEye–Democratizing Medical
    Imaging AI*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 微软研究院剑桥分院. 2022\. *Project InnerEye–Democratizing Medical Imaging AI*.
- en: 'Muth, C., Z. Oravecz, and J. Gabry. 2018\. “User-Friendly Bayesian Regression
    Modeling: A Tutorial with rstanarm and shinystan.” *The Quantitative Methods for
    Psychology* 14 (2): 99–119.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 'Muth, C., Z. Oravecz, and J. Gabry. 2018\. “User-Friendly Bayesian Regression
    Modeling: A Tutorial with rstanarm and shinystan.” *The Quantitative Methods for
    Psychology* 14 (2): 99–119.'
- en: Ousterhout, J. 2018\. *A Philosophy of Software Design*. Yaknyam Press.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Ousterhout, J. 2018\. *A Philosophy of Software Design*. Yaknyam Press.
- en: Project Jupyter. 2022\. *Jupyter*. [https://jupyter.org/](https://jupyter.org/).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Project Jupyter. 2022\. *Jupyter*. [https://jupyter.org/](https://jupyter.org/).
- en: 'Schubert, E., J. Sander, M. Ester, H. P. Kriegel, and X Xu. 2017\. “DBSCAN
    Revisited, Revisited: Why and How You Should (Still) Use DBSCAN.” *ACM Transactions
    on Database Systems* 42 (3): 19.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '施布特, E., J. 桑德, M. 埃斯特, H. P. 克里格尔, 和 X 徐. 2017. “DBSCAN 重访，再重访：为什么以及如何（仍然）使用
    DBSCAN.” *ACM 数据库系统事务* 42 (3): 19.'
- en: 'Scikit-learn Developers. 2022\. *Scikit-learn: Machine Learning in Python*.
    [https://scikit-learn.org/](https://scikit-learn.org/).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 'Scikit-learn 开发者. 2022. *Scikit-learn: Python 中的机器学习*. [https://scikit-learn.org/](https://scikit-learn.org/).'
- en: Spotify. 2022b. *Spotify Engineering Blog*. [https://engineering.atspotify.com/](https://engineering.atspotify.com/).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Spotify. 2022b. *Spotify 工程博客*. [https://engineering.atspotify.com/](https://engineering.atspotify.com/).
- en: 'The mypy Project. 2014\. *mypy: Optional Static Typing for Python*. [http://mypy-lang.org/](http://mypy-lang.org/).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: mypy 项目. 2014. *mypy：Python 的可选静态类型*. [http://mypy-lang.org/](http://mypy-lang.org/).
- en: 'Thomas, D., and A. Hunt. 2019\. *The Pragmatic Programmer: Your Journey to
    Mastery*. Anniversary. Addison-Wesley.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 托马斯, D., 和 A. 汉特. 2019. *实用程序员：你的精通之旅*. 周年纪念版. 奥德赛出版社.
- en: Uber Technologies. 2022\. *Uber Engineering Blog*. [https://eng.uber.com/](https://eng.uber.com/).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Uber 技术公司. 2022. *Uber 工程博客*. [https://eng.uber.com/](https://eng.uber.com/).
- en: van Heesch, D. 2022\. *Doxygen*. [https://www.doxygen.nl/index.html](https://www.doxygen.nl/index.html).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 范希施，D. 2022. *Doxygen*. [https://www.doxygen.nl/index.html](https://www.doxygen.nl/index.html).
- en: 'Wickham, H., P. Danenberg, G. Csárdi, M. Eugster, and RStudio. 2022\. *roxygen2:
    In-Line Documentation for R*.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 惠克姆, H., P. 丹内伯格, G. 卡尔迪, M. 尤格斯特, 和 RStudio. 2022. *roxygen2：R 的内联文档*.
- en: Xie, Y. 2015\. *Dynamic Documents with R and knitr*. 2nd ed. CRC Press.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 谢宇. 2015. *使用 R 和 knitr 创建动态文档*. 2版. CRC 压力出版社.
- en: 'Zelvenskiy, S., G. Harisinghani, T. Yu, E. Ng, and R. Wei. 2022\. *Project
    Radar: Intelligent Early-Fraud Detection*. [https://eng.uber.com/project-radar-intelligent-early-fraud-detection/](https://eng.uber.com/project-radar-intelligent-early-fraud-detection/).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 泽尔文斯基，S., G. 哈里桑尼, T. 余, E. 邱, 和 R. 韦. 2022. *Project Radar：智能早期欺诈检测*. [https://eng.uber.com/project-radar-intelligent-early-fraud-detection/](https://eng.uber.com/project-radar-intelligent-early-fraud-detection/).
