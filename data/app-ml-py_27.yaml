- en: Bagging and Random Forest
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bagging å’Œéšæœºæ£®æ—
- en: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ensemble_trees.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ensemble_trees.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ensemble_trees.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ensemble_trees.html)
- en: Michael J. Pyrcz, Professor, The University of Texas at Austin
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·JÂ·çš®å°”èŒ¨ï¼Œæ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python
    åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html) | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
- en: 'Chapter of e-book â€œApplied Machine Learning in Python: a Hands-on Guide with
    Codeâ€.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç”µå­ä¹¦â€œPython åº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„æ‰‹å†Œâ€çš„ä¸€ç« ã€‚
- en: 'Cite this e-Book as:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å°†æ­¤ç”µå­ä¹¦å¼•ç”¨å¦‚ä¸‹ï¼š
- en: 'Pyrcz, M.J., 2024, *Applied Machine Learning in Python: A Hands-on Guide with
    Code* [e-book]. Zenodo. doi:10.5281/zenodo.15169138 [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: çš®å°”èŒ¨ï¼ŒM.J.ï¼Œ2024ï¼Œ*Python åº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„æ‰‹å†Œ* [ç”µå­ä¹¦]. Zenodo. doi:10.5281/zenodo.15169138
    [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)
- en: 'The workflows in this book and more are available here:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦ä¸­çš„å·¥ä½œæµç¨‹ä»¥åŠå…¶ä»–å·¥ä½œæµç¨‹éƒ½å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ï¼š
- en: 'Cite the MachineLearningDemos GitHub Repository as:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å°† MachineLearningDemos GitHub ä»“åº“å¼•ç”¨å¦‚ä¸‹ï¼š
- en: 'Pyrcz, M.J., 2024, *MachineLearningDemos: Python Machine Learning Demonstration
    Workflows Repository* (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312\.
    GitHub repository: [GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'çš®å°”èŒ¨ï¼ŒM.J.ï¼Œ2024ï¼Œ*MachineLearningDemos: Python æœºå™¨å­¦ä¹ æ¼”ç¤ºå·¥ä½œæµç¨‹ä»“åº“*ï¼ˆ0.0.3ï¼‰[è½¯ä»¶]. Zenodo.
    DOI: 10.5281/zenodo.13835312\. GitHub ä»“åº“ï¼š[GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
- en: By Michael J. Pyrcz
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ï¼šè¿ˆå…‹å°”Â·JÂ·çš®å°”èŒ¨
- en: Â© Copyright 2024.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Â© ç‰ˆæƒæ‰€æœ‰ 2024ã€‚
- en: This chapter is a tutorial for / demonstration of **Bagging and Random Forest**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« æ˜¯å…³äº**Bagging å’Œéšæœºæ£®æ—**çš„æ•™ç¨‹å’Œæ¼”ç¤ºã€‚
- en: '**YouTube Lecture**: check out my lectures on:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**YouTube è®²åº§**ï¼šæŸ¥çœ‹æˆ‘åœ¨ä»¥ä¸‹æ–¹é¢çš„è®²åº§ï¼š'
- en: '[Introduction to Machine Learning](https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æœºå™¨å­¦ä¹ ç®€ä»‹](https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl)'
- en: '[Decision Tree](https://youtu.be/JUGo1Pu3QT4?si=ebQXv6Yglar0mYWp)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å†³ç­–æ ‘](https://youtu.be/JUGo1Pu3QT4?si=ebQXv6Yglar0mYWp)'
- en: '[Random Forest](https://youtu.be/m5_wk310fho?si=up-mzVPHvniXsYE6)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[éšæœºæ£®æ—](https://youtu.be/m5_wk310fho?si=up-mzVPHvniXsYE6)'
- en: '[Gradient Boosting](https://youtu.be/___T8_ixIwc?si=ozHR_eIuMF3SPTxJ)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ¢¯åº¦æå‡](https://youtu.be/___T8_ixIwc?si=ozHR_eIuMF3SPTxJ)'
- en: These lectures are all part of my [Machine Learning Course](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)
    on YouTube with linked well-documented Python workflows and interactive dashboards.
    My goal is to share accessible, actionable, and repeatable educational content.
    If you want to know about my motivation, check out [Michaelâ€™s Story](https://michaelpyrcz.com/my-story).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è®²åº§éƒ½æ˜¯æˆ‘ YouTube ä¸Šçš„[æœºå™¨å­¦ä¹ è¯¾ç¨‹](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)çš„ä¸€éƒ¨åˆ†ï¼Œå…¶ä¸­åŒ…å«é“¾æ¥çš„è¯¦ç»†è®°å½•çš„
    Python å·¥ä½œæµç¨‹å’Œäº¤äº’å¼ä»ªè¡¨æ¿ã€‚æˆ‘çš„ç›®æ ‡æ˜¯åˆ†äº«æ˜“äºè·å–ã€å¯æ“ä½œå’Œå¯é‡å¤çš„æ•™è‚²å†…å®¹ã€‚å¦‚æœä½ æƒ³äº†è§£æˆ‘çš„åŠ¨æœºï¼Œè¯·æŸ¥çœ‹[è¿ˆå…‹å°”çš„æ•…äº‹](https://michaelpyrcz.com/my-story)ã€‚
- en: Motivations for Bagging and Random Forest
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Bagging å’Œéšæœºæ£®æ—çš„åŠ¨æœº
- en: Decision tree are not the most powerful, cutting edge method in machine learning,
    but,
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘ä¸æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¼ºå¤§ã€æœ€å‰æ²¿çš„æ–¹æ³•ï¼Œä½†ï¼Œ
- en: one of the most understandable, interpretable predictive machine learning modeling
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€æ˜“äºç†è§£ã€å¯è§£é‡Šçš„é¢„æµ‹æœºå™¨å­¦ä¹ å»ºæ¨¡ä¹‹ä¸€
- en: '![](../Images/e66b56981b9ff607c82a7fbfc116ccb1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e66b56981b9ff607c82a7fbfc116ccb1.png)'
- en: Solitary black spruce tree in Hinton, Alberta, Canada, image from https://hikebiketravel.com/6-fun-things-to-do-in-hinton-alberta-in-winter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ æ‹¿å¤§è‰¾ä¼¯å¡”çœå¸Œé¡¿çš„å­¤ç‹¬é»‘äº‘æ‰æ ‘ï¼Œå›¾ç‰‡æ¥è‡ª https://hikebiketravel.com/6-fun-things-to-do-in-hinton-alberta-in-winter.
- en: decision trees are enhanced with random forests, bagging and boosting to be
    one of the best models in many cases
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘é€šè¿‡éšæœºæ£®æ—ã€è¢‹è£…å’Œæå‡è¢«å¢å¼ºï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹æˆä¸ºæœ€ä½³æ¨¡å‹ä¹‹ä¸€
- en: '![](../Images/ca4872f08f83736f351592c849901c2b.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca4872f08f83736f351592c849901c2b.png)'
- en: Black spruce forest near Hinton, Alberta, east of Jasper National Park, Canada,
    image from https://en.wikivoyage.org/wiki/Hinton.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ æ‹¿å¤§è‰¾ä¼¯å¡”çœHintoné™„è¿‘çš„é»‘äº‘æ‰æ£®æ—ï¼Œè´¾æ–¯ç€å›½å®¶å…¬å›­ä¸œéƒ¨ï¼Œå›¾ç‰‡æ¥è‡ª https://en.wikivoyage.org/wiki/Hintonã€‚
- en: Now we cover ensemble trees, tree bagging and random forest building on decision
    trees. First, I provide some prerequisite concepts for decision trees and then
    for ensemble methods.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ¥ä»‹ç»åŸºäºå†³ç­–æ ‘çš„é›†æˆæ ‘ã€æ ‘è¢‹å’Œéšæœºæ£®æ—æ„å»ºã€‚é¦–å…ˆï¼Œæˆ‘æä¾›ä¸€äº›å†³ç­–æ ‘å’Œé›†æˆæ–¹æ³•çš„åŸºç¡€æ¦‚å¿µã€‚
- en: if you are not familiar with decision trees it may be a good idea to review
    the [Decision Tree Chapter](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_decision_tree.html).
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸å¤ªç†Ÿæ‚‰å†³ç­–æ ‘ï¼Œå›é¡¾ä¸€ä¸‹[å†³ç­–æ ‘ç« èŠ‚](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_decision_tree.html)å¯èƒ½æ˜¯ä¸ªå¥½ä¸»æ„ã€‚
- en: Tree Model Formulation
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‘æ¨¡å‹å…¬å¼
- en: 'The prediction feature space is partitioned into \(J\) exhaustive, mutually
    exclusive regions \(R_1, R_2, \ldots, R_J\). For a given prediction case \(x_1,\ldots,x_m
    \in R_j\), the prediction is:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ç©ºé—´è¢«åˆ†å‰²æˆ \(J\) ä¸ªç©·å°½ä¸”äº’æ–¥çš„åŒºåŸŸ \(R_1, R_2, \ldots, R_J\)ã€‚å¯¹äºç»™å®šçš„é¢„æµ‹æ¡ˆä¾‹ \(x_1,\ldots,x_m
    \in R_j\)ï¼Œé¢„æµ‹ä¸ºï¼š
- en: '**Regression** - the average of the training data in the region, \(R_j\)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›å½’** â€“ åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ•°æ®çš„å¹³å‡å€¼'
- en: \[ \hat{y} = \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} y_i \]
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} y_i \]
- en: where \(\hat{y}\) is the predicted value for input \(\mathbf{x}\), \(R_j\) is
    the region (leaf node) that \(\mathbf{x}\) falls into, \(|R_j|\) is the number
    of training samples in region \(R_j\), and \(y_i\) is the actual target values
    of those training samples in \(R_j\).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\hat{y}\) æ˜¯è¾“å…¥ \(\mathbf{x}\) çš„é¢„æµ‹å€¼ï¼Œ\(R_j\) æ˜¯ \(\mathbf{x}\) è½å…¥çš„åŒºåŸŸï¼ˆå¶èŠ‚ç‚¹ï¼‰ï¼Œ\(|R_j|\)
    æ˜¯åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ ·æœ¬çš„æ•°é‡ï¼Œ\(y_i\) æ˜¯è¿™äº›è®­ç»ƒæ ·æœ¬åœ¨ \(R_j\) ä¸­çš„å®é™…ç›®æ ‡å€¼ã€‚
- en: '**Classification** - category with the plurality of training cases (most common
    case) in region \(R_j\):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»** â€“ åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ¡ˆä¾‹å¤šæ•°ï¼ˆæœ€å¸¸è§æ¡ˆä¾‹ï¼‰çš„ç±»åˆ«ï¼š'
- en: \[ \hat{y} = \arg\max_{c \in C} \left( \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in
    R_j} \mathbb{1}(y_i = c) \right) \]
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \arg\max_{c \in C} \left( \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in
    R_j} \mathbb{1}(y_i = c) \right) \]
- en: where \(C\) is the set of all possible categories, \(\mathbb{1}(y_i = c)\) is
    indicator transform, 1 if \(y_i = c\), 0 otherwise, \(|R_j|\) is the number of
    training samples in region \(R_j\), and \(\hat{y}\) is the predicted class label.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(C\) æ˜¯æ‰€æœ‰å¯èƒ½ç±»åˆ«çš„é›†åˆï¼Œ\(\mathbb{1}(y_i = c)\) æ˜¯æŒ‡ç¤ºå˜æ¢ï¼Œè‹¥ \(y_i = c\) åˆ™ä¸º 1ï¼Œå¦åˆ™ä¸º 0ï¼Œ\(|R_j|\)
    æ˜¯åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ ·æœ¬çš„æ•°é‡ï¼Œ\(\hat{y}\) æ˜¯é¢„æµ‹çš„ç±»åˆ«æ ‡ç­¾ã€‚
- en: The predictor space, \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\), is segmented into \(J\) mutually exclusive,
    exhaustive regions, \(R_j, j = 1,\ldots,J\), where the regions are,
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç©ºé—´ï¼Œ\(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\)ï¼Œè¢«åˆ†å‰²æˆ\(J\)ä¸ªäº’æ–¥ä¸”ç©·å°½çš„åŒºåŸŸï¼Œ\(R_j, j = 1,\ldots,J\)ï¼Œå…¶ä¸­åŒºåŸŸä¸ºï¼Œ
- en: '**mutually exclusive** â€“ any combination of predictor features, \(x_1,\ldots,x_ğ‘š\),
    only belongs to a single region, \(R_j\)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**äº’æ–¥** â€“ ä»»ä½•é¢„æµ‹ç‰¹å¾ \(x_1,\ldots,x_ğ‘š\) çš„ç»„åˆåªå±äºå•ä¸ªåŒºåŸŸ \(R_j\)'
- en: '**exhaustive** â€“ all combinations of predictor feature values belong a region,
    \(R_j\), i.e., all the regions, \(R_j, j = 1,\ldots,J\), cover entire predictor
    feature space'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç©·å°½** â€“ æ‰€æœ‰é¢„æµ‹ç‰¹å¾å€¼çš„ç»„åˆéƒ½å±äºä¸€ä¸ªåŒºåŸŸï¼Œ\(R_j\)ï¼Œå³æ‰€æœ‰åŒºåŸŸï¼Œ\(R_j, j = 1,\ldots,J\)ï¼Œè¦†ç›–æ•´ä¸ªé¢„æµ‹ç‰¹å¾ç©ºé—´'
- en: All prediction cases, \(x_1,\ldots,x_m\) that fall in the same region, \(R_j\),
    are estimated with the same value.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è½åœ¨åŒä¸€åŒºåŸŸ \(R_j\) ä¸­çš„é¢„æµ‹æ¡ˆä¾‹ \(x_1,\ldots,x_m\) éƒ½ç”¨ç›¸åŒçš„å€¼è¿›è¡Œä¼°è®¡ã€‚
- en: the prediction model inherently discontinuous at the region boundaries
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹æ¨¡å‹åœ¨åŒºåŸŸè¾¹ç•Œå¤„æœ¬è´¨ä¸Šæ˜¯ä¸è¿ç»­çš„
- en: For example, consider this decision tree prediction model for the production
    response feature, \(\hat{Y}\)Â Ì‚from porosity, \(X_1\), predictor feature,
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè€ƒè™‘è¿™ä¸ªå†³ç­–æ ‘é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºä»å­”éš™ç‡ \(X_1\) é¢„æµ‹ç”Ÿäº§å“åº”ç‰¹å¾ \(\hat{Y}\)ï¼Œ
- en: '![](../Images/98d8fb73fe41299a6a9b443163b47c96.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98d8fb73fe41299a6a9b443163b47c96.png)'
- en: Four region decision tree with data and predictions, \(\hat{Y}(R_j) = \overline{Y}(R_j)\)
    by region, \(R_j, j=1,â€¦,4\). For example, given a predictor feature value of 13%
    porosity, the model predicts about 2,000 MCFPD for production.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å››åŒºåŸŸå†³ç­–æ ‘ä¸æ•°æ®å’Œé¢„æµ‹ï¼Œ\(\hat{Y}(R_j) = \overline{Y}(R_j)\) æŒ‰åŒºåŸŸ \(R_j, j=1,â€¦,4\) è®¡ç®—ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªå­”éš™ç‡ä¸º
    13% çš„é¢„æµ‹ç‰¹å¾å€¼ï¼Œæ¨¡å‹é¢„æµ‹äº§é‡çº¦ä¸º 2,000 MCFPDã€‚
- en: How do we segment the predictor feature space?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•åˆ†å‰²é¢„æµ‹ç‰¹å¾ç©ºé—´ï¼Ÿ
- en: the set of regions based on hierarchical, binary segmentation.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºåˆ†å±‚ã€äºŒåˆ†åˆ†å‰²çš„åŒºåŸŸé›†åˆã€‚
- en: Tree Loss Functions
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‘æŸå¤±å‡½æ•°
- en: For regression trees we minimize the residual sum of squares and for classification
    trees we minimize the weighted average Gini impurity.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå›å½’æ ‘ï¼Œæˆ‘ä»¬æœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œï¼Œå¯¹äºåˆ†ç±»æ ‘ï¼Œæˆ‘ä»¬æœ€å°åŒ–åŠ æƒå¹³å‡åŸºå°¼ä¸çº¯åº¦ã€‚
- en: The Residual Sum of Squares (RSS) measures the total squared difference between
    the actual values and predicted values in a regression tree,
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä½™å¹³æ–¹å’Œï¼ˆRSSï¼‰è¡¡é‡å›å½’æ ‘ä¸­å®é™…å€¼ä¸é¢„æµ‹å€¼ä¹‹é—´çš„æ€»å¹³æ–¹å·®ï¼Œ
- en: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
- en: where \(J\) is the total number of regions in the tree, \(R_j\) is the \(j\)
    region, \(y_i\) is the truth value of the response feature at observation the
    \(i\) training data, and \(\hat{y}_{R_j}\) is the predicted value for region \(R_j\),
    the mean of \(y_i \; \forall \; i \in R_j\).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(J\) æ˜¯æ ‘ä¸­åŒºåŸŸçš„æ€»æ•°ï¼Œ\(R_j\) æ˜¯ \(j\) åŒºåŸŸï¼Œ\(y_i\) æ˜¯ \(i\) ä¸ªè®­ç»ƒæ•°æ®ä¸­å“åº”ç‰¹å¾çš„çœŸå€¼ï¼Œ\(\hat{y}_{R_j}\)
    æ˜¯åŒºåŸŸ \(R_j\) çš„é¢„æµ‹å€¼ï¼Œå³ \(y_i \; \forall \; i \in R_j\) çš„å¹³å‡å€¼ã€‚
- en: 'When a parent node splits into two child nodes ( t_L ) and ( t_R ), the weighted
    Gini impurity is:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸€ä¸ªçˆ¶èŠ‚ç‚¹åˆ†è£‚æˆä¸¤ä¸ªå­èŠ‚ç‚¹ï¼ˆt_Lï¼‰å’Œï¼ˆt_Rï¼‰æ—¶ï¼ŒåŠ æƒåŸºå°¼ä¸çº¯åº¦ä¸ºï¼š
- en: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
- en: where \(J\) is the total number of regions in the tree, \(N\) is the total number
    of samples in the dataset, \(N_j\) is the number of samples in leaf node \(j\),
    and \(\text{Gini}(j)\) is the Gini impurity of leaf node \(j\).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(J\) æ˜¯æ ‘ä¸­åŒºåŸŸçš„æ€»æ•°ï¼Œ\(N\) æ˜¯æ•°æ®é›†ä¸­æ ·æœ¬çš„æ€»æ•°ï¼Œ\(N_j\) æ˜¯å¶å­èŠ‚ç‚¹ \(j\) ä¸­çš„æ ·æœ¬æ•°ï¼Œ\(\text{Gini}(j)\)
    æ˜¯å¶å­èŠ‚ç‚¹ \(j\) çš„åŸºå°¼ä¸çº¯åº¦ã€‚
- en: The Gini impurity for a single decision tree node is calculated as,
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä¸ªå†³ç­–æ ‘èŠ‚ç‚¹çš„åŸºå°¼ä¸çº¯åº¦è®¡ç®—å¦‚ä¸‹ï¼Œ
- en: \[ \text{Gini}(j) = 1 - \sum_{c=1}^{C} p_{j,c}^2 \]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Gini}(j) = 1 - \sum_{c=1}^{C} p_{j,c}^2 \]
- en: where \(p_{j,c}\) is the proportion of class \(c\) samples in node \(j\).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(p_{j,c}\) æ˜¯èŠ‚ç‚¹ \(j\) ä¸­ç±»åˆ« \(c\) æ ·æœ¬çš„æ¯”ä¾‹ã€‚
- en: For classification our loss function does not compare the predictions to the
    truth values like our regression loss!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåˆ†ç±»ï¼Œæˆ‘ä»¬çš„æŸå¤±å‡½æ•°ä¸æ¯”è¾ƒé¢„æµ‹å€¼ä¸çœŸå€¼ï¼Œå°±åƒæˆ‘ä»¬çš„å›å½’æŸå¤±ä¸€æ ·ï¼
- en: the Gini impurity penalizes mixtures of training data categories! A region of
    all one category of training data will have a Gini impurity of 0 to contribute
    to the over all loss.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºå°¼ä¸çº¯åº¦æƒ©ç½šè®­ç»ƒæ•°æ®ç±»åˆ«æ··åˆï¼æ‰€æœ‰ç±»åˆ«ä¸ºå•ä¸€ç±»åˆ«çš„è®­ç»ƒæ•°æ®åŒºåŸŸå°†å…·æœ‰åŸºå°¼ä¸çº¯åº¦ä¸º 0ï¼Œä»¥è´¡çŒ®æ•´ä½“æŸå¤±ã€‚
- en: Note that the by-region Gini impurity is,
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼ŒæŒ‰åŒºåŸŸè®¡ç®—çš„åŸºå°¼ä¸çº¯åº¦æ˜¯ï¼Œ
- en: '**weighted** - by the number of training data in each regions, regions with
    more training data have greater impact on the overall loss'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŠ æƒ** - ç”±æ¯ä¸ªåŒºåŸŸä¸­çš„è®­ç»ƒæ•°æ®æ•°é‡å†³å®šï¼Œå…·æœ‰æ›´å¤šè®­ç»ƒæ•°æ®çš„åŒºåŸŸå¯¹æ•´ä½“æŸå¤±æœ‰æ›´å¤§çš„å½±å“'
- en: '**averaged** - over all the regions to calculate the total Gini impurity of
    the decision tree'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¹³å‡** - åœ¨æ‰€æœ‰åŒºåŸŸä¸Šè®¡ç®—å†³ç­–æ ‘çš„æ€»åŸºå°¼ä¸çº¯åº¦'
- en: These losses are calculated during,
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æŸå¤±åœ¨ä»¥ä¸‹è¿‡ç¨‹ä¸­è®¡ç®—ï¼Œ
- en: '**tree model training** - with respect to training data to grow the tree'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‘æ¨¡å‹è®­ç»ƒ** - ä¸è®­ç»ƒæ•°æ®ç›¸å…³ï¼Œç”¨äºç”Ÿé•¿æ ‘'
- en: '**tree model tuning** - with respect to withheld testing data to select the
    optimum tree complexity.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‘æ¨¡å‹è°ƒæ•´** - ä¸ä¿ç•™çš„æµ‹è¯•æ•°æ®ç›¸å…³ï¼Œä»¥é€‰æ‹©æœ€ä½³æ ‘å¤æ‚åº¦ã€‚'
- en: Letâ€™s talk about tree model training first and then tree model tuning.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å…ˆè°ˆè°ˆæ ‘æ¨¡å‹è®­ç»ƒï¼Œç„¶åå†è°ˆæ ‘æ¨¡å‹è°ƒæ•´ã€‚
- en: Training the Tree Model
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ ‘æ¨¡å‹
- en: How do we calculate these mutually exclusive, exhaustive regions? This is accomplished
    through hierarchical binary segmentation of the predictor feature space.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•è®¡ç®—è¿™äº›äº’æ–¥ã€ç©·å°½çš„åŒºåŸŸï¼Ÿè¿™æ˜¯é€šè¿‡é¢„æµ‹ç‰¹å¾ç©ºé—´çš„åˆ†å±‚äºŒåˆ†åˆ†å‰²æ¥å®ç°çš„ã€‚
- en: Training a decision tree model is both,
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹æ˜¯ï¼Œ
- en: assigning the mutual exclusive, exhaustive regions
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†é…äº’æ–¥ã€ç©·å°½çš„åŒºåŸŸ
- en: building a decision tree, each region is a terminal node, also known as a leaf
    node
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ„å»ºå†³ç­–æ ‘æ—¶ï¼Œæ¯ä¸ªåŒºåŸŸéƒ½æ˜¯ä¸€ä¸ªç»ˆç«¯èŠ‚ç‚¹ï¼Œä¹Ÿç§°ä¸ºå¶å­èŠ‚ç‚¹
- en: These are the same thing! Letâ€™s list the steps and then walk through a training
    a tree to demonstrate this.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯åŒä¸€ä»¶äº‹ï¼è®©æˆ‘ä»¬åˆ—å‡ºæ­¥éª¤ï¼Œç„¶åé€šè¿‡è®­ç»ƒä¸€ä¸ªæ ‘æ¥æ¼”ç¤ºè¿™ä¸€ç‚¹ã€‚
- en: '**Assign All Data to a Single Region** - this region covers the entire predictor
    feature space'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å°†æ‰€æœ‰æ•°æ®åˆ†é…åˆ°å•ä¸ªåŒºåŸŸ** - è¿™ä¸ªåŒºåŸŸè¦†ç›–äº†æ•´ä¸ªé¢„æµ‹ç‰¹å¾ç©ºé—´'
- en: '**Scan All Possible Splits** - over all regions and over all features'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ‰«ææ‰€æœ‰å¯èƒ½çš„åˆ†å‰²** - åœ¨æ‰€æœ‰åŒºåŸŸå’Œæ‰€æœ‰ç‰¹å¾ä¸Š'
- en: '**Select the Best Split** - this is greedy optimization, i.e., the best split
    minimizes the residual sum of squares of errors over all the training data \(y_i\)
    over all of the regions \(j = 1,\ldots,J\).'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©æœ€ä½³åˆ†å‰²** - è¿™æ˜¯è´ªå©ªä¼˜åŒ–ï¼Œå³æœ€ä½³åˆ†å‰²æœ€å°åŒ–äº†æ‰€æœ‰è®­ç»ƒæ•°æ® \(y_i\) åœ¨æ‰€æœ‰åŒºåŸŸ \(j = 1,\ldots,J\) ä¸Šçš„æ®‹å·®å¹³æ–¹å’Œã€‚'
- en: '**Iterate Until Very Overfit** - return to step 1 for the next split until
    the tree is very overfit.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¿­ä»£ç›´åˆ°è¿‡åº¦æ‹Ÿåˆ** - è¿”å›æ­¥éª¤1è¿›è¡Œä¸‹ä¸€ä¸ªåˆ†å‰²ï¼Œç›´åˆ°æ ‘è¿‡åº¦æ‹Ÿåˆã€‚'
- en: For brevity we stop here, and make these observations,
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€æ´ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œåœæ­¢ï¼Œå¹¶åšå‡ºä»¥ä¸‹è§‚å¯Ÿï¼Œ
- en: hierarchical, binary segmentation is the same as sequentially building a decision
    tree, each split adds a new decision node and increases the number of leaf nodes
    by one.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å±‚æ¬¡åŒ–ã€äºŒåˆ†åˆ†å‰²ä¸é¡ºåºæ„å»ºå†³ç­–æ ‘ç›¸åŒï¼Œæ¯æ¬¡åˆ†å‰²éƒ½ä¼šæ·»åŠ ä¸€ä¸ªæ–°çš„å†³ç­–èŠ‚ç‚¹ï¼Œå¹¶å°†å¶èŠ‚ç‚¹æ•°é‡å¢åŠ ä¸€ä¸ªã€‚
- en: the simple decision trees are in the complicated decision tree, i.e., if we
    build an \(8\) leaf node model, we have the \(8, 7, \ldots, 2\) leaf node model
    by sequentially removing the decision nodes, in the order of last one is the first
    one to remove.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®€å•çš„å†³ç­–æ ‘åœ¨å¤æ‚çš„å†³ç­–æ ‘ä¸­ï¼Œå³å¦‚æœæˆ‘ä»¬æ„å»ºä¸€ä¸ª\(8\)ä¸ªå¶èŠ‚ç‚¹çš„æ¨¡å‹ï¼Œæˆ‘ä»¬é€šè¿‡é¡ºåºç§»é™¤å†³ç­–èŠ‚ç‚¹ï¼Œä»¥æœ€åä¸€ä¸ªç§»é™¤çš„é¡ºåºï¼Œå¾—åˆ°\(8, 7, \ldots,
    2\)ä¸ªå¶èŠ‚ç‚¹çš„æ¨¡å‹ã€‚
- en: the ultimate overfit model is number of leaf nodes equal to the number of training
    data. In this case, the training error is 0.0 as have one region for each training
    data a we estimate with the training data response feature values for all the
    at the training data cases.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€ç»ˆè¿‡åº¦æ‹Ÿåˆçš„æ¨¡å‹æ˜¯å¶èŠ‚ç‚¹æ•°ç­‰äºè®­ç»ƒæ•°æ®æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒè¯¯å·®ä¸º0.0ï¼Œå› ä¸ºæ¯ä¸ªè®­ç»ƒæ•°æ®æœ‰ä¸€ä¸ªåŒºåŸŸï¼Œæˆ‘ä»¬ä½¿ç”¨è®­ç»ƒæ•°æ®çš„å“åº”ç‰¹å¾å€¼æ¥ä¼°è®¡æ‰€æœ‰è¿™äº›è®­ç»ƒæ•°æ®æ¡ˆä¾‹ã€‚
- en: Tuning the Tree Model
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è°ƒæ•´æ ‘æ¨¡å‹
- en: To tune the decision tree we take the very overfit trained tree model,
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è°ƒæ•´å†³ç­–æ ‘ï¼Œæˆ‘ä»¬é‡‡ç”¨éå¸¸è¿‡åº¦æ‹Ÿåˆçš„æ ‘æ¨¡å‹ï¼Œ
- en: sequentially cut the last decision node
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¡ºåºåœ°åˆ‡å‰²æœ€åä¸€ä¸ªå†³ç­–èŠ‚ç‚¹
- en: i.e., prune the last branch of the decision tree
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å³ï¼Œå‰ªæå†³ç­–æ ‘çš„æœ€åä¸€ä¸ªåˆ†æ”¯ã€‚
- en: Since the simpler trees are inside the complicated tree!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºç®€å•çš„æ ‘åœ¨å¤æ‚çš„æ ‘å†…éƒ¨ï¼
- en: We can calculate test error as we prune and select tree with minimum test error
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨å‰ªæå’Œé€‰æ‹©å…·æœ‰æœ€å°æµ‹è¯•è¯¯å·®çš„æ ‘æ—¶è®¡ç®—æµ‹è¯•è¯¯å·®
- en: We overfit the decision tree model, with a large number of leaf nodes and then
    we reduce the number of leaf nodes while tracking the test error.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿‡åº¦æ‹Ÿåˆå†³ç­–æ ‘æ¨¡å‹ï¼Œå…·æœ‰å¤§é‡çš„å¶èŠ‚ç‚¹ï¼Œç„¶åæˆ‘ä»¬å‡å°‘å¶èŠ‚ç‚¹æ•°ï¼ŒåŒæ—¶è·Ÿè¸ªæµ‹è¯•è¯¯å·®ã€‚
- en: we select the number of leaf nodes that minimize the testing error.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©ä½¿æµ‹è¯•è¯¯å·®æœ€å°çš„å¶èŠ‚ç‚¹æ•°ã€‚
- en: since we are sequentially removing the last branch to simplify the tree, we
    call model tuning **pruning** for decision trees
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ˜¯é¡ºåºåœ°ç§»é™¤æœ€åä¸€ä¸ªåˆ†æ”¯ä»¥ç®€åŒ–æ ‘ï¼Œæ‰€ä»¥æˆ‘ä»¬ç§°å†³ç­–æ ‘çš„æ¨¡å‹è°ƒæ•´ä¸º**å‰ªæ**ã€‚
- en: Letâ€™s discuss decision tree hyperparameters. I prefer number of leaf nodes as
    my decision tree hyperparameter because it provides,
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®¨è®ºå†³ç­–æ ‘è¶…å‚æ•°ã€‚æˆ‘æ›´å–œæ¬¢å°†å¶èŠ‚ç‚¹æ•°ä½œä¸ºæˆ‘çš„å†³ç­–æ ‘è¶…å‚æ•°ï¼Œå› ä¸ºå®ƒæä¾›äº†ï¼Œ
- en: '**continuous, uniform increase in complexity** - equal steps in increased complexity
    without jumps'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿ç»­ã€å‡åŒ€çš„å¤æ‚åº¦å¢åŠ ** - å¤æ‚åº¦å¢åŠ çš„æ­¥é•¿ç›¸ç­‰ï¼Œæ²¡æœ‰è·³è·ƒã€‚'
- en: '**intuitive control on complexity** - we can understand and relate the \(2,
    3, \ldots, 100\) leaf node decision trees'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç›´è§‚çš„å¤æ‚åº¦æ§åˆ¶** - æˆ‘ä»¬å¯ä»¥ç†è§£å’Œå…³è”\(2, 3, \ldots, 100\)ä¸ªå¶èŠ‚ç‚¹çš„å†³ç­–æ ‘ã€‚'
- en: '**flexible complexity** - the tree is free to grow in any manner to reduce
    training error, including highly asymmetric decision trees'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**çµæ´»çš„å¤æ‚åº¦** - æ ‘å¯ä»¥è‡ªç”±åœ°ä»¥ä»»ä½•æ–¹å¼ç”Ÿé•¿ä»¥å‡å°‘è®­ç»ƒè¯¯å·®ï¼ŒåŒ…æ‹¬é«˜åº¦ä¸å¯¹ç§°çš„å†³ç­–æ ‘'
- en: There are other common decision tree hyperparameters including,
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä»–å¸¸è§çš„å†³ç­–æ ‘è¶…å‚æ•°åŒ…æ‹¬ï¼Œ
- en: '**Minimum reduction in RSS** â€“ related to the idea that incremental increase
    in complexity must be offset by sufficient reduction in training error. This could
    stop the model early, for example, a split with low reduction in training error
    could lead to a subsequent split with a much larger reduction in training error'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœ€å°å‡å°‘çš„RSS** â€“ ä¸å¢é‡å¢åŠ å¤æ‚åº¦å¿…é¡»é€šè¿‡è¶³å¤Ÿçš„è®­ç»ƒè¯¯å·®å‡å°‘æ¥æŠµæ¶ˆçš„æƒ³æ³•ç›¸å…³ã€‚è¿™å¯èƒ½å¯¼è‡´æ¨¡å‹æå‰åœæ­¢ï¼Œä¾‹å¦‚ï¼Œè®­ç»ƒè¯¯å·®å‡å°‘è¾ƒå°çš„åˆ†å‰²å¯èƒ½å¯¼è‡´åç»­åˆ†å‰²æœ‰æ›´å¤§çš„è®­ç»ƒè¯¯å·®å‡å°‘'
- en: '**Minimum number of training data in each region** â€“ related to the concept
    of accuracy of the by-region estimates, i.e., we need at least \(n\) data for
    a reliable mean and most common category'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¯ä¸ªåŒºåŸŸçš„æœ€å°è®­ç»ƒæ•°æ®æ•°** â€“ ä¸æŒ‰åŒºåŸŸä¼°è®¡çš„å‡†ç¡®æ€§æ¦‚å¿µç›¸å…³ï¼Œå³æˆ‘ä»¬éœ€è¦è‡³å°‘\(n\)ä¸ªæ•°æ®æ¥è·å¾—å¯é çš„å‡å€¼å’Œæœ€å¸¸è§çš„ç±»åˆ«ã€‚'
- en: '**Maximum number of levels** â€“ forces symmetric trees, similar number of splits
    to get to each leaf node. There is a large change in model complexity with change
    in the hyperparameter.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœ€å¤§å±‚æ•°** â€“ å¼ºåˆ¶å¯¹ç§°æ ‘ï¼Œåˆ°è¾¾æ¯ä¸ªå¶èŠ‚ç‚¹çš„åˆ†å‰²æ•°ç›¸ä¼¼ã€‚æ¨¡å‹å¤æ‚åº¦éšç€è¶…å‚æ•°çš„å˜åŒ–è€Œå¤§å¹…å˜åŒ–ã€‚'
- en: Ensemble Methods
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆæ–¹æ³•
- en: What is the Testing Accuracy of Our Predictive Machine Learning Models?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„æµ‹è¯•å‡†ç¡®ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: Recall the equation for expected test error has three components.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å›å¿†ä¸€ä¸‹é¢„æœŸæµ‹è¯•è¯¯å·®çš„æ–¹ç¨‹æœ‰ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ã€‚
- en: \[ \mathbb{E}\left[(y_0 - \hat{f}(x_1^0, \ldots, x_m^0))^2\right] = \left(\mathbb{E}[\hat{f}(x_1^0,
    \ldots, x_m^0)] - f(x_1^0, \ldots, x_m^0)\right)^2 + \mathbb{E}\left[\left(\hat{f}(x_1^0,
    \ldots, x_m^0) - \mathbb{E}[\hat{f}(x_1^0, \ldots, x_m^0)]\right)^2\right] + \sigma_\varepsilon^2
    \]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbb{E}\left[(y_0 - \hat{f}(x_1^0, \ldots, x_m^0))^2\right] = \left(\mathbb{E}[\hat{f}(x_1^0,
    \ldots, x_m^0)] - f(x_1^0, \ldots, x_m^0)\right)^2 + \mathbb{E}\left[\left(\hat{f}(x_1^0,
    \ldots, x_m^0) - \mathbb{E}[\hat{f}(x_1^0, \ldots, x_m^0)]\right)^2\right] + \sigma_\varepsilon^2
    \]
- en: 'There can be labeled as:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥æ ‡è®°ä¸ºï¼š
- en: \[ \text{Expected Test Error} = \text{Model Bias}^2 + \text{Model Variance}
    + \text{Irreducible Error} \]
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Expected Test Error} = \text{Model Bias}^2 + \text{Model Variance}
    + \text{Irreducible Error} \]
- en: where,
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ
- en: '**Model Variance** - is the error in the model predictions due to sensitivity
    to the data, i.e., what if we used different training data?'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ–¹å·®** - æ˜¯ç”±äºå¯¹æ•°æ®çš„æ•æ„Ÿæ€§å¯¼è‡´çš„æ¨¡å‹é¢„æµ‹è¯¯å·®ï¼Œå³å¦‚æœæˆ‘ä»¬ä½¿ç”¨äº†ä¸åŒçš„è®­ç»ƒæ•°æ®ä¼šæ€æ ·ï¼Ÿ'
- en: '**Model Bias** - is error in the model predictions due to using an approximate
    model / model is too simple'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åå·®** - æ˜¯ç”±äºä½¿ç”¨è¿‘ä¼¼æ¨¡å‹/æ¨¡å‹è¿‡äºç®€å•å¯¼è‡´çš„æ¨¡å‹é¢„æµ‹è¯¯å·®'
- en: '**Irreducible Error** - is error in the model predictions due to missing features
    and limited samples canâ€™t be fixed with modeling / entire feature space is not
    sampled'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸å¯å‡å°‘è¯¯å·®** - æ˜¯ç”±äºç¼ºå°‘ç‰¹å¾å’Œæ ·æœ¬æ•°é‡æœ‰é™å¯¼è‡´çš„æ¨¡å‹é¢„æµ‹è¯¯å·®ï¼Œæ— æ³•é€šè¿‡å»ºæ¨¡/æ•´ä¸ªç‰¹å¾ç©ºé—´æœªé‡‡æ ·æ¥ä¿®å¤'
- en: Now we can visualize the model variance and bias tradeoff as,
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹æ–¹å·®å’Œåå·®æƒè¡¡å¯è§†åŒ–ï¼Œ
- en: '![](../Images/10e6db08085f4ca1ff6ceb66f673d9d8.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10e6db08085f4ca1ff6ceb66f673d9d8.png)'
- en: Model variance and bias trade-off, for simple to complicated predictive machine
    learning models.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®å’Œåå·®æƒè¡¡ï¼Œé€‚ç”¨äºä»ç®€å•åˆ°å¤æ‚çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
- en: Model variance limits the complexity and text accuracy of our models.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®é™åˆ¶äº†æˆ‘ä»¬çš„æ¨¡å‹å¤æ‚æ€§å’Œæ–‡æœ¬å‡†ç¡®æ€§ã€‚
- en: '**How Can We Reduce Model Variance?** - so that we can use more complicated
    and more accurate models.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¦‚ä½•å‡å°‘æ¨¡å‹æ–¹å·®ï¼Ÿ** - ä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤æ‚å’Œæ›´å‡†ç¡®çš„æ¨¡å‹ã€‚'
- en: By standard error in the average, we observe the reduction in variance by averaging!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¹³å‡æ ‡å‡†è¯¯å·®ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°é€šè¿‡å¹³å‡æ¥å‡å°‘æ–¹å·®ï¼
- en: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
- en: where \(\sigma^2_s\) is the sample variance, \(n\) is the number of samples,
    and \(\sigma_{\bar{x}}^2\) is the variance of the average under the assumption
    of independent, identically distributed sampling.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma^2_s\) æ˜¯æ ·æœ¬æ–¹å·®ï¼Œ\(n\) æ˜¯æ ·æœ¬æ•°é‡ï¼Œ\(\sigma_{\bar{x}}^2\) æ˜¯åœ¨ç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ ·å‡è®¾ä¸‹çš„å¹³å‡æ–¹å·®ã€‚
- en: '![](../Images/11ec8dafb91278a4a07a22c274b18c52.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11ec8dafb91278a4a07a22c274b18c52.png)'
- en: Model variance and bias trade-off, for simple to complicated predictive machine
    learning models with model variance reduced by averaging.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®å’Œåå·®æƒè¡¡ï¼Œå¯¹äºç®€å•åˆ°å¤æ‚çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡å¹³å‡å‡å°‘æ¨¡å‹æ–¹å·®ã€‚
- en: We can reduce model variance by calculating many estimates and averaging them
    together. We will need to make \(B\) estimates,
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—å¤šä¸ªä¼°è®¡å€¼å¹¶å°†å®ƒä»¬å¹³å‡åœ¨ä¸€èµ·æ¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚æˆ‘ä»¬éœ€è¦è¿›è¡Œ \(B\) ä¸ªä¼°è®¡ï¼Œ
- en: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]
- en: where,
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ
- en: \(\hat{y}^{(b)}\) is the prediction made by the \(b^{th}\) model in the ensemble,
    \(\hat{f}^{(b)}\) is the \(b^{th}\) estimator, \(X_1, \ldots, X_m\) is the predictor
    features, and \(B\) is the total number of estimators (the multiple models).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{y}^{(b)}\) æ˜¯é›†æˆä¸­ç¬¬ \(b\) ä¸ªæ¨¡å‹çš„é¢„æµ‹ï¼Œ\(\hat{f}^{(b)}\) æ˜¯ç¬¬ \(b\) ä¸ªä¼°è®¡é‡ï¼Œ\(X_1,
    \ldots, X_m\) æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œ\(B\) æ˜¯ä¼°è®¡é‡çš„æ€»æ•°ï¼ˆå¤šä¸ªæ¨¡å‹ï¼‰ã€‚
- en: Then our ultimate estimate will be the average (regression) or plurality (classification)
    of our estimates,
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬çš„æœ€ç»ˆä¼°è®¡å°†æ˜¯æˆ‘ä»¬çš„ä¼°è®¡çš„å¹³å‡å€¼ï¼ˆå›å½’ï¼‰æˆ–å¤šæ•°ï¼ˆåˆ†ç±»ï¼‰ï¼Œ
- en: regression ensemble estimate,
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å½’é›†æˆä¼°è®¡ï¼Œ
- en: \[ \hat{y} = \frac{1}{B} \sum_{b=1}^{B} \hat{y}^{(b)} \]
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \frac{1}{B} \sum_{b=1}^{B} \hat{y}^{(b)} \]
- en: classification ensemble estimate,
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»é›†æˆä¼°è®¡ï¼Œ
- en: \[ \hat{y} = \arg\max_y \sum_{b=1}^{B} \mathbb{I}(\hat{y}^{(b)} = y) \]
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \arg\max_y \sum_{b=1}^{B} \mathbb{I}(\hat{y}^{(b)} = y) \]
- en: This requires multiple prediction models, \(f^{b}, b = 1,\ldots, B\) to make
    \(B\) predictions,
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éœ€è¦å¤šä¸ªé¢„æµ‹æ¨¡å‹ï¼Œ\(f^{b}, b = 1,\ldots, B\) æ¥è¿›è¡Œ \(B\) ä¸ªé¢„æµ‹ï¼Œ
- en: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]![](../Images/885306737841b4ce2406407ca170fe7f.png)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]![](../Images/885306737841b4ce2406407ca170fe7f.png)
- en: Multiple models to make multiple predictions to reduce model variance by averaging
    over the ensemble.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¤šä¸ªæ¨¡å‹è¿›è¡Œå¤šä¸ªé¢„æµ‹ï¼Œé€šè¿‡åœ¨é›†æˆä¸­å¹³å‡æ¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚
- en: But we only have access to a single dataset, \(Y,X_1,\ldots,X_m\); therefore,
    every model will be the same,
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬åªèƒ½è®¿é—®å•ä¸ªæ•°æ®é›†ï¼Œ\(Y,X_1,\ldots,X_m\)ï¼›å› æ­¤ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½å°†ç›¸åŒï¼Œ
- en: '![](../Images/f4dd12f28990215e1c5906e7c36793a1.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4dd12f28990215e1c5906e7c36793a1.png)'
- en: Multiple models to make multiple predictions to reduce model variance by averaging
    over the ensemble, with the same data result in the same model and the same predictions.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¤šä¸ªæ¨¡å‹è¿›è¡Œå¤šæ¬¡é¢„æµ‹ï¼Œé€šè¿‡åœ¨é›†æˆä¸­å¹³å‡æ¥å‡å°‘æ¨¡å‹æ–¹å·®ï¼Œä½¿ç”¨ç›¸åŒçš„æ•°æ®å¾—åˆ°ç›¸åŒçš„æ¨¡å‹å’Œç›¸åŒçš„é¢„æµ‹ã€‚
- en: Our models are generally deterministic, train with the same data and hyperparameters
    and we get the same estimate.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡å¼é€šå¸¸æ˜¯ç¡®å®šæ€§çš„ï¼Œä½¿ç”¨ç›¸åŒçš„æ•°æ®å’Œè¶…å‚æ•°è¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬å¾—åˆ°ç›¸åŒçš„ä¼°è®¡ã€‚
- en: Bootstrap
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªä¸¾
- en: One source of uncertainty is the paucity of data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªæ¥æºæ˜¯æ•°æ®é‡ä¸è¶³ã€‚
- en: Do these 200 or so wells provide a precise (and accurate estimate) of the mean?
    standard deviation? skew? P13?
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›200å¤šä¸ªäº•æ˜¯å¦æä¾›äº†ç²¾ç¡®ï¼ˆå’Œå‡†ç¡®çš„ä¼°è®¡ï¼‰çš„å‡å€¼ï¼Ÿæ ‡å‡†å·®ï¼Ÿååº¦ï¼ŸP13ï¼Ÿ
- en: What is the impact of uncertainty in the mean porosity, for example, \(20\%
    \pm 2\%\)?
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå­”éš™ç‡å¹³å‡å€¼çš„ä¸ç¡®å®šæ€§ï¼ˆä¾‹å¦‚ï¼Œ\(20\% \pm 2\%\)ï¼‰æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ
- en: '![](../Images/cc8a09c3c5b404de658a3f4d6a4ace64.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/cc8a09c3c5b404de658a3f4d6a4ace64.png)'
- en: Samples and population, from Bootstrap chapter of Applied Geostatistics in Python
    e-book.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æ ·æœ¬å’Œæ€»ä½“ï¼Œæ¥è‡ªPythonåœ°çƒç»Ÿè®¡å­¦ç”µå­ä¹¦ä¸­çš„Bootstrapç« èŠ‚ã€‚
- en: What if we had \(L\) different datasets? \(L\) parallel universes where we collected
    \(n\) samples from the inaccessible truth (the population).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æ‹¥æœ‰ \(L\) ä¸ªä¸åŒçš„æ•°æ®é›†ï¼Ÿ\(L\) ä¸ªå¹³è¡Œå®‡å®™ï¼Œæˆ‘ä»¬ä»æ— æ³•è§¦åŠçš„çœŸç›¸ï¼ˆæ€»ä½“ï¼‰ä¸­æ”¶é›† \(n\) ä¸ªæ ·æœ¬ã€‚
- en: '![](../Images/03a47e7d2a75afebba6ca7928b259afe.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/03a47e7d2a75afebba6ca7928b259afe.png)'
- en: Multiple dataset realizations from the truth population, from Bootstrap chapter
    of Applied Geostatistics in Python e-book.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ä»Bootstrapç« èŠ‚çš„Pythonåœ°çƒç»Ÿè®¡å­¦ç”µå­ä¹¦ä¸­çš„çœŸå®æ€»ä½“ä¸­è·å–çš„å¤šä¸ªæ•°æ®é›†å®ç°ã€‚
- en: but we only exist in 1 universe \(\rightarrow\) this is not possible.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬åªå­˜åœ¨äºä¸€ä¸ªå®‡å®™ \(\rightarrow\) è¿™æ˜¯ä¸å¯èƒ½çš„ã€‚
- en: Instead we sample \(n\) times from the dataset with replacement,
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ˜¯ä»æ•°æ®é›†ä¸­æœ‰æ”¾å›åœ°æŠ½å– \(n\) æ¬¡ï¼Œè€Œæ˜¯
- en: bootstrap realizations of the data
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®çš„è‡ªä¸¾å®ç°
- en: that vary by due to some samples being left out and others sampled multiple
    times.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæŸäº›æ ·æœ¬è¢«é—æ¼è€Œå…¶ä»–æ ·æœ¬è¢«å¤šæ¬¡æŠ½å–è€Œæœ‰æ‰€ä¸åŒã€‚
- en: '![](../Images/07925f4d15205ea985dfc081c24b0589.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/07925f4d15205ea985dfc081c24b0589.png)'
- en: Multiple dataset bootstrap datasets.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šä¸ªæ•°æ®é›†çš„è‡ªä¸¾æ•°æ®é›†ã€‚
- en: Now, hereâ€™s a definition of bootstrap,
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªè‡ªä¸¾çš„å®šä¹‰ï¼Œ
- en: method to assess the uncertainty in a sample statistic by repeated random sampling
    with replacement simulating the sampling process to acquire dataset realizations
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é‡å¤éšæœºæŠ½æ ·ï¼ˆæœ‰æ”¾å›æ¨¡æ‹ŸæŠ½æ ·è¿‡ç¨‹ä»¥è·å–æ•°æ®é›†å®ç°ï¼‰æ¥è¯„ä¼°æ ·æœ¬ç»Ÿè®¡é‡ä¸ç¡®å®šæ€§çš„æ–¹æ³•
- en: Under the assumptions,
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™äº›å‡è®¾ä¸‹ï¼Œ
- en: '**sufficient sample** - enough data to infer the population parameters. Bootstrap
    cannot make up for too few data!'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¶³å¤Ÿçš„æ ·æœ¬** - æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥æ¨æ–­æ€»ä½“å‚æ•°ã€‚è‡ªä¸¾ä¸èƒ½å¼¥è¡¥æ•°æ®è¿‡å°‘çš„é—®é¢˜ï¼'
- en: '**representative sampling** - bias in the sample will be passed to the bootstrap
    uncertainty model, for example, if the mean is biased in the sample, then the
    bootstrap uncertainty model will be centered on the biased mean from the sample.
    We must first debias our data.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»£è¡¨æ€§æŠ½æ ·** - æ ·æœ¬ä¸­çš„åå·®å°†ä¼ é€’åˆ°è‡ªä¸¾ä¸ç¡®å®šæ€§æ¨¡å‹ä¸­ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæ ·æœ¬ä¸­çš„å‡å€¼æœ‰åå·®ï¼Œé‚£ä¹ˆè‡ªä¸¾ä¸ç¡®å®šæ€§æ¨¡å‹å°†åŸºäºæ ·æœ¬ä¸­çš„åå·®å‡å€¼è¿›è¡Œä¸­å¿ƒåŒ–ã€‚æˆ‘ä»¬å¿…é¡»é¦–å…ˆæ¶ˆé™¤æ•°æ®çš„åå·®ã€‚'
- en: There are also various limitations for bootstrap, including,
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªä¸¾ä¹Ÿæœ‰å„ç§å±€é™æ€§ï¼ŒåŒ…æ‹¬ï¼Œ
- en: '**stationarity** - the statistics from the sample are assumed to be constant
    over the model space'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¹³ç¨³æ€§** - å‡è®¾æ ·æœ¬çš„ç»Ÿè®¡é‡åœ¨æ¨¡å‹ç©ºé—´ä¸­æ˜¯æ’å®šçš„'
- en: '**one uncertainty source only** - only accounts for uncertainty due to too
    few samples, for example, no uncertainty due to changes away from data'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»…ä¸€ä¸ªä¸ç¡®å®šæ€§æ¥æº** - åªè€ƒè™‘æ ·æœ¬è¿‡å°‘å¯¼è‡´çš„ä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚ï¼Œä¸è€ƒè™‘æ•°æ®å˜åŒ–å¯¼è‡´çš„ä¸ç¡®å®šæ€§'
- en: '**does not account for area of interest** - larger model region or smaller
    model region, bootstrap uncertainty does not change.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è€ƒè™‘æ„Ÿå…´è¶£çš„åŒºåŸŸ** - æ¨¡å‹åŒºåŸŸè¾ƒå¤§æˆ–è¾ƒå°ï¼Œè‡ªä¸¾ä¸ç¡®å®šæ€§ä¸ä¼šæ”¹å˜ã€‚'
- en: '**independence between the samples** - does not account for correlation, relationships
    between the samples'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ·æœ¬ä¹‹é—´çš„ç‹¬ç«‹æ€§** - ä¸è€ƒè™‘æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå…³ç³»'
- en: '**no local conditioning** - does not account for other local information sources'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ— å±€éƒ¨æ¡ä»¶** - ä¸è€ƒè™‘å…¶ä»–å±€éƒ¨ä¿¡æ¯æ¥æº'
- en: We could summarize all of this limitations as, bootstrap does not account for
    the spatial (or temporal) context of the data.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰è¿™äº›å±€é™æ€§æ€»ç»“ä¸ºï¼Œè‡ªä¸¾ä¸è€ƒè™‘æ•°æ®çš„ç©ºé—´ï¼ˆæˆ–æ—¶é—´ï¼‰èƒŒæ™¯ã€‚
- en: there is a form of bootstrap, known as spatial bootstrap that does account for
    spatial context, [spatial bootstrap and bagging for ensemble machine learning](https://www.sciencedirect.com/science/article/pii/S0098300424000414).
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­˜åœ¨ä¸€ç§è‡ªä¸¾å½¢å¼ï¼Œç§°ä¸ºç©ºé—´è‡ªä¸¾ï¼Œå®ƒç¡®å®è€ƒè™‘äº†ç©ºé—´èƒŒæ™¯ï¼Œ[ç©ºé—´è‡ªä¸¾å’Œé›†æˆæœºå™¨å­¦ä¹ çš„bagging](https://www.sciencedirect.com/science/article/pii/S0098300424000414)ã€‚
- en: Letâ€™s visualize bootstrap for the case of calculating uncertainty in sample
    mean estimated ultimate recovery (EUR) given \(n=10\) observations from 10 wells.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯è§†åŒ–ä½¿ç”¨ \(n=10\) ä¸ªæ¥è‡ª 10 å£äº•çš„è§‚æµ‹å€¼è®¡ç®—æ ·æœ¬å‡å€¼ä¼°è®¡çš„æœ€ç»ˆå¯é‡‡å‚¨é‡ï¼ˆEURï¼‰çš„ä¸ç¡®å®šæ€§çš„è‡ªåŠ©æ³•ã€‚
- en: '![](../Images/1cfe358ff534628282d37d9e47ad383a.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cfe358ff534628282d37d9e47ad383a.png)'
- en: \(n = 10\) samples with replacement to calculate a single realization of the
    sample mean.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: \(n = 10\) ä¸ªæœ‰æ”¾å›æ ·æœ¬ä»¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ä¸€ä¸ªå®ç°ã€‚
- en: Now we repeat and calculate a \(2^{nd}\) realization of the sample mean,
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬é‡å¤å¹¶è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬äºŒæ¬¡å®ç°ï¼Œ
- en: '![](../Images/2a1d9d26290cdc6495c88246af159f42.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a1d9d26290cdc6495c88246af159f42.png)'
- en: Second realization of \(n = 10\) samples with replacement to calculate the second
    realization of the sample mean.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ¬¡é‡å¤ \(n = 10\) ä¸ªæœ‰æ”¾å›æ ·æœ¬ä»¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬äºŒæ¬¡å®ç°ã€‚
- en: and a third realization of the data to calculate the \(3^{rd}\) realization
    of the sample mean,
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä½¿ç”¨ç¬¬ä¸‰ä¸ªæ•°æ®å®ç°æ¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬ä¸‰æ¬¡å®ç°ï¼Œ
- en: '![](../Images/508b11f7b9417d09182403573f7e40d7.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/508b11f7b9417d09182403573f7e40d7.png)'
- en: Third realization of \(n = 10\) samples with replacement to calculate the third
    realization of the sample mean.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰æ¬¡é‡å¤ \(n = 10\) ä¸ªæœ‰æ”¾å›æ ·æœ¬ä»¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬ä¸‰æ¬¡å®ç°ã€‚
- en: and if we repeat \(L\) times we sample the complete distribution for the uncertainty
    in the sample mean.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬é‡å¤ \(L\) æ¬¡ï¼Œæˆ‘ä»¬å°†é‡‡æ ·å®Œæ•´åˆ†å¸ƒä»¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ä¸ç¡®å®šæ€§ã€‚
- en: '![](../Images/5f2dabcbf8e395ea433527e012d41490.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f2dabcbf8e395ea433527e012d41490.png)'
- en: $L$ realizations of the data for $L$ realizations to completely sample the uncertainty
    in the mean.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: $L$ ä¸ªæ•°æ®å®ç°ï¼Œä»¥å®Œå…¨é‡‡æ ·å‡å€¼çš„ä¸ç¡®å®šæ€§ã€‚
- en: Letâ€™s summarize bootstrap,
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹è‡ªåŠ©æ³•ï¼Œ
- en: developed by [Efron, 1982](https://epubs.siam.org/doi/pdf/10.1137/1.9781611970319.fm)
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”± [Efron, 1982](https://epubs.siam.org/doi/pdf/10.1137/1.9781611970319.fm) å¼€å‘
- en: statistical resampling procedure to calculate uncertainty in a calculated statistic
    from the data itself.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡é‡é‡‡æ ·è¿‡ç¨‹ï¼Œç”¨äºä»æ•°æ®æœ¬èº«è®¡ç®—è®¡ç®—ç»Ÿè®¡çš„ä¸ç¡®å®šæ€§ã€‚
- en: seems impossible, but go ahead and compare it to known cases like standard error
    and you will see that it works,
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼¼ä¹æ˜¯ä¸å¯èƒ½çš„ï¼Œä½†ç»§ç»­ä¸æ ‡å‡†è¯¯å·®ç­‰å·²çŸ¥æƒ…å†µè¿›è¡Œæ¯”è¾ƒï¼Œä½ ä¼šå‘ç°å®ƒæ˜¯æœ‰æ•ˆçš„ï¼Œ
- en: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
- en: where \(\sigma^2_s\) is the sample variance, \(n\) is the number of samples,
    and \(\sigma_{\bar{x}}^2\) is the variance of the average under the assumption
    of independent, identically distributed sampling.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma^2_s\) æ˜¯æ ·æœ¬æ–¹å·®ï¼Œ\(n\) æ˜¯æ ·æœ¬æ•°é‡ï¼Œ\(\sigma_{\bar{x}}^2\) æ˜¯åœ¨ç‹¬ç«‹ã€åŒåˆ†å¸ƒé‡‡æ ·å‡è®¾ä¸‹çš„å¹³å‡æ–¹å·®ã€‚
- en: may be applied to calculate the uncertainty in any statistic, for example, \(13^{th}\)
    percentile, skew, etc.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ç”¨äºè®¡ç®—ä»»ä½•ç»Ÿè®¡çš„ä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚ï¼Œç¬¬ \(13\) ç™¾åˆ†ä½æ•°ã€ååº¦ç­‰ã€‚
- en: advanced forms account for spatial information and strategy (game theory).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜çº§å½¢å¼è€ƒè™‘ç©ºé—´ä¿¡æ¯å’Œç­–ç•¥ï¼ˆåšå¼ˆè®ºï¼‰ã€‚
- en: '![](../Images/a360524ac8f082a989d9ff04d88b3906.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a360524ac8f082a989d9ff04d88b3906.png)'
- en: The general flow chart for bootstrap.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•çš„ä¸€èˆ¬æµç¨‹å›¾ã€‚
- en: Bagging Models
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•æ¨¡å‹
- en: Bagging models in machine learning apply bootstrap to,
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­çš„è‡ªåŠ©æ³•æ¨¡å‹åº”ç”¨è‡ªåŠ©æ³•ï¼Œ
- en: calculate multiple realizations of the data
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ•°æ®çš„å¤šä¸ªå®ç°
- en: train multiple realizations of the model
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ¨¡å‹çš„å¤šä¸ªå®ç°
- en: calculate multiple realizations of the estimate
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—ä¼°è®¡çš„å¤šä¸ªå®ç°
- en: average the estimates to reduce model variance
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹³å‡ä¼°è®¡ä»¥å‡å°‘æ¨¡å‹æ–¹å·®
- en: Hereâ€™s the flow chart for bagging models,
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è‡ªåŠ©æ³•æ¨¡å‹çš„æµç¨‹å›¾ï¼Œ
- en: '![](../Images/aa378f660d65104e433bf1eb53c1cd7f.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa378f660d65104e433bf1eb53c1cd7f.png)'
- en: The bagging machine learning model flow chart.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•æœºå™¨å­¦ä¹ æ¨¡å‹æµç¨‹å›¾ã€‚
- en: Apply statistical bootstrap to obtain multiple realizations of the data,
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨ç»Ÿè®¡è‡ªåŠ©æ³•ä»¥è·å¾—æ•°æ®çš„å¤šä¸ªå®ç°ï¼Œ
- en: \[ Y^b, X_1^b, \dots, X_m^b,\quad b = 1, \dots, B \]
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y^b, X_1^b, \dots, X_m^b,\quad b = 1, \dots, B \]
- en: Train a prediction model (estimator) for each data realization,
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¯ä¸ªæ•°æ®å®ç°è®­ç»ƒé¢„æµ‹æ¨¡å‹ï¼ˆä¼°è®¡å™¨ï¼‰ï¼Œ
- en: \[ \hat{f}^b(X_1^b, \dots, X_m^b) \]
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{f}^b(X_1^b, \dots, X_m^b) \]
- en: Calculate a prediction with each estimator,
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¯ä¸ªä¼°è®¡å™¨è¿›è¡Œé¢„æµ‹ï¼Œ
- en: \[ \hat{Y}^b = \hat{f}^b(X_1^b, \dots, X_m^b) \]
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y}^b = \hat{f}^b(X_1^b, \dots, X_m^b) \]
- en: Aggregate the ensemble of ğµ predictions over the estimators,
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ä¼°è®¡å™¨çš„ \(B\) ä¸ªé¢„æµ‹è¿›è¡Œèšåˆï¼Œ
- en: '**Regression** â€“ aggregate the ensemble predictions with the average,'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å›å½’** â€“ ä½¿ç”¨å¹³å‡å€¼èšåˆé›†æˆé¢„æµ‹ï¼Œ'
- en: \[ \hat{Y} = \frac{1}{B} \sum_{b=1}^{B} \hat{Y}^b \]
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} = \frac{1}{B} \sum_{b=1}^{B} \hat{Y}^b \]
- en: '**Classification** â€“ aggregate the ensemble predictions with majority-rule,
    plurality,'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»** â€“ ä½¿ç”¨å¤šæ•°è§„åˆ™ã€å¤šæ•°æŠ•ç¥¨èšåˆé›†æˆé¢„æµ‹ï¼Œ'
- en: \[ \hat{Y} = \arg\max(\hat{Y}^b) \]
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} = \arg\max(\hat{Y}^b) \]
- en: I built out an interactive Python dashboard for [bagging linear regression](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Bootstrap_Bagging.ipynb).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸º[æ‰“åŒ…çº¿æ€§å›å½’](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Bootstrap_Bagging.ipynb)æ„å»ºäº†ä¸€ä¸ªäº¤äº’å¼çš„Pythonä»ªè¡¨æ¿ã€‚
- en: '![](../Images/734e60e25fd461f174b74321a8caef2b.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/734e60e25fd461f174b74321a8caef2b.png)'
- en: Interactive machine learning bagging with linear regression, 16 data bootstrap,
    model and prediction realizations aggregated by averaging.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çº¿æ€§å›å½’è¿›è¡Œäº¤äº’å¼æœºå™¨å­¦ä¹ æ‰“åŒ…ï¼Œ16ä¸ªæ•°æ®è‡ªåŠ©æ³•ï¼Œé€šè¿‡å¹³å‡èšåˆæ¨¡å‹å’Œé¢„æµ‹å®ç°ã€‚
- en: Training and Tuning Bagging Models
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰“åŒ…æ¨¡å‹çš„è®­ç»ƒå’Œè°ƒæ•´
- en: What is the Bagging Regression Model?
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ‰“åŒ…å›å½’æ¨¡å‹ï¼Ÿ
- en: Multiple models each trained on different bootstrap data realizations, all with
    the same hyperparameter(s).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹éƒ½åœ¨ä¸åŒçš„è‡ªåŠ©æ•°æ®å®ç°ä¸Šè®­ç»ƒï¼Œæ‰€æœ‰æ¨¡å‹éƒ½å…·æœ‰ç›¸åŒçš„è¶…å‚æ•°ï¼ˆsï¼‰ã€‚
- en: '![](../Images/b80d0d8659d6a69c67cc48f81cd46888.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/b80d0d8659d6a69c67cc48f81cd46888.png)'
- en: The bagging model, we train individually, but we tune the ensemble.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰“åŒ…æ¨¡å‹ï¼Œæˆ‘ä»¬åˆ†åˆ«è®­ç»ƒï¼Œä½†æˆ‘ä»¬è°ƒæ•´çš„æ˜¯é›†æˆã€‚
- en: The bagging prediction, \(\hat{y}\), the aggregate of the individual estimators,
    is the output of this model.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰“åŒ…é¢„æµ‹ï¼Œ\(\hat{y}\)ï¼Œå•ä¸ªä¼°è®¡å™¨çš„æ€»å’Œï¼Œæ˜¯è¿™ä¸ªæ¨¡å‹çš„è¾“å‡ºã€‚
- en: '![](../Images/8734bb5c0493ecba4f618382a639010c.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/8734bb5c0493ecba4f618382a639010c.png)'
- en: Bagging regression predictions by averaging multiple prediction models.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¹³å‡å¤šä¸ªé¢„æµ‹æ¨¡å‹è¿›è¡Œæ‰“åŒ…å›å½’é¢„æµ‹ã€‚
- en: or for classification,
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…å¯¹äºåˆ†ç±»ï¼Œ
- en: '![](../Images/8734bb5c0493ecba4f618382a639010c.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/8734bb5c0493ecba4f618382a639010c.png)'
- en: Bagging classification predictions by plurality of multiple prediction models.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¤šæ•°æŠ•ç¥¨æ³•å¯¹å¤šä¸ªé¢„æµ‹æ¨¡å‹çš„åˆ†ç±»é¢„æµ‹è¿›è¡Œæ‰“åŒ…ã€‚
- en: Each model, known as an estimator in the ensemble of models, is trained with
    their respective bootstrapped data realization, during training each model minimizes
    train error of the individual estimator with the bootstrapped data realization,
    residual sum of squares for regression,
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹ï¼Œåœ¨æ¨¡å‹é›†æˆçš„ä¼°è®¡å™¨ä¸­è¢«ç§°ä¸ºä¼°è®¡å™¨ï¼Œåœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨å®ƒä»¬å„è‡ªçš„é´å±‚æ•°æ®å®ç°è¿›è¡Œè®­ç»ƒï¼Œåœ¨è®­ç»ƒæœŸé—´ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½æœ€å°åŒ–å•ä¸ªä¼°è®¡å™¨çš„é´å±‚æ•°æ®å®ç°çš„è®­ç»ƒè¯¯å·®ï¼Œå›å½’çš„æ®‹å·®å¹³æ–¹å’Œï¼Œ
- en: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
- en: and Gini impurity for classification,
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠåˆ†ç±»çš„åŸºå°¼ä¸çº¯åº¦ï¼Œ
- en: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
- en: each estimator is trained separately, but they all share the same hyperparameters.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªä¼°è®¡å™¨éƒ½æ˜¯å•ç‹¬è®­ç»ƒçš„ï¼Œä½†å®ƒä»¬å…±äº«ç›¸åŒçš„è¶…å‚æ•°ã€‚
- en: This provides the flexibility to build the best possible model to fit each bootstrap
    dataset.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æä¾›äº†æ„å»ºæœ€é€‚åˆæ¯ä¸ªè‡ªåŠ©æ•°æ®é›†çš„æœ€ä½³æ¨¡å‹çš„çµæ´»æ€§ã€‚
- en: '![](../Images/038bd000e2192149c3a4abd1ab0d5cde.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/038bd000e2192149c3a4abd1ab0d5cde.png)'
- en: Estimators in the ensemble of models are trained individually, but share the
    same hyperparameter(s).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆæ¨¡å‹ä¸­çš„ä¼°è®¡å™¨æ˜¯å•ç‹¬è®­ç»ƒçš„ï¼Œä½†å…±äº«ç›¸åŒçš„è¶…å‚æ•°ï¼ˆsï¼‰ã€‚
- en: We tune our bagged model with the error of the bagging estimate from aggregating
    the ensemble of estimates, for the case of regression,
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå›å½’çš„æƒ…å†µï¼Œæˆ‘ä»¬é€šè¿‡èšåˆä¼°è®¡é›†çš„ä¼°è®¡å€¼æ¥è°ƒæ•´æˆ‘ä»¬çš„æ‰“åŒ…æ¨¡å‹ï¼Œä»¥å‡å°‘æ‰“åŒ…ä¼°è®¡çš„é”™è¯¯ï¼Œ
- en: \[ \text{MSE} = \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 \]
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{MSE} = \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 \]
- en: 'where the predicted value \(\hat{y}_i\) is given by:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­é¢„æµ‹å€¼ \(\hat{y}_i\) ç”±ä»¥ä¸‹ç»™å‡ºï¼š
- en: \[ \hat{y}_i = \frac{1}{B} \sum_{b=1}^{B} \hat{y}_i^{(b)} \]
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}_i = \frac{1}{B} \sum_{b=1}^{B} \hat{y}_i^{(b)} \]
- en: We tune our ensemble jointly over all estimators, we do not consider the error
    of individual model estimators, \(\hat{y}_i^ğ‘ - y_i\), within the ensemble for
    model tuning.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹æ‰€æœ‰ä¼°è®¡å™¨è”åˆè°ƒæ•´é›†æˆï¼Œæˆ‘ä»¬ä¸è€ƒè™‘é›†æˆä¸­å•ä¸ªæ¨¡å‹ä¼°è®¡å™¨çš„è¯¯å·®ï¼Œ\(\hat{y}_i^ğ‘ - y_i\)ï¼Œåœ¨æ¨¡å‹è°ƒæ•´ä¸­ã€‚
- en: '![](../Images/fb1f17d4c2c24d97eb7c0121be84a79f.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/fb1f17d4c2c24d97eb7c0121be84a79f.png)'
- en: Estimators in the ensemble of models, sharing the same number of leaf nodes
    hyperparameter.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹é›†æˆä¸­çš„ä¼°è®¡å™¨å…±äº«ç›¸åŒæ•°é‡çš„å¶èŠ‚ç‚¹è¶…å‚æ•°ã€‚
- en: The result is a single measure of test error for each hyperparameter setting,
    for the case above with number of leaf nodes, we get this result,
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¯æ¯ä¸ªè¶…å‚æ•°è®¾ç½®çš„å•ä¸ªæµ‹è¯•è¯¯å·®åº¦é‡ï¼Œå¯¹äºä¸Šè¿°å¶èŠ‚ç‚¹æ•°é‡çš„æƒ…å†µï¼Œæˆ‘ä»¬å¾—åˆ°è¿™ä¸ªç»“æœï¼Œ
- en: '![](../Images/c1090b95f0977ae34559787c21ef3800.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/c1090b95f0977ae34559787c21ef3800.png)'
- en: Ensemble test error vs. number of leaf nodes hyperparameter.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆæµ‹è¯•è¯¯å·®ä¸å¶èŠ‚ç‚¹è¶…å‚æ•°æ•°é‡ã€‚
- en: to select the ensemble hyperparameter to minimize test error. For clarity, letâ€™s
    add the tuning to our previous training bagging models workflow,
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†é€‰æ‹©æœ€å°åŒ–æµ‹è¯•è¯¯å·®çš„é›†æˆè¶…å‚æ•°ã€‚ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œè®©æˆ‘ä»¬å°†è°ƒæ•´æ·»åŠ åˆ°æˆ‘ä»¬ä¹‹å‰çš„è®­ç»ƒæ‰“åŒ…æ¨¡å‹çš„å·¥ä½œæµç¨‹ä¸­ï¼Œ
- en: we loop over hyperparameters
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éå†è¶…å‚æ•°
- en: minimize the test error of the ensemble estimates
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å°åŒ–é›†æˆä¼°è®¡çš„æµ‹è¯•è¯¯å·®
- en: '![](../Images/96ee3c145e994796c9a01d181704650c.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96ee3c145e994796c9a01d181704650c.png)'
- en: The workflow for tuning a bagging model.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒæ•´è¢‹è£…æ¨¡å‹çš„æµç¨‹ã€‚
- en: Out-of-Bag Cross Validation
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¢‹å¤–äº¤å‰éªŒè¯
- en: In expectation, \(\frac{1}{3}\) of the training data is left out of each bootstrap
    data realization, \(b^c\); therefore, cross-validation is built in.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœŸæœ›ä¸­ï¼Œæ¯æ¬¡è‡ªä¸¾æ•°æ®å®ç° \(b^c\) ä¸­æœ‰ \(\frac{1}{3}\) çš„è®­ç»ƒæ•°æ®è¢«æ’é™¤åœ¨å¤–ï¼›å› æ­¤ï¼Œäº¤å‰éªŒè¯æ˜¯å†…ç½®çš„ã€‚
- en: Sample with replacement \(\frac{2}{3}\) of the training data (in expectation),
    \(Y^b, X_1^b, \dots, X_m^b\).
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨æ›¿æ¢æ³•æŠ½å–è®­ç»ƒæ•°æ®çš„ \(\frac{2}{3}\)ï¼ˆåœ¨æœŸæœ›ä¸­ï¼‰ï¼Œ\(Y^b, X_1^b, \dots, X_m^b\)ã€‚
- en: Train an estimator with the \(\frac{2}{3}\) of training data (in expectation).
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(\frac{2}{3}\) çš„è®­ç»ƒæ•°æ®ï¼ˆåœ¨æœŸæœ›ä¸­ï¼‰è®­ç»ƒä¼°è®¡å™¨ã€‚
- en: Predict at the out-of-bag samples, \(X_1^{b^c}, \dots, X_m^{b^c}\), \(\frac{1}{3}\)
    of the training data (in expectation).
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨è¢‹å¤–æ ·æœ¬ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œ\(X_1^{b^c}, \dots, X_m^{b^c}\)ï¼Œ\(\frac{1}{3}\) çš„è®­ç»ƒæ•°æ®ï¼ˆåœ¨æœŸæœ›ä¸­ï¼‰ã€‚
- en: '![](../Images/63c6819827d1a77f4c0cabcd47f88524.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63c6819827d1a77f4c0cabcd47f88524.png)'
- en: Out-of-bag error calculation workflow, to apply add to the hyperparameter tuning
    loop.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: è¢‹å¤–é”™è¯¯è®¡ç®—å·¥ä½œæµç¨‹ï¼Œå°†å…¶åº”ç”¨äºè¶…å‚æ•°è°ƒæ•´å¾ªç¯ã€‚
- en: Pool the ğµ/3 predictions (in expectation) for each sample data from all the
    ğµ models and make an out-of-bag prediction, for regression,
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰ \(B\) ä¸ªæ¨¡å‹ä¸­æ¯ä¸ªæ ·æœ¬æ•°æ®çš„ \(\frac{B}{3}\) é¢„æµ‹ï¼ˆåœ¨æœŸæœ›ä¸­ï¼‰æ±‡æ€»ï¼Œå¹¶å¯¹å›å½’è¿›è¡Œè¢‹å¤–é¢„æµ‹ï¼Œ
- en: \[ \hat{y}_\alpha^{\text{oob}} = \frac{1}{\left(\frac{B}{3}\right)} \sum_{b=1}^{\frac{B}{3}}
    \hat{y}_\alpha^{(b^c)} \]
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}_\alpha^{\text{oob}} = \frac{1}{\left(\frac{B}{3}\right)} \sum_{b=1}^{\frac{B}{3}}
    \hat{y}_\alpha^{(b^c)} \]
- en: Calculate the out-of-bag error to assess model performance.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—è¢‹å¤–é”™è¯¯ä»¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚
- en: \[ \text{MSE}_{\text{OOB}} = \frac{1}{n} \sum_{\alpha=1}^{n} \left[\hat{y}_\alpha^{\text{oob}}
    - y_\alpha \right]^2 \]
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{MSE}_{\text{OOB}} = \frac{1}{n} \sum_{\alpha=1}^{n} \left[\hat{y}_\alpha^{\text{oob}}
    - y_\alpha \right]^2 \]
- en: Number of Estimators
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨æ•°é‡
- en: Number of Estimators is an important hyperparameter for bagging models
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨çš„æ•°é‡æ˜¯è¢‹è£…æ¨¡å‹çš„ä¸€ä¸ªé‡è¦è¶…å‚æ•°
- en: '**More estimators** â€“ improve generalization up to a point, increasing the
    number of trees generally improves performance and reduces variance, as predictions
    are averaged across more models.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´å¤šä¼°è®¡å™¨** â€“ åœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå¢åŠ æ ‘çš„æ•°é‡é€šå¸¸å¯ä»¥æé«˜æ€§èƒ½å¹¶å‡å°‘æ–¹å·®ï¼Œå› ä¸ºé¢„æµ‹æ˜¯åœ¨æ›´å¤šæ¨¡å‹ä¸Šå¹³å‡çš„ã€‚'
- en: '**Diminishing returns** - beyond a point, adding more estimators gives little
    or no improvement and only increases computational cost.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ”¶ç›Šé€’å‡** - è¶…è¿‡æŸä¸ªç‚¹åï¼Œæ·»åŠ æ›´å¤šä¼°è®¡å™¨åªä¼šå¸¦æ¥å¾ˆå°‘æˆ–æ²¡æœ‰æ”¹è¿›ï¼Œå¹¶ä¸”åªä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚'
- en: '**Improved stability** - more trees reduce the likelihood of overfitting to
    random noise in the training set.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æé«˜ç¨³å®šæ€§** - æ›´å¤šçš„æ ‘å‡å°‘äº†è¿‡åº¦æ‹Ÿåˆåˆ°è®­ç»ƒé›†ä¸­éšæœºå™ªå£°çš„å¯èƒ½æ€§ã€‚'
- en: '![](../Images/4ed3a0e3d2ee36395e6476183e806b8a.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ed3a0e3d2ee36395e6476183e806b8a.png)'
- en: Number of estimators, few (upper) and more (lower), within the ensemble model.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨æ•°é‡ï¼Œåœ¨é›†æˆæ¨¡å‹ä¸­è¾ƒå°‘ï¼ˆä¸Šæ–¹ï¼‰å’Œè¾ƒå¤šï¼ˆä¸‹æ–¹ï¼‰ã€‚
- en: Estimator Complexity
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨å¤æ‚æ€§
- en: The hyperparameter(s) shared by the estimators remain as important hyperparameters.
    Hereâ€™s guidance with a focus on tree bagging,
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨å…±äº«çš„è¶…å‚æ•°ä»ç„¶ä½œä¸ºé‡è¦çš„è¶…å‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³äºæ ‘è¢‹çš„æŒ‡å¯¼ï¼Œ
- en: '**More complicated models** â€“ bagging reduces model variance, so we often train
    more complicated models for the ensemble.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´å¤æ‚çš„æ¨¡å‹** â€“ è¢‹è£…å¯ä»¥é™ä½æ¨¡å‹æ–¹å·®ï¼Œå› æ­¤æˆ‘ä»¬é€šå¸¸ä¸ºé›†æˆè®­ç»ƒæ›´å¤æ‚çš„æ¨¡å‹ã€‚'
- en: '**Too simple models** â€“ may not see any improvement from bagging, because model
    variance is not an issue for simple models and does not need to be reduced.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿‡äºç®€å•çš„æ¨¡å‹** â€“ å¯èƒ½ä¸ä¼šä»è¢‹è£…ä¸­çœ‹åˆ°ä»»ä½•æ”¹è¿›ï¼Œå› ä¸ºå¯¹äºç®€å•æ¨¡å‹æ¥è¯´ï¼Œæ¨¡å‹æ–¹å·®ä¸æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿä¸éœ€è¦é™ä½ã€‚'
- en: '**Feature interactions** â€“ more complicated models capture more of the interactions
    between features, for example, tree bagging models with tree depth ğ‘‘ can capture
    ğ‘‘-way feature interactions'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾äº¤äº’** â€“ æ›´å¤æ‚çš„æ¨¡å‹å¯ä»¥æ•æ‰åˆ°æ›´å¤šç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œä¾‹å¦‚ï¼Œæ ‘æ·±åº¦ä¸º \(d\) çš„æ ‘è¢‹æ¨¡å‹å¯ä»¥æ•æ‰ \(d\) æ–¹ç‰¹å¾äº¤äº’'
- en: '![](../Images/b5d39d63f35aded00e0a6d996fa7b353.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5d39d63f35aded00e0a6d996fa7b353.png)'
- en: Ensembles with different tree depth hyperparameters, 2 (upper), 3 (middle) and
    4 (lower).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰ä¸åŒçš„æ ‘æ·±åº¦è¶…å‚æ•°çš„é›†æˆï¼Œ2ï¼ˆä¸Šæ–¹ï¼‰ï¼Œ3ï¼ˆä¸­é—´ï¼‰å’Œ4ï¼ˆä¸‹æ–¹ï¼‰ã€‚
- en: Tree Bagging
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‘è¢‹
- en: Now letâ€™s summarize the approach,
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹è¿™ç§æ–¹æ³•ï¼Œ
- en: Build an ensemble of decision trees with multiple, bootstrap realizations of
    the data.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ•°æ®çš„å¤šä¸ªè‡ªä¸¾å®ç°æ„å»ºå†³ç­–æ ‘é›†æˆã€‚
- en: and provide some guidance,
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶æä¾›ä¸€äº›æŒ‡å¯¼ï¼Œ
- en: the ensemble of tree estimators reduces model variance
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ‘ä¼°è®¡å™¨çš„é›†æˆé™ä½äº†æ¨¡å‹æ–¹å·®
- en: hyperparameter tune over the entire ensemble model, i.e., All trees in the ensemble
    have the same hyperparameters.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•´ä¸ªé›†æˆæ¨¡å‹ä¸Šè¶…å‚æ•°è°ƒæ•´ï¼Œå³é›†æˆä¸­çš„æ‰€æœ‰æ ‘éƒ½å…·æœ‰ç›¸åŒçš„è¶…å‚æ•°ã€‚
- en: number of estimators is an additional, important hyperparameter in addition
    to the tree estimatorsâ€™ complexity
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†æ ‘ä¼°è®¡é‡çš„å¤æ‚æ€§ä¹‹å¤–ï¼Œä¼°è®¡é‡æ•°é‡æ˜¯å¦ä¸€ä¸ªé‡è¦çš„è¶…å‚æ•°ã€‚
- en: in expectation, $\frac{1}{3} of the data is not used for each tree, this provides
    the opportunity to have access to out-of-bag samples for cross validation, so
    we can build our model and cross validate with all the data at once, no train
    and test split.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æœŸæœ›ä¸Šï¼Œæ¯æ£µæ ‘ä¸ä½¿ç”¨ \( \frac{1}{3} \) çš„æ•°æ®ï¼Œè¿™æä¾›äº†è®¿é—®è¢‹å¤–æ ·æœ¬è¿›è¡Œäº¤å‰éªŒè¯çš„æœºä¼šï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä¸€æ¬¡æ€§æ„å»ºæ¨¡å‹å¹¶è¿›è¡Œäº¤å‰éªŒè¯ï¼Œæ— éœ€è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²ã€‚
- en: overgrown trees will often outperform simpler trees due to reduction in model
    variance with averaging over the estimators.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºåœ¨ä¼°è®¡é‡ä¸Šå¹³å‡ï¼Œè¿‡ç”Ÿé•¿çš„æ ‘é€šå¸¸ä¼˜äºç®€å•çš„æ ‘ï¼Œå› ä¸ºæ¨¡å‹æ–¹å·®å‡å°‘ã€‚
- en: Spoiler Alert - we want the trees to be decorrelated, diverse to maximize the
    reduction in model variance, this leads to random forest. More on this later.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: æ­ç¤ºè­¦æŠ¥â€”â€”æˆ‘ä»¬å¸Œæœ›æ ‘ä¸ç›¸å…³ï¼Œå¤šæ ·åŒ–ä»¥æœ€å¤§åŒ–æ¨¡å‹æ–¹å·®çš„å‡å°‘ï¼Œè¿™å¯¼è‡´äº†éšæœºæ£®æ—ã€‚å…³äºè¿™ä¸€ç‚¹ç¨åè¿˜ä¼šè¯¦ç»†ä»‹ç»ã€‚
- en: To visualize tree bagging, hereâ€™s an example of tree bagging by-hand, 6 estimators
    from bootstrap realizations of the data, predicting over porosity and brittleness
    and the average over all the estimates as the bagging model.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯è§†åŒ–æ ‘è¢‹è£…ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæ‰‹åŠ¨æ ‘è¢‹è£…çš„ä¾‹å­ï¼Œ6ä¸ªä¼°è®¡é‡æ¥è‡ªæ•°æ®çš„è‡ªä¸¾å®ç°ï¼Œé¢„æµ‹å­”éš™ç‡å’Œè„†æ€§ï¼Œæ‰€æœ‰ä¼°è®¡é‡çš„å¹³å‡å€¼ä½œä¸ºè¢‹è£…æ¨¡å‹ã€‚
- en: '![](../Images/88fba0db87ba8271f1b97819bfcf45b6.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88fba0db87ba8271f1b97819bfcf45b6.png)'
- en: 6 bootstrapped, complicated decision trees (left) and the bagging model, average
    of all 6 models (right).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 6ä¸ªè‡ªä¸¾çš„å¤æ‚å†³ç­–æ ‘ï¼ˆå·¦ï¼‰å’Œè¢‹è£…æ¨¡å‹ï¼Œæ‰€æœ‰6ä¸ªæ¨¡å‹çš„å¹³å‡å€¼ï¼ˆå³ï¼‰ã€‚
- en: Observe the impact on the prediction model with the addition of more trees â€“
    transition from a discontinuous to continuous prediction model!
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€æ ‘çš„æ•°é‡å¢åŠ å¯¹é¢„æµ‹æ¨¡å‹çš„å½±å“â€”â€”ä»éè¿ç»­é¢„æµ‹æ¨¡å‹åˆ°è¿ç»­é¢„æµ‹æ¨¡å‹çš„è½¬å˜ï¼
- en: '![](../Images/8c66db0c2607c6dd31082060dda55ace.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c66db0c2607c6dd31082060dda55ace.png)'
- en: 6 tree bagging prediction models and all training data with increasing number
    of estimators, for 1, 3, 5, 10, 30 and 500 trees.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 6ä¸ªæ ‘è¢‹è£…é¢„æµ‹æ¨¡å‹å’Œæ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œéšç€ä¼°è®¡é‡æ•°é‡çš„å¢åŠ ï¼Œå¯¹äº1ã€3ã€5ã€10ã€30å’Œ500æ£µæ ‘ã€‚
- en: Observe the improved testing accuracy in cross validation with increasing number
    of trees,
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€æ ‘çš„æ•°é‡å¢åŠ äº¤å‰éªŒè¯ä¸­æµ‹è¯•ç²¾åº¦çš„æé«˜ï¼Œ
- en: '![](../Images/042efb5835a7679f992c4a08097693ad.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/042efb5835a7679f992c4a08097693ad.png)'
- en: Cross validation with 6 tree bagging prediction models with increasing number
    of trees.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨6ä¸ªæ ‘è¢‹è£…é¢„æµ‹æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯ï¼Œæ ‘çš„æ•°é‡é€æ¸å¢åŠ ã€‚
- en: Observe the reduction in model variance with increasing number of trees,
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€æ ‘çš„æ•°é‡å¢åŠ æ¨¡å‹æ–¹å·®çš„å‡å°‘ï¼Œ
- en: '![](../Images/b40d9508fd3daba20f8724ac4dcfb8a5.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b40d9508fd3daba20f8724ac4dcfb8a5.png)'
- en: 3 models with 1 and 100 trees to demonstrate the reduction in model variance
    with increased ensemble aggregation.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 3ä¸ªæ¨¡å‹ï¼Œ1æ£µå’Œ100æ£µæ ‘ï¼Œä»¥å±•ç¤ºéšç€é›†æˆèšåˆå¢åŠ æ¨¡å‹æ–¹å·®çš„å‡å°‘ã€‚
- en: Random Forest
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—
- en: A limitation with tree bagging is that the individual trees may be highly correlated.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‘è¢‹è£…çš„ä¸€ä¸ªå±€é™æ€§æ˜¯å•ä¸ªæ ‘å¯èƒ½é«˜åº¦ç›¸å…³ã€‚
- en: this occurs when there is a dominant predictor feature as it will always be
    applied to the top split(s), the result is all the trees in the ensemble are very
    similar (i.e., correlated)
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™å‘ç”Ÿåœ¨å­˜åœ¨ä¸»å¯¼é¢„æµ‹ç‰¹å¾æ—¶ï¼Œå› ä¸ºå®ƒå°†å§‹ç»ˆåº”ç”¨äºé¡¶éƒ¨åˆ†å‰²ï¼ˆsï¼‰ï¼Œç»“æœæ˜¯é›†æˆä¸­çš„æ‰€æœ‰æ ‘éƒ½éå¸¸ç›¸ä¼¼ï¼ˆå³ç›¸å…³ï¼‰
- en: '![](../Images/d21f6ab27e26033ce1dd293c469b1851.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d21f6ab27e26033ce1dd293c469b1851.png)'
- en: Highly correlated trees in a tree bagging ensemble model, trees with the same
    initial splits resulting in very similar predictions.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ ‘è¢‹è£…é›†æˆæ¨¡å‹ä¸­é«˜åº¦ç›¸å…³çš„æ ‘ï¼Œå…·æœ‰ç›¸åŒåˆå§‹åˆ†å‰²çš„æ ‘å¯¼è‡´éå¸¸ç›¸ä¼¼çš„é¢„æµ‹ã€‚
- en: With highly correlated trees, there is significantly less reduction in model
    variance with the ensemble,
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸é«˜åº¦ç›¸å…³çš„æ ‘ç›¸æ¯”ï¼Œä½¿ç”¨é›†æˆæ¨¡å‹æ—¶æ¨¡å‹æ–¹å·®å‡å°‘çš„å¹…åº¦æ˜¾è‘—è¾ƒå°ï¼Œ
- en: consider, standard error in the mean assumes the samples ğ‘› are independent!
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°å¹³å‡æ ‡å‡†è¯¯å·®å‡è®¾æ ·æœ¬ \(ğ‘›\) æ˜¯ç‹¬ç«‹çš„ï¼
- en: \[ \sigma_{\bar{x}}^2 = \frac{\sigma_s^2}{n} \]
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\bar{x}}^2 = \frac{\sigma_s^2}{n} \]
- en: correlation between samples reduces the ğ‘› to a ğ‘› effective, as correlation increases,
    \(n\) effectively is reduced.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§å‡å°‘äº† \(ğ‘›\) åˆ° \(ğ‘›\) æœ‰æ•ˆï¼Œéšç€ç›¸å…³æ€§çš„å¢åŠ ï¼Œ\(n\) æœ‰æ•ˆå‡å°‘ã€‚
- en: Random forest is tree bagging, but for each split only a subset \(ğ‘\) of the
    \(ğ‘š\) available predictors are candidates for splits (selected at random).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—æ˜¯æ ‘è¢‹è£…ï¼Œä½†å¯¹äºæ¯ä¸ªåˆ†å‰²ï¼Œåªæœ‰ \(ğ‘š\) ä¸ªå¯ç”¨é¢„æµ‹å› å­ä¸­çš„å­é›† \(ğ‘\) æ˜¯åˆ†å‰²çš„å€™é€‰è€…ï¼ˆéšæœºé€‰æ‹©ï¼‰ã€‚
- en: \[ p \ll m \]
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p \ll m \]
- en: This forces each tree in the ensemble to evolve in dissimilar manner,
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¿«ä½¿é›†æˆä¸­çš„æ¯æ£µæ ‘ä»¥ä¸åŒçš„æ–¹å¼è¿›åŒ–ï¼Œ
- en: Common defaults for ğ‘ for classification,
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»ä¸­ \(ğ‘\) çš„å¸¸è§é»˜è®¤å€¼ï¼Œ
- en: \[ p = \sqrt{m} \quad \text{or} \quad \log_2(p) \]
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p = \sqrt{m} \quad \text{æˆ–} \quad \log_2(p) \]
- en: and for regression,
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå›å½’ï¼Œ
- en: \[ p=\frac{m}{3} \]
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p=\frac{m}{3} \]
- en: Lower \(p\) less correlation, better generalization, higher \(p\) more correlation,
    may overfit. note, too low \(p\) will underfit with high model bias
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: è¾ƒä½çš„\(p\)å€¼é™ä½ç›¸å…³æ€§ï¼Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¾ƒé«˜çš„\(p\)å€¼å¢åŠ ç›¸å…³æ€§ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆã€‚æ³¨æ„ï¼Œ\(p\)å€¼è¿‡ä½ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆï¼Œæ¨¡å‹åå·®é«˜
- en: Hereâ€™s an example random forest model for the previous prediction problem,
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªç”¨äºå…ˆå‰é¢„æµ‹é—®é¢˜çš„éšæœºæ£®æ—æ¨¡å‹ç¤ºä¾‹ï¼Œ
- en: 300 trees, trained to a maximum depth of \(7\), \(ğ‘=1\), i.e., 1 predictor feature
    randomly selected for each split
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 300æ£µæ ‘ï¼Œè®­ç»ƒåˆ°æœ€å¤§æ·±åº¦ä¸º\(7\)ï¼Œ\(ğ‘=1\)ï¼Œå³æ¯ä¸ªåˆ†å‰²éšæœºé€‰æ‹©1ä¸ªé¢„æµ‹ç‰¹å¾
- en: '![](../Images/8af256b868880607f4d3a18527c44eac.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8af256b868880607f4d3a18527c44eac.png)'
- en: Highly correlated trees in a tree bagging ensemble model, trees with the same
    initial splits resulting in very similar predictions.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ ‘è¢‹é›†æˆæ¨¡å‹ä¸­é«˜åº¦ç›¸å…³çš„æ ‘ï¼Œå…·æœ‰ç›¸åŒåˆå§‹åˆ†å‰²çš„æ ‘äº§ç”Ÿéå¸¸ç›¸ä¼¼çš„é¢„æµ‹ã€‚
- en: Now we are ready to demonstrate tree bagging and random forest.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å‡†å¤‡æ¼”ç¤ºæ ‘è¢‹å’Œéšæœºæ£®æ—ã€‚
- en: Load the Required Libraries
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½æ‰€éœ€çš„åº“
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›æ ‡å‡†åŒ…ã€‚è¿™äº›åº”è¯¥å·²ç»ä¸Anaconda 3ä¸€èµ·å®‰è£…ã€‚
- en: '[PRE0]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing â€˜python -m pip install [package-name]â€™. More assistance is available
    with the respective package docs.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨é‡åˆ°åŒ…å¯¼å…¥é”™è¯¯ï¼Œæ‚¨å¯èƒ½é¦–å…ˆéœ€è¦å®‰è£…å…¶ä¸­çš„ä¸€äº›åŒ…ã€‚è¿™é€šå¸¸å¯ä»¥é€šè¿‡åœ¨Windowsä¸Šæ‰“å¼€å‘½ä»¤çª—å£ç„¶åè¾“å…¥â€˜python -m pip install
    [package-name]â€™æ¥å®Œæˆã€‚æœ‰å…³ç›¸åº”åŒ…çš„æ›´å¤šå¸®åŠ©ï¼Œè¯·å‚é˜…å„è‡ªçš„åŒ…æ–‡æ¡£ã€‚
- en: Declare Functions
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å£°æ˜å‡½æ•°
- en: Letâ€™s define a couple of functions to streamline plotting correlation matrices
    and visualization of a decision, boosting tree and random forest regression model.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å®šä¹‰å‡ ä¸ªå‡½æ•°æ¥ç®€åŒ–ç›¸å…³çŸ©é˜µçš„ç»˜åˆ¶å’Œå†³ç­–ã€æå‡æ ‘å’Œéšæœºæ£®æ—å›å½’æ¨¡å‹çš„å¯è§†åŒ–ã€‚
- en: '[PRE1]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Set the working directory
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¾ç½®å·¥ä½œç›®å½•
- en: I always like to do this so I donâ€™t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å–œæ¬¢è¿™æ ·åšï¼Œè¿™æ ·æˆ‘å°±ä¸ä¼šä¸¢å¤±æ–‡ä»¶ï¼Œå¹¶ä¸”å¯ä»¥ç®€åŒ–åç»­çš„è¯»å–å’Œå†™å…¥ï¼ˆé¿å…æ¯æ¬¡éƒ½åŒ…å«å®Œæ•´åœ°å€ï¼‰ã€‚
- en: '[PRE2]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You will have to update the part in quotes with your own working directory and
    the format is different on a Mac (e.g. â€œ~/PGEâ€).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å°†éœ€è¦æ›´æ–°å¼•å·å†…çš„éƒ¨åˆ†ä»¥åæ˜ æ‚¨è‡ªå·±çš„å·¥ä½œç›®å½•ï¼Œå¹¶ä¸”åœ¨Macä¸Šæ ¼å¼ä¸åŒï¼ˆä¾‹å¦‚ï¼šâ€œ~/PGEâ€ï¼‰ã€‚
- en: Loading Data
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®
- en: 'Letâ€™s load the provided multivariate, spatial dataset [unconv_MV.csv](https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv)
    available in my GeoDataSet repo. It is a comma delimited file with:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€ç©ºé—´æ•°æ®é›† [unconv_MV.csv](https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv)ï¼Œå®ƒåœ¨æˆ‘çš„GeoDataSetä»“åº“ä¸­å¯ç”¨ã€‚å®ƒæ˜¯ä¸€ä¸ªé€—å·åˆ†éš”çš„æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
- en: well index (integer)
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•æŒ‡æ•°ï¼ˆæ•´æ•°ï¼‰
- en: porosity (%)
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ï¼ˆ%ï¼‰
- en: permeability (\(mD\))
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡ï¼ˆ\(mD\)ï¼‰
- en: acoustic impedance (\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^6\)).
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ—ï¼ˆ\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^6\)ï¼‰
- en: brittleness (%)
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å»¶å±•æ€§ï¼ˆ%ï¼‰
- en: total organic carbon (%)
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€»æœ‰æœºç¢³ï¼ˆ%ï¼‰
- en: vitrinite reflectance (%)
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çƒç²’åå°„ç‡ï¼ˆ%ï¼‰
- en: initial gas production (90 day average) (MCFPD)
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆå§‹æ°”äº§é‡ï¼ˆ90å¤©å¹³å‡ï¼‰ï¼ˆMCFPDï¼‰
- en: We load it with the pandas â€˜read_csvâ€™ function into a data frame we called â€˜dfâ€™
    and then preview it to make sure it loaded correctly.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨pandasçš„â€˜read_csvâ€™å‡½æ•°å°†å…¶åŠ è½½åˆ°æˆ‘ä»¬ç§°ä¸ºâ€˜dfâ€™çš„æ•°æ®æ¡†ä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚
- en: '**Python Tip: using functions from a package** just type the label for the
    package that we declared at the beginning:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '**PythonæŠ€å·§ï¼šä½¿ç”¨åŒ…ä¸­çš„å‡½æ•°**åªéœ€è¾“å…¥æˆ‘ä»¬åœ¨å¼€å¤´å£°æ˜çš„åŒ…çš„æ ‡ç­¾ï¼š'
- en: '[PRE3]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'so we can access the pandas function â€˜read_csvâ€™ with the command:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‘½ä»¤è®¿é—®pandaså‡½æ•°â€˜read_csvâ€™ï¼š
- en: '[PRE4]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: but read csv has required input parameters. The essential one is the name of
    the file. For our circumstance all the other default parameters are fine. If you
    want to see all the possible parameters for this function, just go to the docs
    [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œread csvéœ€è¦è¾“å…¥å‚æ•°ã€‚æœ€é‡è¦çš„ä¸€ä¸ªæ˜¯æ–‡ä»¶åã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰å…¶ä»–é»˜è®¤å‚æ•°éƒ½å¾ˆå¥½ã€‚å¦‚æœæ‚¨æƒ³æŸ¥çœ‹æ­¤å‡½æ•°çš„æ‰€æœ‰å¯èƒ½å‚æ•°ï¼Œè¯·å‚é˜…[æ­¤å¤„](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)çš„æ–‡æ¡£ã€‚
- en: The docs are always helpful
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–‡æ¡£æ€»æ˜¯å¾ˆæœ‰å¸®åŠ©
- en: There is often a lot of flexibility for Python functions, possible through using
    various inputs parameters
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pythonå‡½æ•°é€šå¸¸æœ‰å¾ˆå¤šçµæ´»æ€§ï¼Œè¿™å¯ä»¥é€šè¿‡ä½¿ç”¨å„ç§è¾“å…¥å‚æ•°æ¥å®ç°
- en: also, the program has an output, a pandas DataFrame loaded from the data. So
    we have to specify the name / variable representing that new object.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œç¨‹åºæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œä¸€ä¸ªä»æ•°æ®åŠ è½½çš„pandas DataFrameã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»æŒ‡å®šä»£è¡¨è¯¥æ–°å¯¹è±¡çš„åå­—/å˜é‡ã€‚
- en: '[PRE5]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Letâ€™s run this command to load the data and then this command to extract a random
    subset of the data.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œæ­¤å‘½ä»¤æ¥åŠ è½½æ•°æ®ï¼Œç„¶åè¿è¡Œæ­¤å‘½ä»¤æ¥æå–æ•°æ®çš„ä¸€ä¸ªéšæœºå­é›†ã€‚
- en: '[PRE6]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Feature Engineering
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‰¹å¾å·¥ç¨‹
- en: 'Letâ€™s make some changes to the data to improve the workflow:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œä¸€äº›ä¿®æ”¹ä»¥æ”¹è¿›å·¥ä½œæµç¨‹ï¼š
- en: '**Select the predictor features (x2) and the response feature (x1)**, make
    sure the metadata is also consistent.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©é¢„æµ‹ç‰¹å¾ï¼ˆx2ï¼‰å’Œå“åº”ç‰¹å¾ï¼ˆx1ï¼‰**ï¼Œç¡®ä¿å…ƒæ•°æ®ä¹Ÿä¿æŒä¸€è‡´ã€‚'
- en: '**Metadata** encoding such as the units, labels and display ranges for each
    feature.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å…ƒæ•°æ®**ç¼–ç ï¼Œå¦‚æ¯ä¸ªç‰¹å¾çš„å•ä½ã€æ ‡ç­¾å’Œæ˜¾ç¤ºèŒƒå›´ã€‚'
- en: '**Reduce the number of data** for ease of visualization (hard to see if too
    many points on our plots).'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‡å°‘æ•°æ®æ•°é‡**ä»¥æ–¹ä¾¿å¯è§†åŒ–ï¼ˆå¦‚æœå›¾ä¸Šç‚¹å¤ªå¤šï¼Œåˆ™éš¾ä»¥çœ‹æ¸…ï¼‰ã€‚'
- en: '**Train and test data split** to demonstrate and visualize simple hyperparameter
    tuning.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²**ä»¥å±•ç¤ºå’Œå¯è§†åŒ–ç®€å•çš„è¶…å‚æ•°è°ƒæ•´ã€‚'
- en: '**Add random noise to the data** to demonstrate model overfit. The original
    data is error free and does not readily demonstrate overfit.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‘æ•°æ®æ·»åŠ éšæœºå™ªå£°**ä»¥å±•ç¤ºæ¨¡å‹è¿‡æ‹Ÿåˆã€‚åŸå§‹æ•°æ®æ— è¯¯å·®ï¼Œå¹¶ä¸å®¹æ˜“å±•ç¤ºè¿‡æ‹Ÿåˆã€‚'
- en: Given this is properly set, one should be able to use any dataset and features
    for this demonstration.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè®¾ç½®å¾—å½“ï¼Œåº”è¯¥èƒ½å¤Ÿä½¿ç”¨ä»»ä½•æ•°æ®é›†å’Œç‰¹å¾è¿›è¡Œæ­¤æ¼”ç¤ºã€‚
- en: for brevity we donâ€™t show any feature selection here. Previous chapter, e.g.,
    k-nearest neighbours include some feature selection methods, but see the feature
    selection chapter for many possible methods with codes for feature selection.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€æ´ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸å±•ç¤ºä»»ä½•ç‰¹å¾é€‰æ‹©ã€‚å‰ä¸€ç« ï¼Œä¾‹å¦‚k-æœ€è¿‘é‚»ç®—æ³•åŒ…æ‹¬ä¸€äº›ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œä½†è¯·å‚é˜…ç‰¹å¾é€‰æ‹©ç« èŠ‚ï¼Œä»¥äº†è§£è®¸å¤šå¯èƒ½çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•åŠå…¶ä»£ç ã€‚
- en: 'Optional: Add Random Noise to the Response Feature'
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯é€‰ï¼šå‘å“åº”ç‰¹å¾æ·»åŠ éšæœºå™ªå£°
- en: We can do this to observe the impact of data noise on overfit and hyperparameter
    tuning.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è¿™æ ·åšä»¥è§‚å¯Ÿæ•°æ®å™ªå£°å¯¹è¿‡æ‹Ÿåˆå’Œè¶…å‚æ•°è°ƒæ•´çš„å½±å“ã€‚
- en: This is for experiential learning, of course we wouldnâ€™t add random noise to
    our data
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸ºäº†ç»éªŒå­¦ä¹ ï¼Œå½“ç„¶æˆ‘ä»¬ä¸ä¼šå‘æ•°æ®æ·»åŠ éšæœºå™ªå£°ã€‚
- en: We set the random number seed for reproducibility
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾ç½®äº†éšæœºæ•°ç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§ã€‚
- en: '[PRE7]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Letâ€™s make sure that we have selected reasonable features to build a model
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¡®ä¿æˆ‘ä»¬å·²ç»é€‰æ‹©äº†åˆç†çš„ç‰¹å¾æ¥æ„å»ºæ¨¡å‹ã€‚
- en: the 2 predictor features are not collinear, as this would result in an unstable
    prediction model
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªé¢„æµ‹ç‰¹å¾ä¸å…±çº¿ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´é¢„æµ‹æ¨¡å‹ä¸ç¨³å®šã€‚
- en: each of the features are related to the response feature, the predictor features
    inform the response
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªç‰¹å¾éƒ½ä¸å“åº”ç‰¹å¾ç›¸å…³ï¼Œé¢„æµ‹ç‰¹å¾é€šçŸ¥å“åº”ç‰¹å¾ã€‚
- en: Calculate the Correlation Matrix and Correlation with Response Ranking
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¡ç®—ç›¸å…³çŸ©é˜µå’Œä¸å“åº”ç‰¹å¾çš„ç›¸å…³æ€§æ’å
- en: Letâ€™s start with correlation analysis. We can calculate and view the correlation
    matrix and correlation to the response features with these previously declared
    functions.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ç›¸å…³æ€§åˆ†æå¼€å§‹ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¹‹å‰å£°æ˜çš„å‡½æ•°è®¡ç®—å¹¶æŸ¥çœ‹ç›¸å…³çŸ©é˜µä»¥åŠä¸å“åº”ç‰¹å¾çš„ç›¸å…³æ€§ã€‚
- en: correlation analysis is based on the assumption of linear relationships, but
    it is a good start
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å…³æ€§åˆ†æåŸºäºçº¿æ€§å…³ç³»çš„å‡è®¾ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªè‰¯å¥½çš„èµ·ç‚¹ã€‚
- en: '[PRE8]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png](../Images/fe078f42023f81da1972474b1d3bbf26.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/fe078f42023f81da1972474b1d3bbf26.png)'
- en: Note the 1.0 diagonal resulting from the correlation of each variable with themselves.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ç”±äºæ¯ä¸ªå˜é‡ä¸å…¶è‡ªèº«çš„ç›¸å…³æ€§è€Œäº§ç”Ÿçš„1.0å¯¹è§’çº¿ã€‚
- en: This looks good. There is a mix of correlation magnitudes. Of course, correlation
    coefficients are limited to degree of linear correlations.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœ‹èµ·æ¥ä¸é”™ã€‚å­˜åœ¨å¤šç§ç›¸å…³æ€§çš„å¤§å°ã€‚å½“ç„¶ï¼Œç›¸å…³ç³»æ•°ä»…é™äºçº¿æ€§ç›¸å…³æ€§çš„ç¨‹åº¦ã€‚
- en: Letâ€™s look at the matrix scatter plot to see the pairwise relationship between
    the features.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹çŸ©é˜µæ•£ç‚¹å›¾ï¼Œä»¥æŸ¥çœ‹ç‰¹å¾ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚
- en: '[PRE9]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png](../Images/515a70a53d49c49c9ecf98249cd67b5d.png)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/515a70a53d49c49c9ecf98249cd67b5d.png)'
- en: Train and Test Split
  id: totrans-370
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²
- en: Since we are working with ensemble methods the train and test split is built
    into the model training with out-of-bag samples.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨é›†æˆæ–¹æ³•ï¼Œå› æ­¤è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²å·²å†…ç½®åˆ°æ¨¡å‹è®­ç»ƒä¸­ï¼ŒåŒ…æ‹¬è¢‹å¤–æ ·æœ¬ã€‚
- en: we will work with the entire dataset
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å¤„ç†æ•´ä¸ªæ•°æ®é›†ã€‚
- en: note, we could split a testing dataset for the train, validate, test approach.
    For simplicity I only use train and test in these workflows.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ–¹æ³•åˆ†å‰²ä¸€ä¸ªæµ‹è¯•æ•°æ®é›†ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘åœ¨è¿™äº›å·¥ä½œæµç¨‹ä¸­åªä½¿ç”¨è®­ç»ƒå’Œæµ‹è¯•ã€‚
- en: Visualize the DataFrame
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–æ•°æ®æ¡†
- en: Visualizing the train and test DataFrame is useful check before we build our
    models.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬æ„å»ºæ¨¡å‹ä¹‹å‰ï¼Œå¯è§†åŒ–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†æ˜¯æœ‰ç”¨çš„æ£€æŸ¥ã€‚
- en: many things can go wrong, e.g., we loaded the wrong data, all the features did
    not load, etc.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¸å¤šäº‹æƒ…å¯èƒ½ä¼šå‡ºé”™ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬åŠ è½½äº†é”™è¯¯çš„æ•°æ®ï¼Œæ‰€æœ‰ç‰¹å¾éƒ½æ²¡æœ‰åŠ è½½ç­‰ã€‚
- en: We can preview by utilizing the â€˜headâ€™ DataFrame member function (with a nice
    and clean format, see below).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨â€˜headâ€™DataFrameæˆå‘˜å‡½æ•°æ¥é¢„è§ˆï¼ˆæ ¼å¼æ•´æ´ï¼Œè§ä¸‹æ–‡ï¼‰ã€‚
- en: '[PRE10]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '|  | Por | Brittle | Production |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Brittle | Production |'
- en: '| --- | --- | --- | --- |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 7.22 | 63.09 | 2006.074005 |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 7.22 | 63.09 | 2006.074005 |'
- en: '| 1 | 13.01 | 50.41 | 4244.321703 |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 13.01 | 50.41 | 4244.321703 |'
- en: '| 2 | 10.03 | 37.74 | 2493.189177 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 10.03 | 37.74 | 2493.189177 |'
- en: '| 3 | 18.10 | 56.09 | 6124.075271 |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 18.10 | 56.09 | 6124.075271 |'
- en: '| 4 | 16.95 | 61.43 | 5951.336259 |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 16.95 | 61.43 | 5951.336259 |'
- en: Summary Statistics for Tabular Data
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¡¨æ ¼æ•°æ®çš„æ±‡æ€»ç»Ÿè®¡
- en: There are a lot of efficient methods to calculate summary statistics from tabular
    data in DataFrames.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨DataFramesä¸­ï¼Œæœ‰è®¸å¤šé«˜æ•ˆçš„æ–¹æ³•å¯ä»¥è®¡ç®—è¡¨æ ¼æ•°æ®çš„æ±‡æ€»ç»Ÿè®¡ã€‚
- en: The describe command provides count, mean, minimum, maximum, percentiles in
    a nice data table.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: describeå‘½ä»¤ä»¥æ•°æ®è¡¨çš„å½¢å¼æä¾›è®¡æ•°ã€å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼ã€ç™¾åˆ†ä½æ•°ã€‚
- en: '[PRE11]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '|  | Por | Brittle | Production |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Brittle | Production |'
- en: '| --- | --- | --- | --- |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| count | 140.000000 | 140.000000 | 140.000000 |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| count | 140.000000 | 140.000000 | 140.000000 |'
- en: '| mean | 14.897357 | 48.345429 | 4273.644226 |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| mean | 14.897357 | 48.345429 | 4273.644226 |'
- en: '| std | 3.181639 | 14.157619 | 1138.466092 |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| std | 3.181639 | 14.157619 | 1138.466092 |'
- en: '| min | 6.550000 | 10.940000 | 1517.373571 |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| min | 6.550000 | 10.940000 | 1517.373571 |'
- en: '| 10% | 10.866000 | 28.853000 | 2957.573690 |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 10% | 10.866000 | 28.853000 | 2957.573690 |'
- en: '| 50% | 14.855000 | 50.735000 | 4315.186629 |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 14.855000 | 50.735000 | 4315.186629 |'
- en: '| 90% | 18.723000 | 65.813000 | 5815.526968 |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 90% | 18.723000 | 65.813000 | 5815.526968 |'
- en: '| max | 23.550000 | 84.330000 | 6907.632261 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| max | 23.550000 | 84.330000 | 6907.632261 |'
- en: It is good that we checked the summary statistics.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ£€æŸ¥æ±‡æ€»ç»Ÿè®¡æ˜¯ä»¶å¥½äº‹ã€‚
- en: there are no obvious issues
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰æ˜æ˜¾çš„é”™è¯¯
- en: check out the range of values for each feature to set up and adjust plotting
    limits. See above.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ¯ä¸ªç‰¹å¾å€¼çš„èŒƒå›´ï¼Œä»¥è®¾ç½®å’Œè°ƒæ•´ç»˜å›¾é™åˆ¶ã€‚è§ä¸Šæ–‡ã€‚
- en: Visualize the Distributions
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–åˆ†å¸ƒ
- en: Letâ€™s check the histograms and scatter plots of the predictor features.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ£€æŸ¥é¢„æµ‹ç‰¹å¾çš„å†å²å›¾å’Œæ•£ç‚¹å›¾ã€‚
- en: check to make sure the data cover the range of possible predictor feature combinations
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ•°æ®æ˜¯å¦è¦†ç›–äº†å¯èƒ½çš„é¢„æµ‹ç‰¹å¾ç»„åˆèŒƒå›´
- en: check that the predictor features are not highly correlated, collinear, as this
    increases model variance
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥é¢„æµ‹ç‰¹å¾æ˜¯å¦æ²¡æœ‰é«˜åº¦ç›¸å…³æ€§ï¼Œæ²¡æœ‰å…±çº¿æ€§ï¼Œå› ä¸ºè¿™ä¼šå¢åŠ æ¨¡å‹æ–¹å·®
- en: '[PRE12]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![_images/c9e941b61d19ec872e32d0b10c48a28622e57437ff6fa45205763cc62773906a.png](../Images/3afbd7af1752bc8c73a552f17ebbfd8d.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![_images/c9e941b61d19ec872e32d0b10c48a28622e57437ff6fa45205763cc62773906a.png](../Images/3afbd7af1752bc8c73a552f17ebbfd8d.png)'
- en: Once again, the distributions are well behaved,
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œåˆ†å¸ƒè¡¨ç°è‰¯å¥½ï¼Œ
- en: we cannot observe obvious gaps nor truncations.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ— æ³•è§‚å¯Ÿåˆ°æ˜æ˜¾çš„é—´éš™æˆ–æˆªæ–­ã€‚
- en: the predictor features are not highly correlated
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ä¹‹é—´æ²¡æœ‰é«˜åº¦ç›¸å…³æ€§
- en: Letâ€™s look at a scatter plot of Porosity vs. Brittleness with points colored
    by Production.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å­”éš™ç‡ä¸è„†æ€§ä¹‹é—´çš„æ•£ç‚¹å›¾ï¼Œç‚¹æ ¹æ®äº§é‡ç€è‰²ã€‚
- en: to visualize the prediction problem, i.e., the shape of the system
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–é¢„æµ‹é—®é¢˜ï¼Œå³ç³»ç»Ÿçš„å½¢çŠ¶
- en: '[PRE13]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![_images/6980039b0d3453603a0540f6ba29b6b821be9104ac38a6c3b26a9b0a9cd5a007.png](../Images/872ca67d7fc1098e9ee39b83f936887b.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![_images/6980039b0d3453603a0540f6ba29b6b821be9104ac38a6c3b26a9b0a9cd5a007.png](../Images/872ca67d7fc1098e9ee39b83f936887b.png)'
- en: Ensemble Tree Method - Tree Bagging Regression
  id: totrans-416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆæ ‘æ–¹æ³• - æ ‘è¢‹å›å½’
- en: 'We are ready to build a tree bagging model. To perform tree bagging we:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡†å¤‡æ„å»ºä¸€ä¸ªæ ‘è¢‹æ¨¡å‹ã€‚è¦æ‰§è¡Œæ ‘è¢‹æ“ä½œï¼Œæˆ‘ä»¬ï¼š
- en: set the hyperparameters for the individual trees
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºå•ä¸ªæ ‘è®¾ç½®è¶…å‚æ•°
- en: '[PRE14]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: instantiate an individual regression tree
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ä¾‹åŒ–å•ä¸ªå›å½’æ ‘
- en: '[PRE15]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: set the bagging hyperparameters
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®è¢‹è£…è¶…å‚æ•°
- en: '[PRE16]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: instantiate the bagging regressor with the previously instantiated regression
    tree (wrapping the decision tree)
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å…ˆå‰å®ä¾‹åŒ–çš„å›å½’æ ‘ï¼ˆåŒ…è£…å†³ç­–æ ‘ï¼‰å®ä¾‹åŒ–è¢‹è£…å›å½’å™¨
- en: '[PRE17]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: train the bagging regression (wrapping the decision tree)
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®­ç»ƒè¢‹è£…å›å½’ï¼ˆåŒ…è£…å†³ç­–æ ‘ï¼‰
- en: '[PRE18]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: visualize the model result over the feature space (easy to do as we have only
    2 predictor features)
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ç‰¹å¾ç©ºé—´ä¸Šå¯è§†åŒ–æ¨¡å‹ç»“æœï¼ˆç”±äºæˆ‘ä»¬åªæœ‰ä¸¤ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œå› æ­¤å¾ˆå®¹æ˜“åšåˆ°ï¼‰
- en: Demonstration of Bagging by-Hand
  id: totrans-429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰‹åŠ¨è¢‹è£…æ¼”ç¤º
- en: For demonstration of by-hand tree bagging letâ€™s set the number of trees to 1
    and run tree bagging regression 6 times.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ‰‹åŠ¨æ¼”ç¤ºæ ‘è¢‹ï¼Œæˆ‘ä»¬å°†æ ‘çš„æ•°é‡è®¾ç½®ä¸º1ï¼Œå¹¶è¿è¡Œ6æ¬¡æ ‘è¢‹å›å½’ã€‚
- en: the result for each is a single complicated decision tree
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªç»“æœçš„éƒ½æ˜¯ä¸€ä¸ªå¤æ‚çš„å•ä¸ªå†³ç­–æ ‘
- en: note, the random_state parameter is the random number seed for the bootstrap
    in the bagging method
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œrandom_stateå‚æ•°æ˜¯è¢‹è£…æ–¹æ³•ä¸­è‡ªä¸¾çš„éšæœºæ•°ç§å­
- en: the trees vary for each random number seed since the bootstrapped dataset will
    be different for each
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºè‡ªåŠ©æ•°æ®é›†å¯¹äºæ¯ä¸ªéšæœºæ•°ç§å­éƒ½ä¼šä¸åŒï¼Œå› æ­¤æ ‘å¯¹äºæ¯ä¸ªéšæœºæ•°ç§å­éƒ½ä¼šæœ‰æ‰€ä¸åŒ
- en: We will loop over the models and store each of them in an list of models.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†éå†æ¨¡å‹å¹¶å°†æ¯ä¸ªæ¨¡å‹å­˜å‚¨åœ¨ä¸€ä¸ªæ¨¡å‹åˆ—è¡¨ä¸­ã€‚
- en: '[PRE19]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![_images/eea5b5097df4ef4a221f3d871149c4a47c31d4898b463afa9acc7b2d628ea79f.png](../Images/31276b65834e695aebb5de91a9019af9.png)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/31276b65834e695aebb5de91a9019af9.png)'
- en: Notice the data changes for each model,
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æ¯ä¸ªæ¨¡å‹çš„æ•°æ®å˜åŒ–ï¼Œ
- en: we have bootstrapped the dataset so some of the data are missing and others
    are used 2 or more times
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹æ•°æ®é›†è¿›è¡Œäº†è‡ªåŠ©é‡é‡‡æ ·ï¼Œå› æ­¤ä¸€äº›æ•°æ®ç¼ºå¤±ï¼Œè€Œå…¶ä»–æ•°æ®è¢«ä½¿ç”¨äº†2æ¬¡æˆ–æ›´å¤šã€‚
- en: recall, in expectation, only 2/3 of the data are used for each tree, and 1/3
    is out-of-bag
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›æƒ³ä¸€ä¸‹ï¼Œåœ¨æœŸæœ›ä¸­ï¼Œåªæœ‰2/3çš„æ•°æ®ç”¨äºæ¯æ£µæ ‘ï¼Œ1/3æ˜¯è¢‹å¤–æ•°æ®ã€‚
- en: Letâ€™s check the cross validation results with the out-of-bag data.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨è¢‹å¤–æ•°æ®æ¥æ£€æŸ¥äº¤å‰éªŒè¯çš„ç»“æœã€‚
- en: '[PRE20]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![_images/783d535af6b2da8c5c69b4db7d4c9baff9168424e9c07006449e47e66dc7c771.png](../Images/efaec048c6783e5270a3de45c28fb832.png)'
  id: totrans-442
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/efaec048c6783e5270a3de45c28fb832.png)'
- en: Now letâ€™s demonstrate the averaging of the predictions over the 6 decision trees,
    we are performing bagging tree prediction by-hand to clearly demonstrate the method.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¼”ç¤ºå¯¹6æ£µå†³ç­–æ ‘çš„é¢„æµ‹è¿›è¡Œå¹³å‡ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æ‰§è¡Œè¢‹è£…æ ‘é¢„æµ‹ä»¥æ¸…æ¥šåœ°å±•ç¤ºè¯¥æ–¹æ³•ã€‚
- en: we average the predicted response feature (production) over the discretized
    predictor feature space
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç¦»æ•£åŒ–çš„é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šå¹³å‡é¢„æµ‹å“åº”ç‰¹å¾ï¼ˆäº§é‡ï¼‰ã€‚
- en: we can take advantage of broadcast methods for operations on entire arrays
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ©ç”¨å¹¿æ’­æ–¹æ³•å¯¹æ•´ä¸ªæ•°ç»„è¿›è¡Œæ“ä½œã€‚
- en: we will apply the same model check, but we will use a modified function to will
    read in the response feature 2D array, instead of a model
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åº”ç”¨ç›¸åŒçš„æ¨¡å‹æ£€æŸ¥ï¼Œä½†æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªä¿®æ”¹åçš„å‡½æ•°æ¥è¯»å–å“åº”ç‰¹å¾äºŒç»´æ•°ç»„ï¼Œè€Œä¸æ˜¯æ¨¡å‹ã€‚
- en: '[PRE21]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![_images/f20a801dbb20a98a7b2ad7c35c59f481b086f7e243c708954eaafbad1eeac330.png](../Images/e53f12af38e9579211e007a9e5ad0273.png)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/e53f12af38e9579211e007a9e5ad0273.png)'
- en: We made 6 complicated trees, each trained with bootstrap resamples of the original
    data and then averaged the predictions from each.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ¶ä½œäº†6æ£µå¤æ‚çš„æ ‘ï¼Œæ¯æ£µæ ‘éƒ½ä½¿ç”¨åŸå§‹æ•°æ®çš„è‡ªåŠ©é‡é‡‡æ ·è¿›è¡Œè®­ç»ƒï¼Œç„¶åå¹³å‡æ¯æ£µæ ‘çš„é¢„æµ‹ç»“æœã€‚
- en: the result is more smooth - lower model variance
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“æœæ›´åŠ å¹³æ»‘ - æ¨¡å‹æ–¹å·®æ›´ä½ã€‚
- en: the result more closely matches the training data
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“æœæ›´æ¥è¿‘è®­ç»ƒæ•°æ®
- en: Demonstration of Bagging with Increasing Number of Trees
  id: totrans-452
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¢åŠ æ ‘çš„æ•°é‡è¿›è¡Œè¢‹è£…æ¼”ç¤º
- en: For demonstration, letâ€™s build 6 bagging tree regression models with increasing
    number of overly complicated (and likely overfit) trees averaged.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¼”ç¤ºï¼Œè®©æˆ‘ä»¬æ„å»º6ä¸ªå…·æœ‰å¢åŠ æ•°é‡çš„è¿‡åº¦å¤æ‚ï¼ˆå¹¶ä¸”å¯èƒ½è¿‡æ‹Ÿåˆï¼‰æ ‘çš„è¢‹è£…æ ‘å›å½’æ¨¡å‹è¿›è¡Œå¹³å‡ã€‚
- en: with the bagging regressor from scikit learn this is automated with the â€˜num_treeâ€™
    hyperparameter
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨scikit learnçš„è¢‹è£…å›å½’å™¨ï¼Œè¿™å¯ä»¥é€šè¿‡â€˜num_treeâ€™è¶…å‚æ•°è‡ªåŠ¨å®Œæˆã€‚
- en: We will loop over the models and store each of them in an list of models again!
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†éå†æ¨¡å‹å¹¶å°†æ¯ä¸ªæ¨¡å‹å†æ¬¡å­˜å‚¨åœ¨ä¸€ä¸ªæ¨¡å‹åˆ—è¡¨ä¸­ï¼
- en: '[PRE22]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![_images/e9e7848dcfd2d82704e1e1d9b3907be8d850b9056a7478092436d1d3dd0376bb.png](../Images/349923f1fbb703de6e34e449aa5461aa.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/349923f1fbb703de6e34e449aa5461aa.png)'
- en: Observe the impact of averaging an increasing number of trees.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿå¹³å‡å¢åŠ æ ‘çš„æ•°é‡å¯¹å¹³å‡çš„å½±å“ã€‚
- en: we transition from a discontinuous response prediction model to a smooth prediction
    model (the jumps are smoothed out)
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»æ–­ç»­çš„å“åº”é¢„æµ‹æ¨¡å‹è¿‡æ¸¡åˆ°ä¸€ä¸ªå¹³æ»‘çš„é¢„æµ‹æ¨¡å‹ï¼ˆè·³è·ƒè¢«å¹³æ»‘å¤„ç†äº†ï¼‰
- en: Letâ€™s repeat the modeling cross validation step with the withheld testing data.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ä¿ç•™çš„æµ‹è¯•æ•°æ®é‡å¤å»ºæ¨¡äº¤å‰éªŒè¯æ­¥éª¤ã€‚
- en: '[PRE23]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![_images/897537eef68fdc77ecefa72c0cf2f943ddf6dd1f8cb70e99a54d498f9c901116.png](../Images/e9bf860174405c58ee5d3b39292d0e44.png)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/e9bf860174405c58ee5d3b39292d0e44.png)'
- en: See the improvement with testing accuracy with increasing level of ensemble
    model averaging?
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹çœ‹éšç€é›†æˆæ¨¡å‹å¹³å‡æ°´å¹³çš„å¢åŠ ï¼Œæµ‹è¯•ç²¾åº¦æ˜¯å¦æœ‰æ”¹è¿›ï¼Ÿ
- en: Letâ€™s run many cases and check the accuracy vs. number of trees.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œå¤šä¸ªæ¡ˆä¾‹å¹¶æ£€æŸ¥ç²¾åº¦ä¸æ ‘çš„æ•°é‡ä¹‹é—´çš„å…³ç³»ã€‚
- en: '[PRE24]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![_images/20cacfb6fdbc25ddeb7189cfe3d06ce924ab316613a2ab54a7cf162211ee6ca9.png](../Images/b32b7809d8b78abb96826fd4f0392d2b.png)'
  id: totrans-466
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/b32b7809d8b78abb96826fd4f0392d2b.png)'
- en: The number of trees improves model accuracy through reduction in model variance.
    Letâ€™s actually observe this reduction in model variance with an experiment.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‘çš„æ•°é‡é€šè¿‡å‡å°‘æ¨¡å‹æ–¹å·®æ¥æé«˜æ¨¡å‹ç²¾åº¦ã€‚è®©æˆ‘ä»¬é€šè¿‡å®éªŒå®é™…è§‚å¯Ÿæ¨¡å‹æ–¹å·®çš„è¿™ç§å‡å°‘ã€‚
- en: Model Variance vs. Ensemble Model Averaging
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®ä¸é›†æˆæ¨¡å‹å¹³å‡
- en: Letâ€™s see the change in model variance through model averaging, we will compare
    multiple models with different numbers of trees averaged.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹é€šè¿‡æ¨¡å‹å¹³å‡æ¨¡å‹æ–¹å·®çš„å˜åŒ–ï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒå…·æœ‰ä¸åŒæ ‘æ•°é‡å¹³å‡çš„å¤šä¸ªæ¨¡å‹ã€‚
- en: we accomplish this by visual comparison, letâ€™s look at different bagging modeling
    through changing the random number seed
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡æ”¹å˜éšæœºæ•°ç§å­æ¥é€šè¿‡è§†è§‰æ¯”è¾ƒä¸åŒçš„è¢‹è£…å»ºæ¨¡
- en: '[PRE25]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![_images/b98738c95478440ea08fddbeba7798bc726e6077288dbed59915ba84d147fdd9.png](../Images/d419947c372df1ff5fa41d90a33dde05.png)'
  id: totrans-472
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/d419947c372df1ff5fa41d90a33dde05.png)'
- en: 'As we increase the number of decision trees averaged for the bagged tree regression
    models:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æˆ‘ä»¬å¢åŠ ç”¨äºè¢‹è£…æ ‘å›å½’æ¨¡å‹çš„å¹³å‡å†³ç­–æ ‘çš„æ•°é‡ï¼š
- en: once again, the response predictions over the predictor feature space gets more
    smooth
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œå“åº”é¢„æµ‹åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šå˜å¾—æ›´åŠ å¹³æ»‘
- en: the multiple realizations of the model start to converge, this is lower model
    variance
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„å¤šæ¬¡å®ç°å¼€å§‹æ”¶æ•›ï¼Œè¿™æ˜¯è¾ƒä½çš„æ¨¡å‹æ–¹å·®
- en: Random Forest
  id: totrans-476
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—
- en: With random forest we limit the number of features considered for each split.
    Note, in scikit learn the default is \(\frac{m}{3}\). Use this hyperparameter
    to set to square root of the number of predictor features. Another common alternative
    in practice \(\sqrt{m}\).
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨éšæœºæ£®æ—ä¸­ï¼Œæˆ‘ä»¬é™åˆ¶äº†æ¯ä¸ªåˆ†å‰²è€ƒè™‘çš„ç‰¹å¾æ•°é‡ã€‚æ³¨æ„ï¼Œåœ¨scikit learnä¸­é»˜è®¤æ˜¯ \(\frac{m}{3}\)ã€‚ä½¿ç”¨æ­¤è¶…å‚æ•°å°†å…¶è®¾ç½®ä¸ºé¢„æµ‹ç‰¹å¾æ•°çš„å¹³æ–¹æ ¹ã€‚å®è·µä¸­å¦ä¸€ä¸ªå¸¸è§çš„æ›¿ä»£æ–¹æ¡ˆæ˜¯
    \(\sqrt{m}\)ã€‚
- en: '[PRE26]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This forces tree diversity / decorrelates the trees.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¿«ä½¿æ ‘å¤šæ ·æ€§/è§£ç›¸å…³æ ‘ã€‚
- en: recall the model variance reduced by averaging over multiple decision trees
    \(Y = \frac{1}{B} \sum_{b=1}^{B} Y^b(X_1^b,...,X_m^b)\)
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å¿†ä¸€ä¸‹ï¼Œé€šè¿‡å¹³å‡å¤šä¸ªå†³ç­–æ ‘æ¥å‡å°‘æ¨¡å‹æ–¹å·® \(Y = \frac{1}{B} \sum_{b=1}^{B} Y^b(X_1^b,...,X_m^b)\)
- en: recall from the [spatial bootstrap workflow](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/SubsurfaceDataAnalytics_Spatial_Bootstrap.ipynb)
    that correlation of samples being averaged attenuates the variance reduction
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»[ç©ºé—´è‡ªåŠ©å·¥ä½œæµç¨‹](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/SubsurfaceDataAnalytics_Spatial_Bootstrap.ipynb)ä¸­å›å¿†èµ·ï¼Œå¹³å‡æ ·æœ¬çš„ç›¸å…³æ€§ä¼šå‡å¼±æ–¹å·®å‡å°‘
- en: Letâ€™s experiment with random forest to demonstrate this.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡å®éªŒéšæœºæ£®æ—æ¥å±•ç¤ºè¿™ä¸€ç‚¹ã€‚
- en: Set the hyperparameters.
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®è¶…å‚æ•°ã€‚
- en: Even if I am just running one model, I set the random number seed to ensure
    I have a deterministic model, a model that can be rerun to get the same result
    every time. If the random number seed is not set, then it is likely set based
    on the system time.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æˆ‘åªè¿è¡Œä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä¹Ÿä¼šè®¾ç½®éšæœºæ•°ç§å­ä»¥ç¡®ä¿æˆ‘æœ‰ä¸€ä¸ªç¡®å®šæ€§çš„æ¨¡å‹ï¼Œä¸€ä¸ªæ¯æ¬¡é‡æ–°è¿è¡Œéƒ½èƒ½å¾—åˆ°ç›¸åŒç»“æœçš„æ¨¡å‹ã€‚å¦‚æœæœªè®¾ç½®éšæœºæ•°ç§å­ï¼Œåˆ™å®ƒå¾ˆå¯èƒ½æ˜¯åŸºäºç³»ç»Ÿæ—¶é—´è®¾ç½®çš„ã€‚
- en: '[PRE27]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We will overfit the trees, let them grow overly complicated. Once again, the
    ensemble approach will mitigate model variance and overfit.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿‡åº¦æ‹Ÿåˆæ ‘ï¼Œè®©å®ƒä»¬å˜å¾—è¿‡äºå¤æ‚ã€‚å†æ¬¡å¼ºè°ƒï¼Œé›†æˆæ–¹æ³•å°†å‡è½»æ¨¡å‹æ–¹å·®å’Œè¿‡åº¦æ‹Ÿåˆã€‚
- en: '[PRE28]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We will use a large number of trees to mitigate model variance and to benefit
    from random forest tree diversity.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨å¤§é‡æ ‘æ¥å‡è½»æ¨¡å‹æ–¹å·®å¹¶ä»éšæœºæ£®æ—æ ‘çš„å¤šæ ·æ€§ä¸­å—ç›Šã€‚
- en: '[PRE29]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We are using a simple 2 predictor feature example for ease of visualization.
    The default for scikit learnâ€™s random forest is to select \(\frac{m}{3}\) features
    at random for consideration for each split.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„2ä¸ªé¢„æµ‹ç‰¹å¾ç¤ºä¾‹æ¥ç®€åŒ–å¯è§†åŒ–ã€‚scikit learnçš„éšæœºæ£®æ—é»˜è®¤æƒ…å†µä¸‹æ˜¯éšæœºé€‰æ‹© \(\frac{m}{3}\) ä¸ªç‰¹å¾ä½œä¸ºæ¯ä¸ªåˆ†å‰²çš„è€ƒè™‘å› ç´ ã€‚
- en: This doesnâ€™t make much sense when \(m = 2\), as with our case, so we set the
    maximum number of features considered for each split to 1.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ \(m = 2\) æ—¶ï¼Œè¿™æ²¡æœ‰å¤ªå¤šæ„ä¹‰ï¼Œå› ä¸ºåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œæ‰€ä»¥æˆ‘ä»¬è®¾ç½®æ¯ä¸ªåˆ†å‰²è€ƒè™‘çš„æœ€å¤§ç‰¹å¾æ•°ä¸º1ã€‚
- en: We are forcing random selection of porosity or brittleness for consideration
    with each split, hierarchical binary segmentation.
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨å¼ºåˆ¶éšæœºé€‰æ‹©å­”éš™åº¦æˆ–è„†æ€§ä½œä¸ºæ¯ä¸ªåˆ†å‰²çš„è€ƒè™‘å› ç´ ï¼Œåˆ†å±‚äºŒè¿›åˆ¶åˆ†å‰²ã€‚
- en: '[PRE30]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Instantiate the random forest regressor with our hyperparameters
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æˆ‘ä»¬çš„è¶…å‚æ•°å®ä¾‹åŒ–éšæœºæ£®æ—å›å½’å™¨
- en: '[PRE31]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Train the random forest regression
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®­ç»ƒéšæœºæ£®æ—å›å½’
- en: '[PRE32]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Visualize the model result over the feature space (easy to do as we have only
    2 predictor features)
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ç‰¹å¾ç©ºé—´ä¸Šå¯è§†åŒ–æ¨¡å‹ç»“æœï¼ˆç”±äºæˆ‘ä»¬åªæœ‰2ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œè¿™å¾ˆå®¹æ˜“åšåˆ°ï¼‰
- en: Letâ€™s build, visualize and cross validate our first random forest regression
    model.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ„å»ºã€å¯è§†åŒ–å’Œäº¤å‰éªŒè¯æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªéšæœºæ£®æ—å›å½’æ¨¡å‹ã€‚
- en: '[PRE33]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![_images/95b5bfda652444fd962f82e48a68222434830f5645e78fb1598f64cd5a3e888e.png](../Images/87ab12ba6d0253a69f93da3499c21f86.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/87ab12ba6d0253a69f93da3499c21f86.png)'
- en: The power of tree diversity! We just built our best model so far.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‘çš„å¤šæ ·æ€§åŠ›é‡ï¼æˆ‘ä»¬åˆšåˆšæ„å»ºäº†è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„æ¨¡å‹ã€‚
- en: the conditional bias has decreased (our plot has a slope closer to 1:1)
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¡ä»¶åå·®å·²ç»é™ä½ï¼ˆæˆ‘ä»¬çš„å›¾æœ‰æ›´æ¥è¿‘1:1çš„æ–œç‡ï¼‰
- en: we have the lower out-of-bag mean score error
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰è¾ƒä½çš„è¢‹å¤–å¹³å‡åˆ†æ•°è¯¯å·®
- en: Letâ€™s run some tests to make sure we understand random forest regression model.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œä¸€äº›æµ‹è¯•ä»¥ç¡®ä¿æˆ‘ä»¬ç†è§£éšæœºæ£®æ—å›å½’æ¨¡å‹ã€‚
- en: First letâ€™s confirm that only one feature (at random) is considered for each
    split
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬ç¡®è®¤æ¯ä¸ªåˆ†å‰²åªè€ƒè™‘ä¸€ä¸ªç‰¹å¾ï¼ˆéšæœºé€‰æ‹©ï¼‰
- en: limit ourselves to maximum depth = 1, only one split
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™åˆ¶æœ€å¤§æ·±åº¦ä¸º1ï¼Œåªæœ‰ä¸€ä¸ªåˆ†å‰²
- en: limit ourselves to a single tree in each forest!
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªæ£®æ—ä¸­ä»…é™äºä¸€æ£µæ ‘ï¼
- en: This way we can see the diversity in the first splits over multiple models.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤šä¸ªæ¨¡å‹ä¸­ç¬¬ä¸€æ¬¡åˆ†å‰²çš„å¤šæ ·æ€§ã€‚
- en: '[PRE34]'
  id: totrans-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![_images/c161b87c59434bdd65f9831ab841ba71436cfc60c9e04fa4d5980bbfa7bd80c5.png](../Images/8f016e3c4f9adb7f07b4035f2e51c1e8.png)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/8f016e3c4f9adb7f07b4035f2e51c1e8.png)'
- en: Notice that the first splits are 50/50 porosity and brittleness.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæœ€åˆçš„åˆ†å‰²æ˜¯50/50çš„å­”éš™ç‡å’Œè„†æ€§ã€‚
- en: aside, for all decision trees that I have fit to this dataset, porosity is always
    the feature selected for the first 2-3 levels of the tree.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œå¯¹äºæˆ‘æ‹Ÿåˆåˆ°è¿™ä¸ªæ•°æ®é›†çš„æ‰€æœ‰å†³ç­–æ ‘ï¼Œå­”éš™ç‡æ€»æ˜¯è¢«é€‰ä¸ºæ ‘çš„å‰2-3å±‚ä¸­çš„ç‰¹å¾ã€‚
- en: the random forest has resulted in model diversity by limiting the predictor
    features under consideration for the first split!
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é™åˆ¶ç¬¬ä¸€æ¬¡åˆ†å‰²æ—¶è€ƒè™‘çš„é¢„æµ‹ç‰¹å¾ï¼Œéšæœºæ£®æ—å®ç°äº†æ¨¡å‹å¤šæ ·æ€§ï¼
- en: Just incase you donâ€™t trust this, letâ€™s rerun the above code with both predictors
    allowed for all splits.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸ä¿¡ä»»è¿™ä¸ªç»“æœï¼Œè®©æˆ‘ä»¬é‡æ–°è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œå…è®¸æ‰€æœ‰åˆ†å‰²éƒ½ä½¿ç”¨ä¸¤ä¸ªé¢„æµ‹å› å­ã€‚
- en: '[PRE35]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![_images/1b44bed65bdc0d762afa4706304f8c37a7f517a522d534c448aabf24ae1a9e9a.png](../Images/040c1daaa86a87e50c8d4df661597508.png)'
  id: totrans-517
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/040c1daaa86a87e50c8d4df661597508.png)'
- en: Now we have a set of first splits that vary (due to the bootstrap of the training
    data), but are all over porosity.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ç»„ç¬¬ä¸€æ¬¡åˆ†å‰²ï¼Œè¿™äº›åˆ†å‰²å› è®­ç»ƒæ•°æ®çš„è‡ªåŠ©æŠ½æ ·è€Œå˜åŒ–ï¼Œä½†éƒ½åœ¨å­”éš™ç‡ä¸Šã€‚
- en: Model Performance by Out-of-Bag and Feature Importance
  id: totrans-519
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¢‹å¤–å’Œç‰¹å¾é‡è¦æ€§çš„æ¨¡å‹æ€§èƒ½
- en: Since we are now building a more robust model with a large ensemble of trees,
    letâ€™s get more serious about model checking.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬ç°åœ¨æ­£åœ¨æ„å»ºä¸€ä¸ªç”±å¤§é‡æ ‘ç»„æˆçš„æ›´å¥å£®çš„æ¨¡å‹ï¼Œè®©æˆ‘ä»¬å¯¹æ¨¡å‹æ£€æŸ¥æ›´åŠ è®¤çœŸã€‚
- en: we will look at out-of-bag mean square error
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŸ¥çœ‹è¢‹å¤–å‡æ–¹è¯¯å·®ã€‚
- en: we will look at feature importance
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§ã€‚
- en: Letâ€™s start with a pretty big forest, this may take a while to run!
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªéå¸¸å¤§çš„æ£®æ—å¼€å§‹ï¼Œè¿™å¯èƒ½ä¼šè¿è¡Œä¸€æ®µæ—¶é—´ï¼
- en: '[PRE36]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![_images/735c2983e57fae5ab1825ca0a3a59ee1c45ab833f9d685009c96b01ecdc3728b.png](../Images/dc651fd9d250853ed0b993f26122923c.png)'
  id: totrans-525
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/dc651fd9d250853ed0b993f26122923c.png)'
- en: To get the feature importance we just have to access the model member â€˜feature_importance_â€™.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è·å–ç‰¹å¾é‡è¦æ€§ï¼Œæˆ‘ä»¬åªéœ€è®¿é—®æ¨¡å‹çš„â€˜feature_importance_â€™æˆå‘˜ã€‚
- en: we had to set feature_importance to true in the model instantiation for this
    to be available
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»åœ¨æ¨¡å‹å®ä¾‹åŒ–æ—¶å°†feature_importanceè®¾ç½®ä¸ºtrueæ‰èƒ½ä½¿å…¶å¯ç”¨
- en: this measure is standardized to sum to 1.0
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåº¦é‡æ ‡å‡†åŒ–ä¸ºæ€»å’Œä¸º1.0
- en: same order as the predictor features in the 2D array, porosity and then brittleness
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸2Dæ•°ç»„ä¸­é¢„æµ‹ç‰¹å¾ç›¸åŒçš„é¡ºåºï¼Œå­”éš™ç‡ç„¶åæ˜¯è„†æ€§
- en: feature importance is the proportion of total MSE reduction through splits for
    each feature
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é‡è¦æ€§æ˜¯æ¯ä¸ªç‰¹å¾é€šè¿‡åˆ†å‰²å¸¦æ¥çš„æ€»å‡æ–¹è¯¯å·®å‡å°‘çš„æ¯”ä¾‹ã€‚
- en: we can access the importance for each feature for each tree in the forest or
    the global average for each over the entire forest
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è®¿é—®æ£®æ—ä¸­æ¯æ£µæ ‘æ¯ä¸ªç‰¹å¾çš„é‡è¦æ€§ï¼Œæˆ–è€…åœ¨æ•´ä¸ªæ£®æ—ä¸­æ¯ä¸ªç‰¹å¾çš„å…¨çƒå¹³å‡å€¼ã€‚
- en: We get the global average of feature importance with this member of the random
    forest regressor model.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡è¿™ä¸ªéšæœºæ£®æ—å›å½’æ¨¡å‹æˆå‘˜è·å¾—ç‰¹å¾é‡è¦æ€§çš„å…¨å±€å¹³å‡å€¼ã€‚
- en: '[PRE37]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Letâ€™s plot the feature importance with significance calculated from the ensemble.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾ï¼Œå¹¶ä»é›†æˆä¸­è®¡ç®—æ˜¾è‘—æ€§ã€‚
- en: when we report model-based feature importance, it is always a good idea to show
    that the model is a good model. I like to show a model check beside the feature
    importance result, in this case the out-of-bag cross validation plot and mean
    square error.
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬æŠ¥å‘ŠåŸºäºæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§æ—¶ï¼Œæ€»æ˜¯å±•ç¤ºæ¨¡å‹æ˜¯ä¸€ä¸ªå¥½æ¨¡å‹æ˜¯ä¸ªå¥½ä¸»æ„ã€‚æˆ‘å–œæ¬¢åœ¨ç‰¹å¾é‡è¦æ€§ç»“æœæ—è¾¹å±•ç¤ºä¸€ä¸ªæ¨¡å‹æ£€æŸ¥ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯è¢‹å¤–äº¤å‰éªŒè¯å›¾å’Œå‡æ–¹è¯¯å·®ã€‚
- en: '[PRE38]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![_images/bfd529c0f34dd25a412354a45b90571b09239a3df8498d1354f217fdd4261c67.png](../Images/2c8c91f2d316367792438970dc37eac7.png)'
  id: totrans-537
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/2c8c91f2d316367792438970dc37eac7.png)'
- en: Letâ€™s try some hyperparameter training with the out-of-bag mean square error
    measure from our forest.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨æ£®æ—çš„è¢‹å¤–å‡æ–¹è¯¯å·®åº¦é‡è¿›è¡Œä¸€äº›è¶…å‚æ•°è®­ç»ƒã€‚
- en: Letâ€™s start with the number of trees in our forest.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æ£®æ—ä¸­çš„æ ‘çš„æ•°é‡å¼€å§‹ã€‚
- en: '[PRE39]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![_images/db70240c4201575375d6d14e35f366a22e45978000e8acabb77231b8d2d2b89f.png](../Images/b9b9a6c0574ef6e5325b02feabf44f82.png)'
  id: totrans-541
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/b9b9a6c0574ef6e5325b02feabf44f82.png)'
- en: Now letâ€™s try the depth of the trees, given enough trees (weâ€™ll use 60 trees)
    as determined above.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å°è¯•æ ‘çš„æ·±åº¦ï¼Œæ ¹æ®ä¸Šè¿°ç¡®å®šçš„è¶³å¤Ÿå¤šçš„æ ‘ï¼ˆæˆ‘ä»¬å°†ä½¿ç”¨60æ£µæ ‘ï¼‰ã€‚
- en: '[PRE40]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![_images/50da58b3e08eb8830bbeb48b559c70b77602e790fec0e4d361e547e0c74ffb4b.png](../Images/a8dc1e34abadac0b98b890891c53267e.png)'
  id: totrans-544
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/a8dc1e34abadac0b98b890891c53267e.png)'
- en: It looks like we need a maximum tree depth of at least 10 for best performance
    of our model with respect to out-of-bag mean square error.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥æˆ‘ä»¬éœ€è¦è‡³å°‘10çš„æœ€å¤§æ ‘æ·±åº¦æ‰èƒ½ä½¿æˆ‘ä»¬çš„æ¨¡å‹åœ¨è¢‹å¤–å‡æ–¹è¯¯å·®æ–¹é¢è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚
- en: note that our model is robust and resistant to overfit, the out-of-bag performance
    evaluation is close to monotonically increasing.
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å…·æœ‰é²æ£’æ€§ï¼Œä¸”å¯¹è¿‡æ‹Ÿåˆå…·æœ‰æŠµæŠ—åŠ›ï¼Œè¢‹å¤–æ€§èƒ½è¯„ä¼°æ¥è¿‘å•è°ƒé€’å¢ã€‚
- en: Machine Learning Pipelines for Clean, Compact Machine Learning Code
  id: totrans-547
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¸…æ´ã€ç´§å‡‘çš„æœºå™¨å­¦ä¹ ä»£ç çš„æœºå™¨å­¦ä¹ ç®¡é“
- en: Pipelines are a scikit-learn class that allows for the encapsulation of a sequence
    of data preparation and modeling steps
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡é“æ˜¯scikit-learnç±»ï¼Œå…è®¸å°è£…ä¸€ç³»åˆ—æ•°æ®å‡†å¤‡å’Œå»ºæ¨¡æ­¥éª¤
- en: then we can treat the pipeline as an object in our much condensed workflow
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†ç®¡é“è§†ä¸ºæˆ‘ä»¬é«˜åº¦ç®€åŒ–çš„å·¥ä½œæµç¨‹ä¸­çš„å¯¹è±¡
- en: 'The pipeline class allows us to:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡é“ç±»å…è®¸æˆ‘ä»¬ï¼š
- en: improve code readability and to keep everything straight
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜ä»£ç å¯è¯»æ€§å¹¶ä¿æŒä¸€åˆ‡äº•ç„¶æœ‰åº
- en: build complete workflows with very few lines of readable code
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨éå¸¸å°‘çš„å¯è¯»ä»£ç æ„å»ºå®Œæ•´çš„æµç¨‹
- en: avoid common workflow problems like data leakage, testing data informing model
    parameter training
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…å¸¸è§çš„æµç¨‹é—®é¢˜ï¼Œå¦‚æ•°æ®æ³„éœ²ã€æµ‹è¯•æ•°æ®å‘ŠçŸ¥æ¨¡å‹å‚æ•°è®­ç»ƒ
- en: abstract common machine learning modeling and focus on building the best model
    possible
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŠ½è±¡å¸¸è§çš„æœºå™¨å­¦ä¹ å»ºæ¨¡ï¼Œä¸“æ³¨äºæ„å»ºå°½å¯èƒ½å¥½çš„æ¨¡å‹
- en: The fundamental philosophy is to treat machine learning as a combinatorial search
    to find the best model (AutoML)
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬å“²å­¦æ˜¯å°†æœºå™¨å­¦ä¹ è§†ä¸ºç»„åˆæœç´¢ä»¥æ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼ˆAutoMLï¼‰
- en: For more information see my recorded lecture on [Machine Learning Pipelines](https://www.youtube.com/watch?v=tYrPs8s1l9U&list=PLG19vXLQHvSAufDFgZEFAYQEwMJXklnQV&index=5)
    and a well-documented demonstration [Machine Learning Pipeline Workflow](http://localhost:8892/notebooks/OneDrive%20-%20The%20University%20of%20Texas%20at%20Austin/Courses/Workflows/PythonDataBasics_Pipelines.ipynb).
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šä¿¡æ¯è¯·å‚é˜…æˆ‘å…³äº[æœºå™¨å­¦ä¹ ç®¡é“](https://www.youtube.com/watch?v=tYrPs8s1l9U&list=PLG19vXLQHvSAufDFgZEFAYQEwMJXklnQV&index=5)çš„å½•éŸ³è®²åº§å’Œè¯¦ç»†è®°å½•çš„æ¼”ç¤º[æœºå™¨å­¦ä¹ ç®¡é“å·¥ä½œæµç¨‹](http://localhost:8892/notebooks/OneDrive%20-%20The%20University%20of%20Texas%20at%20Austin/Courses/Workflows/PythonDataBasics_Pipelines.ipynb)ã€‚
- en: '[PRE41]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Practice on a New Dataset
  id: totrans-559
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨æ–°çš„æ•°æ®é›†ä¸Šè¿›è¡Œå®è·µ
- en: Ok, time to get to work. Letâ€™s load up a dataset and build a random forest prediction
    model with,
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæ˜¯æ—¶å€™å¼€å§‹å·¥ä½œäº†ã€‚è®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªæ•°æ®é›†å¹¶ä½¿ç”¨éšæœºæ£®æ—é¢„æµ‹æ¨¡å‹ï¼Œ
- en: compact code
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç´§å‡‘çš„ä»£ç 
- en: basic visaulizations
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºæœ¬å¯è§†åŒ–
- en: save the output
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜è¾“å‡º
- en: You can select any of these datasets or modify the code and add your own to
    do this.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€‰æ‹©è¿™äº›æ•°æ®é›†ä¹‹ä¸€ï¼Œæˆ–ä¿®æ”¹ä»£ç å¹¶æ·»åŠ æ‚¨è‡ªå·±çš„æ•°æ®é›†æ¥å®Œæˆæ­¤æ“ä½œã€‚
- en: Dataset 0, Unconventional Multivariate v4
  id: totrans-565
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®é›†0ï¼Œéå¸¸è§„å¤šå…ƒå˜é‡v4
- en: 'Letâ€™s load the provided multivariate, dataset [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv).
    This dataset has variables from 1,000 unconventional wells including:'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒæ•°æ®é›†[unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv)ã€‚æ­¤æ•°æ®é›†åŒ…å«1,000å£éå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š
- en: well average porosity
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•å¹³å‡å­”éš™ç‡
- en: log transform of permeability (to linearize the relationships with other variables)
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡çš„å¯¹æ•°å˜æ¢ï¼ˆä»¥çº¿æ€§åŒ–ä¸å…¶ä»–å˜é‡çš„å…³ç³»ï¼‰
- en: acoustic impedance (kg/m^3 x m/s x 10^6)
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ—ï¼ˆkg/m^3 x m/s x 10^6ï¼‰
- en: brittleness ratio (%)
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡æ¯”ï¼ˆ%ï¼‰
- en: total organic carbon (%)
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€»æœ‰æœºç¢³ï¼ˆ%ï¼‰
- en: vitrinite reflectance (%)
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»ç’ƒè´¨åå°„ç‡ï¼ˆ%ï¼‰
- en: initial production 90 day average (MCFPD).
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆå§‹ç”Ÿäº§90å¤©å¹³å‡ï¼ˆMCFPDï¼‰ã€‚
- en: Dataset 2, Reservoir 21
  id: totrans-574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®é›†2ï¼Œå‚¨å±‚21
- en: 'Letâ€™s load the provided multivariate, 3D spatial dataset [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv).
    This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50
    m reservoir unit:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€3Dç©ºé—´æ•°æ®é›†[res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv)ã€‚æ­¤æ•°æ®é›†åŒ…å«æ¥è‡ª10,000m
    x 10,000m x 50 må‚¨å±‚å•å…ƒçš„73å£å‚ç›´äº•çš„å˜é‡ï¼š
- en: well (ID)
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•ï¼ˆIDï¼‰
- en: X (m), Y (m), Depth (m) location coordinates
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xï¼ˆmï¼‰ï¼ŒYï¼ˆmï¼‰ï¼Œæ·±åº¦ï¼ˆmï¼‰ä½ç½®åæ ‡
- en: Porosity (%) after units conversion
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä½è½¬æ¢åçš„å­”éš™ç‡ï¼ˆ%ï¼‰
- en: Permeability (mD)
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡ï¼ˆmDï¼‰
- en: Acoustic Impedance (kg/m2s*10^6) after units conversion
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä½è½¬æ¢åçš„å£°é˜»æŠ—ï¼ˆkg/m2s*10^6ï¼‰
- en: Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley
    Sand, to Sandstone.
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸ï¼ˆåˆ†ç±»ï¼‰- ä»é¡µå²©ã€ç ‚è´¨é¡µå²©ã€é¡µå²©ç ‚åˆ°ç ‚å²©çš„é¡ºåºã€‚
- en: Density (g/cm^3)
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯†åº¦ï¼ˆg/cm^3ï¼‰
- en: Compressible velocity (m/s)
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯å‹ç¼©é€Ÿåº¦ï¼ˆm/sï¼‰
- en: Youngs modulus (GPa)
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨æ°æ¨¡é‡ï¼ˆGPaï¼‰
- en: Shear velocity (m/s)
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡é€Ÿåº¦ï¼ˆm/sï¼‰
- en: Shear modulus (GPa)
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡æ¨¡é‡ï¼ˆGPaï¼‰
- en: 3 year cumulative oil production (Mbbl)
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3å¹´ç´¯è®¡çŸ³æ²¹äº§é‡ï¼ˆç™¾ä¸‡æ¡¶ï¼‰
- en: We load the tabular data with the pandas â€˜read_csvâ€™ function into a DataFrame
    we called â€˜my_dataâ€™ and then preview it to make sure it loaded correctly.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨pandasçš„â€˜read_csvâ€™å‡½æ•°å°†è¡¨æ ¼æ•°æ®åŠ è½½åˆ°æˆ‘ä»¬ç§°ä¸ºâ€˜my_dataâ€™çš„DataFrameä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚
- en: we also populate lists with data ranges and labels for ease of plotting
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹Ÿç”¨æ•°æ®èŒƒå›´å’Œæ ‡ç­¾å¡«å……åˆ—è¡¨ï¼Œä»¥ä¾¿äºç»˜å›¾
- en: Load and format the data,
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®å¹¶æ ¼å¼åŒ–ï¼Œ
- en: drop the response feature
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ é™¤å“åº”ç‰¹å¾
- en: reformate the features as needed
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®éœ€è¦é‡æ–°æ ¼å¼åŒ–ç‰¹å¾
- en: also, I like to store the metadata in lists
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä¹Ÿå–œæ¬¢å°†å…ƒæ•°æ®å­˜å‚¨åœ¨åˆ—è¡¨ä¸­
- en: '[PRE43]'
  id: totrans-594
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '|  | Por | Perm | AI | Brittle | TOC | VR | Prod |'
  id: totrans-595
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Perm | AI | Brittle | TOC | VR | Prod |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-596
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |'
  id: totrans-597
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |'
- en: '| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |'
  id: totrans-598
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |'
- en: '| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |'
  id: totrans-599
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |'
- en: '| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |'
  id: totrans-600
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |'
- en: '| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |'
  id: totrans-601
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |'
- en: '| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |'
- en: '| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |'
- en: '| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |'
- en: '| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |'
- en: '| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |'
- en: '| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |'
  id: totrans-607
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |'
- en: '| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |'
  id: totrans-608
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |'
- en: '| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |'
  id: totrans-609
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |'
- en: Build and Check Model
  id: totrans-610
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ„å»ºå’Œæ£€æŸ¥æ¨¡å‹
- en: We apply the follow steps,
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”ç”¨ä»¥ä¸‹æ­¥éª¤ï¼Œ
- en: specify the K-fold method
  id: totrans-612
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å®šKæŠ˜æ³•
- en: loop over number of leaf nodes, instantiate, fit and record the error
  id: totrans-613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éå†å¶èŠ‚ç‚¹æ•°ï¼Œå®ä¾‹åŒ–ã€æ‹Ÿåˆå¹¶è®°å½•é”™è¯¯
- en: plot the test error vs. number of leaf nodes, select the hyperparameter that
    minimizes test error
  id: totrans-614
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æµ‹è¯•è¯¯å·®ä¸å¶èŠ‚ç‚¹æ•°çš„å…³ç³»å›¾ï¼Œé€‰æ‹©æœ€å°åŒ–æµ‹è¯•è¯¯å·®çš„è¶…å‚æ•°
- en: retrain the model with the tuned hyperparameter and all of the data
  id: totrans-615
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è°ƒæ•´å¥½çš„è¶…å‚æ•°å’Œæ‰€æœ‰æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹
- en: '[PRE44]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![_images/447cb9297891445a4687987aa0d2d5d1a7bc5f5ea046a61c2ddd9590e8c8d9dc.png](../Images/4541279cae3ac88f62404f70b893beda.png)'
  id: totrans-617
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/4541279cae3ac88f62404f70b893beda.png)'
- en: Comments
  id: totrans-618
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„è®º
- en: I hope you found this chapter helpful. Much more could be done and discussed,
    I have many more resources. Check out my [shared resource inventory](https://michaelpyrcz.com/my-resources),
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æ‚¨è§‰å¾—è¿™ä¸€ç« æœ‰ç”¨ã€‚è¿˜æœ‰å¾ˆå¤šå¯ä»¥åšçš„å’Œè®¨è®ºçš„ï¼Œæˆ‘æœ‰å¾ˆå¤šæ›´å¤šçš„èµ„æºã€‚æŸ¥çœ‹æˆ‘çš„[å…±äº«èµ„æºæ¸…å•](https://michaelpyrcz.com/my-resources)ï¼Œ
- en: '*Michael*'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: About the Author
  id: totrans-621
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºä½œè€…
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  id: totrans-622
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”å¥‡æ•™æˆåœ¨å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡40è‹±äº©æ ¡å›­çš„åŠå…¬å®¤ã€‚
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”å¥‡ï¼ˆMichael Pyrczï¼‰æ˜¯å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡[Cockrellå·¥ç¨‹å­¦é™¢](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)å’Œ[æ°å…‹é€Šåœ°çƒç§‘å­¦å­¦é™¢](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)çš„æ•™æˆï¼Œä»–åœ¨[å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡](https://www.utexas.edu/)ä»äº‹å’Œæ•™æˆåœ°ä¸‹ã€ç©ºé—´æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ã€‚è¿ˆå…‹å°”è¿˜æ˜¯ï¼Œ
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[èƒ½æºåˆ†æ](https://fri.cns.utexas.edu/energy-analytics)æ–°ç”Ÿç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œä»¥åŠå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡è‡ªç„¶ç§‘å­¦å­¦é™¢æœºå™¨å­¦ä¹ å®éªŒå®¤çš„æ ¸å¿ƒæ•™å‘˜'
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ã€Šè®¡ç®—æœºä¸åœ°è´¨å­¦ã€‹](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)çš„å‰¯ç¼–è¾‘ï¼Œä»¥åŠå›½é™…æ•°å­¦åœ°è´¨å­¦åä¼š[ã€Šæ•°å­¦åœ°è´¨å­¦ã€‹](https://link.springer.com/journal/11004/editorial-board)çš„è‘£äº‹ä¼šæˆå‘˜ã€‚'
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”å·²ç»æ’°å†™äº†70å¤šç¯‡[åŒè¡Œè¯„å®¡çš„å‡ºç‰ˆç‰©](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)ï¼Œä¸€ä¸ªç”¨äºç©ºé—´æ•°æ®åˆ†æçš„[PythonåŒ…](https://pypi.org/project/geostatspy/)ï¼Œåˆè‘—äº†ä¸€æœ¬å…³äºç©ºé—´æ•°æ®åˆ†æçš„æ•™ç§‘ä¹¦ã€Š[åœ°è´¨ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)ã€‹ï¼Œå¹¶æ˜¯ä¸¤æœ¬æœ€è¿‘å‘å¸ƒçš„ç”µå­ä¹¦çš„ä½œè€…ï¼Œåˆ†åˆ«æ˜¯ã€Š[Pythonä¸­çš„åº”ç”¨åœ°è´¨ç»Ÿè®¡å­¦ï¼šGeostatsPyå®è·µæŒ‡å—](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)ã€‹å’Œã€Š[Pythonä¸­çš„åº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„å®è·µæŒ‡å—](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)ã€‹ã€‚
- en: All of Michaelâ€™s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michaelâ€™s work and shared educational resources visit his
    Website.
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”çš„æ‰€æœ‰å¤§å­¦è®²åº§éƒ½å¯ä»¥åœ¨ä»–çš„[YouTubeé¢‘é“](https://www.youtube.com/@GeostatsGuyLectures)ä¸Šæ‰¾åˆ°ï¼Œé™„æœ‰100å¤šä¸ªPythonäº¤äº’å¼ä»ªè¡¨æ¿å’Œ40å¤šä¸ªå­˜å‚¨åº“ä¸­çš„è¯¦ç»†è®°å½•çš„å·¥ä½œæµç¨‹ï¼Œè¿™äº›å­˜å‚¨åº“åœ¨ä»–çš„[GitHubè´¦æˆ·](https://github.com/GeostatsGuy)ä¸Šï¼Œä»¥æ”¯æŒä»»ä½•æ„Ÿå…´è¶£çš„å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«ï¼Œæä¾›æŒç»­æ›´æ–°çš„å†…å®¹ã€‚è¦äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„å·¥ä½œå’Œå…±äº«æ•™è‚²èµ„æºï¼Œè¯·è®¿é—®ä»–çš„ç½‘ç«™ã€‚
- en: Want to Work Together?
  id: totrans-629
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›è¿™ä¸ªå†…å®¹å¯¹é‚£äº›æƒ³äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æå’Œå­¦ä¹ æœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«éƒ½æ¬¢è¿å‚åŠ ã€‚
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£åˆä½œã€æ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººæ˜¯çº¦ç¿°Â·ç¦æ–¯ç‰¹æ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶å°†æ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µç›¸ç»“åˆï¼Œä»¥å¼€å‘æ–°çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ï¼Œå¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)è”ç³»æˆ‘ã€‚
- en: Iâ€™m always happy to discuss,
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è¿›è¡Œè®¨è®ºï¼Œ
- en: '*Michael*'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨ï¼Œåšå£«ï¼ŒP.Eng. æ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡Cockrellå·¥ç¨‹å­¦é™¢å’ŒJacksonåœ°çƒç§‘å­¦å­¦é™¢
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šèµ„æºè¯·è®¿é—®ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
- en: Motivations for Bagging and Random Forest
  id: totrans-638
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¢‹è£…å’Œéšæœºæ£®æ—çš„åŠ¨æœº
- en: Decision tree are not the most powerful, cutting edge method in machine learning,
    but,
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘ä¸æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¼ºå¤§ã€æœ€å‰æ²¿çš„æ–¹æ³•ï¼Œä½†ï¼Œ
- en: one of the most understandable, interpretable predictive machine learning modeling
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€æ˜“äºç†è§£ã€å¯è§£é‡Šçš„é¢„æµ‹æœºå™¨å­¦ä¹ å»ºæ¨¡ä¹‹ä¸€
- en: '![](../Images/e66b56981b9ff607c82a7fbfc116ccb1.png)'
  id: totrans-641
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/e66b56981b9ff607c82a7fbfc116ccb1.png)'
- en: Solitary black spruce tree in Hinton, Alberta, Canada, image from https://hikebiketravel.com/6-fun-things-to-do-in-hinton-alberta-in-winter.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ æ‹¿å¤§è‰¾ä¼¯å¡”çœHintonçš„ä¸€æ£µå­¤ç‹¬çš„é»‘äº‘æ‰æ ‘ï¼Œå›¾ç‰‡æ¥è‡ª https://hikebiketravel.com/6-fun-things-to-do-in-hinton-alberta-in-winterã€‚
- en: decision trees are enhanced with random forests, bagging and boosting to be
    one of the best models in many cases
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†³ç­–æ ‘é€šè¿‡éšæœºæ£®æ—ã€è¢‹è£…å’Œæå‡æˆä¸ºè®¸å¤šæƒ…å†µä¸‹çš„æœ€ä½³æ¨¡å‹ä¹‹ä¸€
- en: '![](../Images/ca4872f08f83736f351592c849901c2b.png)'
  id: totrans-644
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/ca4872f08f83736f351592c849901c2b.png)'
- en: Black spruce forest near Hinton, Alberta, east of Jasper National Park, Canada,
    image from https://en.wikivoyage.org/wiki/Hinton.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ æ‹¿å¤§è‰¾ä¼¯å¡”çœHintoné™„è¿‘çš„é»‘äº‘æ‰æ£®æ—ï¼Œå›¾ç‰‡æ¥è‡ª https://en.wikivoyage.org/wiki/Hintonã€‚
- en: Now we cover ensemble trees, tree bagging and random forest building on decision
    trees. First, I provide some prerequisite concepts for decision trees and then
    for ensemble methods.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ¥ä»‹ç»åŸºäºå†³ç­–æ ‘çš„é›†æˆæ ‘ã€æ ‘è¢‹å’Œéšæœºæ£®æ—ã€‚é¦–å…ˆï¼Œæˆ‘æä¾›ä¸€äº›å†³ç­–æ ‘å’Œé›†æˆæ–¹æ³•çš„å‰ææ¦‚å¿µã€‚
- en: if you are not familiar with decision trees it may be a good idea to review
    the [Decision Tree Chapter](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_decision_tree.html).
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸å¤ªç†Ÿæ‚‰å†³ç­–æ ‘ï¼Œå›é¡¾ä¸€ä¸‹[å†³ç­–æ ‘ç« èŠ‚](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_decision_tree.html)å¯èƒ½æ˜¯ä¸ªå¥½ä¸»æ„ã€‚
- en: Tree Model Formulation
  id: totrans-648
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‘æ¨¡å‹å…¬å¼
- en: 'The prediction feature space is partitioned into \(J\) exhaustive, mutually
    exclusive regions \(R_1, R_2, \ldots, R_J\). For a given prediction case \(x_1,\ldots,x_m
    \in R_j\), the prediction is:'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ç©ºé—´è¢«åˆ’åˆ†ä¸º \(J\) ä¸ªäº’æ–¥çš„ç©·å°½åŒºåŸŸ \(R_1, R_2, \ldots, R_J\)ã€‚å¯¹äºç»™å®šçš„é¢„æµ‹æ¡ˆä¾‹ \(x_1,\ldots,x_m
    \in R_j\)ï¼Œé¢„æµ‹å¦‚ä¸‹ï¼š
- en: '**Regression** - the average of the training data in the region, \(R_j\)'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›å½’** - åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ•°æ®çš„å¹³å‡å€¼'
- en: \[ \hat{y} = \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} y_i \]
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} y_i \]
- en: where \(\hat{y}\) is the predicted value for input \(\mathbf{x}\), \(R_j\) is
    the region (leaf node) that \(\mathbf{x}\) falls into, \(|R_j|\) is the number
    of training samples in region \(R_j\), and \(y_i\) is the actual target values
    of those training samples in \(R_j\).
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\hat{y}\) æ˜¯è¾“å…¥ \(\mathbf{x}\) çš„é¢„æµ‹å€¼ï¼Œ\(R_j\) æ˜¯ \(\mathbf{x}\) è½å…¥çš„åŒºåŸŸï¼ˆå¶èŠ‚ç‚¹ï¼‰ï¼Œ\(|R_j|\)
    æ˜¯åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ ·æœ¬çš„æ•°é‡ï¼Œ\(y_i\) æ˜¯ \(R_j\) ä¸­é‚£äº›è®­ç»ƒæ ·æœ¬çš„å®é™…ç›®æ ‡å€¼ã€‚
- en: '**Classification** - category with the plurality of training cases (most common
    case) in region \(R_j\):'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»** - åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ¡ˆä¾‹æ•°é‡æœ€å¤šçš„ç±»åˆ«ï¼ˆæœ€å¸¸è§çš„æƒ…å†µï¼‰ï¼š'
- en: \[ \hat{y} = \arg\max_{c \in C} \left( \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in
    R_j} \mathbb{1}(y_i = c) \right) \]
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \arg\max_{c \in C} \left( \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in
    R_j} \mathbb{1}(y_i = c) \right) \]
- en: where \(C\) is the set of all possible categories, \(\mathbb{1}(y_i = c)\) is
    indicator transform, 1 if \(y_i = c\), 0 otherwise, \(|R_j|\) is the number of
    training samples in region \(R_j\), and \(\hat{y}\) is the predicted class label.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(C\) æ˜¯æ‰€æœ‰å¯èƒ½ç±»åˆ«çš„é›†åˆï¼Œ\(\mathbb{1}(y_i = c)\) æ˜¯æŒ‡ç¤ºå˜æ¢ï¼Œå¦‚æœ \(y_i = c\) åˆ™ä¸º 1ï¼Œå¦åˆ™ä¸º 0ï¼Œ\(|R_j|\)
    æ˜¯åŒºåŸŸ \(R_j\) ä¸­è®­ç»ƒæ ·æœ¬çš„æ•°é‡ï¼Œ\(\hat{y}\) æ˜¯é¢„æµ‹çš„ç±»åˆ«æ ‡ç­¾ã€‚
- en: The predictor space, \(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\), is segmented into \(J\) mutually exclusive,
    exhaustive regions, \(R_j, j = 1,\ldots,J\), where the regions are,
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç©ºé—´ï¼Œ\(ğ‘‹_1,\ldots,ğ‘‹_ğ‘š\)ï¼Œè¢«åˆ†å‰²æˆ \(J\) ä¸ªäº’æ–¥ã€ç©·å°½çš„åŒºåŸŸï¼Œ\(R_j, j = 1,\ldots,J\)ï¼Œå…¶ä¸­åŒºåŸŸä¸ºï¼Œ
- en: '**mutually exclusive** â€“ any combination of predictor features, \(x_1,\ldots,x_ğ‘š\),
    only belongs to a single region, \(R_j\)'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**äº’æ–¥** â€“ ä»»ä½•é¢„æµ‹ç‰¹å¾ç»„åˆï¼Œ\(x_1,\ldots,x_ğ‘š\)ï¼Œåªå±äºä¸€ä¸ªå•ä¸€åŒºåŸŸï¼Œ\(R_j\)'
- en: '**exhaustive** â€“ all combinations of predictor feature values belong a region,
    \(R_j\), i.e., all the regions, \(R_j, j = 1,\ldots,J\), cover entire predictor
    feature space'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç©·å°½** â€“ æ‰€æœ‰é¢„æµ‹ç‰¹å¾å€¼çš„ç»„åˆå±äºä¸€ä¸ªåŒºåŸŸï¼Œ\(R_j\)ï¼Œå³æ‰€æœ‰åŒºåŸŸï¼Œ\(R_j, j = 1,\ldots,J\)ï¼Œè¦†ç›–æ•´ä¸ªé¢„æµ‹ç‰¹å¾ç©ºé—´'
- en: All prediction cases, \(x_1,\ldots,x_m\) that fall in the same region, \(R_j\),
    are estimated with the same value.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è½åœ¨åŒä¸€åŒºåŸŸï¼Œ\(R_j\)ï¼Œçš„é¢„æµ‹æ¡ˆä¾‹ï¼Œ\(x_1,\ldots,x_m\)ï¼Œéƒ½ä½¿ç”¨ç›¸åŒçš„å€¼è¿›è¡Œä¼°è®¡ã€‚
- en: the prediction model inherently discontinuous at the region boundaries
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹æ¨¡å‹åœ¨åŒºåŸŸè¾¹ç•Œå¤„æœ¬è´¨ä¸Šæ˜¯ä¸è¿ç»­çš„
- en: For example, consider this decision tree prediction model for the production
    response feature, \(\hat{Y}\)Â Ì‚from porosity, \(X_1\), predictor feature,
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè€ƒè™‘è¿™ä¸ªå†³ç­–æ ‘é¢„æµ‹æ¨¡å‹ï¼Œä»å­”éš™ç‡ï¼Œ\(X_1\)ï¼Œé¢„æµ‹ç‰¹å¾ï¼Œ
- en: '![](../Images/98d8fb73fe41299a6a9b443163b47c96.png)'
  id: totrans-662
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98d8fb73fe41299a6a9b443163b47c96.png)'
- en: Four region decision tree with data and predictions, \(\hat{Y}(R_j) = \overline{Y}(R_j)\)
    by region, \(R_j, j=1,â€¦,4\). For example, given a predictor feature value of 13%
    porosity, the model predicts about 2,000 MCFPD for production.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: å››ä¸ªåŒºåŸŸå†³ç­–æ ‘ä¸æ•°æ®å’Œé¢„æµ‹ï¼Œ\(\hat{Y}(R_j) = \overline{Y}(R_j)\) æŒ‰åŒºåŸŸï¼Œ\(R_j, j=1,â€¦,4\)ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªé¢„æµ‹ç‰¹å¾å€¼ä¸º
    13% å­”éš™ç‡çš„å€¼ï¼Œæ¨¡å‹é¢„æµ‹ç”Ÿäº§å¤§çº¦ 2,000 MCFPDã€‚
- en: How do we segment the predictor feature space?
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•å¯¹é¢„æµ‹ç‰¹å¾ç©ºé—´è¿›è¡Œåˆ†å‰²ï¼Ÿ
- en: the set of regions based on hierarchical, binary segmentation.
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºåˆ†å±‚ã€äºŒè¿›åˆ¶åˆ†å‰²çš„åŒºåŸŸé›†ã€‚
- en: Tree Loss Functions
  id: totrans-666
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‘æŸå¤±å‡½æ•°
- en: For regression trees we minimize the residual sum of squares and for classification
    trees we minimize the weighted average Gini impurity.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå›å½’æ ‘ï¼Œæˆ‘ä»¬æœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œï¼Œå¯¹äºåˆ†ç±»æ ‘ï¼Œæˆ‘ä»¬æœ€å°åŒ–åŠ æƒå¹³å‡åŸºå°¼ä¸çº¯åº¦ã€‚
- en: The Residual Sum of Squares (RSS) measures the total squared difference between
    the actual values and predicted values in a regression tree,
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä½™å¹³æ–¹å’Œï¼ˆRSSï¼‰è¡¡é‡å›å½’æ ‘ä¸­å®é™…å€¼ä¸é¢„æµ‹å€¼ä¹‹é—´æ€»å¹³æ–¹å·®çš„åº¦é‡ï¼Œ
- en: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
- en: where \(J\) is the total number of regions in the tree, \(R_j\) is the \(j\)
    region, \(y_i\) is the truth value of the response feature at observation the
    \(i\) training data, and \(\hat{y}_{R_j}\) is the predicted value for region \(R_j\),
    the mean of \(y_i \; \forall \; i \in R_j\).
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(J\) æ˜¯æ ‘ä¸­çš„åŒºåŸŸæ€»æ•°ï¼Œ\(R_j\) æ˜¯ç¬¬ \(j\) ä¸ªåŒºåŸŸï¼Œ\(y_i\) æ˜¯ç¬¬ \(i\) ä¸ªè®­ç»ƒæ•°æ®å“åº”ç‰¹å¾çš„çœŸå€¼ï¼Œ\(\hat{y}_{R_j}\)
    æ˜¯åŒºåŸŸ \(R_j\) çš„é¢„æµ‹å€¼ï¼Œ\(y_i \; \forall \; i \in R_j\) çš„å¹³å‡å€¼ã€‚
- en: 'When a parent node splits into two child nodes ( t_L ) and ( t_R ), the weighted
    Gini impurity is:'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸€ä¸ªçˆ¶èŠ‚ç‚¹åˆ†è£‚æˆä¸¤ä¸ªå­èŠ‚ç‚¹ï¼ˆt_Lï¼‰å’Œï¼ˆt_Rï¼‰æ—¶ï¼ŒåŠ æƒåŸºå°¼ä¸çº¯åº¦ä¸ºï¼š
- en: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
- en: where \(J\) is the total number of regions in the tree, \(N\) is the total number
    of samples in the dataset, \(N_j\) is the number of samples in leaf node \(j\),
    and \(\text{Gini}(j)\) is the Gini impurity of leaf node \(j\).
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(J\) æ˜¯æ ‘ä¸­çš„åŒºåŸŸæ€»æ•°ï¼Œ\(N\) æ˜¯æ•°æ®é›†ä¸­çš„æ ·æœ¬æ€»æ•°ï¼Œ\(N_j\) æ˜¯å¶èŠ‚ç‚¹ \(j\) ä¸­çš„æ ·æœ¬æ•°ï¼Œ\(\text{Gini}(j)\)
    æ˜¯å¶èŠ‚ç‚¹ \(j\) çš„åŸºå°¼ä¸çº¯åº¦ã€‚
- en: The Gini impurity for a single decision tree node is calculated as,
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä¸ªå†³ç­–æ ‘èŠ‚ç‚¹çš„åŸºå°¼ä¸çº¯åº¦è®¡ç®—å¦‚ä¸‹ï¼Œ
- en: \[ \text{Gini}(j) = 1 - \sum_{c=1}^{C} p_{j,c}^2 \]
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Gini}(j) = 1 - \sum_{c=1}^{C} p_{j,c}^2 \]
- en: where \(p_{j,c}\) is the proportion of class \(c\) samples in node \(j\).
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(p_{j,c}\) æ˜¯èŠ‚ç‚¹ \(j\) ä¸­ç±»åˆ« \(c\) æ ·æœ¬çš„æ¯”ä¾‹ã€‚
- en: For classification our loss function does not compare the predictions to the
    truth values like our regression loss!
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåˆ†ç±»ï¼Œæˆ‘ä»¬çš„æŸå¤±å‡½æ•°ä¸æ¯”è¾ƒé¢„æµ‹å€¼ä¸çœŸå€¼ï¼Œå°±åƒæˆ‘ä»¬çš„å›å½’æŸå¤±ä¸€æ ·ï¼
- en: the Gini impurity penalizes mixtures of training data categories! A region of
    all one category of training data will have a Gini impurity of 0 to contribute
    to the over all loss.
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºå°¼ä¸çº¯åº¦æƒ©ç½šè®­ç»ƒæ•°æ®ç±»åˆ«æ··åˆï¼æ‰€æœ‰å•ä¸€ç±»åˆ«è®­ç»ƒæ•°æ®çš„åŒºåŸŸå°†å…·æœ‰åŸºå°¼ä¸çº¯åº¦ä¸º 0ï¼Œä»¥è´¡çŒ®æ•´ä½“æŸå¤±ã€‚
- en: Note that the by-region Gini impurity is,
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼ŒæŒ‰åŒºåŸŸè®¡ç®—çš„åŸºå°¼ä¸çº¯åº¦ä¸ºï¼Œ
- en: '**weighted** - by the number of training data in each regions, regions with
    more training data have greater impact on the overall loss'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŠ æƒ** â€“ æ¯ä¸ªåŒºåŸŸçš„è®­ç»ƒæ•°æ®æ•°é‡ï¼Œå…·æœ‰æ›´å¤šè®­ç»ƒæ•°æ®çš„åŒºåŸŸå¯¹æ•´ä½“æŸå¤±æœ‰æ›´å¤§çš„å½±å“'
- en: '**averaged** - over all the regions to calculate the total Gini impurity of
    the decision tree'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¹³å‡** - æ‰€æœ‰åŒºåŸŸä»¥è®¡ç®—å†³ç­–æ ‘çš„æ€»åŸºå°¼ä¸çº¯åº¦'
- en: These losses are calculated during,
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æŸå¤±åœ¨ä»¥ä¸‹è¿‡ç¨‹ä¸­è®¡ç®—ï¼Œ
- en: '**tree model training** - with respect to training data to grow the tree'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‘æ¨¡å‹è®­ç»ƒ** - æ ¹æ®è®­ç»ƒæ•°æ®æ¥ç”Ÿé•¿æ ‘'
- en: '**tree model tuning** - with respect to withheld testing data to select the
    optimum tree complexity.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‘æ¨¡å‹è°ƒä¼˜** - æ ¹æ®ä¿ç•™çš„æµ‹è¯•æ•°æ®æ¥é€‰æ‹©æœ€ä½³çš„æ ‘å¤æ‚åº¦ã€‚'
- en: Letâ€™s talk about tree model training first and then tree model tuning.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å…ˆè°ˆè°ˆæ ‘æ¨¡å‹è®­ç»ƒï¼Œç„¶åå†è°ˆæ ‘æ¨¡å‹è°ƒä¼˜ã€‚
- en: Training the Tree Model
  id: totrans-686
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ ‘æ¨¡å‹
- en: How do we calculate these mutually exclusive, exhaustive regions? This is accomplished
    through hierarchical binary segmentation of the predictor feature space.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•è®¡ç®—è¿™äº›äº’æ–¥ã€ç©·å°½çš„åŒºåŸŸï¼Ÿè¿™æ˜¯é€šè¿‡é¢„æµ‹ç‰¹å¾ç©ºé—´çš„åˆ†å±‚äºŒè¿›åˆ¶åˆ†å‰²æ¥å®ç°çš„ã€‚
- en: Training a decision tree model is both,
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹æ—¢æ˜¯ï¼Œ
- en: assigning the mutual exclusive, exhaustive regions
  id: totrans-689
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†é…äº’æ–¥ã€ç©·å°½çš„åŒºåŸŸ
- en: building a decision tree, each region is a terminal node, also known as a leaf
    node
  id: totrans-690
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ„å»ºå†³ç­–æ ‘æ—¶ï¼Œæ¯ä¸ªåŒºåŸŸéƒ½æ˜¯ä¸€ä¸ªç»ˆç«¯èŠ‚ç‚¹ï¼Œä¹Ÿç§°ä¸ºå¶å­èŠ‚ç‚¹
- en: These are the same thing! Letâ€™s list the steps and then walk through a training
    a tree to demonstrate this.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯åŒä¸€ä»¶äº‹ï¼è®©æˆ‘ä»¬åˆ—å‡ºæ­¥éª¤ï¼Œç„¶åé€šè¿‡è®­ç»ƒä¸€ä¸ªæ ‘æ¥æ¼”ç¤ºè¿™ä¸€ç‚¹ã€‚
- en: '**Assign All Data to a Single Region** - this region covers the entire predictor
    feature space'
  id: totrans-692
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å°†æ‰€æœ‰æ•°æ®åˆ†é…åˆ°å•ä¸ªåŒºåŸŸ** - è¿™ä¸ªåŒºåŸŸè¦†ç›–äº†æ•´ä¸ªé¢„æµ‹ç‰¹å¾ç©ºé—´'
- en: '**Scan All Possible Splits** - over all regions and over all features'
  id: totrans-693
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ‰«ææ‰€æœ‰å¯èƒ½çš„åˆ†å‰²** - åœ¨æ‰€æœ‰åŒºåŸŸå’Œæ‰€æœ‰ç‰¹å¾ä¸Š'
- en: '**Select the Best Split** - this is greedy optimization, i.e., the best split
    minimizes the residual sum of squares of errors over all the training data \(y_i\)
    over all of the regions \(j = 1,\ldots,J\).'
  id: totrans-694
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©æœ€ä½³åˆ†å‰²** - è¿™æ˜¯è´ªå©ªä¼˜åŒ–ï¼Œå³æœ€ä½³åˆ†å‰²æœ€å°åŒ–äº†æ‰€æœ‰è®­ç»ƒæ•°æ® \(y_i\) åœ¨æ‰€æœ‰åŒºåŸŸ \(j = 1,\ldots,J\) ä¸Šçš„æ®‹å·®å¹³æ–¹å’Œã€‚'
- en: '**Iterate Until Very Overfit** - return to step 1 for the next split until
    the tree is very overfit.'
  id: totrans-695
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¿­ä»£è‡³è¿‡åº¦æ‹Ÿåˆ** - è¿”å›æ­¥éª¤1è¿›è¡Œä¸‹ä¸€æ¬¡åˆ†å‰²ï¼Œç›´åˆ°æ ‘éå¸¸è¿‡åº¦æ‹Ÿåˆã€‚'
- en: For brevity we stop here, and make these observations,
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€æ´ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œåœæ­¢ï¼Œå¹¶åšå‡ºä»¥ä¸‹è§‚å¯Ÿï¼Œ
- en: hierarchical, binary segmentation is the same as sequentially building a decision
    tree, each split adds a new decision node and increases the number of leaf nodes
    by one.
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å±‚ã€äºŒè¿›åˆ¶åˆ†å‰²ä¸æŒ‰é¡ºåºæ„å»ºå†³ç­–æ ‘ç›¸åŒï¼Œæ¯æ¬¡åˆ†å‰²æ·»åŠ ä¸€ä¸ªæ–°çš„å†³ç­–èŠ‚ç‚¹ï¼Œå¹¶å°†å¶å­èŠ‚ç‚¹æ•°é‡å¢åŠ ä¸€ä¸ªã€‚
- en: the simple decision trees are in the complicated decision tree, i.e., if we
    build an \(8\) leaf node model, we have the \(8, 7, \ldots, 2\) leaf node model
    by sequentially removing the decision nodes, in the order of last one is the first
    one to remove.
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®€å•çš„å†³ç­–æ ‘åœ¨å¤æ‚çš„å†³ç­–æ ‘ä¸­ï¼Œå³å¦‚æœæˆ‘ä»¬æ„å»ºä¸€ä¸ª8ä¸ªå¶å­èŠ‚ç‚¹çš„æ¨¡å‹ï¼Œæˆ‘ä»¬é€šè¿‡æŒ‰é¡ºåºç§»é™¤å†³ç­–èŠ‚ç‚¹ï¼ˆæœ€åä¸€ä¸ªç§»é™¤çš„æ˜¯ç¬¬ä¸€ä¸ªç§»é™¤çš„ï¼‰æ¥å¾—åˆ°8ã€7ã€...ã€2ä¸ªå¶å­èŠ‚ç‚¹çš„æ¨¡å‹ã€‚
- en: the ultimate overfit model is number of leaf nodes equal to the number of training
    data. In this case, the training error is 0.0 as have one region for each training
    data a we estimate with the training data response feature values for all the
    at the training data cases.
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€ç»ˆè¿‡åº¦æ‹Ÿåˆæ¨¡å‹æ˜¯å¶å­èŠ‚ç‚¹æ•°é‡ç­‰äºè®­ç»ƒæ•°æ®æ•°é‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒé”™è¯¯ä¸º0.0ï¼Œå› ä¸ºæ¯ä¸ªè®­ç»ƒæ•°æ®éƒ½æœ‰ä¸€ä¸ªåŒºåŸŸï¼Œæˆ‘ä»¬ä½¿ç”¨è®­ç»ƒæ•°æ®å“åº”ç‰¹å¾å€¼æ¥ä¼°è®¡æ‰€æœ‰è®­ç»ƒæ•°æ®æ¡ˆä¾‹ã€‚
- en: Tuning the Tree Model
  id: totrans-700
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è°ƒæ•´æ ‘æ¨¡å‹
- en: To tune the decision tree we take the very overfit trained tree model,
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è°ƒä¼˜å†³ç­–æ ‘ï¼Œæˆ‘ä»¬é‡‡ç”¨è¿‡åº¦æ‹Ÿåˆçš„å·²è®­ç»ƒæ ‘æ¨¡å‹ï¼Œ
- en: sequentially cut the last decision node
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒ‰é¡ºåºå‰ªæ‰æœ€åä¸€ä¸ªå†³ç­–èŠ‚ç‚¹
- en: i.e., prune the last branch of the decision tree
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å³å‰ªæ‰å†³ç­–æ ‘çš„æœ€åä¸€ä¸ªåˆ†æ”¯
- en: Since the simpler trees are inside the complicated tree!
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºç®€å•çš„æ ‘åœ¨å¤æ‚çš„æ ‘ä¸­ï¼
- en: We can calculate test error as we prune and select tree with minimum test error
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨å‰ªæå’Œé€‰æ‹©å…·æœ‰æœ€å°æµ‹è¯•é”™è¯¯çš„æ ‘æ—¶è®¡ç®—æµ‹è¯•é”™è¯¯ã€‚
- en: We overfit the decision tree model, with a large number of leaf nodes and then
    we reduce the number of leaf nodes while tracking the test error.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿‡åº¦æ‹Ÿåˆäº†å†³ç­–æ ‘æ¨¡å‹ï¼Œå…·æœ‰å¤§é‡å¶å­èŠ‚ç‚¹ï¼Œç„¶åæˆ‘ä»¬åœ¨è·Ÿè¸ªæµ‹è¯•é”™è¯¯çš„åŒæ—¶å‡å°‘å¶å­èŠ‚ç‚¹çš„æ•°é‡ã€‚
- en: we select the number of leaf nodes that minimize the testing error.
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©æœ€å°åŒ–æµ‹è¯•é”™è¯¯çš„å¶å­èŠ‚ç‚¹æ•°é‡ã€‚
- en: since we are sequentially removing the last branch to simplify the tree, we
    call model tuning **pruning** for decision trees
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ˜¯æŒ‰é¡ºåºç§»é™¤æœ€åä¸€ä¸ªåˆ†æ”¯ä»¥ç®€åŒ–æ ‘ï¼Œæ‰€ä»¥æˆ‘ä»¬ç§°æ¨¡å‹è°ƒä¼˜ä¸ºå†³ç­–æ ‘çš„**å‰ªæ**ã€‚
- en: Letâ€™s discuss decision tree hyperparameters. I prefer number of leaf nodes as
    my decision tree hyperparameter because it provides,
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®¨è®ºå†³ç­–æ ‘è¶…å‚æ•°ã€‚æˆ‘æ›´å–œæ¬¢å¶å­èŠ‚ç‚¹æ•°é‡ä½œä¸ºæˆ‘çš„å†³ç­–æ ‘è¶…å‚æ•°ï¼Œå› ä¸ºå®ƒæä¾›ï¼Œ
- en: '**continuous, uniform increase in complexity** - equal steps in increased complexity
    without jumps'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿ç»­ã€å‡åŒ€å¢åŠ å¤æ‚åº¦** - åœ¨å¢åŠ å¤æ‚åº¦æ—¶æ²¡æœ‰è·³è·ƒ'
- en: '**intuitive control on complexity** - we can understand and relate the \(2,
    3, \ldots, 100\) leaf node decision trees'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç›´è§‚æ§åˆ¶å¤æ‚æ€§** - æˆ‘ä»¬å¯ä»¥ç†è§£å’Œå…³è” \(2, 3, \ldots, 100\) ä¸ªå¶èŠ‚ç‚¹çš„å†³ç­–æ ‘'
- en: '**flexible complexity** - the tree is free to grow in any manner to reduce
    training error, including highly asymmetric decision trees'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**çµæ´»çš„å¤æ‚æ€§** - æ ‘å¯ä»¥è‡ªç”±ç”Ÿé•¿ä»¥å‡å°‘è®­ç»ƒè¯¯å·®ï¼ŒåŒ…æ‹¬é«˜åº¦ä¸å¯¹ç§°çš„å†³ç­–æ ‘'
- en: There are other common decision tree hyperparameters including,
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä»–å¸¸è§çš„å†³ç­–æ ‘è¶…å‚æ•°åŒ…æ‹¬ï¼Œ
- en: '**Minimum reduction in RSS** â€“ related to the idea that incremental increase
    in complexity must be offset by sufficient reduction in training error. This could
    stop the model early, for example, a split with low reduction in training error
    could lead to a subsequent split with a much larger reduction in training error'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœ€å°å‡å°‘RSS** â€“ ä¸å¢é‡å¢åŠ å¤æ‚æ€§å¿…é¡»é€šè¿‡è¶³å¤Ÿçš„è®­ç»ƒè¯¯å·®å‡å°‘æ¥æŠµæ¶ˆçš„æƒ³æ³•ç›¸å…³ã€‚è¿™å¯èƒ½å¯¼è‡´æ¨¡å‹æå‰åœæ­¢ï¼Œä¾‹å¦‚ï¼Œè®­ç»ƒè¯¯å·®å‡å°‘å¾ˆå°çš„åˆ†å‰²å¯èƒ½å¯¼è‡´åç»­åˆ†å‰²æœ‰æ›´å¤§çš„è®­ç»ƒè¯¯å·®å‡å°‘'
- en: '**Minimum number of training data in each region** â€“ related to the concept
    of accuracy of the by-region estimates, i.e., we need at least \(n\) data for
    a reliable mean and most common category'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¯ä¸ªåŒºåŸŸçš„è®­ç»ƒæ•°æ®çš„æœ€å°æ•°é‡** â€“ ä¸åŒºåŸŸä¼°è®¡çš„å‡†ç¡®ç‡æ¦‚å¿µç›¸å…³ï¼Œå³æˆ‘ä»¬éœ€è¦è‡³å°‘ \(n\) ä¸ªæ•°æ®æ¥è·å¾—å¯é çš„å‡å€¼å’Œæœ€å¸¸è§çš„ç±»åˆ«'
- en: '**Maximum number of levels** â€“ forces symmetric trees, similar number of splits
    to get to each leaf node. There is a large change in model complexity with change
    in the hyperparameter.'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœ€å¤§å±‚æ•°** â€“ å¼ºåˆ¶å¯¹ç§°æ ‘ï¼Œåˆ°è¾¾æ¯ä¸ªå¶èŠ‚ç‚¹éœ€è¦ç›¸ä¼¼æ•°é‡çš„åˆ†å‰²ã€‚æ¨¡å‹å¤æ‚åº¦éšç€è¶…å‚æ•°çš„å˜åŒ–è€Œå¤§å¹…å˜åŒ–ã€‚'
- en: Ensemble Methods
  id: totrans-717
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆæ–¹æ³•
- en: What is the Testing Accuracy of Our Predictive Machine Learning Models?
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹çš„æµ‹è¯•å‡†ç¡®ç‡æ˜¯å¤šå°‘ï¼Ÿ
- en: Recall the equation for expected test error has three components.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: å›å¿†ä¸€ä¸‹é¢„æœŸæµ‹è¯•è¯¯å·®æ–¹ç¨‹æœ‰ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ã€‚
- en: \[ \mathbb{E}\left[(y_0 - \hat{f}(x_1^0, \ldots, x_m^0))^2\right] = \left(\mathbb{E}[\hat{f}(x_1^0,
    \ldots, x_m^0)] - f(x_1^0, \ldots, x_m^0)\right)^2 + \mathbb{E}\left[\left(\hat{f}(x_1^0,
    \ldots, x_m^0) - \mathbb{E}[\hat{f}(x_1^0, \ldots, x_m^0)]\right)^2\right] + \sigma_\varepsilon^2
    \]
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbb{E}\left[(y_0 - \hat{f}(x_1^0, \ldots, x_m^0))^2\right] = \left(\mathbb{E}[\hat{f}(x_1^0,
    \ldots, x_m^0)] - f(x_1^0, \ldots, x_m^0)\right)^2 + \mathbb{E}\left[\left(\hat{f}(x_1^0,
    \ldots, x_m^0) - \mathbb{E}[\hat{f}(x_1^0, \ldots, x_m^0)]\right)^2\right] + \sigma_\varepsilon^2
    \]
- en: 'There can be labeled as:'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥æ ‡è®°ä¸ºï¼š
- en: \[ \text{Expected Test Error} = \text{Model Bias}^2 + \text{Model Variance}
    + \text{Irreducible Error} \]
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Expected Test Error} = \text{Model Bias}^2 + \text{Model Variance}
    + \text{Irreducible Error} \]
- en: where,
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ
- en: '**Model Variance** - is the error in the model predictions due to sensitivity
    to the data, i.e., what if we used different training data?'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹æ–¹å·®** - æ˜¯æ¨¡å‹é¢„æµ‹è¯¯å·®ç”±äºå¯¹æ•°æ®çš„æ•æ„Ÿæ€§ï¼Œå³å¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„è®­ç»ƒæ•°æ®ä¼šæ€æ ·ï¼Ÿ'
- en: '**Model Bias** - is error in the model predictions due to using an approximate
    model / model is too simple'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹åå·®** - æ˜¯ç”±äºä½¿ç”¨è¿‘ä¼¼æ¨¡å‹/æ¨¡å‹è¿‡äºç®€å•å¯¼è‡´çš„æ¨¡å‹é¢„æµ‹è¯¯å·®'
- en: '**Irreducible Error** - is error in the model predictions due to missing features
    and limited samples canâ€™t be fixed with modeling / entire feature space is not
    sampled'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸å¯å‡å°‘è¯¯å·®** - æ˜¯ç”±äºç¼ºå°‘ç‰¹å¾å’Œæ ·æœ¬æœ‰é™å¯¼è‡´çš„æ¨¡å‹é¢„æµ‹è¯¯å·®ï¼Œæ— æ³•é€šè¿‡å»ºæ¨¡/æ•´ä¸ªç‰¹å¾ç©ºé—´æœªé‡‡æ ·æ¥ä¿®å¤'
- en: Now we can visualize the model variance and bias tradeoff as,
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹æ–¹å·®å’Œåå·®æƒè¡¡å¯è§†åŒ–ï¼Œ
- en: '![](../Images/10e6db08085f4ca1ff6ceb66f673d9d8.png)'
  id: totrans-728
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10e6db08085f4ca1ff6ceb66f673d9d8.png)'
- en: Model variance and bias trade-off, for simple to complicated predictive machine
    learning models.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®å’Œåå·®æƒè¡¡ï¼Œå¯¹äºç®€å•åˆ°å¤æ‚çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
- en: Model variance limits the complexity and text accuracy of our models.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®é™åˆ¶äº†æˆ‘ä»¬çš„æ¨¡å‹å¤æ‚æ€§å’Œæ–‡æœ¬å‡†ç¡®æ€§ã€‚
- en: '**How Can We Reduce Model Variance?** - so that we can use more complicated
    and more accurate models.'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¦‚ä½•å‡å°‘æ¨¡å‹æ–¹å·®ï¼Ÿ** - è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨æ›´å¤æ‚å’Œæ›´ç²¾ç¡®çš„æ¨¡å‹ã€‚'
- en: By standard error in the average, we observe the reduction in variance by averaging!
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¹³å‡çš„æ ‡å‡†è¯¯å·®ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°é€šè¿‡å¹³å‡æ¥å‡å°‘æ–¹å·®ï¼
- en: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
- en: where \(\sigma^2_s\) is the sample variance, \(n\) is the number of samples,
    and \(\sigma_{\bar{x}}^2\) is the variance of the average under the assumption
    of independent, identically distributed sampling.
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma^2_s\) æ˜¯æ ·æœ¬æ–¹å·®ï¼Œ\(n\) æ˜¯æ ·æœ¬æ•°é‡ï¼Œ\(\sigma_{\bar{x}}^2\) æ˜¯åœ¨ç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ ·å‡è®¾ä¸‹çš„å¹³å‡æ–¹å·®ã€‚
- en: '![](../Images/11ec8dafb91278a4a07a22c274b18c52.png)'
  id: totrans-735
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11ec8dafb91278a4a07a22c274b18c52.png)'
- en: Model variance and bias trade-off, for simple to complicated predictive machine
    learning models with model variance reduced by averaging.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®å’Œåå·®æƒè¡¡ï¼Œå¯¹äºç®€å•åˆ°å¤æ‚çš„é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡å¹³å‡å‡å°‘æ¨¡å‹æ–¹å·®ã€‚
- en: We can reduce model variance by calculating many estimates and averaging them
    together. We will need to make \(B\) estimates,
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—å¤šä¸ªä¼°è®¡å€¼å¹¶å°†å®ƒä»¬å¹³å‡åœ¨ä¸€èµ·æ¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚æˆ‘ä»¬éœ€è¦åšå‡º \(B\) ä¸ªä¼°è®¡ï¼Œ
- en: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]
- en: where,
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ
- en: \(\hat{y}^{(b)}\) is the prediction made by the \(b^{th}\) model in the ensemble,
    \(\hat{f}^{(b)}\) is the \(b^{th}\) estimator, \(X_1, \ldots, X_m\) is the predictor
    features, and \(B\) is the total number of estimators (the multiple models).
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{y}^{(b)}\) æ˜¯é›†æˆä¸­ç¬¬ \(b\) ä¸ªæ¨¡å‹åšå‡ºçš„é¢„æµ‹ï¼Œ\(\hat{f}^{(b)}\) æ˜¯ç¬¬ \(b\) ä¸ªä¼°è®¡é‡ï¼Œ\(X_1,
    \ldots, X_m\) æ˜¯é¢„æµ‹ç‰¹å¾ï¼Œ\(B\) æ˜¯ä¼°è®¡é‡æ€»æ•°ï¼ˆå¤šä¸ªæ¨¡å‹ï¼‰ã€‚
- en: Then our ultimate estimate will be the average (regression) or plurality (classification)
    of our estimates,
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬çš„æœ€ç»ˆä¼°è®¡å°†æ˜¯æˆ‘ä»¬çš„ä¼°è®¡çš„å¹³å‡å€¼ï¼ˆå›å½’ï¼‰æˆ–å¤šæ•°ï¼ˆåˆ†ç±»ï¼‰ï¼Œ
- en: regression ensemble estimate,
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å½’é›†æˆä¼°è®¡ï¼Œ
- en: \[ \hat{y} = \frac{1}{B} \sum_{b=1}^{B} \hat{y}^{(b)} \]
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \frac{1}{B} \sum_{b=1}^{B} \hat{y}^{(b)} \]
- en: classification ensemble estimate,
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»é›†æˆä¼°è®¡ï¼Œ
- en: \[ \hat{y} = \arg\max_y \sum_{b=1}^{B} \mathbb{I}(\hat{y}^{(b)} = y) \]
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \arg\max_y \sum_{b=1}^{B} \mathbb{I}(\hat{y}^{(b)} = y) \]
- en: This requires multiple prediction models, \(f^{b}, b = 1,\ldots, B\) to make
    \(B\) predictions,
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éœ€è¦å¤šä¸ªé¢„æµ‹æ¨¡å‹ï¼Œ\(f^{b}, b = 1,\ldots, B\) æ¥åšå‡º \(B\) ä¸ªé¢„æµ‹ï¼Œ
- en: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]![](../Images/885306737841b4ce2406407ca170fe7f.png)
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}^{(b)} = \hat{f}^{(b)}(X_1, \ldots, X_m), \quad b = 1, \ldots, B \]![å›¾ç‰‡](../Images/885306737841b4ce2406407ca170fe7f.png)
- en: Multiple models to make multiple predictions to reduce model variance by averaging
    over the ensemble.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¯¹é›†æˆè¿›è¡Œå¹³å‡æ¥å‡å°‘æ¨¡å‹æ–¹å·®ï¼Œä½¿ç”¨å¤šä¸ªæ¨¡å‹è¿›è¡Œå¤šä¸ªé¢„æµ‹ã€‚
- en: But we only have access to a single dataset, \(Y,X_1,\ldots,X_m\); therefore,
    every model will be the same,
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬åªèƒ½è®¿é—®ä¸€ä¸ªæ•°æ®é›†ï¼Œ\(Y,X_1,\ldots,X_m\)ï¼›å› æ­¤ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½å°†ç›¸åŒï¼Œ
- en: '![](../Images/f4dd12f28990215e1c5906e7c36793a1.png)'
  id: totrans-750
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/f4dd12f28990215e1c5906e7c36793a1.png)'
- en: Multiple models to make multiple predictions to reduce model variance by averaging
    over the ensemble, with the same data result in the same model and the same predictions.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç›¸åŒçš„æ•°æ®è¿›è¡Œå¤šä¸ªé¢„æµ‹ä»¥å‡å°‘æ¨¡å‹æ–¹å·®ï¼Œé€šè¿‡é›†æˆå¹³å‡ï¼Œç›¸åŒçš„æ•°æ®å¯¼è‡´ç›¸åŒçš„æ¨¡å‹å’Œç›¸åŒçš„é¢„æµ‹ã€‚
- en: Our models are generally deterministic, train with the same data and hyperparameters
    and we get the same estimate.
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡å¼é€šå¸¸æ˜¯ç¡®å®šæ€§çš„ï¼Œä½¿ç”¨ç›¸åŒçš„æ•°æ®å’Œè¶…å‚æ•°è¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬å¾—åˆ°ç›¸åŒçš„ä¼°è®¡ã€‚
- en: Bootstrap
  id: totrans-753
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªä¸¾
- en: One source of uncertainty is the paucity of data.
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªæ¥æºæ˜¯æ•°æ®é‡ä¸è¶³ã€‚
- en: Do these 200 or so wells provide a precise (and accurate estimate) of the mean?
    standard deviation? skew? P13?
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™äº›å¤§çº¦200å£äº•æ˜¯å¦æä¾›äº†å¯¹å¹³å‡å€¼çš„ç²¾ç¡®ï¼ˆå’Œå‡†ç¡®ï¼‰ä¼°è®¡ï¼Ÿæ ‡å‡†å·®ï¼Ÿååº¦ï¼ŸP13ï¼Ÿ
- en: What is the impact of uncertainty in the mean porosity, for example, \(20\%
    \pm 2\%\)?
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¹³å‡å­”éš™ç‡çš„ä¸ç¡®å®šæ€§å¯¹ä¾‹å¦‚ \(20\% \pm 2\%\) æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ
- en: '![](../Images/cc8a09c3c5b404de658a3f4d6a4ace64.png)'
  id: totrans-757
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/cc8a09c3c5b404de658a3f4d6a4ace64.png)'
- en: Samples and population, from Bootstrap chapter of Applied Geostatistics in Python
    e-book.
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: æ ·æœ¬å’Œæ€»ä½“ï¼Œæ¥è‡ª Python åœ°çƒç»Ÿè®¡å­¦ç”µå­ä¹¦çš„åº”ç”¨åœ°çƒç»Ÿè®¡å­¦ç« èŠ‚ã€‚
- en: What if we had \(L\) different datasets? \(L\) parallel universes where we collected
    \(n\) samples from the inaccessible truth (the population).
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æœ‰ \(L\) ä¸ªä¸åŒçš„æ•°æ®é›†å‘¢ï¼Ÿ\(L\) ä¸ªå¹³è¡Œå®‡å®™ï¼Œæˆ‘ä»¬ä»ä¸å¯åŠçš„çœŸç›¸ï¼ˆæ€»ä½“ï¼‰ä¸­æ”¶é›† \(n\) ä¸ªæ ·æœ¬ã€‚
- en: '![](../Images/03a47e7d2a75afebba6ca7928b259afe.png)'
  id: totrans-760
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/03a47e7d2a75afebba6ca7928b259afe.png)'
- en: Multiple dataset realizations from the truth population, from Bootstrap chapter
    of Applied Geostatistics in Python e-book.
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ªçœŸå®æ€»ä½“çš„å¤šä¸ªæ•°æ®é›†å®ç°ï¼Œæ¥è‡ª Python åœ°çƒç»Ÿè®¡å­¦ç”µå­ä¹¦çš„åº”ç”¨åœ°çƒç»Ÿè®¡å­¦ç« èŠ‚ã€‚
- en: but we only exist in 1 universe \(\rightarrow\) this is not possible.
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬åªå­˜åœ¨äºä¸€ä¸ªå®‡å®™ä¸­ \(\rightarrow\) è¿™æ˜¯ä¸å¯èƒ½çš„ã€‚
- en: Instead we sample \(n\) times from the dataset with replacement,
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸åï¼Œæˆ‘ä»¬ä»æ•°æ®é›†ä¸­æ›¿æ¢ \(n\) æ¬¡é‡‡æ ·ï¼Œ
- en: bootstrap realizations of the data
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®çš„è‡ªä¸¾å®ç°
- en: that vary by due to some samples being left out and others sampled multiple
    times.
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å˜åŒ–æ˜¯ç”±äºä¸€äº›æ ·æœ¬è¢«é—æ¼è€Œå…¶ä»–æ ·æœ¬è¢«å¤šæ¬¡é‡‡æ ·æ‰€å¼•èµ·çš„ã€‚
- en: '![](../Images/07925f4d15205ea985dfc081c24b0589.png)'
  id: totrans-766
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/07925f4d15205ea985dfc081c24b0589.png)'
- en: Multiple dataset bootstrap datasets.
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šä¸ªæ•°æ®é›†çš„è‡ªä¸¾æ•°æ®é›†ã€‚
- en: Now, hereâ€™s a definition of bootstrap,
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¿™æ˜¯å¯¹è‡ªä¸¾ï¼ˆbootstrapï¼‰çš„ä¸€ä¸ªå®šä¹‰ï¼Œ
- en: method to assess the uncertainty in a sample statistic by repeated random sampling
    with replacement simulating the sampling process to acquire dataset realizations
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é‡å¤éšæœºæŠ½æ ·å¹¶æ›¿æ¢æ¥è¯„ä¼°æ ·æœ¬ç»Ÿè®¡é‡ä¸ç¡®å®šæ€§çš„æ–¹æ³•ï¼Œæ¨¡æ‹ŸæŠ½æ ·è¿‡ç¨‹ä»¥è·å–æ•°æ®é›†å®ç°ã€‚
- en: Under the assumptions,
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡è®¾ä¸‹ï¼Œ
- en: '**sufficient sample** - enough data to infer the population parameters. Bootstrap
    cannot make up for too few data!'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¶³å¤Ÿçš„æ ·æœ¬** - è¶³å¤Ÿçš„æ•°æ®æ¥æ¨æ–­æ€»ä½“å‚æ•°ã€‚è‡ªä¸¾ä¸èƒ½å¼¥è¡¥æ•°æ®é‡è¿‡å°‘çš„é—®é¢˜ï¼'
- en: '**representative sampling** - bias in the sample will be passed to the bootstrap
    uncertainty model, for example, if the mean is biased in the sample, then the
    bootstrap uncertainty model will be centered on the biased mean from the sample.
    We must first debias our data.'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»£è¡¨æ€§é‡‡æ ·** - æ ·æœ¬ä¸­çš„åå·®å°†ä¼ é€’åˆ°è‡ªä¸¾ä¸ç¡®å®šæ€§æ¨¡å‹ä¸­ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæ ·æœ¬ä¸­çš„å‡å€¼æœ‰åå·®ï¼Œé‚£ä¹ˆè‡ªä¸¾ä¸ç¡®å®šæ€§æ¨¡å‹å°†åŸºäºæ ·æœ¬ä¸­çš„åå·®å‡å€¼è¿›è¡Œä¸­å¿ƒåŒ–ã€‚æˆ‘ä»¬å¿…é¡»é¦–å…ˆæ¶ˆé™¤æ•°æ®åå·®ã€‚'
- en: There are also various limitations for bootstrap, including,
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªä¸¾ä¹Ÿæœ‰å„ç§å±€é™æ€§ï¼ŒåŒ…æ‹¬ï¼Œ
- en: '**stationarity** - the statistics from the sample are assumed to be constant
    over the model space'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¹³ç¨³æ€§** - å‡è®¾æ ·æœ¬ä¸­çš„ç»Ÿè®¡é‡åœ¨æ¨¡å‹ç©ºé—´ä¸­æ˜¯æ’å®šçš„'
- en: '**one uncertainty source only** - only accounts for uncertainty due to too
    few samples, for example, no uncertainty due to changes away from data'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åªæœ‰ä¸€ä¸ªä¸ç¡®å®šæ€§æ¥æº** - åªè€ƒè™‘ç”±äºæ ·æœ¬å¤ªå°‘å¼•èµ·çš„ä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚ï¼Œä¸è€ƒè™‘æ•°æ®å˜åŒ–å¼•èµ·çš„ä¸ç¡®å®šæ€§'
- en: '**does not account for area of interest** - larger model region or smaller
    model region, bootstrap uncertainty does not change.'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è€ƒè™‘æ„Ÿå…´è¶£çš„åŒºåŸŸ** - è¾ƒå¤§çš„æ¨¡å‹åŒºåŸŸæˆ–è¾ƒå°çš„æ¨¡å‹åŒºåŸŸï¼Œè‡ªä¸¾ä¸ç¡®å®šæ€§ä¸ä¼šæ”¹å˜ã€‚'
- en: '**independence between the samples** - does not account for correlation, relationships
    between the samples'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ·æœ¬ä¹‹é—´çš„ç‹¬ç«‹æ€§** - ä¸è€ƒè™‘æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå…³ç³»'
- en: '**no local conditioning** - does not account for other local information sources'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ²¡æœ‰å±€éƒ¨æ¡ä»¶** - ä¸è€ƒè™‘å…¶ä»–å±€éƒ¨ä¿¡æ¯æ¥æº'
- en: We could summarize all of this limitations as, bootstrap does not account for
    the spatial (or temporal) context of the data.
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰è¿™äº›é™åˆ¶æ€»ç»“ä¸ºï¼Œè‡ªä¸¾ä¸è€ƒè™‘æ•°æ®çš„ç©ºé—´ï¼ˆæˆ–æ—¶é—´ï¼‰ä¸Šä¸‹æ–‡ã€‚
- en: there is a form of bootstrap, known as spatial bootstrap that does account for
    spatial context, [spatial bootstrap and bagging for ensemble machine learning](https://www.sciencedirect.com/science/article/pii/S0098300424000414).
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ç§å½¢å¼çš„è‡ªä¸¾ï¼Œç§°ä¸ºç©ºé—´è‡ªä¸¾ï¼Œå®ƒç¡®å®è€ƒè™‘äº†ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œ[ç©ºé—´è‡ªä¸¾å’Œé›†æˆæœºå™¨å­¦ä¹ çš„æ‰“åŒ…](https://www.sciencedirect.com/science/article/pii/S0098300424000414)ã€‚
- en: Letâ€™s visualize bootstrap for the case of calculating uncertainty in sample
    mean estimated ultimate recovery (EUR) given \(n=10\) observations from 10 wells.
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯è§†åŒ–ä½¿ç”¨ \(n=10\) ä¸ªæ¥è‡ª 10 ä¸ªäº•çš„è§‚æµ‹å€¼æ¥è®¡ç®—æ ·æœ¬å‡å€¼ä¼°è®¡çš„æœ€ç»ˆå¯é‡‡å‚¨é‡ï¼ˆEURï¼‰çš„ä¸ç¡®å®šæ€§æ—¶çš„è‡ªä¸¾è¿‡ç¨‹ã€‚
- en: '![](../Images/1cfe358ff534628282d37d9e47ad383a.png)'
  id: totrans-782
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cfe358ff534628282d37d9e47ad383a.png)'
- en: \(n = 10\) samples with replacement to calculate a single realization of the
    sample mean.
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: \(n = 10\) ä¸ªæ ·æœ¬çš„é‡å¤é‡‡æ ·æ¥è®¡ç®—æ ·æœ¬å‡å€¼çš„å•ä¸ªå®ç°ã€‚
- en: Now we repeat and calculate a \(2^{nd}\) realization of the sample mean,
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬é‡å¤å¹¶è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬äºŒæ¬¡å®ç°ï¼Œ
- en: '![](../Images/2a1d9d26290cdc6495c88246af159f42.png)'
  id: totrans-785
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a1d9d26290cdc6495c88246af159f42.png)'
- en: Second realization of \(n = 10\) samples with replacement to calculate the second
    realization of the sample mean.
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ¬¡é‡å¤ \(n = 10\) ä¸ªæ ·æœ¬çš„é‡å¤é‡‡æ ·æ¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬äºŒæ¬¡å®ç°ã€‚
- en: and a third realization of the data to calculate the \(3^{rd}\) realization
    of the sample mean,
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶è®¡ç®—æ•°æ®ç¬¬ä¸‰æ¬¡å®ç°ä»¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬ä¸‰æ¬¡å®ç°ã€‚
- en: '![](../Images/508b11f7b9417d09182403573f7e40d7.png)'
  id: totrans-788
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/508b11f7b9417d09182403573f7e40d7.png)'
- en: Third realization of \(n = 10\) samples with replacement to calculate the third
    realization of the sample mean.
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰æ¬¡é‡å¤ \(n = 10\) ä¸ªæ ·æœ¬çš„é‡å¤é‡‡æ ·æ¥è®¡ç®—æ ·æœ¬å‡å€¼çš„ç¬¬ä¸‰æ¬¡å®ç°ã€‚
- en: and if we repeat \(L\) times we sample the complete distribution for the uncertainty
    in the sample mean.
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬é‡å¤ \(L\) æ¬¡ï¼Œæˆ‘ä»¬å°†é‡‡æ ·æ•´ä¸ªæ ·æœ¬å‡å€¼çš„ä¸ç¡®å®šæ€§åˆ†å¸ƒã€‚
- en: '![](../Images/5f2dabcbf8e395ea433527e012d41490.png)'
  id: totrans-791
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f2dabcbf8e395ea433527e012d41490.png)'
- en: $L$ realizations of the data for $L$ realizations to completely sample the uncertainty
    in the mean.
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº \(L\) æ¬¡å®ç°çš„æ•°æ®ï¼Œè¿›è¡Œ \(L\) æ¬¡å®ç°ä»¥å®Œå…¨é‡‡æ ·å‡å€¼çš„ä¸ç¡®å®šæ€§ã€‚
- en: Letâ€™s summarize bootstrap,
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹è‡ªä¸¾ï¼Œ
- en: developed by [Efron, 1982](https://epubs.siam.org/doi/pdf/10.1137/1.9781611970319.fm)
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”± [Efron, 1982](https://epubs.siam.org/doi/pdf/10.1137/1.9781611970319.fm) å¼€å‘
- en: statistical resampling procedure to calculate uncertainty in a calculated statistic
    from the data itself.
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡é‡é‡‡æ ·è¿‡ç¨‹ï¼Œç”¨äºä»æ•°æ®æœ¬èº«è®¡ç®—è®¡ç®—ç»Ÿè®¡çš„ä¸ç¡®å®šæ€§ã€‚
- en: seems impossible, but go ahead and compare it to known cases like standard error
    and you will see that it works,
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™çœ‹èµ·æ¥ä¼¼ä¹æ˜¯ä¸å¯èƒ½çš„ï¼Œä½†ç»§ç»­æ¯”è¾ƒå·²çŸ¥æ¡ˆä¾‹ï¼Œå¦‚æ ‡å‡†è¯¯å·®ï¼Œä½ å°±ä¼šçœ‹åˆ°å®ƒæ˜¯æœ‰æ•ˆçš„ï¼Œ
- en: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\bar{x}}^2 = \frac{\sigma^2_s}{n} \]
- en: where \(\sigma^2_s\) is the sample variance, \(n\) is the number of samples,
    and \(\sigma_{\bar{x}}^2\) is the variance of the average under the assumption
    of independent, identically distributed sampling.
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ \(\sigma^2_s\) æ˜¯æ ·æœ¬æ–¹å·®ï¼Œ\(n\) æ˜¯æ ·æœ¬æ•°é‡ï¼Œ\(\sigma_{\bar{x}}^2\) æ˜¯åœ¨ç‹¬ç«‹ã€åŒåˆ†å¸ƒé‡‡æ ·å‡è®¾ä¸‹çš„å¹³å‡æ–¹å·®ã€‚
- en: may be applied to calculate the uncertainty in any statistic, for example, \(13^{th}\)
    percentile, skew, etc.
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ä»¥åº”ç”¨äºè®¡ç®—ä»»ä½•ç»Ÿè®¡çš„ä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚ï¼Œç¬¬ \(13\) ç™¾åˆ†ä½æ•°ï¼Œååº¦ç­‰ã€‚
- en: advanced forms account for spatial information and strategy (game theory).
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é«˜çº§å½¢å¼è€ƒè™‘ç©ºé—´ä¿¡æ¯å’Œç­–ç•¥ï¼ˆåšå¼ˆè®ºï¼‰ã€‚
- en: '![](../Images/a360524ac8f082a989d9ff04d88b3906.png)'
  id: totrans-801
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a360524ac8f082a989d9ff04d88b3906.png)'
- en: The general flow chart for bootstrap.
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªä¸¾çš„ä¸€èˆ¬æµç¨‹å›¾ã€‚
- en: Bagging Models
  id: totrans-803
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Baggingæ¨¡å‹
- en: Bagging models in machine learning apply bootstrap to,
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­çš„Baggingæ¨¡å‹åº”ç”¨è‡ªä¸¾ï¼Œ
- en: calculate multiple realizations of the data
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—å¤šä¸ªæ•°æ®å®ç°
- en: train multiple realizations of the model
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒå¤šä¸ªæ¨¡å‹å®ç°
- en: calculate multiple realizations of the estimate
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—å¤šä¸ªä¼°è®¡å®ç°
- en: average the estimates to reduce model variance
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¹³å‡ä¼°è®¡å€¼ä»¥å‡å°‘æ¨¡å‹æ–¹å·®
- en: Hereâ€™s the flow chart for bagging models,
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯Baggingæ¨¡å‹çš„æµç¨‹å›¾ï¼Œ
- en: '![](../Images/aa378f660d65104e433bf1eb53c1cd7f.png)'
  id: totrans-810
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa378f660d65104e433bf1eb53c1cd7f.png)'
- en: The bagging machine learning model flow chart.
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: Baggingæœºå™¨å­¦ä¹ æ¨¡å‹æµç¨‹å›¾ã€‚
- en: Apply statistical bootstrap to obtain multiple realizations of the data,
  id: totrans-812
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨ç»Ÿè®¡è‡ªä¸¾ä»¥è·å¾—æ•°æ®çš„å¤šä¸ªå®ç°ï¼Œ
- en: \[ Y^b, X_1^b, \dots, X_m^b,\quad b = 1, \dots, B \]
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y^b, X_1^b, \dots, X_m^b,\quad b = 1, \dots, B \]
- en: Train a prediction model (estimator) for each data realization,
  id: totrans-814
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ¯ä¸ªæ•°æ®å®ç°è®­ç»ƒä¸€ä¸ªé¢„æµ‹æ¨¡å‹ï¼ˆä¼°è®¡å™¨ï¼‰ï¼Œ
- en: \[ \hat{f}^b(X_1^b, \dots, X_m^b) \]
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{f}^b(X_1^b, \dots, X_m^b) \]
- en: Calculate a prediction with each estimator,
  id: totrans-816
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¯ä¸ªä¼°è®¡å™¨è¿›è¡Œé¢„æµ‹è®¡ç®—ï¼Œ
- en: \[ \hat{Y}^b = \hat{f}^b(X_1^b, \dots, X_m^b) \]
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y}^b = \hat{f}^b(X_1^b, \dots, X_m^b) \]
- en: Aggregate the ensemble of ğµ predictions over the estimators,
  id: totrans-818
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ä¼°è®¡å™¨çš„Bä¸ªé¢„æµ‹è¿›è¡Œèšåˆï¼Œ
- en: '**Regression** â€“ aggregate the ensemble predictions with the average,'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å›å½’** â€“ ä½¿ç”¨å¹³å‡å€¼èšåˆé›†æˆé¢„æµ‹ï¼Œ'
- en: \[ \hat{Y} = \frac{1}{B} \sum_{b=1}^{B} \hat{Y}^b \]
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} = \frac{1}{B} \sum_{b=1}^{B} \hat{Y}^b \]
- en: '**Classification** â€“ aggregate the ensemble predictions with majority-rule,
    plurality,'
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»** â€“ ä½¿ç”¨å¤šæ•°è§„åˆ™ã€å¤šæ•°æŠ•ç¥¨èšåˆé›†æˆé¢„æµ‹ï¼Œ'
- en: \[ \hat{Y} = \arg\max(\hat{Y}^b) \]
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{Y} = \arg\max(\hat{Y}^b) \]
- en: I built out an interactive Python dashboard for [bagging linear regression](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Bootstrap_Bagging.ipynb).
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸º[baggingçº¿æ€§å›å½’](https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Bootstrap_Bagging.ipynb)æ„å»ºäº†ä¸€ä¸ªäº¤äº’å¼Pythonä»ªè¡¨æ¿ã€‚
- en: '![](../Images/734e60e25fd461f174b74321a8caef2b.png)'
  id: totrans-824
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/734e60e25fd461f174b74321a8caef2b.png)'
- en: Interactive machine learning bagging with linear regression, 16 data bootstrap,
    model and prediction realizations aggregated by averaging.
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡çº¿æ€§å›å½’è¿›è¡Œäº¤äº’å¼æœºå™¨å­¦ä¹ Baggingï¼Œ16ä¸ªæ•°æ®è‡ªä¸¾ï¼Œé€šè¿‡å¹³å‡èšåˆæ¨¡å‹å’Œé¢„æµ‹å®ç°ã€‚
- en: Training and Tuning Bagging Models
  id: totrans-826
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œè°ƒæ•´Baggingæ¨¡å‹
- en: What is the Bagging Regression Model?
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯Baggingå›å½’æ¨¡å‹ï¼Ÿ
- en: Multiple models each trained on different bootstrap data realizations, all with
    the same hyperparameter(s).
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨ä¸åŒçš„è‡ªä¸¾æ•°æ®å®ç°è¿›è¡Œè®­ç»ƒï¼Œä½†éƒ½ä½¿ç”¨ç›¸åŒçš„è¶…å‚æ•°ï¼ˆsï¼‰ã€‚
- en: '![](../Images/b80d0d8659d6a69c67cc48f81cd46888.png)'
  id: totrans-829
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b80d0d8659d6a69c67cc48f81cd46888.png)'
- en: The bagging model, we train individually, but we tune the ensemble.
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å•ç‹¬è®­ç»ƒBaggingæ¨¡å‹ï¼Œä½†è°ƒæ•´é›†æˆã€‚
- en: The bagging prediction, \(\hat{y}\), the aggregate of the individual estimators,
    is the output of this model.
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: Baggingé¢„æµ‹ï¼Œ\(\hat{y}\)ï¼Œå³å•ä¸ªä¼°è®¡å™¨çš„æ€»å’Œï¼Œæ˜¯è¯¥æ¨¡å‹çš„è¾“å‡ºã€‚
- en: '![](../Images/8734bb5c0493ecba4f618382a639010c.png)'
  id: totrans-832
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8734bb5c0493ecba4f618382a639010c.png)'
- en: Bagging regression predictions by averaging multiple prediction models.
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¹³å‡å¤šä¸ªé¢„æµ‹æ¨¡å‹è¿›è¡ŒBaggingå›å½’é¢„æµ‹ã€‚
- en: or for classification,
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…å¯¹äºåˆ†ç±»ï¼Œ
- en: '![](../Images/8734bb5c0493ecba4f618382a639010c.png)'
  id: totrans-835
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8734bb5c0493ecba4f618382a639010c.png)'
- en: Bagging classification predictions by plurality of multiple prediction models.
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¤šä¸ªé¢„æµ‹æ¨¡å‹çš„å¤šæ•°æŠ•ç¥¨è¿›è¡ŒBaggingåˆ†ç±»é¢„æµ‹ã€‚
- en: Each model, known as an estimator in the ensemble of models, is trained with
    their respective bootstrapped data realization, during training each model minimizes
    train error of the individual estimator with the bootstrapped data realization,
    residual sum of squares for regression,
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹ï¼Œåœ¨æ¨¡å‹é›†æˆä¸­è¢«ç§°ä¸ºä¼°è®¡å™¨ï¼Œéƒ½æ˜¯ä½¿ç”¨å„è‡ªçš„bootstrappedæ•°æ®å®ç°è¿›è¡Œè®­ç»ƒçš„ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½æœ€å°åŒ–å•ä¸ªä¼°è®¡å™¨çš„bootstrappedæ•°æ®å®ç°çš„è®­ç»ƒè¯¯å·®ï¼Œå›å½’çš„æ®‹å·®å¹³æ–¹å’Œï¼Œ
- en: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \]
- en: and Gini impurity for classification,
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠç”¨äºåˆ†ç±»çš„Giniä¸çº¯åº¦ï¼Œ
- en: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
    \]
- en: each estimator is trained separately, but they all share the same hyperparameters.
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªä¼°è®¡å™¨éƒ½æ˜¯å•ç‹¬è®­ç»ƒçš„ï¼Œä½†å®ƒä»¬éƒ½å…±äº«ç›¸åŒçš„è¶…å‚æ•°ã€‚
- en: This provides the flexibility to build the best possible model to fit each bootstrap
    dataset.
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æä¾›äº†æ„å»ºæœ€é€‚åˆæ¯ä¸ªè‡ªä¸¾æ•°æ®é›†çš„æœ€ä½³æ¨¡å‹çš„çµæ´»æ€§ã€‚
- en: '![](../Images/038bd000e2192149c3a4abd1ab0d5cde.png)'
  id: totrans-843
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/038bd000e2192149c3a4abd1ab0d5cde.png)'
- en: Estimators in the ensemble of models are trained individually, but share the
    same hyperparameter(s).
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆæ¨¡å‹ä¸­çš„ä¼°è®¡å™¨æ˜¯å•ç‹¬è®­ç»ƒçš„ï¼Œä½†å…±äº«ç›¸åŒçš„è¶…å‚æ•°ã€‚
- en: We tune our bagged model with the error of the bagging estimate from aggregating
    the ensemble of estimates, for the case of regression,
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä»é›†æˆä¼°è®¡çš„èšåˆä¸­å¾—åˆ°çš„è¢‹è£…ä¼°è®¡è¯¯å·®æ¥è°ƒæ•´æˆ‘ä»¬çš„è¢‹è£…æ¨¡å‹ï¼Œå¯¹äºå›å½’çš„æƒ…å†µï¼Œ
- en: \[ \text{MSE} = \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 \]
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{MSE} = \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 \]
- en: 'where the predicted value \(\hat{y}_i\) is given by:'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­é¢„æµ‹å€¼ \(\hat{y}_i\) ç”±ä»¥ä¸‹ç»™å‡ºï¼š
- en: \[ \hat{y}_i = \frac{1}{B} \sum_{b=1}^{B} \hat{y}_i^{(b)} \]
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}_i = \frac{1}{B} \sum_{b=1}^{B} \hat{y}_i^{(b)} \]
- en: We tune our ensemble jointly over all estimators, we do not consider the error
    of individual model estimators, \(\hat{y}_i^ğ‘ - y_i\), within the ensemble for
    model tuning.
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹æ‰€æœ‰ä¼°è®¡å™¨è”åˆè°ƒæ•´æˆ‘ä»¬çš„é›†æˆï¼Œæˆ‘ä»¬ä¸åœ¨é›†æˆä¸­è€ƒè™‘å•ä¸ªæ¨¡å‹ä¼°è®¡å™¨çš„è¯¯å·®ï¼Œ\(\hat{y}_i^ğ‘ - y_i\)ï¼Œä»¥è¿›è¡Œæ¨¡å‹è°ƒæ•´ã€‚
- en: '![](../Images/fb1f17d4c2c24d97eb7c0121be84a79f.png)'
  id: totrans-850
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/fb1f17d4c2c24d97eb7c0121be84a79f.png)'
- en: Estimators in the ensemble of models, sharing the same number of leaf nodes
    hyperparameter.
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆæ¨¡å‹ä¸­çš„ä¼°è®¡å™¨å…±äº«ç›¸åŒæ•°é‡çš„å¶èŠ‚ç‚¹è¶…å‚æ•°ã€‚
- en: The result is a single measure of test error for each hyperparameter setting,
    for the case above with number of leaf nodes, we get this result,
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¯æ¯ä¸ªè¶…å‚æ•°è®¾ç½®çš„å•ä¸ªæµ‹è¯•è¯¯å·®åº¦é‡ï¼Œå¯¹äºä¸Šè¿°å¶èŠ‚ç‚¹æ•°é‡çš„æƒ…å†µï¼Œæˆ‘ä»¬å¾—åˆ°è¿™ä¸ªç»“æœï¼Œ
- en: '![](../Images/c1090b95f0977ae34559787c21ef3800.png)'
  id: totrans-853
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/c1090b95f0977ae34559787c21ef3800.png)'
- en: Ensemble test error vs. number of leaf nodes hyperparameter.
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆæµ‹è¯•è¯¯å·®ä¸å¶èŠ‚ç‚¹æ•°é‡è¶…å‚æ•°çš„å…³ç³»ã€‚
- en: to select the ensemble hyperparameter to minimize test error. For clarity, letâ€™s
    add the tuning to our previous training bagging models workflow,
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©é›†æˆè¶…å‚æ•°ä»¥æœ€å°åŒ–æµ‹è¯•è¯¯å·®ã€‚ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œè®©æˆ‘ä»¬å°†è°ƒæ•´æ·»åŠ åˆ°æˆ‘ä»¬ä¹‹å‰çš„è®­ç»ƒè¢‹è£…æ¨¡å‹å·¥ä½œæµç¨‹ä¸­ï¼Œ
- en: we loop over hyperparameters
  id: totrans-856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éå†è¶…å‚æ•°
- en: minimize the test error of the ensemble estimates
  id: totrans-857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€å°åŒ–é›†æˆä¼°è®¡çš„æµ‹è¯•è¯¯å·®
- en: '![](../Images/96ee3c145e994796c9a01d181704650c.png)'
  id: totrans-858
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/96ee3c145e994796c9a01d181704650c.png)'
- en: The workflow for tuning a bagging model.
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒæ•´è¢‹è£…æ¨¡å‹çš„å·¥ä½œæµç¨‹ã€‚
- en: Out-of-Bag Cross Validation
  id: totrans-860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‡ºè¢‹äº¤å‰éªŒè¯
- en: In expectation, \(\frac{1}{3}\) of the training data is left out of each bootstrap
    data realization, \(b^c\); therefore, cross-validation is built in.
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœŸæœ›å€¼ä¸Šï¼Œæ¯ä¸ªè‡ªåŠ©æ•°æ®å®ç°ä¸­ç•™ä¸‹ \(\frac{1}{3}\) çš„è®­ç»ƒæ•°æ®ï¼Œ\(b^c\)ï¼›å› æ­¤ï¼Œäº¤å‰éªŒè¯æ˜¯å†…ç½®çš„ã€‚
- en: Sample with replacement \(\frac{2}{3}\) of the training data (in expectation),
    \(Y^b, X_1^b, \dots, X_m^b\).
  id: totrans-862
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨æ›¿æ¢æ³•ä»è®­ç»ƒæ•°æ®ä¸­æŠ½å– \(\frac{2}{3}\) çš„æ ·æœ¬ï¼ˆæœŸæœ›å€¼ï¼‰ï¼Œ\(Y^b, X_1^b, \dots, X_m^b\)ã€‚
- en: Train an estimator with the \(\frac{2}{3}\) of training data (in expectation).
  id: totrans-863
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ \(\frac{2}{3}\) çš„è®­ç»ƒæ•°æ®ï¼ˆæœŸæœ›å€¼ï¼‰è®­ç»ƒä¼°è®¡å™¨ã€‚
- en: Predict at the out-of-bag samples, \(X_1^{b^c}, \dots, X_m^{b^c}\), \(\frac{1}{3}\)
    of the training data (in expectation).
  id: totrans-864
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å‡ºè¢‹æ ·æœ¬ \(X_1^{b^c}, \dots, X_m^{b^c}\)ï¼Œ\(\frac{1}{3}\) çš„è®­ç»ƒæ•°æ®ï¼ˆæœŸæœ›å€¼ï¼‰ä¸Šè¿›è¡Œé¢„æµ‹ã€‚
- en: '![](../Images/63c6819827d1a77f4c0cabcd47f88524.png)'
  id: totrans-865
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/63c6819827d1a77f4c0cabcd47f88524.png)'
- en: Out-of-bag error calculation workflow, to apply add to the hyperparameter tuning
    loop.
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºè¢‹é”™è¯¯è®¡ç®—å·¥ä½œæµç¨‹ï¼Œå°†å…¶æ·»åŠ åˆ°è¶…å‚æ•°è°ƒæ•´å¾ªç¯ä¸­ã€‚
- en: Pool the ğµ/3 predictions (in expectation) for each sample data from all the
    ğµ models and make an out-of-bag prediction, for regression,
  id: totrans-867
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ¥è‡ªæ‰€æœ‰ \(\mathbf{B}\) ä¸ªæ¨¡å‹çš„æ¯ä¸ªæ ·æœ¬æ•°æ®çš„ \(\mathbf{B}/3\) ä¸ªé¢„æµ‹ï¼ˆæœŸæœ›å€¼ï¼‰æ±‡æ€»ï¼Œå¹¶åšå‡ºå‡ºè¢‹é¢„æµ‹ï¼Œå¯¹äºå›å½’ï¼Œ
- en: \[ \hat{y}_\alpha^{\text{oob}} = \frac{1}{\left(\frac{B}{3}\right)} \sum_{b=1}^{\frac{B}{3}}
    \hat{y}_\alpha^{(b^c)} \]
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}_\alpha^{\text{oob}} = \frac{1}{\left(\frac{B}{3}\right)} \sum_{b=1}^{\frac{B}{3}}
    \hat{y}_\alpha^{(b^c)} \]
- en: Calculate the out-of-bag error to assess model performance.
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—å‡ºè¢‹è¯¯å·®ä»¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚
- en: \[ \text{MSE}_{\text{OOB}} = \frac{1}{n} \sum_{\alpha=1}^{n} \left[\hat{y}_\alpha^{\text{oob}}
    - y_\alpha \right]^2 \]
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{MSE}_{\text{OOB}} = \frac{1}{n} \sum_{\alpha=1}^{n} \left[\hat{y}_\alpha^{\text{oob}}
    - y_\alpha \right]^2 \]
- en: Number of Estimators
  id: totrans-871
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨æ•°é‡
- en: Number of Estimators is an important hyperparameter for bagging models
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨æ•°é‡æ˜¯è¢‹è£…æ¨¡å‹çš„ä¸€ä¸ªé‡è¦è¶…å‚æ•°
- en: '**More estimators** â€“ improve generalization up to a point, increasing the
    number of trees generally improves performance and reduces variance, as predictions
    are averaged across more models.'
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´å¤šä¼°è®¡å™¨** â€“ åœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå¢åŠ æ ‘çš„æ•°é‡é€šå¸¸å¯ä»¥æé«˜æ€§èƒ½å¹¶å‡å°‘æ–¹å·®ï¼Œå› ä¸ºé¢„æµ‹æ˜¯åœ¨æ›´å¤šæ¨¡å‹ä¸Šå¹³å‡çš„ã€‚'
- en: '**Diminishing returns** - beyond a point, adding more estimators gives little
    or no improvement and only increases computational cost.'
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€’å‡å›æŠ¥** - è¶…è¿‡ä¸€å®šç‚¹ï¼Œæ·»åŠ æ›´å¤šä¼°è®¡å™¨åªä¼šå¸¦æ¥å¾ˆå°‘æˆ–æ²¡æœ‰æ”¹è¿›ï¼Œå¹¶ä¸”åªä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚'
- en: '**Improved stability** - more trees reduce the likelihood of overfitting to
    random noise in the training set.'
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æé«˜ç¨³å®šæ€§** - æ›´å¤šæ ‘å‡å°‘äº†è¿‡åº¦æ‹Ÿåˆåˆ°è®­ç»ƒé›†ä¸­éšæœºå™ªå£°çš„å¯èƒ½æ€§ã€‚'
- en: '![](../Images/4ed3a0e3d2ee36395e6476183e806b8a.png)'
  id: totrans-876
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/4ed3a0e3d2ee36395e6476183e806b8a.png)'
- en: Number of estimators, few (upper) and more (lower), within the ensemble model.
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: é›†åˆæ¨¡å‹ä¸­ä¼°è®¡å™¨çš„æ•°é‡ï¼Œå°‘ï¼ˆä¸Šæ–¹ï¼‰å’Œå¤šï¼ˆä¸‹æ–¹ï¼‰ã€‚
- en: Estimator Complexity
  id: totrans-878
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨å¤æ‚æ€§
- en: The hyperparameter(s) shared by the estimators remain as important hyperparameters.
    Hereâ€™s guidance with a focus on tree bagging,
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡å™¨å…±äº«çš„è¶…å‚æ•°ä»ç„¶æ˜¯é‡è¦çš„è¶…å‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³äºæ ‘è¢‹çš„æŒ‡å¯¼ï¼Œ
- en: '**More complicated models** â€“ bagging reduces model variance, so we often train
    more complicated models for the ensemble.'
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ›´å¤æ‚çš„æ¨¡å‹** â€“ è¢‹è£…å‡å°‘äº†æ¨¡å‹æ–¹å·®ï¼Œå› æ­¤æˆ‘ä»¬é€šå¸¸ä¸ºé›†æˆè®­ç»ƒæ›´å¤æ‚çš„æ¨¡å‹ã€‚'
- en: '**Too simple models** â€“ may not see any improvement from bagging, because model
    variance is not an issue for simple models and does not need to be reduced.'
  id: totrans-881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿‡äºç®€å•çš„æ¨¡å‹** â€“ å¯èƒ½ä¸ä¼šä»è¢‹è£…ä¸­çœ‹åˆ°ä»»ä½•æ”¹è¿›ï¼Œå› ä¸ºå¯¹äºç®€å•æ¨¡å‹æ¥è¯´ï¼Œæ¨¡å‹æ–¹å·®ä¸æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿä¸éœ€è¦å‡å°‘ã€‚'
- en: '**Feature interactions** â€“ more complicated models capture more of the interactions
    between features, for example, tree bagging models with tree depth ğ‘‘ can capture
    ğ‘‘-way feature interactions'
  id: totrans-882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾äº¤äº’** â€“ æ›´å¤æ‚çš„æ¨¡å‹å¯ä»¥æ•æ‰æ›´å¤šç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œä¾‹å¦‚ï¼Œæ ‘è¢‹æ¨¡å‹ä¸­æ ‘æ·±åº¦ä¸º ğ‘‘ å¯ä»¥æ•æ‰ ğ‘‘ æ–¹ç‰¹å¾äº¤äº’ã€‚'
- en: '![](../Images/b5d39d63f35aded00e0a6d996fa7b353.png)'
  id: totrans-883
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/b5d39d63f35aded00e0a6d996fa7b353.png)'
- en: Ensembles with different tree depth hyperparameters, 2 (upper), 3 (middle) and
    4 (lower).
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰ä¸åŒçš„æ ‘æ·±åº¦è¶…å‚æ•°çš„é›†æˆï¼Œ2ï¼ˆä¸Šæ–¹ï¼‰ã€3ï¼ˆä¸­é—´ï¼‰å’Œ4ï¼ˆä¸‹æ–¹ï¼‰ã€‚
- en: Tree Bagging
  id: totrans-885
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‘è¢‹
- en: Now letâ€™s summarize the approach,
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹æ–¹æ³•ï¼Œ
- en: Build an ensemble of decision trees with multiple, bootstrap realizations of
    the data.
  id: totrans-887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ•°æ®çš„å¤šä¸ªè‡ªåŠ©é‡é‡‡æ ·æ„å»ºå†³ç­–æ ‘é›†æˆã€‚
- en: and provide some guidance,
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶æä¾›ä¸€äº›æŒ‡å¯¼ï¼Œ
- en: the ensemble of tree estimators reduces model variance
  id: totrans-889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ‘ä¼°è®¡å™¨çš„é›†æˆå‡å°‘äº†æ¨¡å‹æ–¹å·®ã€‚
- en: hyperparameter tune over the entire ensemble model, i.e., All trees in the ensemble
    have the same hyperparameters.
  id: totrans-890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ•´ä¸ªé›†æˆæ¨¡å‹ä¸Šè°ƒæ•´è¶…å‚æ•°ï¼Œå³ï¼Œé›†æˆä¸­çš„æ‰€æœ‰æ ‘éƒ½æœ‰ç›¸åŒçš„è¶…å‚æ•°ã€‚
- en: number of estimators is an additional, important hyperparameter in addition
    to the tree estimatorsâ€™ complexity
  id: totrans-891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤äº†æ ‘ä¼°è®¡å™¨çš„å¤æ‚æ€§ä¹‹å¤–ï¼Œä¼°è®¡å™¨çš„æ•°é‡æ˜¯ä¸€ä¸ªé¢å¤–çš„ã€é‡è¦çš„è¶…å‚æ•°ã€‚
- en: in expectation, $\frac{1}{3} of the data is not used for each tree, this provides
    the opportunity to have access to out-of-bag samples for cross validation, so
    we can build our model and cross validate with all the data at once, no train
    and test split.
  id: totrans-892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æœŸæœ›ä¸­ï¼Œæ¯æ£µæ ‘æœ‰ $\frac{1}{3}$ çš„æ•°æ®æœªè¢«ä½¿ç”¨ï¼Œè¿™æä¾›äº†è®¿é—®è¢‹å¤–æ ·æœ¬è¿›è¡Œäº¤å‰éªŒè¯çš„æœºä¼šï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä¸€æ¬¡æ€§ä½¿ç”¨æ‰€æœ‰æ•°æ®æ¥æ„å»ºæ¨¡å‹å¹¶è¿›è¡Œäº¤å‰éªŒè¯ï¼Œæ— éœ€è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²ã€‚
- en: overgrown trees will often outperform simpler trees due to reduction in model
    variance with averaging over the estimators.
  id: totrans-893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºä¼°è®¡å™¨å¹³å‡åŒ–å¯¼è‡´çš„æ¨¡å‹æ–¹å·®å‡å°‘ï¼Œè¿‡é•¿çš„æ ‘é€šå¸¸ä¼˜äºç®€å•çš„æ ‘ã€‚
- en: Spoiler Alert - we want the trees to be decorrelated, diverse to maximize the
    reduction in model variance, this leads to random forest. More on this later.
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
  zh: æ­ç¤ºè­¦æŠ¥ - æˆ‘ä»¬å¸Œæœ›æ ‘ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œå¤šæ ·åŒ–ä»¥æœ€å¤§åŒ–æ¨¡å‹æ–¹å·®çš„å‡å°‘ï¼Œè¿™å¯¼è‡´äº†éšæœºæ£®æ—ã€‚å…³äºè¿™ä¸€ç‚¹ç¨åè¿˜ä¼šè¯¦ç»†ä»‹ç»ã€‚
- en: To visualize tree bagging, hereâ€™s an example of tree bagging by-hand, 6 estimators
    from bootstrap realizations of the data, predicting over porosity and brittleness
    and the average over all the estimates as the bagging model.
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯è§†åŒ–æ ‘è¢‹ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæ‰‹åŠ¨æ ‘è¢‹çš„ä¾‹å­ï¼Œä»æ•°æ®çš„è‡ªåŠ©é‡é‡‡æ ·ä¸­å¾—åˆ°çš„6ä¸ªä¼°è®¡å™¨ï¼Œé¢„æµ‹å­”éš™ç‡å’Œè„†æ€§ï¼Œæ‰€æœ‰ä¼°è®¡çš„å¹³å‡å€¼ä½œä¸ºè¢‹è£…æ¨¡å‹ã€‚
- en: '![](../Images/88fba0db87ba8271f1b97819bfcf45b6.png)'
  id: totrans-896
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/88fba0db87ba8271f1b97819bfcf45b6.png)'
- en: 6 bootstrapped, complicated decision trees (left) and the bagging model, average
    of all 6 models (right).
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: 6ä¸ªè‡ªåŠ©å¤åˆ¶çš„å¤æ‚å†³ç­–æ ‘ï¼ˆå·¦ä¾§ï¼‰å’Œè¢‹è£…æ¨¡å‹ï¼Œæ‰€æœ‰6ä¸ªæ¨¡å‹çš„å¹³å‡å€¼ï¼ˆå³ä¾§ï¼‰ã€‚
- en: Observe the impact on the prediction model with the addition of more trees â€“
    transition from a discontinuous to continuous prediction model!
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€æ›´å¤šæ ‘çš„åŠ å…¥å¯¹é¢„æµ‹æ¨¡å‹çš„å½±å“ â€“ ä»ä¸è¿ç»­é¢„æµ‹æ¨¡å‹è¿‡æ¸¡åˆ°è¿ç»­é¢„æµ‹æ¨¡å‹ï¼
- en: '![](../Images/8c66db0c2607c6dd31082060dda55ace.png)'
  id: totrans-899
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/8c66db0c2607c6dd31082060dda55ace.png)'
- en: 6 tree bagging prediction models and all training data with increasing number
    of estimators, for 1, 3, 5, 10, 30 and 500 trees.
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: 6ä¸ªæ ‘è¢‹é¢„æµ‹æ¨¡å‹å’Œæ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œéšç€ä¼°è®¡å™¨æ•°é‡çš„å¢åŠ ï¼Œåˆ†åˆ«ä¸º1ã€3ã€5ã€10ã€30å’Œ500æ£µæ ‘ã€‚
- en: Observe the improved testing accuracy in cross validation with increasing number
    of trees,
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€æ ‘çš„æ•°é‡å¢åŠ ï¼Œäº¤å‰éªŒè¯ä¸­æµ‹è¯•ç²¾åº¦çš„æé«˜ï¼Œ
- en: '![](../Images/042efb5835a7679f992c4a08097693ad.png)'
  id: totrans-902
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/042efb5835a7679f992c4a08097693ad.png)'
- en: Cross validation with 6 tree bagging prediction models with increasing number
    of trees.
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨6ä¸ªæ ‘è¢‹é¢„æµ‹æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯ï¼Œæ ‘çš„æ•°é‡é€æ¸å¢åŠ ã€‚
- en: Observe the reduction in model variance with increasing number of trees,
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€æ ‘çš„æ•°é‡å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®å‡å°‘çš„æƒ…å†µï¼Œ
- en: '![](../Images/b40d9508fd3daba20f8724ac4dcfb8a5.png)'
  id: totrans-905
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/b40d9508fd3daba20f8724ac4dcfb8a5.png)'
- en: 3 models with 1 and 100 trees to demonstrate the reduction in model variance
    with increased ensemble aggregation.
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 3ä¸ªæ¨¡å‹ï¼Œåˆ†åˆ«æœ‰1æ£µå’Œ100æ£µæ ‘ï¼Œä»¥å±•ç¤ºéšç€é›†æˆèšåˆçš„å¢åŠ ï¼Œæ¨¡å‹æ–¹å·®çš„å‡å°‘ã€‚
- en: Random Forest
  id: totrans-907
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—
- en: A limitation with tree bagging is that the individual trees may be highly correlated.
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‘è¢‹çš„ä¸€ä¸ªå±€é™æ€§æ˜¯å•ä¸ªæ ‘å¯èƒ½é«˜åº¦ç›¸å…³ã€‚
- en: this occurs when there is a dominant predictor feature as it will always be
    applied to the top split(s), the result is all the trees in the ensemble are very
    similar (i.e., correlated)
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“å­˜åœ¨ä¸»å¯¼é¢„æµ‹ç‰¹å¾æ—¶ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œå› ä¸ºå®ƒå°†å§‹ç»ˆåº”ç”¨äºé¡¶éƒ¨åˆ†å‰²ï¼ˆsï¼‰ï¼Œç»“æœæ˜¯é›†æˆä¸­çš„æ‰€æœ‰æ ‘éƒ½éå¸¸ç›¸ä¼¼ï¼ˆå³ï¼Œç›¸å…³ï¼‰
- en: '![](../Images/d21f6ab27e26033ce1dd293c469b1851.png)'
  id: totrans-910
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d21f6ab27e26033ce1dd293c469b1851.png)'
- en: Highly correlated trees in a tree bagging ensemble model, trees with the same
    initial splits resulting in very similar predictions.
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ ‘è¢‹é›†æˆæ¨¡å‹ä¸­é«˜åº¦ç›¸å…³çš„æ ‘ï¼Œå…·æœ‰ç›¸åŒåˆå§‹åˆ†å‰²çš„æ ‘å¯¼è‡´éå¸¸ç›¸ä¼¼çš„é¢„æµ‹ã€‚
- en: With highly correlated trees, there is significantly less reduction in model
    variance with the ensemble,
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é«˜åº¦ç›¸å…³çš„æ ‘ä¸­ï¼Œé›†æˆæ¨¡å‹ä¸­çš„æ¨¡å‹æ–¹å·®å‡å°‘æ˜¾è‘—è¾ƒå°‘ï¼Œ
- en: consider, standard error in the mean assumes the samples ğ‘› are independent!
  id: totrans-913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°å¹³å‡æ ‡å‡†è¯¯å·®å‡è®¾æ ·æœ¬ ğ‘› æ˜¯ç‹¬ç«‹çš„ï¼
- en: \[ \sigma_{\bar{x}}^2 = \frac{\sigma_s^2}{n} \]
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma_{\bar{x}}^2 = \frac{\sigma_s^2}{n} \]
- en: correlation between samples reduces the ğ‘› to a ğ‘› effective, as correlation increases,
    \(n\) effectively is reduced.
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§å‡å°‘ \(n\) åˆ°æœ‰æ•ˆ \(n\)ï¼Œéšç€ç›¸å…³æ€§çš„å¢åŠ ï¼Œæœ‰æ•ˆ \(n\) å‡å°‘ã€‚
- en: Random forest is tree bagging, but for each split only a subset \(ğ‘\) of the
    \(ğ‘š\) available predictors are candidates for splits (selected at random).
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—æ˜¯æ ‘è¢‹ï¼Œä½†å¯¹äºæ¯ä¸ªåˆ†å‰²ï¼Œåªæœ‰ \(ğ‘š\) ä¸ªå¯ç”¨é¢„æµ‹å› å­ä¸­çš„å­é›† \(ğ‘\) æ˜¯åˆ†å‰²çš„å€™é€‰ï¼ˆéšæœºé€‰æ‹©ï¼‰ã€‚
- en: \[ p \ll m \]
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p \ll m \]
- en: This forces each tree in the ensemble to evolve in dissimilar manner,
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¿«ä½¿é›†æˆä¸­çš„æ¯ä¸€æ£µæ ‘ä»¥ä¸åŒçš„æ–¹å¼è¿›åŒ–ï¼Œ
- en: Common defaults for ğ‘ for classification,
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»ä¸­ \(ğ‘\) çš„å¸¸è§é»˜è®¤å€¼ï¼Œ
- en: \[ p = \sqrt{m} \quad \text{or} \quad \log_2(p) \]
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p = \sqrt{m} \quad \text{æˆ–} \quad \log_2(p) \]
- en: and for regression,
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå›å½’ï¼Œ
- en: \[ p=\frac{m}{3} \]
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p=\frac{m}{3} \]
- en: Lower \(p\) less correlation, better generalization, higher \(p\) more correlation,
    may overfit. note, too low \(p\) will underfit with high model bias
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: è¾ƒä½çš„ \(p\) è¡¨ç¤ºç›¸å…³æ€§è¾ƒä½ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå¥½ï¼Œè¾ƒé«˜çš„ \(p\) è¡¨ç¤ºç›¸å…³æ€§è¾ƒé«˜ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆã€‚æ³¨æ„ï¼Œ\(p\) è¿‡ä½ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆï¼Œæ¨¡å‹åå·®è¾ƒé«˜
- en: Hereâ€™s an example random forest model for the previous prediction problem,
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªç”¨äºå…ˆå‰é¢„æµ‹é—®é¢˜çš„éšæœºæ£®æ—æ¨¡å‹ç¤ºä¾‹ï¼Œ
- en: 300 trees, trained to a maximum depth of \(7\), \(ğ‘=1\), i.e., 1 predictor feature
    randomly selected for each split
  id: totrans-925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 300 æ£µæ ‘ï¼Œè®­ç»ƒåˆ°æœ€å¤§æ·±åº¦ä¸º \(7\)ï¼Œ\(ğ‘=1\)ï¼Œå³æ¯ä¸ªåˆ†å‰²éšæœºé€‰æ‹© 1 ä¸ªé¢„æµ‹ç‰¹å¾
- en: '![](../Images/8af256b868880607f4d3a18527c44eac.png)'
  id: totrans-926
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8af256b868880607f4d3a18527c44eac.png)'
- en: Highly correlated trees in a tree bagging ensemble model, trees with the same
    initial splits resulting in very similar predictions.
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ ‘è¢‹é›†æˆæ¨¡å‹ä¸­é«˜åº¦ç›¸å…³çš„æ ‘ï¼Œå…·æœ‰ç›¸åŒåˆå§‹åˆ†å‰²çš„æ ‘å¯¼è‡´éå¸¸ç›¸ä¼¼çš„é¢„æµ‹ã€‚
- en: Now we are ready to demonstrate tree bagging and random forest.
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡æ¼”ç¤ºæ ‘è¢‹å’Œéšæœºæ£®æ—ã€‚
- en: Load the Required Libraries
  id: totrans-929
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½æ‰€éœ€çš„åº“
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›æ ‡å‡†åŒ…ã€‚è¿™äº›åº”è¯¥å·²ç»ä¸ Anaconda 3 ä¸€èµ·å®‰è£…ã€‚
- en: '[PRE45]'
  id: totrans-931
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing â€˜python -m pip install [package-name]â€™. More assistance is available
    with the respective package docs.
  id: totrans-932
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨é‡åˆ°åŒ…å¯¼å…¥é”™è¯¯ï¼Œæ‚¨å¯èƒ½å¿…é¡»é¦–å…ˆå®‰è£…è¿™äº›åŒ…ä¸­çš„ä¸€äº›ã€‚è¿™é€šå¸¸å¯ä»¥é€šè¿‡åœ¨ Windows ä¸Šæ‰“å¼€å‘½ä»¤çª—å£ç„¶åè¾“å…¥â€˜python -m pip install
    [package-name]â€™æ¥å®Œæˆã€‚æœ‰å…³ç›¸åº”åŒ…çš„æ–‡æ¡£ï¼Œå¯ä»¥è·å¾—æ›´å¤šå¸®åŠ©ã€‚
- en: Declare Functions
  id: totrans-933
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å£°æ˜å‡½æ•°
- en: Letâ€™s define a couple of functions to streamline plotting correlation matrices
    and visualization of a decision, boosting tree and random forest regression model.
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å®šä¹‰å‡ ä¸ªå‡½æ•°æ¥ç®€åŒ–ç»˜åˆ¶ç›¸å…³çŸ©é˜µå’Œå†³ç­–ã€æå‡æ ‘å’Œéšæœºæ£®æ—å›å½’æ¨¡å‹çš„å¯è§†åŒ–ã€‚
- en: '[PRE46]'
  id: totrans-935
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Set the working directory
  id: totrans-936
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¾ç½®å·¥ä½œç›®å½•
- en: I always like to do this so I donâ€™t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å–œæ¬¢è¿™æ ·åšï¼Œè¿™æ ·æˆ‘å°±ä¸ä¼šä¸¢å¤±æ–‡ä»¶ï¼Œå¹¶ä¸”å¯ä»¥ç®€åŒ–åç»­çš„è¯»å–å’Œå†™å…¥ï¼ˆæ¯æ¬¡éƒ½é¿å…åŒ…å«å®Œæ•´åœ°å€ï¼‰ã€‚
- en: '[PRE47]'
  id: totrans-938
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: You will have to update the part in quotes with your own working directory and
    the format is different on a Mac (e.g. â€œ~/PGEâ€).
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å°†ä¸å¾—ä¸æ›´æ–°å¼•å·å†…çš„éƒ¨åˆ†ä»¥åŒ…å«æ‚¨è‡ªå·±çš„å·¥ä½œç›®å½•ï¼Œå¹¶ä¸”åœ¨ Mac ä¸Šæ ¼å¼ä¸åŒï¼ˆä¾‹å¦‚ï¼šâ€œ~/PGEâ€ï¼‰ã€‚
- en: Loading Data
  id: totrans-940
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®
- en: 'Letâ€™s load the provided multivariate, spatial dataset [unconv_MV.csv](https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv)
    available in my GeoDataSet repo. It is a comma delimited file with:'
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€ç©ºé—´æ•°æ®é›† [unconv_MV.csv](https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv)ï¼Œå®ƒä½äºæˆ‘çš„
    GeoDataSet ä»“åº“ä¸­ã€‚è¿™æ˜¯ä¸€ä¸ªä»¥é€—å·åˆ†éš”çš„æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
- en: well index (integer)
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•æŒ‡æ•°ï¼ˆæ•´æ•°ï¼‰
- en: porosity (%)
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­”éš™ç‡ï¼ˆ%ï¼‰
- en: permeability (\(mD\))
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡ (\(mD\))
- en: acoustic impedance (\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^6\)).
  id: totrans-945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ— (\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^6\))
- en: brittleness (%)
  id: totrans-946
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡ç‡ (%)
- en: total organic carbon (%)
  id: totrans-947
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€»æœ‰æœºç¢³å«é‡ (%)
- en: vitrinite reflectance (%)
  id: totrans-948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç…¤å²©åå°„ç‡ (%)
- en: initial gas production (90 day average) (MCFPD)
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆå§‹æ°”ä½“äº§é‡ï¼ˆ90 å¤©å¹³å‡ï¼‰(MCFPD)
- en: We load it with the pandas â€˜read_csvâ€™ function into a data frame we called â€˜dfâ€™
    and then preview it to make sure it loaded correctly.
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ pandas çš„â€˜read_csvâ€™å‡½æ•°å°†å…¶åŠ è½½åˆ°åä¸ºâ€˜dfâ€™çš„æ•°æ®æ¡†ä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚
- en: '**Python Tip: using functions from a package** just type the label for the
    package that we declared at the beginning:'
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python å°è´´å£«ï¼šä½¿ç”¨åŒ…ä¸­çš„å‡½æ•°**åªéœ€è¾“å…¥æˆ‘ä»¬åœ¨å¼€å¤´å£°æ˜çš„åŒ…çš„æ ‡ç­¾ï¼š'
- en: '[PRE48]'
  id: totrans-952
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'so we can access the pandas function â€˜read_csvâ€™ with the command:'
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‘½ä»¤è®¿é—® pandas å‡½æ•°â€˜read_csvâ€™ï¼š
- en: '[PRE49]'
  id: totrans-954
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: but read csv has required input parameters. The essential one is the name of
    the file. For our circumstance all the other default parameters are fine. If you
    want to see all the possible parameters for this function, just go to the docs
    [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).
  id: totrans-955
  prefs: []
  type: TYPE_NORMAL
  zh: ä½† read csv éœ€è¦è¾“å…¥å‚æ•°ã€‚æœ€é‡è¦çš„ä¸€ä¸ªæ˜¯æ–‡ä»¶åã€‚å¯¹äºæˆ‘ä»¬çš„æƒ…å†µï¼Œæ‰€æœ‰å…¶ä»–é»˜è®¤å‚æ•°éƒ½å¾ˆå¥½ã€‚å¦‚æœæ‚¨æƒ³æŸ¥çœ‹æ­¤å‡½æ•°çš„æ‰€æœ‰å¯èƒ½å‚æ•°ï¼Œè¯·å‚é˜…æ–‡æ¡£[æ­¤å¤„](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)ã€‚
- en: The docs are always helpful
  id: totrans-956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–‡æ¡£æ€»æ˜¯å¾ˆæœ‰å¸®åŠ©
- en: There is often a lot of flexibility for Python functions, possible through using
    various inputs parameters
  id: totrans-957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python å‡½æ•°é€šå¸¸æœ‰å¾ˆå¤šçµæ´»æ€§ï¼Œè¿™å¯ä»¥é€šè¿‡ä½¿ç”¨å„ç§è¾“å…¥å‚æ•°æ¥å®ç°ã€‚
- en: also, the program has an output, a pandas DataFrame loaded from the data. So
    we have to specify the name / variable representing that new object.
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œç¨‹åºæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œä¸€ä¸ªä»æ•°æ®åŠ è½½çš„ pandas DataFrameã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»æŒ‡å®šä»£è¡¨è¯¥æ–°å¯¹è±¡çš„åå­—/å˜é‡ã€‚
- en: '[PRE50]'
  id: totrans-959
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Letâ€™s run this command to load the data and then this command to extract a random
    subset of the data.
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œæ­¤å‘½ä»¤æ¥åŠ è½½æ•°æ®ï¼Œç„¶åè¿è¡Œæ­¤å‘½ä»¤æ¥æå–æ•°æ®çš„éšæœºå­é›†ã€‚
- en: '[PRE51]'
  id: totrans-961
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Feature Engineering
  id: totrans-962
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‰¹å¾å·¥ç¨‹
- en: 'Letâ€™s make some changes to the data to improve the workflow:'
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œä¸€äº›æ›´æ”¹ä»¥æ”¹è¿›å·¥ä½œæµç¨‹ï¼š
- en: '**Select the predictor features (x2) and the response feature (x1)**, make
    sure the metadata is also consistent.'
  id: totrans-964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€‰æ‹©é¢„æµ‹ç‰¹å¾ï¼ˆx2ï¼‰å’Œå“åº”ç‰¹å¾ï¼ˆx1ï¼‰**ï¼Œç¡®ä¿å…ƒæ•°æ®ä¹Ÿä¸€è‡´ã€‚'
- en: '**Metadata** encoding such as the units, labels and display ranges for each
    feature.'
  id: totrans-965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å…ƒæ•°æ®**ç¼–ç ï¼Œå¦‚æ¯ä¸ªç‰¹å¾çš„å•ä½ã€æ ‡ç­¾å’Œæ˜¾ç¤ºèŒƒå›´ã€‚'
- en: '**Reduce the number of data** for ease of visualization (hard to see if too
    many points on our plots).'
  id: totrans-966
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‡å°‘æ•°æ®æ•°é‡**ä»¥æ–¹ä¾¿å¯è§†åŒ–ï¼ˆå¦‚æœå›¾è¡¨ä¸Šçš„ç‚¹å¤ªå¤šå°±éš¾ä»¥çœ‹åˆ°ï¼‰ã€‚'
- en: '**Train and test data split** to demonstrate and visualize simple hyperparameter
    tuning.'
  id: totrans-967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²**ä»¥å±•ç¤ºå’Œå¯è§†åŒ–ç®€å•çš„è¶…å‚æ•°è°ƒæ•´ã€‚'
- en: '**Add random noise to the data** to demonstrate model overfit. The original
    data is error free and does not readily demonstrate overfit.'
  id: totrans-968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‘æ•°æ®æ·»åŠ éšæœºå™ªå£°**ä»¥å±•ç¤ºæ¨¡å‹è¿‡æ‹Ÿåˆã€‚åŸå§‹æ•°æ®æ— è¯¯å·®ä¸”ä¸æ˜“å±•ç¤ºè¿‡æ‹Ÿåˆã€‚'
- en: Given this is properly set, one should be able to use any dataset and features
    for this demonstration.
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾è¿™å·²ç»æ­£ç¡®è®¾ç½®ï¼Œé‚£ä¹ˆåº”è¯¥èƒ½å¤Ÿä½¿ç”¨ä»»ä½•æ•°æ®é›†å’Œç‰¹å¾è¿›è¡Œæ­¤æ¼”ç¤ºã€‚
- en: for brevity we donâ€™t show any feature selection here. Previous chapter, e.g.,
    k-nearest neighbours include some feature selection methods, but see the feature
    selection chapter for many possible methods with codes for feature selection.
  id: totrans-970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€æ´ï¼Œæˆ‘ä»¬è¿™é‡Œä¸å±•ç¤ºä»»ä½•ç‰¹å¾é€‰æ‹©ã€‚ä¾‹å¦‚ï¼Œå‰ä¸€ç« ä¸­çš„ k-æœ€è¿‘é‚»åŒ…æ‹¬ä¸€äº›ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œä½†è¯·å‚é˜…ç‰¹å¾é€‰æ‹©ç« èŠ‚ï¼Œä»¥äº†è§£è®¸å¤šå¯èƒ½çš„å¸¦æœ‰ç‰¹å¾é€‰æ‹©ä»£ç çš„æ–¹æ³•ã€‚
- en: 'Optional: Add Random Noise to the Response Feature'
  id: totrans-971
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯é€‰ï¼šå‘å“åº”ç‰¹å¾æ·»åŠ éšæœºå™ªå£°
- en: We can do this to observe the impact of data noise on overfit and hyperparameter
    tuning.
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™æ ·åšæ¥è§‚å¯Ÿæ•°æ®å™ªå£°å¯¹è¿‡æ‹Ÿåˆå’Œè¶…å‚æ•°è°ƒæ•´çš„å½±å“ã€‚
- en: This is for experiential learning, of course we wouldnâ€™t add random noise to
    our data
  id: totrans-973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸ºäº†ç»éªŒå­¦ä¹ ï¼Œå½“ç„¶æˆ‘ä»¬ä¸ä¼šå‘æˆ‘ä»¬çš„æ•°æ®æ·»åŠ éšæœºå™ªå£°
- en: We set the random number seed for reproducibility
  id: totrans-974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾ç½®äº†éšæœºæ•°ç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
- en: '[PRE52]'
  id: totrans-975
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Letâ€™s make sure that we have selected reasonable features to build a model
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¡®ä¿æˆ‘ä»¬å·²ç»é€‰æ‹©äº†åˆç†çš„ç‰¹å¾æ¥æ„å»ºæ¨¡å‹
- en: the 2 predictor features are not collinear, as this would result in an unstable
    prediction model
  id: totrans-977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªé¢„æµ‹ç‰¹å¾ä¸å…±çº¿æ€§ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´é¢„æµ‹æ¨¡å‹ä¸ç¨³å®š
- en: each of the features are related to the response feature, the predictor features
    inform the response
  id: totrans-978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªç‰¹å¾éƒ½ä¸å“åº”ç‰¹å¾ç›¸å…³ï¼Œé¢„æµ‹ç‰¹å¾å‘å“åº”ç‰¹å¾æä¾›ä¿¡æ¯
- en: Calculate the Correlation Matrix and Correlation with Response Ranking
  id: totrans-979
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¡ç®—ç›¸å…³çŸ©é˜µå’Œç›¸å…³å“åº”æ’å
- en: Letâ€™s start with correlation analysis. We can calculate and view the correlation
    matrix and correlation to the response features with these previously declared
    functions.
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ç›¸å…³æ€§åˆ†æå¼€å§‹ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¹‹å‰å£°æ˜çš„å‡½æ•°è®¡ç®—å¹¶æŸ¥çœ‹ç›¸å…³çŸ©é˜µå’Œç›¸å…³å“åº”ç‰¹å¾ã€‚
- en: correlation analysis is based on the assumption of linear relationships, but
    it is a good start
  id: totrans-981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸å…³æ€§åˆ†æåŸºäºçº¿æ€§å…³ç³»çš„å‡è®¾ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªè‰¯å¥½çš„å¼€å§‹
- en: '[PRE53]'
  id: totrans-982
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png](../Images/fe078f42023f81da1972474b1d3bbf26.png)'
  id: totrans-983
  prefs: []
  type: TYPE_IMG
  zh: '![_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png](../Images/fe078f42023f81da1972474b1d3bbf26.png)'
- en: Note the 1.0 diagonal resulting from the correlation of each variable with themselves.
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ç”±äºæ¯ä¸ªå˜é‡ä¸å…¶è‡ªèº«çš„ç›¸å…³æ€§è€Œäº§ç”Ÿçš„ 1.0 å¯¹è§’çº¿ã€‚
- en: This looks good. There is a mix of correlation magnitudes. Of course, correlation
    coefficients are limited to degree of linear correlations.
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥ä¸é”™ã€‚å­˜åœ¨ä¸åŒå¤§å°çš„ç›¸å…³æ€§ã€‚å½“ç„¶ï¼Œç›¸å…³ç³»æ•°ä»…é™äºçº¿æ€§ç›¸å…³ç¨‹åº¦ã€‚
- en: Letâ€™s look at the matrix scatter plot to see the pairwise relationship between
    the features.
  id: totrans-986
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŸ¥çœ‹çŸ©é˜µæ•£ç‚¹å›¾ï¼Œä»¥æŸ¥çœ‹ç‰¹å¾ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚
- en: '[PRE54]'
  id: totrans-987
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '![_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png](../Images/515a70a53d49c49c9ecf98249cd67b5d.png)'
  id: totrans-988
  prefs: []
  type: TYPE_IMG
  zh: '![_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png](../Images/515a70a53d49c49c9ecf98249cd67b5d.png)'
- en: Train and Test Split
  id: totrans-989
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œæµ‹è¯•æ‹†åˆ†
- en: Since we are working with ensemble methods the train and test split is built
    into the model training with out-of-bag samples.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨é›†æˆæ–¹æ³•ï¼Œå› æ­¤è®­ç»ƒå’Œæµ‹è¯•æ‹†åˆ†å·²å†…ç½®åˆ°æ¨¡å‹è®­ç»ƒä¸­ï¼Œä½¿ç”¨è¢‹å¤–æ ·æœ¬ã€‚
- en: we will work with the entire dataset
  id: totrans-991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å¤„ç†æ•´ä¸ªæ•°æ®é›†
- en: note, we could split a testing dataset for the train, validate, test approach.
    For simplicity I only use train and test in these workflows.
  id: totrans-992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ–¹æ³•æ‹†åˆ†æµ‹è¯•æ•°æ®é›†ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘åœ¨è¿™é¡¹å·¥ä½œæµç¨‹ä¸­åªä½¿ç”¨è®­ç»ƒå’Œæµ‹è¯•ã€‚
- en: Visualize the DataFrame
  id: totrans-993
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯è§†åŒ– DataFrame
- en: Visualizing the train and test DataFrame is useful check before we build our
    models.
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬æ„å»ºæ¨¡å‹ä¹‹å‰ï¼Œå¯è§†åŒ–è®­ç»ƒå’Œæµ‹è¯• DataFrame æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ£€æŸ¥ã€‚
- en: many things can go wrong, e.g., we loaded the wrong data, all the features did
    not load, etc.
  id: totrans-995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¸å¤šäº‹æƒ…å¯èƒ½ä¼šå‡ºé”™ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬åŠ è½½äº†é”™è¯¯çš„æ•°æ®ï¼Œæ‰€æœ‰ç‰¹å¾éƒ½æ²¡æœ‰åŠ è½½ï¼Œç­‰ç­‰ã€‚
- en: We can preview by utilizing the â€˜headâ€™ DataFrame member function (with a nice
    and clean format, see below).
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ©ç”¨ 'head' DataFrame æˆå‘˜å‡½æ•°ï¼ˆæ ¼å¼æ•´æ´ã€ç¾è§‚ï¼Œè§ä¸‹æ–‡ï¼‰æ¥é¢„è§ˆã€‚
- en: '[PRE55]'
  id: totrans-997
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '|  | Por | Brittle | Production |'
  id: totrans-998
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Brittle | Production |'
- en: '| --- | --- | --- | --- |'
  id: totrans-999
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 7.22 | 63.09 | 2006.074005 |'
  id: totrans-1000
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 7.22 | 63.09 | 2006.074005 |'
- en: '| 1 | 13.01 | 50.41 | 4244.321703 |'
  id: totrans-1001
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 13.01 | 50.41 | 4244.321703 |'
- en: '| 2 | 10.03 | 37.74 | 2493.189177 |'
  id: totrans-1002
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 10.03 | 37.74 | 2493.189177 |'
- en: '| 3 | 18.10 | 56.09 | 6124.075271 |'
  id: totrans-1003
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 18.10 | 56.09 | 6124.075271 |'
- en: '| 4 | 16.95 | 61.43 | 5951.336259 |'
  id: totrans-1004
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 16.95 | 61.43 | 5951.336259 |'
- en: Summary Statistics for Tabular Data
  id: totrans-1005
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¡¨æ ¼æ•°æ®çš„æ±‡æ€»ç»Ÿè®¡
- en: There are a lot of efficient methods to calculate summary statistics from tabular
    data in DataFrames.
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ DataFrames ä¸­ä»è¡¨æ ¼æ•°æ®è®¡ç®—æ±‡æ€»ç»Ÿè®¡æœ‰å¾ˆå¤šé«˜æ•ˆçš„æ–¹æ³•ã€‚
- en: The describe command provides count, mean, minimum, maximum, percentiles in
    a nice data table.
  id: totrans-1007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: describe å‘½ä»¤ä»¥æ•°æ®è¡¨çš„å½¢å¼æä¾›è®¡æ•°ã€å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼ã€ç™¾åˆ†ä½æ•°ã€‚
- en: '[PRE56]'
  id: totrans-1008
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '|  | Por | Brittle | Production |'
  id: totrans-1009
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Brittle | Production |'
- en: '| --- | --- | --- | --- |'
  id: totrans-1010
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| count | 140.000000 | 140.000000 | 140.000000 |'
  id: totrans-1011
  prefs: []
  type: TYPE_TB
  zh: '| count | 140.000000 | 140.000000 | 140.000000 |'
- en: '| mean | 14.897357 | 48.345429 | 4273.644226 |'
  id: totrans-1012
  prefs: []
  type: TYPE_TB
  zh: '| mean | 14.897357 | 48.345429 | 4273.644226 |'
- en: '| std | 3.181639 | 14.157619 | 1138.466092 |'
  id: totrans-1013
  prefs: []
  type: TYPE_TB
  zh: '| std | 3.181639 | 14.157619 | 1138.466092 |'
- en: '| min | 6.550000 | 10.940000 | 1517.373571 |'
  id: totrans-1014
  prefs: []
  type: TYPE_TB
  zh: '| min | 6.550000 | 10.940000 | 1517.373571 |'
- en: '| 10% | 10.866000 | 28.853000 | 2957.573690 |'
  id: totrans-1015
  prefs: []
  type: TYPE_TB
  zh: '| 10% | 10.866000 | 28.853000 | 2957.573690 |'
- en: '| 50% | 14.855000 | 50.735000 | 4315.186629 |'
  id: totrans-1016
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 14.855000 | 50.735000 | 4315.186629 |'
- en: '| 90% | 18.723000 | 65.813000 | 5815.526968 |'
  id: totrans-1017
  prefs: []
  type: TYPE_TB
  zh: '| 90% | 18.723000 | 65.813000 | 5815.526968 |'
- en: '| max | 23.550000 | 84.330000 | 6907.632261 |'
  id: totrans-1018
  prefs: []
  type: TYPE_TB
  zh: '| max | 23.550000 | 84.330000 | 6907.632261 |'
- en: It is good that we checked the summary statistics.
  id: totrans-1019
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ£€æŸ¥äº†æ±‡æ€»ç»Ÿè®¡æ˜¯ä»¶å¥½äº‹ã€‚
- en: there are no obvious issues
  id: totrans-1020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ²¡æœ‰æ˜æ˜¾çš„é”™è¯¯
- en: check out the range of values for each feature to set up and adjust plotting
    limits. See above.
  id: totrans-1021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ¯ä¸ªç‰¹å¾å€¼çš„èŒƒå›´ï¼Œä»¥è®¾ç½®å’Œè°ƒæ•´ç»˜å›¾é™åˆ¶ã€‚è§ä¸Šå›¾ã€‚
- en: Visualize the Distributions
  id: totrans-1022
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–åˆ†å¸ƒ
- en: Letâ€™s check the histograms and scatter plots of the predictor features.
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ£€æŸ¥é¢„æµ‹ç‰¹å¾çš„ç›´æ–¹å›¾å’Œæ•£ç‚¹å›¾ã€‚
- en: check to make sure the data cover the range of possible predictor feature combinations
  id: totrans-1024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ•°æ®æ˜¯å¦è¦†ç›–äº†å¯èƒ½çš„é¢„æµ‹ç‰¹å¾ç»„åˆèŒƒå›´
- en: check that the predictor features are not highly correlated, collinear, as this
    increases model variance
  id: totrans-1025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥é¢„æµ‹ç‰¹å¾ä¸æ˜¯é«˜åº¦ç›¸å…³ã€å…±çº¿çš„ï¼Œå› ä¸ºè¿™ä¼šå¢åŠ æ¨¡å‹æ–¹å·®
- en: '[PRE57]'
  id: totrans-1026
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '![_images/c9e941b61d19ec872e32d0b10c48a28622e57437ff6fa45205763cc62773906a.png](../Images/3afbd7af1752bc8c73a552f17ebbfd8d.png)'
  id: totrans-1027
  prefs: []
  type: TYPE_IMG
  zh: '![_images/c9e941b61d19ec872e32d0b10c48a28622e57437ff6fa45205763cc62773906a.png](../Images/3afbd7af1752bc8c73a552f17ebbfd8d.png)'
- en: Once again, the distributions are well behaved,
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œåˆ†å¸ƒè¡¨ç°è‰¯å¥½ï¼Œ
- en: we cannot observe obvious gaps nor truncations.
  id: totrans-1029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ— æ³•è§‚å¯Ÿåˆ°æ˜æ˜¾çš„ç¼ºå£æˆ–æˆªæ–­ã€‚
- en: the predictor features are not highly correlated
  id: totrans-1030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç‰¹å¾ä¹‹é—´æ²¡æœ‰é«˜åº¦ç›¸å…³æ€§
- en: Letâ€™s look at a scatter plot of Porosity vs. Brittleness with points colored
    by Production.
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å­”éš™ç‡ä¸è„†æ€§ç›¸å¯¹äºäº§é‡çš„æ•£ç‚¹å›¾ã€‚
- en: to visualize the prediction problem, i.e., the shape of the system
  id: totrans-1032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯è§†åŒ–é¢„æµ‹é—®é¢˜ï¼Œå³ç³»ç»Ÿçš„å½¢çŠ¶
- en: '[PRE58]'
  id: totrans-1033
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '![_images/6980039b0d3453603a0540f6ba29b6b821be9104ac38a6c3b26a9b0a9cd5a007.png](../Images/872ca67d7fc1098e9ee39b83f936887b.png)'
  id: totrans-1034
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/872ca67d7fc1098e9ee39b83f936887b.png)'
- en: Ensemble Tree Method - Tree Bagging Regression
  id: totrans-1035
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆæ ‘æ–¹æ³• - æ ‘è¢‹è£…å›å½’
- en: 'We are ready to build a tree bagging model. To perform tree bagging we:'
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡†å¤‡å¥½æ„å»ºä¸€ä¸ªæ ‘è¢‹è£…æ¨¡å‹ã€‚è¦æ‰§è¡Œæ ‘è¢‹è£…ï¼Œæˆ‘ä»¬ï¼š
- en: set the hyperparameters for the individual trees
  id: totrans-1037
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®å•ä¸ªæ ‘çš„è¶…å‚æ•°
- en: '[PRE59]'
  id: totrans-1038
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: instantiate an individual regression tree
  id: totrans-1039
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ä¾‹åŒ–ä¸€ä¸ªå•ç‹¬çš„å›å½’æ ‘
- en: '[PRE60]'
  id: totrans-1040
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: set the bagging hyperparameters
  id: totrans-1041
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®è¢‹è£…è¶…å‚æ•°
- en: '[PRE61]'
  id: totrans-1042
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: instantiate the bagging regressor with the previously instantiated regression
    tree (wrapping the decision tree)
  id: totrans-1043
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å…ˆå‰å®ä¾‹åŒ–çš„å›å½’æ ‘ï¼ˆåŒ…è£…å†³ç­–æ ‘ï¼‰å®ä¾‹åŒ–è¢‹è£…å›å½’å™¨
- en: '[PRE62]'
  id: totrans-1044
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: train the bagging regression (wrapping the decision tree)
  id: totrans-1045
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®­ç»ƒè¢‹è£…å›å½’ï¼ˆå†³ç­–æ ‘çš„åŒ…è£…ï¼‰
- en: '[PRE63]'
  id: totrans-1046
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: visualize the model result over the feature space (easy to do as we have only
    2 predictor features)
  id: totrans-1047
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–ç‰¹å¾ç©ºé—´ä¸Šçš„æ¨¡å‹ç»“æœï¼ˆç”±äºæˆ‘ä»¬åªæœ‰2ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œè¿™å¾ˆå®¹æ˜“åšåˆ°ï¼‰
- en: Demonstration of Bagging by-Hand
  id: totrans-1048
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰‹åŠ¨è¢‹è£…æ¼”ç¤º
- en: For demonstration of by-hand tree bagging letâ€™s set the number of trees to 1
    and run tree bagging regression 6 times.
  id: totrans-1049
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¼”ç¤ºæ‰‹åŠ¨æ ‘è¢‹è£…ï¼Œè®©æˆ‘ä»¬å°†æ ‘çš„æ•°é‡è®¾ç½®ä¸º1ï¼Œå¹¶è¿è¡Œ6æ¬¡æ ‘è¢‹è£…å›å½’ã€‚
- en: the result for each is a single complicated decision tree
  id: totrans-1050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªçš„ç»“æœæ˜¯ä¸€æ£µå•ç‹¬çš„å¤æ‚å†³ç­–æ ‘
- en: note, the random_state parameter is the random number seed for the bootstrap
    in the bagging method
  id: totrans-1051
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œrandom_stateå‚æ•°æ˜¯è¢‹è£…æ–¹æ³•ä¸­è‡ªåŠ©é‡‡æ ·çš„éšæœºæ•°ç§å­
- en: the trees vary for each random number seed since the bootstrapped dataset will
    be different for each
  id: totrans-1052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºæ¯ä¸ªéšæœºæ•°ç§å­éƒ½ä¼šç”Ÿæˆä¸åŒçš„è‡ªåŠ©æ•°æ®é›†ï¼Œå› æ­¤æ ‘ä¼šå› æ¯ä¸ªéšæœºæ•°ç§å­è€Œå¼‚
- en: We will loop over the models and store each of them in an list of models.
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†éå†æ¨¡å‹å¹¶å°†æ¯ä¸ªæ¨¡å‹å­˜å‚¨åœ¨ä¸€ä¸ªæ¨¡å‹åˆ—è¡¨ä¸­ã€‚
- en: '[PRE64]'
  id: totrans-1054
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '![_images/eea5b5097df4ef4a221f3d871149c4a47c31d4898b463afa9acc7b2d628ea79f.png](../Images/31276b65834e695aebb5de91a9019af9.png)'
  id: totrans-1055
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/31276b65834e695aebb5de91a9019af9.png)'
- en: Notice the data changes for each model,
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æ¯ä¸ªæ¨¡å‹çš„æ•°æ®å˜åŒ–ï¼Œ
- en: we have bootstrapped the dataset so some of the data are missing and others
    are used 2 or more times
  id: totrans-1057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»å¯¹æ•°æ®é›†è¿›è¡Œäº†è‡ªåŠ©é‡‡æ ·ï¼Œå› æ­¤ä¸€äº›æ•°æ®ä¸¢å¤±ï¼Œå…¶ä»–æ•°æ®è¢«ä½¿ç”¨äº†2æ¬¡æˆ–æ›´å¤šæ¬¡
- en: recall, in expectation, only 2/3 of the data are used for each tree, and 1/3
    is out-of-bag
  id: totrans-1058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æœŸæœ›ä¸­ï¼Œåªæœ‰2/3çš„æ•°æ®ç”¨äºæ¯ä¸ªæ ‘ï¼Œ1/3æ˜¯è¢‹å¤–æ•°æ®
- en: Letâ€™s check the cross validation results with the out-of-bag data.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ£€æŸ¥å¸¦æœ‰è¢‹å¤–æ•°æ®çš„äº¤å‰éªŒè¯ç»“æœã€‚
- en: '[PRE65]'
  id: totrans-1060
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '![_images/783d535af6b2da8c5c69b4db7d4c9baff9168424e9c07006449e47e66dc7c771.png](../Images/efaec048c6783e5270a3de45c28fb832.png)'
  id: totrans-1061
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/efaec048c6783e5270a3de45c28fb832.png)'
- en: Now letâ€™s demonstrate the averaging of the predictions over the 6 decision trees,
    we are performing bagging tree prediction by-hand to clearly demonstrate the method.
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¼”ç¤º6ä¸ªå†³ç­–æ ‘çš„é¢„æµ‹å¹³å‡ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æ‰§è¡Œè¢‹è£…æ ‘é¢„æµ‹ä»¥æ¸…æ¥šåœ°å±•ç¤ºè¯¥æ–¹æ³•ã€‚
- en: we average the predicted response feature (production) over the discretized
    predictor feature space
  id: totrans-1063
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç¦»æ•£åŒ–é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šå¹³å‡é¢„æµ‹å“åº”ç‰¹å¾ï¼ˆäº§é‡ï¼‰
- en: we can take advantage of broadcast methods for operations on entire arrays
  id: totrans-1064
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ©ç”¨å¹¿æ’­æ–¹æ³•å¯¹æ•´ä¸ªæ•°ç»„è¿›è¡Œæ“ä½œ
- en: we will apply the same model check, but we will use a modified function to will
    read in the response feature 2D array, instead of a model
  id: totrans-1065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åº”ç”¨ç›¸åŒçš„æ¨¡å‹æ£€æŸ¥ï¼Œä½†æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªä¿®æ”¹åçš„å‡½æ•°æ¥è¯»å–å“åº”ç‰¹å¾2Dæ•°ç»„ï¼Œè€Œä¸æ˜¯æ¨¡å‹
- en: '[PRE66]'
  id: totrans-1066
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '![_images/f20a801dbb20a98a7b2ad7c35c59f481b086f7e243c708954eaafbad1eeac330.png](../Images/e53f12af38e9579211e007a9e5ad0273.png)'
  id: totrans-1067
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/e53f12af38e9579211e007a9e5ad0273.png)'
- en: We made 6 complicated trees, each trained with bootstrap resamples of the original
    data and then averaged the predictions from each.
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ¶ä½œäº†6ä¸ªå¤æ‚çš„æ ‘ï¼Œæ¯ä¸ªæ ‘éƒ½ä½¿ç”¨åŸå§‹æ•°æ®çš„è‡ªåŠ©æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œç„¶åå¹³å‡æ¯ä¸ªæ ‘çš„é¢„æµ‹ã€‚
- en: the result is more smooth - lower model variance
  id: totrans-1069
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“æœæ›´åŠ å¹³æ»‘ - æ¨¡å‹æ–¹å·®æ›´ä½
- en: the result more closely matches the training data
  id: totrans-1070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“æœæ›´æ¥è¿‘è®­ç»ƒæ•°æ®
- en: Demonstration of Bagging with Increasing Number of Trees
  id: totrans-1071
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¢åŠ æ ‘æ•°é‡çš„è¢‹è£…æ¼”ç¤º
- en: For demonstration, letâ€™s build 6 bagging tree regression models with increasing
    number of overly complicated (and likely overfit) trees averaged.
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¼”ç¤ºï¼Œè®©æˆ‘ä»¬æ„å»º6ä¸ªè¢‹è£…æ ‘å›å½’æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å…·æœ‰ä¸æ–­å¢åŠ çš„è¿‡äºå¤æ‚ï¼ˆå¹¶ä¸”å¯èƒ½è¿‡æ‹Ÿåˆï¼‰çš„æ ‘çš„å¹³å‡å€¼ã€‚
- en: with the bagging regressor from scikit learn this is automated with the â€˜num_treeâ€™
    hyperparameter
  id: totrans-1073
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨scikit learnçš„è¢‹è£…å›å½’å™¨ï¼Œè¿™å¯ä»¥é€šè¿‡â€˜num_treeâ€™è¶…å‚æ•°è‡ªåŠ¨å®Œæˆ
- en: We will loop over the models and store each of them in an list of models again!
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†éå†æ¨¡å‹å¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨æ¨¡å‹åˆ—è¡¨ä¸­ï¼
- en: '[PRE67]'
  id: totrans-1075
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '![_images/e9e7848dcfd2d82704e1e1d9b3907be8d850b9056a7478092436d1d3dd0376bb.png](../Images/349923f1fbb703de6e34e449aa5461aa.png)'
  id: totrans-1076
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/349923f1fbb703de6e34e449aa5461aa.png)'
- en: Observe the impact of averaging an increasing number of trees.
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿå¹³å‡å¢åŠ çš„æ ‘çš„æ•°é‡å¯¹æ¨¡å‹çš„å½±å“ã€‚
- en: we transition from a discontinuous response prediction model to a smooth prediction
    model (the jumps are smoothed out)
  id: totrans-1078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»æ–­ç»­çš„å“åº”é¢„æµ‹æ¨¡å‹è¿‡æ¸¡åˆ°å¹³æ»‘çš„é¢„æµ‹æ¨¡å‹ï¼ˆè·³è·ƒè¢«å¹³æ»‘äº†ï¼‰
- en: Letâ€™s repeat the modeling cross validation step with the withheld testing data.
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ä¿ç•™çš„æµ‹è¯•æ•°æ®é‡å¤å»ºæ¨¡äº¤å‰éªŒè¯æ­¥éª¤ã€‚
- en: '[PRE68]'
  id: totrans-1080
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '![_images/897537eef68fdc77ecefa72c0cf2f943ddf6dd1f8cb70e99a54d498f9c901116.png](../Images/e9bf860174405c58ee5d3b39292d0e44.png)'
  id: totrans-1081
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/e9bf860174405c58ee5d3b39292d0e44.png)'
- en: See the improvement with testing accuracy with increasing level of ensemble
    model averaging?
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿéšç€é›†æˆæ¨¡å‹å¹³å‡æ°´å¹³çš„å¢åŠ ï¼Œæµ‹è¯•å‡†ç¡®æ€§çš„æ”¹è¿›ï¼Ÿ
- en: Letâ€™s run many cases and check the accuracy vs. number of trees.
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿è¡Œè®¸å¤šæ¡ˆä¾‹å¹¶æ£€æŸ¥å‡†ç¡®æ€§ä¸æ ‘çš„æ•°é‡ä¹‹é—´çš„å…³ç³»ã€‚
- en: '[PRE69]'
  id: totrans-1084
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '![_images/20cacfb6fdbc25ddeb7189cfe3d06ce924ab316613a2ab54a7cf162211ee6ca9.png](../Images/b32b7809d8b78abb96826fd4f0392d2b.png)'
  id: totrans-1085
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/b32b7809d8b78abb96826fd4f0392d2b.png)'
- en: The number of trees improves model accuracy through reduction in model variance.
    Letâ€™s actually observe this reduction in model variance with an experiment.
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‘çš„æ•°é‡é€šè¿‡å‡å°‘æ¨¡å‹æ–¹å·®æ¥æé«˜æ¨¡å‹å‡†ç¡®æ€§ã€‚è®©æˆ‘ä»¬é€šè¿‡å®éªŒå®é™…è§‚å¯Ÿè¿™ç§æ¨¡å‹æ–¹å·®å‡å°‘ã€‚
- en: Model Variance vs. Ensemble Model Averaging
  id: totrans-1087
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ–¹å·®ä¸é›†æˆæ¨¡å‹å¹³å‡
- en: Letâ€™s see the change in model variance through model averaging, we will compare
    multiple models with different numbers of trees averaged.
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡æ¨¡å‹å¹³å‡æ¥æŸ¥çœ‹æ¨¡å‹æ–¹å·®çš„å˜åŒ–ï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒå…·æœ‰ä¸åŒæ ‘å¹³å‡æ•°é‡çš„å¤šä¸ªæ¨¡å‹ã€‚
- en: we accomplish this by visual comparison, letâ€™s look at different bagging modeling
    through changing the random number seed
  id: totrans-1089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡è§†è§‰æ¯”è¾ƒæ¥å®Œæˆè¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬é€šè¿‡æ”¹å˜éšæœºæ•°ç§å­æ¥æŸ¥çœ‹ä¸åŒçš„è¢‹è£…å»ºæ¨¡
- en: '[PRE70]'
  id: totrans-1090
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '![_images/b98738c95478440ea08fddbeba7798bc726e6077288dbed59915ba84d147fdd9.png](../Images/d419947c372df1ff5fa41d90a33dde05.png)'
  id: totrans-1091
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡é“¾æ¥](../Images/d419947c372df1ff5fa41d90a33dde05.png)'
- en: 'As we increase the number of decision trees averaged for the bagged tree regression
    models:'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æˆ‘ä»¬å¢åŠ ç”¨äºè¢‹è£…æ ‘å›å½’æ¨¡å‹çš„å¹³å‡å†³ç­–æ ‘çš„æ•°é‡ï¼š
- en: once again, the response predictions over the predictor feature space gets more
    smooth
  id: totrans-1093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œå“åº”é¢„æµ‹åœ¨é¢„æµ‹ç‰¹å¾ç©ºé—´ä¸Šå˜å¾—æ›´åŠ å¹³æ»‘
- en: the multiple realizations of the model start to converge, this is lower model
    variance
  id: totrans-1094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„å¤šç§å®ç°å¼€å§‹æ”¶æ•›ï¼Œè¿™æ˜¯è¾ƒä½çš„æ¨¡å‹æ–¹å·®
- en: Random Forest
  id: totrans-1095
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—
- en: With random forest we limit the number of features considered for each split.
    Note, in scikit learn the default is \(\frac{m}{3}\). Use this hyperparameter
    to set to square root of the number of predictor features. Another common alternative
    in practice \(\sqrt{m}\).
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨éšæœºæ£®æ—ä¸­ï¼Œæˆ‘ä»¬é™åˆ¶äº†æ¯ä¸ªåˆ†å‰²è€ƒè™‘çš„ç‰¹å¾æ•°é‡ã€‚æ³¨æ„ï¼Œåœ¨scikit learnä¸­é»˜è®¤æ˜¯ \(\frac{m}{3}\)ã€‚ä½¿ç”¨æ­¤è¶…å‚æ•°å°†å…¶è®¾ç½®ä¸ºé¢„æµ‹ç‰¹å¾æ•°é‡çš„å¹³æ–¹æ ¹ã€‚å®è·µä¸­å¦ä¸€ä¸ªå¸¸è§çš„æ›¿ä»£æ–¹æ¡ˆ
    \(\sqrt{m}\)ã€‚
- en: '[PRE71]'
  id: totrans-1097
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: This forces tree diversity / decorrelates the trees.
  id: totrans-1098
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¿«ä½¿æ ‘å¤šæ ·åŒ–/å»ç›¸å…³æ ‘ã€‚
- en: recall the model variance reduced by averaging over multiple decision trees
    \(Y = \frac{1}{B} \sum_{b=1}^{B} Y^b(X_1^b,...,X_m^b)\)
  id: totrans-1099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›å¿†ä¸€ä¸‹ï¼Œé€šè¿‡åœ¨å¤šä¸ªå†³ç­–æ ‘ä¸Šå¹³å‡æ¥å‡å°‘æ¨¡å‹æ–¹å·® \(Y = \frac{1}{B} \sum_{b=1}^{B} Y^b(X_1^b,...,X_m^b)\)
- en: recall from the [spatial bootstrap workflow](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/SubsurfaceDataAnalytics_Spatial_Bootstrap.ipynb)
    that correlation of samples being averaged attenuates the variance reduction
  id: totrans-1100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»[ç©ºé—´è‡ªåŠ©å·¥ä½œæµç¨‹](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/SubsurfaceDataAnalytics_Spatial_Bootstrap.ipynb)ä¸­å›å¿†ï¼Œå¹³å‡æ ·æœ¬çš„ç›¸å…³æ€§ä¼šå‡å¼±æ–¹å·®å‡å°‘
- en: Letâ€™s experiment with random forest to demonstrate this.
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡éšæœºæ£®æ—æ¥æ¼”ç¤ºè¿™ä¸€ç‚¹ã€‚
- en: Set the hyperparameters.
  id: totrans-1102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®è¶…å‚æ•°ã€‚
- en: Even if I am just running one model, I set the random number seed to ensure
    I have a deterministic model, a model that can be rerun to get the same result
    every time. If the random number seed is not set, then it is likely set based
    on the system time.
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æˆ‘åªè¿è¡Œä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä¹Ÿä¼šè®¾ç½®éšæœºæ•°ç§å­ä»¥ç¡®ä¿æˆ‘æœ‰ä¸€ä¸ªç¡®å®šæ€§çš„æ¨¡å‹ï¼Œä¸€ä¸ªæ¯æ¬¡é‡æ–°è¿è¡Œéƒ½èƒ½å¾—åˆ°ç›¸åŒç»“æœçš„æ¨¡å‹ã€‚å¦‚æœæ²¡æœ‰è®¾ç½®éšæœºæ•°ç§å­ï¼Œé‚£ä¹ˆå®ƒå¾ˆå¯èƒ½æ˜¯åŸºäºç³»ç»Ÿæ—¶é—´è®¾ç½®çš„ã€‚
- en: '[PRE72]'
  id: totrans-1104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: We will overfit the trees, let them grow overly complicated. Once again, the
    ensemble approach will mitigate model variance and overfit.
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿‡åº¦æ‹Ÿåˆæ ‘ï¼Œè®©å®ƒä»¬å˜å¾—è¿‡äºå¤æ‚ã€‚å†æ¬¡ï¼Œé›†æˆæ–¹æ³•å°†å‡è½»æ¨¡å‹æ–¹å·®å’Œè¿‡åº¦æ‹Ÿåˆã€‚
- en: '[PRE73]'
  id: totrans-1106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: We will use a large number of trees to mitigate model variance and to benefit
    from random forest tree diversity.
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨å¤§é‡æ ‘æ¥å‡è½»æ¨¡å‹æ–¹å·®ï¼Œå¹¶ä»éšæœºæ£®æ—æ ‘çš„å¤šæ ·æ€§ä¸­å—ç›Šã€‚
- en: '[PRE74]'
  id: totrans-1108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We are using a simple 2 predictor feature example for ease of visualization.
    The default for scikit learnâ€™s random forest is to select \(\frac{m}{3}\) features
    at random for consideration for each split.
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„2ä¸ªé¢„æµ‹å™¨ç‰¹å¾ç¤ºä¾‹æ¥ç®€åŒ–å¯è§†åŒ–ã€‚scikit learnçš„éšæœºæ£®æ—é»˜è®¤æƒ…å†µä¸‹æ˜¯éšæœºé€‰æ‹© \(\frac{m}{3}\) ä¸ªç‰¹å¾æ¥è€ƒè™‘æ¯ä¸ªåˆ†å‰²ã€‚
- en: This doesnâ€™t make much sense when \(m = 2\), as with our case, so we set the
    maximum number of features considered for each split to 1.
  id: totrans-1110
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ \(m = 2\) æ—¶ï¼Œè¿™æ²¡æœ‰å¤ªå¤šæ„ä¹‰ï¼Œå› ä¸ºæˆ‘ä»¬çš„æƒ…å†µå°±æ˜¯è¿™æ ·ï¼Œæ‰€ä»¥æˆ‘ä»¬æŠŠæ¯ä¸ªåˆ†å‰²è€ƒè™‘çš„æœ€å¤§ç‰¹å¾æ•°è®¾ç½®ä¸º1ã€‚
- en: We are forcing random selection of porosity or brittleness for consideration
    with each split, hierarchical binary segmentation.
  id: totrans-1111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨å¼ºåˆ¶ä¸ºæ¯ä¸ªåˆ†å‰²è€ƒè™‘å­”éš™ç‡æˆ–è„†æ€§ï¼Œè¿›è¡Œåˆ†å±‚äºŒè¿›åˆ¶åˆ†å‰²ã€‚
- en: '[PRE75]'
  id: totrans-1112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Instantiate the random forest regressor with our hyperparameters
  id: totrans-1113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æˆ‘ä»¬çš„è¶…å‚æ•°å®ä¾‹åŒ–éšæœºæ£®æ—å›å½’å™¨
- en: '[PRE76]'
  id: totrans-1114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Train the random forest regression
  id: totrans-1115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®­ç»ƒéšæœºæ£®æ—å›å½’
- en: '[PRE77]'
  id: totrans-1116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Visualize the model result over the feature space (easy to do as we have only
    2 predictor features)
  id: totrans-1117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–æ¨¡å‹ç»“æœåœ¨ç‰¹å¾ç©ºé—´ä¸Šçš„ç»“æœï¼ˆç”±äºæˆ‘ä»¬åªæœ‰2ä¸ªé¢„æµ‹å™¨ç‰¹å¾ï¼Œè¿™å¾ˆå®¹æ˜“åšåˆ°ï¼‰
- en: Letâ€™s build, visualize and cross validate our first random forest regression
    model.
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ„å»ºã€å¯è§†åŒ–å’Œäº¤å‰éªŒè¯æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªéšæœºæ£®æ—å›å½’æ¨¡å‹ã€‚
- en: '[PRE78]'
  id: totrans-1119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '![_images/95b5bfda652444fd962f82e48a68222434830f5645e78fb1598f64cd5a3e888e.png](../Images/87ab12ba6d0253a69f93da3499c21f86.png)'
  id: totrans-1120
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/87ab12ba6d0253a69f93da3499c21f86.png)'
- en: The power of tree diversity! We just built our best model so far.
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‘å¤šæ ·æ€§çš„åŠ›é‡ï¼æˆ‘ä»¬åˆšåˆšæ„å»ºäº†è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„æ¨¡å‹ã€‚
- en: the conditional bias has decreased (our plot has a slope closer to 1:1)
  id: totrans-1122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¡ä»¶åå·®å·²é™ä½ï¼ˆæˆ‘ä»¬çš„å›¾è¡¨çš„æ–œç‡æ›´æ¥è¿‘1:1ï¼‰
- en: we have the lower out-of-bag mean score error
  id: totrans-1123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰è¾ƒä½çš„è¢‹å¤–å‡æ–¹è¯¯å·®
- en: Letâ€™s run some tests to make sure we understand random forest regression model.
  id: totrans-1124
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿›è¡Œä¸€äº›æµ‹è¯•ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ç†è§£éšæœºæ£®æ—å›å½’æ¨¡å‹ã€‚
- en: First letâ€™s confirm that only one feature (at random) is considered for each
    split
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬ç¡®è®¤æ¯ä¸ªåˆ†å‰²åªè€ƒè™‘ä¸€ä¸ªç‰¹å¾ï¼ˆéšæœºï¼‰
- en: limit ourselves to maximum depth = 1, only one split
  id: totrans-1126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æˆ‘ä»¬çš„æ·±åº¦é™åˆ¶ä¸ºæœ€å¤§æ·±åº¦ = 1ï¼Œä»…è¿›è¡Œä¸€æ¬¡åˆ†å‰²
- en: limit ourselves to a single tree in each forest!
  id: totrans-1127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªæ£®æ—ä¸­ä»…é™åˆ¶ä¸€æ£µæ ‘ï¼
- en: This way we can see the diversity in the first splits over multiple models.
  id: totrans-1128
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°å¤šä¸ªæ¨¡å‹åœ¨ç¬¬ä¸€æ¬¡åˆ†å‰²ä¸­çš„å¤šæ ·æ€§ã€‚
- en: '[PRE79]'
  id: totrans-1129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '![_images/c161b87c59434bdd65f9831ab841ba71436cfc60c9e04fa4d5980bbfa7bd80c5.png](../Images/8f016e3c4f9adb7f07b4035f2e51c1e8.png)'
  id: totrans-1130
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/8f016e3c4f9adb7f07b4035f2e51c1e8.png)'
- en: Notice that the first splits are 50/50 porosity and brittleness.
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç¬¬ä¸€æ¬¡åˆ†å‰²æ˜¯50/50çš„å­”éš™ç‡å’Œè„†æ€§ã€‚
- en: aside, for all decision trees that I have fit to this dataset, porosity is always
    the feature selected for the first 2-3 levels of the tree.
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œå¯¹äºæˆ‘æ‹Ÿåˆåˆ°è¿™ä¸ªæ•°æ®é›†çš„æ‰€æœ‰å†³ç­–æ ‘ï¼Œå­”éš™ç‡æ€»æ˜¯è¢«é€‰ä¸ºæ ‘çš„å‰2-3å±‚çš„ç‰¹å¾ã€‚
- en: the random forest has resulted in model diversity by limiting the predictor
    features under consideration for the first split!
  id: totrans-1133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡é™åˆ¶ç¬¬ä¸€æ¬¡åˆ†å‰²æ—¶è€ƒè™‘çš„é¢„æµ‹å™¨ç‰¹å¾ï¼Œéšæœºæ£®æ—å®ç°äº†æ¨¡å‹å¤šæ ·æ€§ï¼
- en: Just incase you donâ€™t trust this, letâ€™s rerun the above code with both predictors
    allowed for all splits.
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸ä¿¡ä»»è¿™ä¸ªç»“æœï¼Œè®©æˆ‘ä»¬é‡æ–°è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œå…è®¸æ‰€æœ‰åˆ†å‰²éƒ½ä½¿ç”¨ä¸¤ä¸ªé¢„æµ‹å™¨ã€‚
- en: '[PRE80]'
  id: totrans-1135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '![_images/1b44bed65bdc0d762afa4706304f8c37a7f517a522d534c448aabf24ae1a9e9a.png](../Images/040c1daaa86a87e50c8d4df661597508.png)'
  id: totrans-1136
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/040c1daaa86a87e50c8d4df661597508.png)'
- en: Now we have a set of first splits that vary (due to the bootstrap of the training
    data), but are all over porosity.
  id: totrans-1137
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰ä¸€ç»„ç¬¬ä¸€æ¬¡åˆ†å‰²ï¼Œè¿™äº›åˆ†å‰²å› è®­ç»ƒæ•°æ®çš„è‡ªåŠ©é‡‡æ ·è€Œä¸åŒï¼Œä½†éƒ½åœ¨å­”éš™ç‡ä¸Šã€‚
- en: Model Performance by Out-of-Bag and Feature Importance
  id: totrans-1138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ€§èƒ½é€šè¿‡è¢‹å¤–å’Œç‰¹å¾é‡è¦æ€§
- en: Since we are now building a more robust model with a large ensemble of trees,
    letâ€™s get more serious about model checking.
  id: totrans-1139
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬ç°åœ¨æ­£åœ¨æ„å»ºä¸€ä¸ªç”±å¤§é‡æ ‘ç»„æˆçš„æ›´å¥å£®çš„æ¨¡å‹ï¼Œè®©æˆ‘ä»¬å¯¹æ¨¡å‹æ£€æŸ¥æ›´åŠ è®¤çœŸã€‚
- en: we will look at out-of-bag mean square error
  id: totrans-1140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŸ¥çœ‹è¢‹å¤–å‡æ–¹è¯¯å·®
- en: we will look at feature importance
  id: totrans-1141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§
- en: Letâ€™s start with a pretty big forest, this may take a while to run!
  id: totrans-1142
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªéå¸¸å¤§çš„æ£®æ—å¼€å§‹ï¼Œè¿™å¯èƒ½ä¼šèŠ±è´¹ä¸€äº›æ—¶é—´æ¥è¿è¡Œï¼
- en: '[PRE81]'
  id: totrans-1143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '![_images/735c2983e57fae5ab1825ca0a3a59ee1c45ab833f9d685009c96b01ecdc3728b.png](../Images/dc651fd9d250853ed0b993f26122923c.png)'
  id: totrans-1144
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/dc651fd9d250853ed0b993f26122923c.png)'
- en: To get the feature importance we just have to access the model member â€˜feature_importance_â€™.
  id: totrans-1145
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è·å–ç‰¹å¾é‡è¦æ€§ï¼Œæˆ‘ä»¬åªéœ€è®¿é—®æ¨¡å‹æˆå‘˜â€˜feature_importance_â€™ã€‚
- en: we had to set feature_importance to true in the model instantiation for this
    to be available
  id: totrans-1146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»åœ¨æ¨¡å‹å®ä¾‹åŒ–æ—¶å°†feature_importanceè®¾ç½®ä¸ºtrueï¼Œæ‰èƒ½ä½¿å…¶å¯ç”¨
- en: this measure is standardized to sum to 1.0
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤åº¦é‡æ ‡å‡†åŒ–ä¸ºæ€»å’Œä¸º1.0
- en: same order as the predictor features in the 2D array, porosity and then brittleness
  id: totrans-1148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸2Dæ•°ç»„ä¸­é¢„æµ‹ç‰¹å¾ç›¸åŒçš„é¡ºåºï¼Œå­”éš™ç‡ç„¶åæ˜¯è„†æ€§
- en: feature importance is the proportion of total MSE reduction through splits for
    each feature
  id: totrans-1149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é‡è¦æ€§æ˜¯æ¯ä¸ªç‰¹å¾é€šè¿‡åˆ†å‰²å¸¦æ¥çš„æ€»å‡æ–¹è¯¯å·®å‡å°‘çš„æ¯”ä¾‹
- en: we can access the importance for each feature for each tree in the forest or
    the global average for each over the entire forest
  id: totrans-1150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è®¿é—®æ£®æ—ä¸­æ¯æ£µæ ‘æˆ–æ•´ä¸ªæ£®æ—ä¸­æ¯ä¸ªç‰¹å¾çš„ç›¸å¯¹é‡è¦æ€§
- en: We get the global average of feature importance with this member of the random
    forest regressor model.
  id: totrans-1151
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡éšæœºæ£®æ—å›å½’å™¨æ¨¡å‹çš„æ­¤æˆå‘˜è·å¾—ç‰¹å¾é‡è¦æ€§çš„å…¨å±€å¹³å‡å€¼ã€‚
- en: '[PRE82]'
  id: totrans-1152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Letâ€™s plot the feature importance with significance calculated from the ensemble.
  id: totrans-1153
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾ï¼Œè¯¥å›¾æ˜¯ä»é›†æˆä¸­è®¡ç®—å‡ºçš„æ˜¾è‘—æ€§ã€‚
- en: when we report model-based feature importance, it is always a good idea to show
    that the model is a good model. I like to show a model check beside the feature
    importance result, in this case the out-of-bag cross validation plot and mean
    square error.
  id: totrans-1154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬æŠ¥å‘ŠåŸºäºæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§æ—¶ï¼Œæ€»æ˜¯æ˜¾ç¤ºæ¨¡å‹æ˜¯ä¸€ä¸ªå¥½æ¨¡å‹çš„å¥½ä¸»æ„ã€‚æˆ‘å–œæ¬¢åœ¨ç‰¹å¾é‡è¦æ€§ç»“æœæ—è¾¹æ˜¾ç¤ºæ¨¡å‹æ£€æŸ¥ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯è¢‹å¤–äº¤å‰éªŒè¯å›¾å’Œå‡æ–¹è¯¯å·®ã€‚
- en: '[PRE83]'
  id: totrans-1155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '![_images/bfd529c0f34dd25a412354a45b90571b09239a3df8498d1354f217fdd4261c67.png](../Images/2c8c91f2d316367792438970dc37eac7.png)'
  id: totrans-1156
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/2c8c91f2d316367792438970dc37eac7.png)'
- en: Letâ€™s try some hyperparameter training with the out-of-bag mean square error
    measure from our forest.
  id: totrans-1157
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨æ£®æ—çš„è¢‹å¤–å‡æ–¹è¯¯å·®åº¦é‡è¿›è¡Œä¸€äº›è¶…å‚æ•°è®­ç»ƒã€‚
- en: Letâ€™s start with the number of trees in our forest.
  id: totrans-1158
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æ£®æ—ä¸­çš„æ ‘çš„æ•°é‡å¼€å§‹ã€‚
- en: '[PRE84]'
  id: totrans-1159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '![_images/db70240c4201575375d6d14e35f366a22e45978000e8acabb77231b8d2d2b89f.png](../Images/b9b9a6c0574ef6e5325b02feabf44f82.png)'
  id: totrans-1160
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/b9b9a6c0574ef6e5325b02feabf44f82.png)'
- en: Now letâ€™s try the depth of the trees, given enough trees (weâ€™ll use 60 trees)
    as determined above.
  id: totrans-1161
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•æ ‘çš„æ·±åº¦ï¼Œç»™å®šè¶³å¤Ÿçš„æ ‘ï¼ˆæˆ‘ä»¬å°†ä½¿ç”¨60æ£µæ ‘ï¼‰å¦‚ä¸Šæ‰€è¿°ç¡®å®šã€‚
- en: '[PRE85]'
  id: totrans-1162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '![_images/50da58b3e08eb8830bbeb48b559c70b77602e790fec0e4d361e547e0c74ffb4b.png](../Images/a8dc1e34abadac0b98b890891c53267e.png)'
  id: totrans-1163
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/a8dc1e34abadac0b98b890891c53267e.png)'
- en: It looks like we need a maximum tree depth of at least 10 for best performance
    of our model with respect to out-of-bag mean square error.
  id: totrans-1164
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥æˆ‘ä»¬éœ€è¦è‡³å°‘10çš„æœ€å¤§æ ‘æ·±åº¦æ‰èƒ½ä½¿æˆ‘ä»¬çš„æ¨¡å‹åœ¨è¢‹å¤–å‡æ–¹è¯¯å·®æ–¹é¢è¡¨ç°æœ€ä½³ã€‚
- en: note that our model is robust and resistant to overfit, the out-of-bag performance
    evaluation is close to monotonically increasing.
  id: totrans-1165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯å¥å£®çš„ï¼Œå¯¹è¿‡æ‹Ÿåˆæœ‰æŠµæŠ—åŠ›ï¼Œè¢‹å¤–æ€§èƒ½è¯„ä¼°æ¥è¿‘å•è°ƒé€’å¢ã€‚
- en: Machine Learning Pipelines for Clean, Compact Machine Learning Code
  id: totrans-1166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¸…æ´ã€ç´§å‡‘çš„æœºå™¨å­¦ä¹ ä»£ç çš„æœºå™¨å­¦ä¹ ç®¡é“
- en: Pipelines are a scikit-learn class that allows for the encapsulation of a sequence
    of data preparation and modeling steps
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡é“æ˜¯scikit-learnç±»ï¼Œå…è®¸å°è£…ä¸€ç³»åˆ—æ•°æ®å‡†å¤‡å’Œå»ºæ¨¡æ­¥éª¤
- en: then we can treat the pipeline as an object in our much condensed workflow
  id: totrans-1168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†ç®¡é“è§†ä¸ºæˆ‘ä»¬é«˜åº¦ç²¾ç®€çš„å·¥ä½œæµç¨‹ä¸­çš„ä¸€ä¸ªå¯¹è±¡
- en: 'The pipeline class allows us to:'
  id: totrans-1169
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡é“ç±»å…è®¸æˆ‘ä»¬ï¼š
- en: improve code readability and to keep everything straight
  id: totrans-1170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æé«˜ä»£ç å¯è¯»æ€§å¹¶ä¿æŒä¸€åˆ‡æ¸…æ™°
- en: build complete workflows with very few lines of readable code
  id: totrans-1171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨éå¸¸å°‘çš„å¯è¯»ä»£ç æ„å»ºå®Œæ•´çš„æµç¨‹
- en: avoid common workflow problems like data leakage, testing data informing model
    parameter training
  id: totrans-1172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…å¸¸è§çš„æµç¨‹é—®é¢˜ï¼Œå¦‚æ•°æ®æ³„éœ²ã€æµ‹è¯•æ•°æ®å½±å“æ¨¡å‹å‚æ•°è®­ç»ƒ
- en: abstract common machine learning modeling and focus on building the best model
    possible
  id: totrans-1173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŠ½è±¡å¸¸è§çš„æœºå™¨å­¦ä¹ å»ºæ¨¡ï¼Œä¸“æ³¨äºæ„å»ºå°½å¯èƒ½å¥½çš„æ¨¡å‹
- en: The fundamental philosophy is to treat machine learning as a combinatorial search
    to find the best model (AutoML)
  id: totrans-1174
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬å“²å­¦æ˜¯å°†æœºå™¨å­¦ä¹ è§†ä¸ºä¸€ç§ç»„åˆæœç´¢ï¼Œä»¥æ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼ˆAutoMLï¼‰
- en: For more information see my recorded lecture on [Machine Learning Pipelines](https://www.youtube.com/watch?v=tYrPs8s1l9U&list=PLG19vXLQHvSAufDFgZEFAYQEwMJXklnQV&index=5)
    and a well-documented demonstration [Machine Learning Pipeline Workflow](http://localhost:8892/notebooks/OneDrive%20-%20The%20University%20of%20Texas%20at%20Austin/Courses/Workflows/PythonDataBasics_Pipelines.ipynb).
  id: totrans-1175
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šä¿¡æ¯è¯·å‚é˜…æˆ‘çš„å…³äº[æœºå™¨å­¦ä¹ ç®¡é“](https://www.youtube.com/watch?v=tYrPs8s1l9U&list=PLG19vXLQHvSAufDFgZEFAYQEwMJXklnQV&index=5)çš„å½•éŸ³è®²åº§å’Œä¸€ä»½è‰¯å¥½çš„æ–‡æ¡£æ¼”ç¤º[æœºå™¨å­¦ä¹ ç®¡é“å·¥ä½œæµç¨‹](http://localhost:8892/notebooks/OneDrive%20-%20The%20University%20of%20Texas%20at%20Austin/Courses/Workflows/PythonDataBasics_Pipelines.ipynb)ã€‚
- en: '[PRE86]'
  id: totrans-1176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-1177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Practice on a New Dataset
  id: totrans-1178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨æ–°çš„æ•°æ®é›†ä¸Šè¿›è¡Œå®è·µ
- en: Ok, time to get to work. Letâ€™s load up a dataset and build a random forest prediction
    model with,
  id: totrans-1179
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼Œæ˜¯æ—¶å€™å¼€å§‹å·¥ä½œäº†ã€‚è®©æˆ‘ä»¬åŠ è½½æ•°æ®é›†å¹¶ä½¿ç”¨ä»¥ä¸‹å†…å®¹æ„å»ºéšæœºæ£®æ—é¢„æµ‹æ¨¡å‹ï¼Œ
- en: compact code
  id: totrans-1180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç´§å‡‘çš„ä»£ç 
- en: basic visaulizations
  id: totrans-1181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºæœ¬å¯è§†åŒ–
- en: save the output
  id: totrans-1182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿å­˜è¾“å‡º
- en: You can select any of these datasets or modify the code and add your own to
    do this.
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€‰æ‹©è¿™äº›æ•°æ®é›†ä¹‹ä¸€æˆ–ä¿®æ”¹ä»£ç å¹¶æ·»åŠ æ‚¨è‡ªå·±çš„æ•°æ®é›†æ¥å®Œæˆæ­¤æ“ä½œã€‚
- en: Dataset 0, Unconventional Multivariate v4
  id: totrans-1184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®é›† 0ï¼Œéå¸¸è§„å¤šå…ƒ v4
- en: 'Letâ€™s load the provided multivariate, dataset [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv).
    This dataset has variables from 1,000 unconventional wells including:'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒæ•°æ®é›† [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv)ã€‚æ­¤æ•°æ®é›†åŒ…å«æ¥è‡ª
    1,000 ä¸ªéå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š
- en: well average porosity
  id: totrans-1186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•å¹³å‡å­”éš™åº¦
- en: log transform of permeability (to linearize the relationships with other variables)
  id: totrans-1187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡çš„å¯¹æ•°å˜æ¢ï¼ˆä»¥çº¿æ€§åŒ–ä¸å…¶ä»–å˜é‡çš„å…³ç³»ï¼‰
- en: acoustic impedance (kg/m^3 x m/s x 10^6)
  id: totrans-1188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ— (kg/m^3 x m/s x 10^6)
- en: brittleness ratio (%)
  id: totrans-1189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'å‰ªåˆ‡æ¯” (%) '
- en: total organic carbon (%)
  id: totrans-1190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'æ€»æœ‰æœºç¢³ (%) '
- en: vitrinite reflectance (%)
  id: totrans-1191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ç»ç’ƒè´¨åå°„ç‡ (%) '
- en: initial production 90 day average (MCFPD).
  id: totrans-1192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆå§‹ç”Ÿäº§ 90 å¤©å¹³å‡ (MCFPD)ã€‚
- en: Dataset 2, Reservoir 21
  id: totrans-1193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®é›† 2ï¼Œå‚¨å±‚ 21
- en: 'Letâ€™s load the provided multivariate, 3D spatial dataset [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv).
    This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50
    m reservoir unit:'
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒ 3D ç©ºé—´æ•°æ®é›† [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv)ã€‚æ­¤æ•°æ®é›†åŒ…å«
    73 ä¸ªå‚ç›´äº•åœ¨ 10,000m x 10,000m x 50 m å‚¨å±‚å•å…ƒçš„å˜é‡ï¼š
- en: well (ID)
  id: totrans-1195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº• (ID)
- en: X (m), Y (m), Depth (m) location coordinates
  id: totrans-1196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X (m), Y (m), æ·±åº¦ (m) ä½ç½®åæ ‡
- en: Porosity (%) after units conversion
  id: totrans-1197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'å•ä½è½¬æ¢åçš„å­”éš™ç‡ (%) '
- en: Permeability (mD)
  id: totrans-1198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡ (mD)
- en: Acoustic Impedance (kg/m2s*10^6) after units conversion
  id: totrans-1199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ— (kg/m2s*10^6) å•ä½è½¬æ¢å
- en: Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley
    Sand, to Sandstone.
  id: totrans-1200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ°å±‚ (åˆ†ç±») - ä»é¡µå²©ã€ç ‚è´¨é¡µå²©ã€é¡µå²©ç ‚åˆ°ç ‚å²©çš„é¡ºåº
- en: Density (g/cm^3)
  id: totrans-1201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯†åº¦ (g/cm^3)
- en: Compressible velocity (m/s)
  id: totrans-1202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯å‹ç¼©é€Ÿåº¦ (m/s)
- en: Youngs modulus (GPa)
  id: totrans-1203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨æ°æ¨¡é‡ (GPa)
- en: Shear velocity (m/s)
  id: totrans-1204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ‡å˜é€Ÿåº¦ (m/s)
- en: Shear modulus (GPa)
  id: totrans-1205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ‡å˜æ¨¡é‡ (GPa)
- en: 3 year cumulative oil production (Mbbl)
  id: totrans-1206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 å¹´ç´¯è®¡çŸ³æ²¹äº§é‡ (Mbbl)
- en: We load the tabular data with the pandas â€˜read_csvâ€™ function into a DataFrame
    we called â€˜my_dataâ€™ and then preview it to make sure it loaded correctly.
  id: totrans-1207
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ pandas çš„ 'read_csv' å‡½æ•°å°†è¡¨æ ¼æ•°æ®åŠ è½½åˆ°åä¸º 'my_data' çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚
- en: we also populate lists with data ranges and labels for ease of plotting
  id: totrans-1208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜ç”¨æ•°æ®èŒƒå›´å’Œæ ‡ç­¾å¡«å……åˆ—è¡¨ï¼Œä»¥ä¾¿äºç»˜å›¾
- en: Load and format the data,
  id: totrans-1209
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®å¹¶æ ¼å¼åŒ–ï¼Œ
- en: drop the response feature
  id: totrans-1210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ é™¤å“åº”ç‰¹å¾
- en: reformate the features as needed
  id: totrans-1211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®éœ€è¦é‡æ–°æ ¼å¼åŒ–ç‰¹å¾
- en: also, I like to store the metadata in lists
  id: totrans-1212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä¹Ÿå–œæ¬¢å°†å…ƒæ•°æ®å­˜å‚¨åœ¨åˆ—è¡¨ä¸­
- en: '[PRE88]'
  id: totrans-1213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '|  | Por | Perm | AI | Brittle | TOC | VR | Prod |'
  id: totrans-1214
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Perm | AI | Brittle | TOC | VR | Prod |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-1215
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |'
  id: totrans-1216
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |'
- en: '| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |'
  id: totrans-1217
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |'
- en: '| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |'
  id: totrans-1218
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |'
- en: '| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |'
  id: totrans-1219
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |'
- en: '| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |'
  id: totrans-1220
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |'
- en: '| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |'
  id: totrans-1221
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |'
- en: '| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |'
  id: totrans-1222
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |'
- en: '| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |'
  id: totrans-1223
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |'
- en: '| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |'
  id: totrans-1224
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |'
- en: '| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |'
  id: totrans-1225
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |'
- en: '| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |'
  id: totrans-1226
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |'
- en: '| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |'
  id: totrans-1227
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |'
- en: '| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |'
  id: totrans-1228
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |'
- en: Build and Check Model
  id: totrans-1229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ„å»ºå’Œæ£€æŸ¥æ¨¡å‹
- en: We apply the follow steps,
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”ç”¨ä»¥ä¸‹æ­¥éª¤ï¼Œ
- en: specify the K-fold method
  id: totrans-1231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å®š K æŠ˜æ–¹æ³•
- en: loop over number of leaf nodes, instantiate, fit and record the error
  id: totrans-1232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éå†å¶èŠ‚ç‚¹æ•°é‡ï¼Œå®ä¾‹åŒ–ï¼Œæ‹Ÿåˆå¹¶è®°å½•é”™è¯¯
- en: plot the test error vs. number of leaf nodes, select the hyperparameter that
    minimizes test error
  id: totrans-1233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æµ‹è¯•è¯¯å·®ä¸å¶èŠ‚ç‚¹æ•°é‡çš„å…³ç³»å›¾ï¼Œé€‰æ‹©æœ€å°åŒ–æµ‹è¯•è¯¯å·®çš„è¶…å‚æ•°
- en: retrain the model with the tuned hyperparameter and all of the data
  id: totrans-1234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è°ƒæ•´è¿‡çš„è¶…å‚æ•°å’Œæ‰€æœ‰æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹
- en: '[PRE89]'
  id: totrans-1235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '![_images/447cb9297891445a4687987aa0d2d5d1a7bc5f5ea046a61c2ddd9590e8c8d9dc.png](../Images/4541279cae3ac88f62404f70b893beda.png)'
  id: totrans-1236
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/4541279cae3ac88f62404f70b893beda.png)'
- en: Dataset 0, Unconventional Multivariate v4
  id: totrans-1237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®é›† 0ï¼Œéå¸¸è§„å¤šå…ƒ v4
- en: 'Letâ€™s load the provided multivariate, dataset [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv).
    This dataset has variables from 1,000 unconventional wells including:'
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒæ•°æ®é›† [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª
    1,000 ä¸ªéå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š
- en: well average porosity
  id: totrans-1239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•å¹³å‡å­”éš™ç‡
- en: log transform of permeability (to linearize the relationships with other variables)
  id: totrans-1240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡çš„å¯¹æ•°å˜æ¢ï¼ˆä»¥çº¿æ€§åŒ–ä¸å…¶ä»–å˜é‡çš„å…³ç³»ï¼‰
- en: acoustic impedance (kg/m^3 x m/s x 10^6)
  id: totrans-1241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å£°é˜»æŠ—ï¼ˆkg/m^3 x m/s x 10^6ï¼‰
- en: brittleness ratio (%)
  id: totrans-1242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡æ¯”ï¼ˆ%ï¼‰
- en: total organic carbon (%)
  id: totrans-1243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€»æœ‰æœºç¢³ï¼ˆ%ï¼‰
- en: vitrinite reflectance (%)
  id: totrans-1244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»ç’ƒè´¨åå°„ç‡ï¼ˆ%ï¼‰
- en: initial production 90 day average (MCFPD).
  id: totrans-1245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆå§‹ç”Ÿäº§ 90 å¤©å¹³å‡ï¼ˆMCFPDï¼‰ã€‚
- en: Dataset 2, Reservoir 21
  id: totrans-1246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®é›† 2ï¼Œæ°´åº“ 21
- en: 'Letâ€™s load the provided multivariate, 3D spatial dataset [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv).
    This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50
    m reservoir unit:'
  id: totrans-1247
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒ 3D ç©ºé—´æ•°æ®é›† [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª
    73 ä¸ªå‚ç›´äº•åœ¨ 10,000m x 10,000m x 50 m æ°´åº“å•å…ƒçš„å˜é‡ï¼š
- en: well (ID)
  id: totrans-1248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº•ï¼ˆIDï¼‰
- en: X (m), Y (m), Depth (m) location coordinates
  id: totrans-1249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xï¼ˆmï¼‰ï¼ŒYï¼ˆmï¼‰ï¼Œæ·±åº¦ï¼ˆmï¼‰ä½ç½®åæ ‡
- en: Porosity (%) after units conversion
  id: totrans-1250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä½è½¬æ¢åçš„å­”éš™ç‡ï¼ˆ%ï¼‰
- en: Permeability (mD)
  id: totrans-1251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€ç‡ï¼ˆmDï¼‰
- en: Acoustic Impedance (kg/m2s*10^6) after units conversion
  id: totrans-1252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å•ä½è½¬æ¢åçš„å£°é˜»æŠ—ï¼ˆkg/m2s*10^6ï¼‰
- en: Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley
    Sand, to Sandstone.
  id: totrans-1253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›¸ï¼ˆåˆ†ç±»ï¼‰ - ä»é¡µå²©ã€ç ‚è´¨é¡µå²©ã€é¡µå²©ç ‚åˆ°ç ‚å²©çš„é¡ºåºã€‚
- en: Density (g/cm^3)
  id: totrans-1254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯†åº¦ï¼ˆg/cm^3ï¼‰
- en: Compressible velocity (m/s)
  id: totrans-1255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯å‹ç¼©é€Ÿåº¦ï¼ˆm/sï¼‰
- en: Youngs modulus (GPa)
  id: totrans-1256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨æ°æ¨¡é‡ï¼ˆGPaï¼‰
- en: Shear velocity (m/s)
  id: totrans-1257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡é€Ÿåº¦ï¼ˆm/sï¼‰
- en: Shear modulus (GPa)
  id: totrans-1258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‰ªåˆ‡æ¨¡é‡ï¼ˆGPaï¼‰
- en: 3 year cumulative oil production (Mbbl)
  id: totrans-1259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 å¹´ç´¯ç§¯çŸ³æ²¹äº§é‡ï¼ˆMbblï¼‰
- en: We load the tabular data with the pandas â€˜read_csvâ€™ function into a DataFrame
    we called â€˜my_dataâ€™ and then preview it to make sure it loaded correctly.
  id: totrans-1260
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ pandas çš„ â€˜read_csvâ€™ å‡½æ•°å°†è¡¨æ ¼æ•°æ®åŠ è½½åˆ°æˆ‘ä»¬ç§°ä¸º â€˜my_dataâ€™ çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚
- en: we also populate lists with data ranges and labels for ease of plotting
  id: totrans-1261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜ç”¨æ•°æ®èŒƒå›´å’Œæ ‡ç­¾å¡«å……åˆ—è¡¨ï¼Œä»¥ä¾¿äºç»˜å›¾
- en: Load and format the data,
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½æ•°æ®å¹¶æ ¼å¼åŒ–ï¼Œ
- en: drop the response feature
  id: totrans-1263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ é™¤å“åº”ç‰¹å¾
- en: reformate the features as needed
  id: totrans-1264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ ¹æ®éœ€è¦é‡æ–°æ ¼å¼åŒ–ç‰¹å¾
- en: also, I like to store the metadata in lists
  id: totrans-1265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä¹Ÿå–œæ¬¢å°†å…ƒæ•°æ®å­˜å‚¨åœ¨åˆ—è¡¨ä¸­
- en: '[PRE90]'
  id: totrans-1266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '|  | Por | Perm | AI | Brittle | TOC | VR | Prod |'
  id: totrans-1267
  prefs: []
  type: TYPE_TB
  zh: '|  | Por | Perm | AI | Brittle | TOC | VR | Prod |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-1268
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |'
  id: totrans-1269
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |'
- en: '| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |'
  id: totrans-1270
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |'
- en: '| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |'
  id: totrans-1271
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |'
- en: '| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |'
  id: totrans-1272
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |'
- en: '| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |'
  id: totrans-1273
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |'
- en: '| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |'
  id: totrans-1274
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |'
- en: '| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |'
  id: totrans-1275
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |'
- en: '| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |'
  id: totrans-1276
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |'
- en: '| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |'
  id: totrans-1277
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |'
- en: '| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |'
  id: totrans-1278
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |'
- en: '| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |'
  id: totrans-1279
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |'
- en: '| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |'
  id: totrans-1280
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |'
- en: '| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |'
  id: totrans-1281
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |'
- en: Build and Check Model
  id: totrans-1282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ„å»ºå’Œæ£€æŸ¥æ¨¡å‹
- en: We apply the follow steps,
  id: totrans-1283
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”ç”¨ä»¥ä¸‹æ­¥éª¤ï¼Œ
- en: specify the K-fold method
  id: totrans-1284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å®š K æŠ˜æ³•
- en: loop over number of leaf nodes, instantiate, fit and record the error
  id: totrans-1285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éå†å¶èŠ‚ç‚¹æ•°ï¼Œå®ä¾‹åŒ–ã€æ‹Ÿåˆå¹¶è®°å½•é”™è¯¯
- en: plot the test error vs. number of leaf nodes, select the hyperparameter that
    minimizes test error
  id: totrans-1286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æµ‹è¯•è¯¯å·®ä¸å¶èŠ‚ç‚¹æ•°çš„å…³ç³»å›¾ï¼Œé€‰æ‹©æœ€å°åŒ–æµ‹è¯•è¯¯å·®çš„è¶…å‚æ•°
- en: retrain the model with the tuned hyperparameter and all of the data
  id: totrans-1287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è°ƒæ•´åçš„è¶…å‚æ•°å’Œæ‰€æœ‰æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹
- en: '[PRE91]'
  id: totrans-1288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '![_images/447cb9297891445a4687987aa0d2d5d1a7bc5f5ea046a61c2ddd9590e8c8d9dc.png](../Images/4541279cae3ac88f62404f70b893beda.png)'
  id: totrans-1289
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/4541279cae3ac88f62404f70b893beda.png)'
- en: Comments
  id: totrans-1290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„è®º
- en: I hope you found this chapter helpful. Much more could be done and discussed,
    I have many more resources. Check out my [shared resource inventory](https://michaelpyrcz.com/my-resources),
  id: totrans-1291
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æ‚¨è§‰å¾—è¿™ä¸€ç« æœ‰å¸®åŠ©ã€‚è¿˜æœ‰æ›´å¤šå¯ä»¥åšçš„å’Œè®¨è®ºçš„ï¼Œæˆ‘æœ‰å¾ˆå¤šæ›´å¤šçš„èµ„æºã€‚æŸ¥çœ‹æˆ‘çš„[å…±äº«èµ„æºæ¸…å•](https://michaelpyrcz.com/my-resources)ï¼Œ
- en: '*Michael*'
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: About the Author
  id: totrans-1293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºä½œè€…
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  id: totrans-1294
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  id: totrans-1295
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨æ•™æˆåœ¨å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡40è‹±äº©æ ¡å›­çš„åŠå…¬å®¤ã€‚
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  id: totrans-1296
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨æ˜¯[ Cockrellå·¥ç¨‹å­¦é™¢](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)å’Œ[Jacksonåœ°çƒç§‘å­¦å­¦é™¢](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)çš„æ•™æˆï¼Œåœ¨[å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡](https://www.utexas.edu/)è¿›è¡Œç ”ç©¶æ•™å­¦ï¼Œç ”ç©¶å†…å®¹åŒ…æ‹¬åœ°ä¸‹ã€ç©ºé—´æ•°æ®åˆ†æã€åœ°è´¨ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ã€‚è¿ˆå…‹å°”è¿˜æ˜¯ï¼Œ
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  id: totrans-1297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[èƒ½æºåˆ†æ](https://fri.cns.utexas.edu/energy-analytics)æ–°ç”Ÿç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡è‡ªç„¶ç§‘å­¦é™¢æœºå™¨å­¦ä¹ å®éªŒå®¤çš„æ ¸å¿ƒæ•™å‘˜ã€‚'
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  id: totrans-1298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è®¡ç®—æœºä¸åœ°è´¨ç§‘å­¦](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)çš„å‰¯ç¼–è¾‘ï¼Œä»¥åŠ[æ•°å­¦åœ°è´¨å­¦](https://link.springer.com/journal/11004/editorial-board)å›½é™…æ•°å­¦åœ°è´¨å­¦åä¼šçš„è‘£äº‹ä¼šæˆå‘˜ã€‚'
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  id: totrans-1299
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”å·²ç»æ’°å†™äº†è¶…è¿‡70ç¯‡[åŒè¡Œè¯„å®¡çš„å‡ºç‰ˆç‰©](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)ï¼Œä¸€ä¸ªç”¨äºç©ºé—´æ•°æ®åˆ†æçš„[PythonåŒ…](https://pypi.org/project/geostatspy/)ï¼Œåˆè‘—äº†ä¸€æœ¬å…³äºç©ºé—´æ•°æ®åˆ†æçš„æ•™ç§‘ä¹¦ã€Š[åœ°è´¨ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)ã€‹ï¼Œå¹¶ä¸”æ˜¯ä¸¤æœ¬æœ€è¿‘å‘å¸ƒçš„ç”µå­ä¹¦çš„ä½œè€…ï¼Œåˆ†åˆ«æ˜¯ã€Š[Pythonä¸­çš„åº”ç”¨åœ°è´¨ç»Ÿè®¡å­¦ï¼šGeostatsPyå®è·µæŒ‡å—](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)ã€‹å’Œã€Š[Pythonä¸­çš„åº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„å®è·µæŒ‡å—](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)ã€‹ã€‚
- en: All of Michaelâ€™s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michaelâ€™s work and shared educational resources visit his
    Website.
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”çš„æ‰€æœ‰å¤§å­¦è®²åº§éƒ½å¯ä»¥åœ¨ä»–çš„[YouTubeé¢‘é“](https://www.youtube.com/@GeostatsGuyLectures)ä¸Šæ‰¾åˆ°ï¼Œå…¶ä¸­åŒ…å«100å¤šä¸ªPythonäº¤äº’å¼ä»ªè¡¨æ¿å’Œ40å¤šä¸ªå­˜å‚¨åº“ä¸­çš„è¯¦ç»†å·¥ä½œæµç¨‹é“¾æ¥ï¼Œè¿™äº›å­˜å‚¨åº“ä½äºä»–çš„[GitHubè´¦æˆ·](https://github.com/GeostatsGuy)ï¼Œä»¥æ”¯æŒä»»ä½•æ„Ÿå…´è¶£çš„å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«ï¼Œæä¾›æŒç»­æ›´æ–°çš„å†…å®¹ã€‚è¦äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„å·¥ä½œå’Œå…±äº«æ•™è‚²èµ„æºï¼Œè¯·è®¿é—®ä»–çš„ç½‘ç«™ã€‚
- en: Want to Work Together?
  id: totrans-1301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-1302
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™ä¸ªå†…å®¹å¯¹é‚£äº›æƒ³äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„äººæœ‰å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«æ¬¢è¿å‚åŠ ã€‚
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  id: totrans-1303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  id: totrans-1304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ„Ÿå…´è¶£åˆä½œã€æ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººæ˜¯çº¦ç¿°Â·ç¦æ–¯ç‰¹æ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶ç»“åˆæ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºåŠå®è·µï¼Œä»¥å¼€å‘æ–°çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹æ¥å¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-1305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)è”ç³»åˆ°æˆ‘ã€‚
- en: Iâ€™m always happy to discuss,
  id: totrans-1306
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è®¨è®ºï¼Œ
- en: '*Michael*'
  id: totrans-1307
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿ˆå…‹å°”*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-1308
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ˆå…‹å°”Â·çš®å°”èŒ¨ï¼Œåšå£«ï¼Œæ³¨å†Œå·¥ç¨‹å¸ˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ Cockrell å·¥ç¨‹å­¦é™¢å’Œ Jackson åœ°çƒç§‘å­¦å­¦é™¢æ•™æˆ
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-1309
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šèµ„æºè¯·è®¿é—®ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Pythonä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Pythonä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
