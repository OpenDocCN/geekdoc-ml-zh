- en: 5 Exploring and Denoising Your Data Set
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 探索和去噪您的数据集
- en: 原文：[https://mlbook.explained.ai/prep.html](https://mlbook.explained.ai/prep.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mlbook.explained.ai/prep.html](https://mlbook.explained.ai/prep.html)
- en: '[Terence Parr](http://parrt.cs.usfca.edu) and [Jeremy Howard](http://www.fast.ai/about/#jeremy)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[特伦斯·帕特](http://parrt.cs.usfca.edu) 和 [杰里米·霍华德](http://www.fast.ai/about/#jeremy)'
- en: Copyright © 2018-2019 Terence Parr. All rights reserved.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 版权所有 © 2018-2019 特伦斯·帕特。保留所有权利。
- en: '*Please don''t replicate on web or redistribute in any way.*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*请勿在网络上复制或以任何方式重新分发。*'
- en: This book generated from markup+markdown+python+latex source with [Bookish](https://github.com/parrt/bookish).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书由 markup+markdown+python+latex 源代码生成，使用 [Bookish](https://github.com/parrt/bookish)。
- en: You can make **comments or annotate** this page by going to the annotated version
    of this page. You'll see existing annotated bits highlighted in yellow. They are
    *PUBLICLY VISIBLE*. Or, you can send comments, suggestions, or fixes directly
    to [Terence](mailto:parrt@cs.usfca.edu).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过访问此页面的注释版本来**评论或注释**此页。您会看到现有的注释部分以黄色突出显示。它们是**公开可见的**。或者，您可以直接向 [特伦斯](mailto:parrt@cs.usfca.edu)
    发送评论、建议或修正。
- en: Contents
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 目录
- en: '[Getting a quick sniff of the data](#sec:5.1)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速嗅探数据](#sec:5.1)'
- en: '[Training and evaluating an initial model](#sec:initial-model)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[训练和评估初始模型](#sec:initial-model)'
- en: '[Exploring and denoising the apartment rent data](#sec:5.3)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索和去噪公寓租金数据](#sec:5.3)'
- en: '[Examining the data distributions](#sec:5.3.1)'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检查数据分布](#sec:5.3.1)'
- en: '[Excising the anomalies](#sec:5.3.2)'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[去除异常值](#sec:5.3.2)'
- en: '[Comparing models trained on denoised data](#sec:5.4)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较在去噪数据上训练的模型](#sec:5.4)'
- en: '[Log in, exp out](#logtarget)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[登录，退出](#logtarget)'
- en: “*It is a capital mistake to theorize before one has data. Insensibly one begins
    to twist facts to suit theories, instead of theories to suit facts.*” — Arthur
    Conan Doyle (1891) in *A Scandal in Bohemia*
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: “*在没有数据之前就进行理论假设是一个严重的错误。不知不觉中，人们开始扭曲事实以适应理论，而不是让理论适应事实。*” —— 亚瑟·柯南·道尔（1891）在《波希米亚丑闻》中
- en: 'In **Chapter 3** *A First Taste of Applied Machine Learning*, we successfully
    trained a random forest (RF) model to predict New York City rent prices but under
    ideal conditions: the data was already in a form acceptable to a model and was
    mostly free of errors, outliers, and other noise. The unfortunate reality is that
    real data sets are messy and so, in this chapter, we''re going to learn how to
    process the original data from Kaggle bit-by-bit until it looks like that ideal
    data set. The dirty little secret of the machine learning world is that practitioners
    spend roughly 75% of their time acquiring, cleaning, and otherwise preparing data
    for training. (We won''t learn about the acquisition piece in this book, but you
    can check out Terence''s free [Data Acquisition course notes](https://github.com/parrt/msan692).)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **第3章** *初尝应用机器学习滋味* 中，我们成功训练了一个随机森林（RF）模型来预测纽约市租金价格，但是在理想条件下：数据已经以模型可接受的形式存在，并且大部分数据没有错误、异常和其他噪声。不幸的现实是，真实数据集很混乱，因此在本章中，我们将学习如何逐步处理Kaggle上的原始数据，直到它看起来像那个理想数据集。机器学习世界的隐藏秘密是，从业者大约花费75%的时间用于获取、清理和准备数据以供训练。（本书不会介绍数据获取部分，但你可以查看特伦斯的免费[数据获取课程笔记](https://github.com/parrt/msan692)。）
- en: 'To train a model, the data set must follow two fundamental rules: all data
    must be numeric and there can''t be any missing values. We must derive numeric
    features from the nonnumeric features such as strings, dates, and categorical
    variables like `SalesID`. Or, we can simply delete the nonnumeric features. That
    preparation work is a big topic unto itself, which we''ll address in **Chapter
    6** *Categorically Speaking* and **Chapter 7** *Exploring and Cleaning the Bulldozer
    Dataset*. In this chapter, we''ll stick with the numeric fields (bathrooms, bedrooms,
    longitude, latitude) we used before.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练一个模型，数据集必须遵循两个基本规则：所有数据必须是数值型的，并且不能有任何缺失值。我们必须从非数值特征（如字符串、日期和分类变量如`SalesID`）中推导出数值特征。或者，我们可以简单地删除非数值特征。这项准备工作本身就是一个大话题，我们将在
    **第6章** *分类讨论* 和 **第7章** *探索和清理推土机数据集* 中讨论。在本章中，我们将继续使用之前使用的数值字段（浴室、卧室、经度、纬度）。
- en: Even with purely numeric data, there is potential cleanup work to do. The data
    could have outliers, errors, or contradictory information. For example, in our
    apartment data, one place claims to have 2 bedrooms but 10 bathrooms, while other
    apartments claim to be on the equator! Armed with graphs or statistics from the
    data set, we turn to someone with domain expertise to interpret what we observe.
    (Terence's sister lives in New York City and confirms that New York is not on
    the equator, though typically feels that way in August.)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是纯数值数据，也可能需要进行一些清理工作。数据可能包含异常值、错误或矛盾信息。例如，在我们的公寓数据中，有一个地方声称有2个卧室但10个浴室，而其他公寓声称位于赤道！凭借数据集的图表或统计信息，我们转向具有领域专业知识的人来解释我们所观察到的。（特伦斯的妹妹住在纽约市，并证实纽约不在赤道，尽管在8月份通常感觉如此。）
- en: We also have to view all data cleaning operations through the lens of what exactly
    we want the model to do. In our case, we want a model that predicts apartment
    prices but just for New York City and just for the reasonably priced apartments.
    Unfortunately, our data set has a number of records that don't fit the constraints.
    For example, the data set has an outlier apartment costing $4,490,000/month (it
    must have parking) and an apartment whose longitude and latitude place it in Boston.
    We're going to delete these and a few other similar records for the simple reason
    that they exceed our focus. As we learned in **Chapter 3** *A First Taste of Applied
    Machine Learning*, models can only make predictions based upon the training data
    provided to them and we should avoid training them on inappropriate samples.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须从模型确切想要做什么的角度来审视所有数据清理操作。在我们的案例中，我们想要一个能够预测公寓价格的模型，但仅限于纽约市，并且仅限于价格合理的公寓。不幸的是，我们的数据集中有许多记录不符合这些限制。例如，数据集中有一个异常公寓每月租金为449万美元（它必须有停车位），还有一个公寓的经纬度将其放置在波士顿。我们将删除这些以及其他一些类似的记录，仅仅是因为它们超出了我们的关注范围。正如我们在**第3章**
    *A First Taste of Applied Machine Learning*中学到的，模型只能根据提供给它们的训练数据进行预测，我们应该避免在不适用的样本上训练它们。
- en: 'In this chapter we''re going to explore the original apartment data set from
    Kaggle, [Two Sigma Connect: Rental Listing Inquiries](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries),
    looking for and correcting suspicious records and elements. To do that, we''ll
    learn a multitude of useful techniques to examine and manipulate pandas dataframes.
    Along the way, we''ll also use matplotlib to generate some cool looking graphs
    and use sklearn to consider how data cleanup affects model accuracy.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将探索Kaggle的原始公寓数据集，[Two Sigma Connect: Rental Listing Inquiries](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries)，寻找并纠正可疑的记录和元素。为此，我们将学习多种有用的技术来检查和操作pandas数据框。在这个过程中，我们还将使用matplotlib生成一些看起来很酷的图表，并使用sklearn来考虑数据清理如何影响模型精度。'
- en: 5.1 Getting a quick sniff of the data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 快速查看数据
- en: Once were certain we've nailed down the exact problem to solve, the first step
    in a machine learning project is to look at the data, but just for a quick sniff.
    (Use a Jupyter notebook, Excel, an editor, or any other convenient tool.) We need
    to know what the data looks like so our first inspection of the data should yield
    the column names, their datatypes, and whether the target column has numeric values
    or categories. (If we're creating a regressor, those values must be numeric; if
    we're classifying, those values must be categories.)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了解决的确切问题，机器学习项目的第一步就是查看数据，但只是快速地闻一闻。（使用Jupyter笔记本、Excel、编辑器或其他任何方便的工具。）我们需要了解数据的样子，因此我们第一次检查数据应该得到列名、它们的数据类型以及目标列是否有数值或类别值。（如果我们正在创建回归器，这些值必须是数值；如果我们正在分类，这些值必须是类别。）
- en: To get started, make sure that you have file `rent.csv` in your `data` directory
    underneath where you are running Jupyter. (See **Section 3.2.1** *Loading and
    sniffing the training data* for instructions on downloading JSON rent data from
    Kaggle and creating the CSV files.) Then, create a new Jupyter notebook by clicking
    on the “+” button and selecting “Python 3” under the “Notebook” tab. This will
    create a file in the same directory where you started `jupyter lab` (unless you
    have jumped around using the “Files” tab on the left side of the lab browser window).
    It's probably a good idea to give the file a decent name like `clean.ipynb` by
    right clicking on the notebook tab that currently says `Untitled.ipynb`. You might
    also find it convenient to cut/paste from the [notebooks](https://mlbook.explained.ai/notebooks/)
    that were automatically derived from the code snippets from the various chapters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请确保您在运行Jupyter的`data`目录下有文件`rent.csv`。（有关从Kaggle下载JSON租金数据并创建CSV文件的说明，请参阅**第3.2.1节**
    *加载和嗅探训练数据*。）然后，通过点击“+”按钮并在“Notebook”选项卡下选择“Python 3”来创建一个新的Jupyter笔记本。这将创建一个与您启动`jupyter
    lab`的同一目录中的文件（除非您已经使用左侧实验室浏览器窗口上的“文件”选项卡跳来跳去）。通过右键单击当前显示为`Untitled.ipynb`的笔记本选项卡，给文件起一个合适的名字，如`clean.ipynb`可能是个好主意。您可能还会发现从自动从各章节代码片段中导出的[notebooks](https://mlbook.explained.ai/notebooks/)方便使用。
- en: 'Now, let''s enter some code into the notebook to read in the CSV data using
    pandas to get our first look at the original data:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在笔记本中输入一些代码来使用pandas读取CSV数据，以便我们首次查看原始数据：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: (49352, 15)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: (49352, 15)
- en: '|   | bathrooms | bedrooms | building_id | created | description | display_address
    | features | latitude | listing_id | longitude | manager_id | photos | price |
    street_address | interest_level |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '|   | bathrooms | bedrooms | building_id | created | description | display_address
    | features | latitude | listing_id | longitude | manager_id | photos | price |
    street_address | interest_level |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- |'
- en: '|  |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | 1.5000 | 3 | 53a5b119ba8f7b61d4e010512... | 2016-06-24 07:54:24 | A Brand
    New 3 Bedroom 1.5... | Metropolitan Avenue | [] | 40.7145 | 7211212 | -73.9425
    | 5ba989232d0489da1b5f2c45f... | [''https://photos.renthop.... | 3000 | 792 Metropolitan
    Avenue | medium |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.5000 | 3 | 53a5b119ba8f7b61d4e010512... | 2016-06-24 07:54:24 | A Brand
    New 3 Bedroom 1.5... | Metropolitan Avenue | [] | 40.7145 | 7211212 | -73.9425
    | 5ba989232d0489da1b5f2c45f... | [''https://photos.renthop.... | 3000 | 792 Metropolitan
    Avenue | medium |'
- en: '| 1 | 1.0000 | 2 | c5c8a357cba207596b04d1afd... | 2016-06-12 12:19:27 |  |
    Columbus Avenue | [''Doorman'', ''Elevator'', ''... | 40.7947 | 7150865 | -73.9667
    | 7533621a882f71e25173b27e3... | [''https://photos.renthop.... | 5465 | 808 Columbus
    Avenue | low |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.0000 | 2 | c5c8a357cba207596b04d1afd... | 2016-06-12 12:19:27 |  |
    Columbus Avenue | [''Doorman'', ''Elevator'', ''... | 40.7947 | 7150865 | -73.9667
    | 7533621a882f71e25173b27e3... | [''https://photos.renthop.... | 5465 | 808 Columbus
    Avenue | low |'
- en: 'There are many columns and some of them are very wide, so let''s transpose
    the display so that the columns are vertical (`.T` performs a transpose on the
    data frame, flipping rows and columns):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多列，其中一些列非常宽，所以让我们将显示方式转置，使列垂直（`.T`对数据帧执行转置，翻转行和列）：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|   | 0 | 1 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|   | 0 | 1 |'
- en: '| --- | --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| bathrooms | 1.5000 | 1.0000 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| bathrooms | 1.5000 | 1.0000 |'
- en: '| bedrooms | 3 | 2 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| bedrooms | 3 | 2 |'
- en: '| building_id | 53a5b119ba8f7b61d4e010512... | c5c8a357cba207596b04d1afd...
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| building_id | 53a5b119ba8f7b61d4e010512... | c5c8a357cba207596b04d1afd...
    |'
- en: '| created | 2016-06-24 07:54:24 | 2016-06-12 12:19:27 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| created | 2016-06-24 07:54:24 | 2016-06-12 12:19:27 |'
- en: '| description | A Brand New 3 Bedroom 1.5... |  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| description | A Brand New 3 Bedroom 1.5... |  |'
- en: '| display_address | Metropolitan Avenue | Columbus Avenue |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| display_address | Metropolitan Avenue | Columbus Avenue |'
- en: '| features | [] | [''Doorman'', ''Elevator'', ''... |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| features | [] | [''Doorman'', ''Elevator'', ''... |'
- en: '| latitude | 40.7145 | 40.7947 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| latitude | 40.7145 | 40.7947 |'
- en: '| listing_id | 7211212 | 7150865 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| listing_id | 7211212 | 7150865 |'
- en: '| longitude | -73.9425 | -73.9667 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| longitude | -73.9425 | -73.9667 |'
- en: '| manager_id | 5ba989232d0489da1b5f2c45f... | 7533621a882f71e25173b27e3...
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| manager_id | 5ba989232d0489da1b5f2c45f... | 7533621a882f71e25173b27e3...
    |'
- en: '| photos | [''https://photos.renthop.... | [''https://photos.renthop.... |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| photos | [''https://photos.renthop.... | [''https://photos.renthop.... |'
- en: '| price | 3000 | 5465 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| price | 3000 | 5465 |'
- en: '| street_address | 792 Metropolitan Avenue | 808 Columbus Avenue |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| street_address | 792 Metropolitan Avenue | 808 Columbus Avenue |'
- en: '| interest_level | medium | low |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| interest_level | medium | low |'
- en: 'This makes it easier to see the column names, column datatypes, and a sample
    data value for each column. We see a bunch of nonnumeric fields, including some
    columns that actually look like lists of things packed together into a single
    string, such as `photos` and `features`. The `description` seems to be free text
    in a string. Pandas can tell us more specifically about the data types if we ask
    for `info()`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得查看列名、列数据类型以及每个列的样本数据值变得更容易。我们看到许多非数值字段，包括一些看起来像将事物打包成单个字符串的列表的列，例如 `photos`
    和 `features`。`description` 似乎是一段自由文本字符串。如果我们请求 `info()`，Pandas 可以更具体地告诉我们数据类型：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '<class ''pandas.core.frame.DataFrame''> RangeIndex: 49352 entries, 0 to 49351
    Data columns (total 15 columns): bathrooms 49352 non-null float64 bedrooms 49352
    non-null int64 building_id 49352 non-null object created 49352 non-null object
    description 47906 non-null object display_address 49217 non-null object features
    49352 non-null object latitude 49352 non-null float64 listing_id 49352 non-null
    int64 longitude 49352 non-null float64 manager_id 49352 non-null object photos
    49352 non-null object price 49352 non-null int64 street_address 49342 non-null
    object interest_level 49352 non-null object dtypes: float64(3), int64(3), object(9)
    memory usage: 5.6+ MB'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '<class ''pandas.core.frame.DataFrame''> RangeIndex: 49352 entries, 0 to 49351
    Data columns (total 15 columns): bathrooms 49352 non-null float64 bedrooms 49352
    non-null int64 building_id 49352 non-null object created 49352 non-null object
    description 47906 non-null object display_address 49217 non-null object features
    49352 non-null object latitude 49352 non-null float64 listing_id 49352 non-null
    int64 longitude 49352 non-null float64 manager_id 49352 non-null object photos
    49352 non-null object price 49352 non-null int64 street_address 49342 non-null
    object interest_level 49352 non-null object dtypes: float64(3), int64(3), object(9)
    memory usage: 5.6+ MB'
- en: 'The datatypes are in the last column, such as `float64` which means “floating-point
    number using 64-bits (8 bytes) of memory”. The `object` data type is pandas''
    equivalent of a string datatype. Anything other than `float` and `int` are nonnumeric
    datatypes. Because we don''t know how to deal with nonnumeric datatypes at this
    point, we can just drop those columns. All we care about are the numeric fields:
    bathrooms, bedrooms, longitude, latitude, price.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型位于最后一列，例如 `float64` 表示“使用64位（8字节）内存的浮点数”。`object` 数据类型是 pandas 中字符串数据类型的等价物。除了
    `float` 和 `int` 之外的所有内容都是非数值数据类型。因为我们目前不知道如何处理非数值数据类型，所以我们可以直接删除这些列。我们只关心数值字段：浴室数量、卧室数量、经度、纬度、价格。
- en: 'To get a subset of the data frame, we could drop columns from `df`, but it''s
    more explicit to grab a subset of the columns by indexing with a list of column
    names:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取数据帧的子集，我们可以从 `df` 中删除列，但通过列名列表进行索引来获取列的子集更为明确：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '|   | bathrooms | bedrooms | longitude | latitude | price |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|   | 浴室 | 卧室 | 经度 | 纬度 | 价格 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | 1.5000 | 3 | -73.9425 | 40.7145 | 3000 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.5000 | 3 | -73.9425 | 40.7145 | 3000 |'
- en: '| 1 | 1.0000 | 2 | -73.9667 | 40.7947 | 5465 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.0000 | 2 | -73.9667 | 40.7947 | 5465 |'
- en: Indexing on a data frame expects a column name or list of column names, so `df['price']`
    gets just the price column. Because Python list literals use square brackets,
    `['bathrooms',`...`]`, just like indexing, the double-bracket notation looks a
    little funny. Data frame `df_num` acts like a copy of `df` with just those five
    columns but `df_num` is actually a view or perspective of `df` restricted to five
    columns. At this point, we've got the data looking, structurally, very similar
    to what we had in `rent-idea.csv` from **Chapter 3** *A First Taste of Applied
    Machine Learning*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据帧上进行索引时预期的是一个列名或列名列表，所以 `df['price']` 只获取价格列。因为 Python 列表字面量使用方括号，`['bathrooms',`...`]`，就像索引一样，双括号符号看起来有点奇怪。数据帧
    `df_num` 在结构上看起来像是 `df` 的一个副本，只包含这五个列，但 `df_num` 实际上是一个视图或视角，限制在五个列上。到目前为止，我们的数据看起来与第
    3 章 **A First Taste of Applied Machine Learning** 中的 `rent-idea.csv` 非常相似。
- en: 'Because models cannot handle missing values, another standard check is to see
    if there are missing values in the data set:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因为模型无法处理缺失值，另一个标准检查是查看数据集中是否有缺失值：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'bathrooms False bedrooms False longitude False latitude False price False dtype:
    bool'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '浴室 False 卧室 False 经度 False 纬度 False 价格 False dtype: bool'
- en: There are no missing values to deal with in this data set, but we won't be so
    lucky in [chp:feateng].
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中没有缺失值需要处理，但在 [chp:feateng] 中我们可能就不会这么幸运了。
- en: The more you look at the data the more you risk overfitting.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你看数据越多，就越有可能过拟合。
- en: We could explore the data some more, but what exactly would we be looking for?
    As a general principle, try to avoid looking too much at the data values. There
    is an awful temptation to make judgments or prematurely manipulate the data based
    upon our flawed human observations. Remember that we wouldn't need machine learning
    if a human could just look at a big data set and make correct, unbiased predictions.
    For example, if we see a column with lots of missing values, it's tempting to
    remove that from consideration as a feature. Instead, let the model tell you what
    features are important.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步探索数据，但我们到底在寻找什么？作为一个一般原则，尽量避免过多关注数据值。根据我们人类观察的缺陷，很容易做出判断或过早地操纵数据。记住，如果人类能够仅仅通过观察大数据集就能做出正确、无偏见的预测，我们就无需机器学习。例如，如果我们看到一个有很多缺失值的列，我们可能会倾向于将其从考虑特征中去除。相反，让模型告诉你哪些特征是重要的。
- en: 5.2 Training and evaluating an initial model
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 训练和评估初始模型
- en: 2 The cool kids say things like, “there's no signal there” to indicate no relationship
    exists between features and target.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 2 现在的潮流是，人们会说“那里没有信号”，以表明特征和目标之间不存在关系。
- en: We haven't looked at the training data very intensely other than to know all
    of the columns in the data frame are numeric. The next step is to train a model
    to see if there is a relationship between the features and the target and how
    strong that “signal” is.2
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 除了知道数据框中的所有列都是数值之外，我们并没有非常深入地查看训练数据。下一步是训练一个模型，看看特征和目标之间是否存在关系以及这种“信号”有多强。2
- en: 'Here''s the procedure for training a model, once we have a properly-prepared
    data frame, `df_num`, that consists only of numeric values and has no missing
    values:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了正确准备好的数据框 `df_num`，它只包含数值且没有缺失值，以下是训练模型的步骤：
- en: Separate the features and target columns.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 区分特征列和目标列。
- en: '[PRE5]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Create an appropriate model with suitable hyper-parameters.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个具有合适超参数的适当模型。
- en: '[PRE6]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Fit model to the training data.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据。
- en: '[PRE7]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let''s get a measure of how well the model fits the training data using
    `score()`, which returns a common error metric called ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    (literally pronounced “[R squared](https://en.wikipedia.org/wiki/Coefficient_of_determination)”):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `score()` 来衡量模型拟合训练数据的好坏，它返回一个称为 ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    的常见错误指标（字面意思是“[确定系数](https://en.wikipedia.org/wiki/Coefficient_of_determination)”）：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '0.8649'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '0.8649'
- en: A perfect training ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score
    is 1.0, meaning that the model perfectly recalls the training data. An ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score of 0 means the model performs no better than always just returning the average
    price. Unfortunately, a high training ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score (low error) doesn't tell us much. A high score just means that it's *possible*
    there is a relationship between features and target and captured by the model.
    If, however, we can't get a high ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score, it's an indication that there is no relationship or the model is simply
    unable to capture it. RFs are very powerful and can capture relationships even
    between random variables, so expect RF training ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    scores to be high.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 完美的训练 ![](../Images/ec985123b9b52e80981e6500795e8d16.png) 分数是 1.0，这意味着模型完美地回忆了训练数据。![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    分数为 0 表示模型的表现不比总是返回平均价格好。不幸的是，高训练 ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    分数（低误差）并没有告诉我们太多。高分仅仅意味着特征和目标之间可能存在关系，并且被模型捕捉到。然而，如果我们无法获得高 ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    分数，这表明没有关系或模型根本无法捕捉它。随机森林（RF）非常强大，甚至可以捕捉随机变量之间的关系，因此预期随机森林训练 ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    分数会很高。
- en: '**Interpreting R^2 Scores**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**解释 R^2 分数**'
- en: 'Think about the ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score as
    measuring how well our model performs compared to a trivial model that always
    returns the average of the target (apartment price) for any requested prediction.
    Any value less than that, all away down to negative infinity, indicates the model
    performs imperfectly to some degree. Because a model can be arbitrarily bad, the
    ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score can be arbitrarily negative.
    A nice feature of the ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score
    is that it is normalized: scores are always in the range of 1.0 down to negative
    infinity, rather than in units of apartment rent price or average rainfall in
    Nairobi. Just remember that 1.0 means perfect and 0.0 means no better than returning
    the average value. More on this in **Chapter 12** *Evaluating Regressor Performance*.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 将![](../Images/ec985123b9b52e80981e6500795e8d16.png)分数视为衡量我们的模型相对于总是返回目标（公寓价格）平均值的简单模型表现如何。任何低于该值的分数，一直低到负无穷大，都表明模型在某种程度上表现不完美。因为模型可以任意糟糕，所以![](../Images/ec985123b9b52e80981e6500795e8d16.png)分数可以是任意负数。![](../Images/ec985123b9b52e80981e6500795e8d16.png)分数的一个优点是它是归一化的：分数总是在1.0到负无穷大的范围内，而不是以公寓租金价格或内罗毕的平均降雨量为单位。只需记住，1.0表示完美，0.0表示不如返回平均值。更多内容请参阅第12章*评估回归器性能*。
- en: As we discussed in **Section 3.2.4** *Checking model generality*, we care about
    the prediction error on validation or test vectors, not the training error. We
    used the hold out method to assess model performance on validation data that was
    not used for training purposes. Writing code to split out the validation set is
    a hassle and reduces the training set size, however.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第3.2.4节*检查模型一般性*中讨论的那样，我们关心的是验证或测试向量上的预测误差，而不是训练误差。我们使用保留法来评估模型在未用于训练目的的验证数据上的性能。编写代码来分割验证集很麻烦，并且会减少训练集的大小。
- en: Another reason to favor RFs, is that they can efficiently estimate the prediction
    error while training the model, completely avoiding the need for separate validation
    sets. The error score is called the *out-of-bag score* and ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    is the typical metric computed. (*Bag* is an abbreviation of *bootstrap aggregation*,
    which we'll look at in detail in **Chapter 17** *Forests of Randomized Decision
    Trees*.) Recall that RFs are a collection of decision trees, each of which is
    trained on a subset of the training data. The out-of-bag (*OOB*) score looks at
    the prediction accuracy for a particular record using only those trees that did
    not train on that record. Statisticians have shown that the out-of-bag score gives
    an excellent estimate of a model's generality, its true prediction error.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 喜欢随机森林的另一个原因是，它们在训练模型的同时可以有效地估计预测误差，完全避免了需要单独的验证集的需求。误差分数被称为*离包分数*，![](../Images/ec985123b9b52e80981e6500795e8d16.png)是典型的计算指标。（*Bag*是*bootstrap
    aggregation*的缩写，我们将在第17章*随机决策树森林*中详细探讨。）回想一下，随机森林是一组决策树，每棵树都是在训练数据的一个子集上训练的。离包分数（*OOB*）通过只使用那些没有在该记录上训练的树来查看特定记录的预测准确性。统计学家已经证明，离包分数可以很好地估计模型的一般性，其真实的预测误差。
- en: 'The out-of-bag score is still not free computationally and we have to ask for
    the computation with an argument, `oob_score=True`, to the constructor of the
    RF. Here''s how to train a model that computes and prints the OOB score:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 离包分数在计算上仍然不是免费的，我们必须通过向RF的构造函数提供一个参数`oob_score=True`来请求计算。以下是训练一个计算并打印OOB分数的模型的步骤：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: OOB score -0.0076
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: OOB分数 -0.0076
- en: 'That score is terrible, approximately as bad as just predicting the average
    apartment rent price. Because this is our first exposure to ![](../Images/ec985123b9b52e80981e6500795e8d16.png),
    let''s get more comfortable with it by verifying that the average absolute error
    (MAE) in dollars is also terrible. To get a validation set, we have to hold out
    a random 20% subset. In noisy data sets, the range of values in the 20% we select
    could vary significantly from run to run, so let''s get a few MAE numbers for
    comparison. Here''s a simple test rig with the model-related code emphasized:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分数非常糟糕，大约和只预测平均公寓租金价格一样糟糕。因为这是我们第一次接触![](../Images/ec985123b9b52e80981e6500795e8d16.png)，让我们通过验证平均绝对误差（MAE）在美元上的表现也是糟糕的来更加熟悉它。为了获得一个验证集，我们必须保留一个随机的20%子集。在噪声数据集中，我们选择的20%中的值范围可能在每次运行中显著变化，所以让我们获得一些MAE数字进行比较。以下是一个简单的测试装置，其中强调了与模型相关的代码：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Validation MAE trials: $411 $872 $851 $498 $901 $395 $425 Average validation
    MAE $622'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 验证MAE试验：$411 $872 $851 $498 $901 $395 $425 平均验证MAE $622
- en: Those validation errors are definitely worse than the roughly $300 average error
    we saw on the clean data set from **Chapter 3** *A First Taste of Applied Machine
    Learning*. Also, the error values bounce around significantly, which means that
    different subsamples of the data set have different characteristics. This behavior
    is consistent with the low OOB ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score coming from the RF, indicating a model trained on the raw data set gets
    poor results.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这些验证错误肯定比我们在**第3章** *《应用机器学习的第一口滋味》*中看到的干净数据集的大约$300平均误差要差。此外，误差值波动很大，这意味着数据集的不同子样本具有不同的特征。这种行为与RF的低OOB![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)分数一致，表明在原始数据集上训练的模型结果不佳。
- en: Given the strength of RFs, poor performance could indicate there is little to
    no relationship to capture between apartment characteristics and rent price, or
    it could mean the data is inconsistent or has outliers. The variability of the
    hold out validation error hints that the data is inconsistent or has outliers,
    so let's take another look at the data set.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到RFs（随机森林）的强度，性能不佳可能表明公寓特征和租金价格之间几乎没有或没有可捕捉的关系，或者这可能意味着数据不一致或存在异常值。保留验证错误的变异性暗示数据可能不一致或存在异常值，因此让我们再次审视数据集。
- en: 5.3 Exploring and denoising the apartment rent data
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 探索和去噪公寓租金数据
- en: As we've mentioned, we want to avoid doing excessive snooping around in the
    data because it's tempting to start making judgments that negatively impact the
    generality of our model. But, in this case, the poor ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score and unstable validation error is a legitimate reason. The general concept
    of snooping around is called *exploratory data analysis* (EDA). We're going to
    explore the data with the explicit purpose of finding anomalies. The focus of
    our model is on typically-priced apartments and only within New York City proper,
    which means we're going to look for extreme rent values and apartments outside
    of New York City.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，我们想要避免在数据中过度挖掘，因为这会诱使我们开始做出可能对模型泛化产生负面影响的判断。但是，在这种情况下，较差的![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)分数和不稳定的验证错误是一个合理的理由。在数据中四处探索的一般概念被称为*探索性数据分析*（EDA）。我们将带着明确的目的去探索数据，以寻找异常值。我们模型的重点是典型价格的公寓，并且仅限于纽约市本身，这意味着我们将寻找极端的租金值和纽约市外的公寓。
- en: It's critical that we decide what these bounds are before looking at the data.
    Don't look at the data first and then decide on a definition of anomalous. You
    risk removing or altering data simply because it looks inconvenient or looks like
    it might confuse the model. For the apartment data, it's safe to say that an apartment
    for less than $1,000 in New York City is probably missing some key elements like
    windows and doors, so that should be our lowest price. At the high-end, let's
    call $10,000 outside the range of “reasonably priced.”
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看数据之前决定这些界限至关重要。不要先查看数据，然后再决定异常值的定义。你可能会因为数据看起来不方便或可能混淆模型而删除或更改数据。对于公寓数据来说，可以安全地说，在纽约市价格低于1000美元的公寓可能缺少一些关键元素，如窗户和门，因此这应该是我们的最低价格。在高端，我们将10000美元视为“合理价格”范围之外。
- en: 'With those bounds established, let''s take get a high-level look at the complete
    data set. Here''s how to get some basic statistics:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定了这些界限之后，让我们从高层次上审视完整的数据集。以下是如何获取一些基本统计信息的方法：
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '|   | bathrooms | bedrooms | longitude | latitude | price |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|   | 卫生间 | 卧室 | 经度 | 纬度 | 价格 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| count | 49352.0000 | 49352.0000 | 49352.0000 | 49352.0000 | 49352.0000 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 计数 | 49352.0000 | 49352.0000 | 49352.0000 | 49352.0000 | 49352.0000 |'
- en: '| mean | 1.2122 | 1.5416 | -73.9557 | 40.7415 | 3830.1740 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 1.2122 | 1.5416 | -73.9557 | 40.7415 | 3830.1740 |'
- en: '| std | 0.5014 | 1.1150 | 1.1779 | 0.6385 | 22066.8659 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 标准差 | 0.5014 | 1.1150 | 1.1779 | 0.6385 | 22066.8659 |'
- en: '| min | 0.0000 | 0.0000 | -118.2710 | 0.0000 | 43.0000 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 最小值 | 0.0000 | 0.0000 | -118.2710 | 0.0000 | 43.0000 |'
- en: '| 25% | 1.0000 | 1.0000 | -73.9917 | 40.7283 | 2500.0000 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 25% | 1.0000 | 1.0000 | -73.9917 | 40.7283 | 2500.0000 |'
- en: '| 50% | 1.0000 | 1.0000 | -73.9779 | 40.7518 | 3150.0000 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 1.0000 | 1.0000 | -73.9779 | 40.7518 | 3150.0000 |'
- en: '| 75% | 1.0000 | 2.0000 | -73.9548 | 40.7743 | 4100.0000 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 75% | 1.0000 | 2.0000 | -73.9548 | 40.7743 | 4100.0000 |'
- en: '| max | 10.0000 | 8.0000 | 0.0000 | 44.8835 | 4490000.0000 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 10.0000 | 8.0000 | 0.0000 | 44.8835 | 4490000.0000 |'
- en: A number of anomalies pop out from the minimum and maximum for each column.
    There's a place with 10 bathrooms and another with 8 bedrooms. There is a reference
    to longitude 0, which is the prime meridian (Greenwich, England), and a reference
    to latitude zero, the equator. Oh, and let's not forget the apartment that costs
    $4,490,000 per month or the intriguing place that costs $43 per month (probably
    an abandoned vehicle or an apartment that is currently on fire).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 每一列的最小值和最大值都出现了一些异常。有一个地方有10个浴室，另一个地方有8个卧室。还有一个经度为0的参考，这是本初子午线（英国格林尼治），还有一个纬度为0的参考，即赤道。哦，别忘了那个每月租金为449万美元的公寓，或者那个每月租金仅为43美元的有趣地方（可能是一辆废弃的车辆或目前正在着火的公寓）。
- en: 5.3.1 Examining the data distributions
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 检查数据分布
- en: 'Before we start slashing and burning the data set, let''s look more closely
    at the *distribution* of the features. The distribution of a feature is a term
    that, loosely speaking, describes how the values of that feature are spread across
    the range of that feature. (Statisticians call the distribution a *density function*,
    which maps a feature value to the probability of occurrence.) There are number
    of ways we can examine the distribution, such as sorting the prices in reverse
    order and looking at the top price values:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始对数据集进行砍伐和焚烧之前，让我们更仔细地看看特征的*分布*。一个特征的分布是一个术语，大致上描述了该特征值在该特征值范围内的分布情况。（统计学家将分布称为*密度函数*，它将特征值映射到发生概率。）我们可以以多种方式检查分布，例如按价格降序排序并查看最高价格值：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '19558 4490000 9590 1150000 30689 1070000 29665 1070000 10581 135000 25538 111111
    45674 100000 29082 90000 7336 85000 47995 80000 Name: price, dtype: int64'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 19558 4490000 9590 1150000 30689 1070000 29665 1070000 10581 135000 25538 111111
    45674 100000 29082 90000 7336 85000 47995 80000 名称：价格，数据类型：int64
- en: Wow, it looks like there are a number of very expensive apartments (values in
    the right column). Values that are very different in magnitude from the others
    in the feature or target space (range) are called *outliers*. Outliers could be
    the result of noise, but some data sets have outliers that are correct values,
    as is the case here. In New York City, it's certain that there are some hyper-expensive
    apartments and a smattering of apartments from there down to the merely very-expensive
    apartments. (Evaluating `len(df[df.price>10_000])` shows 878 apartments that rent
    for more than $10,000.)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，看起来有很多非常昂贵的公寓（右侧列的值）。与特征或目标空间（范围）中的其他值相比，数值差异很大的值被称为*异常值*。异常值可能是噪声的结果，但某些数据集的异常值是正确的值，就像这里的情况一样。在纽约市，肯定有一些超昂贵的公寓，以及一些从那里到仅仅是非常昂贵的公寓的公寓。
    （评估 `len(df[df.price>10_000])` 显示有878套公寓的租金超过10,000美元。）
- en: Another exploratory technique is to ask pandas for the count of each unique
    value in a particular column, such as the counts of apartments with specific numbers
    of bathrooms and bedrooms.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种探索性方法是询问 pandas 对特定列中每个唯一值的计数，例如具有特定数量浴室和卧室的公寓数量。
- en: '|'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE13]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '1.0 39422 2.0 7660 3.0 745 1.5 645 0.0 313 2.5 277 4.0 159 3.5 70 4.5 29 5.0
    20 5.5 5 6.0 4 6.5 1 10.0 1 7.0 1 Name: bathrooms, dtype: int64 |'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 1.0 39422 2.0 7660 3.0 745 1.5 645 0.0 313 2.5 277 4.0 159 3.5 70 4.5 29 5.0
    20 5.5 5 6.0 4 6.5 1 10.0 1 7.0 1 名称：浴室，数据类型：int64 |
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '1 15752 2 14623 0 9475 3 7276 4 1929 5 247 6 46 8 2 7 2 Name: bedrooms, dtype:
    int64 |'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 1 15752 2 14623 0 9475 3 7276 4 1929 5 247 6 46 8 2 7 2 名称：卧室，数据类型：int64 |
- en: 'It looks like there are only a few outlier apartments listed as having more
    than six bathrooms (out of 44,416) and only a few having more than six bedrooms.
    We can also look at this data visually as a [histogram](https://en.wikipedia.org/wiki/Histogram),
    which breaks up the range of values into fixed-size bins and then counts how many
    values fall into each range:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来只有少数几套公寓被列为拥有超过六个浴室（44,416套中的几套）和只有少数几套拥有超过六个卧室。我们还可以将此数据以直方图的形式进行可视化，它将值范围分成固定大小的区间，然后计算每个区间中有多少个值：
- en: » *Generated by code to left*
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: » *由左侧代码生成*
- en: '[![](../Images/697a27b8b8fa55635ff45ea348106849.png)](images/prep/prep_sniff_16.svg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/697a27b8b8fa55635ff45ea348106849.png)](images/prep/prep_sniff_16.svg)'
- en: '[PRE15]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: (See the aside on color palettes for more on the `bookcolors['blue']` expression.)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: （有关 `bookcolors['blue']` 表达式的更多信息，请参阅有关调色板的附加说明。）
- en: '**Using a consistent color palette**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用一致的调色板**'
- en: A common mistake we see among our students is to use essentially random colors
    or at least inconsistent colors across graphs. In one graph, feature price is
    purple and in the next graph the same feature is green. Humans are very sensitive
    to color and attach meaning to the various colors subconsciously, so it's important
    to be consistent across visualizations. When drawing diagrams manually, it's a
    good idea to choose from a consistent color palette as well. For this book, we
    selected
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到学生中常见的错误是使用基本上是随机的颜色，或者至少在图表中使用不一致的颜色。在一个图表中，特征价格是紫色，而在下一个图表中，相同的特征是绿色。人类对颜色非常敏感，并会在潜意识中赋予各种颜色意义，因此在不同可视化中保持一致性很重要。当手动绘制图表时，选择一个一致的调色板也是一个好主意。对于这本书，我们选择了
- en: '![](../Images/5677b947e832f35db92b8f19e47e3e75.png)as our palette and choose
    from those colors when drawing diagrams. Python code used in the remainder of
    the book will select colors from this pallet using a simple dictionary mechanism:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/5677b947e832f35db92b8f19e47e3e75.png)作为我们的调色板，并在绘制图表时从这些颜色中选择。本书剩余部分使用的Python代码将通过简单的字典机制从该调色板中选择颜色：'
- en: '[PRE16]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We will look up our shade of blue using `bookcolors['blue']` rather than relying
    on whatever the default blue color is for matplotlib.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`bookcolors['blue']`来查找我们的蓝色调色板，而不是依赖于matplotlib的默认蓝色颜色。
- en: The color palette you choose should also be accessible to those with forms of
    colorblindness and make sure the contrast between text and its background is high
    enough contrast for the visually impaired. Chrome's Accessibility Developer Tools
    run an excellent audit for you. A nice site for selecting color pallets is [colorbrewer2.org](http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3);
    make sure to check the “colorblind safe” box so it only shows you colorblind safe
    pallets. When you do draw a diagram, you can also check what it looks like to
    colorblind individuals by uploading that image to [vischeck](http://www.vischeck.com/vischeck/vischeckImage.php).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你选择的调色板也应该对色盲人士友好，并确保文本与其背景之间的对比度足够高，以便视觉障碍人士也能看清楚。Chrome的访问性开发者工具为你提供了一个出色的审计功能。一个不错的颜色调板选择网站是[colorbrewer2.org](http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3)；请确保勾选“色盲安全”选项，以便它只显示色盲安全调板。当你绘制图表时，你也可以通过上传该图像到[vischeck](http://www.vischeck.com/vischeck/vischeckImage.php)来检查色盲人士看到的图表是什么样的。
- en: 'There are also strange things going on with the longitude and latitude features,
    which also popped out from the `df_num.describe()` (see min, max for longitude
    and latitude). There are 12 apartments at location 0,0:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 经纬度特征也存在一些奇怪的现象，这些现象也出现在`df_num.describe()`中（见经度和纬度的最小值和最大值）。在位置0,0有12套公寓：
- en: '[PRE17]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '12'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '12'
- en: Instead of the literal interpretation of 0,0 as apartments floating off the
    west coast of Africa, those values probably represent missing data (manager too
    lazy to look it up). On the other hand, actual values of 0 are technically not
    missing so we could also think of these values erroneous or, more commonly, *noise*.
    Other sources of noise include typos entered by humans or physical devices, such
    as faulty temperature sensors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是将0,0字面解释为漂浮在非洲西海岸的公寓，这些值可能代表缺失数据（管理员太懒，没有查找）。另一方面，实际值为0在技术上不是缺失值，因此我们也可以将这些值视为错误或更常见的*噪声*。其他噪声来源包括人类输入的打字错误或物理设备，如故障温度传感器。
- en: 'Noise and outliers are potential problems because they can lead to inconsistencies.
    An *inconsistency* is a set of similar or identical feature vectors with much
    different target values. For example, if we zero in on the region of New York
    City containing two apartments over $1,000,000, we see other apartments with the
    same characteristics but with reasonable prices:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声和异常值可能是潜在问题，因为它们可能导致不一致。*不一致*是一组具有相似或相同特征向量但目标值差异很大的特征向量。例如，如果我们聚焦于纽约市包含两个超过100万美元的公寓的区域，我们会看到其他具有相同特征但价格合理的公寓：
- en: '[PRE18]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '|   | bedrooms | bathrooms | street_address | price |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|   | 卧室 | 卫生间 | 街道地址 | 价格 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 39939 | 1 | 1.0000 | west 54 st & 8 ave | 2300 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 39939 | 1 | 1.0000 | west 54 st & 8 ave | 2300 |'
- en: '| 21711 | 1 | 1.0000 | 300 West 55th Street | 2400 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 21711 | 1 | 1.0000 | 300 West 55th Street | 2400 |'
- en: '| 15352 | 1 | 1.0000 | 300 West 55th Street | 3350 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 15352 | 1 | 1.0000 | 300 West 55th Street | 3350 |'
- en: '| 48274 | 1 | 1.0000 | 300 West 55th Street | 3400 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 48274 | 1 | 1.0000 | 300 West 55th Street | 3400 |'
- en: '| 29665 | 1 | 1.0000 | 333 West 57th Street | 1070000 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 29665 | 1 | 1.0000 | 333 West 57th Street | 1070000 |'
- en: '| 30689 | 1 | 1.0000 | 333 West 57th Street | 1070000 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 30689 | 1 | 1.0000 | 333 West 57th Street | 1070000 |'
- en: Those ridiculously-priced apartments could be errors or simply outliers, but
    no matter how powerful a machine learning model is, such inconsistent data leads
    to inaccurate predictions. RFs predict the average price for all apartments whose
    features cluster them together (`np.mean(local.price)`=$358575.000 in this case),
    meaning that predictions for all apartments will be hundreds of thousands of dollars
    off.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 那些价格离谱的公寓可能是错误或仅仅是异常值，但无论机器学习模型多么强大，这种不一致的数据都会导致预测不准确。随机森林（RFs）预测所有特征聚类在一起的公寓的平均价格（本例中为
    `np.mean(local.price)`=$358575.000），这意味着所有公寓的预测都将偏离数十万美元。
- en: Now that we have some idea about the outliers and noise in the data set, let's
    do some cleanup work.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对数据集中的异常和噪声有一些了解，让我们做一些清理工作。
- en: 5.3.2 Excising the anomalies
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 删除异常值
- en: We can either leave noisy or outlier records as-is, delete, or “fix” the records,
    but you should err on the side of leaving records as-is. Which alternative we
    choose depends on knowledge about this domain, the goals of the model, how numerous
    the anomalies are, and even what we see in the individual records with anomalous
    values. (Missing data adds another wrinkle.)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择保留嘈杂或异常记录不变、删除或“修复”记录，但你应该选择保留记录不变。我们选择哪种替代方案取决于对这个领域的了解、模型的目标、异常的数量以及我们在具有异常值的单个记录中看到的内容。（缺失数据增加了另一个复杂因素。）
- en: There is no substitute for domain knowledge when building a model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型时，没有领域知识是无法替代的。
- en: 'The most important filter to apply relates to the goals of our model, in this
    case, reasonably-priced apartments just in New York City. We can delete with confidence
    any records outside of these bounds. Pandas has excellent facilities to select
    subsets of the records. For example, `df_num.price>1_000` gives a column of true
    and false values computed by looking at each value in the price column. We can
    then use that column of boolean values as a multi-valued index into the data frame,
    which selects only those rows associated with true values. So, `df_num[df_num.price>1_000]`
    returns a subset of the records in `df_num` whose price is greater than $1,000\.
    We can also do both comparisons at once and assign the dataframe back to a new
    `df_clean` variable:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 应用最重要的过滤器与我们的模型目标相关，在这种情况下，是纽约市合理价格的公寓。我们可以有信心删除这些界限之外的任何记录。Pandas 提供了出色的功能来选择记录的子集。例如，`df_num.price>1_000`
    会根据价格列中的每个值计算出一个包含真和假值的列。然后我们可以使用这个布尔值列作为数据框的多值索引，从而只选择与真值相关的行。因此，`df_num[df_num.price>1_000]`
    返回 `df_num` 中价格大于 $1,000 的记录子集。我们也可以同时进行这两个比较，并将数据框赋值回一个新的 `df_clean` 变量：
- en: '[PRE19]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Selecting a subset of rows is an example of a pandas “view,” which returns a
    filtered perspective on the original data, rather than making a copy.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 选择行子集是 pandas “视图”的一个例子，它返回对原始数据的过滤视角，而不是创建副本。
- en: 'To visualize the distribution of cleaned-up prices, let''s use a histogram
    again:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化清理后的价格分布，我们再次使用直方图：
- en: » *Generated by code to left*
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '> *由左侧代码生成*'
- en: '[![](../Images/961ad42a641f85c9b5c6b9f4b0c733b9.png)](images/prep/prep_sniff_22.svg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](../Images/961ad42a641f85c9b5c6b9f4b0c733b9.png)(images/prep/prep_sniff_22.svg)'
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'It''s always best to use domain knowledge when identifying outliers, but if
    we are uncertain about an appropriate range, we can always clip out the bottom
    and top 1% using a bit of NumPy code. The distribution of the middle 98% of the
    prices looks pretty similar to the clipped version:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在识别异常值时，始终最好使用领域知识，但如果我们对适当的范围不确定，我们可以使用一些 NumPy 代码始终剪切掉底部和顶部的 1%。中间 98% 的价格分布看起来与剪切版本非常相似：
- en: » *Generated by code to left*
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '> *由左侧代码生成*'
- en: '[![](../Images/2d2163ad31508092537f71db99fb16f8.png)](images/prep/prep_sniff_23.svg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](../Images/2d2163ad31508092537f71db99fb16f8.png)(images/prep/prep_sniff_23.svg)'
- en: '[PRE21]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It looks like we have the prices under control now, so let''s turn to deleting
    records outside of New York City proper. We saw previously that there are records
    with longitude and latitude values of zero. These likely represent missing values
    and missing values should normally be handled using techniques from [chp:feateng].
    In this case, however, we find that there are only a few of such records:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们现在已经控制了价格，所以让我们转向删除纽约市以外的记录。我们之前看到有一些经纬度为零的记录。这些很可能代表缺失值，通常应该使用 [chp:feateng]
    中的技术来处理缺失值。然而，在这种情况下，我们发现只有少数这样的记录：
- en: '[PRE22]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '11'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '11'
- en: 'We can delete those 11 records without significantly affecting the training
    set:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以删除这 11 条记录，而不会对训练集产生重大影响：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'A few apartments have GPS coordinates that put them in Boston, not New York
    City (for example, latitude, longitude of 40.5813, -74.5343). These coordinates
    could be typos or just erroneous lookups done by apartment managers. By scrutinizing
    the records, we could probably figure out whether it''s a typo, but there are
    so few, we can just delete them. New York City does not fit neatly in a square,
    but we can still decide on a bounding box around it and then delete records outside
    of that box. A quick check at [gps-coordinates.org](https://gps-coordinates.org/new-york-city-latitude.php),
    gives a rough outline for New York City of latitude, longitude 40.55, -74.1 on
    the lower left and 40.94, -73.67 on the upper right. We can filter `df_clean`
    for this bounding box using another query:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 几个公寓的GPS坐标将它们定位在波士顿，而不是纽约市（例如，纬度40.5813，经度-74.5343）。这些坐标可能是打字错误，或者是公寓经理进行的错误查询。通过仔细审查记录，我们可能能判断出这是否是打字错误，但由于数量很少，我们可以直接删除它们。纽约市并不完美地适合在一个方形区域内，但我们仍然可以围绕它确定一个边界框，然后删除该框外的记录。在[gps-coordinates.org](https://gps-coordinates.org/new-york-city-latitude.php)上快速查看，给出了纽约市的大致轮廓，左下角的纬度是40.55，经度是-74.1，右上角的纬度是40.94，经度是-73.67。我们可以使用另一个查询来过滤`df_clean`以获取这个边界框：
- en: '[PRE24]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Stripping these records is “legal” because they don't fit within the goal previously
    established for the model. We are not arbitrarily deleting records.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 移除这些记录是“合法”的，因为它们不符合之前为模型设定的目标。我们并不是任意删除记录。
- en: The next step could be to examine the few records with extreme numbers of bedrooms
    or bathrooms, but there are so few, it's unlikely they would skew the data set.
    This is particularly true after we've removed price outliers, so let's leave those
    records as-is.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步可能是检查那些具有极端数量卧室或浴室的少量记录，但由于数量很少，它们不太可能扭曲数据集。这尤其在我们移除了价格异常值之后是正确的，所以让我们保留这些记录不变。
- en: 5.4 Comparing models trained on denoised data
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 比较在去噪数据上训练的模型
- en: 'At this point, we''ve cleaned up the data set so that it falls within the focus
    of our model, reasonably-price departments in New York City. We''ve achieved the
    same data set as file `rent-idea.csv` used in **Chapter 3** *A First Taste of
    Applied Machine Learning*. We''re ready to train a model on this denoised data
    set to see if the model performance has improved:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经清理了数据集，使其符合我们模型的重点，即纽约市合理价格的部门。我们已经达到了与**第3章** *《应用机器学习的初尝》*中使用的文件`rent-idea.csv`相同的数据集。我们现在可以在这个去噪数据集上训练一个模型，看看模型性能是否有所提高：
- en: '[PRE25]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Validation OOB score 0.8677
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 验证OOB分数 0.8677
- en: 'Let''s also verify that the MAE is the same as we saw for the ideal data set
    (only the output is shown for brevity):'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也验证一下MAE是否与我们在理想数据集中看到的一致（为了简洁起见，只显示了输出）：
- en: 'Validation MAE trials: $293 $293 $296 $290 $293 $300 $296 Average clean validation
    MAE $294'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 验证MAE试验：$293 $293 $296 $290 $293 $300 $296 平均清洁验证MAE $294
- en: Great! We've now got a prediction model that gets a decent ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    estimated prediction error. Are we done yet? That depends on the definition of
    “good enough” and whether we think we can do better. Imagine a website that used
    our model to predictor rent prices using apartment features entered by a user.
    There is likely a threshold below which users don't find the predictions useful.
    If we have a suitable way to test “good enough,” this should guide whether we
    keep looking for improvements.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！我们现在已经得到了一个具有合理的预测误差的预测模型！我们是否已经完成了？这取决于“足够好”的定义以及我们是否认为我们可以做得更好。想象一下一个网站，它使用我们的模型来预测用户输入的公寓特征所对应的租金价格。很可能存在一个阈值，低于这个阈值用户不会觉得预测有用。如果我们有合适的方式来测试“足够好”，这应该指导我们是否继续寻找改进。
- en: Don't try out too many models because it's a form of overfitting. Eventually,
    you'll find a model that spuriously finds a relationship.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 不要尝试太多的模型，因为这是一种过度拟合的形式。最终，你可能会找到一个错误地发现关系的模型。
- en: 'Let''s assume that we''d like to improve the model''s accuracy. We can try
    different models, but it''s unlikely they would perform significantly better and
    many would perform worse. For example, a linear prediction model called [Lasso
    Regression](https://goo.gl/A9C1Sf) is often a good baseline, but it can''t compute
    an ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score as a result of training
    so we have to hold out a validation set. Here''s a snippet to train the model
    and print the ![](../Images/ec985123b9b52e80981e6500795e8d16.png) scores for the
    training and test sets:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要提高模型的精度。我们可以尝试不同的模型，但它们不太可能表现出显著的改进，而且许多模型的表现会更差。例如，一个名为 [Lasso 回归](https://goo.gl/A9C1Sf)
    的线性预测模型通常是一个很好的基线，但它无法计算训练后的 ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    分数，因此我们必须保留一个验证集。以下是一个训练模型并打印训练集和测试集的 ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    分数的代码片段：
- en: '[PRE26]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: LM Training score 0.5764 LM Validation score 0.5740
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: LM 训练分数 0.5764 LM 验证分数 0.5740
- en: Even the linear model's *training* ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    is significantly worse than the RF's validation score. The linear model is unable
    to capture the relationship between features and apartment price even for training
    data.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是线性模型的 *训练* ![](../Images/ec985123b9b52e80981e6500795e8d16.png) 也明显比 RF 的验证分数差。线性模型甚至无法捕捉到特征与公寓价格之间的关系，即使是训练数据。
- en: 5Normally, a grid search over the hyper parameters is required to tune the model
    and get the best accuracy, but with default parameters gradient boosting does
    not perform as well as an RF for this data set.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，需要对超参数进行网格搜索以调整模型并获取最佳精度，但默认参数的梯度提升在此数据集上并不如 RF 表现得好。
- en: The [gradient boosting](file:///Users/parrt/github/website-explained.ai/gradient-boosting/index.html)
    model is another popular and powerful model (based upon decision trees like RFs),
    but it also fails to capture the relationship as well as an RF:5
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[梯度提升](file:///Users/parrt/github/website-explained.ai/gradient-boosting/index.html)
    模型是另一个流行且强大的模型（基于与 RF 类似的决策树），但它也未能像 RF 那样捕捉到关系：5'
- en: '[PRE27]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: GB Training score 0.8425 GB Validation score 0.8046
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: GB 训练分数 0.8425 GB 验证分数 0.8046
- en: Given the ![](../Images/ec985123b9b52e80981e6500795e8d16.png) and MAE scores
    from our RF model and that model's favorable comparison to other models, it's
    reasonable to declare victory over this problem. Our solution comes from cleaning
    the data to make life easier on the model, rather than choosing the right model
    on the raw data set.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们的 RF 模型的 ![](../Images/ec985123b9b52e80981e6500795e8d16.png) 和 MAE 分数，以及该模型与其他模型的良好比较，宣布解决这个问题是合理的。我们的解决方案来自于清理数据，使模型更容易处理，而不是在原始数据集上选择正确的模型。
- en: How much we care about cleaning up the data depends on the model we're using
    and whether the offending values are in predictor variables (features) or the
    target. One of the advantages of RFs is that they deal gracefully with errors
    and outliers in the predictor variables. RFs behave like nearest-neighbor models
    and feature outliers are partitioned off into lonely corners of the feature space
    automatically. Anomalous values in the target variable are also not a problem,
    unless they lead to inconsistencies, samples with the same or similar feature
    vectors but huge variation in the target values. No model deals well with inconsistent
    training data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对清理数据的关注程度取决于我们使用的模型以及违规值是否在预测变量（特征）或目标中。RF 的一项优点是它们能够优雅地处理预测变量中的错误和异常值。RF
    的行为类似于最近邻模型，特征异常值会自动分区到特征空间的孤立角落。目标变量中的异常值也不是问题，除非它们导致不一致，即具有相同或相似特征向量但目标值差异巨大的样本。没有模型能够很好地处理不一致的训练数据。
- en: 'The inconsistencies in this apartment data set stem from the outliers: the
    extreme apartment rent prices seen in the target variable. That''s why snipping
    out those records as “don''t cares” improves model performance, but there''s a
    final trick that you should know about that hammers down those extreme values.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公寓数据集中的不一致性源于异常值：目标变量中看到的极端公寓租金价格。这就是为什么将这些记录剪掉作为“无关紧要的”可以提高模型性能，但还有一个你应该知道的最终技巧，那就是将这些极端值压低。
- en: 5.5 Log in, exp out
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 登录，退出
- en: Taking the log of a predictor or target variable is useful when there are outliers
    that can't be filtered out because they are important to the model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在无法过滤掉的异常值（因为它们对模型很重要）时，对预测变量或目标变量的对数是有用的。
- en: Transforming the target variable (using the mathematical *log* function) into
    a tighter, more uniform space makes life easier for any model. In some sense,
    the log trick is the opposite of the technique we've done so far in this chapter,
    where we've examined the data and done a lot a little “nip and tuck” operations.
    Now, we're going to perform a single cleaning transformation and get decent accuracy,
    all without having to look at the data and without New York City apartment domain
    expertise.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 将目标变量（使用数学的*对数*函数）转换为一个更紧凑、更均匀的空间，使任何模型的生活更加容易。从某种意义上说，对数技巧是我们在本章中迄今为止所做技术的相反，我们检查了数据并进行了大量的“小手术”操作。现在，我们将执行一个单一的清理转换，并获得相当准确的精度，而无需查看数据，也不需要纽约市公寓领域的专业知识。
- en: The only problem is that, while easy to execute, understanding why taking the
    log of the target variable works and how it affects the training/testing process
    is intellectually challenging. (Both Terence and Jeremy agree that, at the beginning,
    this transformation added nontrivial cognitive load for us.) You can skip this
    section for now, if you like, but just remember that this technique exists and
    check back here if needed in the future.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的问题是，虽然执行起来容易，但要理解为什么对目标变量取对数有效以及它如何影响训练/测试过程，在智力上具有挑战性。（特伦斯和杰里米都认为，一开始，这种转换给我们增加了非同小可的认知负担。）如果你愿意，现在可以跳过这一部分，但请记住，这项技术存在，如果将来需要，请再次查看此处。
- en: '[![](../Images/164565eaf6423d588107a3a5159303fe.png)](images/prep/prep_logs_2.svg)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/164565eaf6423d588107a3a5159303fe.png)](images/prep/prep_logs_2.svg)'
- en: '**Figure 5.1**. Histogram of prices clipped to less than $20,000 and zoomed
    in to make the long right tail more apparent; the triangle marks the average price.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**图5.1**. 价格剪裁至20,000美元以下并放大以使长右尾更明显；三角形标记的是平均价格。'
- en: 7Averages are highly sensitive to outliers; consider the average salary of 10
    of your friends and then add Bill Gates' salary, which would drive the average
    up tremendously.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值对异常值非常敏感；考虑一下你10个朋友的平均工资，然后再加上比尔·盖茨的工资，这会将平均值大幅提升。
- en: To arrive at the log trick, let's look at the distribution of prices again.
    **Figure 5.1** shows the distribution of prices clipped to less than $20,000 and
    zoomed in to show part of the long right tail. Long tails are not necessarily
    a problem themselves; it's the inconsistencies caused by the outliers that lead
    to inaccurate models. During training, RFs combine the prices of identical or
    nearly-identical apartments by averaging them together, thus, forming the prediction
    for those apartments. But, outlier prices wildly skew average prices, so the model's
    predictions could be very far off.7
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 为了达到对数技巧，让我们再次看看价格分布。**图5.1**显示了价格剪裁至20,000美元以下并放大以显示长右尾的一部分。长尾本身并不一定是问题；由异常值引起的不一致性导致了不准确的模型。在训练过程中，随机森林通过平均相同或几乎相同的公寓的价格将它们结合起来，从而为这些公寓形成预测。但是，异常价格会极大地扭曲平均价格，因此模型的预测可能会非常不准确。7
- en: '[![](../Images/bcaa95a0d7a7b0c814748bb793c4cdf4.png)](images/prep/prep_logs_3.svg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/bcaa95a0d7a7b0c814748bb793c4cdf4.png)](images/prep/prep_logs_3.svg)'
- en: '**Figure 5.2**. Histogram of natural log(prices) without clipping outliers;
    the triangle marks the average log price.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**图5.2**. 未剪裁异常值的自然对数（价格）直方图；三角形标记的是平均对数价格。'
- en: Optimally, the distribution of prices would be a narrow “bell curve” distribution
    without a tail. This would make predictions based upon average prices more accurate.
    We need a mathematical operation that transforms the widely-distributed target
    prices into a new space. The “price in dollars space” has a long right tail because
    of outliers and we want to squeeze that space into a new space that is normally
    distributed (“bell curved”). More specifically, we need to shrink large values
    a lot and smaller values a little. That magic operation is called the *logarithm*
    or log for short. **Figure 5.2** shows the histogram resulting from taking the
    log of *all* prices in the data set. We get a nice normally-shaped distribution
    of prices without having to clip outliers. (See **Section 19.3** *Log, orders
    of magnitude, and Euler's number* for more on log.) The max price has dropped
    from millions to about 10.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，价格分布将是一个狭窄的“钟形曲线”分布，没有尾部。这将使基于平均价格进行的预测更加准确。我们需要一个数学运算，将广泛分布的目标价格转换到新的空间。由于异常值，“价格在美元空间”有一个长长的右尾，我们希望将其挤压到一个新的空间，该空间是正态分布的（“钟形曲线”）。更具体地说，我们需要大量缩小大值，稍微缩小小值。这个神奇的操作称为对数或简称为
    log。**图 5.2** 展示了从数据集中所有价格取对数得到的直方图。我们得到了一个没有剪裁异常值的好看的正态分布的价格分布。（有关对数的更多信息，请参阅
    **第 19.3 节** 对数、数量级和欧拉数。）
- en: 'That''s a cool trick to reshape the price distribution, but let''s look at
    the actual effect on some prices. Previously, we looked at the records from a
    tiny patch of New York City that had some extreme outlier prices. Here are those
    records again (in variable `df_local`), but with a new column that shows the log
    of the price to see how it shrinks the values:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个重塑价格分布的酷技巧，但让我们看看它对一些实际价格的实际影响。之前，我们查看了一些来自纽约市一小块区域的记录，其中有一些极端的异常值价格。这里再次展示那些记录（在变量
    `df_local` 中），但新增了一列，显示价格的对数，以查看它如何缩小值：
- en: '|   | bedrooms | bathrooms | street_address | price | log(price) |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|    | 卧室 | 卫生间 | 街道地址 | 价格 | log(price) |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 39939 | 1 | 1 | west 54 st & 8 ave | 2300 | 7.7407 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 39939 | 1 | 1 | west 54 st & 8 ave | 2300 | 7.7407 |'
- en: '| 21711 | 1 | 1 | 300 West 55th Street | 2400 | 7.7832 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 21711 | 1 | 1 | 300 West 55th Street | 2400 | 7.7832 |'
- en: '| 15352 | 1 | 1 | 300 West 55th Street | 3350 | 8.1167 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 15352 | 1 | 1 | 300 West 55th Street | 3350 | 8.1167 |'
- en: '| 48274 | 1 | 1 | 300 West 55th Street | 3400 | 8.1315 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 48274 | 1 | 1 | 300 West 55th Street | 3400 | 8.1315 |'
- en: '| 29665 | 1 | 1 | 333 West 57th Street | 1070000 | 13.8832 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 29665 | 1 | 1 | 333 West 57th Street | 1070000 | 13.8832 |'
- en: '| 30689 | 1 | 1 | 333 West 57th Street | 1070000 | 13.8832 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 30689 | 1 | 1 | 333 West 57th Street | 1070000 | 13.8832 |'
- en: An RF trained on the raw prices, would predict a terrible average price of `np.mean(df_local.price)`=$358575.000
    whereas an RF trained on the log of the prices predicts an average of `np.mean(np.log(df_local.price))`=9.923\.
    At least in the log-of-price space, predicting the average seems like a good bet
    because that average log price is closer to the log price of the reasonably-price
    apartments. To transform prices back to the dollars space, we use the inverse
    of the log, which is the *exp* (exponential) function and get a prediction of
    $20395.690\. By taking the average in the log price space rather than raw prices,
    the average is less sensitive to outliers because we have scrunched the space
    (outliers are brought close in).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始价格上训练的 RF 模型会预测一个糟糕的平均价格 `np.mean(df_local.price)`=$358575.000，而基于价格对数训练的
    RF 模型则预测平均值为 `np.mean(np.log(df_local.price))`=9.923。至少在价格对数空间中，预测平均值似乎是一个不错的赌注，因为平均对数价格更接近合理价格公寓的对数价格。为了将价格转换回美元空间，我们使用对数的逆运算，即指数函数
    exp，得到预测值为 $20395.690。通过在价格对数空间而不是原始价格上取平均值，平均价格对异常值更不敏感，因为我们已经压缩了空间（异常值被拉近）。
- en: Ok, so it makes sense to take the log because it transforms a skewed distribution
    to a normal distribution and it seems useful on one piece of the data. Let's see
    if taking the log of the target variable affects the overall accuracy of a model
    trained on the original, noisy data set.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，所以取对数是有意义的，因为它将偏斜分布转换为正态分布，并且似乎在数据的一个部分中很有用。让我们看看对目标变量取对数是否会影响在原始、有噪声的数据集上训练的模型的总体准确性。
- en: '[PRE28]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: OOB R^2 score for log(price) 0.8767
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: OOB R^2 分数对于 log(price) 为 0.8767
- en: Recall the poor ![](../Images/ec985123b9b52e80981e6500795e8d16.png) of -0.008
    for the model trained on the raw prices. By taking the log of the prices, our
    model's OOB ![](../Images/ec985123b9b52e80981e6500795e8d16.png) matches the ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    of 0.868 from the model trained on just the apartments less than $10,000\. Without
    having to clean the data or know anything about the domain, we achieved the same
    score as the model trainined on the clean data set!
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，对于在原始价格上训练的模型，其![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)为-0.008的糟糕表现。通过取价格的对数，我们的模型在验证集上的![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)与仅对低于10,000美元的公寓进行训练的模型的![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)
    0.868相匹配。无需清理数据或了解任何关于该领域的知识，我们就达到了与在干净数据集上训练的模型相同的评分！
- en: 'To make actual predictions for some `X_test`, though, we have to take the exp
    of model predictions to get prices in dollars instead of log dollars (![](../Images/c983abfa22704f82b36242d1637f9869.png)
    = x):'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了对某些`X_test`进行实际预测，我们必须取模型预测的指数，以得到以美元为单位的价格而不是对数美元（![评分](../Images/c983abfa22704f82b36242d1637f9869.png)
    = x）：
- en: '[PRE29]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: If you are using the ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score
    as the metric to assess model performance, then you're done. But, the ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score isn't the only way to measure performance. We've already seen the MAE and
    there are many others, each one measuring something different related to actual
    versus predicted prices. For example, despite getting a good ![](../Images/ec985123b9b52e80981e6500795e8d16.png),
    the MAE score for a model trained on the log of prices is not nearly as good as
    the MAE for a model trained on clean data. If we care more about MAE than ![](../Images/ec985123b9b52e80981e6500795e8d16.png),
    then cleaning the data gets us a better model than simply taking the log of the
    prices. In the next chapter, we'll learn more about assessing regressor performance
    and how we have to carefully choose an appropriate metric according to the needs
    of our application.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正使用![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)作为评估模型性能的指标，那么你已经完成了。但是，![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)评分并不是衡量性能的唯一方式。我们已经看到了MAE（平均绝对误差），还有许多其他指标，每个指标都测量与实际价格和预测价格相关的不同方面。例如，尽管得到了一个好的![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)，但对于在价格的对数上训练的模型的MAE评分远不如在干净数据上训练的模型的MAE评分。如果我们更关心MAE而不是![评分](../Images/ec985123b9b52e80981e6500795e8d16.png)，那么清理数据比仅仅取价格的对数能让我们得到更好的模型。在下一章中，我们将学习更多关于评估回归器性能的知识，以及我们如何根据应用需求仔细选择合适的指标。
