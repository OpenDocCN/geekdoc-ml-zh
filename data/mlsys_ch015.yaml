- en: Efficient AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高效人工智能
- en: '*DALL·E 3 Prompt: A conceptual illustration depicting efficiency in artificial
    intelligence using a shipyard analogy. The scene shows a bustling shipyard where
    containers represent bits or bytes of data. These containers are being moved around
    efficiently by cranes and vehicles, symbolizing the streamlined and rapid information
    processing in AI systems. The shipyard is meticulously organized, illustrating
    the concept of optimal performance within the constraints of limited resources.
    In the background, ships are docked, representing different platforms and scenarios
    where AI is applied. The atmosphere should convey advanced technology with an
    underlying theme of sustainability and wide applicability.*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*DALL·E 3 提示：使用造船厂类比的概念插图展示人工智能中的效率。场景展示了一个繁忙的造船厂，其中集装箱代表数据位或字节。这些集装箱被起重机和车辆高效地移动，象征着人工智能系统中信息处理的流畅和快速。造船厂组织得井井有条，说明了在有限资源约束下的最优性能概念。在背景中，船只停靠，代表不同的平台和人工智能应用的场景。氛围应传达先进技术，并带有可持续性和广泛适用性的主题。*'
- en: '![](../media/file130.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file130.png)'
- en: Purpose
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目的
- en: '*What key trade-offs shape the pursuit of efficiency in machine learning systems,
    and why must engineers balance competing objectives?*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*是什么关键权衡塑造了机器学习系统中对效率的追求，为什么工程师必须平衡竞争目标？*'
- en: Machine learning system efficiency requires balancing trade-offs across algorithmic
    complexity, computational resources, and data utilization. Improvements in one
    dimension often degrade performance in others, creating engineering tensions that
    require systematic approaches. Understanding these interdependent relationships
    enables engineers to design systems achieving maximum performance within practical
    constraints of time, energy, and cost.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统效率需要在算法复杂性、计算资源和数据利用之间进行权衡。在某一维度的改进往往会导致其他维度的性能下降，从而产生需要系统方法的工程紧张关系。理解这些相互依赖的关系使工程师能够在时间、能源和成本的实际约束内设计出性能最优的系统。
- en: '**Learning Objectives**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习目标**'
- en: Analyze scaling law relationships to determine optimal resource allocation strategies
    for computational budget, model size, and dataset requirements
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析扩展定律关系，以确定计算预算、模型大小和数据集要求的最佳资源分配策略
- en: Compare and contrast algorithmic, compute, and data efficiency trade-offs across
    cloud, edge, mobile, and TinyML deployment contexts
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较和对比在云、边缘、移动和TinyML部署环境中算法、计算和数据效率的权衡
- en: Evaluate machine learning systems using efficiency metrics including throughput,
    latency, energy consumption, and resource utilization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用吞吐量、延迟、能耗和资源利用率等效率指标评估机器学习系统
- en: Apply compression techniques such as pruning, quantization, and knowledge distillation
    to optimize model performance within resource constraints
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用剪枝、量化和知识蒸馏等技术，在资源约束内优化模型性能
- en: Design context-aware efficiency strategies by prioritizing optimization dimensions
    based on deployment requirements and operational constraints
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过根据部署要求和操作约束优先优化维度来设计上下文感知的效率策略
- en: Critique scaling-based approaches by identifying saturation points and proposing
    efficiency-driven alternatives
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过识别饱和点并提出效率驱动的替代方案来批判基于扩展的方法
- en: Assess the environmental and accessibility implications of efficiency choices
    in machine learning system design
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估机器学习系统设计中效率选择的环境和可访问性影响
- en: The Efficiency Imperative
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 效率必要性
- en: Machine learning efficiency has evolved from an afterthought to a fundamental
    discipline as models transitioned from simple statistical approaches to complex,
    resource-intensive architectures. The gap between theoretical capabilities and
    practical deployment has widened significantly, creating efficiency constraints
    that fundamentally affect system feasibility and scalability.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型从简单的统计方法过渡到复杂、资源密集型架构，机器学习效率已经从次要考虑转变为基本学科。理论能力与实际部署之间的差距显著扩大，产生了影响系统可行性和可扩展性的效率约束。
- en: Large-scale language models exemplify this challenge. GPT-3 required training
    costs estimated at $4.6 million (Lambda Labs estimate) and energy consumption
    of 1,287 MWh ([D. Patterson et al. 2021b](ch058.xhtml#ref-Patterson_et_al_2021)).
    The operational requirements, including memory footprints exceeding 700GB for
    inference (350GB for half-precision), create deployment barriers in resource-constrained
    environments. These constraints reveal a tension between model expressiveness
    and system practicality that requires rigorous analysis and optimization strategies.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模语言模型体现了这一挑战。GPT-3的训练成本估计为460万美元（Lambda Labs估计）和1287兆瓦时的能耗([D. Patterson等，2021b](ch058.xhtml#ref-Patterson_et_al_2021))。操作需求，包括推理时超过700GB的内存占用（半精度为350GB），在资源受限的环境中造成了部署障碍。这些限制揭示了模型表达性和系统实用性之间的紧张关系，这需要严格的分析和优化策略。
- en: Efficiency research extends beyond resource optimization to encompass the theoretical
    foundations of learning system design. Engineers must understand how algorithmic
    complexity, computational architectures, and data utilization strategies interact
    to determine system viability. These interdependencies create multi-objective
    optimization problems where improvements in one dimension may degrade performance
    in others.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 效率研究不仅超越了资源优化，还包括学习系统设计的理论基础。工程师必须了解算法复杂性、计算架构和数据利用策略如何相互作用，以确定系统的可行性。这些相互依赖性创造了多目标优化问题，其中某一维度的改进可能会在其他维度上降低性能。
- en: This chapter establishes the framework for analyzing efficiency in machine learning
    systems within Part III’s performance engineering curriculum. The efficiency principles
    here inform the optimization techniques in [Chapter 10](ch016.xhtml#sec-model-optimizations),
    where quantization and pruning methods realize algorithmic efficiency goals, the
    hardware acceleration strategies in [Chapter 11](ch017.xhtml#sec-ai-acceleration)
    that maximize compute efficiency, and the measurement methodologies in [Chapter 12](ch018.xhtml#sec-benchmarking-ai)
    for validating efficiency improvements.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节在第三部分性能工程课程中为分析机器学习系统中的效率建立了框架。这里的效率原则为[第10章](ch016.xhtml#sec-model-optimizations)中的优化技术提供了信息，其中量化剪枝方法实现了算法效率目标，[第11章](ch017.xhtml#sec-ai-acceleration)中的硬件加速策略最大化了计算效率，以及[第12章](ch018.xhtml#sec-benchmarking-ai)中的测量方法用于验证效率改进。
- en: Defining System Efficiency
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义系统效率
- en: 'Consider building a photo search application for a smartphone. You face three
    competing pressures: the model must be small enough to fit in memory (an algorithmic
    challenge), it must run fast enough on the phone’s processor without draining
    the battery (a compute challenge), and it must learn from a user’s personal photos
    without requiring millions of examples (a data challenge). Efficient AI is the
    discipline of navigating these interconnected trade-offs.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以为智能手机构建一个照片搜索应用为例。你面临三个相互竞争的压力：模型必须足够小，以便适应内存（一个算法挑战），它必须在手机处理器上运行得足够快，而不会耗尽电池（一个计算挑战），并且它必须从用户的个人照片中学习，而无需数百万个示例（一个数据挑战）。高效的AI是导航这些相互关联权衡的学科。
- en: Addressing these efficiency challenges requires coordinated optimization across
    three interconnected dimensions that determine system viability.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些效率挑战需要跨三个相互关联的维度进行协调优化，这些维度决定了系统的可行性。
- en: '***Machine Learning System Efficiency*** is the optimization of ML systems
    to minimize *computational*, *memory*, and *energy* demands while maintaining
    performance, achieved through improvements in *algorithms*, *hardware utilization*,
    and *data usage*.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习系统效率**是指通过改进*算法*、*硬件利用率*和*数据使用*，在保持性能的同时，最小化*计算*、*内存*和*能量*需求。'
- en: Understanding these interdependencies is necessary for designing systems that
    achieve maximum performance within practical constraints. Examining how the three
    dimensions interact in practice reveals how scaling laws expose these constraints.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这些相互依赖性对于设计在实用约束内实现最大性能的系统是必要的。研究这三个维度在实际中的相互作用，揭示了扩展定律如何暴露这些限制。
- en: Efficiency Interdependencies
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 效率相互依赖性
- en: The three efficiency dimensions are deeply intertwined, creating a complex optimization
    landscape. Algorithmic efficiency reduces computational requirements through better
    algorithms and architectures, but may increase development complexity or require
    specialized hardware. Compute efficiency maximizes hardware utilization through
    optimized implementations and specialized processors, but may limit model expressiveness
    or require specific algorithmic approaches. Data efficiency enables learning with
    fewer examples through improved training procedures and data utilization, but
    may require more sophisticated algorithms or additional computational resources.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 三个效率维度紧密相连，形成了一个复杂的优化景观。算法效率通过更好的算法和架构减少计算需求，但可能会增加开发复杂性或需要专用硬件。计算效率通过优化的实现和专用处理器最大化硬件利用率，但可能会限制模型的表达能力或需要特定的算法方法。数据效率通过改进的训练程序和数据利用率，使用更少的示例进行学习，但可能需要更复杂的算法或额外的计算资源。
- en: 'A concrete example illustrates these interconnections through the design of
    a photo search application for smartphones. The system must fit in 2GB memory
    (compute constraint), achieve acceptable accuracy with limited training data (data
    constraint), and complete searches within 50ms (algorithmic constraint). Optimization
    of any single dimension in isolation proves inadequate:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具体的例子通过为智能手机设计照片搜索应用程序来说明这些相互联系。系统必须在2GB内存（计算限制）内运行，使用有限的训练数据实现可接受的准确性（数据限制），并在50毫秒内完成搜索（算法限制）。单独优化任何单一维度都证明是不够的：
- en: '**Algorithmic Efficiency** focuses on the model architecture. Using a compact
    vision-language model with 50 million parameters instead of a billion-parameter
    model reduces memory requirements from 4GB to 200MB and cuts inference time from
    2 seconds to 100 milliseconds. However, accuracy decreases from 92% to 85%, necessitating
    careful evaluation of trade-off acceptability.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法效率**关注模型架构。使用具有5000万个参数的紧凑型视觉语言模型而不是具有10亿个参数的模型，可以将内存需求从4GB减少到200MB，并将推理时间从2秒缩短到100毫秒。然而，准确性从92%下降到85%，需要仔细评估权衡的接受度。'
- en: '**Compute Efficiency** addresses hardware utilization. The optimized model
    runs efficiently on smartphone processors, consuming only 10% battery per hour.
    Techniques like 8-bit quantization reduce computation while maintaining quality,
    and batch processing[1](#fn1) handles multiple queries simultaneously. However,
    these optimizations necessitate algorithmic modifications to support reduced precision
    operations.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算效率**关注硬件利用率。优化后的模型在智能手机处理器上运行高效，每小时仅消耗10%的电量。如8位量化等技术可以在保持质量的同时减少计算，批处理[1](#fn1)可以同时处理多个查询。然而，这些优化需要算法修改以支持降低精度的操作。'
- en: '**Data Efficiency** shapes how the model learns. Rather than requiring millions
    of labeled image-text pairs, the system leverages pre-trained foundation models
    and adapts using only thousands of user-specific examples. Continuous learning
    from user interactions provides implicit feedback without explicit labeling. This
    data efficiency necessitates more sophisticated algorithmic approaches and careful
    management of computational resources during adaptation.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据效率**塑造了模型的学习方式。系统不需要数百万个标记的图像-文本对，而是利用预训练的基础模型，并仅使用数千个用户特定的示例进行适应。从用户交互中持续学习提供了隐式反馈，而无需显式标记。这种数据效率需要更复杂的算法方法，并在适应过程中仔细管理计算资源。'
- en: 'Synergy between these dimensions produces emergent benefits: the smaller model
    (algorithmic efficiency) enables on-device processing (compute efficiency), which
    facilitates learning from private user data (data efficiency) without transmitting
    personal images to remote servers. This integration provides enhanced performance
    and privacy protection, demonstrating how efficiency enables capabilities unattainable
    with less efficient approaches.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些维度之间的协同作用产生了新兴的好处：更小的模型（算法效率）使得设备上处理（计算效率）成为可能，这有助于从私有用户数据中学习（数据效率），而无需将个人图像传输到远程服务器。这种集成提供了增强的性能和隐私保护，展示了效率如何使那些使用低效方法无法实现的能力成为可能。
- en: These interdependencies appear across all deployment contexts, from cloud systems
    with abundant resources to edge devices with severe constraints. As illustrated
    in [Figure 9.1](ch015.xhtml#fig-interdependece), understanding these relationships
    is essential before examining how scaling laws reveal fundamental efficiency limits.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些相互依赖性出现在所有部署环境中，从资源丰富的云系统到受严重限制的边缘设备。如图[图9.1](ch015.xhtml#fig-interdependece)所示，在考察扩展定律如何揭示基本效率限制之前，理解这些关系是至关重要的。
- en: '![](../media/file131.svg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file131.svg)'
- en: 'Figure 9.1: : **Efficiency Interdependencies**: The three efficiency dimensions
    (algorithmic, compute, and data) overlap and influence one another, creating systemic
    trade-offs in machine learning systems. Optimizing for one efficiency dimension
    often requires careful consideration of its impact on the others, shaping overall
    system performance and resource utilization.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1：**效率相互依赖性**：三个效率维度（算法、计算和数据）相互重叠并相互影响，在机器学习系统中创造了系统性的权衡。优化一个效率维度通常需要仔细考虑其对其他维度的影响，从而塑造整体系统性能和资源利用。
- en: With this understanding of efficiency dimension interactions, we can examine
    why brute-force scaling alone cannot address real-world efficiency requirements.
    Scaling laws provide the quantitative framework for understanding these limitations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对效率维度相互作用的这种理解，我们可以探讨为什么仅仅 brute-force scaling（暴力扩展）无法解决现实世界的效率需求。扩展定律为理解这些限制提供了定量框架。
- en: AI Scaling Laws
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能扩展定律
- en: 'Machine learning systems have followed a consistent pattern: increasing model
    scale through parameters, training data, and computational resources typically
    improves performance. This empirical observation has driven progress across natural
    language processing, computer vision, and speech recognition, where larger models
    trained on extensive datasets consistently achieve state-of-the-art results.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统遵循了一个一致的模式：通过参数、训练数据和计算资源增加模型规模通常可以提高性能。这一经验观察推动了自然语言处理、计算机视觉和语音识别等领域的进步，在这些领域，基于大量数据集训练的更大模型持续实现最先进的结果。
- en: 'These scaling laws can be seen as the quantitative expression of Richard Sutton’s
    “Bitter Lesson” from [Chapter 1](ch007.xhtml#sec-introduction): performance in
    machine learning is primarily driven by leveraging general methods at massive
    scale. The predictable power-law relationships show *how* computation, when scaled,
    yields better models.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些扩展定律可以看作是理查德·萨顿在[第一章](ch007.xhtml#sec-introduction)中提到的“苦涩教训”的定量表达：机器学习中的性能主要是由在巨大规模上利用通用方法所驱动的。可预测的幂律关系显示了计算在扩展时如何产生更好的模型。
- en: This scaling trajectory raises critical questions about efficiency and sustainability.
    As computational demands grow exponentially and data requirements increase, questions
    emerge regarding when scaling costs outweigh performance benefits. Researchers
    have developed scaling laws[2](#fn2) that quantify how model performance relates
    to training resources, revealing why efficiency becomes increasingly important
    as systems expand in complexity.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这种扩展轨迹引发了关于效率和可持续性的关键问题。随着计算需求呈指数增长和数据需求增加，何时扩展成本超过性能收益的问题浮现出来。研究人员已经开发了扩展定律[2](#fn2)，这些定律量化了模型性能与训练资源之间的关系，揭示了为什么随着系统复杂性的增加，效率变得越来越重要。
- en: This section introduces scaling laws, examines their manifestation across different
    dimensions, and analyzes their implications for system design, establishing why
    the multi-dimensional efficiency optimization framework is a fundamental requirement.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了扩展定律，探讨了它们在不同维度上的表现，并分析了它们对系统设计的影响，确立了为什么多维度效率优化框架是一个基本要求。
- en: Empirical Evidence for Scaling Laws
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩展定律的经验证据
- en: The rapid evolution in AI capabilities over the past decade exemplifies this
    scaling trajectory. GPT-1 (2018) contained 117 million parameters and demonstrated
    basic sentence completion capabilities. GPT-2 (2019) scaled to 1.5 billion parameters
    and achieved coherent paragraph generation. GPT-3 (2020) expanded to 175 billion
    parameters and demonstrated sophisticated text generation across diverse domains.
    Each increase in model size brought dramatically improved capabilities, but at
    exponentially increasing costs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年人工智能能力的快速进化是这种扩展轨迹的例证。GPT-1（2018）包含1.17亿个参数，展示了基本的句子完成能力。GPT-2（2019）扩展到15亿个参数，实现了连贯的段落生成。GPT-3（2020）扩展到1750亿个参数，并在多个领域展示了复杂的文本生成能力。模型规模的每次增加都带来了显著的能力提升，但成本呈指数级增长。
- en: This pattern extends beyond language models. In computer vision, doubling neural
    network size typically yields consistent accuracy gains when training data increases
    proportionally. AlexNet (2012) had 60 million parameters, VGG-16 (2014) scaled
    to 138 million, and large modern vision transformers can exceed 600 million parameters.
    Each generation achieved better image recognition accuracy, but required proportionally
    more computational resources and training data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式不仅限于语言模型。在计算机视觉中，当训练数据成比例增加时，加倍神经网络大小通常会产生一致的准确度提升。AlexNet（2012）有 6000 万个参数，VGG-16（2014）扩展到
    1.38 亿个，现代大型视觉 Transformer 可以超过 6 亿个参数。每一代都实现了更好的图像识别准确度，但需要成比例更多的计算资源和训练数据。
- en: 'The scaling hypothesis underlies this progress: larger models possess increased
    capacity to capture intricate data patterns, facilitating improved accuracy and
    generalization. However, this scaling trajectory introduces critical resource
    constraints. Training GPT-3 required approximately 314 sextillion[3](#fn3) floating-point
    operations (314 followed by 21 zeros), equivalent to running a modern gaming PC
    continuously for over 350 years, at substantial financial and environmental costs.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 放大假设是这一进步的基础：更大的模型具有更强的能力来捕捉复杂的数据模式，从而促进准确性和泛化能力的提高。然而，这种放大轨迹引入了关键资源限制。训练 GPT-3
    需要大约 314 万亿[3](#fn3) 次浮点运算（314 后面跟着 21 个零），相当于连续运行一台现代游戏 PC 超过 350 年，这带来了巨大的财务和环境成本。
- en: These resource demands reveal why understanding scaling laws is necessary for
    efficiency. [Figure 9.2](ch015.xhtml#fig-compute-trends) shows computational demands
    of training state-of-the-art models escalating at an unsustainable rate, growing
    faster than Moore’s Law improvements in hardware.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源需求揭示了为什么理解放大定律对于效率是必要的。[图 9.2](ch015.xhtml#fig-compute-trends) 显示了训练最先进模型的计算需求以不可持续的速度增长，增长速度超过了摩尔定律在硬件方面的改进。
- en: '![](../media/file132.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file132.png)'
- en: 'Figure 9.2: **Model Training Compute Trends**: Model training compute is growing
    at faster and faster rates, especially in the recent deep learning era. Source:
    ([Sevilla et al. 2022b](ch058.xhtml#ref-Sevilla_Heim_Ho_Besiroglu_Hobbhahn_Villalobos_2022).)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2：**模型训练计算趋势**：模型训练计算以越来越快的速度增长，尤其是在最近的深度学习时代。来源：([Sevilla 等人 2022b](ch058.xhtml#ref-Sevilla_Heim_Ho_Besiroglu_Hobbhahn_Villalobos_2022)。)
- en: Scaling laws provide a quantitative framework for understanding these trade-offs.
    They reveal that model performance exhibits predictable patterns as resources
    increase, following power-law relationships where performance improves consistently
    but with diminishing returns[4](#fn4). These laws show that optimal resource allocation
    requires coordinating model size, dataset size, and computational budget rather
    than scaling any single dimension in isolation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 放大定律为理解这些权衡提供了一个定量框架。它们揭示了随着资源的增加，模型性能表现出可预测的模式，遵循幂律关系，其中性能持续改进但回报递减[4](#fn4)。这些定律表明，最优资源分配需要协调模型大小、数据集大小和计算预算，而不是孤立地放大任何单一维度。
- en: '**Refresher: Transformer Computational Characteristics**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**复习：Transformer 计算特性**'
- en: Recall from [Chapter 4](ch010.xhtml#sec-dnn-architectures) that transformers
    process sequences using self-attention mechanisms that compute relationships between
    all token pairs. This architecture’s computational cost scales quadratically with
    sequence length, making resource allocation particularly critical for language
    models. The term “FLOPs” (floating-point operations) quantifies total computational
    work, while “tokens” represent the individual text units (typically subwords)
    that models process during training.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下 [第 4 章](ch010.xhtml#sec-dnn-architectures) 中提到的，Transformer 使用自注意力机制处理序列，该机制计算所有标记对之间的关系。这种架构的计算成本与序列长度成二次方关系，这使得资源分配对于语言模型尤其关键。术语“FLOPs”（浮点运算）量化了总计算工作量，而“标记”代表模型在训练过程中处理的单个文本单元（通常是子词）。
- en: Compute-Optimal Resource Allocation
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算最优资源分配
- en: 'Empirical studies of large language models (LLMs) reveal a key insight: for
    any fixed computational budget, there exists an optimal balance between model
    size and dataset size (measured in tokens[5](#fn5)) that minimizes training loss.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的经验研究表明一个关键见解：对于任何固定的计算预算，存在一个最优的模型大小和数据集大小（以标记[5](#fn5)衡量）之间的平衡，以最小化训练损失。
- en: '[Figure 9.3](ch015.xhtml#fig-compute-optimal) illustrates this principle through
    three related views. The left panel shows ‘IsoFLOP curves,’ where each curve corresponds
    to a constant number of floating-point operations (FLOPs[6](#fn6)) during transformer[7](#fn7)
    training. The valleys in these curves identify the most efficient model size for
    each computational budget when training autoregressive[8](#fn8) language models.
    The center and right panels reveal how the optimal number of parameters and tokens
    scales predictably as computational budgets increase, demonstrating the necessity
    for coordinated scaling to maximize resource utilization.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.3](ch015.xhtml#fig-compute-optimal) 通过三个相关视图展示了这一原理。左侧面板显示了‘IsoFLOP曲线’，其中每条曲线对应于在transformer[7](#fn7)训练过程中恒定的浮点运算次数（FLOPs[6](#fn6)）。这些曲线的谷底确定了在训练自回归[8](#fn8)语言模型时，每个计算预算下最有效的模型大小。中间和右侧面板揭示了随着计算预算的增加，最佳参数数量和标记数量如何可预测地扩展，证明了协调扩展以最大化资源利用的必要性。'
- en: '![](../media/file133.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file133.png)'
- en: 'Figure 9.3: **Optimal Compute Allocation**: For fixed computational budgets,
    language model performance depends on balancing model size and training data volume;
    the left panel maps training loss across parameter counts, identifying an efficiency
    sweet spot for each FLOP level. The center and right panels quantify how optimal
    parameter counts and token requirements scale predictably with increasing compute,
    demonstrating the need for coordinated scaling of both model and data to maximize
    resource utilization in large language models. Source: ([Hoffmann et al. 2022](ch058.xhtml#ref-hoffmann2022training)).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3：**最佳计算分配**：对于固定的计算预算，语言模型性能取决于平衡模型大小和训练数据量；左侧面板将训练损失映射到参数数量，确定了每个FLOP级别的效率最佳点。中间和右侧面板量化了随着计算的增加，最佳参数数量和标记需求如何可预测地扩展，证明了在大规模语言模型中需要协调扩展模型和数据以最大化资源利用的需求。来源：([Hoffmann等人2022](ch058.xhtml#ref-hoffmann2022training))。
- en: 'Kaplan et al. ([2020](ch058.xhtml#ref-kaplan2020scaling)) demonstrated that
    transformer-based language models scale predictably with three factors: the number
    of model parameters, the volume of the training dataset (measured in tokens),
    and the total computational budget (measured in floating-point operations). When
    these factors are augmented proportionally, models exhibit consistent performance
    improvements without requiring architectural modifications or task-specific tuning.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Kaplan等人([2020](ch058.xhtml#ref-kaplan2020scaling))证明了基于transformer的语言模型可以与三个因素可预测地扩展：模型参数数量、训练数据集的体积（以标记衡量）和总计算预算（以浮点运算衡量）。当这些因素成比例增加时，模型会表现出一致的性能改进，而无需进行架构修改或特定任务的调整。
- en: The practical manifestation of these patterns appears clearly in [Figure 9.4](ch015.xhtml#fig-kaplan-scaling),
    which presents test loss curves for models spanning from <semantics><msup><mn>10</mn><mn>3</mn></msup><annotation
    encoding="application/x-tex">10^3</annotation></semantics> to <semantics><msup><mn>10</mn><mn>9</mn></msup><annotation
    encoding="application/x-tex">10^9</annotation></semantics> parameters. The figure
    reveals two key insights. First, larger models demonstrate superior sample efficiency,
    achieving target performance levels with fewer training tokens. Second, as computational
    resources increase, the optimal model size correspondingly grows, with loss decreasing
    predictably when compute is allocated efficiently.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模式的实际表现清晰地体现在[图9.4](ch015.xhtml#fig-kaplan-scaling)中，该图展示了从<semantics><msup><mn>10</mn><mn>3</mn></msup><annotation
    encoding="application/x-tex">10^3</annotation></semantics>到<semantics><msup><mn>10</mn><mn>9</mn></msup><annotation
    encoding="application/x-tex">10^9</annotation></semantics>参数范围的模型测试损失曲线。该图揭示了两个关键见解。首先，较大的模型表现出更高的样本效率，在更少的训练标记下达到目标性能水平。其次，随着计算资源的增加，最佳模型大小相应增长，当计算资源分配得当时，损失会可预测地减少。
- en: '![](../media/file134.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file134.png)'
- en: 'Figure 9.4: **Scaling Laws & Compute Optimality**: Larger models consistently
    achieve better performance with increased training data and compute, but diminishing
    returns necessitate careful resource allocation during training. Optimal model
    size and training duration depend on the available compute budget, as evidenced
    by the convergence of loss curves at different parameter scales and training token
    counts. Source: ([Kaplan et al. 2020](ch058.xhtml#ref-kaplan2020scaling)).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4：**缩放定律与计算最优性**：更大的模型在增加训练数据和计算资源的情况下始终能实现更好的性能，但递减的回报需要训练过程中仔细的资源分配。最优模型大小和训练持续时间取决于可用的计算预算，正如不同参数规模和训练标记数量下损失曲线收敛所证明的那样。来源：([Kaplan
    et al. 2020](ch058.xhtml#ref-kaplan2020scaling)).
- en: 'This theoretical scaling relationship defines optimal compute allocation: for
    a fixed budget, the relationship <semantics><mrow><mi>D</mi><mo>∝</mo><msup><mi>N</mi><mn>0.74</mn></msup></mrow><annotation
    encoding="application/x-tex">D \propto N^{0.74}</annotation></semantics> ([Hoffmann
    et al. 2022](ch058.xhtml#ref-hoffmann2022training)) shows that dataset size <semantics><mi>D</mi><annotation
    encoding="application/x-tex">D</annotation></semantics> and model size <semantics><mi>N</mi><annotation
    encoding="application/x-tex">N</annotation></semantics> must grow in coordinated
    proportions. This means that as model size increases, the dataset should grow
    at roughly three-quarters the rate to maintain compute-optimal efficiency.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种理论缩放关系定义了最优的计算分配：对于固定的预算，关系 <semantics><mrow><mi>D</mi><mo>∝</mo><msup><mi>N</mi><mn>0.74</mn></msup></mrow><annotation
    encoding="application/x-tex">D \propto N^{0.74}</annotation></semantics> ([Hoffmann
    et al. 2022](ch058.xhtml#ref-hoffmann2022training)) 表明数据集大小 <semantics><mi>D</mi><annotation
    encoding="application/x-tex">D</annotation></semantics> 和模型大小 <semantics><mi>N</mi><annotation
    encoding="application/x-tex">N</annotation></semantics> 必须以协调的比例增长。这意味着随着模型大小的增加，数据集应该以大约三分之四的速率增长，以保持计算最优效率。
- en: These theoretical predictions assume perfect compute utilization, which becomes
    challenging in distributed training scenarios. Real-world implementations face
    communication overhead that scales unfavorably with system size, creating bandwidth
    bottlenecks that reduce effective utilization. Beyond 100 nodes, communication
    overhead can reduce expected performance gains by 20-40% depending on workload
    and interconnect, transforming predicted improvements into more modest real-world
    results.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这些理论预测假设了完美的计算利用率，这在分布式训练场景中变得具有挑战性。现实世界的实现面临着与系统规模不利的通信开销，这造成了带宽瓶颈，降低了有效利用率。超过100个节点后，通信开销可能会降低预期性能提升20-40%，具体取决于工作负载和互连方式，将预测的改进转化为更实际的现实结果。
- en: Mathematical Foundations and Operational Regimes
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学基础和操作规则
- en: The predictable patterns observed in scaling behavior can be expressed mathematically
    using power-law relationships, though understanding the intuition behind these
    patterns proves more important than precise mathematical formulation for most
    practitioners.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到的缩放行为中的可预测模式可以用幂律关系来数学表达，尽管理解这些模式背后的直觉对于大多数从业者来说比精确的数学公式更重要。
- en: '**Formal Mathematical Formulation**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**形式化的数学公式**'
- en: 'For readers interested in the formal mathematical framework, scaling laws can
    be expressed as power-law relationships. The general formulation is:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于对形式化数学框架感兴趣的读者，缩放定律可以表示为幂律关系。一般公式为：
- en: <semantics><mrow><mi>ℒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo
    stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>A</mi><msup><mi>N</mi><mrow><mi>−</mi><mi>α</mi></mrow></msup><mo>+</mo><mi>B</mi></mrow>
    <annotation encoding="application/x-tex">\mathcal{L}(N) = A N^{-\alpha} + B</annotation></semantics>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <semantics><mrow><mi>ℒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo
    stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>A</mi><msup><mi>N</mi><mrow><mi>−</mi><mi>α</mi></mrow></msup><mo>+</mo><mi>B</mi></mrow>
    <annotation encoding="application/x-tex">\mathcal{L}(N) = A N^{-\alpha} + B</annotation></semantics>
- en: where loss <semantics><mi>ℒ</mi><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics>
    decreases as resource quantity <semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics>
    increases, following a power-law decay with rate <semantics><mi>α</mi><annotation
    encoding="application/x-tex">\alpha</annotation></semantics>, plus a baseline
    constant <semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics>.
    Here, <semantics><mrow><mi>ℒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo
    stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}(N)</annotation></semantics>
    represents the loss achieved with resource quantity <semantics><mi>N</mi><annotation
    encoding="application/x-tex">N</annotation></semantics>, <semantics><mi>A</mi><annotation
    encoding="application/x-tex">A</annotation></semantics> and <semantics><mi>B</mi><annotation
    encoding="application/x-tex">B</annotation></semantics> are task-dependent constants,
    and <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    is the scaling exponent that characterizes the rate of performance improvement.
    A larger value of <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    signifies more efficient performance improvements with respect to scaling.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，损失 <semantics><mi>ℒ</mi><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics>
    随着资源数量 <semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics>
    的增加而减少，遵循一个以速率 <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    为特征的幂律衰减，加上一个基线常数 <semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics>。在这里，<semantics><mrow><mi>ℒ</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation
    encoding="application/x-tex">\mathcal{L}(N)</annotation></semantics> 表示使用资源数量
    <semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics>
    所达到的损失，<semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics>
    和 <semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics>
    是与任务相关的常数，而 <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    是表征性能改进速率的缩放指数。较大的 <semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics>
    值表示在缩放方面的性能改进更有效。
- en: These theoretical predictions find strong empirical support across multiple
    model configurations. [Figure 9.5](ch015.xhtml#fig-loss-vs-n-d) shows that early-stopped
    test loss varies predictably with both dataset size and model size, and learning
    curves across configurations can be aligned through appropriate parameterization.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些理论预测在多个模型配置中得到了强有力的实证支持。[图9.5](ch015.xhtml#fig-loss-vs-n-d) 显示，提前停止的测试损失随着数据集大小和模型大小的变化而可预测地变化，并且可以通过适当的参数化将不同配置下的学习曲线对齐。
- en: Resource-Constrained Scaling Regimes
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 资源受限缩放区域
- en: Applying scaling laws in practice requires recognizing three distinct resource
    allocation regimes that emerge from trade-offs between compute budget, data availability,
    and optimal resource allocation. These regimes provide practical guidance for
    system designers navigating resource constraints.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中应用缩放定律需要识别出三种不同的资源分配区域，这些区域源于计算预算、数据可用性和最佳资源分配之间的权衡。这些区域为在资源约束下导航的系统设计者提供了实际指导。
- en: Compute-limited regimes characterize scenarios where available computational
    resources restrict scaling potential despite abundant training data. Organizations
    with limited hardware budgets or strict training time constraints operate within
    this regime. The optimal strategy involves training smaller models for longer
    periods, maximizing utilization of available compute through extended training
    schedules rather than larger architectures. This approach proves particularly
    relevant for academic institutions, startups, or projects with constrained infrastructure
    access.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 计算受限区域描述了尽管有丰富的训练数据，但可用的计算资源限制了缩放潜力的场景。拥有有限硬件预算或严格的训练时间约束的组织处于这个区域。最佳策略是训练较小的模型更长时间，通过延长训练计划而不是更大的架构来最大化利用可用的计算资源。这种方法对于学术机构、初创公司或基础设施访问受限的项目尤其相关。
- en: Data-limited regimes emerge when computational resources exceed what can be
    effectively utilized given dataset constraints. High-resource organizations working
    with specialized domains, proprietary datasets, or privacy-constrained data often
    encounter this regime. The optimal strategy involves training larger models for
    fewer optimization steps, leveraging model capacity to extract maximum information
    from limited training examples. This regime commonly appears in specialized applications
    like medical imaging or proprietary commercial datasets.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算资源超过数据集限制下能够有效利用的资源时，会出现数据受限机制。与专门领域、专有数据集或隐私受限数据工作的资源丰富组织经常遇到这种情况。最佳策略是在较少的优化步骤中训练更大的模型，利用模型容量从有限的训练示例中提取最大信息。这种机制通常出现在医学成像或专有商业数据集等专用应用中。
- en: Optimal regimes (Chinchilla Frontier) represent the balanced allocation of compute
    and data resources following compute-optimal scaling laws. This regime achieves
    maximum performance efficiency by scaling model size and training data proportionally,
    as demonstrated by DeepMind’s Chinchilla model, which outperformed much larger
    models through optimal resource allocation ([Hoffmann et al. 2022](ch058.xhtml#ref-hoffmann2022training)).
    Operating within this regime requires sophisticated resource planning but delivers
    superior performance per unit of computational investment.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳机制（Chinchilla前沿）代表了在计算最优扩展定律下计算资源和数据资源的平衡分配。这种机制通过按比例扩展模型大小和训练数据，实现了最大性能效率，正如DeepMind的Chinchilla模型所展示的，它通过最优资源分配超过了更大的模型([Hoffmann等人2022](ch058.xhtml#ref-hoffmann2022training))。在这个机制内运行需要复杂的资源规划，但每单位计算投资都能带来卓越的性能。
- en: Recognizing these regimes enables practitioners to make informed decisions about
    resource allocation strategies, avoiding common inefficiencies such as over-parameterized
    models with insufficient training data or under-parameterized models that fail
    to utilize available computational resources effectively.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到这些机制使得从业者能够就资源分配策略做出明智的决策，避免常见的低效情况，例如过度参数化的模型训练数据不足或参数不足的模型未能有效利用可用的计算资源。
- en: '![](../media/file135.svg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file135.svg)'
- en: 'Figure 9.5: : **Loss vs Model and Dataset Size**: Early-stopped test loss varies
    predictably with both dataset size and model size, highlighting the importance
    of balanced scaling for optimal performance under fixed compute budgets.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.5: **损失与模型和数据集大小**: 早期停止的测试损失随着数据集大小和模型大小的变化而可预测地变化，突出了在固定计算预算下平衡扩展对于最佳性能的重要性。'
- en: 'Scaling laws show that performance improvements follow predictable patterns
    that change depending on resource availability and exhibit distinct behaviors
    across different dimensions. Two important types of scaling regimes emerge: **data-driven
    regimes** that describe how performance changes with dataset size, and **temporal
    regimes** that describe when in the ML lifecycle we apply additional compute.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展定律表明，性能改进遵循可预测的模式，这些模式根据资源可用性而变化，并在不同维度上表现出不同的行为。出现了两种重要的扩展机制：**数据驱动机制**，描述了性能如何随着数据集大小而变化，以及**时间机制**，描述了在机器学习生命周期中何时应用额外的计算。
- en: Data-Limited Scaling Regimes
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据受限扩展机制
- en: The relationship between generalization error and dataset size exhibits three
    distinct regimes, as shown in [Figure 9.6](ch015.xhtml#fig-data-scaling-regimes).
    When limited examples are available, high generalization error results from inadequate
    statistical estimates. As data availability increases, generalization error decreases
    predictably as a function of dataset size, following a power-law relationship
    that provides the most practical benefit from data scaling. Eventually, performance
    reaches saturation, approaching a floor determined by inherent data limitations
    or model capacity, beyond which additional data yields negligible improvements.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 泛化误差与数据集大小之间的关系表现出三种不同的机制，如图[图9.6](ch015.xhtml#fig-data-scaling-regimes)所示。当可用的示例有限时，高泛化误差是由于统计估计不足造成的。随着数据可用性的增加，泛化误差随着数据集大小的增加而可预测地降低，遵循幂律关系，为数据扩展提供了最实用的好处。最终，性能达到饱和，接近由内在数据限制或模型容量决定的底部，在此之后，额外的数据带来的改进微乎其微。
- en: '![](../media/file136.svg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file136.svg)'
- en: 'Figure 9.6: : **Data Scaling Regimes**: The relationship between dataset size
    and generalization error follows distinct scaling regimes. Increasing dataset
    size initially reduces generalization error following a power-law relationship,
    but eventually plateaus at an irreducible error floor determined by inherent data
    limitations or model capacity ([Hestness et al. 2017](ch058.xhtml#ref-hestness2017deep)).
    This behavior exposes diminishing returns from data scaling and informs practical
    decisions about data collection efforts in machine learning systems.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.6: **数据缩放机制**：数据集大小与泛化误差之间的关系遵循不同的缩放机制。随着数据集大小的增加，最初根据幂律关系减少泛化误差，但最终会达到一个由内在数据限制或模型容量决定的不可减少的错误地板([Hestness等人2017](ch058.xhtml#ref-hestness2017deep))。这种行为揭示了数据缩放带来的收益递减，并指导了机器学习系统中数据收集工作的实际决策。'
- en: This three-regime pattern manifests across different resource dimensions beyond
    data alone. Operating within the power-law region provides the most reliable return
    on resource investment. Reaching this regime requires minimum resource thresholds,
    while maintaining operation within it demands careful allocation to avoid premature
    saturation.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种三阶段模式不仅体现在数据之外的不同资源维度上。在幂律区域内操作提供了资源投资的最可靠回报。达到这一阶段需要最低的资源阈值，而在此区域内保持操作则需要仔细的资源分配，以避免过早饱和。
- en: Temporal Scaling Regimes
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 时间缩放机制
- en: While data-driven regimes characterize how performance varies with dataset size,
    a complementary perspective examines temporal allocation of compute resources
    within the ML lifecycle. Recent research has identified three distinct **temporal
    scaling regimes** characterizing different stages of model development and deployment.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据驱动机制描述了性能如何随数据集大小变化，但一个互补的视角是检查机器学习生命周期内计算资源的时序分配。最近的研究已经确定了三个不同的**时间缩放机制**，这些机制描述了模型开发和部署的不同阶段。
- en: '**Pre-training scaling** encompasses the traditional domain of scaling laws,
    characterizing how model performance improves with larger architectures, expanded
    datasets, and increased compute during initial training. Extensive study in foundation
    models has established clear power-law relationships between resources and capabilities.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**预训练缩放**涵盖了传统的缩放定律领域，描述了模型性能如何随着更大架构、扩展的数据集和初始训练期间增加的计算资源而提高。在基础模型中进行的广泛研究已经确立了资源和能力之间的明确幂律关系。'
- en: '**Post-training scaling** characterizes improvements achieved after initial
    training through techniques including fine-tuning, prompt engineering, and task-specific
    adaptation. This regime has gained prominence with foundation models, where adaptation
    rather than retraining frequently provides the most efficient path to enhanced
    performance under moderate resource requirements.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练后缩放**描述了通过微调、提示工程和特定任务适应性等技术，在初始训练后实现的改进。这一机制在基础模型中获得了显著的关注，其中适应性而不是重新训练通常在资源需求适中的情况下提供了提高性能的最有效途径。'
- en: '**Test-time scaling** characterizes how performance improvements result from
    additional compute allocation during inference without modifying model parameters.
    This encompasses methods including ensemble prediction, chain-of-thought prompting,
    and iterative refinement, enabling models to allocate additional processing time
    per input.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试时缩放**描述了性能改进如何通过在推理期间额外分配计算资源而实现，而不修改模型参数。这包括集成预测、思维链提示和迭代细化等方法，使模型能够为每个输入分配额外的处理时间。'
- en: '[Figure 9.7](ch015.xhtml#fig-scaling-regimes) shows these temporal regimes
    exhibit distinct characteristics in computational resource allocation for performance
    improvement. Pre-training demands massive resources while providing broad capabilities,
    post-training offers targeted enhancements under moderate requirements, and test-time
    scaling enables flexible performance-compute trade-offs adjustable per inference.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.7](ch015.xhtml#fig-scaling-regimes)显示了这些时间机制在性能改进的计算资源分配上表现出不同的特征。预训练需要大量资源，同时提供广泛的能力，训练后提供在适度要求下的针对性增强，测试时缩放则允许灵活的性能-计算权衡，可根据推理进行调整。'
- en: '![](../media/file137.svg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file137.svg)'
- en: 'Figure 9.7: : **Temporal Scaling Regimes**: Different temporal scaling regimes
    offer distinct approaches to improving model performance with varying compute
    investments. Pre-training establishes broad capabilities through large-scale training
    from scratch, post-training refines existing models through additional training
    phases, and test-time scaling dynamically allocates compute during inference to
    enhance per-sample results. Understanding these regimes clarifies the trade-offs
    between upfront investment and flexible, on-demand resource allocation for optimal
    system performance.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.7: **时间缩放机制**: 不同的时间缩放机制提供了不同的方法，通过不同的计算投资来提高模型性能。预训练通过从头开始的大规模训练建立广泛的技能，后训练通过额外的训练阶段细化现有模型，测试时缩放在推理过程中动态分配计算资源以增强每个样本的结果。理解这些机制有助于明确前期投资与灵活的按需资源分配之间的权衡，以实现最佳系统性能。'
- en: Data-driven and temporal scaling regimes are crucial for system design, revealing
    multiple paths to performance improvement beyond scaling training resources alone.
    For resource-constrained deployments, post-training and test-time scaling may
    provide more practical approaches than complete model retraining, while data-efficient
    techniques enable effective system operation within the power-law regime using
    smaller datasets.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据驱动和时间缩放机制对于系统设计至关重要，揭示了除了仅扩展训练资源之外，还有多种提高性能的途径。对于资源受限的部署，后训练和测试时缩放可能比完全重新训练模型提供更实用的方法，而数据高效的技术能够在幂律区域内使用较小的数据集有效运行系统。
- en: Practical Applications in System Design
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统设计中的实际应用
- en: Scaling laws provide powerful insights for practical system design and resource
    planning. Consistent observation of power-law trends indicates that within well-defined
    operational regimes, model performance depends predominantly on scale rather than
    idiosyncratic architectural innovations. However, diminishing returns phenomena
    indicate that each additional improvement requires exponentially increased resources
    while delivering progressively smaller benefits.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放定律为实际系统设计和资源规划提供了深刻的见解。一致观察到幂律趋势表明，在定义良好的操作区域内，模型性能主要取决于规模，而不是独特的架构创新。然而，递减回报现象表明，每次额外的改进都需要指数级增加资源，同时带来越来越小的收益。
- en: OpenAI’s development of GPT-3 demonstrates this principle. Rather than conducting
    expensive architecture searches, the authors applied scaling laws derived from
    earlier experiments to determine optimal training dataset size and model parameter
    count ([T. Brown et al. 2020](ch058.xhtml#ref-brown2020language)). They scaled
    an established transformer architecture along the compute-optimal frontier to
    175 billion parameters and approximately 300 billion tokens, enabling advance
    prediction of model performance and resource requirements. This methodology demonstrated
    the practical application of scaling laws in large-scale system planning.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI对GPT-3的开发展示了这一原则。作者们没有进行昂贵的架构搜索，而是应用了从早期实验中推导出的缩放定律来确定最佳训练数据集大小和模型参数数量
    ([T. Brown等人 2020](ch058.xhtml#ref-brown2020language))。他们沿着计算最优前沿扩展了一个已建立的Transformer架构，达到1750亿个参数和大约3000亿个标记，从而能够提前预测模型性能和资源需求。这种方法展示了缩放定律在大规模系统规划中的实际应用。
- en: Scaling laws serve multiple practical functions in system design. They enable
    practitioners to estimate returns on investment for different resource allocations
    during resource budgeting. Under fixed computational budgets, designers can utilize
    empirical scaling curves to determine optimal performance improvement strategies
    across model size, dataset expansion, or training duration.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放定律在系统设计中具有多种实用功能。它们使从业者能够在资源预算期间估计不同资源分配的投资回报。在固定的计算预算下，设计者可以利用经验缩放曲线来确定跨模型大小、数据集扩展或训练持续时间的最佳性能改进策略。
- en: System designers can utilize scaling trends to identify when architectural changes
    yield significant improvements relative to gains achieved through scaling alone,
    thereby avoiding exhaustive architecture search. When a model family exhibits
    favorable scaling behavior, scaling the existing architecture may prove more effective
    than transitioning to more complex but unvalidated designs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 系统设计者可以利用缩放趋势来确定何时架构变化相对于仅通过缩放获得的收益产生显著改进，从而避免详尽的架构搜索。当一个模型系列表现出有利的缩放行为时，扩展现有架构可能比过渡到更复杂但未经验证的设计更有效。
- en: In edge and embedded environments with constrained resource budgets, understanding
    performance degradation under model scaling enables designers to select smaller
    configurations delivering acceptable accuracy within deployment constraints. By
    quantifying scale-performance trade-offs, scaling laws identify when brute-force
    scaling becomes inefficient and indicate the necessity for alternative approaches
    including model compression, efficient knowledge transfer, sparsity techniques,
    and hardware-aware design.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在资源预算受限的边缘和嵌入式环境中，理解模型缩放下的性能下降情况，使设计者能够选择在部署约束内提供可接受精度的较小配置。通过量化缩放-性能权衡，缩放定律确定何时暴力缩放变得低效，并指出采用包括模型压缩、高效知识迁移、稀疏技术和硬件感知设计等替代方法的必要性。
- en: Scaling laws also function as diagnostic instruments. Performance plateaus despite
    increased resources may indicate dimensional saturation—such as inadequate data
    relative to model size—or inefficient computational resource utilization. This
    diagnostic capability renders scaling laws both predictive and prescriptive, facilitating
    systematic bottleneck identification and resolution.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放定律还充当诊断工具。尽管增加了资源，但性能却出现平台期，这可能表明维度饱和——例如相对于模型大小的数据不足——或计算资源利用效率低下。这种诊断能力使缩放定律既具有预测性又具有指导性，有助于系统地识别和解决瓶颈。
- en: Sustainability and Cost Implications
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可持续性和成本影响
- en: Scaling laws illuminate pathways to performance enhancement while revealing
    rapidly escalating resource demands. As models expand, training and deployment
    resource requirements grow disproportionately, creating tension between performance
    gains through scaling and system efficiency.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放定律揭示了性能提升的途径，同时揭示了资源需求的快速增加。随着模型规模的扩大，训练和部署的资源需求不成比例增长，在通过缩放获得性能提升和系统效率之间产生了紧张关系。
- en: Training large-scale models necessitates substantial processing power, typically
    requiring distributed infrastructures[9](#fn9) comprising hundreds or thousands
    of accelerators. State-of-the-art language model training may require tens of
    thousands of GPU-days, consuming millions of kilowatt-hours of electricity. These
    distributed training systems introduce additional complexity around communication
    overhead, synchronization, and scaling efficiency, as detailed in [Chapter 8](ch014.xhtml#sec-ai-training).
    Energy demands have outpaced Moore’s Law improvements, raising critical questions
    about long-term sustainability.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 训练大规模模型需要大量的处理能力，通常需要由数百或数千个加速器组成的分布式基础设施[9](#fn9)。最先进的语言模型训练可能需要数万个GPU天，消耗数百万千瓦时的电力。这些分布式训练系统在通信开销、同步和缩放效率方面引入了额外的复杂性，如第8章[详细所述](ch014.xhtml#sec-ai-training)。能源需求超过了摩尔定律的进步，引发了关于长期可持续性的关键问题。
- en: Large models require extensive, high-quality, diverse datasets to achieve their
    full potential. Data collection, cleansing, and labeling processes consume considerable
    time and resources. As models approach saturation of available high-quality data,
    particularly in natural language processing, additional performance gains through
    data scaling become increasingly difficult to achieve. This reality underscores
    data efficiency as a necessary complement to brute-force scaling approaches.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 大型模型需要广泛、高质量、多样化的数据集才能发挥其全部潜力。数据收集、清洗和标注过程消耗大量时间和资源。当模型接近可用高质量数据的饱和度，尤其是在自然语言处理领域，通过数据缩放获得额外性能提升变得越来越困难。这一现实强调了数据效率作为暴力缩放方法必要补充的重要性。
- en: The financial and environmental implications compound these challenges. Training
    runs for large foundation models can incur millions of dollars in computational
    expenses, and associated carbon footprints[10](#fn10) have garnered increasing
    scrutiny. These costs limit accessibility to cutting-edge research and exacerbate
    disparities in access to advanced AI systems. The democratization challenges introduced
    by efficiency barriers connect directly to accessibility goals addressed in [Chapter 19](ch025.xhtml#sec-ai-good).
    Comprehensive approaches to environmental sustainability in ML systems, including
    carbon footprint measurement and green computing practices, are explored in [Chapter 18](ch024.xhtml#sec-sustainable-ai).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 财务和环境影响加剧了这些挑战。大型基础模型的训练运行可能产生数百万美元的计算费用，相关的碳足迹[10](#fn10)也受到了越来越多的关注。这些成本限制了尖端研究的可及性，并加剧了获取先进人工智能系统的差距。效率障碍带来的民主化挑战直接关联到第
    19 章[第 19 章](ch025.xhtml#sec-ai-good)中解决的访问性目标。第 18 章[第 18 章](ch024.xhtml#sec-sustainable-ai)探讨了机器学习系统中环境可持续性的综合方法，包括碳足迹测量和绿色计算实践。
- en: These trade-offs demonstrate that scaling laws provide valuable frameworks for
    understanding performance growth but do not constitute unencumbered paths to improvement.
    Each incremental performance gain requires evaluation against corresponding resource
    requirements. As systems approach practical scaling limits, emphasis must transition
    from scaling alone to efficient scaling—a comprehensive approach balancing performance,
    cost, energy consumption, and environmental impact.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权衡表明，扩展定律为理解性能增长提供了有价值的框架，但并不构成改善的畅通无阻之路。每一次性能的提升都需要与相应的资源需求进行评估。当系统接近实际扩展极限时，重点必须从单纯的扩展转移到高效扩展——这是一种平衡性能、成本、能耗和环境影响的综合方法。
- en: Scaling Law Breakdown Conditions
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩展定律的失效条件
- en: Scaling laws exhibit remarkable consistency within specific operational regimes
    but possess inherent limitations. As systems expand, they inevitably encounter
    boundaries where underlying assumptions of smooth, predictable scaling cease to
    hold. These breakdown points expose critical inefficiencies and emphasize the
    necessity for refined system design approaches.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展定律在特定操作范围内表现出显著的稳定性，但存在固有的局限性。随着系统规模的扩大，它们不可避免地会遇到边界，在这些边界下，平滑、可预测扩展的基本假设不再成立。这些失效点揭示了关键的低效性，并强调了改进系统设计方法的必要性。
- en: For scaling laws to remain valid, model size, dataset size, and computational
    budget must be augmented in coordinated fashion. Over-investment in one dimension
    while maintaining others constant often results in suboptimal outcomes. For example,
    increasing model size without expanding training datasets may induce overfitting,
    while increasing computational resources without model redesign may lead to inefficient
    utilization ([Hoffmann et al. 2022](ch058.xhtml#ref-hoffmann2022training)).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使扩展定律保持有效，模型大小、数据集大小和计算预算必须协调一致地增加。在一维上过度投资而保持其他维度不变通常会导致次优结果。例如，在不扩大训练数据集的情况下增加模型大小可能会导致过拟合，而在不重新设计模型的情况下增加计算资源可能会导致资源利用效率低下
    ([Hoffmann 等人 2022](ch058.xhtml#ref-hoffmann2022training))。
- en: Large-scale models require carefully tuned training schedules and learning rates
    to fully utilize available resources. When compute is insufficiently allocated
    due to premature stopping, batch size misalignment, or ineffective parallelism,
    models may fail to reach performance potential despite significant infrastructure
    investment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模模型需要精心调整的训练计划和学习率，以充分利用可用资源。当由于提前停止、批大小不匹配或无效的并行性导致计算资源分配不足时，尽管投入了大量的基础设施投资，模型可能无法达到其性能潜力。
- en: Scaling laws presuppose continued performance improvement with sufficient training
    data. However, in numerous domains, availability of high-quality, human-annotated
    data is finite. As models consume increasingly large datasets, they reach points
    of diminishing marginal utility where additional data contributes minimal new
    information. Beyond this threshold, larger models may exhibit memorization rather
    than generalization.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展定律假设在足够训练数据的情况下持续提高性能。然而，在许多领域，高质量、人工标注的数据是有限的。随着模型消耗越来越大的数据集，它们会达到边际效用递减的点，此时额外的数据贡献的信息很少。超过这个阈值，更大的模型可能表现出记忆而不是泛化。
- en: As models grow, they demand greater memory bandwidth[11](#fn11), interconnect
    capacity, and I/O throughput. These hardware limitations become increasingly challenging
    even with specialized accelerators. Distributing trillion-parameter models across
    clusters necessitates meticulous management of data parallelism, communication
    overhead, and fault tolerance.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型的增长，它们需要更大的内存带宽[11](#fn11)、互连容量和I/O吞吐量。即使在专用加速器的情况下，这些硬件限制也变得越来越具有挑战性。在集群中分配万亿参数模型需要精心管理数据并行性、通信开销和容错性。
- en: At extreme scales, models may approach limits of what can be learned from training
    distributions. Performance on benchmarks may continue improving, but these improvements
    may no longer reflect meaningful gains in generalization or understanding. Models
    may become increasingly brittle, susceptible to adversarial examples, or prone
    to generating plausible but inaccurate outputs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在极端规模下，模型可能接近从训练分布中可以学习到的极限。在基准测试上的性能可能继续提高，但这些改进可能不再反映泛化或理解的实质性提升。模型可能变得越来越脆弱，容易受到对抗性样本的影响，或者倾向于生成看似合理但实际不准确的结果。
- en: '[Table 9.1](ch015.xhtml#tbl-scaling-breakdown) synthesizes the primary causes
    of scaling failure, outlining typical breakdown types, underlying causes, and
    representative scenarios as a reference for anticipating inefficiencies and guiding
    balanced system design.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[表9.1](ch015.xhtml#tbl-scaling-breakdown)综合了扩展失败的主要原因，概述了典型的分解类型、潜在原因和代表性场景，作为预测低效和指导平衡系统设计的参考。'
- en: 'Table 9.1: **Scaling Breakdown Types**: Unbalanced scaling across model size,
    data volume, and compute resources leads to specific failure modes, such as overfitting
    or diminishing returns, impacting system performance and efficiency. The table
    categorizes these breakdowns, identifies their root causes, and provides representative
    scenarios to guide more effective system design and resource allocation.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1：**扩展分解类型**：模型大小、数据量和计算资源之间的不平衡扩展会导致特定的失败模式，如过拟合或递减回报，影响系统性能和效率。该表对这些分解进行分类，确定其根本原因，并提供代表性场景以指导更有效的系统设计和资源分配。
- en: '| **Dimension Scaled** | **Type of Breakdown** | **Underlying Cause** | **Example
    Scenario** |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| **维度扩展** | **分解类型** | **潜在原因** | **示例场景** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Model Size** | Overfitting | Model capacity exceeds available data | Billion-parameter
    model on limited dataset |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| **模型大小** | 过拟合 | 模型容量超出可用数据 | 在有限数据集上的十亿参数模型 |'
- en: '| **Data Volume** | Diminishing Returns | Saturation of new or diverse information
    | Scaling web text beyond useful threshold |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **数据量** | 递减回报 | 新或多样化信息的饱和 | 超过有用阈值的网络文本扩展 |'
- en: '| **Compute Budget** | Underutilized Resources | Insufficient training steps
    or inefficient use | Large model with truncated training duration |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| **计算预算** | 资源未充分利用 | 训练步骤不足或使用效率低下 | 训练时间缩短的大型模型 |'
- en: '| **Imbalanced Scaling** | Inefficiency | Uncoordinated increase in model/data/compute
    | Doubling model size without more data or time |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| **不平衡扩展** | 低效 | 模型/数据/计算的不协调增加 | 没有更多数据或时间的情况下加倍模型大小 |'
- en: '| **All Dimensions** | Semantic Saturation | Exhaustion of learnable patterns
    in the domain | No further gains despite scaling all inputs |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| **所有维度** | 语义饱和 | 领域中可学习模式的耗尽 | 尽管扩展了所有输入，但不再有进一步收益 |'
- en: These breakdown points demonstrate that scaling laws describe empirical regularities
    under specific conditions that become increasingly difficult to maintain at scale.
    As machine learning systems continue evolving, discerning where and why scaling
    ceases to be effective becomes necessary, driving development of strategies that
    enhance performance without relying solely on scale.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分解点表明，扩展定律描述了在特定条件下的经验规律，在规模扩大时越来越难以维持。随着机器学习系统的持续发展，确定扩展何时不再有效变得必要，这推动了开发不依赖规模就能提高性能的策略。
- en: Integrating Efficiency with Scaling
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 整合效率和扩展
- en: The limitations exposed by scaling laws (data saturation, infrastructure bottlenecks,
    and diminishing returns) demonstrate that brute-force scaling alone cannot deliver
    sustainable AI systems. These constraints necessitate a shift from expanding scale
    to achieving greater efficiency with reduced resources.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展定律（数据饱和、基础设施瓶颈和递减回报）所暴露的局限性表明，仅靠 brute-force 扩展无法实现可持续的人工智能系统。这些限制需要从扩大规模转向以减少资源的方式实现更高的效率。
- en: 'This transition requires coordinated optimization across three interconnected
    dimensions: **algorithmic efficiency** addresses computational intensity through
    better model design, **compute efficiency** maximizes hardware utilization to
    translate algorithmic improvements into practical gains, and **data efficiency**
    extracts maximum information from limited examples as high-quality data becomes
    scarce. Together, these dimensions provide systematic approaches to achieving
    performance goals that scaling alone cannot sustainably deliver, while addressing
    broader concerns about equitable access to AI capabilities and environmental impact.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这一转变需要三个相互关联的维度之间的协调优化：**算法效率**通过更好的模型设计解决计算强度问题，**计算效率**最大化硬件利用率，将算法改进转化为实际收益，**数据效率**从有限的示例中提取最大信息，因为高质量数据变得稀缺。这三个维度共同提供了系统方法，以实现仅通过缩放无法可持续实现的目标，同时解决关于人工智能能力公平获取和环境影响的更广泛问题。
- en: Having examined how scaling laws reveal fundamental constraints, we now turn
    to the efficiency framework that provides concrete strategies for operating effectively
    within these constraints. The following section details how the three efficiency
    dimensions work together to enable sustainable, accessible machine learning systems.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在考察了缩放定律如何揭示基本约束之后，我们现在转向效率框架，该框架提供了在约束内有效操作的切实策略。下一节将详细说明三个效率维度如何协同工作，以实现可持续、可访问的机器学习系统。
- en: The Efficiency Framework
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 效率框架
- en: 'The constraint identified through scaling laws (that continued progress requires
    systematic efficiency optimization) motivates three complementary efficiency dimensions.
    Each dimension addresses a specific limitation: algorithmic efficiency tackles
    computational intensity, compute efficiency addresses hardware utilization gaps,
    and data efficiency solves the data saturation problem.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过缩放定律（即持续进步需要系统效率优化）确定的约束促使三个互补的效率维度。每个维度解决一个特定的限制：算法效率解决计算强度问题，计算效率解决硬件利用率差距，数据效率解决数据饱和问题。
- en: 'Together, these three dimensions provide a systematic framework for addressing
    the constraints that scaling laws reveal. Targeted optimizations across algorithmic
    design, hardware utilization, and data usage can achieve what brute-force scaling
    cannot: sustainable, accessible, high-performance AI systems.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个维度共同提供了一个系统框架，用于解决缩放定律揭示的约束。在算法设计、硬件利用和数据使用方面的针对性优化可以实现蛮力缩放无法实现的目标：可持续、可访问的高性能人工智能系统。
- en: Multi-Dimensional Efficiency Synergies
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多维效率协同
- en: 'Optimal performance requires coordinated optimization across multiple dimensions.
    No single resource—whether model parameters, training data, or compute budget—can
    be scaled indefinitely to achieve efficiency. Modern techniques demonstrate the
    potential: 10-100x gains in algorithmic efficiency through optimized architectures,
    5-50x improvements in hardware utilization through specialized processors, and
    10-1000x reductions in data requirements through advanced learning methods.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 优化性能需要跨多个维度进行协调优化。没有任何单一资源——无论是模型参数、训练数据还是计算预算——可以无限扩展以实现效率。现代技术展示了潜力：通过优化架构实现算法效率的10-100倍提升，通过专用处理器实现硬件利用率的5-50倍改进，通过高级学习方法实现数据需求的10-1000倍减少。
- en: The power of this framework emerges from interconnections between dimensions,
    as depicted in [Figure 9.8](ch015.xhtml#fig-evolution-efficiency). Algorithmic
    innovations often enable better hardware utilization, while hardware advances
    unlock new algorithmic possibilities. Data-efficient techniques reduce computational
    requirements, while compute-efficient methods enable training on larger datasets.
    Understanding these synergies is essential for building practical ML systems.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架的力量源于维度之间的相互联系，如图[图9.8](ch015.xhtml#fig-evolution-efficiency)所示。算法创新通常能够提高硬件利用率，而硬件进步则解锁新的算法可能性。数据高效技术减少计算需求，而计算高效方法使得在更大的数据集上进行训练成为可能。理解这些协同作用对于构建实用的机器学习系统至关重要。
- en: '![](../media/file138.svg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file138.svg)'
- en: 'Figure 9.8: : **Historical Efficiency Trends**: Algorithmic, computational,
    and data efficiency have each contributed to substantial gains in AI capabilities,
    though at different rates and with diminishing returns. Understanding these historical
    trends clarifies the interplay between these efficiency dimensions and informs
    strategies for scaling machine learning systems in data-limited environments.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.8: **历史效率趋势**: 算法、计算和数据效率各自为人工智能能力的显著提升做出了贡献，尽管它们的增长速度不同，且收益递减。理解这些历史趋势有助于阐明这些效率维度之间的相互作用，并为在数据有限的环境中扩展机器学习系统提供策略。'
- en: The specific priorities vary across deployment environments. Cloud systems with
    abundant resources prioritize scalability and throughput, while edge devices face
    severe memory and power constraints. Mobile applications must balance performance
    with battery life, and TinyML deployments demand extreme resource efficiency.
    Understanding these context-specific patterns enables designers to make informed
    decisions about which efficiency dimensions to prioritize and how to address inevitable
    trade-offs between them.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 具体优先级在不同部署环境中有所不同。资源丰富的云系统优先考虑可扩展性和吞吐量，而边缘设备面临严重的内存和电力限制。移动应用必须在性能和电池寿命之间取得平衡，而TinyML部署需要极端的资源效率。理解这些特定情境的模式使设计者能够就优先考虑哪些效率维度以及如何解决它们之间不可避免的权衡做出明智的决策。
- en: Achieving Algorithmic Efficiency
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现算法效率
- en: Algorithmic efficiency achieves maximum performance per unit of computation
    through optimized model architectures and training procedures. Modern techniques
    achieve 10-100x improvements in computational requirements while maintaining or
    improving accuracy, providing the most direct path to practical AI deployment.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 算法效率通过优化的模型架构和训练过程实现了每单位计算的最大性能。现代技术实现了计算需求10-100倍的改进，同时保持或提高准确度，为实际人工智能部署提供了最直接的途径。
- en: 'The foundation for these improvements lies in a key observation: most neural
    networks are dramatically overparameterized. The lottery ticket hypothesis reveals
    that networks contain sparse subnetworks, typically 10-20% of original parameters
    (though this varies significantly by architecture and task), that achieve comparable
    accuracy when trained in isolation ([Frankle and Carbin 2019](ch058.xhtml#ref-frankle2019lottery)).
    This discovery transforms compression into a principled approach: large models
    serve as initialization strategies for finding efficient architectures.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这些改进的基础在于一个关键观察：大多数神经网络都存在显著过参数化的问题。彩票假设揭示了网络中存在稀疏子网络，通常是原始参数的10-20%（尽管这因架构和任务而显著变化），当单独训练时可以达到相当的准确度（[Frankle和Carbin
    2019](ch058.xhtml#ref-frankle2019lottery)）。这一发现将压缩转化为一种原则性的方法：大型模型作为寻找高效架构的初始化策略。
- en: Model Compression Fundamentals
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型压缩基础
- en: 'Three major approaches dominate modern algorithmic efficiency, each targeting
    different aspects of model inefficiency:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 三种主要方法主导了现代算法效率，每种方法针对模型低效的不同方面：
- en: '**Model Compression** systematically removes redundant components from neural
    networks. Pruning techniques achieve 2-4x inference speedup with 1-3% accuracy
    loss by removing unnecessary weights and structures. Research demonstrates that
    ResNet-50 can be reduced to 20% of original parameters while maintaining 99% of
    ImageNet accuracy ([Gholami et al. 2021](ch058.xhtml#ref-gholami2021survey)).
    The specific pruning algorithms—including magnitude-based selection, structured
    vs. unstructured approaches, and layer-wise sensitivity analysis—are covered in
    detail in [Chapter 10](ch016.xhtml#sec-model-optimizations).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型压缩**系统地从神经网络中移除冗余组件。剪枝技术通过移除不必要的权重和结构，实现了2-4倍的推理速度提升，同时精度损失在1-3%之间。研究表明，ResNet-50可以被减少到原始参数的20%，同时保持99%的ImageNet准确度（[Gholami等人
    2021](ch058.xhtml#ref-gholami2021survey)）。具体的剪枝算法，包括基于幅度的选择、结构化与非结构化方法以及层敏感性分析，在[第10章](ch016.xhtml#sec-model-optimizations)中进行了详细阐述。'
- en: '**Precision Optimization** reduces computational requirements through quantization,
    which maps high-precision floating-point values to lower-precision representations.
    Neural networks demonstrate inherent robustness to precision reduction, with INT8
    quantization achieving 4x memory reduction and 2-4x inference speedup while typically
    maintaining 98-99% of FP32 accuracy ([Jacob et al. 2018a](ch058.xhtml#ref-Jacob_et_al_2018)).
    Modern techniques range from simple post-training quantization to sophisticated
    quantization-aware training. The specific quantization algorithms, calibration
    methods, and training procedures are detailed in [Chapter 10](ch016.xhtml#sec-model-optimizations).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**精度优化**通过量化减少计算需求，将高精度浮点值映射到低精度表示。神经网络显示出对精度降低的固有鲁棒性，INT8量化实现了4倍的内存减少和2-4倍的推理速度提升，同时通常保持98-99%的FP32精度（[Jacob等人2018a](ch058.xhtml#ref-Jacob_et_al_2018)）。现代技术从简单的训练后量化到复杂的量化感知训练都有涉及。具体的量化算法、校准方法和训练过程在第10章（ch016.xhtml#sec-model-optimizations）中详细说明。'
- en: '**Knowledge Transfer** distills capabilities from large teacher models into
    efficient student models. Knowledge distillation[12](#fn12) achieves 40-60% parameter
    reduction while retaining 95-97% of original performance, addressing both computational
    efficiency and data efficiency by requiring fewer training examples. The specific
    distillation algorithms, loss functions, and training procedures are covered in
    [Chapter 10](ch016.xhtml#sec-model-optimizations).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识迁移**将大型教师模型的能力提炼到高效的学生模型中。知识蒸馏[12](#fn12)实现了40-60%的参数减少，同时保留了95-97%的原有性能，通过需要更少的训练样本来提高计算效率和数据效率。具体的蒸馏算法、损失函数和训练过程在第10章（ch016.xhtml#sec-model-optimizations）中介绍。'
- en: Hardware-Algorithm Co-Design
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 硬件-算法协同设计
- en: Algorithmic optimizations alone are insufficient; their practical benefits depend
    on hardware-software co-design. Optimization techniques must be tailored to target
    hardware characteristics (memory bandwidth, compute capabilities, and precision
    support) to achieve real-world speedups. For example, INT8 quantization achieves
    2.3x speedup on NVIDIA V100 GPUs with tensor core support but may provide minimal
    benefit on hardware lacking specialized integer instructions.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 单独的算法优化是不够的；它们的实际效益取决于软硬件协同设计。优化技术必须针对目标硬件特性（内存带宽、计算能力和精度支持）进行定制，以实现实际的加速效果。例如，INT8量化在具有张量核心支持的NVIDIA
    V100 GPU上实现了2.3倍的加速，但在缺乏专用整数指令的硬件上可能提供最小的效益。
- en: Successful co-design requires understanding whether workloads are memory-bound
    (limited by data movement) or compute-bound (limited by processing capacity),
    then applying optimizations that address the actual bottleneck. Techniques like
    operator fusion reduce memory traffic by combining operations, while precision
    reduction exploits specialized hardware units. While [Chapter 10](ch016.xhtml#sec-model-optimizations)
    covers the algorithmic aspects of hardware-aware optimization, [Chapter 11](ch017.xhtml#sec-ai-acceleration)
    details how systematic co-design approaches leverage specific hardware architectures
    for maximum efficiency.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 成功的协同设计需要理解工作负载是内存受限（受数据移动限制）还是计算受限（受处理能力限制），然后应用解决实际瓶颈的优化。如操作融合等技术通过组合操作来减少内存流量，而精度降低则利用了专门的硬件单元。虽然[第10章](ch016.xhtml#sec-model-optimizations)涵盖了硬件感知优化的算法方面，但[第11章](ch017.xhtml#sec-ai-acceleration)详细介绍了系统化协同设计方法如何利用特定硬件架构以实现最大效率。
- en: Architectural Innovation for Efficiency
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 架构创新以提高效率
- en: Modern efficiency requires architectures designed for resource constraints.
    Models like MobileNet[13](#fn13), EfficientNet[14](#fn14), and SqueezeNet[15](#fn15)
    demonstrate that compact designs can deliver high performance through architectural
    innovations rather than scaling up existing designs.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现代效率需要针对资源限制设计的架构。MobileNet[13](#fn13)、EfficientNet[14](#fn14)和SqueezeNet[15](#fn15)等模型表明，紧凑的设计可以通过架构创新而不是通过扩大现有设计来提供高性能。
- en: Different deployment contexts require different efficiency trade-offs. Cloud
    inference prioritizes throughput and can tolerate higher memory usage, favoring
    parallel-friendly operations. Edge deployment prioritizes latency and memory efficiency,
    requiring architectures that minimize memory access. Mobile deployment constrains
    energy usage, demanding architectures optimized for energy-efficient operations.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的部署环境需要不同的效率权衡。云推理优先考虑吞吐量，可以容忍更高的内存使用，有利于并行友好型操作。边缘部署优先考虑延迟和内存效率，需要最小化内存访问的架构。移动部署限制能源使用，要求架构优化以实现节能操作。
- en: Parameter-Efficient Adaptation
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参数高效适应
- en: 'Parameter-efficient fine-tuning[16](#fn16) techniques demonstrate how the three
    efficiency dimensions work together. These methods update less than 1% of model
    parameters while achieving full fine-tuning performance, addressing all three
    efficiency pillars: algorithmic efficiency through reduced parameter updates,
    compute efficiency through lower memory requirements and faster training, and
    data efficiency by leveraging pre-trained representations that require fewer task-specific
    examples.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 参数高效微调[16](#fn16)技术展示了三个效率维度如何协同工作。这些方法更新不到1%的模型参数，同时实现完全微调性能，解决所有三个效率支柱：通过减少参数更新提高算法效率，通过降低内存需求和加快训练提高计算效率，以及通过利用需要较少任务特定示例的预训练表示提高数据效率。
- en: 'The practical impact is transformative: fine-tuning GPT-3 traditionally requires
    storing gradients for 175 billion parameters, consuming over 700GB of GPU memory.
    LoRA reduces this to under 10GB by learning low-rank decompositions of weight
    updates, enabling efficient adaptation on single consumer GPUs while requiring
    only hundreds of examples rather than thousands for effective adaptation.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 实际影响是变革性的：传统的GPT-3微调需要存储175亿个参数的梯度，消耗超过700GB的GPU内存。LoRA通过学习权重更新的低秩分解，将这一需求降低到10GB以下，使得在单个消费级GPU上实现高效适应成为可能，同时只需要数百个示例而不是数千个即可实现有效的适应。
- en: As [Figure 9.9](ch015.xhtml#fig-algo-efficiency) shows, the computational resources
    needed to train a neural network to achieve AlexNet[17](#fn17)-level performance
    on ImageNet[18](#fn18) classification decreased by approximately <semantics><mrow><mn>44</mn><mo>×</mo></mrow><annotation
    encoding="application/x-tex">44\times</annotation></semantics> between 2012 and
    2019\. This improvement, which halved every 16 months, outpaced hardware efficiency
    gains of Moore’s Law[19](#fn19), demonstrating the role of algorithmic advancements
    in driving efficiency ([Hernandez, Brown, et al. 2020](ch058.xhtml#ref-Hernandez_et_al_2020)).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图9.9](ch015.xhtml#fig-algo-efficiency)所示，在ImageNet[18](#fn18)分类上实现AlexNet[17](#fn17)级别性能所需的神经网络训练计算资源在2012年至2019年之间减少了大约<semantics><mrow><mn>44</mn><mo>×</mo></mrow><annotation
    encoding="application/x-tex">44\times</annotation></semantics>。这种每16个月减半的改进超过了摩尔定律[19](#fn19)的硬件效率提升，展示了算法进步在推动效率方面的作用
    ([Hernandez, Brown, 等人 2020](ch058.xhtml#ref-Hernandez_et_al_2020))。
- en: '![](../media/file139.svg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file139.svg)'
- en: 'Figure 9.9: : **Algorithmic Efficiency Progress**: Neural network training
    compute requirements decreased 44× between 2012 and 2019, outpacing hardware improvements
    and demonstrating the significant impact of algorithmic advancements on model
    efficiency. Innovations in model architecture and optimization techniques can
    drive substantial gains in AI system sustainability via this halving of compute
    every 16 months. Source: ([Hernandez, Brown, et al. 2020](ch058.xhtml#ref-Hernandez_et_al_2020)).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9：**算法效率进步**：神经网络训练的计算需求在2012年至2019年之间下降了44倍，超过了硬件改进，并展示了算法进步对模型效率的显著影响。通过每16个月计算量减半，模型架构和优化技术的创新可以推动人工智能系统可持续性的实质性提升。来源：([Hernandez,
    Brown, 等人 2020](ch058.xhtml#ref-Hernandez_et_al_2020))。
- en: The evolution of algorithmic efficiency, from basic compression to hardware-aware
    optimization and parameter-efficient adaptation, demonstrates the centrality of
    these techniques to machine learning progress. As the field advances, algorithmic
    efficiency will remain central to designing systems that are high-performing,
    scalable, and sustainable.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从基本的压缩到硬件感知优化和参数高效适应，算法效率的演变展示了这些技术在机器学习进步中的核心地位。随着该领域的发展，算法效率将继续是设计高性能、可扩展和可持续系统的核心。
- en: Compute Efficiency
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算效率
- en: Compute efficiency focuses on the effective use of hardware and computational
    resources to train and deploy machine learning models. It encompasses strategies
    for reducing energy consumption, optimizing processing speed, and leveraging hardware
    capabilities to achieve scalable and sustainable system performance. While this
    chapter focuses on efficiency principles and trade-offs, the detailed technical
    implementation of hardware acceleration—including GPU architectures, TPU design,
    memory systems, and custom accelerators—is covered in [Chapter 11](ch017.xhtml#sec-ai-acceleration).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 计算效率关注于有效利用硬件和计算资源来训练和部署机器学习模型。它包括减少能源消耗、优化处理速度以及利用硬件能力以实现可扩展和可持续的系统性能的策略。虽然本章重点介绍效率原则和权衡，但硬件加速的详细技术实现，包括GPU架构、TPU设计、内存系统以及定制加速器，将在[第11章](ch017.xhtml#sec-ai-acceleration)中介绍。
- en: From CPUs to AI Accelerators
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从CPU到AI加速器
- en: Compute efficiency’s evolution reveals why specialized hardware became essential.
    In the early days of machine learning, Central Processing Units (CPUs) shaped
    what was possible. CPUs excel at sequential processing and complex decision-making
    but have limited parallelism, typically 4-16 cores optimized for diverse tasks
    rather than the repetitive matrix operations that dominate machine learning. Training
    times for models were measured in days or weeks, as even relatively small datasets
    pushed hardware boundaries.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 计算效率的演变揭示了为什么专用硬件变得至关重要。在机器学习的早期，中央处理器(CPUs)塑造了可能实现的内容。CPU擅长顺序处理和复杂的决策，但并行性有限，通常有4-16个核心，优化用于多种任务，而不是机器学习占主导地位的重复矩阵运算。模型的训练时间以天或周计算，即使是相对较小的数据集也推高了硬件的界限。
- en: This CPU-constrained era ended as deep learning models like AlexNet and ResNet[20](#fn20)
    demonstrated the potential of neural networks, quickly surpassing traditional
    CPU capabilities. As shown in [Figure 9.10](ch015.xhtml#fig-comp_efficiency),
    this marked the beginning of exponential growth in compute usage. OpenAI’s analysis
    reveals that compute used in AI training increased approximately 300,000 times
    from 2012 to 2018, doubling approximately every 3.4 months during this period—a
    rate far exceeding Moore’s Law ([Amodei, Hernandez, et al. 2018](ch058.xhtml#ref-Amodei_et_al_2018)).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这个受CPU限制的时代随着像AlexNet和ResNet[20](#fn20)这样的深度学习模型展示了神经网络的潜力，迅速超越了传统的CPU能力而结束。如图[图9.10](ch015.xhtml#fig-comp_efficiency)所示，这标志着计算使用量指数增长的开始。OpenAI的分析显示，从2012年到2018年，用于AI训练的计算量增加了大约300,000倍，在此期间大约每3.4个月翻一番——这个速度远超过了摩尔定律([Amodei,
    Hernandez, et al. 2018](ch058.xhtml#ref-Amodei_et_al_2018))。
- en: '![](../media/file140.svg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file140.svg)'
- en: 'Figure 9.10: : **AI Training Compute Growth**: AI training experienced a 300,000-fold
    increase in computational requirements from 2012 to 2019, exceeding the growth
    rate predicted by Moore’s Law and driving demand for specialized hardware ([Amodei,
    Hernandez, et al. 2018](ch058.xhtml#ref-Amodei_et_al_2018)). This exponential
    growth underscores the increasing complexity of AI models and the need for efficient
    computing infrastructure to support continued progress.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图[图9.10](ch015.xhtml#fig-comp_efficiency)：**AI训练计算增长**：从2012年到2019年，AI训练的计算需求增加了300,000倍，超过了摩尔定律预测的增长率，推动了专用硬件的需求([Amodei,
    Hernandez, et al. 2018](ch058.xhtml#ref-Amodei_et_al_2018))。这种指数增长突显了AI模型日益复杂化以及支持持续进步的高效计算基础设施的需求。
- en: This rapid growth was driven by adoption of Graphics Processing Units (GPUs),
    which offered unparalleled parallel processing capabilities. While CPUs might
    have 16 cores, modern high-end GPUs like the NVIDIA H100 contain over 16,000 CUDA
    cores[21](#fn21). Specialized hardware accelerators such as Google’s Tensor Processing
    Units (TPUs) further revolutionized compute efficiency by designing chips specifically
    for machine learning workloads, optimizing for specific data types and operations
    most common in neural networks.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这种快速增长是由图形处理单元(GPUs)的采用所驱动的，它们提供了无与伦比的并行处理能力。虽然CPU可能有16个核心，但现代高端GPU如NVIDIA H100包含超过16,000个CUDA核心[21](#fn21)。像Google的Tensor
    Processing Units (TPUs)这样的专用硬件加速器通过为机器学习工作负载设计芯片，优化了神经网络中最常见的特定数据类型和操作，进一步革命化了计算效率。
- en: Sustainable Computing and Energy Awareness
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可持续计算和能源意识
- en: As systems scale further, compute efficiency has become closely tied to sustainability.
    Training state-of-the-art large language models requires massive computational
    resources, leading to increased attention on environmental impact. The projected
    electricity usage of data centers, shown in [Figure 9.11](ch015.xhtml#fig-datacenter-energy-usage),
    highlights this concern. Between 2010 and 2030, electricity consumption is expected
    to rise sharply, particularly under worst-case scenarios where it could exceed
    8,000 TWh by 2030 ([N. Jones 2018](ch058.xhtml#ref-jones2018much)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 随着系统进一步扩展，计算效率与可持续性紧密相连。训练最先进的大型语言模型需要巨大的计算资源，这导致了对环境影响的高度关注。[图9.11](ch015.xhtml#fig-datacenter-energy-usage)中显示的数据中心预计电力使用量突显了这一担忧。在2010年至2030年之间，预计电力消耗将急剧上升，尤其是在最坏的情况下，到2030年可能超过8,000太瓦时（[N.
    Jones 2018](ch058.xhtml#ref-jones2018much)）。
- en: '![](../media/file141.svg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file141.svg)'
- en: 'Figure 9.11: : **Data Center Energy Projections**: Between 2010 and 2030, data
    center electricity usage is projected to increase sharply, particularly under
    worst-case scenarios where consumption could exceed 8,000 TWh by 2030 ([N. Jones
    2018](ch058.xhtml#ref-jones2018much)). This projection underscores the critical
    need for improved energy efficiency in AI systems.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11：**数据中心能源预测**：在2010年至2030年之间，数据中心电力使用量预计将急剧增加，尤其是在最坏的情况下，到2030年消费量可能超过8,000太瓦时（[N.
    Jones 2018](ch058.xhtml#ref-jones2018much)）。这一预测强调了在AI系统中提高能源效率的迫切需要。
- en: This dramatic growth underscores urgency for compute efficiency, as even large
    data centers face energy constraints due to limitations in electrical grid capacity.
    Efficiency improvements alone may not guarantee environmental benefits due to
    a phenomenon known as Jevons Paradox.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这种显著的增长凸显了计算效率的紧迫性，因为即使是大型数据中心也面临着由于电网容量限制而导致的能源约束。仅仅提高效率可能无法保证环境效益，因为存在一种称为杰文斯悖论的现象。
- en: 'Consider the invention of the fuel-efficient car. While each car uses less
    gas per mile, the lower cost of driving encourages people to drive more often
    and live further from work. The result can be an *increase* in total gasoline
    consumption. This is Jevons Paradox: efficiency gains can be offset by increased
    consumption. In AI, this means making models 10x more efficient might lead to
    a 100x increase in their use, resulting in a net negative environmental impact
    if not managed carefully.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以燃油效率高的汽车发明为例。虽然每辆车每英里使用的汽油更少，但驾驶成本的降低鼓励人们更频繁地驾驶，住得离工作地点更远。结果可能是总汽油消费量的增加。这就是杰文斯悖论：效率的提高可能被消费量的增加所抵消。在AI中，这意味着使模型效率提高10倍可能会导致其使用量增加100倍，如果不谨慎管理，可能会导致净负面的环境影响。
- en: Addressing these challenges requires optimizing hardware utilization and minimizing
    energy consumption in both cloud and edge contexts while being mindful of potential
    rebound effects from increased deployment.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 应对这些挑战需要优化云和边缘环境中的硬件利用率，同时最小化能耗，并关注增加部署可能带来的潜在反弹效应。
- en: Key trends include adoption of energy-aware scheduling and resource allocation
    techniques that distribute workloads efficiently across available hardware ([D.
    Patterson et al. 2021b](ch058.xhtml#ref-Patterson_et_al_2021)). Researchers are
    also developing methods to dynamically adjust precision levels during training
    and inference, using lower precision operations (e.g., mixed-precision training)
    to reduce power consumption without sacrificing accuracy.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 主要趋势包括采用能源感知的调度和资源分配技术，这些技术能够高效地在可用硬件上分配工作负载（[D. Patterson 等人 2021b](ch058.xhtml#ref-Patterson_et_al_2021)）。研究人员还在开发动态调整训练和推理中精度水平的方法，使用低精度操作（例如，混合精度训练）来降低功耗，同时不牺牲精度。
- en: Distributed systems achieve compute efficiency by splitting workloads across
    multiple machines. Techniques such as model parallelism[22](#fn22) and data parallelism[23](#fn23)
    allow large-scale models to be trained more efficiently, leveraging clusters of
    GPUs or TPUs to maximize throughput while minimizing idle time.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统通过在多台机器之间分配工作负载来实现计算效率。模型并行[22](#fn22)和数据并行[23](#fn23)等技术允许大规模模型更有效地进行训练，利用GPU或TPU集群来最大化吞吐量，同时最小化空闲时间。
- en: At the edge, compute efficiency addresses growing demand for real-time processing
    in energy-constrained environments. Innovations such as hardware-aware model optimization,
    lightweight inference engines, and adaptive computing architectures enable highly
    efficient edge systems critical for applications like autonomous vehicles and
    smart home devices.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘，计算效率解决了在能源受限环境中对实时处理不断增长的需求。硬件感知的模型优化、轻量级推理引擎和自适应计算架构等创新，使得边缘系统高度高效，这对于自动驾驶汽车和智能家居设备等应用至关重要。
- en: Production Deployment Patterns
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生产部署模式
- en: Real-world efficiency optimization demonstrates practical impact across deployment
    contexts. Production systems routinely achieve 5-10x efficiency gains through
    coordinated application of optimization techniques while maintaining 95%+ of original
    model performance.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 实际世界的效率优化在部署环境中展示了实际影响。生产系统通过协调应用优化技术，通常实现5-10倍的效率提升，同时保持95%以上的原始模型性能。
- en: Mobile applications achieve 4-7x model size reduction and 3-5x latency improvements
    through combined quantization, pruning, and distillation, enabling real-time inference
    on mid-range devices. Modern mobile AI systems distribute workloads across specialized
    processors (NPU for ultra-low power inference, GPU for parallel compute, CPU for
    control logic) based on power, performance, and real-time constraints.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 移动应用程序通过联合量化、剪枝和蒸馏，实现了4-7倍的模型尺寸缩减和3-5倍的延迟改进，从而在中端设备上实现了实时推理。现代移动人工智能系统根据功率、性能和实时约束，将工作负载分配到专用处理器（用于超低功耗推理的NPU、用于并行计算的GPU、用于控制逻辑的CPU）。
- en: Autonomous vehicle systems optimize for safety-critical <10ms latency requirements
    through hardware-aware architectural design and mixed-precision quantization,
    processing multiple high-bandwidth sensor streams within strict power and thermal
    constraints.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶系统通过硬件感知的架构设计和混合精度量化，优化了安全关键性小于10毫秒的延迟要求，在严格的功率和热约束下处理多个高带宽传感器流。
- en: Cloud serving infrastructure reduces costs by 70-80% through systematic optimization
    combining dynamic batching, quantization, and knowledge distillation, serving
    4-5x more requests at comparable quality levels.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务基础设施通过结合动态批处理、量化和知识蒸馏的系统优化，降低了70-80%的成本，在可比的质量水平上服务4-5倍更多的请求。
- en: Edge IoT deployments achieve month-long battery life through extreme model compression
    and duty-cycle optimization, operating on milliwatt power budgets while maintaining
    acceptable accuracy for practical applications.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘物联网部署通过极端模型压缩和占空比优化，实现了长达一个月的电池寿命，在毫瓦级的功率预算下运行，同时保持实际应用可接受的准确性。
- en: These efficiency gains emerge from systematic optimization strategies that coordinate
    multiple techniques rather than applying individual optimizations in isolation.
    The specific optimization sequences, technique combinations, and engineering practices
    that enable these production results are detailed in [Chapter 10](ch016.xhtml#sec-model-optimizations).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些效率提升源于系统性的优化策略，这些策略协调了多种技术，而不是孤立地应用单个优化。实现这些生产结果的具体优化序列、技术组合和工程实践在[第10章](ch016.xhtml#sec-model-optimizations)中详细说明。
- en: Compute efficiency complements algorithmic and data efficiency. Compact models
    reduce computational requirements, while efficient data pipelines streamline hardware
    usage. The evolution of compute efficiency (from early reliance on CPUs through
    specialized accelerators to sustainable computing practices) remains central to
    building scalable, accessible, and environmentally responsible machine learning
    systems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 计算效率补充了算法和数据效率。紧凑的模型减少了计算需求，而高效的数据管道简化了硬件使用。计算效率的演变（从早期对CPU的依赖到专用加速器再到可持续计算实践）对于构建可扩展、可访问和负责任的机器学习系统至关重要。
- en: Data Efficiency
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据效率
- en: Data efficiency focuses on optimizing the amount and quality of data required
    to train machine learning models effectively. Data efficiency has emerged as a
    pivotal dimension, driven by rising costs of data collection, storage, and processing,
    as well as the limits of available high-quality data.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 数据效率专注于优化训练机器学习模型所需的数据量和质量。随着数据收集、存储和处理成本的上升，以及可用高质量数据的限制，数据效率已成为一个关键维度。
- en: Maximizing Learning from Limited Data
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最大化从有限数据中学习
- en: In early machine learning, data efficiency was not a primary focus, as datasets
    were relatively small and manageable. The challenge was often acquiring enough
    labeled data to train models effectively. Researchers relied on curated datasets
    such as [UCI’s Machine Learning Repository](https://archive.ics.uci.edu/)[24](#fn24),
    using feature selection and dimensionality reduction techniques like principal
    component analysis (PCA)[25](#fn25) to extract maximum value from limited data.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的机器学习中，数据效率并不是主要关注点，因为数据集相对较小且易于管理。挑战通常是获取足够的标记数据来有效训练模型。研究人员依赖于如[UCI机器学习仓库](https://archive.ics.uci.edu/)[24](#fn24)这样的整理数据集，使用特征选择和降维技术如主成分分析（PCA）[25](#fn25)从有限的数据中提取最大价值。
- en: The advent of deep learning in the 2010s transformed data’s role. Models like
    AlexNet and GPT-3 demonstrated that larger datasets often led to better performance,
    marking the beginning of the “big data” era. However, this reliance introduced
    inefficiencies. Data collection became costly and time-consuming, requiring vast
    amounts of labeled data for supervised learning.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 2010年代深度学习的出现改变了数据的作用。像AlexNet和GPT-3这样的模型表明，更大的数据集往往会导致更好的性能，标志着“大数据”时代的开始。然而，这种依赖引入了低效。数据收集变得昂贵且耗时，需要大量标记数据来进行监督学习。
- en: Researchers developed techniques enhancing data efficiency even as datasets
    grew. Transfer learning[26](#fn26) allowed pre-trained models to be fine-tuned
    on smaller datasets, reducing task-specific data needs ([Yosinski et al. 2014](ch058.xhtml#ref-yosinski2014transferable)).
    Data augmentation[27](#fn27) artificially expanded datasets by creating new variations
    of existing samples. Active learning[28](#fn28) prioritized labeling only the
    most informative data points ([Settles 2012a](ch058.xhtml#ref-Settles_2009)).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据集在增长，研究人员也开发了提高数据效率的技术。迁移学习[26](#fn26)允许在较小的数据集上微调预训练模型，减少特定任务的数据需求([Yosinski等人2014](ch058.xhtml#ref-yosinski2014transferable))。数据增强[27](#fn27)通过创建现有样本的新变体来人工扩大数据集。主动学习[28](#fn28)优先标记最具信息量的数据点([Settles
    2012a](ch058.xhtml#ref-Settles_2009))。
- en: As systems continue growing in scale, inefficiencies of large datasets have
    become apparent. Data-centric AI[29](#fn29) has emerged as a key paradigm, emphasizing
    data quality over quantity. This approach focuses on enhancing preprocessing,
    removing redundancy, and improving labeling efficiency. Research shows that careful
    curation and filtering can achieve comparable or superior performance while using
    only a fraction of original data volume ([Penedo et al. 2024](ch058.xhtml#ref-penedo2024fineweb)).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 随着系统规模的持续增长，大数据集的低效性变得明显。数据为中心的AI[29](#fn29)已成为一个关键范式，强调数据质量而非数量。这种方法侧重于增强预处理、去除冗余和提高标记效率。研究表明，经过仔细整理和过滤，可以使用只有原始数据量的一小部分实现相当或更优的性能([Penedo等人2024](ch058.xhtml#ref-penedo2024fineweb))。
- en: Several techniques support this transition. Self-supervised learning[30](#fn30)
    enables models to learn meaningful representations from unlabeled data, reducing
    dependency on expensive human-labeled datasets. Active learning strategies selectively
    identify the most informative examples for labeling, while curriculum learning[31](#fn31)
    structures training to progress from simple to complex examples, improving learning
    efficiency.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 几种技术支持这种过渡。自监督学习[30](#fn30)使模型能够从未标记的数据中学习有意义的表示，减少对昂贵的人类标记数据集的依赖。主动学习策略有选择性地识别用于标记的最具信息量的示例，而课程学习[31](#fn31)则将训练结构化，从简单示例逐步过渡到复杂示例，提高学习效率。
- en: Data efficiency is particularly important in foundation models[32](#fn32). As
    these models grow in scale and capability, they approach limits of available high-quality
    training data, especially for language tasks, as shown in [Figure 9.12](ch015.xhtml#fig-running-out-of-human-data).
    This scarcity drives innovation in data processing and curation techniques.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数据效率在基础模型[32](#fn32)中尤为重要。随着这些模型在规模和能力上的增长，它们接近了可用高质量训练数据的极限，尤其是在语言任务中，如图[9.12](ch015.xhtml#fig-running-out-of-human-data)所示。这种稀缺性推动了数据处理和整理技术的创新。
- en: '![](../media/file142.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file142.png)'
- en: 'Figure 9.12: **Dataset Growth**: Foundation models are increasingly trained
    on vast datasets, reflecting the growing stock of human-generated text. This trend
    underscores the challenge of data scarcity in maintaining model performance as
    scale increases. Source: Sevilla et al. ([2022c](ch058.xhtml#ref-villalobos_ho_sevilla_besiroglu_heim_hobbhahn_2024)).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12：**数据集增长**：基础模型越来越多地在大规模数据集上训练，反映了人类生成文本的日益增长。这一趋势突显了随着规模增加，在保持模型性能的同时，数据稀缺性的挑战。来源：Sevilla等([2022c](ch058.xhtml#ref-villalobos_ho_sevilla_besiroglu_heim_hobbhahn_2024))。
- en: Evidence for data quality’s impact appears across different deployment scales.
    In Tiny ML[33](#fn33) applications, datasets like Wake Vision demonstrate how
    performance critically depends on careful data curation ([C. Banbury et al. 2024](ch058.xhtml#ref-banbury2024wakevisiontailoreddataset)).
    At larger scales, research on language models trained on web-scale datasets shows
    that intelligent filtering and selection strategies significantly improve performance
    on downstream tasks ([Penedo et al. 2024](ch058.xhtml#ref-penedo2024fineweb)).
    [Chapter 12](ch018.xhtml#sec-benchmarking-ai) establishes rigorous methodologies
    for measuring these data quality improvements.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量影响证据在不同部署规模中均有体现。在Tiny ML[33](#fn33)应用中，如Wake Vision等数据集展示了性能如何严重依赖于仔细的数据整理([C.
    Banbury等，2024](ch058.xhtml#ref-banbury2024wakevisiontailoreddataset))。在更大规模上，基于网络规模数据集训练的语言模型研究显示，智能过滤和选择策略显著提高了下游任务的表现([Penedo等，2024](ch058.xhtml#ref-penedo2024fineweb))。[第12章](ch018.xhtml#sec-benchmarking-ai)建立了衡量这些数据质量改进的严格方法。
- en: This modern era of data efficiency represents a shift in how systems approach
    data utilization. By focusing on quality over quantity and developing sophisticated
    techniques for data selection and processing, the field is moving toward more
    sustainable and effective approaches to model training and deployment. Data efficiency
    is integral to scalable systems, impacting both model and compute efficiency.
    Smaller, higher-quality datasets reduce training times and computational demands
    while enabling better generalization. These principles complement the privacy-preserving
    techniques explored in [Chapter 15](ch021.xhtml#sec-security-privacy), where minimizing
    data requirements enhances both efficiency and user privacy protection.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据效率的现代时代代表了系统处理数据利用方式的一种转变。通过关注质量而非数量，并开发用于数据选择和处理的复杂技术，该领域正朝着更可持续和有效的模型训练和部署方法迈进。数据效率对于可扩展系统至关重要，它影响着模型和计算效率。更小、质量更高的数据集可以缩短训练时间和计算需求，同时实现更好的泛化。这些原则与第15章中探讨的隐私保护技术相辅相成，其中最小化数据需求可以增强效率和用户隐私保护。
- en: Real-World Efficiency Strategies
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际世界的效率策略
- en: Having explored each efficiency dimension individually and their interconnections,
    we examine how these dimensions manifest across different deployment contexts.
    The efficiency of machine learning systems emerges from understanding relationships
    between algorithmic, compute, and data efficiency in specific operational environments.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在单独探讨了每个效率维度及其相互关系之后，我们考察了这些维度如何在不同的部署环境中体现出来。机器学习系统的效率源于在特定操作环境中理解算法、计算和数据效率之间的关系。
- en: Context-Specific Efficiency Requirements
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文特定的效率需求
- en: The specific priorities and trade-offs vary dramatically across deployment environments.
    As our opening examples illustrated, these range from cloud systems with abundant
    resources to edge devices with severe memory and power constraints. [Table 9.2](ch015.xhtml#tbl-deployment-efficiency-priorities)
    maps how these constraints translate into efficiency optimization priorities.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署环境中，具体的优先级和权衡差异很大。正如我们的开篇示例所示，这些范围从资源丰富的云系统到内存和电源限制严重的边缘设备。 [表9.2](ch015.xhtml#tbl-deployment-efficiency-priorities)展示了这些限制如何转化为效率优化优先级。
- en: 'Table 9.2: **Efficiency Optimization Priorities by Deployment Context**: Each
    environment demands different trade-offs between algorithmic, compute, and data
    optimization strategies based on unique constraints. Cloud systems prioritize
    scalability, edge deployments focus on real-time performance, mobile applications
    balance performance with battery life, and TinyML demands extreme resource efficiency.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.2：**按部署环境优化的效率优先级**：每个环境都根据独特的约束条件，在算法、计算和数据优化策略之间进行不同的权衡。云系统优先考虑可扩展性，边缘部署侧重于实时性能，移动应用在性能与电池寿命之间取得平衡，而TinyML则要求极端的资源效率。
- en: '| **Deployment Context** | **Primary Constraints** | **Efficiency Priorities**
    | **Representative Applications** |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| **部署环境** | **主要约束** | **效率优先级** | **代表性应用** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Cloud** | Cost at scale, energy consumption | Throughput, scalability,
    operational efficiency | Large language model APIs, recommendation engines, video
    processing |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| **云** | 规模成本、能源消耗 | 吞吐量、可扩展性、运营效率 | 大型语言模型API、推荐引擎、视频处理 |'
- en: '| **Edge** | Latency, local compute capacity, connectivity | Real-time performance,
    power efficiency | Autonomous vehicles, industrial automation, smart cameras |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| **边缘** | 延迟、本地计算能力、连接性 | 实时性能、能效 | 自动驾驶汽车、工业自动化、智能摄像头 |'
- en: '| **Mobile** | Battery life, memory, thermal limits | Energy efficiency, model
    size, responsiveness | Voice assistants, photo enhancement, augmented reality
    |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| **移动** | 电池寿命、内存、热限制 | 能效、模型大小、响应性 | 语音助手、照片增强、增强现实 |'
- en: '| **TinyML** | Extreme power/memory constraints | Ultra-low power, minimal
    model size | IoT sensors, wearables, environmental monitoring |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| **TinyML** | 极端功耗/内存限制 | 极低功耗、最小模型大小 | 物联网传感器、可穿戴设备、环境监测 |'
- en: Understanding these context-specific patterns enables designers to make informed
    decisions about which efficiency dimensions to prioritize and how to navigate
    inevitable trade-offs.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这些特定于上下文的模式，使设计者能够做出明智的决定，关于优先考虑哪些效率维度以及如何应对不可避免的权衡。
- en: Scalability and Sustainability
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可扩展性与可持续性
- en: System efficiency serves as a driver of environmental sustainability. When systems
    are optimized for efficiency, they can be deployed at scale while minimizing environmental
    footprint. This relationship creates a positive feedback loop, as shown in [Figure 9.13](ch015.xhtml#fig-virtuous-efficiency-cycle).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 系统效率是环境可持续性的驱动因素。当系统针对效率进行优化时，它们可以大规模部署，同时最小化环境影响。这种关系创造了一个正反馈循环，如图[图9.13](ch015.xhtml#fig-virtuous-efficiency-cycle)所示。
- en: '![](../media/file143.svg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file143.svg)'
- en: 'Figure 9.13: : **Efficiency and Sustainability Feedback Loop**: Optimized machine
    learning systems achieve greater scalability, which in turn incentivizes sustainable
    design practices and further efficiency improvements, creating a reinforcing feedback
    loop for long-term impact.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13：**效率和可持续性反馈循环**：优化的机器学习系统实现更大的可扩展性，这反过来又激励可持续设计实践和进一步的效率改进，从而形成一个增强反馈循环，对长期影响产生积极影响。
- en: Efficient systems are inherently scalable. Reducing resource demands through
    lightweight models, targeted datasets, and optimized compute utilization allows
    systems to deploy broadly. When efficient systems scale, they amplify their contribution
    to sustainability by reducing overall energy consumption and computational waste.
    Sustainability reinforces the need for efficiency, creating a feedback loop that
    strengthens the entire system.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 高效系统本质上具有可扩展性。通过轻量级模型、针对性数据集和优化的计算利用来减少资源需求，使系统能够广泛部署。当高效系统扩展时，它们通过减少整体能源消耗和计算浪费来放大其对可持续性的贡献。可持续性强化了对效率的需求，形成一个反馈循环，从而加强整个系统。
- en: Efficiency Trade-offs and Challenges
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 效率权衡与挑战
- en: 'The three efficiency dimensions can work synergistically under favorable conditions,
    but real-world systems often face scenarios where improving one dimension degrades
    another. The same resource constraints that make efficiency necessary force difficult
    choices: reducing model size may sacrifice accuracy, optimizing for real-time
    performance may increase energy consumption, and curating smaller datasets may
    limit generalization.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在有利条件下，三个效率维度可以协同工作，但现实世界中的系统经常面临改善一个维度会降低另一个维度的场景。使效率成为必要的相同资源限制迫使做出艰难的选择：减少模型大小可能会牺牲准确性，针对实时性能可能会增加能源消耗，以及精心制作更小的数据集可能会限制泛化。
- en: Fundamental Sources of Efficiency Trade-offs
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 效率权衡的基本来源
- en: These tensions manifest in various ways across machine learning systems. Understanding
    their root causes is essential for addressing design challenges. Each efficiency
    dimension influences the others, creating a dynamic interplay that shapes system
    performance.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些紧张关系以各种方式在机器学习系统中体现。理解其根本原因对于解决设计挑战至关重要。每个效率维度都会影响其他维度，形成一个动态的相互作用，从而塑造系统性能。
- en: Algorithmic Efficiency vs. Compute Requirements
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 算法效率与计算需求
- en: Algorithmic efficiency focuses on designing compact models that minimize computational
    and memory demands. By reducing model size or complexity, deployment on resource-limited
    devices becomes feasible. Overly simplifying a model can reduce accuracy, especially
    for complex tasks. To compensate for this loss, additional computational resources
    may be required during training or deployment, placing strain on compute efficiency.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 算法效率关注于设计紧凑的模型，以最小化计算和内存需求。通过减小模型大小或复杂性，在资源受限的设备上部署变得可行。过度简化模型可能会降低准确性，尤其是在复杂任务中。为了弥补这种损失，在训练或部署期间可能需要额外的计算资源，从而对计算效率造成压力。
- en: Compute Efficiency vs. Real-Time Needs
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算效率与实时需求
- en: 'Compute efficiency aims to minimize resources required for training and inference,
    reducing energy consumption, processing time, and memory use. In scenarios requiring
    real-time responsiveness (autonomous vehicles, augmented reality), compute efficiency
    becomes harder to maintain. [Figure 9.14](ch015.xhtml#fig-efficiency-vs-latency)
    illustrates this challenge: real-time systems often require high-performance hardware
    to process data instantly, conflicting with energy efficiency goals or increasing
    system costs.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 计算效率旨在最小化训练和推理所需的资源，以减少能耗、处理时间和内存使用。在需要实时响应的场景（如自动驾驶汽车、增强现实）中，保持计算效率变得更加困难。[图9.14](ch015.xhtml#fig-efficiency-vs-latency)展示了这一挑战：实时系统通常需要高性能硬件来即时处理数据，这与能源效率目标或增加系统成本相冲突。
- en: '![](../media/file144.svg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file144.svg)'
- en: 'Figure 9.14: : **Real-Time System Constraints**: Autonomous vehicles demand
    careful balance between computational efficiency and low latency. Increasing processing
    power to reduce delay can conflict with energy and cost limitations, yet sacrificing
    latency compromises safety by increasing reaction time and braking distance.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14：**实时系统限制**：自动驾驶汽车需要在计算效率和低延迟之间进行仔细的平衡。增加处理能力以减少延迟可能会与能源和成本限制相冲突，而牺牲延迟会通过增加反应时间和制动距离来降低安全性。
- en: Data Efficiency vs. Model Generalization
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据效率与模型泛化
- en: Data efficiency seeks to minimize the amount of data required to train a model
    without sacrificing performance. By curating smaller, high-quality datasets, training
    becomes faster and less resource-intensive. Ideally, this reinforces both algorithmic
    and compute efficiency. However, reducing dataset size can limit diversity, making
    it harder for models to generalize to unseen scenarios. To address this, additional
    compute resources or model complexity may be required, creating tension between
    data efficiency and broader system goals.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 数据效率旨在最小化训练模型所需的数据量，同时不牺牲性能。通过精心挑选更小、质量更高的数据集，训练过程变得更快且资源消耗更少。理想情况下，这可以同时加强算法和计算效率。然而，减小数据集大小可能会限制多样性，使得模型更难泛化到未见过的场景。为了解决这个问题，可能需要额外的计算资源或模型复杂性，从而在数据效率和更广泛系统目标之间产生紧张关系。
- en: Recurring Trade-off Patterns in Practice
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实践中的反复权衡模式
- en: The trade-offs between efficiency dimensions become particularly evident when
    examining specific scenarios. Complex models with millions or billions of parameters
    can achieve higher accuracy by capturing intricate patterns, but require significant
    computational power and memory. A recommendation system in a cloud data center
    might use a highly complex model for better recommendations, but at the cost of
    higher energy consumption and operating costs. On resource-constrained devices
    like smartphones or autonomous vehicles, compact models may operate efficiently
    but require more sophisticated data preprocessing or training procedures to compensate
    for reduced capacity.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当考察特定场景时，效率维度之间的权衡变得尤为明显。具有数百万或数十亿参数的复杂模型可以通过捕捉复杂模式来实现更高的准确性，但需要大量的计算能力和内存。一个云数据中心中的推荐系统可能会使用高度复杂的模型以获得更好的推荐，但代价是更高的能耗和运营成本。在资源受限的设备如智能手机或自动驾驶汽车上，紧凑的模型可能运行效率较高，但需要更复杂的数据预处理或训练程序来补偿其减少的容量。
- en: Energy efficiency and real-time performance often pull systems in opposite directions.
    Real-time systems like autonomous vehicles or augmented reality applications rely
    on high-performance hardware to process large volumes of data quickly, but this
    typically increases energy consumption. An autonomous vehicle must process sensor
    data from cameras, LiDAR, and radar in real time to make navigation decisions,
    requiring specialized accelerators that consume significant energy. In edge deployments
    with battery power or limited energy sources, this trade-off becomes even more
    critical.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 能效和实时性能通常将系统推向相反的方向。像自动驾驶汽车或增强现实应用这样的实时系统依赖于高性能硬件来快速处理大量数据，但这通常会增加能耗。自动驾驶汽车必须实时处理来自摄像头、激光雷达和雷达的传感器数据以做出导航决策，这需要消耗大量能量的专用加速器。在电池供电或能源有限的边缘部署中，这种权衡变得更加关键。
- en: Larger datasets generally provide greater diversity and coverage, enabling models
    to capture subtle patterns and reduce overfitting risk. However, computational
    and memory demands of training on large datasets can be substantial. In resource-constrained
    environments like TinyML deployments, an IoT device monitoring environmental conditions
    might need a model that generalizes well across varying conditions, but collecting
    extensive datasets may be impractical due to storage and computational limitations.
    Smaller, carefully curated datasets or synthetic data may be used to reduce computational
    strain, but this risks missing key edge cases.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的数据集通常提供更大的多样性和覆盖范围，使模型能够捕捉细微的模式并降低过拟合风险。然而，在大数据集上训练的计算和内存需求可能很大。在资源受限的环境中，如TinyML部署，监测环境条件的物联网设备可能需要一个在不同条件下都能良好泛化的模型，但由于存储和计算限制，收集大量数据可能不切实际。较小、精心挑选的数据集或合成数据可以用来减少计算压力，但这也可能导致错过关键边缘情况。
- en: These trade-offs are not merely academic concerns but practical realities that
    shape system design decisions across all deployment contexts.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权衡不仅仅是学术上的关注，而是塑造所有部署环境中系统设计决策的实际情况。
- en: Strategic Trade-off Management
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 战略性权衡管理
- en: The trade-offs inherent in machine learning system design require thoughtful
    strategies to navigate effectively. Achieving the right balance involves difficult
    decisions heavily influenced by specific goals and constraints of the deployment
    environment. Designers can adopt a range of strategies that address unique requirements
    of different contexts.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统设计中固有的权衡需要深思熟虑的策略来有效地导航。实现正确的平衡涉及受特定目标和部署环境约束的困难决策。
- en: Environment-Driven Efficiency Priorities
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环境驱动的效率优先级
- en: Efficiency goals are rarely universal. The specific demands of an application
    or deployment scenario heavily influence which dimension—algorithmic, compute,
    or data—takes precedence. Prioritizing the right dimensions based on context is
    the first step in effectively managing trade-offs.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 效率目标很少是普遍适用的。应用程序或部署场景的具体需求极大地影响了哪个维度——算法、计算或数据——优先。根据具体情况优先考虑正确的维度是有效管理权衡的第一步。
- en: In Mobile ML deployments, battery life is often the primary constraint, placing
    a premium on compute efficiency. Energy consumption must be minimized to preserve
    operational time, so lightweight models are prioritized even if it means sacrificing
    some accuracy or requiring additional data preprocessing.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在移动机器学习部署中，电池寿命通常是主要约束，对计算效率提出了更高的要求。为了保持操作时间，必须最小化能耗，因此即使这意味着牺牲一些精度或需要额外的数据预处理，轻量级模型也被优先考虑。
- en: In Cloud ML systems, scalability and throughput are paramount. These systems
    must process large volumes of data and serve millions of users simultaneously.
    While compute resources are more abundant, energy efficiency and operational costs
    remain important. Algorithmic efficiency plays a critical role in ensuring systems
    can scale without overwhelming infrastructure.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在云机器学习系统中，可扩展性和吞吐量至关重要。这些系统必须处理大量数据并同时服务数百万用户。虽然计算资源更为丰富，但能效和运营成本仍然很重要。算法效率在确保系统可以扩展而不会压倒基础设施方面发挥着关键作用。
- en: Edge ML systems present different priorities. Autonomous vehicles or real-time
    monitoring systems require low-latency processing for safe and reliable operation,
    making real-time performance and compute efficiency paramount, often at the expense
    of energy consumption. However, hardware constraints mean these systems must still
    carefully manage energy and computational resources.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘机器学习系统有不同的优先级。自动驾驶汽车或实时监控系统需要低延迟处理以确保安全和可靠运行，这使得实时性能和计算效率至关重要，往往以能耗为代价。然而，硬件限制意味着这些系统仍需仔细管理能源和计算资源。
- en: '**TinyML** deployments demand extreme efficiency due to severe hardware and
    energy limitations. Algorithmic and data efficiency are top priorities, with models
    highly compact and capable of operating on microcontrollers with minimal memory
    and compute power, while training relies on small, carefully curated datasets.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**TinyML**部署由于严重的硬件和能源限制，需要极高的效率。算法和数据效率是首要任务，模型高度紧凑，能够在具有最小内存和计算能力的微控制器上运行，而训练则依赖于小型、精心挑选的数据集。'
- en: Dynamic Resource Allocation at Inference
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推理过程中的动态资源分配
- en: System adaptability can be enhanced through dynamic resource allocation during
    inference. This approach recognizes that resource needs may fluctuate even within
    specific deployment contexts. By adjusting computational effort at inference time,
    systems can fine-tune performance to meet immediate demands.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通过推理过程中的动态资源分配可以增强系统适应性。这种方法认识到资源需求即使在特定的部署环境中也可能波动。通过在推理时调整计算努力，系统可以微调性能以满足即时需求。
- en: For example, a cloud-based video analysis system might process standard streams
    with a streamlined model to maintain high throughput, but when a critical event
    is detected, dynamically allocate more resources to a complex model for higher
    precision. Similarly, mobile voice assistants might use lightweight models for
    routine commands to conserve battery, but temporarily activate resource-intensive
    models for complex queries.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个基于云的视频分析系统可能会使用简化模型处理标准流以保持高吞吐量，但在检测到关键事件时，会动态分配更多资源给复杂模型以实现更高的精度。同样，移动语音助手可能会使用轻量级模型处理常规命令以节省电池，但在处理复杂查询时会临时激活资源密集型模型。
- en: Implementing test-time compute introduces new challenges. Dynamic resource allocation
    requires sophisticated monitoring and control mechanisms. There are diminishing
    returns—increasing compute beyond certain thresholds may not yield significant
    performance improvements. The ability to dynamically increase compute can also
    create disparities in access to high-performance AI, raising equity concerns.
    Despite these challenges, test-time compute offers a valuable strategy for enhancing
    system adaptability.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 实现测试时计算引入了新的挑战。动态资源分配需要复杂的监控和控制机制。收益递减——计算能力超过一定阈值可能不会带来显著的性能提升。动态增加计算能力也可能导致高性能AI访问的不平等，引发公平性问题。尽管存在这些挑战，测试时计算仍然是提高系统适应性的宝贵策略。
- en: End-to-End Co-Design and Automated Optimization
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端到端协同设计和自动化优化
- en: Efficient machine learning systems are rarely the product of isolated optimizations.
    Achieving balance across efficiency dimensions requires an end-to-end co-design
    perspective, where each system component is designed in tandem with others. This
    holistic approach aligns model architectures, hardware platforms, and data pipelines
    to work seamlessly together.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 高效的机器学习系统很少是孤立优化的产物。在效率维度上实现平衡需要端到端的协同设计视角，其中每个系统组件都是与其他组件一起设计的。这种整体方法使模型架构、硬件平台和数据管道能够无缝协同工作。
- en: Co-design becomes essential in resource-constrained environments. Models must
    align precisely with hardware capabilities—8-bit models require hardware support
    for efficient integer operations, while pruned models benefit from sparse tensor
    operations. Edge accelerators often optimize specific operations like convolutions,
    influencing model architecture choices. Detailed hardware architecture considerations
    are covered comprehensively in [Chapter 11](ch017.xhtml#sec-ai-acceleration).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在资源受限的环境中，协同设计变得至关重要。模型必须与硬件能力精确匹配——8位模型需要硬件对高效整数运算的支持，而剪枝模型则受益于稀疏张量运算。边缘加速器通常优化特定的操作，如卷积，这会影响模型架构的选择。详细的硬件架构考虑因素在[第11章](ch017.xhtml#sec-ai-acceleration)中得到了全面覆盖。
- en: '**Automation and optimization tools** help manage the complexity of navigating
    trade-offs. Automated machine learning (AutoML)[34](#fn34) enables exploration
    of different model architectures and hyperparameter configurations. Building on
    the systematic approach to ML workflows introduced in [Chapter 5](ch011.xhtml#sec-ai-workflow),
    AutoML tools automate many efficiency optimization decisions that traditionally
    required extensive manual tuning.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动化和优化工具**有助于管理导航权衡的复杂性。自动化机器学习（AutoML）[34](#fn34)允许探索不同的模型架构和超参数配置。在第5章（ch011.xhtml#sec-ai-workflow）中介绍的系统化机器学习工作流程的基础上，AutoML工具自动化了许多传统上需要大量手动调整的效率优化决策。'
- en: Neural architecture search (NAS)[35](#fn35) takes automation further by designing
    model architectures tailored to specific hardware or deployment scenarios, evaluating
    a wide range of architectural possibilities to maximize performance while minimizing
    computational demands.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 神经架构搜索（NAS）[35](#fn35)通过设计针对特定硬件或部署场景定制的模型架构，进一步推进了自动化，评估广泛的架构可能性，以最大化性能同时最小化计算需求。
- en: Data efficiency also benefits from automation. Tools that automate dataset curation,
    augmentation, and active learning reduce training dataset size without sacrificing
    performance, prioritizing high-value data points to speed up training and reduce
    computational overhead ([Settles 2012b](ch058.xhtml#ref-settles2009active)). [Chapter 7](ch013.xhtml#sec-ai-frameworks)
    explores how modern ML frameworks incorporate these automation capabilities.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 数据效率也得益于自动化。自动化数据集整理、增强和主动学习的工具可以减少训练数据集的大小，同时不牺牲性能，优先考虑高价值数据点以加快训练并减少计算开销 ([Settles
    2012b](ch058.xhtml#ref-settles2009active))。[第7章](ch013.xhtml#sec-ai-frameworks)探讨了现代机器学习框架如何整合这些自动化能力。
- en: Measuring and Monitoring Efficiency Trade-offs
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量和监控效率权衡
- en: Beyond technical automation lies the broader challenge of systematic evaluation.
    Efficiency optimization necessitates a structured approach assessing trade-offs
    that extends beyond purely technical considerations. As systems transition from
    research to production, success criteria must encompass algorithmic performance,
    economic viability, and operational sustainability.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 技术自动化之外，还存在着更广泛的系统评估挑战。效率优化需要一种结构化的方法来评估权衡，这种方法超越了纯粹的技术考虑。随着系统从研究过渡到生产，成功标准必须包括算法性能、经济可行性和运营可持续性。
- en: Costs associated with efficiency improvements manifest across engineering effort
    (research, experimentation, integration), balanced against ongoing operational
    expenses of running less efficient systems. Benefits span multiple domains—beyond
    direct cost reductions, efficient systems often enable qualitatively new capabilities
    like real-time processing in resource-constrained environments or deployment to
    edge devices.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 效率改进相关的成本贯穿于工程努力（研究、实验、集成）中，与运行效率较低系统的持续运营费用相平衡。效益跨越多个领域——除了直接成本降低之外，高效的系统通常能够实现定性上的新能力，如资源受限环境中的实时处理或部署到边缘设备。
- en: This evaluation framework must be complemented by ongoing assessment mechanisms.
    The dynamic nature of ML systems in production necessitates continuous monitoring
    of efficiency characteristics. As models evolve, data distributions shift, and
    infrastructure changes, efficiency properties can degrade. Real-time monitoring
    enables rapid detection of efficiency regressions, while historical analysis provides
    insight into longer-term trends, revealing whether efficiency improvements are
    sustainable under changing conditions.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个评估框架必须辅以持续的评估机制。生产中机器学习系统的动态特性需要持续监控效率特性。随着模型的发展、数据分布的变化和基础设施的变更，效率属性可能会退化。实时监控能够快速检测效率退化，而历史分析则提供了对长期趋势的洞察，揭示了在变化条件下效率改进是否可持续。
- en: Engineering Principles for Efficient AI
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高效AI的工程原则
- en: Designing an efficient machine learning system requires a holistic approach.
    True efficiency emerges when the entire system is considered as a whole, ensuring
    trade-offs are balanced across all stages of the ML pipeline from data collection
    to deployment. This end-to-end perspective transforms system design.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个高效的机器学习系统需要一种全面的方法。真正的效率在于将整个系统作为一个整体来考虑，确保在ML管道的所有阶段（从数据收集到部署）的权衡都得到平衡。这种端到端视角改变了系统设计。
- en: Holistic Pipeline Optimization
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全面管道优化
- en: Efficiency is achieved not through isolated optimizations but by considering
    the entire pipeline as a unified whole. Each stage—data collection, model training,
    hardware deployment, and inference—contributes to overall system efficiency. Decisions
    at one stage ripple through the rest, influencing performance, resource use, and
    scalability.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 效率不是通过孤立的优化实现的，而是通过将整个管道视为一个统一的整体来实现的。每个阶段——数据收集、模型训练、硬件部署和推理——都对整体系统效率做出贡献。一个阶段的决策会影响到其他阶段，从而影响性能、资源使用和可扩展性。
- en: Data collection and preprocessing are starting points. [Chapter 6](ch012.xhtml#sec-data-engineering)
    provides comprehensive coverage of how data pipeline design decisions cascade
    through the entire system. Curating smaller, high-quality datasets can reduce
    computational costs during training while simplifying model design. However, insufficient
    data diversity may affect generalization, necessitating compensatory measures.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集和预处理是起点。[第6章](ch012.xhtml#sec-data-engineering)提供了数据管道设计决策如何贯穿整个系统的全面概述。精心策划的小型、高质量数据集可以在训练期间降低计算成本，同时简化模型设计。然而，数据多样性不足可能会影响泛化能力，需要采取补偿措施。
- en: Model training is another critical stage. Architecture choice, optimization
    techniques, and hyperparameters must consider deployment hardware constraints.
    A model designed for high-performance cloud systems may emphasize accuracy and
    scalability, while models for edge devices must balance accuracy with size and
    energy efficiency.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练是另一个关键阶段。架构选择、优化技术和超参数必须考虑部署硬件约束。为高性能云系统设计的模型可能强调准确性和可扩展性，而针对边缘设备的模型则必须在准确性与大小和能源效率之间取得平衡。
- en: Deployment and inference demand precise hardware alignment. Each platform offers
    distinct capabilities—GPUs excel at parallel matrix operations, TPUs optimize
    specific neural network computations, and microcontrollers provide energy-efficient
    processing. A smartphone speech recognition system might leverage an NPU’s dedicated
    convolution units for millisecond-level inference at low power, while an autonomous
    vehicle’s FPGA processes multiple sensor streams with microsecond-level latency.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 部署和推理需要精确的硬件对齐。每个平台都提供独特的功能——GPU擅长并行矩阵运算，TPU优化特定的神经网络计算，而微控制器提供节能处理。一个智能手机语音识别系统可能会利用NPU的专用卷积单元，在低功耗下实现毫秒级的推理，而自动驾驶车辆的FPGA则可以以微秒级的延迟处理多个传感器流。
- en: An end-to-end perspective ensures trade-offs are addressed holistically rather
    than shifting inefficiencies between pipeline stages. This systems thinking approach
    becomes particularly critical when deploying to resource-constrained environments,
    as explored in [Chapter 14](ch020.xhtml#sec-ondevice-learning).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 终端到端的角度确保权衡得到全面解决，而不是在管道阶段之间转移低效率。这种系统思维方法在部署到资源受限的环境中尤为重要，如[第14章](ch020.xhtml#sec-ondevice-learning)中所述。
- en: Lifecycle and Environment Considerations
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生命周期和环境考虑因素
- en: Efficiency needs differ significantly depending on lifecycle stage and deployment
    environment—from research prototypes to production systems, from high-performance
    cloud to resource-constrained edge.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 效率需求因生命周期阶段和部署环境而显著不同——从研究原型到生产系统，从高性能云到资源受限的边缘。
- en: In research, the primary focus is often model performance, with efficiency taking
    a secondary role. Prototypes are trained using abundant compute resources, enabling
    exploration of large architectures and extensive hyperparameter tuning. Production
    systems must prioritize efficiency to operate within practical constraints, often
    involving significant optimization like model pruning, quantization, or retraining.
    Production also requires continuous monitoring of efficiency metrics and operational
    frameworks for managing trade-offs at scale—comprehensive production efficiency
    management strategies are detailed in [Chapter 13](ch019.xhtml#sec-ml-operations).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究中，主要关注的是模型性能，效率则处于次要位置。原型通过丰富的计算资源进行训练，这允许探索大型架构和广泛的超参数调整。生产系统必须优先考虑效率，以在实用约束条件下运行，这通常涉及重大的优化，如模型剪枝、量化或重新训练。生产还需要持续监控效率指标和运营框架，以在规模上管理权衡——综合生产效率管理策略在[第13章](ch019.xhtml#sec-ml-operations)中详细阐述。
- en: Cloud-based systems handle massive workloads with relatively abundant resources,
    though energy efficiency and operational costs remain critical. The ML systems
    design principles covered in [Chapter 2](ch008.xhtml#sec-ml-systems) provide architectural
    foundations for building scalable, efficiency-optimized cloud deployments. In
    contrast, edge and mobile systems operate under strict constraints detailed in
    our efficiency framework, demanding solutions prioritizing efficiency over raw
    performance.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 基于云的系统使用相对丰富的资源处理大量工作负载，尽管能源效率和运营成本仍然至关重要。[第2章](ch008.xhtml#sec-ml-systems)中涵盖的机器学习系统设计原则为构建可扩展、效率优化的云部署提供了架构基础。相比之下，边缘和移动系统在严格的约束下运行，这些约束在我们的效率框架中详细说明，需要优先考虑效率而非原始性能。
- en: Some systems like recommendation engines require frequent retraining to remain
    effective, depending heavily on data efficiency with actively labeled datasets
    and sampling strategies. Other systems like embedded models in medical devices
    require long-term stability with minimal updates. [Chapter 16](ch022.xhtml#sec-robust-ai)
    examines how reliability requirements in critical applications influence efficiency
    optimization strategies.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一些系统，如推荐引擎，需要频繁重新训练以保持有效性，严重依赖数据效率，包括具有积极标记的数据集和采样策略。其他系统，如医疗设备中的嵌入式模型，需要长期稳定性，更新最少。[第16章](ch022.xhtml#sec-robust-ai)探讨了关键应用中的可靠性要求如何影响效率优化策略。
- en: Societal and Ethical Implications
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社会和伦理影响
- en: While efficiency in machine learning is often framed as a technical challenge,
    it is also deeply tied to broader questions about AI systems’ purpose and impact.
    Designing efficient systems involves navigating not only practical trade-offs
    but also complex ethical and philosophical considerations. [Chapter 17](ch023.xhtml#sec-responsible-ai)
    provides a comprehensive framework for addressing these ethical considerations.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然机器学习的效率通常被视为一个技术挑战，但它也与更广泛的关于AI系统目的和影响的问题密切相关。设计高效的系统不仅需要处理实际上的权衡，还需要考虑复杂的伦理和哲学问题。[第17章](ch023.xhtml#sec-responsible-ai)提供了一个全面框架，用于解决这些伦理问题。
- en: Equity and Access
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平等与接入
- en: Efficiency has the potential to reduce costs, improve scalability, and expand
    accessibility. However, resources needed to achieve efficiency—advanced hardware,
    curated datasets, state-of-the-art optimization techniques—are often concentrated
    in well-funded organizations, creating inequities in who can leverage efficiency
    gains.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 效率有可能降低成本、提高可扩展性和扩大可接入性。然而，实现效率所需的资源——先进的硬件、精心挑选的数据集、最先进的优化技术——通常集中在资金充足的组织中，这导致了利用效率收益的不平等。
- en: Training costs for state-of-the-art models like GPT-4 and Gemini Ultra require
    tens to hundreds of millions of dollars worth of compute ([Maslej et al. 2024](ch058.xhtml#ref-perrault2024artificial)).
    Research by [OECD.AI](https://oecd.ai/en/) indicates that 90% of global AI computing
    capacity is centralized in only five countries ([OECD.AI 2021](ch058.xhtml#ref-oecd_ai_2021)).
    Academic institutions often lack hardware needed to replicate state-of-the-art
    results, stifling innovation in underfunded sectors. Energy-efficient compute
    technologies like accelerators for TinyML or Mobile ML present promising avenues
    for democratization. By enabling powerful processing on low-cost, low-power devices,
    these technologies allow organizations without high-end infrastructure access
    to build impactful systems.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 训练像GPT-4和Gemini Ultra这样的最先进模型的成本需要数千万美元的算力（[Maslej等人2024](ch058.xhtml#ref-perrault2024artificial)）。[OECD.AI](https://oecd.ai/en/)的研究表明，全球90%的AI算力集中在仅五个国家（[OECD.AI
    2021](ch058.xhtml#ref-oecd_ai_2021)）。学术机构通常缺乏复制最先进结果所需的硬件，这阻碍了资金不足领域的创新。像TinyML或Mobile
    ML的加速器这样的节能计算技术为民主化提供了有希望的途径。通过在低成本、低功耗设备上实现强大的处理能力，这些技术使得没有高端基础设施的组织也能构建有影响力的系统。
- en: Data efficiency is essential where high-quality datasets are scarce, but achieving
    it is unequally distributed. NLP for low-resource languages suffers from lack
    of sufficient training data, leading to significant performance gaps. Efforts
    like the Masakhane project building open-source datasets for African languages
    show how collaborative initiatives can address this, though scaling globally requires
    greater investment. Democratizing data efficiency requires more open sharing of
    pre-trained models and datasets. Initiatives like Hugging Face’s open access to
    transformers or Meta’s No Language Left Behind aim to make state-of-the-art NLP
    models available worldwide, reducing barriers for data-scarce regions.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在高质量数据集稀缺的地方，数据效率至关重要，但实现它并不均衡。为低资源语言开发的自然语言处理（NLP）因缺乏足够的训练数据而受到严重影响，导致性能差距显著。像Masakhane项目这样的努力，为非洲语言建立开源数据集，展示了协作倡议如何解决这个问题，尽管在全球范围内进行扩展需要更大的投资。民主化数据效率需要更开放地共享预训练模型和数据集。像Hugging
    Face的开放访问transformers或Meta的“没有语言被落下”这样的倡议旨在使最先进的NLP模型在全球范围内可用，降低数据稀缺地区的障碍。
- en: Algorithmic efficiency plays a crucial role in democratizing ML by enabling
    advanced capabilities on low-cost, resource-constrained devices. AI-powered diagnostic
    tools on smartphones are transforming healthcare in remote areas, while low-power
    TinyML models enable environmental monitoring in regions without reliable electricity.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 算法效率在通过使低成本、资源受限的设备具备高级功能来民主化机器学习方面发挥着至关重要的作用。智能手机上的AI诊断工具正在改变偏远地区的医疗保健，而低功耗的TinyML模型使得在没有可靠电力的地区进行环境监测成为可能。
- en: Technologies like [TensorFlow Lite](https://ai.google.dev/edge/litert) and [PyTorch
    Mobile](https://pytorch.org/mobile/home/) allow developers to deploy lightweight
    models on everyday devices, expanding access in resource-constrained settings.
    Open-source efforts to share pre-optimized models like MobileNet or EfficientNet
    play a critical role by allowing under-resourced organizations to deploy state-of-the-art
    solutions.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于[TensorFlow Lite](https://ai.google.dev/edge/litert)和[PyTorch Mobile](https://pytorch.org/mobile/home/)这样的技术允许开发者将轻量级模型部署到日常设备上，在资源受限的环境中扩大了访问权限。共享预先优化的模型（如MobileNet或EfficientNet）的开源努力通过允许资源不足的组织部署最先进解决方案发挥了关键作用。
- en: Balancing Innovation with Efficiency Demands
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平衡创新与效率的需求
- en: 'The pursuit of efficiency often brings tension between optimizing for what
    is known and exploring what is new. Equity concerns are intensified by this tension:
    resource concentration in well-funded organizations enables expensive exploratory
    research, while resource-constrained institutions must focus on incremental improvements.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 追求效率往往在优化已知内容与探索新内容之间产生紧张关系。这种紧张关系加剧了公平性问题：资金充足的组织的资源集中使得他们能够进行昂贵的探索性研究，而资源受限的机构必须专注于渐进式改进，优先考虑效率而非新颖性。
- en: 'Efficiency often favors established techniques proven to work well. Optimizing
    neural networks through pruning, quantization, or distillation typically refines
    existing architectures rather than developing entirely new ones. Consider the
    shift from traditional ML to deep learning: early neural network research in the
    1990s-2000s required significant resources and often failed to outperform simpler
    methods, yet researchers persisted, eventually leading to breakthroughs defining
    modern AI.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 效率通常有利于经过验证的成熟技术。通过剪枝、量化或蒸馏来优化神经网络通常是对现有架构的改进，而不是开发全新的架构。考虑从传统机器学习到深度学习的转变：1990年代到2000年代早期的神经网络研究需要大量资源，并且往往无法超越更简单的方法，但研究人员坚持不懈，最终导致了定义现代人工智能的突破。
- en: Pioneering research often requires significant resources. Large language models
    like GPT-4 or PaLM are not inherently efficient—their training consumes enormous
    compute and energy. Yet these models have opened entirely new possibilities, prompting
    advancements that eventually lead to more efficient systems like smaller fine-tuned
    versions.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 开创性研究往往需要大量资源。像GPT-4或PaLM这样的大型语言模型本身并不高效——它们的训练消耗了巨大的计算和能源。然而，这些模型开辟了全新的可能性，促使进步最终导致更高效的系统，如更小的微调版本。
- en: This reliance on resource-intensive innovation raises questions about who gets
    to participate. Well-funded organizations can afford to explore new frontiers,
    while smaller institutions may be constrained to incremental improvements prioritizing
    efficiency over novelty.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对资源密集型创新的依赖引发了关于谁能够参与的问题。资金充足的机构能够承担探索新领域，而较小的机构可能只能局限于渐进式改进，优先考虑效率而非新颖性。
- en: Efficiency-focused design often requires adhering to strict constraints like
    reducing model size or latency. While constraints can drive ingenuity, they can
    also limit exploration scope. However, the drive for efficiency can positively
    impact innovation—constraints force creative thinking, leading to new methods
    maximizing performance within tight resource budgets. Techniques like NAS and
    attention mechanisms arose partly from the need to balance performance and efficiency.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 以效率为导向的设计通常需要遵守严格的约束，如减少模型大小或延迟。虽然约束可以激发创新，但它们也可能限制探索范围。然而，对效率的追求可以积极影响创新——约束迫使创造性思考，导致在紧张的资源配置预算内最大化性能的新方法。例如，NAS（神经架构搜索）和注意力机制的出现部分源于平衡性能和效率的需求。
- en: Organizations and researchers must recognize when to prioritize efficiency and
    when to embrace experimentation risks. Applied systems for real-world deployment
    may demand strict efficiency, while exploratory research labs can focus on pushing
    boundaries. The relationship between innovation and efficiency is not adversarial
    but complementary—efficient systems create foundations for scalable applications,
    while resource-intensive experimentation drives breakthroughs redefining what’s
    possible.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 组织和研究人员必须认识到何时应优先考虑效率，何时应接受实验风险。适用于现实世界部署的应用系统可能需要严格的效率，而探索性研究实验室可以专注于推动边界。创新与效率之间的关系不是对抗性的，而是互补性的——高效的系统为可扩展的应用程序奠定基础，而资源密集型的实验推动突破，重新定义了可能性的界限。
- en: Optimization Limits
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化限制
- en: 'The tensions between equity, innovation, and efficiency ultimately stem from
    a fundamental characteristic of optimization: diminishing returns. Optimization
    is central to building efficient ML systems, but it is not infinite. As systems
    become more refined, each additional improvement requires exponentially more effort,
    time, or resources while delivering increasingly smaller benefits.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 公平、创新和效率之间的紧张关系最终源于优化的一个基本特征：收益递减。优化对于构建高效的机器学习系统至关重要，但它并非无限。随着系统变得更加精细，每次额外的改进都需要指数级更多的努力、时间或资源，同时带来的好处越来越小。
- en: The No Free Lunch (NFL) theorems[36](#fn36) for optimization illustrate inherent
    limitations. According to NFL theorems, no single optimization algorithm can outperform
    all others across every possible problem, implying optimization technique effectiveness
    is highly problem-specific ([Wolpert and Macready 1997](ch058.xhtml#ref-wolpert1997no)).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 优化（No Free Lunch，NFL）定理[36](#fn36)说明了固有的局限性。根据NFL定理，没有单个优化算法可以在所有可能的问题上优于所有其他算法，这意味着优化技术的高效性高度依赖于特定问题（[Wolpert
    和 Macready 1997](ch058.xhtml#ref-wolpert1997no)）。
- en: For example, compressing an ML model can initially reduce memory and compute
    requirements significantly with minimal accuracy loss. However, as compression
    progresses, maintaining performance becomes increasingly challenging. Achieving
    additional gains may necessitate sophisticated techniques like hardware-specific
    optimizations or extensive retraining, increasing complexity and cost. These costs
    extend beyond financial investment to include time, expertise, iterative testing,
    and potential trade-offs in robustness and generalizability.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，压缩机器学习模型可以最初显著减少内存和计算需求，同时最小化精度损失。然而，随着压缩的进行，保持性能变得越来越具有挑战性。实现额外的收益可能需要诸如针对特定硬件的优化或广泛的重新训练等复杂技术，增加复杂性和成本。这些成本不仅包括财务投资，还包括时间、专业知识、迭代测试，以及在鲁棒性和泛化性之间可能存在的权衡。
- en: The NFL theorems highlight that no universal optimization solution exists, emphasizing
    need to balance efficiency pursuits with practical considerations. Over-optimization
    risks wasted resources and reduced adaptability, complicating future updates.
    Identifying when a system is “good enough” ensures resources are allocated effectively.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: NFL（No Free Lunch）定理强调了不存在通用的优化解决方案，强调了在追求效率的同时需要考虑实际因素。过度优化可能导致资源浪费和适应性降低，复杂化未来的更新。确定系统何时“足够好”可以确保资源得到有效分配。
- en: Similarly, optimizing datasets for training efficiency may initially save resources,
    but excessively reducing dataset size risks compromising diversity and weakening
    generalization. Pushing hardware to performance limits may improve metrics like
    latency, yet associated reliability concerns and engineering costs can outweigh
    gains.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，为了提高训练效率而优化数据集可能最初会节省资源，但过度减少数据集大小可能会损害多样性和削弱泛化能力。将硬件性能推至极限可能会提高诸如延迟等指标，但相关的可靠性和工程成本可能会超过收益。
- en: Understanding optimization limits is essential for creating systems balancing
    efficiency with practicality and sustainability. This perspective helps avoid
    over-optimization and ensures resources are invested in areas with meaningful
    returns.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 理解优化极限对于创建平衡效率、实用性和可持续性的系统至关重要。这种观点有助于避免过度优化，并确保资源投资于具有实质性回报的领域。
- en: Moore’s Law Case Study
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 摩尔定律案例研究
- en: One of the most insightful examples of optimization limits appears in Moore’s
    Law and the economic curve underlying it. While Moore’s Law is celebrated as a
    predictor of exponential computational power growth, its success relied on intricate
    economic balance. The relationship between integration and cost provides a compelling
    analogy for diminishing returns in ML optimization.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 优化极限的最有洞察力的例子之一出现在摩尔定律及其背后的经济曲线上。虽然摩尔定律因其作为指数计算能力增长预测者的角色而受到赞誉，但其成功依赖于复杂的经济平衡。集成度与成本之间的关系为机器学习优化中的收益递减提供了一个引人入胜的类比。
- en: '[Figure 9.15](ch015.xhtml#fig-moores-law-plot) shows relative manufacturing
    cost per component as the number of components in an integrated circuit increases.
    Initially, as more components are packed onto a chip, cost per component decreases
    due to economies of scale—higher integration reduces need for packaging and interconnects.
    Moving from hundreds to thousands of components drastically reduced costs and
    improved performance ([G. Moore 2021](ch058.xhtml#ref-moore2021cramming)).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.15](ch015.xhtml#fig-moores-law-plot) 展示了随着集成电路中组件数量的增加，每个组件的相对制造成本。最初，随着越来越多的组件被集成到芯片上，每个组件的成本会因规模经济而降低——更高的集成度减少了封装和互连的需求。从数百个组件增加到数千个组件，成本大幅降低，性能得到提升
    ([G. Moore 2021](ch058.xhtml#ref-moore2021cramming))。'
- en: '![](../media/file145.svg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file145.svg)'
- en: 'Figure 9.15: : **Moore’s Law Economics**: Declining per-component manufacturing
    costs initially drove exponential growth in integrated circuit complexity, but
    diminishing returns eventually limited further cost reductions. This relationship
    mirrors optimization challenges in machine learning, where increasing model complexity
    yields diminishing gains in performance relative to computational expense. Source:
    ([G. Moore 2021](ch058.xhtml#ref-moore2021cramming)).'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '图9.15: **摩尔定律的经济效应**：最初，每个组件的制造成本下降推动了集成电路复杂性的指数级增长，但最终收益递减限制了成本的进一步降低。这种关系反映了机器学习中优化挑战的优化问题，其中模型复杂性的增加相对于计算成本而言，性能提升逐渐减少。来源：([G.
    Moore 2021](ch058.xhtml#ref-moore2021cramming))。'
- en: 'However, as integration continues, the curve begins to rise. Components packed
    closer together face reliability issues like increased heat dissipation and signal
    interference. Addressing these requires more sophisticated manufacturing techniques—advanced
    lithography, error correction, improved materials—increasing complexity and cost.
    This U-shaped curve captures the fundamental trade-off: early improvements yield
    substantial benefits, but beyond a certain point, each additional gain comes at
    greater cost.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着集成度的继续提高，曲线开始上升。更紧密地封装在一起的组件面临可靠性问题，如散热增加和信号干扰。解决这些问题需要更复杂的制造技术——先进的光刻、纠错、改进的材料——增加了复杂性和成本。这个U形曲线捕捉了基本权衡：早期的改进带来了实质性的好处，但超过某个点，每个额外的收益都伴随着更高的成本。
- en: The dynamics mirror ML optimization challenges. Compressing a deep learning
    model to reduce size and energy consumption follows a similar trajectory. Initial
    optimizations like pruning redundant parameters or reducing precision often lead
    to significant savings with minimal accuracy impact. However, as compression progresses,
    performance losses become harder to recover. Techniques like quantization or hardware-specific
    tuning can restore some performance, but these add complexity and cost.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这些动态反映了机器学习优化挑战。压缩深度学习模型以减小尺寸和能耗遵循类似的轨迹。初始优化，如剪枝冗余参数或降低精度，通常会导致显著的节省，同时对准确性的影响最小。然而，随着压缩的进行，性能损失变得更加难以恢复。量化或针对特定硬件的调整等技术可以恢复一些性能，但这些增加了复杂性和成本。
- en: Similarly, in data efficiency, reducing training dataset size often improves
    computational efficiency initially. Yet as datasets shrink further, they may lose
    diversity, compromising generalization. Addressing this often involves synthetic
    data or sophisticated augmentation, demanding additional engineering effort.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在数据效率方面，减少训练数据集的大小最初往往可以提高计算效率。然而，随着数据集进一步缩小，它们可能会失去多样性，损害泛化能力。解决这个问题通常需要合成数据或复杂的增强，这需要额外的工程努力。
- en: The Moore’s Law plot serves as a visual reminder that optimization is not infinite.
    The cost-benefit balance is always context-dependent, and the point of diminishing
    returns varies based on system goals and constraints. ML practitioners, like semiconductor
    engineers, must identify when further optimization ceases to provide meaningful
    benefits. Over-optimization can lead to wasted resources, reduced adaptability,
    and systems overly specialized to initial conditions.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 摩尔定律的图表作为一个视觉提醒，表明优化并非无限。成本效益平衡总是依赖于具体情境，而收益递减的点会根据系统目标和限制而变化。机器学习从业者，如半导体工程师，必须确定何时进一步的优化不再提供有意义的效益。过度优化可能导致资源浪费、适应性降低，以及系统过度专门化于初始条件。
- en: Fallacies and Pitfalls
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谬误与陷阱
- en: Efficiency in AI systems involves complex trade-offs between multiple competing
    objectives that often pull in different directions. The mathematical elegance
    of scaling laws can create false confidence about predictable optimization paths,
    while diverse deployment context requirements create misconceptions about universal
    efficiency strategies.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能系统中，效率涉及在多个竞争目标之间进行复杂的权衡，这些目标往往朝不同的方向拉扯。扩展定律的数学优雅可能会产生关于可预测优化路径的虚假信心，而多样化的部署环境要求会产生关于通用效率策略的误解。
- en: '**Fallacy:** *Efficiency optimizations always improve system performance across
    all metrics.*'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '**谬误：** *效率优化总是能提升系统性能的所有指标。*'
- en: This misconception leads teams to apply efficiency techniques without understanding
    trade-offs and side effects. Optimizing for computational efficiency might degrade
    accuracy, improving memory efficiency could increase latency, and reducing model
    size often requires more complex training procedures. Efficiency gains in one
    dimension frequently create costs in others that may be unacceptable for specific
    scenarios. Effective efficiency optimization requires careful analysis of which
    metrics matter most and acceptance that some performance aspects will necessarily
    be sacrificed.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这种误解导致团队在未理解权衡和副作用的情况下应用效率技术。为了计算效率而优化可能会降低准确性，提高内存效率可能会增加延迟，而减小模型大小通常需要更复杂的训练过程。在一个维度上的效率提升往往在其他维度上产生成本，这些成本在特定场景中可能是不可以接受的。有效的效率优化需要仔细分析哪些指标最重要，并接受某些性能方面必然会被牺牲。
- en: '**Pitfall:** *Assuming scaling laws predict efficiency requirements linearly
    across all model sizes.*'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '**陷阱：** *假设扩展定律可以线性预测所有模型大小的效率要求。*'
- en: Teams often extrapolate efficiency requirements based on scaling law relationships
    without considering breakdown points where these laws no longer apply. Scaling
    laws provide useful guidance for moderate increases, but fail to account for emergent
    behaviors, architectural constraints, and infrastructure limitations appearing
    at extreme scales. Applying scaling law predictions beyond validated ranges can
    lead to wildly inaccurate resource estimates and deployment failures. Successful
    efficiency planning requires understanding both utility and limits of scaling
    law frameworks.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 团队常常基于扩展定律关系外推效率要求，而没有考虑这些定律不再适用的断裂点。扩展定律对于适度的增加是有用的指导，但未能考虑到在极端规模出现的涌现行为、架构限制和基础设施限制。将扩展定律预测应用于验证范围之外可能导致资源估计严重不准确和部署失败。成功的效率规划需要理解扩展定律框架的效用和限制。
- en: '**Fallacy:** *Edge deployment efficiency requirements are simply scaled-down
    versions of cloud requirements.*'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '**谬误：** *边缘部署的效率要求仅仅是云要求的缩小版。*'
- en: This belief assumes edge deployment is merely cloud deployment with smaller
    models and less computation. Edge environments introduce qualitatively different
    constraints including real-time processing requirements, power consumption limits,
    thermal management needs, and connectivity variability. Optimization strategies
    working in cloud environments often fail catastrophically in edge contexts. Edge
    efficiency requires different approaches prioritizing predictable performance,
    energy efficiency, and robust operation under varying conditions.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这种信念假设边缘部署仅仅是云部署，只是模型更小，计算更少。边缘环境引入了质的不同限制，包括实时处理需求、功耗限制、热管理需求以及连接性变化。在云环境中有效的优化策略在边缘环境中往往失败得非常惨重。边缘效率需要不同的方法，优先考虑可预测的性能、能源效率和在不同条件下的稳健运行。
- en: '**Pitfall:** *Focusing on algorithmic efficiency while ignoring system-level
    efficiency factors.*'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '**陷阱：** *专注于算法效率，而忽略系统级效率因素。*'
- en: Many practitioners optimize algorithmic complexity metrics like FLOPs or parameter
    counts without considering how improvements translate to actual system performance.
    Real system efficiency depends on memory access patterns, data movement costs,
    hardware utilization characteristics, and software stack overhead that may not
    correlate with theoretical complexity metrics. A model with fewer parameters might
    still perform worse due to irregular memory access patterns or poor hardware mapping.
    Comprehensive efficiency optimization requires measuring and optimizing actual
    system performance rather than relying solely on algorithmic complexity indicators.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 许多从业者优化算法复杂度指标，如FLOPs或参数计数，而没有考虑这些改进如何转化为实际系统性能。实际系统效率取决于内存访问模式、数据移动成本、硬件利用特性以及可能与理论复杂度指标不相关的软件堆栈开销。具有较少参数的模型可能由于不规则的内存访问模式或较差的硬件映射而表现得更差。全面的效率优化需要衡量和优化实际系统性能，而不仅仅依赖于算法复杂度指标。
- en: Summary
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Efficiency has emerged as a design principle that transforms how we approach
    machine learning systems, moving beyond simple performance optimization toward
    comprehensive resource stewardship. This chapter revealed how scaling laws provide
    empirical insights into relationships between model performance and computational
    resources, establishing efficiency as a strategic advantage enabling broader accessibility,
    sustainability, and innovation. The interdependencies between algorithmic, compute,
    and data efficiency create a complex landscape where decisions in one dimension
    cascade throughout the entire system, requiring a holistic perspective balancing
    trade-offs across the complete ML pipeline.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 效率已成为一种设计原则，它改变了我们对待机器学习系统的方式，超越了简单的性能优化，转向全面资源管理。本章揭示了规模定律如何提供实证见解，深入到模型性能与计算资源之间的关系，将效率确立为战略优势，使更广泛的可访问性、可持续性和创新成为可能。算法、计算和数据效率之间的相互依赖性创造了一个复杂的景观，其中某一维度的决策会影响到整个系统，需要从整体视角平衡整个机器学习管道中的权衡。
- en: The practical challenges of designing efficient systems highlight the importance
    of context-aware decision making, where deployment environments shape efficiency
    priorities. Cloud systems leverage abundant resources for scalability and throughput,
    while edge deployments optimize for real-time performance within strict power
    constraints, and TinyML applications push the boundaries of what’s achievable
    with minimal resources. These diverse requirements demand sophisticated strategies
    including end-to-end co-design, automated optimization tools, and careful prioritization
    based on operational constraints. The emergence of scaling law breakdowns and
    tension between innovation and efficiency underscore that optimal system design
    requires addressing not just technical trade-offs but broader considerations of
    equity, sustainability, and long-term impact.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 设计高效系统的实际挑战突出了情境感知决策的重要性，其中部署环境塑造了效率优先级。云系统利用丰富的资源实现可扩展性和吞吐量，而边缘部署在严格的电源限制内优化实时性能，而TinyML应用将最小资源下可实现的边界推向极限。这些不同的需求要求复杂的策略，包括端到端协同设计、自动化优化工具以及基于操作约束的谨慎优先级排序。规模定律崩溃和创新与效率之间的紧张关系强调了最佳系统设计不仅需要解决技术权衡，还需要考虑更广泛的公平性、可持续性和长期影响。
- en: '**Key Takeaways**'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键要点**'
- en: Efficiency is a strategic enabler that democratizes access to AI capabilities
    across diverse deployment contexts
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效率是一种战略推动者，它使不同部署环境下的AI能力普及化
- en: Scaling laws provide predictive frameworks for resource allocation, but their
    limits reveal opportunities for architectural innovation
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规模定律为资源分配提供了预测框架，但它们的局限性揭示了架构创新的机遇
- en: Trade-offs between algorithmic, compute, and data efficiency are interconnected
    and context-dependent, requiring holistic optimization strategies
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法、计算和数据效率之间的权衡相互关联且取决于具体情境，需要整体优化策略
- en: Automation tools and end-to-end co-design approaches can transform efficiency
    constraints into opportunities for system synergy
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化工具和端到端协同设计方法可以将效率限制转化为系统协同的机会
- en: Having established the three-pillar efficiency framework and explored scaling
    laws as the quantitative foundation for resource allocation, the following chapters
    provide the specific engineering techniques to achieve efficiency in each dimension.
    [Chapter 10](ch016.xhtml#sec-model-optimizations) focuses on algorithmic efficiency
    through systematic approaches to reducing model complexity while preserving performance.
    The chapter covers quantization techniques that reduce numerical precision, pruning
    methods that eliminate redundant parameters, and knowledge distillation approaches
    that transfer capabilities from large models to smaller ones.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立了三支柱效率框架并探讨了作为资源分配定量基础的比例定律之后，接下来的章节提供了在每个维度上实现效率的具体工程技术。[第10章](ch016.xhtml#sec-model-optimizations)通过系统地降低模型复杂性的同时保持性能来关注算法效率。该章节涵盖了降低数值精度的量化技术、消除冗余参数的剪枝方法以及将能力从大型模型转移到较小模型的知识蒸馏方法。
- en: '[Chapter 11](ch017.xhtml#sec-ai-acceleration) addresses compute efficiency
    by exploring how specialized hardware and optimized software implementations maximize
    performance per unit of computational resource. Topics include GPU optimization,
    AI accelerator architectures, and system-level optimizations that improve throughput
    and reduce latency. [Chapter 12](ch018.xhtml#sec-benchmarking-ai) provides the
    measurement methodologies essential for quantifying efficiency gains across all
    three dimensions, covering performance evaluation frameworks, energy measurement
    techniques, and comparative analysis methods.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](ch017.xhtml#sec-ai-acceleration)通过探讨专用硬件和优化软件实现如何最大化每单位计算资源的性能来处理计算效率问题。主题包括GPU优化、AI加速器架构以及提高吞吐量和降低延迟的系统级优化。[第12章](ch018.xhtml#sec-benchmarking-ai)提供了量化所有三个维度效率提升的测量方法，涵盖了性能评估框架、能量测量技术和比较分析方法。'
- en: This progression from principles to specific techniques to measurement methodologies
    reflects the systematic engineering approach necessary for achieving real-world
    efficiency in machine learning systems. Each subsequent chapter builds upon the
    foundational understanding established here, creating a comprehensive toolkit
    for performance engineering that addresses the complex, interconnected trade-offs
    that define efficient AI system design.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 从原则到具体技术再到测量方法的发展过程反映了实现机器学习系统中实际效率所需的系统化工程方法。每一章都建立在在此建立的基础理解之上，创建了一个全面的性能工程工具包，该工具包解决了定义高效AI系统设计的复杂、相互关联的权衡。
- en: These efficiency principles establish the foundation for the specific optimization
    techniques explored in [Chapter 10](ch016.xhtml#sec-model-optimizations), where
    detailed algorithms for quantization, pruning, and knowledge distillation provide
    concrete tools for achieving the efficiency goals outlined here. As machine learning
    systems continue scaling in complexity and reach, the principles of efficient
    design will remain essential for creating systems that are not only performant
    but also sustainable, accessible, and aligned with broader societal goals of responsible
    AI development.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这些效率原则为在[第10章](ch016.xhtml#sec-model-optimizations)中探讨的具体优化技术奠定了基础，该章节详细介绍了量化、剪枝和知识蒸馏的算法，为实现此处概述的效率目标提供了具体工具。随着机器学习系统在复杂性和范围上的持续扩展，高效设计的原则对于创建不仅性能出色而且可持续、可访问且与更广泛的社会目标——负责任的AI发展目标相一致的系统仍然至关重要。
- en: '* * *'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
