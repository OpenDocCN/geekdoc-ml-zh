- en: Concept
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念
- en: 原文：[https://dafriedman97.github.io/mlbook/content/c5/concept.html](https://dafriedman97.github.io/mlbook/content/c5/concept.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://dafriedman97.github.io/mlbook/content/c5/concept.html](https://dafriedman97.github.io/mlbook/content/c5/concept.html)
- en: A decision tree is an interpretable machine learning method for regression and
    classification. Trees iteratively split samples of the training data based on
    the value of a chosen predictor; the goal of each split is to create two sub-samples,
    or “children,” with greater *purity* of the target variable than their “parent”.
    For classification tasks, purity means the first child should have observations
    primarily of one class and the second should have observations primarily of another.
    For regression tasks, purity means the first child should have observations with
    high values of the target variable and the second should have observations with
    low values.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种可解释的机器学习方法，用于回归和分类。树通过根据所选预测器的值迭代地分割训练数据样本；每个分割的目标是创建两个子样本，或称为“子节点”，它们的目标变量比它们的“父节点”具有更高的*纯度*。对于分类任务，纯度意味着第一个子节点应该主要包含一个类的观测值，而第二个子节点应该主要包含另一个类的观测值。对于回归任务，纯度意味着第一个子节点应该包含目标变量高值的观测值，而第二个子节点应该包含目标变量低值的观测值。
- en: An example of a classification decision tree using the [penguins dataset](../appendix/data.html)
    is given below. The tree attempts to classify a penguin’s species—*Adelie*, *Gentoo*,
    or *Chinstrap*—from information about its flippers and bill. The first “node”
    shows that there are 333 training observations, 146 *Adelie*, 68 *Gentoo*, and
    119 *Chinstrap*. We first split based on whether the penguin’s flipper length
    is less than or equal to 206.5 mm. If so, the penguin moves to the node on the
    left and if not, it moves to the node on the right. We then repeat this process
    for each of the child nodes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 下面给出了一个使用[penguins数据集](../appendix/data.html)的分类决策树的例子。该树试图根据企鹅的鳍和喙的信息来分类企鹅的物种—*Adelie*、*Gentoo*或*Chinstrap*。第一个“节点”显示有333个训练观测值，其中146个*Adelie*、68个*Gentoo*和119个*Chinstrap*。我们首先根据企鹅的鳍长度是否小于或等于206.5毫米进行分割。如果是，企鹅移动到左边的节点，如果不是，则移动到右边的节点。然后我们为每个子节点重复此过程。
- en: '![tree](../Images/334a884bbe21b663a8e107a6b34d5bd8.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![树](../Images/334a884bbe21b663a8e107a6b34d5bd8.png)'
- en: Once we’ve reached the bottom of the tree, we make our predictions. For instance,
    if a test observation has a `flipper_length` of 210 and a `bill_depth` of 12,
    we would follow the tree and classify it as a *Gentoo*. This simple decision process
    makes trees very interpretable. However, they may suffer in terms of precision
    (accuracy of predictions) and robustness (sensitivity to variable training data).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们到达树的底部，我们就做出预测。例如，如果一个测试观测值的`flipper_length`为210，`bill_depth`为12，我们会遵循树的结构并将其分类为*Gentoo*。这个简单的决策过程使得树非常易于解释。然而，它们可能在精确度（预测的准确性）和鲁棒性（对变量训练数据的敏感性）方面有所欠缺。
- en: This chapter demonstrates how decision trees are built. The [first](s1/regression_tree.html)
    section covers regression tasks, where the target variable is quantitative, and
    the [second](s1/classification_tree.html) covers classification tasks, where the
    target variable is categorical.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节演示了如何构建决策树。第一部分[链接](s1/regression_tree.html)涵盖了回归任务，其中目标变量是定量型的，而第二部分[链接](s1/classification_tree.html)涵盖了分类任务，其中目标变量是分类型的。
