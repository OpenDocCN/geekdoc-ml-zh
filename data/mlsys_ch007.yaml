- en: Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: '*DALL·E 3 Prompt: A detailed, rectangular, flat 2D illustration depicting a
    roadmap of a book’s chapters on machine learning systems, set on a crisp, clean
    white background. The image features a winding road traveling through various
    symbolic landmarks. Each landmark represents a chapter topic: Introduction, ML
    Systems, Deep Learning, AI Workflow, Data Engineering, AI Frameworks, AI Training,
    Efficient AI, Model Optimizations, AI Acceleration, Benchmarking AI, On-Device
    Learning, Embedded AIOps, Security & Privacy, Responsible AI, Sustainable AI,
    AI for Good, Robust AI, Generative AI. The style is clean, modern, and flat, suitable
    for a technical book, with each landmark clearly labeled with its chapter title.*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*DALL·E 3 提示：一个详细的、矩形的、平面的2D插图，展示了一本关于机器学习系统章节的路线图，背景为清晰、干净的白色。图像中有一条蜿蜒的道路穿过各种象征性的地标。每个地标代表一个章节主题：引言、机器学习系统、深度学习、AI
    工作流程、数据工程、AI 框架、AI 训练、高效AI、模型优化、AI 加速、AI 基准测试、设备上学习、嵌入式 AIOps、安全与隐私、负责任AI、可持续AI、AI
    做善事、鲁棒AI、生成AI。风格简洁、现代、扁平，适合技术书籍，每个地标都清楚地标有其章节标题。*'
- en: '![](../media/file12.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file12.png)'
- en: Purpose
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目的
- en: '*Why must we master the engineering principles that govern systems capable
    of learning, adapting, and operating at massive scale?*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么我们必须掌握治理能够学习、适应和在大规模上运行的系统的工程原则？*'
- en: Machine learning represents the most significant transformation in computing
    since programmable computers, enabling systems whose behavior emerges from data
    rather than explicit instructions. This transformation requires new engineering
    foundations because traditional software engineering principles cannot address
    systems that learn and adapt based on experience. Every major technological challenge,
    from climate modeling and medical diagnosis to autonomous transportation, requires
    systems that process vast amounts of data and operate reliably despite uncertainty.
    Understanding ML systems engineering determines our ability to solve complex problems
    that exceed human cognitive capacity. This discipline provides the foundation
    for building systems that can scale across deployment environments, from massive
    data centers to resource-constrained edge devices, establishing the technical
    groundwork for technological progress in the 21st century.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习代表了自可编程计算机以来计算领域最重大的变革，它使得系统的行为从数据中产生，而不是从明确的指令中产生。这种变革需要新的工程基础，因为传统的软件工程原则无法解决基于经验学习和适应的系统。从气候建模和医疗诊断到自主交通，每一个主要的技术挑战都需要能够处理大量数据并在不确定性下可靠运行的系统。理解机器学习系统工程决定了我们解决超出人类认知能力复杂问题的能力。这一学科为构建能够在部署环境中扩展的系统提供了基础，从大型数据中心到资源受限的边缘设备，为21世纪的技术进步奠定了技术基础。
- en: '**Learning Objectives**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习目标**'
- en: Define machine learning systems as integrated computing systems comprising data,
    algorithms, and infrastructure
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将机器学习系统定义为包含数据、算法和基础设施的集成计算系统
- en: Distinguish ML systems engineering from traditional software engineering through
    failure pattern analysis
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过故障模式分析区分机器学习系统工程与传统软件工程
- en: Analyze interdependencies between data, algorithms, and computing infrastructure
    using the AI Triangle framework
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AI 三角形框架分析数据、算法和计算基础设施之间的相互依赖关系
- en: Trace the historical evolution of AI paradigms from symbolic systems through
    statistical learning to deep learning
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪从符号系统到统计学习再到深度学习的AI范式的历史演变
- en: Evaluate the implications of Sutton’s “Bitter Lesson” for modern ML systems
    engineering priorities
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估Sutton的“苦涩教训”对现代机器学习系统工程优先级的含义
- en: Compare silent performance degradation in ML systems with traditional software
    failure modes
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将机器学习系统中的静默性能下降与传统软件故障模式进行比较
- en: Contrast ML system lifecycle phases with traditional software development
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对比机器学习系统生命周期阶段与传统软件开发
- en: Classify real-world challenges in ML systems across data, model, system, and
    ethical categories
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将机器学习系统中的现实挑战按数据、模型、系统和伦理类别进行分类
- en: Apply the five-pillar framework to evaluate ML system architectures
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用五支柱框架评估机器学习系统架构
- en: The Engineering Revolution in Artificial Intelligence
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能的工程革命
- en: Engineering practice today stands at an inflection point comparable to the most
    transformative periods in technological history. The Industrial Revolution established
    mechanical engineering as a discipline for managing physical forces, while the
    Digital Revolution formalized computational engineering to handle algorithmic
    complexity. Today, artificial intelligence systems require a new engineering paradigm
    for systems that exhibit learned behaviors, autonomous adaptation, and operational
    scales that exceed conventional software engineering methodologies.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的工程实践正处于一个转折点，其重要性可与科技史上最具变革性的时期相媲美。工业革命确立了机械工程作为一门管理物理力的学科，而数字革命则正式化了计算工程，以处理算法复杂性。如今，人工智能系统需要一种新的工程范式来应对表现出学习行为、自主适应和操作规模超越传统软件工程方法的新系统。
- en: 'This shift reconceptualizes the nature of engineered systems. Traditional deterministic
    software architectures operate according to explicitly programmed instructions,
    yielding predictable outputs for given inputs. In contrast, machine learning systems
    are probabilistic architectures whose behaviors emerge from statistical patterns
    extracted from training data. This transformation introduces engineering challenges
    that define the discipline of machine learning systems engineering: ensuring reliability
    in systems whose behaviors are learned rather than programmed, achieving scalability
    for systems processing petabyte-scale[1](#fn1) datasets while serving billions
    of concurrent users, and maintaining robustness when operational data distributions
    diverge from training distributions.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变重新定义了工程系统的本质。传统的确定性软件架构根据显式编程的指令运行，对给定的输入产生可预测的输出。相比之下，机器学习系统是概率性架构，其行为源于从训练数据中提取的统计模式。这种转变引入了工程挑战，这些挑战定义了机器学习系统工程的学科：确保在行为是通过学习而非编程的系统中的可靠性，实现处理PB级[1](#fn1)数据集并服务于数十亿并发用户时的可扩展性，以及在操作数据分布与训练数据分布不一致时保持鲁棒性。
- en: These challenges establish the theoretical and practical foundations of ML systems
    engineering as a distinct academic discipline. This chapter provides the conceptual
    foundation for understanding both the historical evolution that created this field
    and the engineering principles that differentiate machine learning systems from
    traditional software architectures. The analysis synthesizes perspectives from
    computer science, systems engineering, and statistical learning theory to establish
    a framework for the systematic study of intelligent systems.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战为机器学习系统工程作为一门独立的学术学科的理论和实践基础奠定了基础。本章提供了理解这一领域的创建历史和区分机器学习系统与传统软件架构的工程原则的概念基础。分析综合了来自计算机科学、系统工程和统计学习理论的观点，为智能系统的系统研究建立了一个框架。
- en: 'Our investigation begins with the relationship between artificial intelligence
    as a research objective and machine learning as the computational methodology
    for achieving intelligent behavior. We then establish what constitutes a machine
    learning system, the integrated computing systems comprising data, algorithms,
    and infrastructure that this discipline builds. Through historical analysis, we
    trace the evolution of AI paradigms from symbolic reasoning systems through statistical
    learning approaches to contemporary deep learning architectures, demonstrating
    how each transition required new engineering solutions. This progression illuminates
    Sutton’s “bitter lesson” of AI research: that domain-general computational methods
    ultimately supersede hand-crafted knowledge representations, positioning systems
    engineering as central to AI advancement.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的调查从人工智能作为研究目标与机器学习作为实现智能行为的计算方法之间的关系开始。然后我们确定了构成机器学习系统的要素，即该学科构建的包含数据、算法和基础设施的集成计算系统。通过历史分析，我们追溯了人工智能范式的演变，从符号推理系统到统计学习方法，再到当代深度学习架构，展示了每个过渡都要求新的工程解决方案。这一进展照亮了Sutton的“苦涩教训”：领域通用的计算方法最终会超越手工构建的知识表示，将系统工程定位为人工智能进步的核心。
- en: This historical and technical foundation enables us to formally define this
    discipline. Following the pattern established by Computer Engineering’s emergence
    from Electrical Engineering and Computer Science, we establish it as a field focused
    on building reliable, efficient, and scalable machine learning systems across
    computational platforms. This formal definition addresses both the nomenclature
    used in practice and the technical scope of what practitioners actually build.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个历史和技术基础使我们能够正式定义这一学科。遵循计算机工程从电气工程和计算机科学中诞生的模式，我们将它确立为一个专注于在计算平台构建可靠、高效和可扩展机器学习系统的领域。这个正式定义既涵盖了实践中使用的术语，也涵盖了从业者实际构建的技术范围。
- en: Building upon this foundation, we introduce the theoretical frameworks that
    structure the analysis of ML systems throughout this text. The AI Triangle provides
    a conceptual model for understanding the interdependencies among data, algorithms,
    and computational infrastructure. We examine the machine learning system lifecycle,
    contrasting it with traditional software development methodologies to highlight
    the unique phases of problem formulation, data curation, model development, validation,
    deployment, and continuous maintenance that characterize ML system engineering.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基础上，我们引入了结构化本文本中机器学习系统分析的理论框架。AI 三角提供了一个理解数据、算法和计算基础设施之间相互依赖关系的概念模型。我们考察机器学习系统生命周期，将其与传统软件开发方法进行对比，以突出问题制定、数据整理、模型开发、验证、部署和持续维护等独特阶段，这些阶段是机器学习系统工程的特征。
- en: These theoretical frameworks are substantiated through examination of representative
    deployment scenarios that demonstrate the diversity of engineering requirements
    across application domains. From autonomous vehicles operating under stringent
    latency constraints at the network edge to recommendation systems serving billions
    of users through cloud infrastructure, these case studies illustrate how deployment
    context shapes system architecture and engineering trade-offs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些理论框架通过考察代表性的部署场景得到证实，这些场景展示了应用领域内工程需求的多样性。从在网络边缘运行且具有严格延迟约束的自动驾驶汽车到通过云基础设施为数十亿用户提供服务的推荐系统，这些案例研究说明了部署环境如何塑造系统架构和工程权衡。
- en: 'The analysis culminates by identifying the core challenges that establish ML
    systems engineering as both a necessary and complex discipline: silent performance
    degradation patterns that require specialized monitoring approaches, data quality
    issues and distribution shifts that compromise model validity, requirements for
    model robustness and interpretability in high-stakes applications, infrastructure
    scalability demands that exceed conventional distributed systems, and ethical
    considerations that impose new categories of system requirements. These challenges
    provide the foundation for the five-pillar organizational framework that structures
    this text, partitioning ML systems engineering into interconnected sub-disciplines
    that enable the development of robust, scalable, and responsible artificial intelligence
    systems.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分析通过确定建立机器学习系统工程为必要且复杂学科的核心理念而结束：需要专门监控方法的静默性能退化模式，数据质量问题和分布变化损害了模型的有效性，对模型在高风险应用中的鲁棒性和可解释性的要求，超出传统分布式系统的基础设施可扩展性需求，以及强加新的系统要求类别的伦理考量。这些挑战为构建文本的五支柱组织框架提供了基础，将机器学习系统工程划分为相互关联的子学科，以促进稳健、可扩展和负责任的人工智能系统的发展。
- en: 'This chapter establishes the theoretical foundation for Part I: Systems Foundations,
    introducing the principles that underlie all subsequent analysis of ML systems
    engineering. The conceptual frameworks introduced here provide the analytical
    tools that will be refined and applied throughout subsequent chapters, culminating
    in a methodology for engineering systems capable of reliably delivering artificial
    intelligence capabilities in production environments.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为第一部分：系统基础，建立了理论基础，介绍了所有后续对机器学习系统工程分析的基础原则。这里引入的概念框架提供了将在后续章节中完善和应用的分析工具，最终形成一个能够在生产环境中可靠地交付人工智能能力的系统工程方法。
- en: From Artificial Intelligence Vision to Machine Learning Practice
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从人工智能愿景到机器学习实践
- en: 'Having established AI’s transformative impact across society, a question emerges:
    How do we actually create these intelligent capabilities? Understanding the relationship
    between Artificial Intelligence and Machine Learning provides the key to answering
    this question and is central to everything that follows in this book.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在确立了人工智能在社会各领域的变革性影响之后，一个问题随之而来：我们实际上如何创建这些智能能力？理解人工智能与机器学习之间的关系是回答这个问题的关键，也是本书后续所有内容的中心。
- en: 'AI represents the broad goal of creating systems that can perform tasks requiring
    human-like intelligence: recognizing images, understanding language, making decisions,
    and solving problems. AI is the what, the vision of intelligent machines that
    can learn, reason, and adapt.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能代表了创建能够执行需要类似人类智能的任务的系统的广泛目标：识别图像、理解语言、做出决策和解决问题。人工智能是“什么”，是智能机器可以学习、推理和适应的愿景。
- en: Machine Learning (ML) represents the methodological approach and practical discipline
    for creating systems that demonstrate intelligent behavior. Rather than implementing
    intelligence through predetermined rules, machine learning provides the computational
    techniques to automatically discover patterns in data through mathematical processes.
    This methodology transforms AI’s theoretical insights into functioning systems.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）代表了创建表现出智能行为的系统的方法论方法和实践学科。而不是通过预定的规则实现智能，机器学习提供了通过数学过程自动发现数据中模式的计算技术。这种方法将人工智能的理论洞察转化为功能系统。
- en: 'Consider the evolution of chess-playing systems as an example of this shift.
    The AI goal remains constant: “Create a system that can play chess like a human.”
    However, the approaches differ:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以棋类系统的演变为例，说明这种转变。人工智能的目标保持不变：“创建一个可以像人类一样下棋的系统。”然而，方法不同：
- en: '**Symbolic AI Approach (Pre-ML)**: Program the computer with all chess rules
    and hand-craft strategies like “control the center” and “protect the king.” This
    requires expert programmers to explicitly encode thousands of chess principles,
    creating brittle systems that struggle with novel positions.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**符号人工智能方法（预机器学习）**：用所有棋规和手工策略，如“控制中心”和“保护国王”，编程计算机。这需要专家程序员明确编码数千条棋理，从而创建出脆弱的系统，这些系统在处理新位置时遇到困难。'
- en: '**Machine Learning Approach**: Have the computer analyze millions of chess
    games to learn winning strategies automatically from data. Rather than programming
    specific moves, the system discovers patterns that lead to victory through statistical
    analysis of game outcomes.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习方法**：让计算机分析数百万场棋局，从数据中自动学习获胜策略。而不是编程特定的走法，系统通过分析游戏结果进行统计分析，发现导致胜利的模式。'
- en: 'This transformation illustrates why ML has become the dominant approach: In
    rule-based systems, humans translate domain expertise directly into code. In ML
    systems, humans curate training data, design learning architectures, and define
    success metrics, allowing the system to extract its own operational logic from
    examples. Data-driven systems can adapt to situations that programmers never anticipated,
    while rule-based systems remain constrained by their original programming.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变说明了为什么机器学习已成为主导方法：在基于规则的系统中，人类将领域专业知识直接转换为代码。在机器学习系统中，人类整理训练数据，设计学习架构，并定义成功指标，使系统能够从示例中提取自己的操作逻辑。数据驱动系统可以适应程序员从未预料到的情况，而基于规则的系统仍然受限于其原始编程。
- en: Machine learning systems acquire recognition capabilities through processes
    that parallel human learning patterns. Object recognition develops through exposure
    to numerous examples, while natural language processing systems acquire linguistic
    capabilities through extensive textual analysis. These learning approaches operationalize
    theories of intelligence developed in AI research, building on mathematical foundations
    that we establish systematically throughout this text.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统通过与人学习模式平行的过程获得识别能力。物体识别通过接触大量示例而发展，而自然语言处理系统通过广泛的文本分析获得语言能力。这些学习方法将人工智能研究中发展的智能理论转化为实际操作，建立在我们在整篇文章中系统建立的数学基础上。
- en: The distinction between AI as research vision and ML as engineering methodology
    carries significant implications for system design. Modern ML’s data-driven approach
    requires infrastructure capable of collecting, processing, and learning from data
    at massive scale. Machine learning emerged as a practical approach to artificial
    intelligence through extensive research and major paradigm shifts[2](#fn2), transforming
    theoretical principles about intelligence into functioning systems that form the
    algorithmic foundation of today’s intelligent capabilities.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: AI作为研究愿景与ML作为工程方法之间的区别对系统设计具有重大影响。现代ML的数据驱动方法需要能够收集、处理和从大量数据中学习的基础设施。通过广泛的研究和主要范式转变[2](#fn2)，机器学习成为人工智能的一种实用方法，将关于智能的理论原则转化为形成今天智能能力算法基础的运行系统。
- en: '***Artificial Intelligence (AI)*** is the field of computer science focused
    on creating systems that perform tasks requiring human-like *intelligence*, including
    *learning*, *reasoning*, and *adaptation*.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能（AI**）是计算机科学的一个领域，专注于创建执行需要类似人类**智能**的任务的系统，包括**学习**、**推理**和**适应**。'
- en: '***Machine Learning (ML)*** is the approach to AI that enables systems to automatically
    learn *patterns* and make *decisions* from *data* rather than following explicit
    programmed rules.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML**）是使系统能够从数据中自动学习**模式**并做出**决策**的AI方法，而不是遵循明确的编程规则。'
- en: 'The evolution from rule-based AI to data-driven ML represents one of the most
    significant shifts in computing history. This transformation explains why ML systems
    engineering has emerged as a discipline: the path to intelligent systems now runs
    through the engineering challenge of building systems that can effectively learn
    from data at massive scale.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从基于规则的AI到数据驱动的ML的演变代表了计算历史上最重大的转变之一。这种转变解释了为什么机器学习系统工程成为一门学科：通往智能系统的道路现在是通过构建能够从大量数据中有效学习的系统这一工程挑战。
- en: Defining ML Systems
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义ML系统
- en: Before exploring how we arrived at modern machine learning systems, we must
    first establish what we mean by an “ML system.” This definition provides the conceptual
    framework for understanding both the historical evolution and contemporary challenges
    that follow.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索我们如何到达现代机器学习系统之前，我们首先必须确立我们所说的“ML系统”的含义。这个定义为我们理解历史演变和随之而来的当代挑战提供了概念框架。
- en: 'No universally accepted definition of machine learning systems exists, reflecting
    the field’s rapid evolution and multidisciplinary nature. However, building on
    our understanding that modern ML relies on data-driven approaches at scale, this
    textbook adopts a perspective that encompasses the entire ecosystem in which algorithms
    operate:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习系统尚无普遍接受的定义，这反映了该领域的快速演化和跨学科性质。然而，基于我们对现代ML依赖于大规模数据驱动方法的了解，这本教科书采用了一种涵盖算法运行整个生态系统的视角：
- en: '***Machine Learning Systems*** are integrated computing systems comprising
    three interdependent components: *data* that guides behavior, *algorithms* that
    learn patterns, and *computational infrastructure* that enables both *training*
    and *inference*.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习系统**是由三个相互依存的组件组成的集成计算系统：**数据**指导行为，**算法**学习模式，以及**计算基础设施**使**训练**和**推理**成为可能。'
- en: 'As illustrated in [Figure 1.1](ch007.xhtml#fig-ai-triangle), the core of any
    machine learning system consists of three interrelated components that form a
    triangular dependency: Models/Algorithms, Data, and Computing Infrastructure.
    Each element shapes the possibilities of the others. The model architecture dictates
    both the computational demands for training and inference, as well as the volume
    and structure of data required for effective learning. The data’s scale and complexity
    influence what infrastructure is needed for storage and processing, while determining
    which model architectures are feasible. The infrastructure capabilities establish
    practical limits on both model scale and data processing capacity, creating a
    framework within which the other components must operate.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1.1](ch007.xhtml#fig-ai-triangle)所示，任何机器学习系统的核心由三个相互关联的组件组成，形成一个三角形的依赖关系：模型/算法、数据和计算基础设施。每个元素都塑造了其他元素的可能性。模型架构决定了训练和推理的计算需求，以及有效学习所需的数据量和结构。数据的规模和复杂性影响所需的存储和处理基础设施，同时确定哪些模型架构是可行的。基础设施能力为模型规模和数据处理能力设定了实际限制，为其他组件必须运行的框架。
- en: '![](../media/file13.svg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file13.svg)'
- en: 'Figure 1.1: **Component Interdependencies**: Machine learning system performance
    relies on the coordinated interaction of models, data, and computing infrastructure;
    limitations in any one component constrain the capabilities of the others. Effective
    system design requires balancing these interdependencies to optimize overall performance
    and feasibility.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：**组件相互依赖性**：机器学习系统性能依赖于模型、数据和计算基础设施的协调交互；任何一个组件的限制都会约束其他组件的能力。有效的系统设计需要平衡这些相互依赖关系，以优化整体性能和可行性。
- en: 'Each component serves a distinct but interconnected purpose:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组件都服务于一个独特但相互关联的目的：
- en: '**Algorithms**: Mathematical models and methods that learn patterns from data
    to make predictions or decisions'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法**：从数据中学习模式以进行预测或决策的数学模型和方法'
- en: '**Data**: Processes and infrastructure for collecting, storing, processing,
    managing, and serving data for both training and inference'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据**：收集、存储、处理、管理和为训练和推理提供数据的流程和基础设施'
- en: '**Computing**: Hardware and software infrastructure that enables training,
    serving, and operation of models at scale'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算**：支持大规模训练、服务和管理模型的硬件和软件基础设施'
- en: As the triangle illustrates, no single element can function in isolation. Algorithms
    require data and computing resources, large datasets require algorithms and infrastructure
    to be useful, and infrastructure requires algorithms and data to serve any purpose.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如三角形所示，没有任何一个元素可以独立运作。算法需要数据和计算资源，大量数据集需要算法和基础设施才能发挥作用，而基础设施需要算法和数据才能实现任何目的。
- en: Space exploration provides an apt analogy for these relationships. Algorithm
    developers resemble astronauts exploring new frontiers and making discoveries.
    Data science teams function like mission control specialists ensuring constant
    flow of critical information and resources for mission operations. Computing infrastructure
    engineers resemble rocket engineers designing and building systems that enable
    missions. Just as space missions require seamless integration of astronauts, mission
    control, and rocket systems, machine learning systems demand careful orchestration
    of algorithms, data, and computing infrastructure.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 太空探索为这些关系提供了一个恰当的类比。算法开发者类似于探索新领域的宇航员和发现者。数据科学团队就像任务控制专家，确保任务操作中关键信息和资源的持续流动。计算基础设施工程师类似于火箭工程师，设计和构建支持任务的系统。正如太空任务需要宇航员、任务控制和火箭系统的无缝集成一样，机器学习系统需要仔细协调算法、数据和计算基础设施。
- en: These interdependencies become clear when examining breakthrough moments in
    AI history. The 2012 AlexNet[3](#fn3) breakthrough illustrates the principle of
    hardware-software co-design that defines modern ML systems engineering. This deep
    learning revolution succeeded because the algorithmic innovation (convolutional
    neural networks) matched the hardware capability (parallel GPU architectures),
    graphics processing units originally designed for gaming but repurposed for AI
    computations, providing 10-100x speedups over traditional CPUs for machine learning
    tasks. Convolutional operations are inherently parallel, making them naturally
    suited to GPU’s thousands of parallel cores. This co-design approach continues
    to shape ML system development across the industry.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当考察人工智能历史上的突破性时刻时，这些相互依赖关系变得清晰。2012 年的 AlexNet[3](#fn3) 突破体现了定义现代机器学习系统工程的硬件-软件协同设计原则。这次深度学习革命之所以成功，是因为算法创新（卷积神经网络）与硬件能力（并行
    GPU 架构）相匹配，原本为游戏设计的图形处理单元被重新用于人工智能计算，为机器学习任务提供了 10-100 倍的速度提升。卷积操作本质上是并行的，这使得它们非常适合
    GPU 的数千个并行核心。这种协同设计方法继续塑造整个行业中的机器学习系统开发。
- en: 'With this three-component framework established, we must understand a fundamental
    difference that distinguishes ML systems from traditional software: how failures
    manifest across the AI Triangle’s components.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立这个三组件框架之后，我们必须理解一个基本区别，这个区别区分了机器学习系统与传统软件：AI 三角形组件中失败的表现。
- en: How ML Systems Differ from Traditional Software
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统与传统软件的区别
- en: 'The AI Triangle framework reveals what ML systems comprise: data that guides
    behavior, algorithms that extract patterns, and infrastructure that enables learning
    and inference. However, understanding these components alone does not capture
    what makes ML systems engineering fundamentally different from traditional software
    engineering. The critical distinction lies in how these systems fail.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: AI 三角形框架揭示了机器学习系统由什么组成：指导行为的资料，提取模式的算法，以及使学习和推理成为可能的基础设施。然而，仅仅理解这些组件并不能捕捉到使机器学习系统工程与传统软件工程根本不同的地方。关键的区别在于这些系统如何失败。
- en: 'Traditional software exhibits explicit failure modes. When code breaks, applications
    crash, error messages propagate, and monitoring systems trigger alerts. This immediate
    feedback enables rapid diagnosis and remediation. The system operates correctly
    or fails observably. Machine learning systems operate under a fundamentally different
    paradigm: they can continue functioning while their performance degrades silently
    without triggering conventional error detection mechanisms. The algorithms continue
    executing, the infrastructure maintains prediction serving, yet the learned behavior
    becomes progressively less accurate or contextually relevant.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 传统软件表现出明显的故障模式。当代码出错时，应用程序会崩溃，错误信息会传播，监控系统会触发警报。这种即时反馈使得快速诊断和修复成为可能。系统要么正确运行，要么出现可观察到的故障。机器学习系统在根本上是不同的范式：它们可以在性能下降的同时继续运行，而不会触发传统的错误检测机制。算法继续执行，基础设施继续提供预测服务，但学习到的行为变得越来越不准确或与上下文不相关。
- en: 'Consider how an autonomous vehicle’s perception system illustrates this distinction.
    Traditional automotive software exhibits binary operational states: the engine
    control unit either manages fuel injection correctly or triggers diagnostic warnings.
    The failure mode remains observable through standard monitoring. An ML-based perception
    system presents a qualitatively different challenge: the system’s accuracy in
    detecting pedestrians might decline from 95% to 85% over several months due to
    seasonal changes—different lighting conditions, clothing patterns, or weather
    phenomena underrepresented in training data. The vehicle continues operating,
    successfully detecting most pedestrians, yet the degraded performance creates
    safety risks that become apparent only through systematic monitoring of edge cases
    and comprehensive evaluation. Conventional error logging and alerting mechanisms
    remain silent while the system becomes measurably less safe.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下自动驾驶汽车的感知系统如何说明这种区别。传统的汽车软件表现出二元的操作状态：发动机控制单元要么正确管理燃油喷射，要么触发诊断警告。通过标准监控，故障模式仍然是可观察的。基于机器学习的感知系统提出了一个质的不同挑战：由于季节变化——不同的光照条件、服装模式或训练数据中未充分代表的天气现象，该系统在几个月内检测行人的准确性可能会从95%下降到85%。车辆继续运行，成功检测到大多数行人，但性能下降创造了只有通过系统性地监控边缘情况和全面评估才能显现的安全风险。传统的错误记录和警报机制在系统变得可测量地不安全时保持沉默。
- en: 'This silent degradation manifests across all three AI Triangle components.
    The data distribution shifts as the world changes: user behavior evolves, seasonal
    patterns emerge, new edge cases appear. The algorithms continue making predictions
    based on outdated learned patterns, unaware that their training distribution no
    longer matches operational reality. The infrastructure faithfully serves these
    increasingly inaccurate predictions at scale, amplifying the problem. A recommendation
    system experiencing this degradation might decline from 85% accuracy to 60% over
    six months as user preferences evolve and training data becomes stale. The system
    continues generating recommendations, users receive results, the infrastructure
    reports healthy uptime metrics, yet business value silently erodes. This degradation
    often stems from training-serving skew, where features computed differently between
    training and serving pipelines cause model performance to degrade despite unchanged
    code, which is an infrastructure issue that manifests as algorithmic failure.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这种无声的退化体现在AI三角形的三个组成部分中。随着世界的变化，数据分布也在变化：用户行为在演变，季节性模式出现，新的边缘情况出现。算法继续基于过时的学习模式进行预测，而不知道它们的训练分布已经不再与操作现实相匹配。基础设施忠实地服务于这些越来越不准确的预测，放大了问题。一个经历这种退化的推荐系统可能会在六个月内从85%的准确率下降到60%，因为用户偏好发生变化，训练数据变得陈旧。系统继续生成推荐，用户收到结果，基础设施报告健康的服务时间指标，但商业价值却在无声地侵蚀。这种退化通常源于训练-服务偏差，即训练和服务管道中计算的特征不同，导致模型性能下降，尽管代码没有改变，这是一个表现为算法失败的基础设施问题。
- en: This fundamental difference in failure modes distinguishes ML systems from traditional
    software in ways that demand new engineering practices. Traditional software development
    focuses on eliminating bugs and ensuring deterministic behavior. ML systems engineering
    must additionally address probabilistic behaviors, evolving data distributions,
    and performance degradation that occurs without code changes. The monitoring systems
    must track not just infrastructure health but also model performance, data quality,
    and prediction distributions. The deployment practices must enable continuous
    model updates as data distributions shift. The entire system lifecycle, from data
    collection through model training to inference serving, must be designed with
    silent degradation in mind.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种基本不同的失败模式以要求新的工程实践的方式将机器学习系统与传统软件区分开来。传统的软件开发侧重于消除错误和确保确定性行为。机器学习系统工程必须解决概率行为、演化的数据分布以及没有代码更改发生的性能退化。监控系统必须跟踪的不仅仅是基础设施健康，还有模型性能、数据质量和预测分布。部署实践必须能够实现数据分布变化时的持续模型更新。整个系统生命周期，从数据收集到模型训练再到推理服务，必须考虑到无声的退化。
- en: This operational reality establishes why ML systems developed in research settings
    require specialized engineering practices to reach production deployment. The
    unique lifecycle and monitoring requirements that ML systems demand stem directly
    from this failure characteristic, establishing the fundamental motivation for
    ML systems engineering as a distinct discipline.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种操作现实确立了为什么在研究环境中开发的机器学习系统需要专门的工程实践才能达到生产部署。机器学习系统所要求的独特生命周期和监控需求直接源于这种失败特征，确立了机器学习系统工程作为一个独立学科的内在动机。
- en: 'Understanding how ML systems fail differently raises an important question:
    given the three components of the AI Triangle—data, algorithms, and infrastructure—which
    should we prioritize to advance AI capabilities? Should we invest in better algorithms,
    larger datasets, or more powerful computing infrastructure? The answer to this
    question reveals why systems engineering has become central to AI progress.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 理解机器学习系统如何以不同的方式失败，提出了一个重要的问题：鉴于AI三角形的三个组成部分——数据、算法和基础设施——我们应该优先考虑哪个来推进人工智能的能力？我们应该投资于更好的算法、更大的数据集，还是更强大的计算基础设施？这个问题的答案揭示了为什么系统工程已经成为人工智能进步的核心。
- en: 'The Bitter Lesson: Why Systems Engineering Matters'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 《痛苦的教训：为什么系统工程很重要》
- en: The single biggest lesson from 70 years of AI research is that systems that
    can leverage massive computation ultimately win. This is why systems engineering,
    not just algorithmic cleverness, has become the bottleneck for progress in AI.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 70年人工智能研究最大的教训是，能够利用大规模计算的系统能够最终获胜。这就是为什么系统工程，而不仅仅是算法的巧妙性，已经成为人工智能进步的瓶颈。
- en: 'The evolution from symbolic AI through statistical learning to deep learning
    raises a fundamental question for system builders: Should we focus on developing
    more sophisticated algorithms, curating better datasets, or building more powerful
    infrastructure?'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从符号人工智能到统计学习再到深度学习的演变，对系统构建者提出了一个基本问题：我们应该专注于开发更复杂的算法、整理更好的数据集，还是构建更强大的基础设施？
- en: The answer to this question shapes how we approach building AI systems and reveals
    why systems engineering has emerged as a discipline.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的答案塑造了我们对构建人工智能系统的方法，并揭示了为什么系统工程已成为一门学科。
- en: History provides a consistent answer. Across decades of AI research, the greatest
    breakthroughs have not come from better encoding of human knowledge or more algorithmic
    techniques, but from finding ways to leverage greater computational resources
    more effectively. This pattern, articulated by reinforcement learning pioneer
    Richard Sutton[4](#fn4) in his 2019 essay “The Bitter Lesson” ([Sutton 2019](ch058.xhtml#ref-sutton2019bitter)),
    suggests that systems engineering has become the determinant of AI success.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 历史提供了统一的答案。在数十年的AI研究中，最大的突破并非来自对人类知识的更好编码或更多的算法技术，而是找到了更有效地利用更多计算资源的方法。这种模式，由强化学习先驱理查德·萨顿在2019年的文章《苦涩的教训》（[Sutton
    2019](ch058.xhtml#ref-sutton2019bitter)）中阐述，表明系统工程已成为人工智能成功的决定因素。
- en: 'Sutton observed that approaches emphasizing human expertise and domain knowledge,
    while providing short-term improvements, are consistently surpassed by general
    methods that can leverage massive computational resources. He writes: “The biggest
    lesson that can be read from 70 years of AI research is that general methods that
    leverage computation are ultimately the most effective, and by a large margin.”'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 萨顿观察到，强调人类专业知识和领域知识的途径，虽然能带来短期改进，但始终被能够利用大量计算资源的一般方法超越。他写道：“从70年的AI研究中可以得出的最大教训是，利用计算的一般方法最终是最有效的，并且差距很大。”
- en: This principle finds validation across AI breakthroughs. In chess, IBM’s Deep
    Blue defeated world champion Garry Kasparov in 1997 ([Campbell, Hoane, and Hsu
    2002](ch058.xhtml#ref-campbell2002deep)) not by encoding chess strategies, but
    through brute-force search evaluating millions of positions per second. In Go,
    DeepMind’s AlphaGo ([Silver et al. 2016](ch058.xhtml#ref-silver2016mastering))
    achieved superhuman performance by learning from self-play rather than studying
    centuries of human Go wisdom. In computer vision, convolutional neural networks
    that learn features directly from data have surpassed decades of hand-crafted
    feature engineering. In speech recognition, end-to-end deep learning systems have
    outperformed approaches built on detailed models of human phonetics and linguistics.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这一原则在人工智能的突破中得到了验证。在棋类游戏中，IBM的Deep Blue在1997年击败了世界冠军加里·卡斯帕罗夫（[Campbell, Hoane,
    and Hsu 2002](ch058.xhtml#ref-campbell2002deep)），并非通过编码棋类策略，而是通过每秒评估数百万个位置的暴力搜索。在围棋中，DeepMind的AlphaGo（[Silver
    et al. 2016](ch058.xhtml#ref-silver2016mastering)）通过自我对弈学习而非研究数百年的围棋智慧，实现了超人类的表现。在计算机视觉中，直接从数据中学习特征的卷积神经网络超越了数十年的手工特征工程。在语音识别中，端到端深度学习系统优于基于详细的人类语音学和语言学的模型的方法。
- en: The “bitter” aspect of this lesson is that our intuition misleads us. We naturally
    assume that encoding human expertise should be the path to artificial intelligence.
    Yet repeatedly, systems that leverage computation to learn from data outperform
    systems that rely on human knowledge, given sufficient scale. This pattern has
    held across symbolic AI, statistical learning, and deep learning eras—a consistency
    we’ll examine in detail when we trace AI’s historical evolution in the next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这节课的“苦涩”之处在于我们的直觉误导了我们。我们自然地认为，将人类专业知识编码化应该是通往人工智能的道路。然而，在足够大的规模下，反复证明的是，利用计算从数据中学习的系统优于依赖人类知识的系统。这一模式在符号人工智能、统计学习和深度学习时代都得到了保持——我们将在下一节追踪人工智能的历史演变时详细探讨这一一致性。
- en: 'Consider modern language models like GPT-4 or image generation systems like
    DALL-E. Their capabilities emerge not from linguistic or artistic theories encoded
    by humans, but from training general-purpose neural networks on vast amounts of
    data using enormous computational resources. Training GPT-3 consumed approximately
    1,287 MWh of energy ([Strubell, Ganesh, and McCallum 2019a](ch058.xhtml#ref-strubell2019energy);
    [D. Patterson et al. 2021a](ch058.xhtml#ref-patterson2021carbon)), equivalent
    to 120 U.S. homes for a year, while serving the model to millions of users requires
    data centers consuming megawatts of continuous power. The engineering challenge
    is building systems that can manage this scale: collecting and processing petabytes
    of training data, coordinating training across thousands of GPUs each consuming
    300-500 watts, serving models to millions of users with millisecond latency while
    managing thermal and power constraints[5](#fn5), and continuously updating systems
    based on real-world performance.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑现代语言模型如 GPT-4 或图像生成系统如 DALL-E。它们的强大功能并非源于人类编码的语言或艺术理论，而是通过在大量数据上使用巨大的计算资源训练通用神经网络而实现的。训练
    GPT-3 消耗了大约 1,287 MWh 的能源 ([Strubell, Ganesh, and McCallum 2019a](ch058.xhtml#ref-strubell2019energy);
    [D. Patterson et al. 2021a](ch058.xhtml#ref-patterson2021carbon))，相当于 120 个美国家庭一年的能源消耗，而服务于数百万用户则需要消耗兆瓦级持续功率的数据中心。工程挑战在于构建能够管理这种规模系统的系统：收集和处理
    PB 级的训练数据，协调数千个每个消耗 300-500 瓦的 GPU 进行训练，以毫秒级延迟向数百万用户提供模型服务，同时管理热能和电力限制[5](#fn5)，并基于实际性能持续更新系统。
- en: 'These scale requirements reveal a technical reality: the primary constraint
    in modern ML systems is not compute capacity but memory bandwidth[6](#fn6), the
    rate at which data can move between storage and processing units. This memory
    wall represents the primary bottleneck that determines system performance. Modern
    ML systems are memory bound, with matrix multiply operations achieving only 1-10%
    of theoretical peak FLOPS because processors spend most of their time waiting
    for data rather than computing. Moving 1GB from DRAM costs approximately 1000x
    more energy than a 32-bit multiply operation, making data movement the dominant
    factor in both performance and energy consumption. Amdahl’s Law[7](#fn7) quantifies
    this fundamental limitation: if data movement consumes 80% of execution time,
    even infinite compute capacity provides only 1.25x speedup (since only the remaining
    20% can be accelerated). This memory wall drives all modern architectural innovations,
    from in-memory computing and near-data processing to specialized accelerators
    that co-locate compute and storage elements. These system-scale challenges represent
    core engineering problems that this book explores systematically.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些规模需求揭示了技术现实：现代机器学习系统的主要限制不是计算能力，而是内存带宽[6](#fn6)，即数据在存储和处理单元之间移动的速度。这个内存墙代表了决定系统性能的主要瓶颈。现代机器学习系统受内存限制，矩阵乘法操作只能达到理论峰值
    FLOPS 的 1-10%，因为处理器大部分时间都在等待数据而不是计算。将 1GB 数据从 DRAM 移动需要大约比 32 位乘法操作多 1000 倍的能源，使得数据移动成为性能和能耗的主要因素。Amdahl
    定律[7](#fn7) 量化了这种基本限制：如果数据移动消耗了 80% 的执行时间，即使有无限的计算能力也只能提供 1.25 倍的速度提升（因为只有剩余的
    20% 可以加速）。这个内存墙推动了所有现代架构创新，从内存计算和近数据处理到将计算和存储元素协同定位的专用加速器。这些系统级挑战代表了本书系统性地探讨的核心工程问题。
- en: Sutton’s bitter lesson helps explain the motivation for this book. If AI progress
    depends on our ability to scale computation effectively, then understanding how
    to build, deploy, and maintain these computational systems becomes the most important
    skill for AI practitioners. ML systems engineering has become important because
    creating modern systems requires coordinating thousands of GPUs across multiple
    data centers, processing petabytes of text data, and serving resulting models
    to millions of users with millisecond latency requirements. This challenge demands
    expertise in distributed systems[8](#fn8), data engineering, hardware optimization,
    and operational practices that represent an entirely new engineering discipline.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Sutton 的惨痛教训有助于解释本书的动机。如果人工智能的进步取决于我们有效扩展计算的能力，那么理解如何构建、部署和维护这些计算系统就成为了人工智能从业者最重要的技能。机器学习系统工程变得重要，因为创建现代系统需要协调多个数据中心中的数千个
    GPU，处理 PB 级的文本数据，并以毫秒级延迟向数百万用户提供模型服务。这一挑战需要分布式系统[8](#fn8)、数据工程、硬件优化和运营实践方面的专业知识，这代表了一个全新的工程学科。
- en: The convergence of these systems-level challenges suggests that no existing
    discipline addresses what modern AI requires. While Computer Science advances
    ML algorithms and Electrical Engineering develops specialized AI hardware, neither
    discipline alone provides the engineering principles needed to deploy, optimize,
    and sustain ML systems at scale. This gap requires a new engineering discipline.
    But to understand why this discipline has emerged now and what form it takes,
    we must first trace the evolution of AI itself, from early symbolic systems to
    modern machine learning.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统级挑战的汇聚表明，没有现有学科能够满足现代AI的需求。虽然计算机科学推动了机器学习算法的发展，而电气工程开发了专门的AI硬件，但单独的这两个学科都无法提供部署、优化和大规模维持ML系统所需的工程原则。这个差距需要一个新的工程学科。但为了理解为什么这个学科现在出现以及它采取的形式，我们必须首先追溯AI本身的演变，从早期的符号系统到现代机器学习。
- en: Historical Evolution of AI Paradigms
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI范式的历史演变
- en: The systems-centric perspective we’ve established through the Bitter Lesson
    didn’t emerge overnight. It developed through decades of AI research where each
    major transition revealed new insights about the relationship between algorithms,
    data, and computational infrastructure. Tracing this evolution helps us understand
    not just technological progress, but the shifts in approach that explain today’s
    emphasis on scalable systems.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“苦涩教训”我们确立的系统中心视角并非一夜之间出现。它是在数十年的AI研究中逐渐形成的，每一次主要转变都揭示了算法、数据和计算基础设施之间关系的新见解。追踪这一演变不仅帮助我们理解技术进步，还解释了今天对可扩展系统的重视背后的方法转变。
- en: 'Understanding why this transition to systems-focused ML is happening now requires
    recognizing the convergence of three factors in the last decade:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 理解为什么现在会发生这种向系统化机器学习的转变，需要认识到在过去十年中三个因素的汇聚：
- en: '**Massive Datasets**: The internet age created unprecedented data volumes through
    web content, social media, sensor networks, and digital transactions. Public datasets
    like ImageNet (millions of labeled images) and Common Crawl (billions of web pages)
    provide the raw material for learning complex patterns.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**大规模数据集**：互联网时代通过网页内容、社交媒体、传感器网络和数字交易创造了前所未有的数据量。像ImageNet（数百万个标记图像）和Common
    Crawl（数十亿个网页）这样的公共数据集为学习复杂模式提供了原材料。'
- en: '**Algorithmic Breakthroughs**: Deep learning proved remarkably effective across
    diverse domains, from computer vision to natural language processing. Techniques
    like transformers, attention mechanisms, and transfer learning enabled models
    to learn generalizable representations from data.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**算法突破**：深度学习在计算机视觉到自然语言处理等多个领域都证明非常有效。像transformers、注意力机制和迁移学习等技术使得模型能够从数据中学习可泛化的表示。'
- en: '**Hardware Acceleration**: Graphics Processing Units (GPUs) originally designed
    for gaming provided 10-100x speedups for machine learning computations. Cloud
    computing infrastructure made this computational power accessible without massive
    capital investments.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**硬件加速**：最初为游戏设计的图形处理单元（GPU）为机器学习计算提供了10-100倍的加速。云计算基础设施使得这种计算能力在没有大量资本投资的情况下变得可访问。'
- en: 'This convergence explains why we’ve moved from theoretical models to large-scale
    deployed systems requiring a new engineering discipline. Each factor amplified
    the others: bigger datasets demanded more computation, better algorithms justified
    larger datasets, and faster hardware enabled more algorithms. This convergence
    transformed AI from an academic curiosity to a production technology requiring
    robust engineering practices.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种汇聚解释了为什么我们从理论模型转向了需要新工程学科的大规模部署系统。每个因素都放大了其他因素：更大的数据集需要更多的计算，更好的算法证明了更大的数据集的合理性，而更快的硬件使得更多的算法成为可能。这种汇聚将AI从学术好奇心转变为需要稳健工程实践的生产技术。
- en: The evolution of AI, depicted in the timeline shown in [Figure 1.2](ch007.xhtml#fig-ai-timeline),
    highlights key milestones such as the development of the perceptron[9](#fn9) in
    1957 by Frank Rosenblatt ([Wolfe et al. 2024](ch058.xhtml#ref-rosenblatt1957perceptron)),
    an early computational learning algorithm. Computer labs in 1965 contained room-sized
    mainframes[10](#fn10) running programs that could prove basic mathematical theorems
    or play simple games like tic-tac-toe. These early artificial intelligence systems,
    though groundbreaking for their time, differed substantially from today’s machine
    learning systems that detect cancer in medical images or understand human speech.
    The timeline shows the progression from early innovations like the ELIZA[11](#fn11)
    chatbot in 1966, to significant breakthroughs such as IBM’s Deep Blue defeating
    chess champion Garry Kasparov in 1997 ([Campbell, Hoane, and Hsu 2002](ch058.xhtml#ref-campbell2002deep)).
    More recent advancements include the introduction of OpenAI’s GPT-3 in 2020 and
    GPT-4 in 2023 ([OpenAI et al. 2023](ch058.xhtml#ref-openai2023gpt4)), demonstrating
    the dramatic evolution and increasing complexity of AI systems over the decades.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: AI的演变，如图1.2所示的时间线所示，突出了关键里程碑，如1957年由Frank Rosenblatt([Wolfe et al. 2024](ch058.xhtml#ref-rosenblatt1957perceptron))开发的感知器[9](#fn9)，这是一种早期的计算学习算法。1965年的计算机实验室[10](#fn10)中运行着能够证明基本数学定理或玩简单的游戏如井字棋的主机。尽管这些早期的人工智能系统在当时具有开创性，但它们与今天在医学图像中检测癌症或理解人类语音的机器学习系统相比，存在很大差异。时间线显示了从1966年的ELIZA[11](#fn11)聊天机器人等早期创新到1997年IBM的Deep
    Blue击败国际象棋冠军Garry Kasparov等重要突破的进展([Campbell, Hoane, and Hsu 2002](ch058.xhtml#ref-campbell2002deep))。更近期的进步包括2020年OpenAI的GPT-3和2023年的GPT-4([OpenAI
    et al. 2023](ch058.xhtml#ref-openai2023gpt4))的引入，展示了几十年间AI系统的显著演变和日益增加的复杂性。
- en: '![](../media/file14.svg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file14.svg)'
- en: 'Figure 1.2: **AI Development Timeline**: Early AI research focused on symbolic
    reasoning and rule-based systems, while modern AI leverages data-driven approaches
    like neural networks to achieve increasingly complex tasks. This progression exposes
    a shift from hand-coded intelligence to learned intelligence, marked by milestones
    such as the perceptron, deep blue, and large language models like GPT-3.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：**AI发展时间线**：早期AI研究侧重于符号推理和基于规则的系统，而现代AI利用如神经网络等数据驱动方法来实现越来越复杂的任务。这种进展揭示了从手编智能到学习智能的转变，以感知器、Deep
    Blue和GPT-3等大型语言模型等里程碑为标志。
- en: Examining this timeline reveals several distinct eras of development, each building
    upon the lessons of its predecessors while addressing limitations that prevented
    earlier approaches from achieving their promise.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 检查这个时间线可以揭示几个不同的发展时期，每个时期都是在其前辈的教训基础上建立起来的，同时解决阻碍早期方法实现其承诺的限制。
- en: Symbolic AI Era
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 符号人工智能时代
- en: The story of machine learning begins at the historic Dartmouth Conference[12](#fn12)
    in 1956, where pioneers like John McCarthy, Marvin Minsky, and Claude Shannon
    first coined the term “artificial intelligence” ([McCarthy et al. 1955](ch058.xhtml#ref-mccarthy1956dartmouth)).
    Their approach assumed that intelligence could be reduced to symbol manipulation.
    Daniel Bobrow’s STUDENT system from 1964 ([Bobrow 1964](ch058.xhtml#ref-bobrow1964student))
    exemplifies this era by solving algebra word problems through natural language
    understanding.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的故事始于1956年的历史性达特茅斯会议[12](#fn12)，在那里，像John McCarthy、Marvin Minsky和Claude
    Shannon这样的先驱首次提出了“人工智能”一词([McCarthy et al. 1955](ch058.xhtml#ref-mccarthy1956dartmouth))。他们的方法假设智力可以归结为符号操作。1964年Daniel
    Bobrow的STUDENT系统([Bobrow 1964](ch058.xhtml#ref-bobrow1964student))通过自然语言理解解决代数文字问题，是这个时代的典范。
- en: '[PRE0]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Early AI like STUDENT suffered from a limitation: they could only handle inputs
    that exactly matched their pre-programmed patterns and rules. This “brittleness”[13](#fn13)
    meant that while these solutions could appear intelligent when handling very specific
    cases they were designed for, they would break down completely when faced with
    even minor variations or real-world complexity. This limitation drove the evolution
    toward statistical approaches that we’ll examine in the next section.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的AI，如STUDENT，存在一个限制：它们只能处理与它们预先编程的模式和规则完全匹配的输入。这种“脆弱性”[13](#fn13)意味着，尽管这些解决方案在处理为它们设计的非常具体的案例时可能看起来很智能，但面对即使是微小的变化或现实世界的复杂性时，它们会完全崩溃。这种限制推动了向统计方法演化的进程，我们将在下一节中探讨。
- en: Expert Systems Era
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 专家系统时代
- en: Recognizing the limitations of symbolic AI, researchers by the mid-1970s acknowledged
    that general AI was overly ambitious and shifted their focus to capturing human
    expert knowledge in specific, well-defined domains. MYCIN ([Shortliffe 1975](ch058.xhtml#ref-shortliffe1976mycin)),
    developed at Stanford, emerged as one of the first large-scale expert systems
    designed to diagnose blood infections.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到符号人工智能的局限性，到20世纪70年代中期，研究人员承认通用人工智能过于雄心勃勃，并将他们的重点转向在特定、定义明确的领域中捕获人类专家知识。MYCIN([Shortliffe
    1975](ch058.xhtml#ref-shortliffe1976mycin))，由斯坦福大学开发，成为第一个大规模专家系统之一，旨在诊断血液感染。
- en: '[PRE1]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: MYCIN represented a major advance in medical AI with 600 expert rules for diagnosing
    blood infections, yet it revealed key challenges persisting in contemporary ML.
    Getting domain knowledge from human experts and converting it into precise rules
    proved time-consuming and difficult, as doctors often couldn’t explain exactly
    how they made decisions. MYCIN struggled with uncertain or incomplete information,
    unlike human doctors who could make educated guesses. Maintaining and updating
    the rule base became more complex as MYCIN grew, as adding new rules frequently
    conflicted with existing ones, while medical knowledge itself continued to evolve.
    Knowledge capture, uncertainty handling, and maintenance remain concerns in modern
    machine learning, addressed through different technical approaches.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: MYCIN代表了医疗人工智能的一个重大进步，拥有600条专家规则用于诊断血液感染，但它也揭示了当代机器学习中持续存在的关键挑战。从人类专家那里获取领域知识并将其转化为精确的规则既耗时又困难，因为医生往往无法准确解释他们是如何做出决定的。与能够做出有根据的猜测的人类医生不同，MYCIN在处理不确定或不完整信息时遇到了困难。随着MYCIN的增长，维护和更新规则库变得更加复杂，因为添加新规则往往与现有规则冲突，而医学知识本身也在不断演变。知识捕获、不确定性处理和维护仍然是现代机器学习中的关注点，通过不同的技术方法来解决。
- en: Statistical Learning Era
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计学习时代
- en: These challenges with knowledge capture and system maintenance drove researchers
    toward a different approach. The 1990s marked a transformation in artificial intelligence
    as the field shifted from hand-coded rules toward statistical learning approaches.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些与知识捕获和系统维护相关的挑战促使研究人员转向不同的方法。20世纪90年代标志着人工智能领域的转变，该领域从手编规则转向了统计学习方法。
- en: Three converging factors made statistical methods possible and powerful. First,
    the digital revolution meant massive amounts of data were available to train algorithms.
    Second, Moore’s Law ([G. E. Moore 1998](ch058.xhtml#ref-moore1965cramming))[14](#fn14)
    delivered the computational power needed to process this data effectively. Third,
    researchers developed new algorithms like Support Vector Machines and improved
    neural networks that could learn patterns from data rather than following pre-programmed
    rules.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 三个汇聚的因素使得统计方法变得可能且强大。首先，数字革命意味着大量数据可用于训练算法。其次，摩尔定律([G. E. Moore 1998](ch058.xhtml#ref-moore1965cramming))[14](#fn14)提供了处理这些数据所需的计算能力。第三，研究人员开发了新的算法，如支持向量机，并改进了神经网络，这些算法可以从数据中学习模式，而不是遵循预先编程的规则。
- en: 'This combination transformed AI development: rather than encoding human knowledge
    directly, machines could discover patterns automatically from examples, creating
    more robust and adaptable systems.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这种组合转变了人工智能的发展：机器不再直接编码人类知识，而是可以从示例中自动发现模式，从而创建更稳健和适应性强的系统。
- en: 'Email spam filtering evolution illustrates this transformation. Early rule-based
    systems used explicit patterns but exhibited the same brittleness we saw with
    symbolic AI systems, proving easily circumvented. Statistical systems took a different
    approach: if the word ‘viagra’ appears in 90% of spam emails but only 1% of normal
    emails, we can use this pattern to identify spam. Rather than writing explicit
    rules, statistical systems learn these patterns automatically from thousands of
    example emails, making them adaptable to new spam techniques. The mathematical
    foundation relies on Bayes’ theorem to calculate the probability that an email
    is spam given specific words: <semantics><mrow><mi>P</mi><mrow><mo stretchy="true"
    form="prefix">(</mo><mtext mathvariant="normal">spam</mtext><mo stretchy="false"
    form="prefix">|</mo><mtext mathvariant="normal">word</mtext><mo stretchy="true"
    form="postfix">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext
    mathvariant="normal">word</mtext><mo stretchy="false" form="prefix">|</mo><mtext
    mathvariant="normal">spam</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mi>P</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">spam</mtext><mo
    stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>P</mi><mrow><mo stretchy="true"
    form="prefix">(</mo><mtext mathvariant="normal">word</mtext><mo stretchy="true"
    form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(\text{spam}|\text{word})
    = P(\text{word}|\text{spam}) \times P(\text{spam}) / P(\text{word})</annotation></semantics>.
    For emails with multiple words, we combine these probabilities across the entire
    message assuming conditional independence of words given the class (spam or not
    spam), which allows efficient computation despite the simplifying assumption that
    words don’t depend on each other.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件垃圾邮件过滤器的演变说明了这种转变。早期的基于规则的系统使用了显式模式，但表现出与符号人工智能系统相同的脆弱性，证明它们很容易被规避。统计系统采取了不同的方法：如果“viagra”这个词在90%的垃圾邮件中出现，但在正常邮件中只占1%，我们可以利用这个模式来识别垃圾邮件。统计系统不是编写显式规则，而是自动从数千封示例邮件中学习这些模式，使它们能够适应新的垃圾邮件技术。其数学基础依赖于贝叶斯定理来计算给定特定单词的电子邮件是垃圾邮件的概率：[语义内容]
    <semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext
    mathvariant="normal">spam</mtext><mo stretchy="false" form="prefix">|</mo><mtext
    mathvariant="normal">word</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo
    stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">word</mtext><mo
    stretchy="false" form="prefix">|</mo><mtext mathvariant="normal">spam</mtext><mo
    stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mi>P</mi><mrow><mo stretchy="true"
    form="prefix">(</mo><mtext mathvariant="normal">spam</mtext><mo stretchy="true"
    form="postfix">)</mo></mrow><mi>/</mi><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext
    mathvariant="normal">word</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation
    encoding="application/x-tex">P(\text{spam}|\text{word}) = P(\text{word}|\text{spam})
    \times P(\text{spam}) / P(\text{word})</annotation></semantics>。对于包含多个单词的电子邮件，我们假设单词在类别（垃圾邮件或非垃圾邮件）给定条件下的条件独立性，将整个消息中的这些概率结合起来，尽管简化假设是单词之间相互独立，但这也允许高效计算。
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Statistical approaches introduced three concepts that remain central to AI
    development. First, the quality and quantity of training data became as important
    as the algorithms themselves. AI could only learn patterns that were present in
    its training examples. Second, rigorous evaluation methods became necessary to
    measure AI performance, leading to metrics that could measure success and compare
    different approaches. Third, a tension exists between precision (being right when
    making a prediction) and recall (catching all the cases we should find), forcing
    designers to make explicit trade-offs based on their application’s needs. These
    challenges require systematic approaches: [Chapter 6](ch012.xhtml#sec-data-engineering)
    covers data quality and drift detection, while [Chapter 12](ch018.xhtml#sec-benchmarking-ai)
    addresses evaluation metrics and precision-recall trade-offs. Spam filters might
    tolerate some spam to avoid blocking important emails, while medical diagnosis
    systems prioritize catching every potential case despite increased false alarms.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 统计方法引入了三个在人工智能发展中仍然处于核心地位的概念。首先，训练数据的质量和数量与算法本身一样重要。人工智能只能学习其训练示例中存在的模式。其次，为了衡量人工智能的性能，需要严格的评估方法，这导致了可以衡量成功并比较不同方法的指标。第三，精确度（在做出预测时正确）和召回率（捕捉到我们应该找到的所有案例）之间存在紧张关系，迫使设计者根据其应用需求做出明确的权衡。这些挑战需要系统性的方法：[第6章](ch012.xhtml#sec-data-engineering)涵盖了数据质量和漂移检测，而[第12章](ch018.xhtml#sec-benchmarking-ai)则涉及评估指标和精确度-召回率权衡。垃圾邮件过滤器可能容忍一些垃圾邮件以避免阻止重要邮件，而医疗诊断系统则优先考虑捕捉每一个潜在的病例，即使增加了误报。
- en: '[Table 1.1](ch007.xhtml#tbl-ai-evolution-strengths) summarizes the evolutionary
    journey of AI approaches, highlighting key strengths and capabilities emerging
    with each paradigm. Moving from left to right reveals important trends. Before
    examining shallow and deep learning, understanding trade-offs between existing
    approaches provides important context.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[表1.1](ch007.xhtml#tbl-ai-evolution-strengths)总结了人工智能方法的进化历程，突出了每个范例出现的关键优势和功能。从左到右的移动揭示了重要趋势。在考察浅层和深层学习之前，了解现有方法之间的权衡提供了重要背景。'
- en: 'Table 1.1: **AI Paradigm Evolution**: Shifting from symbolic AI to statistical
    approaches transformed machine learning by prioritizing data quantity and quality,
    enabling rigorous performance evaluation, and necessitating explicit trade-offs
    between precision and recall to optimize system behavior for specific applications.
    The table outlines how each paradigm addressed these challenges, revealing a progression
    towards data-driven systems capable of handling complex, real-world problems.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1：**人工智能范例进化**：从符号人工智能到统计方法的转变通过优先考虑数据数量和质量，使机器学习能够进行严格性能评估，并需要明确在精确度和召回率之间进行权衡以优化特定应用的行为。该表概述了每个范例如何应对这些挑战，揭示了向数据驱动系统发展的进程，这些系统能够处理复杂、现实世界的问题。
- en: '| **Aspect** | **Symbolic AI** | **Expert Systems** | **Statistical Learning**
    | **Shallow / Deep Learning** |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| **方面** | **符号人工智能** | **专家系统** | **统计学习** | **浅层/深层学习** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Key Strength** | Logical reasoning | Domain expertise | Versatility | Pattern
    recognition |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| **关键优势** | 逻辑推理 | 领域专业知识 | 通用性 | 模式识别 |'
- en: '| **Best Use Case** | Well-defined, rule-based problems | Specific domain problems
    | Various structured data problems | Complex, unstructured data problems |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **最佳用例** | 明确定义，基于规则的问题 | 特定领域问题 | 各种结构化数据问题 | 复杂，非结构化数据问题 |'
- en: '| **Data Handling** | Minimal data needed | Domain knowledge-based | Moderate
    data required | Large-scale data processing |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| **数据处理** | 需要最少数据 | 基于领域知识 | 需要适度数据 | 大规模数据处理 |'
- en: '| **Adaptability** | Fixed rules | Domain-specific adaptability | Adaptable
    to various domains | Highly adaptable to diverse tasks |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **适应性** | 固定规则 | 领域特定适应性 | 适应各种领域 | 高度适应各种任务 |'
- en: '| **Problem Complexity** | Simple, logic-based | Complicated, domain- specific
    | Complex, structured | Highly complex, unstructured |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| **问题复杂性** | 简单，基于逻辑 | 复杂，领域特定 | 复杂，结构化 | 高度复杂，非结构化 |'
- en: This analysis bridges early approaches with recent developments in shallow and
    deep learning. It explains why certain approaches gained prominence in different
    eras and how each paradigm built upon predecessors while addressing their limitations.
    Earlier approaches continue to influence modern AI techniques, particularly in
    foundation model development.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析将早期方法与浅层和深层学习领域的最新发展联系起来。它解释了为什么某些方法在不同时代获得了突出地位，以及每个范例是如何在解决前辈局限性的同时建立在它们的基础之上的。早期方法继续影响着现代人工智能技术，尤其是在基础模型开发方面。
- en: These core concepts that emerged from statistical learning (data quality, evaluation
    metrics, and precision-recall trade-offs) became the foundation for all subsequent
    developments in machine learning.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这些从统计学习（数据质量、评估指标和精确度-召回率权衡）中涌现的核心概念成为了机器学习后续所有发展的基础。
- en: Shallow Learning Era
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 浅层学习时代
- en: 'Building on these statistical foundations, the 2000s marked a significant period
    in machine learning history known as the “shallow learning” era. The term “shallow”
    refers to architectural depth: shallow learning typically employed one or two
    processing levels, contrasting with deep learning’s multiple hierarchical layers
    that emerged later.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些统计基础之上，21世纪标志着机器学习历史上的一个重要时期，被称为“浅层学习”时代。术语“浅层”指的是架构深度：浅层学习通常采用一到两个处理层，与后来出现的深层学习的多层层次结构形成对比。
- en: 'During this time, several algorithms dominated the machine learning landscape.
    Each brought unique strengths to different problems: Decision trees[15](#fn15)
    provided interpretable results by making choices much like a flowchart. K-nearest
    neighbors made predictions by finding similar examples in past data, like asking
    your most experienced neighbors for advice. Linear and logistic regression offered
    straightforward, interpretable models that worked well for many real-world problems.
    Support Vector Machines[16](#fn16) (SVMs) excelled at finding complex boundaries
    between categories using the “kernel trick”[17](#fn17). This technique transforms
    complex patterns by projecting data into higher dimensions where linear separation
    becomes possible. These algorithms formed the foundation of practical machine
    learning.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段时间里，几种算法主导了机器学习领域。每种算法都为不同的问题带来了独特的优势：决策树[15](#fn15) 通过做出类似于流程图的选择提供了可解释的结果。K最近邻通过在历史数据中寻找相似示例进行预测，就像向经验最丰富的邻居寻求建议。线性回归和逻辑回归提供了简单、可解释的模型，适用于许多现实世界的问题。支持向量机[16](#fn16)
    (SVMs) 通过使用“核技巧”[17](#fn17) 在类别之间找到复杂的边界，表现出色。这种技术通过将数据投影到更高维度来转换复杂模式，在那里线性分离成为可能。这些算法构成了实用机器学习的基础。
- en: 'A typical computer vision solution from 2005 exemplifies this approach:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 2005年的一种典型的计算机视觉解决方案体现了这种方法：
- en: '[PRE3]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This era’s hybrid approach combined human-engineered features with statistical
    learning. They had strong mathematical foundations (researchers could prove why
    they worked). They performed well even with limited data. They were computationally
    efficient. They produced reliable, reproducible results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个时代的混合方法结合了人工设计的特征和统计学习。它们有强大的数学基础（研究人员可以证明为什么它们有效）。即使在有限的数据下，它们也表现出色。它们计算效率高。它们产生了可靠、可重复的结果。
- en: The Viola-Jones algorithm ([Viola and Jones, n.d.](ch058.xhtml#ref-viola2001rapidobject))[18](#fn18)
    (2001) exemplifies this era, achieving real-time face detection using simple rectangular
    features and cascaded classifiers[19](#fn19). This algorithm powered digital camera
    face detection for nearly a decade.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Viola-Jones算法([Viola和Jones, n.d.](ch058.xhtml#ref-viola2001rapidobject))[18](#fn18)（2001）是这个时代的典范，它使用简单的矩形特征和级联分类器[19](#fn19)实现了实时人脸检测。这个算法为数字相机的人脸检测提供了近十年的动力。
- en: Deep Learning Era
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习时代
- en: While Support Vector Machines excelled at finding complex category boundaries
    through mathematical transformations, deep learning adopted a different approach
    inspired by brain architecture. Rather than relying on human-engineered features,
    deep learning employs layers of simple computational units inspired by brain neurons,
    with each layer transforming input data into increasingly abstract representations.
    While [Chapter 3](ch009.xhtml#sec-dl-primer) establishes the mathematical foundations
    of neural networks, [Chapter 4](ch010.xhtml#sec-dnn-architectures) explores the
    detailed architectures that enable this layered learning approach.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当支持向量机通过数学变换在类别之间找到复杂的边界时，深度学习采用了受大脑结构启发的不同方法。深度学习不是依赖于人工设计的特征，而是使用受大脑神经元启发的简单计算单元的层，每一层将输入数据转换成越来越抽象的表示。虽然[第3章](ch009.xhtml#sec-dl-primer)建立了神经网络数学基础，[第4章](ch010.xhtml#sec-dnn-architectures)探讨了实现这种分层学习方法的详细架构。
- en: In image processing, this layered approach works systematically. The first layer
    detects simple edges and contrasts, subsequent layers combine these into basic
    shapes and textures, higher layers recognize specific features like whiskers and
    ears, and final layers assemble these into concepts like “cat.”
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像处理中，这种分层方法系统性地工作。第一层检测简单的边缘和对比度，后续层将这些组合成基本形状和纹理，更高层识别特定的特征，如胡须和耳朵，最终层将这些组合成如“猫”这样的概念。
- en: Unlike shallow learning methods requiring carefully engineered features, deep
    learning networks automatically discover useful features from raw data. This layered
    approach to learning, building from simple patterns to complex concepts, defines
    “deep” learning and proves effective for complex, real-world data like images,
    speech, and text.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与需要精心设计特征的浅层学习方法不同，深度学习网络自动从原始数据中发现有用的特征。这种从简单模式到复杂概念的学习分层方法定义了“深度”学习，并证明了对图像、语音和文本等复杂、现实世界数据是有效的。
- en: AlexNet, shown in [Figure 1.3](ch007.xhtml#fig-alexnet), achieved a breakthrough
    in the 2012 ImageNet[20](#fn20) competition that transformed machine learning
    through a perfect alignment of algorithmic innovation and hardware capability.
    The network required two NVIDIA GTX 580 GPUs with 3GB memory each, delivering
    2.3 TFLOPS peak performance per GPU, but the real breakthrough was memory bandwidth
    utilization. Each GTX 580 provided 192.4 GB/s memory bandwidth, and AlexNet’s
    convolutional operations required approximately 288 GB/s total memory bandwidth
    (theoretical peak) to feed the computation engines—making this the first neural
    network specifically designed around memory bandwidth constraints rather than
    just compute requirements. The 60 million parameters demanded 240MB storage, while
    training on 1.2 million images required sophisticated memory management to split
    the network across GPU boundaries and coordinate gradient updates. Training consumed
    approximately 1,287 GPU-hours over 6 days, achieving 15.3% top-5 error rate compared
    to 26.2% for second place, a 42% relative improvement that demonstrated the power
    of hardware-software co-design. This represented a 10-100x speedup over CPU implementations,
    reducing training time from months to days and proving that specialized hardware
    could unlock previously intractable algorithms ([Krizhevsky, Sutskever, and Hinton
    2017a](ch058.xhtml#ref-krizhevsky2012imagenet)).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1.3](ch007.xhtml#fig-alexnet)所示，AlexNet在2012年ImageNet[20](#fn20)竞赛中取得了突破，通过算法创新与硬件能力的完美结合，改变了机器学习。该网络需要两块NVIDIA
    GTX 580 GPU，每块3GB内存，每块GPU提供2.3 TFLOPS的峰值性能，但真正的突破是内存带宽利用率。每块GTX 580提供了192.4 GB/s的内存带宽，而AlexNet的卷积操作需要大约288
    GB/s的总内存带宽（理论峰值）来喂养计算引擎——这使得这是第一个专门围绕内存带宽约束而不是仅仅计算需求设计的神经网络。6000万个参数需要240MB的存储空间，而在120万张图像上进行训练需要复杂的内存管理来分割网络跨越GPU边界并协调梯度更新。训练消耗了大约1,287
    GPU小时，在6天内完成，与第二名的26.2%相比，实现了15.3%的top-5错误率，相对提高了42%，这证明了硬件-软件协同设计的力量。这代表了比CPU实现快10-100倍的速度提升，将训练时间从数月缩短到数天，并证明专用硬件可以解锁以前难以处理的算法([Krizhevsky,
    Sutskever, and Hinton 2017a](ch058.xhtml#ref-krizhevsky2012imagenet))。
- en: The success of AlexNet wasn’t just a technical achievement; it was a watershed
    moment that demonstrated the practical viability of deep learning. This breakthrough
    required both algorithmic innovation and systems engineering advances. The achievement
    wasn’t just algorithmic, it was enabled by framework infrastructure like Theano
    that could orchestrate GPU parallelism, handle automatic differentiation at scale,
    and manage the complex computational workflows that deep learning demands. Without
    these framework foundations, the algorithmic insights would have remained computationally
    intractable.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet的成功不仅仅是一个技术成就；它是一个分水岭时刻，证明了深度学习的实际可行性。这一突破需要算法创新和系统工程方面的进步。这一成就不仅仅是算法上的，它得益于像Theano这样的框架基础设施，能够协调GPU并行处理，在规模上处理自动微分，并管理深度学习所要求的复杂计算工作流程。没有这些框架基础，算法洞察力将仍然在计算上难以处理。
- en: This pattern of requiring both algorithmic and systems breakthroughs has defined
    every major AI advance since. Modern frameworks represent infrastructure that
    transforms algorithmic possibilities into practical realities. Automatic differentiation
    (autograd) systems represent perhaps the most important innovation that makes
    modern deep learning possible, handling gradient computation automatically and
    enabling the complex architectures we use today. Understanding this framework-centric
    perspective (that major AI capabilities emerge from the intersection of algorithms
    and systems engineering) is important for building robust, scalable machine learning
    systems. This single result triggered an explosion of research and applications
    in deep learning that continues to this day. The infrastructure requirements that
    enabled this breakthrough represent the convergence of algorithmic innovation
    with systems engineering that this book explores.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这种需要算法和系统突破的双重模式定义了自那时以来每一个主要的人工智能进步。现代框架代表了将算法可能性转化为实际现实的基础设施。自动微分（autograd）系统可能是使现代深度学习成为可能的最重要创新，它自动处理梯度计算，并使我们能够使用今天所使用的复杂架构。理解这种以框架为中心的视角（即主要的人工智能能力来自算法和系统工程交叉点）对于构建稳健、可扩展的机器学习系统非常重要。这一单一结果引发了深度学习研究与应用的爆炸式增长，这一趋势至今仍在继续。使这一突破成为可能的设施需求代表了算法创新与系统工程融合的汇聚，这正是本书所探讨的。
- en: '![](../media/file15.svg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file15.svg)'
- en: 'Figure 1.3: **Convolutional Neural Network Architecture**: AlexNet demonstrated
    that deep neural networks could automatically learn effective features from images,
    dramatically outperforming traditional computer vision methods. This breakthrough
    showed that with sufficient data and computing power, neural networks could achieve
    remarkable accuracy in image recognition tasks.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：**卷积神经网络架构**：AlexNet证明了深度神经网络能够自动从图像中学习有效的特征，在传统计算机视觉方法上取得了显著的超越。这一突破表明，在足够的数据和计算能力下，神经网络能够在图像识别任务中达到显著的准确性。
- en: Deep learning subsequently entered an era of extraordinary scale. By the late
    2010s, companies like Google, Facebook, and OpenAI trained neural networks thousands
    of times larger than AlexNet. These massive models, often called “foundation models”[21](#fn21),
    expanded deep learning capabilities to new domains.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习随后进入了一个规模空前的时代。到2010年代末，谷歌、Facebook和OpenAI等公司训练的神经网络比AlexNet大数千倍。这些庞大的模型，通常被称为“基础模型”[21](#fn21)，将深度学习的能力扩展到了新的领域。
- en: 'GPT-3, released in 2020 ([T. Brown et al. 2020](ch058.xhtml#ref-brown2020language)),
    contained 175 billion parameters requiring approximately 350GB to store parameters
    (800GB+ for full training infrastructure), representing a 1,000x scale increase
    from earlier neural networks like BERT-Large[22](#fn22) (340 million parameters).
    Training GPT-3 consumed approximately 314 zettaFLOPs[23](#fn23) of computation
    across 1,024 V100 GPUs[24](#fn24) over several weeks, with training costs estimated
    at $4.6 million. The model processes text at approximately 1.7GB/s memory bandwidth
    and requires specialized infrastructure to serve millions of users with sub-second
    latency. These models demonstrated remarkable emergent abilities that appeared
    only at scale: writing human-like text, engaging in sophisticated conversation,
    generating images from descriptions, and writing functional computer code. These
    capabilities emerged from the scale of computation and data rather than explicit
    programming.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年发布的GPT-3([T. Brown等人 2020](ch058.xhtml#ref-brown2020language))包含1750亿个参数，需要大约350GB来存储参数（完整训练基础设施需要800GB+），比早期的BERT-Large[22](#fn22)（3.4亿个参数）增加了1000倍。训练GPT-3消耗了大约314泽塔FLOPs[23](#fn23)的计算能力，在1,024个V100
    GPU[24](#fn24)上跨越数周，训练成本估计为460万美元。该模型以大约1.7GB/s的内存带宽处理文本，并需要专门的设施以亚秒延迟服务数百万用户。这些模型展示了仅在规模上出现的显著涌现能力：撰写类似人类的文本、参与复杂的对话、根据描述生成图像以及编写功能性的计算机代码。这些能力源于计算和数据规模，而不是明确的编程。
- en: 'A key insight emerged: larger neural networks trained on more data became capable
    of solving increasingly complex tasks. This scale introduced significant systems
    challenges[25](#fn25). Efficiently training large models requires thousands of
    parallel GPUs, storing and serving models hundreds of gigabytes in size, and handling
    massive training datasets.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键的洞见出现了：在更多数据上训练的更大神经网络能够解决越来越复杂的任务。这种规模引入了重大的系统挑战[25](#fn25)。高效训练大型模型需要数千个并行GPU，存储和提供数百GB大小的模型，以及处理庞大的训练数据集。
- en: 'The 2012 deep learning revolution built upon neural network research dating
    to the 1950s. The story begins with Frank Rosenblatt’s Perceptron in 1957, which
    captured the imagination of researchers by showing how a simple artificial neuron
    could learn to classify patterns. Though limited to linearly separable problems,
    as Minsky and Papert’s 1969 book “Perceptrons” ([Minsky and Papert 2017](ch058.xhtml#ref-minsky1969perceptrons))
    demonstrated, it introduced the core concept of trainable neural networks. The
    1980s brought more important breakthroughs: Rumelhart, Hinton, and Williams introduced
    backpropagation ([Rumelhart, Hinton, and Williams 1986](ch058.xhtml#ref-rumelhart1986learning))
    in 1986, providing a systematic way to train multi-layer networks, while Yann
    LeCun demonstrated its practical application in recognizing handwritten digits
    using specialized neural networks designed for image processing ([Y. LeCun et
    al. 1989](ch058.xhtml#ref-lecun1989backpropagation))[26](#fn26).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 2012年的深度学习革命建立在始于20世纪50年代的神经网络研究之上。故事始于1957年弗兰克·罗森布拉特（Frank Rosenblatt）的感知器（Perceptron），它通过展示一个简单的人工神经元如何学习分类模式而吸引了研究者的想象力。尽管它仅限于线性可分问题，正如Minsky和Papert在1969年的著作《感知器》（“Perceptrons”）([Minsky
    and Papert 2017](ch058.xhtml#ref-minsky1969perceptrons))所证明的那样，它引入了可训练神经网络的核心理念。20世纪80年代带来了更多重要的突破：Rumelhart、Hinton和Williams在1986年引入了反向传播([Rumelhart,
    Hinton, and Williams 1986](ch058.xhtml#ref-rumelhart1986learning))，提供了一种系统地训练多层网络的方法，而Yann
    LeCun则展示了它在使用专门为图像处理设计的神经网络识别手写数字中的实际应用([Y. LeCun et al. 1989](ch058.xhtml#ref-lecun1989backpropagation))[26](#fn26)。
- en: 'These networks largely stagnated through the 1990s and 2000s not because the
    ideas were incorrect, but because they preceded necessary technological developments.
    The field lacked three important ingredients: sufficient data to train complex
    networks, enough computational power to process this data, and the technical innovations
    needed to train very deep networks effectively.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些网络在1990年代和2000年代停滞不前，并不是因为理念本身错误，而是因为它们在必要的技术发展之前出现。该领域缺乏三个重要的要素：训练复杂网络所需的大量数据、处理这些数据所需的足够计算能力，以及训练非常深层的网络所需的技术创新。
- en: 'Deep learning’s potential required the convergence of the three AI Triangle
    components we will explore: sufficient data to train complex networks, enough
    computational power to process this data, and algorithmic breakthroughs needed
    to train very deep networks effectively. This extended development period explains
    why the 2012 ImageNet breakthrough represented the culmination of accumulated
    research rather than a sudden revolution. This evolution established machine learning
    systems engineering as a discipline bridging theoretical advancements with practical
    implementation, operating within the interconnected framework the AI Triangle
    represents.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的潜力需要我们探索的三个AI三角形组件的融合：训练复杂网络所需的大量数据、处理这些数据所需的足够计算能力，以及训练非常深层的网络所需的算法突破。这个延长的发展期解释了为什么2012年ImageNet的突破代表了累积研究的顶点，而不是一场突然的革命。这一演变确立了机器学习系统工程作为一门学科，它将理论进步与实际实施相结合，在AI三角形所代表的互联框架内运作。
- en: 'This evolution reveals a crucial insight: as AI progressed from symbolic reasoning
    to statistical learning and deep learning, applications became increasingly ambitious
    and complex. However, this growth introduced challenges extending beyond algorithms,
    necessitating engineering entire systems capable of deploying and sustaining AI
    at scale. Understanding how these modern ML systems operate in practice requires
    examining their lifecycle characteristics and deployment patterns, which distinguish
    them fundamentally from traditional software systems.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这种演变揭示了一个关键洞察：随着人工智能从符号推理发展到统计学习和深度学习，应用变得越来越雄心勃勃和复杂。然而，这种增长引入了超越算法的挑战，需要构建能够大规模部署和维持人工智能的整个系统。理解这些现代机器学习系统在实际中的运作方式需要检查它们的生命周期特征和部署模式，这些特征和模式从根本上将它们与传统软件系统区分开来。
- en: Understanding ML System Lifecycle and Deployment
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解机器学习系统生命周期和部署
- en: Having traced AI’s evolution from symbolic systems through statistical learning
    to deep learning, we can now explore how these modern ML systems operate in practice.
    Understanding the ML lifecycle and deployment landscape is important because these
    factors shape every engineering decision we make.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过追踪人工智能从符号系统到统计学习再到深度学习的演变，我们现在可以探索这些现代机器学习系统在实际中的运作方式。理解机器学习生命周期和部署景观非常重要，因为这些因素塑造了我们做出的每一个工程决策。
- en: The ML Development Lifecycle
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习开发生命周期
- en: 'ML systems fundamentally differ from traditional software in their development
    and operational lifecycle. Traditional software follows predictable patterns where
    developers write explicit instructions that execute deterministically[27](#fn27).
    These systems build on decades of established practices: version control maintains
    precise code histories, continuous integration pipelines[28](#fn28) automate testing,
    and static analysis tools measure quality. This mature infrastructure enables
    reliable software development following well-defined engineering principles.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统在开发和运营生命周期上与传统软件有根本的不同。传统软件遵循可预测的模式，开发者编写显式的指令，这些指令以确定性方式执行[27](#fn27)。这些系统建立在数十年的既定实践之上：版本控制维护精确的代码历史，持续集成管道[28](#fn28)自动化测试，静态分析工具衡量质量。这个成熟的基础设施使得遵循明确工程原则的可靠软件开发成为可能。
- en: Machine learning systems depart from this paradigm. While traditional systems
    execute explicit programming logic, ML systems derive their behavior from data
    patterns discovered through training. This shift from code to data as the primary
    behavior driver introduces complexities that existing software engineering practices
    cannot address. These challenges require specialized workflows that [Chapter 5](ch011.xhtml#sec-ai-workflow)
    addresses.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统偏离了这种范式。虽然传统系统执行显式的编程逻辑，但机器学习系统从通过训练发现的数据模式中推导出其行为。这种从代码到数据作为主要行为驱动因素的转变引入了现有软件工程实践无法解决的复杂性。这些挑战需要专门的流程，[第5章](ch011.xhtml#sec-ai-workflow)对此进行了阐述。
- en: '[Figure 1.4](ch007.xhtml#fig-ml_lifecycle_overview) illustrates how ML systems
    operate in continuous cycles rather than traditional software’s linear progression
    from design through deployment.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.4](ch007.xhtml#fig-ml_lifecycle_overview)说明了机器学习系统如何在连续循环中运行，而不是传统软件从设计到部署的线性进展。'
- en: '![](../media/file16.svg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file16.svg)'
- en: 'Figure 1.4: **ML System Lifecycle**: Continuous iteration defines successful
    machine learning systems, requiring feedback loops to refine models and address
    performance degradation across data collection, model training, evaluation, and
    deployment. This cyclical process contrasts with traditional software development
    and emphasizes the importance of ongoing monitoring and adaptation to maintain
    system reliability and accuracy in dynamic environments.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：**机器学习系统生命周期**：连续迭代定义了成功的机器学习系统，需要反馈循环来优化模型并解决数据收集、模型训练、评估和部署过程中的性能退化。这一循环过程与传统软件开发形成对比，强调了在动态环境中持续监控和适应以保持系统可靠性和准确性的重要性。
- en: 'The data-dependent nature of ML systems creates dynamic lifecycles requiring
    continuous monitoring and adaptation. Unlike source code that changes only through
    developer modifications, data reflects real-world dynamics. Distribution shifts
    can silently alter system behavior without any code changes. Traditional tools
    designed for deterministic code-based systems prove insufficient for managing
    such data-dependent systems: version control excels at tracking discrete code
    changes but struggles with large, evolving datasets; testing frameworks designed
    for deterministic outputs require adaptation for probabilistic predictions. These
    challenges require specialized practices: [Chapter 6](ch012.xhtml#sec-data-engineering)
    addresses data versioning and quality management, while [Chapter 13](ch019.xhtml#sec-ml-operations)
    covers monitoring approaches that handle probabilistic behaviors rather than deterministic
    outputs.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统的数据依赖性特性产生了需要持续监控和适应的动态生命周期。与仅通过开发者修改而变化的源代码不同，数据反映了现实世界的动态。分布变化可以在没有任何代码更改的情况下静默地改变系统行为。为确定性基于代码的系统设计的传统工具在管理此类数据依赖系统方面证明是不够的：版本控制擅长跟踪离散的代码更改，但在处理大型、不断发展的数据集时遇到困难；为确定性输出设计的测试框架需要适应概率预测。这些挑战需要专门的实践：[第6章](ch012.xhtml#sec-data-engineering)讨论了数据版本和质量管理，而[第13章](ch019.xhtml#sec-ml-operations)涵盖了处理概率行为而不是确定性输出的监控方法。
- en: In production, lifecycle stages create either virtuous or vicious cycles. Virtuous
    cycles emerge when high-quality data enables effective learning, robust infrastructure
    supports efficient processing, and well-engineered systems facilitate better data
    collection. Vicious cycles occur when poor data quality undermines learning, inadequate
    infrastructure hampers processing, and system limitations prevent data collection
    improvements—with each problem compounding the others.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，生命周期阶段要么创造良性循环，要么创造恶性循环。当高质量的数据促进有效的学习，强大的基础设施支持高效的处理，以及精心设计的系统促进更好的数据收集时，就会产生良性循环。当数据质量差削弱了学习，基础设施不足阻碍了处理，以及系统限制阻止了数据收集改进时，就会产生恶性循环——每个问题都会加剧其他问题。
- en: The Deployment Spectrum
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署光谱
- en: Managing machine learning systems’ complexity varies across different deployment
    environments, each presenting unique constraints and opportunities that shape
    lifecycle decisions.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 管理机器学习系统复杂性的方法在不同部署环境中有所不同，每个环境都提出了独特的约束和机会，这些约束和机会塑造了生命周期决策。
- en: At one end of the spectrum, cloud-based ML systems run in massive data centers[29](#fn29).
    These systems, including large language models and recommendation engines, process
    petabytes of data while serving millions of users simultaneously. They leverage
    virtually unlimited computing resources but manage enormous operational complexity
    and costs. The architectural approaches for building such large-scale systems
    are covered in [Chapter 2](ch008.xhtml#sec-ml-systems) and [Chapter 11](ch017.xhtml#sec-ai-acceleration).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的一端，基于云的机器学习系统在大型数据中心[29](#fn29)中运行。这些系统包括大型语言模型和推荐引擎，在同时服务数百万用户的同时处理PB级的数据。它们利用几乎无限的计算资源，但管理着巨大的运营复杂性和成本。构建此类大规模系统的架构方法在[第2章](ch008.xhtml#sec-ml-systems)和[第11章](ch017.xhtml#sec-ai-acceleration)中有所介绍。
- en: At the other end, TinyML systems run on microcontrollers[30](#fn30) and embedded
    devices, performing ML tasks with severe memory, computing power, and energy consumption
    constraints. Smart home devices like Alexa or Google Assistant must recognize
    voice commands using less power than LED bulbs, while sensors must detect anomalies
    on battery power for months or years. The specialized techniques for deploying
    ML on such constrained devices are explored in [Chapter 9](ch015.xhtml#sec-efficient-ai)
    and [Chapter 10](ch016.xhtml#sec-model-optimizations), while the unique challenges
    of embedded ML systems are covered in [Chapter 14](ch020.xhtml#sec-ondevice-learning).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的另一端，TinyML系统在微控制器[30](#fn30)和嵌入式设备上运行，在严格的内存、计算能力和能耗限制下执行机器学习任务。像Alexa或Google
    Assistant这样的智能家居设备必须使用比LED灯泡更少的电力来识别语音命令，而传感器必须在电池供电下检测数月或数年的异常。在[第9章](ch015.xhtml#sec-efficient-ai)和[第10章](ch016.xhtml#sec-model-optimizations)中探讨了在如此受限的设备上部署机器学习的专用技术，而嵌入式机器学习系统的独特挑战在[第14章](ch020.xhtml#sec-ondevice-learning)中有所介绍。
- en: 'Between these extremes lies a rich variety of ML systems adapted for different
    contexts. Edge ML systems bring computation closer to data sources, reducing latency[31](#fn31)
    and bandwidth requirements while managing local computing resources. Mobile ML
    systems must balance sophisticated capabilities with severe constraints: modern
    smartphones typically have 4-12GB RAM, ARM processors operating at 1.5-3 GHz,
    and power budgets of 2-5 watts that must be shared across all system functions.
    For example, running a state-of-the-art image classification model on a smartphone
    might consume 100-500mW and complete inference in 10-100ms, compared to cloud
    servers that can use 200+ watts but deliver results in under 1ms. Enterprise ML
    systems often operate within specific business constraints, focusing on particular
    tasks while integrating with existing infrastructure. Some organizations employ
    hybrid approaches, distributing ML capabilities across multiple tiers to balance
    various requirements.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个极端之间，存在着丰富的机器学习系统，它们适应了不同的环境。边缘机器学习系统将计算更靠近数据源，减少延迟[31](#fn31)和带宽需求，同时管理本地计算资源。移动机器学习系统必须在复杂的性能和严格的限制之间取得平衡：现代智能手机通常有4-12GB的RAM，1.5-3
    GHz的ARM处理器，以及2-5瓦的电力预算，这些电力必须分配给所有系统功能。例如，在智能手机上运行最先进的图像分类模型可能会消耗100-500mW的电力，并在10-100ms内完成推理，而云服务器可以使用200+瓦的电力，但结果在1ms以下完成。企业机器学习系统通常在特定的业务约束下运行，专注于特定任务，同时与现有基础设施集成。一些组织采用混合方法，将机器学习能力分布在多个层级，以平衡各种需求。
- en: How Deployment Shapes the Lifecycle
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署如何塑造生命周期
- en: The deployment spectrum we’ve outlined represents more than just different hardware
    configurations. Each deployment environment creates an interplay of requirements,
    constraints, and trade-offs that impact every stage of the ML lifecycle, from
    initial data collection through continuous operation and evolution.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们概述的部署范围不仅仅代表不同的硬件配置。每个部署环境都创造了一个要求、限制和权衡的相互作用，这影响着机器学习生命周期的每个阶段，从最初的数据收集到持续运行和演变。
- en: Performance requirements often drive initial architectural decisions. Latency-sensitive
    applications, like autonomous vehicles or real-time fraud detection, might require
    edge or embedded architectures despite their resource constraints. Conversely,
    applications requiring massive computational power for training, such as large
    language models, naturally gravitate toward centralized cloud architectures. However,
    raw performance is just one consideration in a complex decision space.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 性能要求通常驱动初始架构决策。对延迟敏感的应用，如自动驾驶汽车或实时欺诈检测，尽管资源有限，可能需要边缘或嵌入式架构。相反，需要大量计算能力进行训练的应用，如大型语言模型，自然倾向于集中式云架构。然而，原始性能只是复杂决策空间中的一个考虑因素。
- en: Resource management varies dramatically across architectures and directly impacts
    lifecycle stages. Cloud systems must optimize for cost efficiency at scale, balancing
    expensive GPU clusters, storage systems, and network bandwidth. This affects training
    strategies (how often to retrain models), data retention policies (what historical
    data to keep), and serving architectures (how to distribute inference load). Edge
    systems face fixed resource limits that constrain model complexity and update
    frequency. Mobile and embedded systems operate under the strictest constraints,
    where every byte of memory and milliwatt of power matters, forcing aggressive
    model compression[32](#fn32) and careful scheduling of training updates.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 资源管理在架构之间差异很大，并直接影响生命周期阶段。云系统必须优化大规模成本效率，平衡昂贵的GPU集群、存储系统和网络带宽。这影响了训练策略（多久重新训练模型）、数据保留策略（保留哪些历史数据）和服务架构（如何分配推理负载）。边缘系统面临固定的资源限制，这限制了模型复杂度和更新频率。移动和嵌入式系统在最为严格的约束下运行，每个字节的内存和毫瓦特的电力都至关重要，迫使进行激进的模型压缩[32](#fn32)和仔细安排训练更新。
- en: 'Operational complexity increases with system distribution, creating cascading
    effects throughout the lifecycle. While centralized cloud architectures benefit
    from mature deployment tools and managed services, edge and hybrid systems must
    handle distributed system management complexity. This manifests across all lifecycle
    stages: data collection requires coordination across distributed sensors with
    varying connectivity; version control must track models deployed across thousands
    of edge devices; evaluation needs to account for varying hardware capabilities;
    deployment must handle staged rollouts with rollback capabilities; and monitoring
    must aggregate signals from geographically distributed systems. The systematic
    approaches to operational excellence, including incident response and debugging
    methodologies for production ML systems, are thoroughly addressed in [Chapter 13](ch019.xhtml#sec-ml-operations).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 随着系统分布的增加，操作复杂性也随之增加，在整个生命周期中产生级联效应。虽然集中式云架构受益于成熟的部署工具和管理服务，但边缘和混合系统必须处理分布式系统管理的复杂性。这体现在所有生命周期阶段：数据收集需要协调具有不同连接性的分布式传感器；版本控制必须跟踪部署在数千个边缘设备上的模型；评估需要考虑不同的硬件能力；部署必须处理分阶段推出并具有回滚能力；监控必须汇总来自地理分布系统的信号。系统化的卓越运营方法，包括生产级机器学习系统的故障响应和调试方法，在[第13章](ch019.xhtml#sec-ml-operations)中得到充分阐述。
- en: 'Data considerations introduce competing pressures that reshape lifecycle workflows.
    Privacy requirements or data sovereignty regulations might push toward edge or
    embedded architectures where data stays local, fundamentally changing data collection
    and training strategies—perhaps requiring federated learning[33](#fn33) approaches
    where models train on distributed data without centralization. Yet the need for
    large-scale training data might favor cloud approaches with centralized data aggregation.
    The velocity and volume of data also influence architectural choices: real-time
    sensor data might require edge processing to manage bandwidth during collection,
    while batch analytics might be better suited to cloud processing with periodic
    model updates.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 数据考虑因素引入了相互竞争的压力，这些压力重塑了生命周期工作流程。隐私要求或数据主权法规可能会推动向边缘或嵌入式架构发展，其中数据保持本地化，从根本上改变了数据收集和训练策略——可能需要联邦学习[33](#fn33)方法，其中模型在分布式数据上训练而不进行集中化。然而，对大规模训练数据的需求可能更倾向于云方法，具有集中式数据聚合。数据的速度和体积也会影响架构选择：实时传感器数据可能需要边缘处理来管理收集过程中的带宽，而批量分析可能更适合云处理，并定期更新模型。
- en: Evolution and maintenance requirements must be considered from the initial design.
    Cloud architectures offer flexibility for system evolution with easy model updates
    and A/B testing[34](#fn34), but can incur significant ongoing costs. Edge and
    embedded systems might be harder to update (requiring over-the-air updates[35](#fn35)
    with careful bandwidth management), but could offer lower operational overhead.
    The continuous cycle of ML systems—collect data, train models, evaluate performance,
    deploy updates, monitor behavior—becomes particularly challenging in distributed
    architectures, where updating models and maintaining system health requires careful
    orchestration across multiple tiers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 进化和维护需求必须从最初的设计阶段就考虑。云架构提供了系统进化的灵活性，易于模型更新和A/B测试[34](#fn34)，但可能产生显著的持续成本。边缘和嵌入式系统可能更难更新（需要通过空中更新[35](#fn35)进行，并需仔细管理带宽），但可能提供更低的运营开销。机器学习系统的持续循环——收集数据、训练模型、评估性能、部署更新、监控行为——在分布式架构中尤其具有挑战性，其中更新模型和维护系统健康需要在多个层级上进行仔细的编排。
- en: These trade-offs are rarely simple binary choices. Modern ML systems often adopt
    hybrid approaches, balancing these considerations based on specific use cases
    and constraints. For instance, an autonomous vehicle might perform real-time perception
    and control at the edge for latency reasons, while uploading data to the cloud
    for model improvement and downloading updated models periodically. A voice assistant
    might do wake-word detection on-device to preserve privacy and reduce latency,
    but send full speech to the cloud for complex natural language processing.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权衡很少是简单的二元选择。现代机器学习系统通常采用混合方法，根据具体用例和约束平衡这些考虑因素。例如，自动驾驶汽车可能出于延迟原因在边缘进行实时感知和控制，同时将数据上传到云端以改进模型并定期下载更新模型。语音助手可能在设备上执行唤醒词检测以保护隐私并减少延迟，但将完整语音发送到云端进行复杂自然语言处理。
- en: The key insight is understanding how deployment decisions ripple through the
    entire system lifecycle. A choice to deploy on embedded devices doesn’t just constrain
    model size, it affects data collection strategies (what sensors are feasible),
    training approaches (whether to use federated learning), evaluation metrics (accuracy
    vs. latency vs. power), deployment mechanisms (over-the-air updates), and monitoring
    capabilities (what telemetry can be collected). These interconnected decisions
    demonstrate the AI Triangle framework in practice, where constraints in one component
    create cascading effects throughout the system.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的洞见在于理解部署决策如何在整个系统生命周期中产生连锁反应。在嵌入式设备上部署的选择不仅限制了模型大小，还影响了数据收集策略（哪些传感器是可行的）、训练方法（是否使用联邦学习）、评估指标（准确性
    vs. 延迟 vs. 功耗）、部署机制（空中更新）和监控能力（可以收集哪些遥测数据）。这些相互关联的决策展示了AI三角形框架在实践中的应用，其中某一组件的约束会在整个系统中产生连锁效应。
- en: With this understanding of how ML systems operate across their lifecycle and
    deployment spectrum, we can now examine concrete examples that illustrate these
    principles in action. The case studies that follow demonstrate how different deployment
    choices create distinct engineering challenges and solutions across the system
    lifecycle.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对机器学习系统在其生命周期和部署范围内的操作方式的理解，我们现在可以检查具体示例，这些示例说明了这些原则在实际中的应用。以下案例研究展示了不同的部署选择如何在整个系统生命周期中创造独特的工程挑战和解决方案。
- en: Case Studies in Real-World ML Systems
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现实世界机器学习系统的案例研究
- en: Having established the AI Triangle framework, lifecycle stages, and deployment
    spectrum, we can now examine these principles operating in real-world systems.
    Rather than surveying multiple systems superficially, we focus on one representative
    case study, autonomous vehicles, that illustrates the spectrum of ML systems engineering
    challenges across all three components, multiple lifecycle stages, and complex
    deployment constraints.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立了AI三角形框架、生命周期阶段和部署光谱之后，我们现在可以检查这些原则在现实世界系统中的运作情况。我们不是对多个系统进行表面调查，而是专注于一个代表性的案例研究——自动驾驶汽车，它说明了ML系统工程挑战在整个三个组件、多个生命周期阶段和复杂的部署约束中的光谱。
- en: 'Case Study: Autonomous Vehicles'
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究：自动驾驶汽车
- en: '[Waymo](https://waymo.com/), a subsidiary of Alphabet Inc., stands at the forefront
    of autonomous vehicle technology, representing one of the most ambitious applications
    of machine learning systems to date. Evolving from the Google Self-Driving Car
    Project initiated in 2009, Waymo’s approach to autonomous driving exemplifies
    how ML systems can span the entire spectrum from embedded systems to cloud infrastructure.
    This case study demonstrates the practical implementation of complex ML systems
    in a safety-critical, real-world environment, integrating real-time decision-making
    with long-term learning and adaptation.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[Waymo](https://waymo.com/)，Alphabet Inc.的子公司，处于自动驾驶技术的前沿，代表了迄今为止机器学习系统最雄心勃勃的应用之一。从2009年启动的谷歌自动驾驶汽车项目演变而来，Waymo的自动驾驶方法展示了ML系统如何跨越从嵌入式系统到云基础设施的整个光谱。本案例研究展示了在安全关键、现实世界环境中复杂ML系统的实际实施，将实时决策与长期学习和适应相结合。'
- en: Data Considerations
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据考虑因素
- en: The data ecosystem underpinning Waymo’s technology is vast and dynamic. Each
    vehicle serves as a roving data center, its sensor suite, which comprises LiDAR[36](#fn36),
    radar[37](#fn37), and high-resolution cameras, generating approximately one terabyte
    of data per hour of driving. This real-world data is complemented by an even more
    extensive simulated dataset, with Waymo’s vehicles having traversed over 20 billion
    miles in simulation and more than 20 million miles on public roads. The challenge
    lies not just in the volume of data, but in its heterogeneity and the need for
    real-time processing. Waymo must handle both structured (e.g., GPS coordinates)
    and unstructured data (e.g., camera images) simultaneously. The data pipeline
    spans from edge processing on the vehicle itself to massive cloud-based storage
    and processing systems. Sophisticated data cleaning and validation processes are
    necessary, given the safety-critical nature of the application. The representation
    of the vehicle’s environment in a form amenable to machine learning presents significant
    challenges, requiring complex preprocessing to convert raw sensor data into meaningful
    features that capture the dynamics of traffic scenarios.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 支撑Waymo技术的数据生态系统庞大且动态。每辆汽车都充当一个移动的数据中心，其传感器套件包括激光雷达[36](#fn36)、雷达[37](#fn37)和高分辨率摄像头，每小时行驶过程中产生大约一太字节的数据。这些现实世界的数据得到了一个更加庞大的模拟数据集的补充，Waymo的车辆在模拟中行驶了超过200亿英里，在公共道路上行驶了超过2000万英里。挑战不仅在于数据的量，还在于其异构性和实时处理的需求。Waymo必须同时处理结构化数据（例如，GPS坐标）和非结构化数据（例如，摄像头图像）。数据管道从车辆本身的边缘处理到大规模基于云的存储和处理系统。鉴于应用的安全关键性，需要复杂的数据清洗和验证过程。以适合机器学习的形式表示车辆环境，提出了重大的挑战，需要复杂的预处理将原始传感器数据转换为有意义的功能，以捕捉交通场景的动态性。
- en: Algorithmic Considerations
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 算法考虑因素
- en: Waymo’s ML stack represents a sophisticated ensemble of algorithms tailored
    to the multifaceted challenge of autonomous driving. The perception system employs
    specialized neural networks to process visual data for object detection and tracking.
    Prediction models, needed for anticipating the behavior of other road users, use
    neural networks that can understand patterns over time[38](#fn38) in road user
    behavior. Building such complex multi-model systems requires the architectural
    patterns from [Chapter 4](ch010.xhtml#sec-dnn-architectures) and the framework
    infrastructure covered in [Chapter 7](ch013.xhtml#sec-ai-frameworks). Waymo has
    developed custom ML models like VectorNet for predicting vehicle trajectories.
    The planning and decision-making systems may incorporate learning-from-experience
    techniques to handle complex traffic scenarios.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Waymo的机器学习堆栈代表了一组复杂的算法集合，旨在解决自动驾驶的多方面挑战。感知系统采用专门的神经网络来处理视觉数据以进行目标检测和跟踪。预测模型，用于预测其他道路使用者的行为，使用能够理解道路使用者行为随时间变化的模式[38](#fn38)的神经网络。构建这样的复杂多模型系统需要[第4章](ch010.xhtml#sec-dnn-architectures)中的架构模式和[第7章](ch013.xhtml#sec-ai-frameworks)中涵盖的框架基础设施。Waymo开发了像VectorNet这样的定制机器学习模型来预测车辆轨迹。规划和决策系统可能采用经验学习技术来处理复杂的交通场景。
- en: Infrastructure Considerations
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础设施考虑
- en: The computing infrastructure supporting Waymo’s autonomous vehicles epitomizes
    the challenges of deploying ML systems across the full spectrum from edge to cloud.
    Each vehicle is equipped with a custom-designed compute platform capable of processing
    sensor data and making decisions in real-time, often leveraging specialized hardware
    like GPUs or tensor processing units (TPUs)[39](#fn39). This edge computing is
    complemented by extensive use of cloud infrastructure, leveraging the power of
    Google’s data centers for training models, running large-scale simulations, and
    performing fleet-wide learning. Such systems demand specialized hardware architectures
    ([Chapter 11](ch017.xhtml#sec-ai-acceleration)) and edge-cloud coordination strategies
    ([Chapter 2](ch008.xhtml#sec-ml-systems)) to handle real-time processing at scale.
    The connectivity between these tiers is critical, with vehicles requiring reliable,
    high-bandwidth communication for real-time updates and data uploading. Waymo’s
    infrastructure must be designed for robustness and fault tolerance, ensuring safe
    operation even in the face of hardware failures or network disruptions. The scale
    of Waymo’s operation presents significant challenges in data management, model
    deployment, and system monitoring across a geographically distributed fleet of
    vehicles.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 支持Waymo自动驾驶汽车的计算基础设施体现了在从边缘到云端的整个范围内部署机器学习系统的挑战。每辆车都配备了一个定制的计算平台，能够实时处理传感器数据并做出决策，通常利用像GPU或张量处理单元（TPUs）这样的专用硬件[39](#fn39)。这种边缘计算通过广泛使用云基础设施得到补充，利用谷歌数据中心的力量来训练模型、运行大规模模拟和进行车队范围内的学习。这样的系统需要专门的硬件架构([第11章](ch017.xhtml#sec-ai-acceleration))和边缘-云协调策略([第2章](ch008.xhtml#sec-ml-systems))来处理大规模的实时处理。这些层级之间的连接至关重要，车辆需要可靠、高带宽的通信来进行实时更新和数据上传。Waymo的基础设施必须设计为具有鲁棒性和容错性，即使在硬件故障或网络中断的情况下也能确保安全运行。Waymo运营的规模在数据管理、模型部署和地理分布的车队系统监控方面提出了重大挑战。
- en: Future Implications
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 未来影响
- en: Waymo’s impact extends beyond technological advancement, potentially revolutionizing
    transportation, urban planning, and numerous aspects of daily life. The launch
    of Waymo One, a commercial ride-hailing service using autonomous vehicles in Phoenix,
    Arizona, represents a significant milestone in the practical deployment of AI
    systems in safety-critical applications. Waymo’s progress has broader implications
    for the development of robust, real-world AI systems, driving innovations in sensor
    technology, edge computing, and AI safety that have applications far beyond the
    automotive industry. However, it also raises important questions about liability,
    ethics, and the interaction between AI systems and human society. As Waymo continues
    to expand its operations and explore applications in trucking and last-mile delivery,
    it serves as an important test bed for advanced ML systems, driving progress in
    areas such as continual learning, robust perception, and human-AI interaction.
    The Waymo case study underscores both the tremendous potential of ML systems to
    transform industries and the complex challenges involved in deploying AI in the
    real world.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Waymo 的影响超越了技术进步，可能彻底改变交通、城市规划以及日常生活的许多方面。在亚利桑那州凤凰城推出的商业叫车服务 Waymo One，使用自动驾驶汽车，代表了在安全关键应用中实际部署人工智能系统的重大里程碑。Waymo
    的进展对开发稳健、现实世界的人工智能系统具有更广泛的影响，推动了传感器技术、边缘计算和人工智能安全方面的创新，这些创新的应用远远超出了汽车行业。然而，它也引发了关于责任、伦理以及人工智能系统与人类社会之间互动的重要问题。随着
    Waymo 继续扩大其运营范围并探索卡车运输和最后一英里配送的应用，它成为高级机器学习系统的重要测试平台，推动了持续学习、稳健感知和人类-人工智能交互等领域的发展。Waymo
    案例研究突出了机器学习系统在转型行业中的巨大潜力以及将人工智能应用于现实世界所涉及的复杂挑战。
- en: Contrasting Deployment Scenarios
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对比部署场景
- en: 'While Waymo illustrates the full complexity of hybrid edge-cloud ML systems,
    other deployment scenarios present different constraint profiles. [FarmBeats](https://www.microsoft.com/en-us/research/project/farmbeats-iot-agriculture/),
    a Microsoft Research project for agricultural IoT, operates at the opposite end
    of the spectrum—severely resource-constrained edge deployments in remote locations
    with limited connectivity. FarmBeats demonstrates how ML systems engineering adapts
    to constraints: simpler models that can run on low-power microcontrollers, innovative
    connectivity solutions using TV white spaces, and local processing that minimizes
    data transmission. The challenges include maintaining sensor reliability in harsh
    conditions, validating data quality with limited human oversight, and updating
    models on devices that may be offline for extended periods.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Waymo 展示了混合边缘-云机器学习系统的全部复杂性，但其他部署场景呈现了不同的约束配置文件。[FarmBeats](https://www.microsoft.com/en-us/research/project/farmbeats-iot-agriculture/)，微软研究院的一个农业物联网项目，位于光谱的另一端——在偏远地区进行严重资源受限的边缘部署，连接性有限。FarmBeats
    展示了机器学习系统工程如何适应约束：可以在低功耗微控制器上运行的简单模型，使用电视白空间等创新连接解决方案，以及最小化数据传输的本地处理。挑战包括在恶劣条件下保持传感器的可靠性，在有限的人类监督下验证数据质量，以及在可能长时间离线的设备上更新模型。
- en: 'Conversely, [AlphaFold](https://deepmind.google/technologies/alphafold/) ([Jumper
    et al. 2021](ch058.xhtml#ref-jumper2021highly)) represents purely cloud-based
    scientific ML where computational resources are essentially unlimited but accuracy
    is paramount. AlphaFold’s protein structure prediction required training on 128
    TPUv3 cores for weeks, processing hundreds of millions of protein sequences from
    multiple databases. The systems challenges differ markedly from Waymo or FarmBeats:
    managing massive training datasets (the Protein Data Bank contains over 180,000
    structures), coordinating distributed training across specialized hardware, and
    validating predictions against experimental ground truth. Unlike Waymo’s latency
    constraints or FarmBeats’ power constraints, AlphaFold prioritizes computational
    throughput to explore vast search spaces—training costs exceeded $100,000 but
    enabled scientific breakthroughs.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，[AlphaFold](https://deepmind.google/technologies/alphafold/) ([Jumper et
    al. 2021](ch058.xhtml#ref-jumper2021highly)) 代表了纯云端的科学机器学习，其中计算资源基本上是无限的，但准确性至关重要。AlphaFold
    的蛋白质结构预测需要使用 128 个 TPUv3 核心，持续数周时间，处理来自多个数据库的数亿个蛋白质序列。系统挑战与 Waymo 或 FarmBeats
    明显不同：管理庞大的训练数据集（蛋白质数据银行包含超过 180,000 个结构），协调跨专用硬件的分布式训练，以及将预测与实验真实情况进行验证。与 Waymo
    的延迟约束或 FarmBeats 的电力约束不同，AlphaFold 优先考虑计算吞吐量以探索广阔的搜索空间——训练成本超过 10 万美元，但实现了科学突破。
- en: These three systems—Waymo (hybrid, latency-critical), FarmBeats (edge, resource-constrained),
    and AlphaFold (cloud, compute-intensive)—illustrate how deployment environment
    shapes every engineering decision. The fundamental three-component framework applies
    to all, but the specific constraints and optimization priorities differ dramatically.
    Understanding this deployment diversity is essential for ML systems engineers,
    as the same algorithmic insight may require entirely different system implementations
    depending on operational context.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个系统——Waymo（混合型，延迟关键型）、FarmBeats（边缘型，资源受限型）和AlphaFold（云型，计算密集型）——说明了部署环境如何塑造每一个工程决策。基本的三组件框架适用于所有系统，但具体的约束和优化优先级差异很大。对于机器学习系统工程师来说，理解这种部署多样性至关重要，因为相同的算法洞察可能需要根据操作环境完全不同的系统实现。
- en: With concrete examples established, we can now examine the challenges that emerge
    across different deployment scenarios and lifecycle stages.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在确立了具体例子之后，我们现在可以检查不同部署场景和生命周期阶段出现的挑战。
- en: Core Engineering Challenges in ML Systems
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统中的核心工程挑战
- en: The Waymo case study and comparative deployment scenarios reveal how the AI
    Triangle framework creates interdependent challenges across data, algorithms,
    and infrastructure. We’ve already established how ML systems differ from traditional
    software in their failure patterns and performance degradation. Now we can examine
    the specific challenge categories that emerge from this difference.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Waymo案例研究和比较部署场景揭示了AI三角形框架如何在数据、算法和基础设施之间创造相互依赖的挑战。我们已经建立了如何从失败模式和性能退化方面来看，机器学习系统与传统软件的不同。现在我们可以检查由此差异产生的具体挑战类别。
- en: Data Challenges
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据挑战
- en: 'The foundation of any ML system is its data, and managing this data introduces
    several core challenges that can silently degrade system performance. Data quality
    emerges as the primary concern: real-world data is often messy, incomplete, and
    inconsistent. Waymo’s sensor suite must contend with environmental interference
    (rain obscuring cameras, LiDAR reflections from wet surfaces), sensor degradation
    over time, and data synchronization across multiple sensors capturing information
    at different rates. Unlike traditional software where input validation can catch
    malformed data, ML systems must handle ambiguity and uncertainty inherent in real-world
    observations.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习系统的基础是其数据，管理这些数据引入了几个核心挑战，这些挑战可能会悄无声息地降低系统性能。数据质量成为首要关注点：现实世界的数据通常是杂乱无章的、不完整的和不一致的。Waymo的传感器套件必须应对环境干扰（雨模糊摄像头、湿表面上的激光雷达反射）、随着时间的推移传感器退化，以及多个传感器在不同速率上捕获信息时的数据同步。与输入验证可以捕获格式错误数据的传统软件不同，机器学习系统必须处理现实世界观察中固有的模糊性和不确定性。
- en: Scale represents another critical dimension. Waymo generates approximately one
    terabyte per vehicle per hour—managing this data volume requires sophisticated
    infrastructure for collection, storage, processing, and efficient access during
    training. The challenge isn’t just storing petabytes of data, but maintaining
    data quality metadata, version control for datasets, and efficient retrieval for
    model training. As systems scale to thousands of vehicles across multiple cities,
    these data management challenges compound exponentially.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 规模代表另一个关键维度。Waymo每小时每辆车生成大约一太字节的数据——管理这些数据量需要复杂的收集、存储、处理和训练期间高效访问的基础设施。挑战不仅仅是存储PB级的数据，还要维护数据质量元数据、数据集的版本控制和模型训练的高效检索。随着系统扩展到多个城市的数千辆车，这些数据管理挑战呈指数级增加。
- en: 'Perhaps most serious is data drift[40](#fn40), the gradual change in data patterns
    over time that silently degrades model performance. Waymo’s models encounter new
    traffic patterns, road configurations, weather conditions, and driving behaviors
    that weren’t present in training data. A model trained primarily on Phoenix driving
    might perform poorly when deployed in New York due to distribution shift: denser
    traffic, more aggressive drivers, different road layouts. Unlike traditional software
    where specifications remain constant, ML systems must adapt as the world they
    model evolves.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最严重的是数据漂移[40](#fn40)，随着时间的推移，数据模式逐渐变化，悄无声息地降低了模型性能。Waymo的模型遇到了训练数据中不存在的新的交通模式、道路配置、天气条件和驾驶行为。一个主要在凤凰城驾驶训练的模型，当部署在纽约时可能会因为分布变化而表现不佳：更密集的交通、更具侵略性的驾驶员、不同的道路布局。与规格保持恒定的传统软件不同，机器学习系统必须随着它们所模拟的世界的发展而适应。
- en: This adaptation requirement introduces an important constraint that is often
    overlooked. While ML systems can generalize to unseen situations through learned
    statistical patterns, once trained, the model’s learned behavior becomes fixed.
    The model cannot modify its understanding during deployment; it can only apply
    the patterns it learned during training. When distribution shift occurs, the model
    follows these outdated learned patterns just as deterministic code follows outdated
    rules. If construction zones triple in frequency, or new vehicle types appear
    regularly, the model’s fixed responses may prove no more appropriate than hardcoded
    logic written for a different operational context. The advantage of ML emerges
    not from runtime adaptation but from the capacity to retrain with new data, a
    process requiring deliberate engineering intervention.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这种适应性要求引入了一个经常被忽视的重要约束。虽然机器学习系统可以通过学习到的统计模式泛化到未见过的情境，但一旦训练完成，模型的学习行为就会固定。模型在部署期间无法修改其理解；它只能应用在训练期间学到的模式。当分布偏移发生时，模型会遵循这些过时的学习模式，就像确定性代码遵循过时的规则一样。如果施工区域频率增加三倍，或者新的车辆类型定期出现，模型固定的响应可能并不比为不同运营环境编写的硬编码逻辑更合适。机器学习的优势不在于运行时适应性，而在于能够使用新数据重新训练的能力，这个过程需要故意的工程干预。
- en: 'Distribution shift manifests through multiple pathways. Seasonal variations
    affect sensor performance through changing sun angles and precipitation patterns.
    Infrastructure modifications alter road layouts. Urban growth evolves traffic
    patterns. Each shift can degrade specific model components: pedestrian detection
    accuracy may decline in winter conditions, while lane following confidence may
    decrease on newly repaved roads. Detecting these shifts requires continuous monitoring
    of input distributions and model performance across operational contexts.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式偏移通过多种途径表现出来。季节性变化通过改变太阳角度和降水模式影响传感器性能。基础设施的修改改变道路布局。城市增长演变交通模式。每一次变化都可能降低特定模型组件的性能：在冬季条件下，行人检测的准确性可能会下降，而在新铺路的道路上，车道跟随的信心可能会降低。检测这些变化需要对输入分布和模型性能在运营环境中的持续监控。
- en: The systematic approaches to managing these data challenges (quality assurance,
    versioning, drift detection, and remediation strategies) are covered in [Chapter 6](ch012.xhtml#sec-data-engineering).
    The key insight is that data challenges in ML systems are continuous and dynamic,
    requiring ongoing engineering attention rather than one-time solutions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 管理这些数据挑战（质量保证、版本控制、漂移检测和修复策略）的系统方法在[第6章](ch012.xhtml#sec-data-engineering)中有详细说明。关键洞察是，机器学习系统中的数据挑战是持续和动态的，需要持续的工程关注，而不是一次性解决方案。
- en: Model Challenges
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型挑战
- en: 'Creating and maintaining the ML models themselves presents another set of challenges.
    Modern ML models, particularly in deep learning, can be complex. Consider a language
    model like GPT-3, which has hundreds of billions of parameters that need to be
    optimized through training processes[41](#fn41). This complexity creates practical
    challenges: these models require enormous computing power to train and run, making
    it difficult to deploy them in situations with limited resources, like on mobile
    phones or IoT devices.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 创建和维护机器学习模型本身又带来了一组新的挑战。现代机器学习模型，尤其是在深度学习领域，可能非常复杂。以GPT-3这样的语言模型为例，它有数百亿个参数需要通过训练过程进行优化[41](#fn41)。这种复杂性带来了实际挑战：这些模型需要巨大的计算能力来训练和运行，这使得在资源有限的环境中部署它们变得困难，例如在手机或物联网设备上。
- en: 'Training these models effectively is itself a significant challenge. Unlike
    traditional programming where we write explicit instructions, ML models learn
    from examples. This learning process involves many architectural and hyperparameter
    choices: How should we structure the model? How long should we train it? How can
    we tell if it’s learning the right patterns rather than memorizing training data?
    Making these decisions often requires both technical expertise and considerable
    trial and error.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 有效训练这些模型本身就是一个重大挑战。与传统的编程不同，我们不是编写明确的指令，而是机器学习模型从例子中学习。这个过程涉及许多架构和超参数选择：我们应该如何构建模型？我们应该训练多长时间？我们如何判断它是否在学习正确的模式而不是记住训练数据？做出这些决定通常需要技术专长和大量的试错。
- en: Modern practice increasingly relies on transfer learning—reusing models developed
    for one task as starting points for related tasks. Rather than training a new
    image recognition model from scratch, practitioners might start with a model pre-trained
    on millions of images and adapt it to their specific domain (say, medical imaging
    or agricultural monitoring). This approach dramatically reduces both the training
    data and computation required, but introduces new challenges around ensuring the
    pre-trained model’s biases don’t transfer to the new application. These training
    challenges—transfer learning, distributed training, and bias mitigation—require
    systematic approaches that [Chapter 8](ch014.xhtml#sec-ai-training) explores,
    building on the framework infrastructure from [Chapter 7](ch013.xhtml#sec-ai-frameworks).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现代实践越来越多地依赖于迁移学习——将针对一个任务开发的模型作为相关任务的起点。而不是从头开始训练一个新的图像识别模型，从业者可能会从一个在数百万张图像上预训练的模型开始，并将其调整到他们特定的领域（例如，医学成像或农业监测）。这种方法显著减少了训练数据和计算需求，但引入了确保预训练模型偏差不会转移到新应用的新挑战。这些训练挑战——迁移学习、分布式训练和偏差缓解——需要系统性的方法，[第8章](ch014.xhtml#sec-ai-training)中对此进行了探讨，并建立在[第7章](ch013.xhtml#sec-ai-frameworks)中框架基础设施的基础上。
- en: A particularly important challenge is ensuring that models work well in real-world
    conditions beyond their training data. This generalization gap, the difference
    between training performance and real-world performance, represents a central
    challenge in machine learning. A model might achieve 99% accuracy on its training
    data but only 75% accuracy in production due to subtle distribution differences.
    For important applications like autonomous vehicles or medical diagnosis systems,
    understanding and minimizing this gap becomes necessary for safe deployment.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别重要的挑战是确保模型在训练数据之外的实际情况中也能良好工作。这种泛化差距，即训练性能与实际性能之间的差异，代表了机器学习中的一个核心挑战。一个模型可能在训练数据上达到99%的准确率，但由于微妙的分布差异，在生产中可能只有75%的准确率。对于自动驾驶汽车或医疗诊断系统等重要应用，理解和最小化这一差距对于安全部署变得必要。
- en: System Challenges
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统挑战
- en: Getting ML systems to work reliably in the real world introduces its own set
    of challenges. Unlike traditional software that follows fixed rules, ML systems
    need to handle uncertainty and variability in their inputs and outputs. They also
    typically need both training systems (for learning from data) and serving systems
    (for making predictions), each with different requirements and constraints.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让机器学习系统在现实世界中可靠工作引入了自己的挑战集。与遵循固定规则的传统软件不同，机器学习系统需要处理输入和输出的不确定性和变化性。它们通常还需要训练系统（用于从数据中学习）和服务系统（用于做出预测），每个系统都有不同的要求和约束。
- en: Consider a company building a speech recognition system. They need infrastructure
    to collect and store audio data, systems to train models on this data, and then
    separate systems to actually process users’ speech in real-time. Each part of
    this pipeline needs to work reliably and efficiently, and all the parts need to
    work together seamlessly. The engineering principles for building such robust
    data pipelines are covered in [Chapter 6](ch012.xhtml#sec-data-engineering), while
    the operational practices for maintaining these systems in production are explored
    in [Chapter 13](ch019.xhtml#sec-ml-operations).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一家正在构建语音识别系统的公司。他们需要收集和存储音频数据的基础设施，用于在此数据上训练模型系统，以及处理用户实时语音的独立系统。这个流程的每一部分都需要可靠且高效地工作，并且所有部分需要无缝协作。构建这样稳健的数据管道的工程原则在[第6章](ch012.xhtml#sec-data-engineering)中有详细阐述，而维护这些系统在生产中的操作实践则在[第13章](ch019.xhtml#sec-ml-operations)中进行了探讨。
- en: These systems also need constant monitoring and updating. How do we know if
    the system is working correctly? How do we update models without interrupting
    service? How do we handle errors or unexpected inputs? These operational challenges
    become particularly complex when ML systems are serving millions of users.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统也需要持续的监控和更新。我们如何知道系统是否工作正确？我们如何在不中断服务的情况下更新模型？我们如何处理错误或意外输入？当机器学习系统服务于数百万用户时，这些操作挑战变得尤为复杂。
- en: Ethical Considerations
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 伦理考量
- en: As ML systems become more prevalent in our daily lives, their broader impacts
    on society become increasingly important to consider. One major concern is fairness,
    as ML systems can sometimes learn to make decisions that discriminate against
    certain groups of people. This often happens unintentionally, as the systems pick
    up biases present in their training data. For example, a job application screening
    system might inadvertently learn to favor certain demographics if those groups
    were historically more likely to be hired. Detecting and mitigating such biases
    requires careful auditing of both training data and model behavior across different
    demographic groups.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习系统在我们日常生活中的日益普及，它们对社会产生的更广泛影响越来越需要考虑。一个主要担忧是公平性，因为机器学习系统有时会学会做出歧视某些人群的决定。这种情况通常是无意的，因为系统会吸收其训练数据中存在的偏见。例如，一个求职申请筛选系统可能会无意中学会偏爱某些人口统计群体，如果这些群体在历史上更有可能被雇佣。检测和减轻这种偏见需要对不同人口统计群体的训练数据和模型行为进行仔细审计。
- en: Another important consideration is transparency and interpretability. Many modern
    ML models, particularly deep learning models with millions or billions of parameters,
    function as black boxes—systems where we can observe inputs and outputs but struggle
    to understand the internal reasoning. Like a radio that receives signals and produces
    sound without most users understanding the electronics inside, these models make
    predictions through complex mathematical transformations that resist human interpretation.
    A deep neural network might correctly diagnose a medical condition from an X-ray,
    but explaining why it reached that diagnosis—which visual features it considered
    most important—remains challenging. This opacity becomes particularly problematic
    when ML systems make consequential decisions affecting people’s lives in domains
    like healthcare, criminal justice, or financial services, where stakeholders reasonably
    expect explanations for decisions that impact them.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的考虑因素是透明度和可解释性。许多现代机器学习模型，尤其是具有数百万或数十亿参数的深度学习模型，作为黑盒系统运行——在这些系统中，我们可以观察到输入和输出，但难以理解内部推理。就像一个接收信号并产生声音但没有大多数用户理解内部电子的收音机一样，这些模型通过复杂的数学变换做出预测，这些变换抗拒人类的解释。一个深度神经网络可能能够从X光片中正确诊断出医疗状况，但解释它为什么做出这样的诊断——它考虑了哪些视觉特征最为重要——仍然是一个挑战。当机器学习系统在医疗保健、刑事司法或金融服务等领域做出影响人们生活的重大决策时，这种不透明性变得尤为成问题，在这些领域，利益相关者合理地期望对影响他们的决策进行解释。
- en: 'Privacy is also a major concern. ML systems often need large amounts of data
    to work effectively, but this data might contain sensitive personal information.
    How do we balance the need for data with the need to protect individual privacy?
    How do we ensure that models don’t inadvertently memorize and reveal private information
    through inference attacks[42](#fn42)? These challenges aren’t merely technical
    problems to be solved, but ongoing considerations that shape how we approach ML
    system design and deployment. These concerns require integrated approaches: [Chapter 17](ch023.xhtml#sec-responsible-ai)
    addresses fairness and bias detection, [Chapter 15](ch021.xhtml#sec-security-privacy)
    covers privacy-preserving techniques and inference attack mitigation, while [Chapter 16](ch022.xhtml#sec-robust-ai)
    ensures system resilience under adversarial conditions.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私也是一个主要担忧。机器学习系统通常需要大量数据才能有效工作，但这些数据可能包含敏感的个人信息。我们如何平衡数据需求与保护个人隐私的需求？我们如何确保模型不会无意中通过推理攻击[42](#fn42)
    记忆并泄露私人信息？这些挑战不仅仅是需要解决的技术问题，而是持续考虑的问题，这些考虑塑造了我们如何处理机器学习系统设计和部署的方法。这些问题需要综合方法：[第17章](ch023.xhtml#sec-responsible-ai)讨论了公平性和偏见检测，[第15章](ch021.xhtml#sec-security-privacy)涵盖了隐私保护技术和推理攻击缓解，而[第16章](ch022.xhtml#sec-robust-ai)确保系统在对抗条件下具有弹性。
- en: Understanding Challenge Interconnections
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解挑战之间的相互联系
- en: As the Waymo case study illustrates, challenges cascade and compound across
    the AI Triangle. Data quality issues (sensor noise, distribution shift) degrade
    model performance. Model complexity constraints (latency budgets, power limits)
    force architectural compromises that may affect fairness (simpler models might
    show more bias). System-level failures (over-the-air update problems) can prevent
    deployment of improved models that address ethical concerns.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Waymo案例研究所示，挑战在AI三角形的各个层面层层叠加和累积。数据质量问题（传感器噪声、分布偏移）会降低模型性能。模型复杂度限制（延迟预算、功率限制）迫使架构做出妥协，这可能会影响公平性（更简单的模型可能表现出更多的偏差）。系统级故障（空中更新问题）可能会阻止部署解决伦理问题的改进模型。
- en: 'This interdependency explains why ML systems engineering requires holistic
    thinking that considers the AI Triangle components together rather than optimizing
    them independently. A decision to use a larger model for better accuracy creates
    ripple effects: more training data required, longer training times, higher serving
    costs, increased latency, and potentially more pronounced biases if the training
    data isn’t carefully curated. Successfully navigating these trade-offs requires
    understanding how choices in one dimension affect others.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这种相互依赖性解释了为什么机器学习系统工程需要整体思考，考虑AI三角形的各个组成部分，而不是独立优化它们。决定使用更大的模型以获得更好的准确性会产生连锁反应：需要更多的训练数据，更长的训练时间，更高的服务成本，增加的延迟，如果训练数据没有仔细整理，可能会出现更明显的偏差。成功导航这些权衡需要理解一个维度的选择如何影响其他维度。
- en: The challenge landscape also explains why many research models fail to reach
    production. Academic ML often focuses on maximizing accuracy on benchmark datasets,
    potentially ignoring practical constraints like inference latency, training costs,
    data privacy, or operational monitoring. Production ML systems must balance accuracy
    against deployment feasibility, operational costs, ethical considerations, and
    long-term maintainability. This gap between research priorities and production
    realities motivates this book’s emphasis on systems engineering rather than pure
    algorithmic innovation.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战的地形也解释了为什么许多研究模型无法达到生产阶段。学术机器学习通常专注于在基准数据集上最大化准确性，可能忽略了实际约束，如推理延迟、训练成本、数据隐私或运营监控。生产机器学习系统必须在准确性、部署可行性、运营成本、伦理考虑和长期可维护性之间取得平衡。研究重点与生产现实之间的差距促使本书强调系统工程而非纯算法创新。
- en: These interconnected challenges, spanning data quality and model complexity
    to infrastructure scalability and ethical considerations, distinguish ML systems
    from traditional software engineering. The transition from algorithmic innovation
    to systems integration challenges, combined with the unique operational characteristics
    we’ve examined, establishes the need for a distinct engineering discipline. We
    call this emerging field AI Engineering.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这些相互关联的挑战，从数据质量和模型复杂度到基础设施可扩展性和伦理考量，将机器学习系统与传统软件工程区分开来。从算法创新到系统集成挑战的转变，加上我们考察的独特运营特性，确立了需要一种独特的工程学科。我们称这个新兴领域为人工智能工程。
- en: Defining AI Engineering
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义人工智能工程
- en: Having explored the historical evolution, lifecycle characteristics, practical
    applications, and core challenges of machine learning systems, we can now formally
    establish the discipline that addresses these systems-level concerns.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在探讨了机器学习系统在历史演变、生命周期特性、实际应用和核心挑战方面的历史演变后，我们现在可以正式确立解决这些系统级问题的学科。
- en: '***AI Engineering*** is the engineering discipline focused on the *systems-level
    integration* of machine learning *algorithms*, *data*, and *computational infrastructure*
    to build and operate production systems that are *reliable*, *efficient*, and
    *scalable*.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能工程**是专注于机器学习**算法**、**数据**和**计算基础设施**的**系统级集成**的工程学科，旨在构建和运营**可靠**、**高效**和**可扩展**的生产系统。'
- en: 'As we’ve traced through AI’s history, a fundamental transformation has occurred.
    While AI once encompassed symbolic reasoning, expert systems, and rule-based approaches,
    learning-based methods now dominate the field. When organizations build AI today,
    they build machine learning systems. Netflix’s recommendation engine processes
    billions of viewing events to train models serving millions of subscribers. Waymo’s
    autonomous vehicles run dozens of neural networks processing sensor data in real
    time. Training GPT-4 required coordinating thousands of GPUs across data centers,
    consuming megawatts of power. Modern AI is overwhelmingly machine learning: systems
    whose capabilities emerge from learning patterns in data.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们回顾人工智能的历史，发生了根本性的转变。虽然人工智能曾经包括符号推理、专家系统和基于规则的途径，但现在基于学习的方法主导了该领域。当组织今天构建人工智能时，它们构建的是机器学习系统。Netflix的推荐引擎处理数十亿次的观看事件来训练服务于数百万订阅者的模型。Waymo的自动驾驶汽车运行数十个神经网络实时处理传感器数据。训练GPT-4需要协调数据中心内的数千个GPU，消耗兆瓦的电力。现代人工智能压倒性地是机器学习：其能力源于从数据中学习到的模式。
- en: This convergence makes “AI Engineering” the natural name for the discipline,
    even though this text focuses specifically on machine learning systems as its
    subject matter. The term reflects how AI is actually built and deployed in practice
    today.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这种融合使得“人工智能工程”成为该学科的天然名称，尽管本文特别关注机器学习系统作为其主题。这个术语反映了人工智能在实际中是如何构建和部署的。
- en: 'AI Engineering encompasses the complete lifecycle of building production intelligent
    systems. A breakthrough algorithm requires efficient data collection and processing,
    distributed computation across hundreds or thousands of machines, reliable service
    to users with strict latency requirements, and continuous monitoring and updating
    based on real-world performance. The discipline addresses fundamental challenges
    at every level: designing efficient algorithms for specialized hardware, optimizing
    data pipelines that process petabytes daily, implementing distributed training
    across thousands of GPUs, deploying models that serve millions of concurrent users,
    and maintaining systems whose behavior evolves as data distributions shift. Energy
    efficiency is not an afterthought but a first-class constraint alongside accuracy
    and latency. The physics of memory bandwidth limitations, the breakdown of Dennard
    scaling, and the energy costs of data movement shape every architectural decision
    from chip design to data center deployment.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能工程涵盖了构建生产级智能系统的完整生命周期。一个突破性的算法需要高效的数据收集和处理，数百或数千台机器上的分布式计算，对用户提供具有严格延迟要求的可靠服务，以及基于实际性能的持续监控和更新。该学科在每一层面都解决了基本挑战：为专用硬件设计高效算法，优化每日处理PB级数据的管道，在数千个GPU上实施分布式训练，部署服务于数百万并发用户的模型，以及维护随着数据分布变化而演变的系统。能源效率不仅仅是事后考虑，而是与准确性和延迟一样是第一类约束。内存带宽限制的物理、Dennard缩放效应的崩溃以及数据移动的能量成本塑造了从芯片设计到数据中心部署的每一个架构决策。
- en: This emergence of AI Engineering as a distinct discipline mirrors how Computer
    Engineering emerged in the late 1960s and early 1970s.[43](#fn43) As computing
    systems grew more complex, neither Electrical Engineering nor Computer Science
    alone could address the integrated challenges of building reliable computers.
    Computer Engineering emerged as a complete discipline bridging both fields. Today,
    AI Engineering faces similar challenges at the intersection of algorithms, infrastructure,
    and operational practices. While Computer Science advances machine learning algorithms
    and Electrical Engineering develops specialized AI hardware, neither discipline
    fully encompasses the systems-level integration, deployment strategies, and operational
    practices required to build production AI systems at scale.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能工程作为一门独立学科的兴起，反映了计算机工程在20世纪60年代末和70年代初的诞生过程。[43](#fn43) 随着计算系统变得更加复杂，仅靠电气工程或计算机科学单独是无法解决构建可靠计算机的综合性挑战的。计算机工程应运而生，成为连接这两个领域的完整学科。如今，人工智能工程在算法、基础设施和运营实践交汇处面临着类似的挑战。虽然计算机科学推动了机器学习算法的发展，电气工程开发了专门的AI硬件，但这两个学科都没有完全涵盖构建大规模生产级AI系统所需的系统级集成、部署策略和运营实践。
- en: 'With AI Engineering now formally defined as the discipline, the remainder of
    this text discusses the practice of building and operating machine learning systems.
    We use “ML systems engineering” throughout to describe this practice—the work
    of designing, deploying, and maintaining the machine learning systems that constitute
    modern AI. These terms refer to the same discipline: AI Engineering is what we
    call it, ML systems engineering is what we do.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI工程现在正式被定义为学科，本文的其余部分将讨论构建和运营机器学习系统的实践。我们全篇使用“ML系统工程”来描述这一实践——设计、部署和维护构成现代AI的机器学习系统的工作。这些术语指的是同一个学科：AI工程是我们所称呼的，ML系统工程是我们所执行的。
- en: Having established AI Engineering as a discipline, we can now organize its practice
    into a coherent framework that addresses the challenges we’ve identified systematically.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在将AI工程确立为学科之后，我们现在可以将其实践组织成一个连贯的框架，系统地解决我们已识别出的挑战。
- en: 'Organizing ML Systems Engineering: The Five-Pillar Framework'
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组织机器学习系统工程：五支柱框架
- en: 'The challenges we’ve explored, from silent performance degradation and data
    drift to model complexity and ethical concerns, reveal why ML systems engineering
    has emerged as a distinct discipline. The unique failure patterns we discussed
    earlier exemplify the need for specialized approaches: traditional software engineering
    practices cannot address systems that degrade quietly rather than failing obviously.
    These challenges cannot be addressed through algorithmic innovation alone; they
    require systematic engineering practices that span the entire system lifecycle
    from initial data collection through continuous operation and evolution.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将机器学习系统工程组织在五个相互关联的学科周围，这些学科直接针对我们已识别出的挑战类别。这些支柱，如图1.5所示，代表了连接研究原型和能够在大规模上可靠运行的系统所需的核心工程能力。
- en: This book organizes ML systems engineering around five interconnected disciplines
    that directly address the challenge categories we’ve identified. These pillars,
    illustrated in [Figure 1.5](ch007.xhtml#fig-pillars), represent the core engineering
    capabilities required to bridge the gap between research prototypes and production
    systems capable of operating reliably at scale.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](../media/file17.png)'
- en: '![](../media/file17.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: 五个工程学科
- en: 'Figure 1.5: **ML System Lifecycle**: Machine learning systems engineering encompasses
    five interconnected disciplines that address the real-world challenges of building,
    deploying, and maintaining AI systems at scale. Each pillar represents critical
    engineering capabilities needed to bridge the gap between research prototypes
    and production systems.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：**ML系统生命周期**：机器学习系统工程涵盖了五个相互关联的学科，这些学科解决了在规模上构建、部署和维护AI系统的现实挑战。每个支柱代表连接研究原型和能够可靠地在大规模上运行的系统之间的关键工程能力。
- en: The Five Engineering Disciplines
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们所探讨的挑战，从无声的性能退化到数据漂移，再到模型复杂性和伦理问题，揭示了为什么机器学习系统工程已成为一个独立的学科。我们之前讨论的独特故障模式证明了需要专门的方法：传统的软件工程实践无法解决那些不会明显失败而是悄悄退化的系统。仅通过算法创新无法解决这些挑战；它们需要贯穿整个系统生命周期的系统化工程实践，从最初的数据收集到持续运行和演变。
- en: 'The five-pillar framework shown in [Figure 1.5](ch007.xhtml#fig-pillars) emerged
    directly from the systems challenges that distinguish ML from traditional software.
    Each pillar addresses specific challenge categories while recognizing their interdependencies:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1.5](ch007.xhtml#fig-pillars)所示的五支柱框架直接源于区分机器学习与传统软件的系统挑战。每个支柱都针对特定的挑战类别，同时认识到它们之间的相互依赖性：
- en: '**Data Engineering** ([Chapter 6](ch012.xhtml#sec-data-engineering)) addresses
    the data-related challenges we identified: quality assurance, scale management,
    drift detection, and distribution shift. This pillar encompasses building robust
    data pipelines that ensure quality, handle massive scale, maintain privacy, and
    provide the infrastructure upon which all ML systems depend. For systems like
    Waymo, this means managing terabytes of sensor data per vehicle, validating data
    quality in real-time, detecting distribution shifts across different cities and
    weather conditions, and maintaining data lineage for debugging and compliance.
    The techniques covered include data versioning, quality monitoring, drift detection
    algorithms, and privacy-preserving data processing.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据工程** ([第6章](ch012.xhtml#sec-data-engineering)) 解决了我们确定的数据相关挑战：质量保证、规模管理、漂移检测和分布偏移。这一支柱包括构建健壮的数据管道，确保质量，处理大规模数据，维护隐私，并为所有机器学习系统提供基础设施。对于像Waymo这样的系统，这意味着管理每辆车数TB的传感器数据，实时验证数据质量，检测不同城市和不同天气条件下的分布偏移，以及维护数据血缘以进行调试和合规性。涉及的技术包括数据版本控制、质量监控、漂移检测算法和隐私保护数据处理。'
- en: '**Training Systems** ([Chapter 8](ch014.xhtml#sec-ai-training)) tackles the
    model-related challenges around complexity and scale. This pillar covers developing
    training systems that can manage large datasets and complex models while optimizing
    computational resource utilization across distributed environments. Modern foundation
    models require coordinating thousands of GPUs, implementing parallelization strategies,
    managing training failures and restarts, and balancing training costs against
    model quality. The chapter explores distributed training architectures, optimization
    algorithms, hyperparameter tuning at scale, and the frameworks that make large-scale
    training practical.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练系统** ([第8章](ch014.xhtml#sec-ai-training)) 应对与模型相关的复杂性和规模挑战。这一支柱涵盖了开发能够管理大型数据集和复杂模型，同时在分布式环境中优化计算资源利用的训练系统。现代基础模型需要协调数千个GPU，实施并行化策略，管理训练故障和重启，以及平衡训练成本与模型质量。本章探讨了分布式训练架构、优化算法、大规模超参数调整以及使大规模训练成为可能的框架。'
- en: '**Deployment Infrastructure** ([Chapter 13](ch019.xhtml#sec-ml-operations),
    [Chapter 14](ch020.xhtml#sec-ondevice-learning)) addresses system-related challenges
    around the training-serving divide and operational complexity. This pillar encompasses
    building reliable deployment infrastructure that can serve models at scale, handle
    failures gracefully, and adapt to evolving requirements in production environments.
    Deployment spans the full spectrum from cloud services handling millions of requests
    per second to edge devices operating under severe latency and power constraints.
    The techniques include model serving architectures, edge deployment optimization,
    A/B testing frameworks, and staged rollout strategies that minimize risk while
    enabling rapid iteration.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**部署基础设施** ([第13章](ch019.xhtml#sec-ml-operations), [第14章](ch020.xhtml#sec-ondevice-learning))
    解决了训练与服务分离以及操作复杂性的系统相关挑战。这一支柱包括构建可靠的部署基础设施，能够大规模地提供服务模型，优雅地处理故障，并适应生产环境中的不断变化的需求。部署涵盖了从每秒处理数百万请求的云服务到在严重延迟和电源限制下运行的边缘设备的全谱系。技术包括模型服务架构、边缘部署优化、A/B
    测试框架以及分阶段推出策略，这些策略在降低风险的同时，使快速迭代成为可能。'
- en: '**Operations and Monitoring** ([Chapter 13](ch019.xhtml#sec-ml-operations),
    [Chapter 12](ch018.xhtml#sec-benchmarking-ai)) directly addresses the silent performance
    degradation patterns we identified as distinctive to ML systems. This pillar covers
    creating monitoring and maintenance systems that ensure continued performance,
    enable early issue detection, and support safe system updates in production. Unlike
    traditional software monitoring focused on infrastructure metrics, ML operations
    requires the four-dimensional monitoring we discussed: infrastructure health,
    model performance, data quality, and business impact. The chapter explores metrics
    design, alerting strategies, incident response procedures, debugging techniques
    for production ML systems, and continuous evaluation approaches that catch degradation
    before it impacts users.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**运营和监控** ([第13章](ch019.xhtml#sec-ml-operations), [第12章](ch018.xhtml#sec-benchmarking-ai))
    直接针对我们识别为机器学习系统特有的静默性能退化模式。这个支柱涵盖了创建监控和维护系统，确保持续的性能，实现早期问题检测，并支持生产中的安全系统更新。与关注基础设施指标的常规软件监控不同，机器学习运营需要我们讨论的四维监控：基础设施健康、模型性能、数据质量和业务影响。本章探讨了指标设计、警报策略、事件响应程序、生产机器学习系统的调试技术以及连续评估方法，这些方法可以在退化影响用户之前捕捉到它。'
- en: '**Ethics and Governance** ([Chapter 17](ch023.xhtml#sec-responsible-ai), [Chapter 15](ch021.xhtml#sec-security-privacy),
    [Chapter 18](ch024.xhtml#sec-sustainable-ai)) addresses the ethical and societal
    challenges around fairness, transparency, privacy, and safety. This pillar implements
    responsible AI practices throughout the system lifecycle rather than treating
    ethics as an afterthought. For safety-critical systems like autonomous vehicles,
    this includes formal verification methods, scenario-based testing, bias detection
    and mitigation, privacy-preserving learning techniques, and explainability approaches
    that support debugging and certification. The chapters cover both technical methods
    (differential privacy, fairness metrics, interpretability techniques) and organizational
    practices (ethics review boards, incident response protocols, stakeholder engagement).'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**伦理和治理** ([第17章](ch023.xhtml#sec-responsible-ai), [第15章](ch021.xhtml#sec-security-privacy),
    [第18章](ch024.xhtml#sec-sustainable-ai)) 解决了围绕公平、透明度、隐私和安全的社会和伦理挑战。这个支柱在整个系统生命周期中实施负责任的AI实践，而不是将伦理视为事后考虑的事情。对于像自动驾驶汽车这样的关键安全系统，这包括正式验证方法、基于场景的测试、偏差检测和缓解、隐私保护学习技术和支持调试和认证的可解释性方法。这些章节涵盖了技术方法（差分隐私、公平性指标、可解释性技术）和组织实践（伦理审查委员会、事件响应协议、利益相关者参与）。'
- en: Connecting Components, Lifecycle, and Disciplines
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接组件、生命周期和学科
- en: 'The five pillars emerge naturally from the AI Triangle framework and lifecycle
    stages we established earlier. Each AI Triangle component maps to specific pillars:
    Data Engineering handles the data component’s full lifecycle; Training Systems
    and Deployment Infrastructure address how algorithms interact with infrastructure
    during different lifecycle phases; Operations bridges all components by monitoring
    their interactions; Ethics & Governance cuts across all components, ensuring responsible
    practices throughout.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 五个支柱自然地从我们之前确立的AI三角形框架和生命周期阶段中产生。每个AI三角形组件映射到特定的支柱：数据工程处理数据组件的完整生命周期；训练系统和部署基础设施解决算法在不同生命周期阶段与基础设施的交互；运营通过监控它们的交互连接所有组件；伦理与治理跨越所有组件，确保在整个生命周期中实施负责任的做法。
- en: 'The challenge categories we identified find their solutions within specific
    pillars: Data challenges → Data Engineering. Model challenges → Training Systems.
    System challenges → Deployment Infrastructure and Operations. Ethical challenges
    → Ethics & Governance. As we established with the AI Triangle framework, these
    pillars must coordinate rather than operate in isolation.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确定的挑战类别在特定的支柱中找到解决方案：数据挑战 → 数据工程。模型挑战 → 训练系统。系统挑战 → 部署基础设施和运营。伦理挑战 → 伦理与治理。正如我们在AI三角形框架中确立的那样，这些支柱必须协调一致，而不是孤立运作。
- en: This structure reflects how AI evolved from algorithm-centric research to systems-centric
    engineering, shifting focus from “can we make this algorithm work?” to “can we
    build systems that reliably deploy, operate, and maintain these algorithms at
    scale?” The five pillars represent the engineering capabilities required to answer
    “yes.”
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结构反映了人工智能如何从以算法为中心的研究发展到以系统为中心的工程，将重点从“我们能否让这个算法工作？”转移到“我们能否构建能够可靠地部署、运营和维护这些算法的系统？”五个支柱代表了回答“是”所需的工程能力。
- en: Future Directions in ML Systems Engineering
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习系统工程的未来方向
- en: While these five pillars provide a stable framework for ML systems engineering,
    the field continues evolving. Understanding current trends helps anticipate how
    the core challenges and trade-offs will manifest in future systems.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这五个支柱为机器学习系统工程提供了一个稳定的框架，但该领域仍在不断发展。了解当前趋势有助于预测核心挑战和权衡在未来系统中将如何体现。
- en: 'Application-level innovation increasingly features agentic systems that move
    beyond reactive prediction to autonomous action. Systems that can plan, reason,
    and execute complex tasks introduce new requirements for decision-making frameworks
    and safety constraints. These advances don’t eliminate the five pillars but increase
    their importance: autonomous systems that can take consequential actions require
    even more rigorous data quality, more reliable deployment infrastructure, more
    comprehensive monitoring, and stronger ethical safeguards.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 应用层面的创新越来越多地以具有代理能力的系统为特征，这些系统能够超越反应性预测，实现自主行动。能够规划、推理和执行复杂任务的系统对决策框架和安全约束提出了新的要求。这些进步并没有消除五个支柱，而是增加了它们的重要性：能够采取重要行动的自主系统需要更加严格的数据质量、更可靠的部署基础设施、更全面的监控和更强的伦理保障。
- en: System architecture evolution addresses sustainability and efficiency concerns
    that have become critical as models scale. Innovation in model compression, efficient
    training techniques, and specialized hardware stems from both environmental and
    economic pressures. Future architectures must balance the pursuit of more powerful
    models against growing resource constraints. These efficiency innovations primarily
    impact Training Systems and Deployment Infrastructure pillars, introducing new
    techniques like quantization, pruning, and neural architecture search that optimize
    for multiple objectives simultaneously.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 系统架构的演进解决了随着模型规模扩大而变得至关重要的可持续性和效率问题。模型压缩、高效训练技术和专用硬件的创新源于环境和经济压力。未来的架构必须在追求更强大的模型与日益增长的资源限制之间取得平衡。这些效率创新主要影响训练系统和部署基础设施支柱，引入了量化、剪枝和神经架构搜索等新技术，这些技术可以同时优化多个目标。
- en: Infrastructure advances continue reshaping deployment possibilities. Specialized
    AI accelerators are emerging across the spectrum from powerful data center chips
    to efficient edge processors. This heterogeneous computing landscape enables dynamic
    model distribution across tiers based on capabilities and conditions, blurring
    traditional boundaries between cloud, edge, and embedded systems. These infrastructure
    innovations affect how all five pillars operate—new hardware enables new algorithms,
    which require new training approaches, which demand new monitoring strategies.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施的发展持续重塑部署的可能性。从强大的数据中心芯片到高效的边缘处理器，专用AI加速器正在整个范围内出现。这种异构计算环境使得可以根据能力和条件在各个层级动态分配模型，模糊了云、边缘和嵌入式系统之间的传统边界。这些基础设施创新影响了所有五个支柱的运作方式——新的硬件使得新的算法成为可能，这需要新的训练方法，这又要求新的监控策略。
- en: Democratization of AI technology is making ML systems more accessible to developers
    and organizations of all sizes. Cloud providers offer pre-trained models and automated
    ML platforms that reduce the expertise barrier for deploying AI solutions. This
    accessibility trend doesn’t diminish the importance of systems engineering—if
    anything, it increases demand for robust, reliable systems that can operate without
    constant expert oversight. The five pillars become even more critical as ML systems
    proliferate into domains beyond traditional tech companies.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能技术的民主化使得机器学习系统对各种规模的开发者和组织更加可访问。云服务提供商提供预训练模型和自动机器学习平台，降低了部署人工智能解决方案的专业知识门槛。这种可访问性趋势并没有减少系统工程的重要性——如果有什么不同的话，它增加了对稳健、可靠的系统需求，这些系统可以在没有持续专家监督的情况下运行。随着机器学习系统向传统科技公司以外的领域扩散，五个支柱变得更加关键。
- en: 'These trends share a common theme: they create ML systems that are more capable
    and widespread, but also more complex to engineer reliably. The five-pillar framework
    provides the foundation for navigating this landscape, though specific techniques
    within each pillar will continue advancing.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这些趋势有一个共同的主题：它们创造了更强大、更广泛的机器学习系统，但同时也使得这些系统在可靠地设计上更加复杂。五个支柱框架为导航这一领域提供了基础，尽管每个支柱内的具体技术将继续进步。
- en: The Nature of Systems Knowledge
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统知识本质
- en: Machine learning systems engineering differs epistemologically from purely theoretical
    computer science disciplines. While fields like algorithms, complexity theory,
    or formal verification build knowledge through mathematical proofs and rigorous
    derivations, ML systems engineering is a practice, a craft learned through building,
    deploying, and maintaining systems at scale. This distinction becomes apparent
    in topics like MLOps, where you’ll encounter fewer theorems and more battle-tested
    patterns that have emerged from production experience. The knowledge here isn’t
    about proving optimal solutions exist but about recognizing which approaches work
    reliably under real-world constraints.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统工程在认识论上与纯理论计算机科学学科不同。虽然算法、复杂性理论或形式验证等领域通过数学证明和严格的推导来构建知识，但机器学习系统工程是一种实践，一种通过构建、部署和维护大规模系统来学习的技艺。这种区别在MLOps等主题中变得明显，在那里你会遇到更少的定理和更多来自生产经验的经过实战检验的模式。这里的知识不是关于证明最优解的存在，而是关于识别在现实世界约束下哪些方法能够可靠地工作。
- en: This practical orientation reflects ML systems engineering’s nature as a systems
    discipline. Like other engineering fields—civil, electrical, mechanical—the core
    challenge lies in managing complexity and trade-offs rather than deriving closed-form
    solutions. You’ll learn to reason about latency versus accuracy trade-offs, to
    recognize when data quality issues will undermine even sophisticated models, to
    anticipate how infrastructure choices propagate through entire system architectures.
    This systems thinking develops through experience with concrete scenarios, debugging
    production failures, and understanding why certain design patterns persist across
    different applications.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实用导向反映了机器学习系统工程作为系统学科的本质。与其他工程领域——如土木、电气、机械工程一样——核心挑战在于管理复杂性和权衡，而不是推导封闭形式的解决方案。你将学会推理关于延迟与准确性的权衡，识别数据质量问题将如何破坏甚至复杂的模型，预测基础设施选择如何在整个系统架构中传播。这种系统思维是通过具体场景的经验、调试生产故障以及理解为什么某些设计模式在不同应用中持续存在来发展的。
- en: 'The implication for learning is significant: mastery comes through building
    intuition about patterns, understanding trade-off spaces, and recognizing how
    different system components interact. When you read about monitoring strategies
    or deployment architectures, the goal isn’t memorizing specific configurations
    but developing judgment about which approaches suit which contexts. This book
    provides the frameworks, principles, and representative examples, but expertise
    ultimately develops through applying these concepts to real problems, making mistakes,
    and building the pattern recognition that distinguishes experienced systems engineers
    from those who only understand individual components.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 学习的启示是显著的：掌握知识来自于对模式建立直觉、理解权衡空间以及识别不同系统组件如何相互作用。当你阅读关于监控策略或部署架构的内容时，目标不是记住特定的配置，而是发展对不同方法适合何种情境的判断。本书提供了框架、原则和代表性示例，但专业知识最终是通过将这些概念应用于实际问题、犯错误以及建立区分经验丰富的系统工程师和仅理解单个组件的人的模式识别来发展的。
- en: How to Use This Textbook
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用这本教科书
- en: 'For readers approaching this material, the chapters build systematically on
    these foundational concepts:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接触这些材料的读者，章节系统地建立在这些基础概念之上：
- en: '**Foundation chapters** ([Chapter 2](ch008.xhtml#sec-ml-systems), [Chapter 3](ch009.xhtml#sec-dl-primer),
    [Chapter 4](ch010.xhtml#sec-dnn-architectures)) explore the algorithmic and architectural
    fundamentals, providing the technical background for understanding system-level
    decisions. These chapters answer “what are we building?” before addressing “how
    do we build it reliably?”'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '**基础章节**（[第2章](ch008.xhtml#sec-ml-systems)，[第3章](ch009.xhtml#sec-dl-primer)，[第4章](ch010.xhtml#sec-dnn-architectures)）探讨了算法和架构基础，为理解系统级决策提供了技术背景。这些章节在回答“我们要构建什么？”之后，再讨论“我们如何可靠地构建它？”'
- en: '**Pillar chapters** follow the five-discipline organization, with each pillar
    containing multiple chapters that progress from fundamentals to advanced topics.
    Readers can follow linearly through all chapters or focus on specific pillars
    relevant to their work, though understanding the interdependencies we’ve discussed
    helps appreciate how decisions in one pillar affect others.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '**支柱章节**遵循五学科组织结构，每个支柱包含多个章节，从基础到高级主题逐步推进。读者可以线性地阅读所有章节，或者关注与他们的工作相关的特定支柱，尽管理解我们讨论的相互依赖性有助于欣赏一个支柱中的决策如何影响其他支柱。'
- en: '**Specialized topics** ([Chapter 19](ch025.xhtml#sec-ai-good), [Chapter 18](ch024.xhtml#sec-sustainable-ai),
    [Chapter 20](ch026.xhtml#sec-agi-systems)) examine how ML systems engineering
    applies to specific domains and emerging challenges, demonstrating the framework’s
    flexibility across diverse applications.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**专门主题**（[第19章](ch025.xhtml#sec-ai-good)，[第18章](ch024.xhtml#sec-sustainable-ai)，[第20章](ch026.xhtml#sec-agi-systems)）探讨了机器学习系统工程如何应用于特定领域和新兴挑战，展示了框架在多样化应用中的灵活性。'
- en: 'The cross-reference system throughout the book helps navigate connections—when
    one chapter discusses a concept covered in detail elsewhere, references guide
    you to that material. This interconnected structure reflects the AI Triangle framework’s
    reality: ML systems engineering requires understanding how data, algorithms, and
    infrastructure interact rather than studying them in isolation.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 本书全书的交叉引用系统有助于导航联系——当某一章节讨论了在其他地方详细阐述的概念时，引用会引导你找到相关材料。这种相互关联的结构反映了AI三角形框架的现实：机器学习系统工程需要理解数据、算法和基础设施如何相互作用，而不是孤立地研究它们。
- en: For more detailed information about the book’s learning outcomes, target audience,
    prerequisites, and how to maximize your experience with this resource, please
    refer to the [About the Book](ch003.xhtml#about-the-book) section, which also
    provides details about our learning community and additional resources.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解本书的学习成果、目标受众、先决条件和如何最大化利用此资源，请参阅[关于本书](ch003.xhtml#about-the-book)部分，该部分还提供了关于我们的学习社区和额外资源的详细信息。
- en: 'This introduction has established the conceptual foundation for everything
    that follows. We began by understanding the relationship between artificial intelligence
    as vision and machine learning as methodology. We defined machine learning systems
    as the artifacts we build: integrated computing systems comprising data, algorithms,
    and infrastructure. Through the Bitter Lesson and AI’s historical evolution, we
    discovered why systems engineering has become fundamental to AI progress and how
    learning-based approaches came to dominate the field. This context enabled us
    to formally define AI Engineering as a distinct discipline, following the pattern
    of Computer Engineering’s emergence, establishing it as the field dedicated to
    building reliable, efficient, and scalable machine learning systems across all
    computational platforms.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本介绍为后续内容建立了概念基础。我们首先理解了人工智能作为愿景与机器学习作为方法论之间的关系。我们将机器学习系统定义为我们所构建的工件：由数据、算法和基础设施组成的集成计算系统。通过痛苦的教训和人工智能的历史演变，我们发现了系统工程为何成为人工智能进步的基础，以及基于学习的方法如何成为该领域的支配力量。这种背景使我们能够正式定义人工智能工程作为一个独立的学科，遵循计算机工程出现的模式，将其确立为致力于在所有计算平台上构建可靠、高效和可扩展的机器学习系统的领域。
- en: The journey ahead explores each pillar of AI Engineering systematically, providing
    both conceptual understanding and practical techniques for building production
    ML systems. The challenges we’ve identified—silent performance degradation, data
    drift, model complexity, operational overhead, ethical concerns—recur throughout
    these chapters, but now with specific engineering solutions grounded in real-world
    experience and best practices.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的旅程系统地探讨了人工智能工程的每个支柱，提供了对构建生产级机器学习系统的概念理解和实用技术。我们识别出的挑战——无声的性能退化、数据漂移、模型复杂性、运营开销、伦理问题——贯穿于这些章节，但现在有了基于实际经验和最佳实践的特定工程解决方案。
- en: Welcome to AI Engineering.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到人工智能工程。
- en: '* * *'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
