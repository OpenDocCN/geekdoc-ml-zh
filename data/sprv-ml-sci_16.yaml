- en: 10  Causality
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10  因果关系
- en: 原文：[https://ml-science-book.com/causality.html](https://ml-science-book.com/causality.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ml-science-book.com/causality.html](https://ml-science-book.com/causality.html)
- en: '[Integrating Machine Learning Into Science](./part-two.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[将机器学习融入科学](./part-two.html)'
- en: '[10  Causality](./causality.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[因果关系](./causality.html)'
- en: 'Machine learning exploits all available information to make predictions – and
    there are many ways to predict things. A good example of this is assessing a person’s
    COVID risk. You can predict it from features such as:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习利用所有可用信息进行预测——有无数种预测事物的方法。一个很好的例子是评估一个人的COVID风险。你可以从以下特征中预测它：
- en: wearing a mask
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 戴口罩
- en: symptoms like dry cough
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像干咳这样的症状
- en: vitamin D levels
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维生素D水平
- en: From a causal perspective, these features relate differently to the COVID risk.
    This difference is illustrated in the so-called *causal graph* below, which is
    a graphical tool for thinking about causal dependencies.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从因果角度来看，这些特征与COVID风险的关系不同。这种差异在下图的所谓*因果图*中得到说明，这是一种用于思考因果依赖关系的图形工具。
- en: '![](../Images/d9849ad0150ca072cb94716dd6b44d48.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9849ad0150ca072cb94716dd6b44d48.png)'
- en: '**Causes:** Wearing a mask is a causal factor for the COVID risk. Why is it
    a cause? Well, those who put on a mask can thereby lower their COVID risk [[1]](references.html#ref-howard2021evidence).
    The fact that masks are causal for COVID risk is highlighted by the outgoing arrow
    from the mask node to the COVID node.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原因：** 戴口罩是COVID风险的因果因素。为什么它是原因？好吧，那些戴口罩的人可以因此降低他们的COVID风险 [[1]](references.html#ref-howard2021evidence)。口罩对COVID风险的因果作用通过从口罩节点到COVID节点的出向箭头得到强调。'
- en: '**Effects:** Dry cough is an effect of COVID [[2]](references.html#ref-alimohamadi2020determine).
    People who are healthy and then get infected with COVID likely get dry cough as
    a symptom. Importantly, it is not a cause of COVID – if people take cough sirup
    this may help against their cough but does not change their COVID risk. The fact
    that dry coughing is an effect of COVID is highlighted by the incoming arrow to
    the cough node from the COVID node.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效果：** 干咳是COVID的一种效果 [[2]](references.html#ref-alimohamadi2020determine)。那些原本健康然后感染COVID的人可能会出现干咳作为症状。重要的是，它不是COVID的原因——如果人们服用止咳药水，这可能有助于缓解他们的咳嗽，但不会改变他们的COVID风险。干咳是COVID效果的强调通过从COVID节点到咳嗽节点的入向箭头。'
- en: '**Associations:** Vitamin D levels are associated with COVID risk [[3]](references.html#ref-d2022vitamin).
    For example, in the overall population, people with higher vitamin D levels less
    often get COVID than people with low vitamin D levels. Still, it is unclear if
    higher vitamin D levels cause a lower COVID risk or if the association arises
    for entirely different reasons. The unexplained association between vitamin D
    levels and COVID is highlighted by an undirected dashed arrow.[¹](#fn1)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联性：** 维生素D水平与COVID风险相关 [[3]](references.html#ref-d2022vitamin)。例如，在总体人群中，维生素D水平较高的人比维生素D水平较低的人更少感染COVID。然而，尚不清楚较高的维生素D水平是否会导致较低的COVID风险，或者这种关联是否由完全不同的原因引起。维生素D水平与COVID之间的未解释关联通过一个无向的虚线箭头得到强调。[¹](#fn1)'
- en: 'Initially, there was a lot of hype about machine learning in Raven Medicine.
    Some even proclaimed the end of costly medical experiments. But the enthusiasm
    soon waned: Machine learning provided little insight into how to treat Ravens
    to make them healthy. Was the red pill or the blue pill more effective? The old
    proverb “correlation is not causation” hit the machine learning enthusiasts hard.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，在Raven医学中关于机器学习的炒作很多。有些人甚至宣称昂贵医疗实验的终结。但热情很快消退：机器学习在如何治疗Ravens以使其健康方面提供了很少的见解。红色药丸或蓝色药丸哪个更有效？古老的谚语“相关性不等于因果性”对机器学习爱好者产生了强烈的影响。
- en: '![](../Images/f0a114295bfd0436fd7a196513a13a93.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0a114295bfd0436fd7a196513a13a93.png)'
- en: 10.1 Prediction does not require causal understanding
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 预测不需要因果理解
- en: 'All the features we have just listed can be equally helpful in predicting COVID
    risk with machine learning. You may decide to rely only on causes or only on effects:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚列出的所有特征都可以在预测COVID风险时通过机器学习同等有帮助。你可以选择只依赖原因或只依赖效果：
- en: '**Predict effects from causes:** An example is the protein folding problem
    discussed at the beginning, where the amino acid sequence causally determines
    the protein structure [[5]](references.html#ref-scholkopf2012causal).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从原因预测效果：** 一个例子是开头讨论的蛋白质折叠问题，其中氨基酸序列因果决定了蛋白质结构 [[5]](references.html#ref-scholkopf2012causal)。'
- en: '**Predict causes from effects:** An example is predicting the presence of a
    black hole from its gravitational effects on the surrounding bodies.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从效果预测原因：**一个例子是从黑洞对其周围天体的引力效应预测黑洞的存在。'
- en: '**Mixed prediction:** This is probably the most common case. An example is
    medical diagnosis. To diagnose malaria, doctors take into account symptoms like
    high fever but at the same time causes such as a mosquito bite from your South
    America travels.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合预测：**这可能是最常见的情况。一个例子是医学诊断。为了诊断疟疾，医生会考虑高烧等症状，同时也会考虑原因，比如来自南美洲的蚊子叮咬。'
- en: In the end, it is your decision as a modeler what you want to incorporate in
    your prediction model, whether it is causes, effects, causes of effects, or even
    spurious associations. For the machine learning model to successfully predict,
    all that matters is that the feature contains information about the target variable.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，作为模型构建者，你决定在预测模型中包含什么，无论是原因、效果、效果的起因，甚至是虚假的关联。对于机器学习模型能够成功预测，重要的是特征中包含有关目标变量的信息。
- en: 10.2 Costly experiments distinguish causes from effects
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 费用高昂的实验区分原因和效果
- en: 'Controlled experiments are the best approach to distinguish between causes
    and effects. Let’s say you have two variables, vitamin D and COVID. To establish
    whether higher vitamin D levels reduce the COVID risk, you could run a *randomized
    control trial (RCT)*. You have 10,000 test subjects: 5,000 *randomly* selected
    subjects belong to the treatment group (they get vitamin D supplements); the other
    5,000 belong to the control group (they get placebos). If after a certain time,
    the COVID infections in the treatment group are significantly lower than in the
    control group, you can conclude that vitamin D is a causal factor for COVID risk.
    Easy, right?!'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 控制实验是区分原因和效果的最佳方法。假设你有两个变量，维生素D和COVID。为了确定更高的维生素D水平是否能降低COVID风险，你可以进行一个*随机对照试验（RCT）*。你有10,000名测试对象：5,000名*随机*选择的受试者属于治疗组（他们获得维生素D补充剂）；其余5,000名属于对照组（他们获得安慰剂）。如果在一定时间后，治疗组的COVID感染率显著低于对照组，你可以得出结论，维生素D是COVID风险的因果因素。简单，对吧?!
- en: Unfortunately, conducting controlled experiments in the real world is cumbersome.
    It takes a lot of time, money, and resources. Some experiments can be ethically
    or legally problematic, such as the administration of harmful drugs to humans.
    Other experiments are beyond the capabilities of humans – like investigating the
    effects of pushing Jupiter out of its solar trajectory – you’d need to be as strong
    as Saitama [²](#fn2) for that…
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在现实世界中进行控制实验是繁琐的。它需要大量的时间、金钱和资源。有些实验在伦理或法律上可能存在问题，例如向人类施用有害药物。其他实验超出了人类的范围——比如调查将木星推出其太阳轨道的影响——你需要像埼玉一样强大
    [²](#fn2) 才能完成这项任务...
- en: Social scientists, in particular, often deal with *observational data*. Observational
    data is data that is measured without controlled conditions. Like asking random
    people on the streets for their vitamin D levels and if they had COVID. Observational
    data is what we gather all the time – the little measuring device in your pocket
    is piling up tons of it.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 社会科学家，尤其是，经常处理*观察数据*。观察数据是在没有控制条件下测量的数据。比如询问街上随机的人他们的维生素D水平以及他们是否患有COVID。观察数据是我们一直在收集的——你口袋里的小测量设备正在积累大量的数据。
- en: 10.3 Machine learning can generate causal insights
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 机器学习可以生成因果洞察
- en: Observational data is what you are likely feeding your machine learning algorithm.
    Unfortunately, observational data alone does not provide causal insight [[6]](references.html#ref-pearl2018book).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 观察数据很可能是你提供给机器学习算法的。不幸的是，仅凭观察数据本身并不提供因果洞察 [[6]](references.html#ref-pearl2018book)。
- en: '*Insight* *It is impossible to distinguish causes from effects from observational
    data alone [[6]](references.html#ref-pearl2018book).*  *If you cannot even distinguish
    between causes and effects from observational data alone, how can machine learning
    help with causality? It turns out that machine learning can help with causal inference
    (answering causal questions with the help of data), but usually not for free:
    You have to make assumptions about causal structures.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*洞察* *仅凭观察数据无法区分原因和效果 [[6]](references.html#ref-pearl2018book)。* *如果你连仅凭观察数据都无法区分原因和效果，那么机器学习如何帮助因果推断呢？事实证明，机器学习可以帮助进行因果推断（借助数据回答因果问题），但通常并非免费：你必须对因果结构做出假设。'
- en: 'These are the causal questions that machine learning can help with:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是机器学习可以帮助解决的因果关系问题：
- en: '**Studying associations to form causal hypotheses:** Machine learning helps
    to investigate associations in data such as the association between COVID and
    vitamin D levels, which can be the starting point for causal hypothesizing.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究关联以形成因果关系假设**：机器学习有助于调查数据中的关联，例如COVID与维生素D水平之间的关联，这可以是因果关系假设的起点。'
- en: '**Estimating causal effects:** Machine learning can be used to estimate causal
    effects, such as quantifying the effect of vitamin D on the COVID risk.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**估计因果关系**：机器学习可以用来估计因果关系，例如量化维生素D对COVID风险的影响。'
- en: '**Learning causal models:** You can use machine learning to learn causal models.
    Causal models are formal tools to reason about real-world interventions and counterfactual
    scenarios.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习因果关系模型**：您可以使用机器学习来学习因果关系模型。因果关系模型是推理现实世界干预和反事实情景的正式工具。'
- en: '**Learning causal graphs:** Causal graphs encode the direction of causal relationships,
    and machine learning can help learn them directly from data.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习因果关系图**：因果关系图编码了因果关系的方向，机器学习可以帮助直接从数据中学习它们。'
- en: '**Learning causal representations:** Machine learning can learn causal variables,
    which are high-level representations (e.g. objects) of low-level inputs (e.g. pixels).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习因果关系表示**：机器学习可以学习因果关系变量，这些是低级输入（例如像素）的高级表示（例如对象）。'
- en: These five tasks structure the rest of this chapter.*  *## 10.4 Studying associations
    to form causal hypotheses
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这五个任务构成了本章的其余部分结构。*  *## 10.4 通过研究关联形成因果关系假设
- en: You may have heard that machine learning models are capturing complex associations
    in data. But what are associations? It is easiest to understand associations by
    their opposite, namely statistical independence. Two events are independent if
    knowing one event is uninformative about the other, e.g. knowing about your COVID
    risk does not tell anything about the weather on the planet Venus. More formally,
    two features \(A\) and \(B\) are *statistically independent* if \(\mathbb{P}(A\mid
    B)=\mathbb{P}(A)\). We call two features *associated* whenever they are not statistically
    independent. For example, COVID risk is associated with wealth. Statistically,
    the higher your wealth the lower your COVID risk [[7]](references.html#ref-gong2022wealth).
    But be careful, associations are complex creatures. For example, wealthier venders
    are likely to have a higher COVID risk than poor venders because they have contact
    with more customers. This is called an *interaction effect*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过机器学习模型正在捕捉数据中的复杂关联。但什么是关联？通过它们的对立面，即统计独立性，最容易理解关联。如果知道一个事件对另一个事件没有信息，则两个事件是独立的，例如，知道你的COVID风险并不能告诉你金星上的天气。更正式地说，如果两个特征
    \(A\) 和 \(B\) 是 *统计独立的*，则 \(\mathbb{P}(A\mid B)=\mathbb{P}(A)\)。当两个特征不是统计独立时，我们称它们为
    *关联的*。例如，COVID风险与财富相关。统计上，你的财富越高，你的COVID风险越低 [[7]](references.html#ref-gong2022wealth)。但请注意，关联是复杂的生物。例如，较富裕的卖家可能比贫穷的卖家有更高的COVID风险，因为他们与更多客户有接触。这被称为
    *交互效应*。
- en: 'Like classical statistical techniques, machine learning together with interpretability
    methods (see [Chapter 9](interpretability.html)) enables you to read out complex
    properties of your data. You can for example study:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与经典统计技术一样，机器学习结合可解释性方法（见第9章[interpretability.html]）使您能够读取数据的复杂属性。例如，您可以研究：
- en: '**Feature effects & interactions:** How is the target associated with certain
    input features?'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征效应与交互作用**：目标是如何与某些输入特征相关联的？'
- en: '**Feature importance:** How much do certain features contribute to the prediction
    of the target?'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征重要性**：某些特征对目标预测的贡献有多大？'
- en: '**Attention:** What features is our model listening to when predicting the
    target?'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意**：当预测目标时，我们的模型在听哪些特征？'
- en: 10.4.1 Form causal hypotheses with the Reichenbach principle
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.1 使用赖因哈特原理形成因果关系假设
- en: 'Assume you find in your data the association between vitamin D and the COVID
    risk. Then, the **Reichenbach principle** can guide you in forming a causal hypothesis.
    The principle states three possibilities where the association can come from [[8]](references.html#ref-sep-physics-Rpcc):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在你的数据中发现了维生素D与COVID风险之间的关联。那么，**赖因哈特原理**可以指导你形成因果关系假设。该原理指出三种可能的关联来源 [[8]](references.html#ref-sep-physics-Rpcc)：
- en: Vitamin D can be a cause of COVID.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 维生素D可能是COVID的原因。
- en: '![](../Images/09895202d28297e5abf0b48d1a57531b.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09895202d28297e5abf0b48d1a57531b.png)'
- en: COVID can be a cause of vitamin D.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: COVID可以是维生素D的**原因**。
- en: '![](../Images/d525ce89882804721623f3cb2721197e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/d525ce89882804721623f3cb2721197e.png)'
- en: Or, there is a common cause \(Z\) of both, vitamin D and COVID.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 或者，维生素D和COVID都有共同的**原因** \(Z\)。
- en: '![](../Images/601366aea4e96d9ed42b420b0ed3e30f.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/601366aea4e96d9ed42b420b0ed3e30f.png)'
- en: 'Nothing against Reichenbach, but in reality, there are two more explanations
    for the association:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 并非针对Reichenbach，但在现实中，还有两个解释可以解释这种关联：
- en: First, the association can be *spurious*. It is only there because of limited
    data. If you continue gathering data, the association will vanish. [Figure 10.1](#fig-spurious)
    shows an almost perfect association between worldwide non-commercial space launches
    and the number of doctorates awarded in sociology [[9]](references.html#ref-vigen2015spurious).
    But is it causal? Perhaps Elon Musk can boost his business by awarding a few PhD
    scholarships in sociology…
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，这种关联可能是**虚假的**。它仅仅是因为数据有限而存在。如果你继续收集数据，这种关联将会消失。[图10.1](#fig-spurious)显示了全球非商业太空发射次数与授予的社会学博士学位数量之间几乎完美的关联
    [[9]](references.html#ref-vigen2015spurious)。但这是否是因果关系？也许Elon Musk可以通过在社会学领域授予几个博士奖学金来提升他的业务…
- en: Second, the association can result from a *selection bias* in the data collection
    process. It occurs if the data sample is not representative of the overall population.
    For example, while niceness and handsomeness are probably statistically independent
    traits in the overall population, they can become dependent if you only look at
    people you would date [[10]](references.html#ref-ellenberg2014not).
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，这种关联可能源于数据收集过程中的*选择偏差*。如果数据样本不能代表总体人群，就会发生这种情况。例如，虽然善良和英俊在总体人群中可能是统计上独立的特征，但如果你只看那些你可能会与之约会的人
    [[10]](references.html#ref-ellenberg2014not)，它们可能会变得相关。
- en: '![](../Images/8aee4a295d94e5e9aa7d5fa8c311d67e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8aee4a295d94e5e9aa7d5fa8c311d67e.png)'
- en: 'Figure 10.1: There is an almost perfect association between the worldwide non-commercial
    space launches and the number of sociology doctorates awarded. Chart by Tyler
    Vigen, CC-BY (https://creativecommons.org/licenses/by/4.0/)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：全球非商业太空发射次数与授予的社会学博士学位数量之间几乎存在完美的关联。图表由Tyler Vigen制作，CC-BY（https://creativecommons.org/licenses/by/4.0/）
- en: But how to identify the correct explanation for the association between COVID
    and vitamin D? Because there is a lot of data (not spurious) and the association
    is found in the overall population (no selection bias), you may infer that one
    of Reichenbach’s three cases applies. Gibbons et al. [[11]](references.html#ref-gibbons2022association)
    compared a large group of veterans receiving different vitamin D supplementations
    to a group without treatment. They found that the treatment with vitamin D reduces
    the risk of getting COVID significantly and therefore recommend broad supplementation.
    Even though the study was not a randomized control trial, it strongly indicates
    that there is a causal link between vitamin D levels and COVID risk.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但如何确定COVID和维生素D之间关联的正确解释呢？因为有很多数据（并非虚假数据）并且这种关联在总体人群中被发现（没有选择偏差），你可以推断Reichenbach的三个案例之一适用。Gibbons等人
    [[11]](references.html#ref-gibbons2022association)比较了一组接受不同维生素D补充剂的老兵与一组未接受治疗的人。他们发现维生素D治疗显著降低了感染COVID的风险，因此建议广泛补充。尽管这项研究不是随机对照试验，但它强烈表明维生素D水平和COVID风险之间存在因果关系。
- en: '![](../Images/09895202d28297e5abf0b48d1a57531b.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/09895202d28297e5abf0b48d1a57531b.png)'
- en: 'The scientific story may continue at that point: There might be unknown common
    causes of both vitamin D and COVID risk. Moreover, the causal link does not explain
    by what mechanism in the body vitamin D acts on COVID risk. That’s how science
    works, new questions keep popping up…'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 科学故事可能在那一点继续：维生素D和COVID风险可能存在未知的共同原因。此外，因果联系并不能解释维生素D在身体上如何作用于COVID风险。这就是科学工作的方式，新的问题不断涌现…
- en: 10.4.2 Select explanatory variables with feature importance
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.2 选择具有特征重要性的解释变量
- en: '*Importances* of features primarily allow you to evaluate which features are
    most informative for predicting the target. For example, they may tell you whether
    vitamin D levels contain any information about your COVID risk beyond the information
    that is already contained in the mask and the cough features. But importance itself
    gives no causal insight. It can still be useful for a causal analysis: importance
    allows you to understand what information is redundant, noisy, or just unnecessary.
    This may prove helpful in selecting sparse and robust features for a causal analysis
    [[12]](references.html#ref-yu2020causality).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 特征的*重要性*主要允许你评估哪些特征对预测目标最有信息量。例如，它们可能会告诉你维生素D水平是否包含关于你的COVID风险的信息，这些信息超出了口罩和咳嗽特征中已经包含的信息。但重要性本身并不提供因果洞察。它仍然可以用于因果分析：重要性允许你了解哪些信息是冗余的、嘈杂的或是不必要的。这可能在选择用于因果分析的稀疏和鲁棒特征时有所帮助[[12]](references.html#ref-yu2020causality)。
- en: 'Imagine you know a person’s age, country of origin, gender, favorite color,
    and favorite band. You want to predict again her COVID risk. By studying feature
    importance, you may find out that:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你了解一个人的年龄、国籍、性别、最喜欢的颜色和最喜欢的乐队。你想再次预测她的COVID风险。通过研究特征重要性，你可能会发现：
- en: The favorite color has very little importance under all constellations. It might
    even have negative importance as it introduces noise.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有情况下，最喜欢的颜色的重要性都很小。它甚至可能具有负重要性，因为它引入了噪声。
- en: The favorite band is extremely informative. You can even drop all other features
    without a major loss in predictive performance.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最喜欢的乐队具有极高的信息量。即使去掉所有其他特征，也不会对预测性能造成重大损失。
- en: If you know the age, country of origin, and gender of a person, knowing her
    favorite band does not add much.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你了解一个人的年龄、国籍和性别，知道她的最喜欢的乐队并不会增加多少。
- en: Depending on your goal, this can be very insightful. You can generally drop
    the favorite color feature, it is not predictive and will not provide insights
    for a causal analysis. If you want to reason about policy interventions to lower
    the COVID risk, you can exclude the favorite band from your causal analysis. If,
    on the other hand, you are a sociologist who wants to study how taste in music
    is related to health, you may want to keep all features.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的目标，这可能会非常有见地。通常情况下，你可以去掉最喜欢的颜色这一特征，因为它不具有预测性，也不会为因果分析提供洞察。如果你想推理降低COVID风险的政策干预措施，你可以从因果分析中排除最喜欢的乐队。另一方面，如果你是一位想要研究音乐品味与健康之间关系的
    sociologist，你可能希望保留所有特征。
- en: '![](../Images/4a936296dba52672b5d3879588ea2fcc.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/4a936296dba52672b5d3879588ea2fcc.png)'
- en: 10.4.3 Find high-level variables with attention
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.3 使用注意力寻找高级变量
- en: The question of what a model is attending to in its decisions is prominent in
    interpretability research, particularly in image classification [[13]](references.html#ref-adebayo2018sanity).
    Although scientists may be more concerned with the relationship in the data than
    in the model, model attention may still be relevant if the input features have
    meaning only in the aggregate, not individually. Think of pixels that constitute
    images, letters that constitute sentences, or frequencies that constitute sounds.
    Attention can point you to meaningful constructs or subparts that are associated
    with the target and allow you to form causal hypotheses about them.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在可解释性研究中，模型在其决策中关注什么的问题非常突出，尤其是在图像分类[[13]](references.html#ref-adebayo2018sanity)中。尽管科学家可能更关注数据中的关系而不是模型，但如果输入特征只有整体上有意义，而不是单独有意义，模型注意力仍然可能相关。想想构成图像的像素、构成句子的字母或构成声音的频率。注意力可以指向与目标相关的有意义的结构或子部分，并允许你形成关于它们的因果假设。
- en: For example, while predicting COVID from CT scans sounds like taking a sledgehammer
    to crack a nut, it can be an interesting approach to learning more about how the
    disease affects the human body. Even though the input features themselves are
    pixels, they collectively form higher-level concepts that can be highlighted by
    saliency-based interpretability techniques. This approach was for example used
    by [[14]](references.html#ref-hu2020weakly) to detect lesions in the lungs of
    COVID patients as illustrated in [Figure 10.2](#fig-lesions).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，虽然从CT扫描中预测COVID听起来像是用大锤砸核桃，但这可以是一种了解疾病如何影响人体有趣的方法。尽管输入特征本身是像素，但它们共同构成了可以由基于显著性的可解释技术突出的更高层次的概念。例如，这种方法被[[14]](references.html#ref-hu2020weakly)用于检测COVID患者的肺部病变，如[图10.2](#fig-lesions)所示。
- en: '![](../Images/5ff5d7bb631e9fa2190c3a0cd3c37b73.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5ff5d7bb631e9fa2190c3a0cd3c37b73.png)'
- en: 'Figure 10.2: Lesions in CT scans of lungs detected with integrated gradients,
    small in green, mixed in yellow, large in red. Figure by [[14]](references.html#ref-hu2020weakly),
    CC-BY (https://creativecommons.org/licenses/by/4.0/)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：使用集成梯度检测到的肺部CT扫描中的病变，小的用绿色表示，混合的用黄色表示，大的用红色表示。图源[[14]](references.html#ref-hu2020weakly)，CC-BY
    (https://creativecommons.org/licenses/by/4.0/)
- en: 10.5 Estimating causal effects with machine learning
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 使用机器学习估计因果效应
- en: So far, we have assumed that researchers are searching in the dark, where they
    use machine learning to find interesting associations to form and test causal
    hypotheses. However, often researchers have causal knowledge or intuitions about
    how features relate to each other. Their goal is causal inference, or, to be more
    precise, to estimate causal effects, which is a more well-defined problem than
    just exploring associations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们假设研究人员在黑暗中寻找，他们使用机器学习来寻找有趣的关联以形成和测试因果假设。然而，研究人员通常对特征之间的关系有因果知识或直觉。他们的目标是因果推断，或者更准确地说，是估计因果效应，这比仅仅探索关联是一个更明确的问题。
- en: 'Causal graphs show causal dependencies, e.g. if you put on a mask, it will
    causally affect your COVID risk. But this begs the question of **how** it affects
    your risk. Is wearing a mask lowering your COVID risk and if yes, by how much?
    This question asks for a *causal effect*. Questions for causal effects were omnipresent
    during the pandemic:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 因果图显示了因果关系，例如，如果你戴上口罩，它将因果地影响你的COVID风险。但这引发了一个问题：**如何**影响你的风险。戴口罩是否会降低你的COVID风险，如果是的话，降低多少？这个问题要求一个*因果关系*。在疫情期间，关于因果效应的问题无处不在：
- en: How does vaccination affect the COVID risk of elderly people?
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 疫苗接种如何影响老年人的COVID风险？
- en: How does the average COVID risk change with contact restrictions compared to
    without them?
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与没有限制接触相比，平均COVID风险如何随着接触限制而变化？
- en: How does treatment with vitamin D pills lower the COVID risk of African Americans
    [[11]](references.html#ref-gibbons2022association)?
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维生素D药片的治疗如何降低非洲裔美国人的COVID风险[[11]](references.html#ref-gibbons2022association)？
- en: 'Causal effects always have the same form. You compare a variable of interest
    such as COVID risk *with treatment*, for example, masks, against those *without
    treatment* (no-mask). This gives us the so-called *Average Treatment Effect* (ATE).
    In the case of masks being the treatment, we can formally describe the effect
    on the COVID risk:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因果效应总是具有相同的形式。你比较一个感兴趣的变量，例如COVID风险*与治疗*（例如，口罩），与那些*未接受治疗*（不戴口罩）的人。这给我们带来了所谓的*平均治疗效应*（ATE）。在口罩作为治疗的情况下，我们可以正式描述对COVID风险的影响：
- en: \[\text{ATE}=\mathbb{E}[\text{COVID}\mid do(\text{mask}=1)] - \mathbb{E}[\text{COVID}\mid
    do(\text{mask}=0)]\]
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{ATE}=\mathbb{E}[\text{COVID}\mid do(\text{mask}=1)] - \mathbb{E}[\text{COVID}\mid
    do(\text{mask}=0)]\]
- en: Let’s unpack this formula. The *do* in the ATE denotes the do-operator, which
    means you intervene on a variable and set it to a certain value. Thus, the first
    term describes the expected COVID risk if you force people to wear masks. The
    second term describes the expected COVID risk if you force people not to wear
    masks. The difference between the two terms describes the causal effect of masks
    on the COVID risk.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来分解这个公式。ATE中的*do*表示do运算符，这意味着你干预一个变量并将其设置为某个特定值。因此，第一个术语描述了强制人们戴口罩时的预期COVID风险。第二个术语描述了强制人们不戴口罩时的预期COVID风险。这两个术语之间的差异描述了口罩对COVID风险的因果效应。
- en: 'In many cases, rather than asking for the ATE, you ask for the treatment effect
    for a specific subgroup of people that share certain characteristics. During the
    pandemic, for example, researchers might have asked about the causal effect of
    masks for children under 10 years of age. This is the so-called *Conditional Average
    Treatment Effect* (CATE):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你不会要求ATE，而是要求具有某些特定特征的人群的特定子组的治疗效应。例如，在疫情期间，研究人员可能会询问10岁以下儿童的口罩的因果效应。这就是所谓的*条件平均治疗效应*（CATE）：
- en: \[\begin{align*} \text{CATE} &= \mathbb{E}[\text{COVID} \mid do(\text{mask}=1),
    \text{age}<10] \\ &\quad - \mathbb{E}[\text{COVID} \mid do(\text{mask}=0), \text{age}<10]
    \end{align*}\]
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \text{CATE} &= \mathbb{E}[\text{COVID} \mid do(\text{mask}=1),
    \text{age}<10] \\ &\quad - \mathbb{E}[\text{COVID} \mid do(\text{mask}=0), \text{age}<10]
    \end{align*}\]
- en: The *do()* terms in the two formulas give the impression that you have to run
    controlled experiments to estimate the causal effects. And conducting experiments
    would be the most reliable way – if you can do it, you should! Unfortunately,
    experiments are sometimes not feasible. In some situations, you are lucky because
    you can estimate the ATE and CATE from observational data alone. If this is the
    case, the causal effect is *identifiable*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 两个公式中的*do()*项给人一种印象，即你必须运行受控实验来估计因果效应。进行实验将是最可靠的方式——如果你能做，你应该！不幸的是，有时实验是不可行的。在某些情况下，你很幸运，因为你可以仅从观察数据中估计ATE和CATE。如果是这种情况，因果效应是*可识别的*。
- en: 10.5.1 Identify causal effects with the backdoor criterion
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 使用后门准则识别因果关系
- en: 'The classical way to identify a causal effect is via the so-called *backdoor
    criterion*. The idea is simple. Let’s say you want to know the ATE of masks on
    the COVID risk. You only have observational data. But your data allows you to
    read out: 1\. how many people with masks got infected and 2\. how many people
    without masks got infected. Just subtract the latter from the former and you are
    finished, right? No! The problem is that the information you want to obtain is
    potentially blurred by other factors. For example:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 识别因果效应的经典方式是通过所谓的*后门准则*。这个想法很简单。假设你想知道口罩对COVID风险的ATE。你只有观察数据。但你的数据允许你读出：1. 戴口罩的人数感染了多少，2.
    不戴口罩的人数感染了多少。只是从后者减去前者就结束了，对吗？不！问题是，你想要获得的信息可能被其他因素模糊化。例如：
- en: '**Sticking to the rules:** People who stick to the rules are more likely to
    wear masks and also follow other rules like contact restrictions. Therefore, they
    also have on average a lower COVID risk.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遵守规则：** 遵守规则的人更有可能戴口罩，并遵循其他规则，如接触限制。因此，他们平均而言的COVID风险也较低。'
- en: '**Number of contacts:** People who have many contacts (e.g. postmen, salespeople,
    or doctors) wear masks to lower their own risk and the COVID risk of others. But
    many contacts increase also their COVID risk.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**接触次数：** 有很多接触的人（例如邮递员、销售人员或医生）戴口罩以降低自己的风险以及他人的COVID风险。但很多接触也会增加他们的COVID风险。'
- en: '**Age:** Younger people are less likely to wear masks because they think masks
    do not look cool or because COVID is less dangerous for young people. At the same
    time, young people are more resistant to getting infected with COVID [[15]](references.html#ref-fischer2020resistance).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**年龄：** 年轻人不太可能戴口罩，因为他们认为口罩看起来不酷，或者因为COVID对年轻人来说不那么危险。同时，年轻人对感染COVID的抵抗力更强
    [[15]](references.html#ref-fischer2020resistance)。'
- en: 'Those factors are called *confounders*. They are both a cause of the treatment
    and the variable of interest. Imagine you knew all those confounders and accounted
    for them. Then, you could isolate the association that is solely due to the masks
    themselves. This is exactly what the backdoor criterion is doing. If you know
    all confounders \(W\), the ATE can be estimated by:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素被称为*混杂因素*。它们既是治疗的原因，也是感兴趣变量的原因。想象一下，如果你知道所有这些混杂因素并考虑了它们，那么你就可以隔离出仅由口罩本身引起的关联。这正是后门准则所做的事情。如果你知道所有混杂因素
    \(W\)，ATE可以通过以下方式估计：
- en: \[\begin{align*} \text{ATE} &= \mathbb{E}_W[\mathbb{E}_{\text{COVID}\mid W}[\text{COVID}
    \mid \text{mask}=1, W]] \\ &\quad - \mathbb{E}_W[\mathbb{E}_{\text{COVID} \mid
    W}[\text{COVID} \mid \text{mask}=0, W]] \end{align*}\]
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \text{ATE} &= \mathbb{E}_W[\mathbb{E}_{\text{COVID}\mid W}[\text{COVID}
    \mid \text{mask}=1, W]] \\ &\quad - \mathbb{E}_W[\mathbb{E}_{\text{COVID} \mid
    W}[\text{COVID} \mid \text{mask}=0, W]] \end{align*}\]
- en: A great success, there are no do-terms left. But be aware that knowledge of
    all confounders is a super strong requirement that can rarely ever be met in reality.
    And not knowing a confounder may bias your estimate significantly. The same happens
    if you mistake a variable for a confounder that is caused by both the treatment
    and the variable of interest (this is called a *collider bias*). So conditioning
    on more features is not always better.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一个巨大的成功，没有剩余的do-terms。但请注意，对所有混杂因素的了解是一个超级强烈的要求，在现实中很少能够满足。而且不知道一个混杂因素可能会显著地偏差你的估计。如果你错误地将一个变量误认为是由于治疗和感兴趣变量共同引起的混杂因素（这被称为*碰撞偏差*），也会发生同样的事情。所以基于更多特征的条件并不总是更好的。
- en: The back-door criterion is not the only option to identify causal effects. There
    is for example also its friendly sibling, the *frontdoor criterion*. Both, the
    front and the backdoor criterion are special cases of the do-calculus. Whenever
    it is possible to identify a causal effect, you can do so using the do-calculus.
    This book will stay at this surface level on the question of identifiability,
    if you like math and want to dig deeper, check out [[16]](references.html#ref-pearl2009causality).
    The cool thing is, you don’t have to know all of that necessarily to do causal
    analysis. The identification step can be fully automated given a causal graph,
    for example, using the Python package *DoWhy* [[17]](references.html#ref-dowhy).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 后门准则并不是识别因果效应的唯一选择。例如，还有其友好的兄弟，**前门准则**。前门和后门准则都是do-calculus的特殊情况。每当可能识别因果效应时，都可以使用do-calculus来识别。如果你喜欢数学并想深入了解，可以查看[[16]](references.html#ref-pearl2009causality)。酷的是，你不必
    necessarily 知道所有这些才能进行因果分析。给定一个因果图，识别步骤可以完全自动化，例如，使用Python包 *DoWhy* [[17]](references.html#ref-dowhy)。
- en: 'Let’s take a look into two machine learning-based methods that allow for estimating
    causal effects: the T-Learner and Double Machine Learning [³](#fn3). Both are
    designed for the backdoor criterion setting. That means, in both cases, you assume
    that you have observed all confounders \(W\), and your causal graph looks like
    this'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看两种基于机器学习的方法，这些方法允许估计因果效应：T-Learner和双重机器学习[³](#fn3)。两者都设计用于后门准则设置。这意味着，在两种情况下，你假设你已经观察到了所有混杂因素
    \(W\)，你的因果图如下所示
- en: '![](../Images/31aa88212051de02d4fcc0bfdf4dbd20.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/31aa88212051de02d4fcc0bfdf4dbd20.png)'
- en: 10.5.2 How to estimate causal effects with the T-Learner
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.2 如何使用T-Learner估计因果效应
- en: 'The T-Learner is maybe the simplest approach to estimate the ATE (or with slight
    modifications CATE) from observational data. The name T-Learner stems from using
    **t**wo different learners to estimate the ATE. The T-learner uses the formula
    from the backdoor criterion:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: T-Learner可能是从观察数据中估计ATE（或经过轻微修改的CATE）的最简单方法。T-Learner这个名字来源于使用**两个**不同的学习器来估计ATE。T-Learner使用来自后门准则的公式：
- en: \[\begin{align*} \text{ATE} &= \mathbb{E}_W[\underbrace{\mathbb{E}_{\text{COVID}\mid
    W}[\text{COVID} \mid \text{mask}=1, W]}_{\phi_1}] \\ &\quad - \mathbb{E}_W[\underbrace{\mathbb{E}_{\text{COVID}\mid
    W}[\text{COVID} \mid \text{mask}=0, W]}_{\phi_0}] \end{align*}\]
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \text{ATE} &= \mathbb{E}_W[\underbrace{\mathbb{E}_{\text{COVID}\mid
    W}[\text{COVID} \mid \text{mask}=1, W]}_{\phi_1}] \\ &\quad - \mathbb{E}_W[\underbrace{\mathbb{E}_{\text{COVID}\mid
    W}[\text{COVID} \mid \text{mask}=0, W]}_{\phi_0}] \end{align*}\]
- en: 'The T-Learner fits two machine learning models, \(\hat{\phi_0}: \mathcal{W}\rightarrow
    \mathcal{Y}\) and \(\hat{\phi_1}: \mathcal{W}\rightarrow \mathcal{Y}\), where
    \(\hat{\phi_0}\) is estimated only with data where \(\text{mask}=0\) and \(\hat{\phi_1}\)
    with data where \(\text{mask}=1\). The ATE can then be computed by averaging over
    different values of \(W\) via'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 'T-Learner拟合了两个机器学习模型，\(\hat{\phi_0}: \mathcal{W}\rightarrow \mathcal{Y}\) 和
    \(\hat{\phi_1}: \mathcal{W}\rightarrow \mathcal{Y}\)，其中 \(\hat{\phi_0}\) 仅使用 \(\text{mask}=0\)
    的数据估计，而 \(\hat{\phi_1}\) 使用 \(\text{mask}=1\) 的数据估计。然后可以通过对 \(W\) 的不同值进行平均来计算ATE：'
- en: \[\text{ATE}\approx \frac{1}{n}\sum\limits_{i=1}^n \left(\hat{\phi_1}(w_i)-\hat{\phi}_0(w_i)\right).\]
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{ATE}\approx \frac{1}{n}\sum\limits_{i=1}^n \left(\hat{\phi_1}(w_i)-\hat{\phi}_0(w_i)\right).\]
- en: 10.5.3 How to estimate causal effects with Double Machine Learning
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.3 如何使用双重机器学习估计因果效应
- en: 'Double Machine Learning is an improvement over the T-Learner. Not only is the
    name much cooler, but the estimation of the ATE is much more sophisticated [[22]](references.html#ref-chernozhukov2018double).
    The estimate is both unbiased and data-efficient. The estimation process works
    as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 双重机器学习是T-Learner的改进。不仅名字听起来更酷，而且ATE的估计更加复杂[[22]](references.html#ref-chernozhukov2018double)。估计既无偏又数据高效。估计过程如下：
- en: '**Predict outcome & treatment from controls:** Fit a machine learning model
    to predict COVID from the confounders \(W\). This gives you the prediction \(\widehat{\text{COVID}}\).
    Next, fit a machine learning model to predict whether people wear masks or not
    from the confounders \(W\). This gives you the prediction \(\widehat{\text{mask}}\).
    You need to split your data into training and estimation data, the machine learning
    models should be learned only from the training data.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从对照组预测结果与处理：**拟合一个机器学习模型来预测从混淆因子\(W\)的COVID。这给出了预测\(\widehat{\text{COVID}}\)。接下来，拟合一个机器学习模型来预测人们是否戴口罩，从混淆因子\(W\)。这给出了预测\(\widehat{\text{mask}}\)。你需要将你的数据分为训练数据和估计数据，机器学习模型应该只从训练数据中学习。'
- en: '**Estimate outcome residuals from treatment residuals:** Fit a linear regression
    model to predict \(\text{COVID}-\widehat{\text{COVID}}\) from \(\text{mask}-\widehat{\text{mask}}\).
    Then, your estimand of interest is the coefficient \(\beta_1\). Why? Well, surprisingly,
    this coefficient describes the treatment effect. But you need quite some math
    to show this, search for the Frisch-Waugh-Lovell theorem if you want to learn
    more. The linear regression must be fitted on the estimation data not the training
    data for models from step 1.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从处理残差估计结果残差：**拟合一个线性回归模型来预测\(\text{COVID}-\widehat{\text{COVID}}\)从\(\text{mask}-\widehat{\text{mask}}\)。然后，你感兴趣的估计量是系数\(\beta_1\)。为什么？好吧，令人惊讶的是，这个系数描述了处理效应。但你需要相当多的数学来证明这一点，如果你想了解更多，可以搜索Frisch-Waugh-Lovell定理。线性回归必须在估计数据上拟合，而不是在步骤1中的模型训练数据上。'
- en: '**Cross-fitting:** Run steps 1 and 2 again, but this time switch the training
    data you use to fit the machine learning models in step 1 with the estimation
    data you use in step 2 for the linear regression. Average your two estimates \(\hat{\beta_1}^1\)
    and \(\hat{\beta_1}^2\) to obtain your final estimate \(\hat{\beta_1}=(\hat{\beta_1}^1+\hat{\beta_1}^2)/2\).'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**交叉拟合：**再次运行步骤1和2，但这次将步骤1中用于拟合机器学习模型的训练数据与步骤2中用于线性回归的估计数据交换。将你的两个估计值\(\hat{\beta_1}^1\)和\(\hat{\beta_1}^2\)平均，以获得最终估计值\(\hat{\beta_1}=(\hat{\beta_1}^1+\hat{\beta_1}^2)/2\)。'
- en: 'Why does this strange procedure make sense? If you want to get the details,
    check out [[22]](references.html#ref-chernozhukov2018double). The key ideas are:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这个奇怪的过程有意义？如果你想了解细节，请查看[[22]](references.html#ref-chernozhukov2018double)。关键思想是：
- en: You want to get rid of the bias in your estimation that stems from regularization
    in your machine learning model. This is done in steps one and two, exploiting
    the so-called Neyman orthogonality condition.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要消除来自你的机器学习模型正则化中产生的估计偏差。这在一、二步中完成，利用所谓的Neyman正交条件。
- en: You want to get rid of the bias in your estimation that stems from overfitting
    to the data you have and at the same time be data efficient. If you would train
    our machine learning model on the same data on which you estimate the linear coefficient,
    you would introduce an overfitting bias. Splitting the data into training and
    estimation data circumvents this pitfall. However, splitting the data just once
    is less data efficient. Thus, you switch the roles of training and estimation
    data and compute the average in step three.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要消除来自你对现有数据进行过度拟合的估计偏差，同时保持数据效率。如果你会在你估计线性系数的相同数据上训练我们的机器学习模型，你会引入一个过度拟合偏差。将数据分为训练数据和估计数据可以避免这个陷阱。然而，只分割一次数据会降低数据效率。因此，你在第三步中交换训练数据和估计数据的角色，并计算平均值。
- en: If you want to use Double Machine Learning in your research, check out the package
    `DoubleML` in R [[23]](references.html#ref-DoubleML2021R) and Python [[24]](references.html#ref-DoubleML2022Python).
    Generally, there are many more methods now to estimate causal effects with machine
    learning, check out [[25]](references.html#ref-dandl2023causality), [[20]](references.html#ref-Knaus2022)
    or [[21]](references.html#ref-kunzel2019metalearners) to get an overview.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在你的研究中使用双重机器学习，请查看R中的`DoubleML`包[[23]](references.html#ref-DoubleML2021R)和Python中的[[24]](references.html#ref-DoubleML2022Python)。通常，现在有更多方法可以用机器学习来估计因果效应，查看[[25]](references.html#ref-dandl2023causality)、[[20]](references.html#ref-Knaus2022)或[[21]](references.html#ref-kunzel2019metalearners)以获得概述。
- en: 10.6 Learning causal models if we know the causal graph
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 如果我们知道因果图，学习因果模型
- en: 'Causal graphs are simple objects that contain:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因果图包含简单的对象：
- en: '**Nodes:** Describe the features that are interesting to you, like the COVID
    risk, if you wear masks, if you have a dry cough, or your vitamin D levels.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点：**描述对你来说有趣的特征，例如COVID风险、你是否戴口罩、你是否干咳，或者你的维生素D水平。'
- en: '**Arrows:** describe how the features are causally linked. Like the causal
    arrow between COVID risk and dry cough.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**箭头**：描述特征之间的因果联系。例如，COVID风险和干咳之间的因果箭头。'
- en: Usually, you pose two additional assumptions on causal graphs – they should
    be directed and acyclic. Directed means that each arrow has a start node and end
    node, not unlike the dashed arrow in the case of vitamin D in the beginning which
    treats both nodes the same. Acyclic means that it should not be possible to start
    from a node and return to it while only walking along the directed arrows. If
    the graph is directed and acyclic, we talk about a DAG – a directed-acyclic graph.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你在因果图上提出两个额外的假设——它们应该是有向的和无环的。有向意味着每个箭头都有一个起始节点和结束节点，这与开始时维生素D的情况中的虚线箭头不同，它将两个节点视为相同。无环意味着不应该可能从一个节点开始并返回到它，而只需沿着有向箭头行走。如果图是有向和无环的，我们谈论DAG——有向无环图。
- en: So, causal graphs are a tool to reason about causal relations. But wouldn’t
    it be nice to have *causal models*? Models that once they are constructed allow
    you to think about a whole range of questions without always running this whole
    treatment effect estimation process?
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，因果图是推理因果关系的工具。但不是很好有一个*因果模型*？一旦构建了模型，就可以思考一系列问题，而无需总是运行整个治疗效果估计过程？
- en: What is the effect of masks on the COVID risk? How about both masks and contact
    restrictions? What if you only look at older people? Imagine all these questions
    can be answered with one model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 口罩对COVID风险的影响是什么？如果同时考虑口罩和接触限制呢？如果只关注老年人呢？想象一下所有这些问题都可以用一个模型来回答。
- en: 10.6.1 Bayesian causal networks allow to reason about interventions
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.1 贝叶斯因果网络允许进行干预推理
- en: In causal graphs, we talked about the nodes of the graph, like the mask node,
    the COVID node, or the cough node. But how to interpret these nodes specifically?
    The perspective of Causal Bayesian Networks (CBNs) is to see these nodes as random
    variables. If causal graphs are a combination of graphs and causality, CBNs add
    probability theory to the mix.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在因果图中，我们讨论了图中的节点，如口罩节点、COVID节点或咳嗽节点。但如何具体解释这些节点呢？因果贝叶斯网络（CBNs）的视角是将这些节点视为随机变量。如果因果图是图和因果性的结合，CBNs则增加了概率理论。
- en: CBNs allow you to ask classical probabilistic questions, like what is the probability
    that people wear masks if they have a cough \(\mathbb{P}(\text{mask}\mid \text{cough}=1)\).
    But what CBNs are ultimately designed for is answering causal questions about
    interventions. Like what is the average COVID risk if everyone must wear a mask
    \(\mathbb{P}(\text{COVID}\mid do(\text{mask}=1))\)?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: CBNs允许你提出经典概率问题，例如，如果人们咳嗽，他们戴口罩的概率是多少 \(\mathbb{P}(\text{mask}\mid \text{cough}=1)\)。但CBNs最终设计的目的在于回答关于干预的因果问题。例如，如果每个人都必须戴口罩，平均COVID风险是多少
    \(\mathbb{P}(\text{COVID}\mid do(\text{mask}=1))\)？
- en: '![](../Images/ecb8db9924b65d32c163ee3897b1a432.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ecb8db9924b65d32c163ee3897b1a432.png)'
- en: 'Let’s check out this simplified causal graph with only three variables: mask,
    COVID risk, and cough. Mask is causal for COVID risk and COVID is causal for cough.
    In this simple setting, you must specify three things to obtain a CBN:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这个只有三个变量的简化因果图：口罩、COVID风险和咳嗽。口罩是COVID风险的因果因素，COVID是咳嗽的因果因素。在这个简单的情况下，你必须指定以下三个事项来获得一个CBN：
- en: The marginal probability of wearing a mask, i.e. \(\mathbb{P}(\text{mask})\).
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 戴口罩的边际概率，即 \(\mathbb{P}(\text{mask})\)。
- en: The COVID risk for both people who either wear or don’t wear masks, that means
    \(\mathbb{P}(\text{COVID}\mid \text{mask}=0)\) and \(\mathbb{P}(\text{COVID}\mid
    \text{mask}=1)\).
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无论是戴口罩还是不戴口罩的人的COVID风险，这意味着 \(\mathbb{P}(\text{COVID}\mid \text{mask}=0)\) 和
    \(\mathbb{P}(\text{COVID}\mid \text{mask}=1)\)。
- en: The probability of having a cough if the COVID risk is low or high, that means
    \(\mathbb{P}(\text{cough}\mid \text{COVID}=1)\) and \(\mathbb{P}(\text{cough}\mid
    \text{COVID}=0)\).
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果COVID风险低或高时咳嗽的概率，这意味着 \(\mathbb{P}(\text{cough}\mid \text{COVID}=1)\) 和 \(\mathbb{P}(\text{cough}\mid
    \text{COVID}=0)\)。
- en: Let’s look at a toy example. Assume that 50% of people wear masks. Assume the
    COVID risk is 80% low / 20% high if people wear a mask and reversed if people
    do not wear a mask. And, the probability that people have a cough if they have
    a high COVID risk is 90%, and conversely, 10% if they have a low COVID risk.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个玩具示例。假设50%的人戴口罩。假设如果人们戴口罩，COVID风险是80%低/20%高，如果不戴口罩则相反。此外，如果人们有高COVID风险，他们咳嗽的概率是90%，反之，如果他们有低COVID风险，咳嗽的概率是10%。
- en: 'Then, you can ask the following question and address it formally:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以提出以下问题并正式解决它：
- en: '**Observational question:** What is the probability of wearing a mask, having
    a high COVID risk, and not coughing? This can be computed by:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**观察问题**：戴口罩、有高COVID风险且不咳嗽的概率是多少？这可以通过以下方式计算：'
- en: \[\begin{align*} &\mathbb{P}(\text{mask}=1, \text{COVID}=1, \text{cough}=0)
    \\ &=\mathbb{P}(\text{mask}=1) \times \mathbb{P}(\text{COVID}=1 \mid \text{mask}=1)
    \\ & \quad \times \mathbb{P}(\text{cough}=0 \mid \text{COVID}=1) \\ &= 0.5 \times
    0.2 \times 0.1 = 0.01 \end{align*}\]
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\mathbb{P}(\text{mask}=1, \text{COVID}=1, \text{cough}=0)
    \\ &=\mathbb{P}(\text{mask}=1) \times \mathbb{P}(\text{COVID}=1 \mid \text{mask}=1)
    \\ & \quad \times \mathbb{P}(\text{cough}=0 \mid \text{COVID}=1) \\ &= 0.5 \times
    0.2 \times 0.1 = 0.01 \end{align*}\]
- en: 'So this is a pretty unlikely combination. You can also ask a causal question,
    like:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是一个相当不可能的组合。你也可以问一个因果问题，比如：
- en: '**Interventional question:** What is the probability of having a high COVID
    risk and cough if the policymaker enforces masks? This can be computed by:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**干预问题**：如果政策制定者强制戴口罩，那么患有高COVID风险和咳嗽的概率是多少？这可以通过以下方式计算：'
- en: \[\begin{align*} &\mathbb{P}(\text{COVID}=1, \text{cough}=1 \mid do(\text{mask}=1))
    \\ &= \mathbb{P}(\text{COVID}=1 \mid \text{mask}=1) \times \mathbb{P}(\text{cough}=1
    \mid \text{COVID}=1) \\ &= 0.2 \times 0.9 = 0.18 \end{align*}\]
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\mathbb{P}(\text{COVID}=1, \text{cough}=1 \mid do(\text{mask}=1))
    \\ &= \mathbb{P}(\text{COVID}=1 \mid \text{mask}=1) \times \mathbb{P}(\text{cough}=1
    \mid \text{COVID}=1) \\ &= 0.2 \times 0.9 = 0.18 \end{align*}\]
- en: Let’s generalize the ideas of this example. What do you need for a BCN?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们推广这个例子中的思想。你需要什么来构建一个BCN？
- en: The marginal distribution \(\mathbb{P}(X_r)\) of all nodes in the causal graph
    without incoming arrows. These nodes are called root nodes.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果图中所有没有入箭头的节点的边缘分布 \(\mathbb{P}(X_r)\)。这些节点被称为根节点。
- en: For all non-root nodes, you need their conditional distribution \(\mathbb{P}(X_j\mid
    pa_j)\) given their direct causes. The direct causes of a node are called parents.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于所有非根节点，你需要它们的条件分布 \(\mathbb{P}(X_j\mid pa_j)\)，给定它们直接的原因。一个节点的直接原因被称为父节点。
- en: 'If you have those two ingredients specified, you have a BCN. It allows you
    to compute both observational and interventional probabilities:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你指定了这两个成分，你就有了BCN。它允许你计算观察和干预概率：
- en: '**Observational probabilities:**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**观察概率**：'
- en: \[\mathbb{P}(X)=\prod\limits_{i=1}^p \mathbb{P}(X_i | pa_i)\]
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathbb{P}(X)=\prod\limits_{i=1}^p \mathbb{P}(X_i | pa_i)\]
- en: '**Interventional probabilities:**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**干预概率**：'
- en: \[\mathbb{P}(X_{-j}\mid do(X_j=z))=\prod\limits_{\substack{i\neq j, \\j\not\in
    pa_i}}\mathbb{P}(X_i\mid pa_i) \prod\limits_{j\in pa_i}\mathbb{P}(X_i\mid pa_i,X_j=z)\]
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathbb{P}(X_{-j}\mid do(X_j=z))=\prod\limits_{\substack{i\neq j, \\j\not\in
    pa_i}}\mathbb{P}(X_i\mid pa_i) \prod\limits_{j\in pa_i}\mathbb{P}(X_i\mid pa_i,X_j=z)\]
- en: To calculate interventional probabilities, you set the intervened variable to
    the desired value wherever it appears in the formula and the corresponding probability
    that the variable has this value to \(1\).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算干预概率，你需要在公式中设置干预变量为所需值，并相应地将变量的概率设置为 \(1\)。
- en: All of this is nice theory and toy modeling. But how about the real world where
    you do not magically have the BCN? Indeed, in practice, you can learn the BCN
    if you know the causal graph. All that differs between a BCN and a causal graph
    are marginal and conditional probabilities. If you have data, this is exactly
    where machine learning can help – estimating conditional probabilities. We generally
    advise estimating conditional probabilities with non-parametric machine learning
    models like neural networks or random forests, however, for small data sizes classical
    parametric approaches like maximum likelihood estimation or expectation maximization
    might be preferable [[26]](references.html#ref-rothfuss2019conditional).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是很好的理论和玩具模型。但在现实世界中，你并没有神奇地拥有BCN（贝叶斯网络）。实际上，如果你知道因果图，你可以学习BCN。BCN和因果图之间的区别只是边缘和条件概率。如果你有数据，这正是机器学习可以发挥作用的地方——估计条件概率。我们通常建议使用非参数机器学习模型，如神经网络或随机森林来估计条件概率，然而，对于小数据量，经典参数方法如最大似然估计或期望最大化可能更可取
    [[26]](references.html#ref-rothfuss2019conditional)。
- en: 10.6.2 Structural causal models allow you to reason about counterfactuals
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.2 结构因果模型允许你推理反事实
- en: Interventional questions are often important if we want to act. But what if
    you want to explain *why* something has happened? Let’s say *you* got COVID and
    want to know why. Was it not wearing a mask? Or, was it that party last week?
    Or did you catch it in the metro from this guy who was sneezing heavily?
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要采取行动，干预性问题通常很重要。但如果你想要解释“为什么”某事发生了呢？比如说，*你*感染了COVID，想知道为什么。是不是因为没有戴口罩？或者，是不是上周的那个派对？或者是不是你在地铁上从那个正在剧烈打喷嚏的人那里感染了它？
- en: Answering why questions is always the most difficult, but usually also the most
    interesting. What is needed to answer such questions? You have to think through
    counterfactual scenarios. You know that you went to the party and you also know
    that you got COVID. To answer the why question, you need to find out how you got
    infected. Would you have got COVID if you hadn’t gone to the party? Would you
    have caught COVID if you hadn’t spoken to your charming but coughing neighbor
    at the party?
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 回答“为什么”的问题总是最困难的，但通常也是最有趣的。要回答这样的问题需要什么？你必须思考反事实场景。你知道你参加了派对，你也知道你感染了COVID。要回答“为什么”的问题，你需要找出你是如何被感染的。如果你没有参加派对，你会感染COVID吗？如果你没有在派对上和那个迷人的但正在咳嗽的邻居交谈，你会感染COVID吗？
- en: BCNs are not expressive enough to reason about counterfactual scenarios. Why
    not? Firstly, BCNs describe causal relations probabilistically on the level of
    groups of individuals who share certain features. Like the probability of getting
    COVID if everyone is forced to the party. The causal relationships are learned
    from data of people who did and of people who did not attend the party. The why
    question is more specific. It asks why you individually got COVID. Did you get
    COVID *because* you attended the party?[⁴](#fn4) Secondly, the fact that you got
    COVID is informative about you, it might reveal information about your properties
    on which there is no data. Like info about your immune system and how resilient
    it is against COVID. This information should not be ignored.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: BCNs在推理反事实场景方面表达力不足。为什么？首先，BCNs在具有某些特征的个体群体层面上以概率形式描述因果关系。比如，如果所有人都被强迫参加派对，那么感染COVID的概率。因果关系是从参加派对的人和没有参加派对的人的数据中学习得到的。而“为什么”这个问题更为具体。它询问的是你个人为什么感染了COVID。你是不是因为参加了派对才感染COVID的？[⁴](#fn4)
    其次，你感染COVID的事实对你个人是有信息的，它可能揭示了关于你的属性的信息，而这些属性上没有数据。比如关于你的免疫系统及其对COVID的抵抗力的信息。这些信息不应被忽视。
- en: To answer why questions you need to simulate alternative scenarios, i.e. to
    perform counterfactual reasoning. A Structural Causal Model (SCM) is a model designed
    to simulate such alternative scenarios. Instead of describing probabilistic relationships
    in the data, a SCM explicitly models the mechanism that generates the data.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答“为什么”的问题，你需要模拟不同的场景，即进行反事实推理。结构因果模型（SCM）是一种旨在模拟这些不同场景的模型。与描述数据中的概率关系不同，SCM明确地模拟了生成数据的机制。
- en: 'Let’s look at a super simple SCM with just two factors: whether you go to the
    party or not and whether you have COVID or not. These factors that you have explicit
    information about are called the endogenous variables.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个非常简单的SCM，它只包含两个因素：你是否参加派对以及你是否感染了COVID。这些你具有明确信息的因素被称为内生变量。
- en: '![](../Images/a8930b2c5b082900875182945d29d36a.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8930b2c5b082900875182945d29d36a.png)'
- en: The model moreover contains two *exogenous* variables. Exogenous variables describe
    background factors on which you have no data but which play a role in determining
    the endogenous variables. For example, whether you go to the party or not might
    be determined by whether you are in the mood for partying. Similarly, whether
    you get COVID or not might be influenced by how well your immune system is currently
    working. The exogenous variables are very powerful in SCMs. These factors completely
    determine the endogenous variables.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该模型还包含两个*外生*变量。外生变量描述了背景因素，你对这些因素没有数据，但它们在确定内生变量方面发挥作用。例如，你是否参加派对可能取决于你是否想参加派对。同样，你是否感染COVID可能受你当前免疫系统的功能状态的影响。在外生变量中，SCMs非常强大。这些因素完全决定了内生变量。
- en: 'The SCM is thus specified by:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，SCM由以下内容指定：
- en: 'Two noise terms: \(U_{\text{mood}}=Ber(0.5)\) describes whether you are in
    the mood for partying and the chances are fifty-fifty. \(U_{\text{immune}}=Ber(0.8)\)
    describes whether your immune system is up and the chances are pretty high (80%)
    that your immune system works well.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个噪声项：\(U_{\text{mood}}=Ber(0.5)\) 描述了你是否想参加派对，概率是五五开。\(U_{\text{immune}}=Ber(0.8)\)
    描述了你的免疫系统是否正常，概率相当高（80%）你的免疫系统工作良好。
- en: One structural equation for the endogenous party variable, i.e. \(\text{party}:=
    U_{\text{mood}}\). Whether you go to the party is fully determined by whether
    you are in the mood for it.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于内生派对变量的结构方程，即 \(\text{party}:= U_{\text{mood}}\)。你是否去派对完全由你是否想参加派对决定。
- en: One structural equation for the endogenous COVID variable, i.e. \(\text{COVID}:=max(0,\text{party}-U_{\text{immune}})\).
    That means, you only get COVID if you are at the party and your immune system
    is down.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于内生COVID变量的结构方程，即 \(\text{COVID}:=max(0,\text{party}-U_{\text{immune}})\)。这意味着，只有当你参加派对并且你的免疫系统下降时，你才会感染COVID。
- en: 'This SCM allows you to answer the counterfactual question: You went to the
    party and you caught COVID, would you have gotten COVID if you hadn’t gone to
    the party? Such counterfactuals are computed in three steps:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个SCM允许你回答反事实问题：你去了派对并且感染了COVID，如果你没有去派对，你会感染COVID吗？这样的反事实问题通过三个步骤来计算：
- en: '**Abduction:** What does the fact that you got COVID tell you about the noise
    variables? Well, you could not have caught COVID with your immune system up. Thus,
    you can infer that \(U_{\text{immune}}=0\). Similarly, you know that you were
    in the mood for partying because otherwise, you would not have gone, i.e. \(U_{\text{mood}}=1\).'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理：** 你感染了COVID的事实告诉你关于噪声变量的什么信息？嗯，如果你的免疫系统正常，你就不会感染COVID。因此，你可以推断 \(U_{\text{immune}}=0\)。同样，你知道你当时想参加派对，否则你不会去，即
    \(U_{\text{mood}}=1\)。'
- en: '**Action:** Let’s say you would not have gone to the party, that means you
    intervene and turn the party variable from one to zero, i.e. \(do(\text{party}=0)\).'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行动：** 假设你没有去派对，这意味着你进行干预，将派对变量从一变为零，即 \(do(\text{party}=0)\)。'
- en: '**Prediction:** What happens with the COVID variable if you switch party to
    zero? According to the structural equation of COVID, you only get COVID if both
    happens, you go to the party and your immune system is down. Thus, you do not
    get COVID.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测：** 如果你将派对变量切换为零，COVID变量会发生什么？根据COVID的结构方程，只有当你去派对并且你的免疫系统下降时，你才会感染COVID。因此，你不会感染COVID。'
- en: In consequence, if you hadn’t gone to the party, you would not have caught COVID.
    So, you got COVID **because** you went to the party.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你没有去派对，你就不会感染COVID。所以，你感染COVID **是因为**你去了派对。
- en: What if the counterfactual had not been true? Would partying still be a cause?
    Well, then things get more complicated. It could for instance be that you would
    have gone for sports instead of the party and caught COVID there. But partying
    would still have been the actual cause of you catching COVID. Search for *actual
    causation* to learn more about the topic.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果反事实不是真的呢？派对还是原因吗？嗯，那么事情就变得更复杂了。例如，你可能本想去运动而不是去派对，并在那里感染了COVID。但派对仍然是你感染COVID的实际原因。搜索*实际因果关系*了解更多关于这个主题的信息。
- en: 'Let’s generalize the ideas of the example. For a SCM, you need:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们推广示例中的思想。对于一个结构因果模型（SCM），你需要：
- en: A set of exogenous variables \(U\) that are determined by factors outside the
    model and independent from each other.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组外生变量 \(U\)，它们由模型外的因素决定，并且彼此独立。
- en: A set of endogenous variables \(X\) that are fully determined by the factors
    inside the model.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组内生变量 \(X\)，它们完全由模型内的因素决定。
- en: A set of structural equations \(F\) that describe for each endogenous variable
    \(X_j\) how it is determined by its parents and its exogenous variable \(X_j=f(pa_j,
    U_j)\).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组结构方程 \(F\)，它描述了对于每个内生变量 \(X_j\)，它是如何由其父变量和其外生变量 \(X_j=f(pa_j, U_j)\) 决定的。
- en: Obtaining SCMs in real life is difficult. You may use machine learning to learn
    the structural equations if you know the causal dependencies between variables.
    However, even for that, you need quite some data, and making parametric assumptions
    can be advisable.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中获得SCMs很困难。如果你知道变量之间的因果依赖关系，你可以使用机器学习来学习结构方程。然而，即使是那样，你也需要相当多的数据，并且做出参数假设可能是可取的。
- en: Like counterfactuals themselves, SCMs are highly speculative objects. There
    is no easy way to verify that a given SCM is correct, it always relies on counterfactual
    assumptions. Still, since humans reason in terms of counterfactuals all the time
    and are deeply concerned with *why* questions, it is nice to have a formalism
    that can capture counterfactual reasoning.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 就像反事实本身一样，SCMs（结构因果模型）是非常具有推测性的对象。没有简单的方法可以验证给定的SCM是否正确，它总是依赖于反事实假设。尽管如此，由于人类总是以反事实的方式进行推理，并且对“为什么”这类问题深感兴趣，因此拥有一种可以捕捉反事实推理的形式化方法是非常有用的。
- en: 10.7 Learning causal graphs from data
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.7 从数据中学习因果图
- en: 'Machine learning has revived an old idea – with enough data, we might be able
    to completely automatize science. In Part 1 and Part 2 of this chapter, you always
    needed a human scientist in the background. Someone to come up with interesting
    hypotheses, run experiments, or provide us with a causal graph. This part will
    be the most ambitious, it asks:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习重新唤起了一个古老的想法——有了足够的数据，我们可能能够完全自动化科学。在本章的第1部分和第2部分中，你总是需要一个在幕后的人类科学家。有人提出有趣的假设，进行实验，或者为我们提供因果图。这部分将是最具雄心的，它提出了以下问题：
- en: Can you get a causal graph just from data, without entering domain knowledge?
    This problem is often referred to as *causal structure learning* or *causal discovery*.
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你能否仅从数据中获取因果图，而不需要进入领域知识？这个问题通常被称为*因果结构学习*或*因果发现*。
- en: Didn’t we tell you in the beginning that observational data alone doesn’t do
    the trick? Correct! But it is intriguing to see how far you can go, especially
    if you add some additional assumptions. Clear the stage for a truly fascinating
    branch of research!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在开始时没有告诉你，仅凭观察数据是不够的吗？正确！但是，看到你可以走多远是非常有趣的，尤其是如果你添加了一些额外的假设。为真正迷人的研究领域做好准备！
- en: 'Imagine all you have is a dataset containing 5,000 entries. Each entry contains
    information about a person’s BMI, COVID vaccination status, flu vaccination status,
    COVID risk, fatigue, fever, appetite, and the density of population in the area
    the person lives in (Example based on [[28]](references.html#ref-jehi2020individualizing)
    and [[29]](references.html#ref-konig2023improvement)). The task is to structure
    these features in a causal graph – the problem of *causal discovery*. Let’s say
    the true graph that you want to learn looks like this:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你手中有一个包含5,000条记录的数据集。每条记录包含有关一个人BMI、COVID疫苗接种状态、流感疫苗接种状态、COVID风险、疲劳、发烧、食欲以及该人居住区域人口密度的信息（示例基于[[28]](references.html#ref-jehi2020individualizing)和[[29]](references.html#ref-konig2023improvement))。任务是构建这些特征的一个因果图——即因果发现问题。假设你想要学习的真实图示如下：
- en: '![](../Images/e39de7c6dad49aab27b5a89b510311b0.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/e39de7c6dad49aab27b5a89b510311b0.png)'
- en: 'Before you can approach this problem, you have to get some more background
    on how causal mechanisms, associations, and data relate to each other. The causal
    mechanism generates data. Within this data, features are associated with each
    other. That means that causal dependencies induce statistical (in-)dependencies.
    Particularly, if you have a causal graph, the so-called causal Markov condition
    applies:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在你能够接近这个问题之前，你必须了解一些关于因果机制、关联和数据如何相互关联的更多背景知识。因果机制生成数据。在这些数据中，特征相互关联。这意味着因果依赖性产生了统计（非）依赖性。特别是，如果你有一个因果图，那么所谓的因果马尔可夫条件适用：
- en: '*Causal Markov condition:* *Given its parents in the causal graph, a variable
    is statistically independent of all its non-descendants. Or formally, let \(G\)
    be a causal graph and \(X_i\) be any variable in the network, then for all its
    non-descending variables \(nd_i\) holds \(X_i\perp \!\!\! \perp nd_i\mid pa_i\).
    Descendants of a given variable \(X_i\) are all the variables that can be reached
    from \(X_i\) by walking along the direction of arrows.*  *To get an intuition
    on the causal Markov condition, take a look at the graph below. Consider the variable
    appetite as an example. Its parents are COVID and density. Its nondescendants
    are BMI, COVID-vac, flu-vac, fever, and fatigue.[⁵](#fn5) The causal Markov condition
    allows you for example to say that appetite is statistically independent of fever
    if you know COVID and density. The formal way to write this is \(\;\text{appetite}
    \perp \!\!\! \perp \text{fever}\mid \text{COVID}, \text{density}\), where \(\perp
    \!\!\! \perp\) is the symbol for independence.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*因果马尔可夫条件*：*在因果图中的父节点给定的情况下，一个变量与其所有非后继变量在统计上独立。或者正式地说，令 \(G\) 为一个因果图，\(X_i\)
    为网络中的任何变量，那么对于所有其非后继变量 \(nd_i\)，都有 \(X_i\perp \!\!\! \perp nd_i\mid pa_i\)。给定变量
    \(X_i\) 的后继变量是所有可以通过沿着箭头方向从 \(X_i\) 到达的变量。* 为了对因果马尔可夫条件有一个直观的理解，请看下面的图。以食欲变量为例。其父节点是COVID和密度。其非后继变量是BMI、COVID-vac、flu-vac、fever和fatigue。[⁵](#fn5)
    因果马尔可夫条件允许你例如在知道COVID和密度的情况下说食欲与fever在统计上独立。正式的写法是 \(\;\text{appetite} \perp \!\!\!
    \perp \text{fever}\mid \text{COVID}, \text{density}\)，其中 \(\perp \!\!\! \perp\)
    是独立性的符号。'
- en: '![](../Images/7956b8e8ec56dba496c1a618f43c3f50.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/7956b8e8ec56dba496c1a618f43c3f50.png)'
- en: Cool, causal graphs induce statistical independencies, but what to do with that?
    Well, you have a dataset, so you can test for statistical independencies.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 很酷，因果图可以诱导出统计独立性，但我们应该如何利用这一点呢？好吧，你有一个数据集，所以你可以测试统计独立性。
- en: There are many different approaches to test such (conditional) independencies,
    and they vary regarding the parametric assumptions they pose. Some test the statistical
    dependency to be Gaussian or linear (e.g. partial correlation), or are tailored
    for categorical data like the chi-squared test [[30]](references.html#ref-peters2017elements).
    Others allow for a greater variety of dependencies, like tests based on the Hilbert-Schmidt
    independence criterion (HSIC) [[31]](references.html#ref-fukumizu2007kernel).
    The current trend goes even more non-parametric towards machine learning based
    tests for conditional independence. Questions of independence are translated into
    classification problems, where powerful machine learning models can be utilized
    (e.g. neural nets or random forests) [[32]](references.html#ref-sen2017model),
    [[33]](references.html#ref-watson2021testing). However, the fewer parametric assumptions
    you pose, the more statistical dependencies are possible. Thus, non-parametric
    tests usually have a very bad statistical power, which means you need a lot of
    data to identify independencies [[34]](references.html#ref-shah2020hardness).
    This problem gets worse the more variables you condition on – conditioning can
    be viewed as reducing the data you can test with. Incorrect conditional dependencies
    can lead to incorrect causal conclusions.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 测试此类（条件）独立性的方法有很多种，它们在所提出的参数假设方面有所不同。有些测试统计依赖性是否为高斯或线性（例如，部分相关），或者针对分类数据如卡方检验[[30]](references.html#ref-peters2017elements)。其他方法允许有更多样化的依赖性，例如基于希尔伯特-施密特独立性准则（HSIC）[[31]](references.html#ref-fukumizu2007kernel)的测试。当前趋势甚至更偏向于基于机器学习的条件独立性测试的非参数方法。独立性问题被转化为分类问题，其中可以利用强大的机器学习模型（例如，神经网络或随机森林）[[32]](references.html#ref-sen2017model)，[[33]](references.html#ref-watson2021testing)。然而，你提出的参数假设越少，可能的统计依赖性就越多。因此，非参数测试通常具有非常差的统计功效，这意味着你需要大量的数据来识别独立性[[34]](references.html#ref-shah2020hardness)。当考虑更多变量时，这个问题会变得更糟——条件可以被视为减少了你可以测试的数据。错误的条件依赖可能导致错误的因果结论。
- en: 'Let’s say you found a set of statistical independencies, how does this help
    you to learn the causal graph? Well, statistical independencies in the data are
    only compatible with certain kinds of causal structures. The data narrows down
    the causal stories that make sense. So the question is, how many *faithful* causal
    graphs (see the box: “Central assumptions in causality”) are compatible with the
    data?'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你发现了一组统计独立性，这如何帮助你学习因果图呢？好吧，数据中的统计独立性仅与某些类型的因果结构相兼容。数据缩小了有意义的因果故事。所以问题是，有多少*忠实*的因果图（见框：“因果性的核心假设”）与数据相兼容？
- en: 'As an example, assume you had only three variables: fatigue, COVID, and fever.
    By running statistical tests, you find that'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你只有三个变量：疲劳、COVID 和发热。通过运行统计测试，你会发现
- en: fatigue is independent of fever given COVID (Formally, \(\text{fatigue}\perp
    \!\!\! \perp \text{fever}\mid \text{COVID}\))
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 COVID 的情况下，疲劳与发热是独立的（形式上，\(\text{fatigue}\perp \!\!\! \perp \text{fever}\mid
    \text{COVID}\)）
- en: None of the three variables is unconditionally independent of the other.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这三个变量中没有一个是无条件独立于其他变量的。
- en: Then, three causal stories (causal chains) would explain this data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，三个因果故事（因果链）可以解释这些数据。
- en: 'Story 1: \(\text{fatigue}\rightarrow \text{COVID}\rightarrow \text{fever}\).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故事 1：\(\text{fatigue}\rightarrow \text{COVID}\rightarrow \text{fever}\).
- en: 'Story 2: \(\text{fatigue}\leftarrow \text{COVID}\leftarrow \text{fever}\).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故事 2：\(\text{fatigue}\leftarrow \text{COVID}\leftarrow \text{fever}\).
- en: 'Story 3: \(\text{fatigue}\leftarrow \text{COVID}\rightarrow \text{fever}\)
    (called fork structure)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故事 3：\(\text{fatigue}\leftarrow \text{COVID}\rightarrow \text{fever}\) （称为叉结构）
- en: All of these stories (or causal graphs) are faithful and compatible with the
    given statistical (in-)dependencies. Also, one can show that there is no other
    causal graph that satisfies this.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些故事（或因果图）都是忠实的，并且与给定的统计（非）依赖性兼容。还可以证明没有其他因果图满足这一点。
- en: '*The elements of causality: chains, forks, and immoralities* *Let’s assume
    you have the variables \(X, Y\), and \(Z\). Three basic path structures in causal
    graphs are distinguished in causal discovery:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '*因果要素：链、叉和道德败坏* *假设你拥有变量 \(X, Y\) 和 \(Z\)。在因果图中，区分了三种基本的路径结构，用于因果发现：'
- en: '*Causal chains*, where \(Y\) is called a *mediator*:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果链*，其中 \(Y\) 被称为 *中介者*：'
- en: '![](../Images/97287f66736cded2ea051b1979effbea.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97287f66736cded2ea051b1979effbea.png)'
- en: '*Forks*, where \(Y\) is called a *common cause*:'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Forks*，其中 \(Y\) 被称为 *共同原因*：'
- en: '![](../Images/902a64ed49f44f74face68fe85cd5932.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/902a64ed49f44f74face68fe85cd5932.png)'
- en: '*Immoralities*, where \(Y\) is called a *collider*:'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*道德败坏*，其中 \(Y\) 被称为 *碰撞器*：'
- en: '![](../Images/ccd1944eccf15f1ecaa1bd86a5451ecd.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccd1944eccf15f1ecaa1bd86a5451ecd.png)'
- en: 'Causal chains and forks imply identical conditional dependencies:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 因果链和叉意味着相同的条件依赖性：
- en: \(X \perp \!\!\! \perp Z \mid Y\) (X and Z are independent given Y)
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(X \perp \!\!\! \perp Z \mid Y\) （在 Y 的条件下，X 和 Z 是独立的）
- en: X and Y are dependent
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: X 和 Y 是相互依赖的
- en: X and Z are dependent
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: X 和 Z 是相互依赖的
- en: Y and Z are dependent
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Y 和 Z 是相互依赖的
- en: 'Immoralities, however, exhibit a distinct pattern:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，道德败坏表现出一种独特的模式：
- en: \(X \perp \!\!\! \perp Z\) (X and Z are marginally independent)
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: \(X \perp \!\!\! \perp Z\) （X 和 Z 在边缘上是独立的）
- en: X and Z are dependent conditional on Y
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: X 和 Z 在 Y 的条件下是相互依赖的
- en: X and Y are dependent
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: X 和 Y 是相互依赖的
- en: Y and Z are dependent*  *We call the set of faithful causal models that satisfies
    the same set of statistical (in-)dependencies the *Markov equivalence class*.
    How can you find the Markov equivalence class if all you have is a dataset? We
    provide one of many answers here, the so-called PC algorithm.[⁶](#fn6)
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Y 和 Z 是相互依赖的*  *我们将满足相同一组统计（非）依赖关系的忠实因果模型集合称为 *马尔可夫等价类*。如果你只有数据集，你如何找到马尔可夫等价类？我们在这里提供许多答案之一，所谓的
    PC 算法。[⁶](#fn6)
- en: '**The Peter-Clark (PC) algorithm:** The most well-known algorithmic approach
    for finding the Markov equivalence class of causal models that is compatible with
    the statistical (in-)dependencies found in a dataset [[36]](references.html#ref-spirtes2000causation).
    It requires causal sufficiency and the faithfulness condition to be satisfied.
    It runs the following steps:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**彼得-克拉克 (PC) 算法**：寻找与数据集中发现的统计（非）依赖性兼容的因果模型马尔可夫等价类的最知名算法方法 [[36]](references.html#ref-spirtes2000causation)。它要求满足因果充分性和忠实性条件。它执行以下步骤：'
- en: '**Identify the skeleton:** We start with a fully connected network with undirected
    arrows. Then, step by step we look through all unconditional and conditional independencies
    between features. We start with unconditional independencies, continue with independencies
    conditional on one variable, then two, and so on. If two features are (conditionally)
    independent, we erase the arrows between them. In the end, we get the so-called
    skeleton graph without directed arrows.'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**识别骨骼结构**：我们从具有无向箭头的完全连接网络开始。然后，逐步检查所有特征之间的无条件独立性和条件独立性。我们从无条件独立性开始，继续检查一个变量的独立性，然后是两个，依此类推。如果两个特征（条件上）是独立的，我们就删除它们之间的箭头。最后，我们得到所谓的无向箭头的骨骼图。'
- en: '*Unconditional independence:* By running a statistical test, we learn that
    BMI, COVID-vac, flu-vac, and density are all pairwise independent. This allows
    us to erase the arrows between those variables.'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无条件独立性：* 通过运行统计测试，我们了解到BMI、COVID-vac、flu-vac和密度都是成对独立的。这允许我们擦除这些变量之间的箭头。'
- en: '*Independence conditioned on one variable:* Conditioning on COVID makes fatigue,
    fever, and appetite pairwise independent. Moreover, BMI, COVID-vac, flu-vac, and
    density become independent of fatigue and fever. We can erase all arrows between
    these variables.'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于一个变量的条件独立性：* 在COVID上条件化使疲劳、发烧和食欲成对独立。此外，BMI、COVID-vac、flu-vac和密度与疲劳和发烧独立。我们可以擦除这些变量之间的所有箭头。'
- en: '*Independence conditioned on two variables:* If we condition on COVID and density,
    BMI, COVID-vac, and flu-vac become independent of appetite. We can therefore erase
    all arrows between appetite and these variables.'
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于两个变量的条件独立性：* 如果我们在COVID和密度上条件化，BMI、COVID-vac和flu-vac就会与食欲独立。因此，我们可以擦除食欲与这些变量之间的所有箭头。'
- en: We find no further independencies. So this is our resulting skeleton!
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们没有发现更多的独立性。因此，这就是我们的结果骨架！
- en: '![](../Images/ed1eff85fc7411b022c1e97748423100.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ed1eff85fc7411b022c1e97748423100.png)'
- en: '**Identify immoralities:** Immoralities are paths of the form \(X\rightarrow
    Y\leftarrow Z\) that lead to unique (in)dependencies, namely to \(X\perp \!\!\!
    \perp Z\) and \(X,Z\) are dependent conditional on \(Y\). We can use this uniqueness
    to orient some arrows. Go through all unconditional independencies \(X\perp \!\!\!
    \perp Z\) where the nodes are connected via one intermediate variable \(Y\), check
    whether conditioning on \(Y\) makes them dependent. If yes, you found an immorality
    and can orient the arrows.'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**识别不道德行为：** 不道德行为是形式为 \(X\rightarrow Y\leftarrow Z\) 的路径，导致唯一的（不）独立性，即 \(X\perp
    \!\!\! \perp Z\) 和 \(X,Z\) 在 \(Y\) 条件下是相关的。我们可以利用这种唯一性来调整一些箭头的方向。检查所有无条件独立性 \(X\perp
    \!\!\! \perp Z\)，其中节点通过一个中间变量 \(Y\) 连接，检查是否在 \(Y\) 上条件化会使它们变得相关。如果是，你找到了一个不道德行为，可以调整箭头的方向。'
- en: As you can see, in our skeleton all arrows are undirected. We now check for
    all unconditionally independent variables that become dependent if we condition
    on one variable. This is the case for BMI, COVID-vac, flu-vac, and density. They
    are unconditionally independent but become dependent if we condition the COVID
    variable. We can therefore orient some arrows in our graph.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如您所见，在我们的骨架图中，所有箭头都是无向的。我们现在检查所有无条件独立的变量，如果我们在一个变量上条件化，它们就会变得相关。这种情况适用于BMI、COVID-vac、flu-vac和密度。它们是无条件独立的，但如果我们对COVID变量进行条件化，它们就会变得相关。因此，我们可以在我们的图中调整一些箭头的方向。
- en: '![](../Images/44fcc5def264d8a1c48e2c9889532da4.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/44fcc5def264d8a1c48e2c9889532da4.png)'
- en: '**Apply logic:** Now you have identified all immoralities. Thus, if you find
    three variables that are connected like this \(X\rightarrow Y-Z\) where the arrow
    between \(Y\) and \(Z\) is undirected, you can infer that \(X \rightarrow Y \rightarrow
    Z\), because otherwise there would be another immorality that you must have discovered.
    Also, we search for an acyclic graph. So if there is only one way to avoid making
    a cycle, that is the way you orient the arrows.'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**应用逻辑：** 现在你已经识别了所有的不道德行为。因此，如果你发现三个变量以这种方式连接 \(X\rightarrow Y-Z\)，其中 \(Y\)
    和 \(Z\) 之间的箭头是无向的，你可以推断出 \(X \rightarrow Y \rightarrow Z\)，因为否则会有另一个你必须发现的不道德行为。此外，我们寻找一个无环图。所以如果只有一种避免形成循环的方法，那就是你调整箭头的方法。'
- en: 'Which arrows would lead to new immoralities? If fatigue, fever, and appetite
    had arrows towards COVID, new immoralities would emerge that would have been found
    in the statistical testing. Thus, they must have arrows coming from the COVID
    variable. Now only one arrow is left undirected, the arrow between density and
    appetite. If this arrow would go from density towards appetite, there would be
    a cycle: \(\text{COVID}\rightarrow \text{appetite}\rightarrow \text{density}\rightarrow
    \text{COVID}\). Thus, the arrow must go from density to appetite.'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些箭头会导致新的不道德行为？如果疲劳、发烧和食欲有指向COVID的箭头，就会产生新的不道德行为，这些行为会在统计测试中被发现。因此，它们必须有来自COVID变量的箭头。现在只剩下一个无向箭头，即密度和食欲之间的箭头。如果这个箭头指向食欲，就会形成一个循环：\(\text{COVID}\rightarrow
    \text{appetite}\rightarrow \text{density}\rightarrow \text{COVID}\)。因此，箭头必须指向食欲。
- en: '![](../Images/64b872d3d938cd8a81df221131fe4e83.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/64b872d3d938cd8a81df221131fe4e83.png)'
- en: 'Cool, we were able to identify the full causal graph just from the (in-)dependencies!
    But we were lucky. If we had looked at a more complex graph, the PC algorithm
    would have spit out a graph where some arrows are left unoriented. All possible
    ways for orienting these remaining arrows define the Markov equivalence class.
    But can you go further? Is there a way to identify the correct causal model among
    the Markov equivalence class? You need something extra for this:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 很酷，我们仅从（不）依赖关系就能识别出完整的因果图！但我们很幸运。如果我们观察一个更复杂的图，PC算法就会输出一个箭头方向未定的图。所有剩余箭头方向的可能排列定义了马尔可夫等价类。但你能否更进一步？有没有一种方法可以在马尔可夫等价类中识别出正确的因果模型？你需要额外的信息来做这件事：
- en: '**Perform real-world experiments:** You could simply run experiments. There
    are proven bounds for how many experiments you have to perform to identify the
    correct causal graph. For instance, if multi-node interventions are allowed, \(log_2[n]+1\)
    interventions are sufficient to identify the causal graph, where \(n\) is the
    number of nodes [[37]](references.html#ref-eberhardt2005).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进行现实世界的实验：** 你可以简单地运行实验。已经证明了确定正确因果图所需进行的实验数量的界限。例如，如果允许多节点干预，则\(log_2[n]+1\)次干预就足以识别因果图，其中\(n\)是节点的数量[[37]](references.html#ref-eberhardt2005)。'
- en: '**Pose more assumptions:** One of the most prominent assumptions for the identifiability
    of the causal graph is the linearity of the relationship and non-Gaussian noise
    terms in the structural equations. Alternatively, you can assume non-linearity
    and the additivity of noise. Check out [[30]](references.html#ref-peters2017elements)
    to learn more. Most approaches rely on the idea that the noise variables are independent
    in one but not in the other causal direction.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提出更多假设：** 对于因果图的识别性而言，最突出的假设之一是结构方程中关系的线性以及非高斯噪声项。或者，你也可以假设非线性以及噪声的加性。查看[[30]](references.html#ref-peters2017elements)了解更多信息。大多数方法都依赖于这样一个观点，即噪声变量在一个因果方向上是独立的，而在另一个因果方向上则不是。'
- en: '*Central assumptions in causality* *You can see causal models as devices for
    interpreting data. But when are the interpretations correct? Only if certain assumptions
    are satisfied. Causality is therefore a deeply assumption-driven field. The most
    crucial ones are listed here:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '*因果性的核心假设* 你可以将因果模型视为解释数据的工具。但何时解释才是正确的？只有当满足某些假设时，解释才是正确的。因此，因果性是一个深度假设驱动的领域。其中最重要的假设如下：'
- en: '**Causal sufficiency**: This is one of the key assumptions in the field. It
    is sometimes also referenced as the assumption of **no unobserved confounders**.
    It means that you have not missed a causally relevant variable in your model that
    would be a cause of two or more variables in the model. This assumption is not
    testable and without it, far less can be derived [[38]](references.html#ref-manski2003partial).'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**因果充分性：** 这是该领域的一个关键假设。有时也被称为**无未观察到的混杂因素**的假设。这意味着在你的模型中，你没有遗漏一个因果相关的变量，该变量将是模型中两个或更多变量的原因。这个假设是不可检验的，没有它，能得出的结论就少得多[[38]](references.html#ref-manski2003partial)。'
- en: '**Independence of mechanisms:** Means that causal models are modular. Intervening
    on one structural equation does not affect other structural equations. Or on a
    probabilistic take, changing the marginal distribution of one variable does not
    affect the conditional distributions where this variable acts as a causal parent.
    This assumption seems almost definitional to mechanistic modeling and implies
    the independence of the exogenous noise terms [[30]](references.html#ref-peters2017elements).'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机制独立性：** 意味着因果模型是模块化的。对一个结构方程的干预不会影响其他结构方程。或者从概率的角度来看，改变一个变量的边缘分布不会影响该变量作为因果父变量时的条件分布。这个假设对于机制建模似乎是定义性的，并暗示了外生噪声项的独立性[[30]](references.html#ref-peters2017elements)。'
- en: '**Faithfulness:** Is connected to how to interpret causal graphs probabilistically.
    Faithfulness means that every causal dependence in the graph results in a statistical
    dependence. Note that it is hard to justify faithfulness in finite data regimes
    [[39]](references.html#ref-uhler2013geometry).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**忠实性：** 与如何概率性地解释因果图有关。忠实性意味着图中每个因果依赖都导致统计依赖。请注意，在有限数据体系中很难证明忠实性[[39]](references.html#ref-uhler2013geometry)。'
- en: '**Positivity:** For every group of the population, you have both subgroups
    with and without treatment. This is crucial when it comes to *treatment effect
    estimation*. If positivity is violated, you extrapolate (non-)treatment effects
    for certain subgroups, which can go terribly wrong.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正性原则：**对于人口中的每一个群体，你都有接受过治疗的子组和未接受治疗的子组。在*治疗效果估计*时这一点至关重要。如果违反了正性原则，你可能会错误地推断某些子组的（非）治疗效果，这可能会非常糟糕。'
- en: This list is far from complete, there are many more, such as consistency, exchangeability,
    and no interference [[16]](references.html#ref-pearl2009causality), [[40]](references.html#ref-neal2020introduction).
    The correctness of your interpretations of data with causal models or the causal
    models you may partially derive from data are extremely sensitive to these assumptions.
    If possible, check if they apply!***  ***## 10.8 Learning causal representations
    from data
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表远未完整，还有很多，例如一致性、可交换性和无干扰 [[16]](references.html#ref-pearl2009causality),
    [[40]](references.html#ref-neal2020introduction)。你对数据使用因果模型或可能从数据部分推导出的因果模型的解释的正确性，对这些假设极为敏感。如果可能的话，检查它们是否适用！***  ***
- en: 'Causal discovery only makes sense if the features are meaningful representations
    and you can talk meaningfully about their causal relationships. This is the case
    with highly structured, tabular data that has been heavily pre-processed by the
    human mind. But the data you often have, especially the data you want to analyze
    with machine learning, doesn’t look like that, it consists of:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当特征是有意义的表示，并且你可以有意义地讨论它们的因果关系时，因果发现才有意义。这在高度结构化、经过人类大脑大量预处理的数据中是成立的。但通常你拥有的数据，尤其是你想用机器学习分析的数据，看起来并不是这样，它由以下组成：
- en: images made of pixels
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由像素组成的图像
- en: texts made of letters
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由字母组成的文本
- en: sounds made of frequencies
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由频率组成的声波
- en: For example, it makes no sense to construct a causal model where the variables
    are single pixels. However, it may be meaningful to talk about the causal relationships
    between objects in images. How can you go from pixels to these objects? How can
    you get meaningful higher-order representations from lower-order features?[⁷](#fn7)
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，构建一个变量为单个像素的因果模型是没有意义的。然而，讨论图像中对象之间的因果关系可能是有意义的。你如何从像素过渡到这些对象？你如何从低阶特征中获得有意义的更高阶表示？[⁷](#fn7)
- en: 'Machine learning is a field concerned with learning higher-order representations.
    Causal representation learning therefore describes a dream that many in machine
    learning share – the dream of fusing symbolic approaches like causal models with
    modern machine learning. This would combine the strengths of both worlds: learning
    complex meaningful representations from data AND reasoning symbolically in a transparent
    and logical manner.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个关注学习高阶表示的领域。因此，因果表示学习描述了许多机器学习研究者共同的一个梦想——将符号方法如因果模型与现代机器学习融合的梦想。这将结合两个世界的优点：从数据中学习复杂而有意义的表现，并在透明和逻辑的方式中进行符号推理。
- en: Indeed, doing so is extremely difficult and the research in this field is still
    in its infancy. Machine learning models learn complex representations to perform
    their predictions, however, whether the representations are in any sense similar
    to the ones humans form or at all understandable to us is an open question. Adding
    labels to the representations you want and modifying the loss function to use
    these representations might be one way to go [[42]](references.html#ref-koh2020concept).
    But it is data costly! Is there a way to make sure that machine learning models
    learn meaningful representations that could be used to construct causal models?
    Can you maybe even build in constraints informed by your understanding of causality
    to learn such representations? We’ll give you some hunch in this direction…
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这样做极其困难，这个领域的研究仍处于起步阶段。机器学习模型学习复杂的表现来执行它们的预测，然而，这些表现是否在某种程度上与人类形成的表现相似，或者是否对我们来说完全可理解，这是一个悬而未决的问题。给表现添加标签并修改损失函数以使用这些表现可能是一种方法
    [[42]](references.html#ref-koh2020concept)。但这需要大量数据！有没有一种方法可以确保机器学习模型学习到有意义的表示，这些表示可以用来构建因果模型？你甚至可以构建基于你对因果性的理解的约束来学习这样的表示吗？我们将给你一些这方面的启示…
- en: '*Variational autoencoders (VAEs)* *Autoencoders consist of two parts. An encoder
    maps the input to a higher-order representation and a decoder maps the higher-order
    representation back to the original input space. The only difference in a variational
    autoencoder is that input is encoded into a set of parameters of a probability
    distribution, whereas the decoder takes a sample from this distribution and maps
    it back to the original input space. VAEs are (unlike the rest of the book) unsupervised
    learning techniques. They allow, among other things, to compress high-dimensional
    information into low-dimensional features with little or no loss of information.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*变分自编码器（VAEs）* *自编码器由两部分组成。编码器将输入映射到更高阶的表示，解码器将更高阶的表示映射回原始输入空间。变分自编码器中唯一的区别是输入被编码成一个概率分布的参数集，而解码器从这个分布中抽取一个样本并将其映射回原始输入空间。VAEs（与本书的其余部分不同）是一种无监督学习技术。它们允许，例如，以几乎不损失信息的方式将高维信息压缩到低维特征中。'
- en: '![](../Images/b64616f87eb09d22e29451da05b7ca9e.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![变分自编码器结构](../Images/b64616f87eb09d22e29451da05b7ca9e.png)'
- en: 'Structure of a Variational Autoencoder.*  ***Putting causal constraints in
    variational autoencoders:** You can see the probability distributions in the middle
    of VAEs as abstractions of the low-level features your data lives in. Therefore,
    VAEs are constantly discussed in the context of representation learning in general
    and there are many ways to incorporate knowledge about these representations both
    via the architecture and the loss function [[43]](references.html#ref-bengio2013representation).
    Instead of learning representations and then looking at how you can incorporate
    them in causal models, you can do the reverse and ask: What makes representations
    good candidates for causal models and how can such knowledge be incorporated into
    the VAE framework? Since research on the topic is still in its infancy, we will
    only provide a list of a few ideas inspired by [[44]](references.html#ref-scholkopf2021toward)
    :'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '*变分自编码器中的因果约束：* 您可以将VAE中间部分的概率分布视为数据所居住的低级特征的抽象。因此，VAEs经常在一般表示学习背景下进行讨论，并且有多种方法可以通过架构和损失函数来融入关于这些表示的知识
    [[43]](references.html#ref-bengio2013representation)。您不必先学习表示然后再看如何将它们融入因果模型，而是可以反过来，问：什么使表示成为因果模型的良好候选者，以及如何将此类知识融入VAE框架？由于该主题的研究仍处于起步阶段，我们只提供一些受[[44]](references.html#ref-scholkopf2021toward)启发的想法列表：'
- en: '**Sparsity:** One key idea in causality is that a few powerful representations
    are enough to explain all kinds of complex phenomena. This can for example be
    enforced by the size of the middle VAE layer.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀疏性：** 因果性中的一个关键思想是，一些强大的表示足以解释各种复杂现象。例如，可以通过中间VAE层的尺寸来强制执行这一点。'
- en: '**Generality across domains:** Powerful representations are useful across tasks.
    What makes them useful is that they capture robust patterns in nature. You can
    enforce this for instance in VAEs by training them to use the same representations
    for different decoding tasks.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨领域的通用性：** 强大的表示在多个任务中都是有用的。使它们有用的原因是它们捕捉了自然界中的稳健模式。例如，您可以通过训练VAEs使用相同的表示来执行不同的解码任务来实现这一点。'
- en: '**Independence:** First, if two representations contain the same information,
    one of them is redundant. But you want to have simple models to efficiently communicate
    about the world. Second, the core idea in causality is that you have independent
    sources of variation and that you can disentangle these sources and their interactions.
    One approach for achieving this in VAEs is modifying the loss to make sure that
    the representations in the intermediate layer are statistically independent.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独立性：** 首先，如果两个表示包含相同的信息，其中一个就是冗余的。但您希望拥有简单的模型来高效地关于世界进行沟通。其次，因果性的核心思想是您有独立的变异来源，并且您可以解开这些来源及其相互作用。在变分自编码器（VAEs）中实现这一点的
    一种方法是通过修改损失函数来确保中间层的表示在统计上是独立的。'
- en: '**Human interventions:** What makes a variable suitable for causal modeling
    is that you can intervene upon it. Thus, 42 % of randomly selected atoms from
    a table do not constitute a good representation, as you cannot use or intervene
    in these 42% in isolation. This human-centered causal bias can be entered into
    VAEs for example through video data, where objects are constantly moved and intervened
    upon but stay persistent.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类干预：**一个变量适合进行因果建模的原因是你可以对它进行干预。因此，从一张桌子中随机选取的42%的原子并不能构成一个好的代表，因为你无法单独使用或干预这42%。这种以人为中心的因果偏差可以通过视频数据输入到VAEs中，例如，在视频中，物体不断移动和干预，但仍然保持持久。'
- en: '**Simple relationships:** Causal models are rarely densely connected. Instead,
    a handful of causal relationships between higher-order variables give rise to
    the associations you observe in the world. This inductive bias of simplicity can
    be enforced via the decoder architecture or the loss function.*  *## 10.9 Causality
    helps to formulate problems'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单关系：**因果模型很少是高度连接的。相反，一些高级变量之间的因果关系引起了你在世界中观察到的关联。这种简单性的归纳偏差可以通过解码器架构或损失函数来强制执行。'
- en: After finishing this chapter, you may feel a little overwhelmed. A lot of theoretical
    concepts were presented and at the same time, there was little practical advice,
    e.g. compared to the domain-knowledge chapter (see [Chapter 8](domain.html)).
    We have the impression that the link between causal theory and the practical problems
    of scientists is underdeveloped in current research. For example, there are only
    a few examples where causal discovery algorithms have been used to gain insights
    from practice.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这一章后，你可能会有点不知所措。在这一章中，介绍了许多理论概念，同时，实际建议却很少，例如，与领域知识章节（见[第8章](domain.html)）相比。我们有一种印象，即当前研究中因果理论与科学家实际问题的联系不够发达。例如，只有少数例子表明因果发现算法已被用于从实践中获得洞察。
- en: Nevertheless, we believe that every researcher should be familiar with the concepts
    presented above, such as the Reichenbach principle, treatment effect estimation,
    and causal modeling. Causality is what many of you are ultimately looking for
    when you want to control, explain, and reason about a phenomenon. While causality
    as a field does often not provide ready-made practical solutions, it offers you
    a language to formulate your problem and describe possible solutions.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们相信每位研究人员都应该熟悉上述概念，例如里肯巴赫原理、治疗效果估计和因果建模。因果性是你们在想要控制、解释和推理现象时最终寻求的东西。虽然因果性作为一个领域通常不提供现成的实际解决方案，但它为你提供了一种语言来表述你的问题和描述可能的解决方案。
- en: 'Many of the chapters in this book are closely related to causality:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的许多章节都与因果性密切相关：
- en: Some domain knowledge (see [Chapter 8](domain.html)) you want to encode may
    be causal.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要编码的一些领域知识（见[第8章](domain.html)）可能是因果性的。
- en: Many questions addressed via model interpretation (see [Chapter 9](interpretability.html)),
    such as algorithmic recourse, are ultimately causal questions [[29]](references.html#ref-konig2023improvement).
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多通过模型解释（见[第9章](interpretability.html)）解决的问题，例如算法回溯，最终都是因果问题 [[29]](references.html#ref-konig2023improvement)。
- en: Causality is one leading approach to improving robustness (see [Chapter 11](robustness.html))
    [[45]](references.html#ref-scholkopf2022causality).
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果性是提高鲁棒性的主要方法之一（见[第11章](robustness.html)） [[45]](references.html#ref-scholkopf2022causality)。
- en: Approaches for better uncertainty quantification, such as conformal prediction
    (see [Chapter 12](uncertainty.html)) are currently being integrated into causal
    inference [[46]](references.html#ref-lei2021conformal).
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前正在将更好的不确定性量化方法，如一致性预测（见[第12章](uncertainty.html)）整合到因果推理中 [[46]](references.html#ref-lei2021conformal)。
- en: '[1]J. Howard *et al.*, “An evidence review of face masks against COVID-19,”
    *Proceedings of the National Academy of Sciences*, vol. 118, no. 4, p. e2014564118,
    2021, doi: [10.1073/pnas.2014564118](https://doi.org/10.1073/pnas.2014564118).[2]Y.
    Alimohamadi, M. Sepandi, M. Taghdir, and H. Hosamirudsari, “Determine the most
    common clinical symptoms in COVID-19 patients: A systematic review and meta-analysis,”
    *Journal of preventive medicine and hygiene*, vol. 61, no. 3, p. E304, 2020, doi:
    [10.15167/2421-4248/jpmh2020.61.3.1530](https://doi.org/10.15167/2421-4248/jpmh2020.61.3.1530).[3]O.
    D’Ecclesiis *et al.*, “Vitamin d and SARS-CoV2 infection, severity and mortality:
    A systematic review and meta-analysis,” *PLoS One*, vol. 17, no. 7, p. e0268396,
    2022, doi: [10.1371/journal.pone.0268396](https://doi.org/10.1371/journal.pone.0268396).[4]F.
    Ayoub, T. Sato, and A. Sakuraba, “Football and COVID-19 risk: Correlation is not
    causation,” *Clinical Microbiology and Infection*, vol. 27, no. 2, pp. 291–292,
    2021, doi: [10.1016/j.cmi.2020.08.034](https://doi.org/10.1016/j.cmi.2020.08.034
    ) .[5]B. Schölkopf, D. Janzing, J. Peters, E. Sgouritsa, K. Zhang, and J. Mooij,
    “On causal and anticausal learning,” *arXiv preprint arXiv:1206.6471*, 2012, doi:
    [10.48550/arXiv.1206.6471](https://doi.org/10.48550/arXiv.1206.6471).[6]J. Pearl
    and D. Mackenzie, *The book of why: The new science of cause and effect*. Basic
    books, 2018.[7]Y. Gong and G. Zhao, “Wealth, health, and beyond: Is COVID-19 less
    likely to spread in rich neighborhoods?” *Plos one*, vol. 17, no. 5, p. e0267487,
    2022, doi: [10.1371%2Fjournal.pone.0267487](https://doi.org/10.1371%2Fjournal.pone.0267487).[8]C.
    Hitchcock and M. Rédei, “Reichenbach’s Common Cause Principle,” in *The Stanford
    encyclopedia of philosophy*, Summer 2021., E. N. Zalta, Ed., [https://plato.stanford.edu/archives/sum2021/entries/physics-Rpcc/](https://plato.stanford.edu/archives/sum2021/entries/physics-Rpcc/);
    Metaphysics Research Lab, Stanford University, 2021.[9]T. Vigen, *Spurious correlations*.
    Hachette UK, 2015.[10]J. Ellenberg, *How not to be wrong: The hidden maths of
    everyday life*. Penguin UK, 2014.[11]J. B. Gibbons *et al.*, “Association between
    vitamin d supplementation and COVID-19 infection and mortality,” *Scientific Reports*,
    vol. 12, no. 1, p. 19397, 2022, doi: [10.1038/s41598-022-24053-4](https://doi.org/10.1038/s41598-022-24053-4).[12]K.
    Yu *et al.*, “Causality-based feature selection: Methods and evaluations,” *ACM
    Computing Surveys (CSUR)*, vol. 53, no. 5, pp. 1–36, 2020, doi: [10.1145/3409382](https://doi.org/10.1145/3409382).[13]J.
    Adebayo, J. Gilmer, M. Muelly, I. Goodfellow, M. Hardt, and B. Kim, “Sanity checks
    for saliency maps,” *Advances in neural information processing systems*, vol.
    31, 2018, doi: [10.1609/aaai.v34i04.6064](https://doi.org/10.1609/aaai.v34i04.6064).[14]S.
    Hu *et al.*, “Weakly supervised deep learning for covid-19 infection detection
    and classification from ct images,” *IEEE Access*, vol. 8, pp. 118869–118883,
    2020, doi: [10.1109/access.2020.3005510](https://doi.org/10.1109/access.2020.3005510).[15]A.
    Fischer, “Resistance of children to covid-19\. how?” *Mucosal Immunology*, vol.
    13, no. 4, pp. 563–565, 2020, doi: [10.1038/s41385-020-0303-9](https://doi.org/10.1038/s41385-020-0303-9).[16]J.
    Pearl, *Causality*. Cambridge university press, 2009.[17]A. Sharma and E. Kiciman,
    “DoWhy: An end-to-end library for causal inference,” *arXiv preprint arXiv:2011.04216*,
    2020.[18]J. Yoon, J. Jordon, and M. Van Der Schaar, “GANITE: Estimation of individualized
    treatment effects using generative adversarial nets,” in *International conference
    on learning representations*, 2018.[19]S. Athey, J. Tibshirani, and S. Wager,
    “Generalized random forests,” 2019, doi: [10.1214/18-aos1709](https://doi.org/10.1214/18-aos1709).[20]M.
    C. Knaus, “Double machine learning-based programme evaluation under unconfoundedness,”
    *The Econometrics Journal*, vol. 25, no. 3, pp. 602–627, Jun. 2022, doi: [10.1093/ectj/utac015](https://doi.org/10.1093/ectj/utac015).[21]S.
    R. Künzel, J. S. Sekhon, P. J. Bickel, and B. Yu, “Metalearners for estimating
    heterogeneous treatment effects using machine learning,” *Proceedings of the national
    academy of sciences*, vol. 116, no. 10, pp. 4156–4165, 2019, doi: [10.1073/pnas.1804597116](https://doi.org/10.1073/pnas.1804597116).[22]V.
    Chernozhukov *et al.*, “Double/debiased machine learning for treatment and structural
    parameters.” Oxford University Press Oxford, UK, 2018\. doi: [10.1111/ectj.12097](https://doi.org/10.1111/ectj.12097).[23]Bach,
    V. Chernozhukov, M. S. Kurz, and M. Spindler, “DoubleML – An object-oriented implementation
    of double machine learning in R.” 2021\. doi: [10.32614/cran.package.doubleml](https://doi.org/10.32614/cran.package.doubleml).[24]Bach,
    V. Chernozhukov, M. S. Kurz, and M. Spindler, “DoubleML – An object-oriented implementation
    of double machine learning in Python,” *Journal of Machine Learning Research*,
    vol. 23, no. 53, pp. 1–6, 2022, doi: [10.18637/jss.v108.i03](https://doi.org/10.18637/jss.v108.i03).[25]S.
    Dandl, “Causality concepts in machine learning: Heterogeneous treatment effect
    estimation with machine learning & model interpretation with counterfactual and
    semi-factual explanations,” PhD thesis, lmu, 2023\. doi: [10.5282/edoc.32947](https://doi.org/10.5282/edoc.32947).[26]J.
    Rothfuss, F. Ferreira, S. Walther, and M. Ulrich, “Conditional density estimation
    with neural networks: Best practices and benchmarks,” *arXiv preprint arXiv:1903.00954*,
    2019, doi: [10.48550/arXiv.1903.00954](https://doi.org/10.48550/arXiv.1903.00954).[27]S.
    Beckers and J. Vennekens, “A principled approach to defining actual causation,”
    *Synthese*, vol. 195, no. 2, pp. 835–862, 2018, doi: [10.1007/s11229-016-1247-1](https://doi.org/10.1007/s11229-016-1247-1).[28]L.
    Jehi *et al.*, “Individualizing risk prediction for positive coronavirus disease
    2019 testing: Results from 11,672 patients,” *Chest*, vol. 158, no. 4, pp. 1364–1375,
    2020, doi: [10.1016/j.chest.2020.05.580.](https://doi.org/10.1016/j.chest.2020.05.580.)[29]G.
    König, T. Freiesleben, and M. Grosse-Wentrup, “Improvement-focused causal recourse
    (ICR),” in *Proceedings of the AAAI conference on artificial intelligence*, 2023,
    pp. 11847–11855\. doi: [10.1609/aaai.v37i10.26398](https://doi.org/10.1609/aaai.v37i10.26398).[30]J.
    Peters, D. Janzing, and B. Schölkopf, *Elements of causal inference: Foundations
    and learning algorithms*. The MIT Press, 2017.[31]K. Fukumizu, A. Gretton, X.
    Sun, and B. Schölkopf, “Kernel measures of conditional dependence,” *Advances
    in neural information processing systems*, vol. 20, 2007.[32]R. Sen, A. T. Suresh,
    K. Shanmugam, A. G. Dimakis, and S. Shakkottai, “Model-powered conditional independence
    test,” *Advances in neural information processing systems*, vol. 30, 2017, doi:
    [10.5555/3294996.3295055](https://doi.org/10.5555/3294996.3295055).[33]D. S. Watson
    and M. N. Wright, “Testing conditional independence in supervised learning algorithms,”
    *Machine Learning*, vol. 110, no. 8, pp. 2107–2129, Aug. 2021, doi: [10.1007/s10994-021-06030-6](https://doi.org/10.1007/s10994-021-06030-6).[34]R.
    D. Shah and J. Peters, “The hardness of conditional independence testing and the
    generalised covariance measure,” *The Annals of Statistics*, vol. 48, no. 3, pp.
    1514–1538, 2020, doi: [10.1214/19-AOS1857](https://doi.org/10.1214/19-AOS1857).[35]M.
    Kalisch, M. Mächler, D. Colombo, M. H. Maathuis, and P. Bühlmann, “Causal inference
    using graphical models with the r package pcalg,” *Journal of statistical software*,
    vol. 47, pp. 1–26, 2012, doi: [10.18637/jss.v047.i11](https://doi.org/10.18637/jss.v047.i11).[36]P.
    Spirtes, C. N. Glymour, and R. Scheines, *Causation, prediction, and search*.
    MIT press, 2000\. doi: [10.1007/978-1-4612-2748-9](https://doi.org/10.1007/978-1-4612-2748-9).[37]F.
    Eberhardt, C. Glymour, and R. Scheines, “On the number of experiments sufficient
    and in the worst case necessary to identify all causal relations among n variables,”
    in *Proceedings of the twenty-first conference on uncertainty in artificial intelligence*,
    in UAI’05\. Arlington, Virginia, USA: AUAI Press, 2005, pp. 178–184.[38]C. F.
    Manski, *Partial identification of probability distributions*, vol. 5\. Springer,
    2003\. doi: [10.1007/b97478](https://doi.org/10.1007/b97478).[39]C. Uhler, G.
    Raskutti, P. Bühlmann, and B. Yu, “Geometry of the faithfulness assumption in
    causal inference,” *The Annals of Statistics*, pp. 436–463, 2013.[40]B. Neal,
    “Introduction to causal inference,” *Course Lecture Notes (draft)*, 2020.[41]S.
    Beckers and J. Y. Halpern, “Abstracting causal models,” in *Proceedings of the
    aaai conference on artificial intelligence*, 2019, pp. 2678–2685\. doi: [10.1609/aaai.v33i01.33012678](https://doi.org/10.1609/aaai.v33i01.33012678).[42]P.
    W. Koh *et al.*, “Concept bottleneck models,” in *International conference on
    machine learning*, PMLR, 2020, pp. 5338–5348.[43]Y. Bengio, A. Courville, and
    P. Vincent, “Representation learning: A review and new perspectives,” *IEEE Transactions
    on Pattern Analysis and Machine Intelligence*, vol. 35, no. 8, pp. 1798–1828,
    2013, doi: [10.1109/TPAMI.2013.50](https://doi.org/10.1109/TPAMI.2013.50).[44]B.
    Schölkopf *et al.*, “Toward causal representation learning,” *Proceedings of the
    IEEE*, vol. 109, no. 5, pp. 612–634, 2021, doi: [10.1109/JPROC.2021.3058954](https://doi.org/10.1109/JPROC.2021.3058954).[45]B.
    Schölkopf, “Causality for machine learning,” in *Probabilistic and causal inference:
    The works of judea pearl*, 2022, pp. 765–804.[46]L. Lei and E. J. Candès, “Conformal
    inference of counterfactuals and individual treatment effects,” *Journal of the
    Royal Statistical Society Series B: Statistical Methodology*, vol. 83, no. 5,
    pp. 911–938, 2021, doi: [10.1111/rssb.12445](https://doi.org/10.1111/rssb.12445).'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There is also an association between COVID risk and the FIFA football ranking
    [[4]](references.html#ref-ayoub2021football). Here, the causal story is spuriously
    Messi…[↩︎](#fnref1)
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: COVID风险与FIFA足球排名之间也存在关联 [[4]](references.html#ref-ayoub2021football)。在这里，因果故事是莫名的梅西…[↩︎](#fnref1)
- en: Saitama is the protagonist of the anime series “One-Punch Man” who defeats his
    opponents with just one punch. In one of the episodes, he accidentally damages
    good old Jupiter.[↩︎](#fnref2)
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 埼玉是动漫系列“一拳超人”的主角，他只需一拳就能击败对手。在一集中，他意外地损坏了老好的木星。[↩︎](#fnref2)
- en: There are two general approaches for estimating treatment effects with machine
    learning, model-agnostic and model-specific techniques. Model-specific techniques
    are based on a certain class of machine learning models, such as GANITE for neural
    nets [[18]](references.html#ref-yoon2018ganite) or causal forests for random forests
    [[19]](references.html#ref-athey2019generalized). Model-specific techniques often
    come with the advantage of valid confidence intervals. Other techniques are model
    agnostic, which means, you can simply plug in any machine learning model into
    the estimation. The T-Learner and Double Machine Learning we present here are
    examples of such model-agnostic approaches. Today, there are tons of approaches
    to estimating causal effects with machine learning, check out [[20]](references.html#ref-Knaus2022)
    or [[21]](references.html#ref-kunzel2019metalearners) to learn more.[↩︎](#fnref3)
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用机器学习估计治疗效果有两种一般方法，即模型无关和模型特定技术。模型特定技术基于某一类机器学习模型，例如用于神经网络的GANITE [[18]](references.html#ref-yoon2018ganite)
    或用于随机森林的因果森林 [[19]](references.html#ref-athey2019generalized)。模型特定技术通常具有有效置信区间的优势。其他技术是模型无关的，这意味着您可以将任何机器学习模型简单地插入到估计中。我们在这里提出的T-Learner和双机器学习就是这类模型无关方法的例子。今天，有大量使用机器学习估计因果效应的方法，您可以查看
    [[20]](references.html#ref-Knaus2022) 或 [[21]](references.html#ref-kunzel2019metalearners)
    以了解更多信息。[↩︎](#fnref3)
- en: In the literature, it is differentiated between counterfactuals and actual causes
    [[27]](references.html#ref-beckers2018principled).[↩︎](#fnref4)
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文献中，反事实和实际原因被区分开来 [[27]](references.html#ref-beckers2018principled)。[↩︎](#fnref4)
- en: The parents are indeed also non-descendants. However, the conditional independence
    you can derive from the causal Markov condition between \(E\) of \(C\) given you
    know \(C\) holds trivially for an arbitrary variable by \(\mathbb{P}(E,C\mid C)=\mathbb{P}(E,C,C)/\mathbb{P}(C)=\mathbb{P}(E\mid
    C)=\mathbb{P}(E\mid C)\mathbb{P}(C\mid C).\)[↩︎](#fnref5)
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 父母实际上也是非后裔。然而，从因果马尔可夫条件中可以推导出的条件独立性，在已知 \(C\) 的情况下对 \(E\) 的 \(C\)，对于任意变量来说都是显而易见的，因为
    \(\mathbb{P}(E,C\mid C)=\mathbb{P}(E,C,C)/\mathbb{P}(C)=\mathbb{P}(E\mid C)=\mathbb{P}(E\mid
    C)\mathbb{P}(C\mid C)\)。[↩︎](#fnref5)
- en: The PC algorithm is already quite old but great for understanding the general
    idea of causal discovery. There are many extensions, generalizations, and alternatives
    of PCs on the market. We point you to [[30]](references.html#ref-peters2017elements)
    for an overview and to [[35]](references.html#ref-kalisch2012causal) for an R
    package implementing standard causal discovery algorithms.[↩︎](#fnref6)
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PC算法已经相当古老，但非常适合理解因果发现的总体概念。市场上有很多PC的扩展、泛化和替代方案。我们为您提供了 [[30]](references.html#ref-peters2017elements)
    的概述，以及 [[35]](references.html#ref-kalisch2012causal) 的R包，该包实现了标准的因果发现算法。[↩︎](#fnref6)
- en: Causal abstraction is a cool framework for thinking about the relationship between
    low-level and high-level causal representations [[41]](references.html#ref-beckers2019abstracting).
    Science is all about causal models at different levels of description, think of
    the relationship between physical models, chemical models, and biological models.[↩︎](#fnref7)*****
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因果抽象是一个用于思考低级和高级因果表示之间关系的酷框架 [[41]](references.html#ref-beckers2019abstracting)。科学就是关于不同描述层次上的因果模型，想想物理模型、化学模型和生物模型之间的关系。[↩︎](#fnref7)*****
