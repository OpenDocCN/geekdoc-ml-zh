- en: 13  Reproducibility
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 可复现性
- en: 原文：[https://ml-science-book.com/reproducibility.html](https://ml-science-book.com/reproducibility.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ml-science-book.com/reproducibility.html](https://ml-science-book.com/reproducibility.html)
- en: '[Integrating Machine Learning Into Science](./part-two.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[将机器学习融入科学](./part-two.html)'
- en: '[13  Reproducibility](./reproducibility.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[13 可复现性](./reproducibility.html)'
- en: 'The beauty of code: Once written, you can use it as often as you like. If set
    up correctly, the same code applied to the same data will produce the same results.
    Ideally, training your machine learning model works the same: at the click of
    a button, you can run your code again and get the exact same machine learning
    model. This is known as computational reproducibility, and it [comes with many
    advantages](https://book.the-turing-way.org/reproducible-research/overview/overview-benefit).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 代码之美：一旦编写，你可以随心所欲地使用它。如果设置正确，相同的代码应用于相同的数据将产生相同的结果。理想情况下，训练你的机器学习模型也是一样的：点击一下按钮，你就可以再次运行你的代码，并得到完全相同的机器学习模型。这被称为计算可复现性，它[带来了许多优势](https://book.the-turing-way.org/reproducible-research/overview/overview-benefit)。
- en: Reproducibility makes it easier to track changes in your project.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可复现性使跟踪项目中的变化变得更容易。
- en: You can reproduce your work. Comes in handy when reviewer 2 asks you to retrain
    your model.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以复现你的工作。当审稿人2要求你重新训练你的模型时，这会很有用。
- en: People will enjoy working with you and your beautiful code base.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们会喜欢与你和你的美丽代码库一起工作。
- en: Other researchers can build on your work.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他研究人员可以基于你的工作继续研究。
- en: Reproducibility allows you to put a model into production later.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可复现性允许你稍后把模型投入生产。
- en: But making your code reproducible is much harder than it seems. Computational
    reproducibility is inherently unstable due to ever-changing computing environments
    and the unique challenges of machine learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但使你的代码可复现比看起来要困难得多。由于不断变化的计算环境和机器学习的独特挑战，计算可复现性本质上是不稳定的。
- en: '*Reproducibility versus replicability* *You may have heard about the replicability
    crisis in the social sciences [[1]](references.html#ref-open2015estimating): Many
    research findings couldn’t be replicated. Reproducibility focuses on a narrower
    goal: getting the same results (e.g. the same model) using the same code on the
    same data. For an overview of definitions, see the [Turing Way Book](https://book.the-turing-way.org/reproducible-research/overview/overview-definitions)
    [[2]](references.html#ref-arnold2019turing).*  *Reproducibility is not binary,
    but it is a spectrum. This chapter will help you move up that spectrum by highlighting
    the unique challenges that machine learning poses to reproducibility. Let’s dive
    in.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*可复现性与可重复性* *你可能已经听说过社会科学中的可重复性危机 [[1]](references.html#ref-open2015estimating)：许多研究结果无法重复。可复现性关注一个更窄的目标：使用相同的代码在相同的数据上得到相同的结果（例如，相同的模型）。有关定义的概述，请参阅[Turing
    Way Book](https://book.the-turing-way.org/reproducible-research/overview/overview-definitions)
    [[2]](references.html#ref-arnold2019turing)。*  *可复现性不是二元的，而是一个连续体。本章将通过突出机器学习对可复现性提出的独特挑战，帮助你在这个连续体上前进。让我们深入探讨。*'
- en: The tornado prediction model worked like a charm for many years. Until it didn’t.
    One hot summer day, the server had a meltdown and the model was gone. Rattle went
    into early retirement with a wealth of money, but her original learning algorithm
    was still sitting on an old laptop. Well, should be a simple retraining task.
    Or so they thought. They were confronted with a strange folder structure, mysterious
    file names, and unclear instructions. Other Ravens’ code can be such a pain.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 暴风雨预测模型多年来一直工作得很好。直到它不再了。在一个炎热的夏日，服务器崩溃了，模型消失了。Rattle带着丰富的财富提前退休了，但她的原始学习算法仍然坐在一台旧笔记本电脑上。嗯，应该是一个简单的再训练任务。或者他们是这样想的。他们面对的是一个奇怪的文件夹结构，神秘的文件名，以及不明确的说明。其他ravens的代码可能会很痛苦。
- en: '![](../Images/bab47648c997b411e3835973c0ac5751.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bab47648c997b411e3835973c0ac5751.png)'
- en: 13.1 Making any coding project reproducible
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 使任何编码项目可复现
- en: 'Reproducibility is a challenge for any coding project even without machine
    learning. This chapter focuses more on the machine learning-specific challenges,
    but it wouldn’t be complete if we didn’t mention some general tips and tricks
    for reproducibility [[3]](references.html#ref-seibold_2024_12744715):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可复现性对于任何编码项目来说都是一个挑战，即使没有机器学习也是如此。本章更多地关注机器学习特有的挑战，但如果我们不提及一些关于可复现性的通用技巧和窍门，它就不会完整
    [[3]](references.html#ref-seibold_2024_12744715)：
- en: Create a clear folder structure.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个清晰的文件夹结构。
- en: Use good names for files, folders, and functions.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为文件、文件夹和函数使用好的名称。
- en: Document your project, including a README, metadata, and code documentation.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录你的项目，包括README、元数据和代码文档。
- en: Use version control software such as git to track changes to code and text.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用git等版本控制软件来跟踪代码和文本的变化。
- en: Stabilize the computing environment and software using environment management
    tools such as Conda and virtualization tools such as Docker.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Conda等环境管理工具和Docker等虚拟化工具来稳定计算环境和软件。
- en: Automate computations, e.g. Makefile, workflow stuff, and have all steps reproducible
    with code.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化计算，例如Makefile、工作流程相关内容，并确保所有步骤都能通过代码进行复现。
- en: Publish your work.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布你的工作。
- en: The more of these tips you follow, the more reproducible and satisfying your
    project will be. However, it may require learning new tools like git and adopting
    new habits like documenting your code – this is an initial investment of time
    and effort, but it will pay off in the long run. Your future self will thank you.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你遵循的这些提示越多，你的项目就越具有可复现性和满意度。然而，这可能需要学习新的工具，如git，并养成新的习惯，如记录代码——这是一次时间和精力的初始投资，但长远来看会得到回报。你的未来自我会感谢你。
- en: Now let’s move on to the machine learning-specific challenges.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续探讨机器学习特有的挑战。
- en: 13.2 Handling non-deterministic code
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 处理非确定性代码
- en: 'Running the same code twice can produce different results due to randomness.
    Machine learning involves a lot of randomness: random weight initialization, stochastic
    gradient descent, random forests, and random data splitting. It is not a bug,
    it is a feature: Randomness is an inherent driver of learning. For example, randomly
    splitting data into training and testing simulates “drawing from the same distribution”
    which is a crucial element of generalization (see [Chapter 7](generalization.html))
    and stochastic gradient descent implicitly regularizes the model through its random
    nature [[4]](references.html#ref-bottou2010largescale).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 运行相同的代码两次可能会因为随机性而产生不同的结果。机器学习涉及大量的随机性：随机权重初始化、随机梯度下降、随机森林和随机数据分割。这不是错误，这是一个特性：随机性是学习的内在驱动力。例如，随机将数据分割为训练集和测试集模拟了“从同一分布中抽取”的过程，这是泛化的关键要素（参见[第7章](generalization.html)）和随机梯度下降通过其随机性质隐式地正则化模型
    [[4]](references.html#ref-bottou2010largescale)。
- en: To introduce randomness into the deterministic world of programming logic, machine
    learning software relies on “random number generators”. These generators are not
    truly random – they are based on pseudorandom processes that can be controlled
    by setting an initial random seed. A random seed initializes the random number
    generator, and all subsequent “random” numbers are deterministic.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将随机性引入编程逻辑的确定性世界，机器学习软件依赖于“随机数生成器”。这些生成器并非真正随机——它们基于伪随机过程，可以通过设置一个初始随机种子来控制。随机种子初始化随机数生成器，所有后续的“随机”数都是确定性的。
- en: 'This random seed is also your key to reproducibility for code with randomness.
    Without a random seed, training a machine learning model will produce different
    models every time. At least it is unlikely to get the same results twice. But
    by setting a random seed, you make the random number generation reproducible.
    There are some exceptions: When running multiple processes in parallel, setting
    a random seed may still not guarantee deterministic results if the order of execution
    is inconsistent.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个随机种子也是你实现具有随机性的代码可复现性的关键。没有随机种子，每次训练机器学习模型都会产生不同的模型。至少，两次得到相同结果的可能性很小。但通过设置随机种子，你可以使随机数生成可复现。有一些例外：当并行运行多个进程时，如果执行顺序不一致，设置随机种子可能仍然不能保证确定性结果。
- en: 'Besides your computer’s random number generator, there are other reasons why
    running the same code twice may produce different results, even if you have followed
    all the tips, like making sure you are using the same software:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 除了你电脑的随机数生成器外，还有其他原因可能导致运行相同的代码两次产生不同的结果，即使你已经遵循了所有提示，比如确保你使用的是相同的软件：
- en: Operations on GPUs can be non-deterministic, even simple ones like a sum (see
    [this StackOverflow question](https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu)).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU上进行的操作可能是非确定性的，即使是像求和这样的简单操作（参见[这个StackOverflow问题](https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu)）。
- en: External systems can change over time (e.g. API calls).
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外部系统可能会随时间变化（例如API调用）。
- en: Floating point arithmetic can vary between different hardware and software platforms.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浮点运算在不同硬件和软件平台上可能会有所不同。
- en: 13.3 Jupyter Notebooks
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3 Jupyter Notebooks
- en: Jupyter Notebooks are a blessing and a course to research.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebooks是研究中的祝福和诅咒。
- en: '*Jupyter Notebook* *The term refers to both the software and the document,
    just as “Excel” can refer to both the program and a single spreadsheet. Jupyter
    Notebooks – the software – is essentially an HTML application where you can manage
    multiple notebooks (the documents), create new ones, delete, edit, and run them.
    A notebook – the document – is a collection of “cells”. A cell can contain markdown,
    code, or plain text. Markdown cells are rendered so that you can structure your
    notebook like a document, with titles, bold text, and other formatting. You can
    execute code cells, and the results are embedded in the document, whether it is
    a plot, code warnings, or a printout.*  *Notebooks let you experiment, quickly
    prototype ideas, and explore data; they encourage documentation; they are great
    for reporting results. But they make reproducibility difficult. In his provocative
    talk [“I Don’t Like Notebooks”](https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI),
    Joel Grus specifically criticized “hidden states” that make reproducibility difficult:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*Jupyter Notebook* 这个术语既指软件也指文档，就像“Excel”可以指程序也可以指单个电子表格一样。Jupyter Notebooks（软件）本质上是一个HTML应用程序，您可以在其中管理多个笔记本（文档），创建新的，删除，编辑和运行它们。笔记本（文档）是一系列“单元格”。单元格可以包含Markdown、代码或纯文本。Markdown单元格被渲染，以便您可以像文档一样结构化笔记本，包括标题、粗体文本和其他格式。您可以执行代码单元格，结果会嵌入到文档中，无论是图表、代码警告还是打印输出。*  *Notebooks让您可以实验，快速原型设计，探索数据；它们鼓励文档记录；它们非常适合报告结果。但它们使可重复性变得困难。在Joel
    Grus的挑衅性演讲[“我不喜欢Notebooks”](https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI)中，他特别批评了“隐藏状态”，这使得可重复性变得困难：'
- en: You can run the cells in any order.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以按任何顺序运行单元格。
- en: You can delete cells, but the variables that were created remain in the workspace.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以删除单元格，但创建的变量仍然保留在工作区中。
- en: You can change a cell’s content while only running the old version.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在只运行旧版本的情况下更改单元格的内容。
- en: Imagine you’re working on a machine learning project in a Jupyter Notebook.
    You decide to standardize features before training but forget to run the updated
    cell. You save the model, but now the code doesn’t match the model, and re-running
    the notebook produces a different model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 想象您正在Jupyter Notebook中从事一个机器学习项目。您决定在训练之前标准化特征，但忘记运行更新的单元格。您保存了模型，但现在代码与模型不匹配，重新运行笔记本会产生不同的模型。
- en: In another scenario, you accidentally delete the cell that generates a weight
    vector shortly after writing the code. But because you executed the cell, the
    vector is in memory. You finish the project, check your latest changes into version
    control, and call it a day. The next person to work on the project gets an error
    about the missing weight vector.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一种情况下，您在编写代码后不久意外删除了生成权重向量的单元格。但由于您已执行了该单元格，向量已存储在内存中。您完成了项目，将最新的更改提交到版本控制，然后结束工作。下一个参与项目的人会遇到关于缺失权重向量的错误。
- en: 'There are even more problems with notebooks: While you can put them under version
    control, they are quite verbose because they store all HTML output, and actually
    comparing code changes is no fun like this.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本还有更多问题：虽然您可以将其置于版本控制之下，但它们相当冗长，因为它们存储了所有HTML输出，实际上比较代码更改并不像这样有趣。
- en: It is possible to make a research project reproducible, even if it relies on
    notebooks. But you have to be very strict about running them *linearly* from the
    first cell to the last, and always with a fresh Python session.*  *## 13.4 APIs
    and proprietary software
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 即使研究项目依赖于笔记本，也有可能使其可重复。但您必须非常严格地从第一个单元格到最后的单元格线性运行它们，并且始终使用一个新的Python会话。*  *##
    13.4 API和专有软件
- en: 'Training a machine learning algorithm on someone else’s hardware can make your
    life a lot easier: You don’t have to worry about hardware and software installations.
    Hundreds of machine-learning-as-a-service platforms allow you to upload your data
    and train a model. The problem: lack of reproducibility. The company behind the
    machine learning software can change its software without informing you. And even
    if they don’t: You may not have enough control over the workflow to make it fully
    reproducible for others. It may not be transparent what algorithms, settings,
    and software versions the platform uses. Or the company may simply go out of business
    and you lose access to your training setup.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在他人的硬件上训练机器学习算法可以使你的生活变得更加容易：你不必担心硬件和软件的安装。数百个机器学习即服务平台允许你上传数据并训练模型。问题是缺乏可重复性。机器学习软件背后的公司可以更改其软件而不通知你。即使他们没有这样做：你可能没有足够的控制权来使工作流程对他人完全可重复。可能不清楚平台使用的算法、设置和软件版本。或者公司可能简单地倒闭，你将失去访问你的训练设置。
- en: 'This problem has gotten much worse with generative AI, especially with large
    language models like ChatGPT. Whether you are studying ChatGPT for bias or using
    it to label data: The company behind it is constantly updating the models, and
    once a model is retired, no one can reproduce your research.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式AI的发展，特别是像ChatGPT这样的大型语言模型，这个问题变得更加严重。无论你是为了研究ChatGPT的偏见还是用它来标注数据：背后的公司不断更新模型，一旦一个模型被退役，就没有人能够复制你的研究。
- en: 13.5 Hardware-specific challenges
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 硬件特定挑战
- en: Even if you control the server or use your laptop and have followed all the
    reproducibility recommendations, your project may still not be at 100% reproducible.
    At least when it comes to running your code on different hardware. The problem
    is that we can’t completely abstract the training and so on from the hardware.
    Increasingly, machine learning, especially deep learning, relies on more specific
    hardware, such as NVIDIA GPUs and Google TPUs. The more hardware-specific your
    setup, the harder it is for others to reproduce your models.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你控制服务器或使用你的笔记本电脑并遵循了所有可重复性建议，你的项目可能仍然无法达到100%的可重复性。至少当涉及到在不同的硬件上运行你的代码时是这样。问题是，我们无法完全抽象化训练等操作与硬件的关系。越来越，机器学习，尤其是深度学习，依赖于更具体的硬件，如NVIDIA
    GPU和Google TPUs。你的设置越依赖于硬件，其他人复制你的模型就越困难。
- en: 13.6 Inaccessible data
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.6 无法访问的数据
- en: 'Data can be inaccessible for a number of reasons: it may be too large to share,
    there may be privacy concerns (such as patient data), or it may be proprietary.
    This makes reproducibility difficult. But even making it reproducible within the
    project itself can be difficult, especially with large datasets. A possible “incremental”
    solution would be to share a subset of the data or simulated data.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可能由于多种原因而无法访问：它可能太大而无法共享，可能存在隐私问题（例如患者数据），或者可能是专有的。这使得可重复性变得困难。但是，即使在项目内部使其可重复也可能很困难，尤其是在处理大型数据集时。一个可能的“增量”解决方案是共享数据子集或模拟数据。
- en: '*Reproducible versus reusable* *Reproducibility and reusability are not the
    same thing: A research result can be reproducible without being reusable. You
    may be able to reproduce someone else’s project but if, for example, many things
    are hard-coded, it will take a lot of effort to adapt it to your use case.*  *##
    13.7 Reproducibility and other issues'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*可重复性与可重用性* 可重复性与可重用性不是同一回事：一个研究结果可以是可重复的，而不一定是可重用的。你可能能够复制他人的项目，但如果例如许多内容是硬编码的，那么适应你的用例将需要大量的努力。*##
    13.7 可重复性与其他问题'
- en: 'Reproducibility is about more than just making sure that others, including
    your future self, can reproduce your work. It relates to many other aspects we
    cover in this book:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 可重复性不仅仅是确保其他人，包括你未来的自己，可以复制你的工作。它与我们在这本书中讨论的许多其他方面相关：
- en: 'You can think of reproducibility as a form of robustness (see [Chapter 11](robustness.html)):
    A reproducible model is robust to the computing environment and to the random
    number generation.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将可重复性视为一种鲁棒性（参见[第11章](robustness.html)）：一个可重复的模型对计算环境和随机数生成都是鲁棒的。
- en: A lack of reproducibility introduces uncertainty (see [Chapter 12](uncertainty.html)).
    Let’s say you forgot to set a random seed. This means that the next time the model
    is trained, it will be subject to uncertainty due to random splitting of the data
    and other operations based on a random number generator.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏可重复性会引入不确定性（见[第12章](uncertainty.html)）。比如说你忘记设置随机种子。这意味着下一次模型训练时，它将由于数据随机分割和其他基于随机数生成器的操作而面临不确定性。
- en: 'Publication (see [Chapter 14](reporting.html)) and reproducibility both rely
    on documentation and go well together: If you have good reporting, you have also
    made your project more reproducible.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出版（见[第14章](reporting.html)）和可重复性都依赖于文档，并且相辅相成：如果你有良好的报告，你的项目也变得更易于重复。
- en: '[1]O. S. Collaboration, “Estimating the reproducibility of psychological science,”
    *Science*, vol. 349, no. 6251, p. aac4716, 2015, doi: [10.1126/science.aac4716](https://doi.org/10.1126/science.aac4716).[2]B.
    Arnold *et al.*, “The turing way: A handbook for reproducible data science,” *Zenodo*,
    2019.[3]H. Seibold, *6 steps towards reproducible research*. Zenodo, 2024\. doi:
    [10.5281/zenodo.12744715](https://doi.org/10.5281/zenodo.12744715).[4]L. Bottou,
    “Large-Scale Machine Learning with Stochastic Gradient Descent,” in *Proceedings
    of COMPSTAT’2010*, Y. Lechevallier and G. Saporta, Eds., Heidelberg: Physica-Verlag
    HD, 2010, pp. 177–186\. doi: [10.1007/978-3-7908-2604-3_16](https://doi.org/10.1007/978-3-7908-2604-3_16).***'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]O. S. Collaboration, “Estimating the reproducibility of psychological science,”
    *Science*, vol. 349, no. 6251, p. aac4716, 2015, doi: [10.1126/science.aac4716](https://doi.org/10.1126/science.aac4716).[2]B.
    Arnold *et al.*, “The turing way: A handbook for reproducible data science,” *Zenodo*,
    2019.[3]H. Seibold, *6 steps towards reproducible research*. Zenodo, 2024\. doi:
    [10.5281/zenodo.12744715](https://doi.org/10.5281/zenodo.12744715).[4]L. Bottou,
    “Large-Scale Machine Learning with Stochastic Gradient Descent,” in *Proceedings
    of COMPSTAT’2010*, Y. Lechevallier and G. Saporta, Eds., Heidelberg: Physica-Verlag
    HD, 2010, pp. 177–186\. doi: [10.1007/978-3-7908-2604-3_16](https://doi.org/10.1007/978-3-7908-2604-3_16).***'
