- en: Conclusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: '*DALL·E 3 Prompt: An image depicting a concluding chapter of an ML systems
    book, open to a two-page spread. The pages summarize key concepts such as neural
    networks, model architectures, hardware acceleration, and MLOps. One page features
    a diagram of a neural network and different model architectures, while the other
    page shows illustrations of hardware components for acceleration and MLOps workflows.
    The background includes subtle elements like circuit patterns and data points
    to reinforce the technological theme. The colors are professional and clean, with
    an emphasis on clarity and understanding.*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*DALL·E 3 提示：一幅描绘机器学习系统书籍结论章节的图像，展开至两页。页面总结了诸如神经网络、模型架构、硬件加速和MLOps等关键概念。一页展示神经网络和不同模型架构的图表，另一页展示了用于加速和MLOps工作流程的硬件组件插图。背景中包含电路图案和数据点等细微元素，以强化技术主题。色彩专业且干净，强调清晰度和理解性。*'
- en: '![](../media/file327.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file327.png)'
- en: '**Learning Objectives**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习目标**'
- en: Synthesize the six core systems engineering principles that transcend specific
    ML technologies and provide systematic guidance for engineering decisions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 综合超越特定机器学习技术的六个核心系统工程原则，为工程决策提供系统指导
- en: Analyze how the “measure everything” principle manifests across data engineering,
    benchmarking, and operational monitoring contexts
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析“衡量一切”原则如何在数据工程、基准测试和运营监控环境中体现
- en: Apply the “design for 10x scale” principle to evaluate system architectures
    for cloud, edge, and mobile deployment scenarios
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用“设计10倍扩展”原则来评估云、边缘和移动部署场景的系统架构
- en: Evaluate bottleneck optimization strategies across the full ML systems stack
    from data pipelines to inference deployment
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估从数据管道到推理部署的完整机器学习系统栈中的瓶颈优化策略
- en: Critique failure planning approaches in ML systems by comparing traditional
    software reliability with ML-specific failure modes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过比较传统软件可靠性与机器学习特定的故障模式来批判机器学习系统中的故障规划方法
- en: Design cost-conscious ML systems that balance computational performance, operational
    expenses, and environmental sustainability
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计成本意识强的机器学习系统，平衡计算性能、运营成本和环境可持续性
- en: Assess hardware-software co-design opportunities across different deployment
    contexts including cloud, edge, and embedded systems
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估不同部署场景（包括云、边缘和嵌入式系统）中的硬件-软件协同设计机会
- en: Create integrated solutions that combine technical excellence with operational
    maturity, security requirements, and ethical considerations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建结合技术卓越、运营成熟度、安全需求和伦理考量的综合解决方案
- en: 'Synthesizing ML Systems Engineering: From Components to Intelligence'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 综合机器学习系统工程：从组件到智能
- en: This chapter synthesizes machine learning systems engineering concepts from
    the preceding twenty chapters, establishing systems thinking as the fundamental
    paradigm for artificial intelligence development. Our progression from data engineering
    principles through model architectures, optimization techniques, and operational
    infrastructure has constructed a comprehensive knowledge foundation spanning ML
    systems engineering. This synthesis establishes theoretical and practical frameworks
    that define professional competency in machine learning systems engineering within
    computer systems research.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章综合了前二十章中机器学习系统工程的概念，确立了系统思维作为人工智能发展的基本范式。我们从数据工程原则到模型架构、优化技术和运营基础设施的进步，构建了一个涵盖机器学习系统工程的全面知识基础。这种综合建立了理论和实践框架，定义了计算机系统研究范围内机器学习系统工程的职业能力。
- en: 'Contemporary artificial intelligence[1](#fn1) achievements emerge not from
    isolated algorithmic innovations, but through principled systems integration that
    unifies computational theory with engineering practice. This systems perspective
    positions machine learning within computer systems engineering traditions, where
    transformative capabilities arise from systematic orchestration of interdependent
    components. The transformer architectures ([Vaswani et al. 2017](ch058.xhtml#ref-vaswani2017attention))
    enabling large language models exemplify this principle: their practical utility
    derives from integrating mathematical foundations with distributed training infrastructure,
    algorithmic optimization techniques, and robust operational frameworks rather
    than architectural innovation alone.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当代人工智能[1](#fn1)的成就并非来自孤立的算法创新，而是通过原则性的系统集成，将计算理论与工程实践统一起来。这种系统视角将机器学习置于计算机系统工程传统之中，其中变革性能力源于对相互依存组件的系统协调。使大型语言模型成为可能的变压器架构([Vaswani
    et al. 2017](ch058.xhtml#ref-vaswani2017attention))体现了这一原则：它们的实际效用源于将数学基础与分布式训练基础设施、算法优化技术和稳健的运营框架相结合，而不仅仅是架构创新。
- en: This chapter addresses three fundamental questions that define machine learning
    systems engineering boundaries. First, what enduring principles transcend specific
    technologies and provide systematic guidance for engineering decisions across
    deployment contexts, from contemporary production systems to anticipated artificial
    general intelligence architectures? Second, how do these principles manifest across
    resource-abundant cloud infrastructures, resource-constrained edge devices, and
    emerging generative systems? Third, how can this knowledge be applied systematically
    to create systems that satisfy technical requirements while addressing broader
    societal objectives and ethical considerations?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了定义机器学习系统工程边界的三个基本问题。首先，哪些持久的原则超越了具体技术，并为部署环境中的工程决策提供系统指导，从当代生产系统到预期的通用人工智能架构？其次，这些原则如何在资源丰富的云基础设施、资源受限的边缘设备和新兴的生成系统中体现？第三，如何系统地应用这些知识来创建满足技术要求的同时解决更广泛的社会目标和伦理考量的系统？
- en: 'Our analysis reflects the systems thinking paradigm that has structured this
    textbook, drawing from established computer systems research and engineering methodology.
    We systematically derive six fundamental engineering principles from technical
    concepts established throughout the text: comprehensive measurement, scale-oriented
    design, bottleneck optimization, systematic failure planning, cost-conscious design,
    and hardware co-design. These principles constitute a framework for principled
    decision-making across machine learning systems contexts. We examine their application
    across three domains that structure contemporary ML systems engineering: establishing
    technical foundations, engineering for performance at scale, and navigating production
    deployment realities.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析反映了构建这本教科书的系统思维范式，借鉴了建立已久的计算机系统研究和方法。我们从文本中确立的技术概念中系统地推导出六个基本工程原则：全面测量、面向规模的设计、瓶颈优化、系统故障规划、成本意识设计和硬件协同设计。这些原则构成了在机器学习系统环境中进行原则性决策的框架。我们考察了它们在三个构建当代机器学习系统工程的领域中应用：建立技术基础、面向规模性能的工程和导航生产部署现实。
- en: The analysis examines emerging frontiers where these principles confront their
    most significant challenges. From developing resilient AI systems that manage
    failure modes gracefully to deploying artificial intelligence for societal benefit
    across healthcare, education, and climate science, these engineering principles
    will determine artificial intelligence’s societal impact trajectory. As artificial
    intelligence systems approach general intelligence capabilities[2](#fn2), the
    critical question becomes not feasibility, but whether they will be engineered
    according to established principles of sound systems design and responsible computing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 分析考察了这些原则面临其最显著挑战的新兴前沿。从开发能够优雅处理故障模式的弹性人工智能系统，到在医疗保健、教育和气候科学等领域部署人工智能以造福社会，这些工程原则将决定人工智能的社会影响轨迹。随着人工智能系统接近通用智能能力[2](#fn2)，关键问题不再是可行性，而是它们是否将根据既定的良好系统设计和负责任计算原则进行工程化。
- en: 'The frameworks synthesized in this chapter establish systematic approaches
    for navigating the rapidly evolving artificial intelligence technology landscape
    while maintaining focus on fundamental engineering objectives: creating systems
    that scale effectively, perform reliably under diverse conditions, and address
    significant societal challenges. Artificial intelligence’s future trajectory will
    be determined not through isolated research contributions, but through systematic
    application of systems engineering principles by practitioners who master the
    integration of technical excellence with operational realities and societal responsibility.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中综合的框架建立了在快速发展的人工智能技术景观中导航的系统方法，同时保持对基本工程目标的关注：创建能够有效扩展、在各种条件下可靠运行并解决重大社会挑战的系统。人工智能的未来轨迹将不是通过孤立的研究贡献来决定，而是通过掌握将技术卓越与运营现实和社会责任相结合的实践者系统地应用系统工程原则来决定。
- en: This synthesis establishes systematic theoretical understanding and provides
    the conceptual foundation for professional application within machine learning
    systems as a mature engineering discipline.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种综合建立了系统性的理论理解，并为机器学习系统作为一个成熟的工程学科中的专业应用提供了概念基础。
- en: Systems Engineering Principles for ML
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统工程原则
- en: We extract six core principles that unite the concepts explored across twenty
    chapters. These principles transcend specific technologies and provide enduring
    guidance for building today’s production systems or tomorrow’s artificial general
    intelligence.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提取了六个核心原则，这些原则将二十个章节中探讨的概念统一起来。这些原则超越了特定技术，为构建今天的生产系统或明天的通用人工智能提供了持久的指导。
- en: '**Principle 1: Measure Everything**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则1：衡量一切**'
- en: The measurement frameworks established in [Chapter 12](ch018.xhtml#sec-benchmarking-ai),
    complemented by the monitoring systems from [Chapter 13](ch019.xhtml#sec-ml-operations),
    demonstrate that successful ML systems instrument every component because you
    cannot optimize what you do not measure. Four analytical frameworks provide enduring
    measurement foundations that transcend specific technologies.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第12章](ch018.xhtml#sec-benchmarking-ai)中建立的测量框架，辅以[第13章](ch019.xhtml#sec-ml-operations)中的监控系统，表明成功的机器学习系统会对每个组件进行仪表化，因为你不衡量你无法优化。四个分析框架提供了超越特定技术的持久测量基础。
- en: Roofline analysis[3](#fn3) identifies computational bottlenecks by plotting
    operational intensity against peak performance, revealing whether systems are
    memory bound or compute bound, essential for optimizing everything from training
    workloads to edge inference.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 屋顶线分析[3](#fn3) 通过绘制操作强度与峰值性能的关系图来识别计算瓶颈，揭示系统是受内存限制还是受计算限制，这对于优化从训练工作负载到边缘推理的各个方面至关重要。
- en: 'Cost performance evaluation systematically compares total ownership costs against
    delivered capabilities, incorporating training expenses, infrastructure requirements,
    and operational overhead to guide deployment decisions. Systematic benchmarking
    establishes reproducible measurement protocols that enable fair comparisons across
    architectures, frameworks, and deployment targets, ensuring optimization efforts
    target actual rather than perceived bottlenecks. These measurements reveal a critical
    insight: systems rarely fail at expected loads but when demand exceeds design
    assumptions by orders of magnitude.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 成本性能评估系统地比较了总拥有成本与交付能力，包括培训费用、基础设施需求和运营开销，以指导部署决策。系统基准测试建立了可重复的测量协议，使得可以在架构、框架和部署目标之间进行公平的比较，确保优化努力针对实际而不是感知的瓶颈。这些测量揭示了一个关键见解：系统很少在预期的负载下失败，而是在需求超过设计假设的量级时失败。
- en: '**Principle 2: Design for 10x Scale**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则2：设计10倍扩展**'
- en: 'Systems that work in research rarely survive production traffic, requiring
    design for an order of magnitude more data, users, and computational demands than
    currently needed[4](#fn4). Building on concepts from [Chapter 2](ch008.xhtml#sec-ml-systems),
    this principle manifests across deployment contexts: cloud systems must handle
    traffic spikes from thousands to millions of users, edge systems need redundancy
    for network partitions, and embedded systems require graceful degradation under
    resource exhaustion.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究工作中表现良好的系统很少能在生产流量中生存，需要设计能够处理比目前所需多一个数量级的数据、用户和计算需求的系统[4](#fn4)。基于[第2章](ch008.xhtml#sec-ml-systems)中的概念，这一原则在部署环境中体现出来：云系统必须处理从数千到数百万用户的流量峰值，边缘系统需要网络分区的冗余，嵌入式系统在资源耗尽时需要优雅降级。
- en: Scale alone, however, provides no value if systems waste resources on non-critical
    paths.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果系统在非关键路径上浪费资源，仅仅规模本身并不能提供价值。
- en: '**Principle 3: Optimize the Bottleneck**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则3：优化瓶颈**'
- en: 'While [Chapter 9](ch015.xhtml#sec-efficient-ai) establishes efficiency principles
    and [Chapter 10](ch016.xhtml#sec-model-optimizations) provides optimization techniques,
    systems analysis reveals that 80% of performance gains come from addressing the
    primary constraint: memory bandwidth in training workloads, network latency in
    distributed inference, or energy consumption in mobile deployment.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然[第9章](ch015.xhtml#sec-efficient-ai)确立了效率原则，[第10章](ch016.xhtml#sec-model-optimizations)提供了优化技术，但系统分析表明，80%的性能提升来自于解决主要约束：训练工作负载中的内存带宽、分布式推理中的网络延迟或在移动部署中的能耗。
- en: '**Principle 4: Plan for Failure**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则4：为失败做准备**'
- en: The robustness techniques from [Chapter 16](ch022.xhtml#sec-robust-ai), combined
    with security frameworks from [Chapter 17](ch023.xhtml#sec-responsible-ai), assume
    systems will fail, requiring redundancy, monitoring, and recovery mechanisms from
    the start. Production systems experience component failures, network partitions,
    and adversarial inputs daily, necessitating circuit breakers[5](#fn5), graceful
    fallbacks, and automated recovery procedures.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[第16章](ch022.xhtml#sec-robust-ai)的鲁棒性技术，以及来自[第17章](ch023.xhtml#sec-responsible-ai)的安全框架，假设系统会失败，需要从一开始就具备冗余、监控和恢复机制。生产系统每天都会经历组件故障、网络分区和敌对输入，需要断路器[5](#fn5)、优雅降级和自动恢复程序。
- en: '**Principle 5: Design Cost-Consciously**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则5：有意识地设计成本**'
- en: From sustainability concerns to operational expenses, every technical decision
    has economic implications. Optimizing for total cost of ownership[6](#fn6), not
    just performance, becomes critical when cloud GPU costs can exceed $30,000/month
    for large models ([Strubell, Ganesh, and McCallum 2019c](ch058.xhtml#ref-ben2019cost)),
    making efficiency optimizations worth millions in operational savings over deployment
    lifetimes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从可持续性关注到运营成本，每个技术决策都有经济影响。当云GPU成本可能超过每月30,000美元的大模型时([Strubell, Ganesh, and
    McCallum 2019c](ch058.xhtml#ref-ben2019cost))，优化总拥有成本[6](#fn6)，而不仅仅是性能，变得至关重要，这使得效率优化在部署生命周期中节省数百万美元的运营成本变得有价值。
- en: '**Principle 6: Co-Design for Hardware**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则6：硬件协同设计**'
- en: 'Building on the acceleration techniques from [Chapter 11](ch017.xhtml#sec-ai-acceleration),
    efficient AI systems require algorithm hardware co-optimization, not just individual
    component excellence. This comprehensive approach encompasses three critical dimensions:
    algorithm hardware matching ensures computational patterns align with target hardware
    capabilities (systolic arrays favor dense matrix operations while sparse accelerators
    require structured pruning patterns), memory hierarchy optimization provides frameworks
    for analyzing data movement costs and optimizing for cache locality, and energy
    efficiency modeling incorporates TOPS/W metrics to guide power-conscious design
    decisions essential for mobile and edge deployment.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 基于第11章[第11章](ch017.xhtml#sec-ai-acceleration)中的加速技术，高效的AI系统需要算法硬件协同优化，而不仅仅是单个组件的卓越。这种全面的方法包括三个关键维度：算法硬件匹配确保计算模式与目标硬件能力相匹配（收缩阵列有利于密集矩阵运算，而稀疏加速器需要结构化剪枝模式），内存层次优化提供分析数据移动成本和优化缓存局部性的框架，能源效率建模结合TOPS/W指标来指导移动和边缘部署中节能的设计决策。
- en: Applying Principles Across Three Critical Domains
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在三个关键领域应用原则
- en: 'These six foundational principles apply practically across the ML systems landscape.
    These principles are not abstract ideals but concrete guides that shaped every
    technical decision explored throughout our journey. Their manifestation varies
    by context yet remains consistent in purpose. We examine how they operate across
    three critical domains that structure ML systems engineering: building robust
    technical foundations where measurement and co-design establish the groundwork,
    engineering for performance at scale where optimization and planning enable growth,
    and navigating production realities where all principles converge under operational
    constraints.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这六个基础原则在机器学习系统领域具有实际应用。这些原则不是抽象的理想，而是具体的指导方针，塑造了我们整个旅程中探索的每一个技术决策。它们的表现形式因环境而异，但目的始终一致。我们考察了它们在三个关键领域如何运作，这些领域构成了机器学习系统工程的结构：建立稳健的技术基础，其中测量和协同设计奠定基础；在规模性能上进行工程，其中优化和规划促进增长；在现实生产中进行导航，所有原则在操作约束下汇聚。
- en: Building Technical Foundations
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建立技术基础
- en: Machine learning systems engineering rests on solid technical foundations where
    multiple principles converge.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统工程建立在坚实的技术基础之上，其中多个原则汇聚在一起。
- en: The foundation begins with data engineering, where [Chapter 5](ch011.xhtml#sec-ai-workflow)
    established that data quality determines system quality. “Data is the new code”
    ([Karpathy 2017](ch058.xhtml#ref-karpathy2017software)) for neural networks. Production
    systems require instrumentation for schema evolution, lineage tracking, and quality
    degradation detection. When data quality degrades, effects cascade through the
    entire system, making data governance both a technical necessity and ethical imperative.
    The measurement principle manifests through continuous monitoring of distribution
    shifts, labeling consistency, and pipeline performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基础始于数据工程，[第5章](ch011.xhtml#sec-ai-workflow)中确立了数据质量决定系统质量。“数据是新的代码”([Karpathy
    2017](ch058.xhtml#ref-karpathy2017software))对于神经网络而言。生产系统需要用于模式演变的仪器、血缘跟踪和质量退化检测。当数据质量下降时，影响会通过整个系统级联，使得数据治理既是技术必要性也是道德上的迫切要求。测量原则通过持续监测分布变化、标签一致性和管道性能来体现。
- en: Building on this data foundation, frameworks and training systems embody both
    scale and co-design principles. The framework ecosystem from [Chapter 7](ch013.xhtml#sec-ai-frameworks)
    introduced you to navigating trade-offs between TensorFlow’s production maturity
    and PyTorch’s research flexibility. [Chapter 8](ch014.xhtml#sec-ai-training) then
    revealed how these frameworks scale beyond single machines, teaching you data
    parallelism strategies that transform weeks of training into hours through distributed
    coordination. Framework selection ([Chapter 7](ch013.xhtml#sec-ai-frameworks))
    impacts development velocity and deployment constraints. Specialization from TensorFlow
    Lite for mobile ([Chapter 7](ch013.xhtml#sec-ai-frameworks)) to JAX for research
    ([Chapter 7](ch013.xhtml#sec-ai-frameworks)) exemplifies hardware co-design. Distributed
    training through data and model parallelism, mixed precision techniques, and gradient
    compression all demonstrate designing for scale beyond current needs while optimizing
    for hardware capabilities.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据基础上，框架和训练系统体现了规模和协同设计原则。[第7章](ch013.xhtml#sec-ai-frameworks)中引入的框架生态系统向您介绍了在TensorFlow的生产成熟度和PyTorch的研究灵活性之间的权衡。[第8章](ch014.xhtml#sec-ai-training)随后揭示了这些框架如何扩展到单机之外，向您传授了将数据并行策略转化为通过分布式协调将数周的训练时间缩短到数小时的方法。框架选择([第7章](ch013.xhtml#sec-ai-frameworks))影响开发速度和部署限制。从TensorFlow
    Lite用于移动([第7章](ch013.xhtml#sec-ai-frameworks))到JAX用于研究([第7章](ch013.xhtml#sec-ai-frameworks))的专业化是硬件协同设计的例子。通过数据并行和模型并行、混合精度技术和梯度压缩进行分布式训练，所有这些都展示了在设计时考虑超出当前需求规模的规模，同时优化硬件能力。
- en: 'Efficiency and Optimization (Principle 3: Optimize the Bottleneck): [Chapter 9](ch015.xhtml#sec-efficient-ai)
    demonstrates that efficiency determines whether AI moves beyond laboratories to
    resource-constrained deployment. Neural compression algorithms (pruning, quantization,
    and knowledge distillation) systematically address bottlenecks (memory, compute,
    energy) while maintaining performance. This multidimensional optimization requires
    identifying the limiting factor and addressing it systematically rather than pursuing
    isolated improvements.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 效率和优化（原则3：优化瓶颈）：[第9章](ch015.xhtml#sec-efficient-ai) 展示了效率决定了人工智能是否能够超越实验室，进入资源受限的部署。神经网络压缩算法（剪枝、量化和知识蒸馏）系统性地解决瓶颈（内存、计算、能源）同时保持性能。这种多维优化需要识别限制因素并系统性地解决它，而不是追求孤立的改进。
- en: Engineering for Performance at Scale
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规模化性能的工程
- en: The technical foundations we have examined (data engineering, frameworks, and
    efficiency) provide the substrate for ML systems. Yet foundations alone do not
    create value. The second pillar of ML systems engineering transforms these foundations
    into systems that perform reliably at scale, shifting focus from “does it work?”
    to “does it work efficiently for millions of users?” This transition demands new
    engineering priorities and systematic application of our scaling and optimization
    principles.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考察的技术基础（数据工程、框架和效率）为机器学习系统提供了基础。然而，仅凭基础并不能创造价值。机器学习系统工程的第二个支柱将这些基础转化为在规模上可靠运行的系统，将重点从“它是否工作？”转移到“它是否为百万用户高效工作？”这种转变需要新的工程优先级和系统性地应用我们的扩展和优化原则。
- en: Model Architecture and Optimization
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型架构和优化
- en: '[Chapter 4](ch010.xhtml#sec-dnn-architectures) traced your journey from understanding
    simple perceptrons (where you first grasped how weighted inputs produce decisions)
    through convolutional networks that revealed how hierarchical feature extraction
    mirrors biological vision, to transformer architectures whose attention mechanisms
    enabled the language understanding powering today’s AI assistants. However, architectural
    innovation alone proves insufficient for production deployment. Optimization techniques
    from [Chapter 10](ch016.xhtml#sec-model-optimizations) bridge research architectures
    and production constraints.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](ch010.xhtml#sec-dnn-architectures) 回顾了您的旅程，从理解简单的感知器（您首次掌握了加权输入如何产生决策）到卷积网络，揭示了层次特征提取如何与生物视觉相呼应，再到注意力机制使语言理解成为今天人工智能助手的动力的转换器架构。然而，仅仅依靠架构创新不足以证明其在生产部署中的充分性。[第10章](ch016.xhtml#sec-model-optimizations)
    中的优化技术将研究架构与生产约束联系起来。'
- en: 'Following the hardware co-design principles outlined earlier, three complementary
    compression approaches demonstrate systematic bottleneck optimization: pruning
    removes redundant parameters while maintaining accuracy, quantization reduces
    precision requirements for 4x memory reduction, and knowledge distillation transfers
    capabilities to compact networks for resource-constrained deployment.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循之前概述的硬件协同设计原则，三种互补的压缩方法展示了系统瓶颈优化的方法：剪枝在保持准确性的同时去除冗余参数，量化通过4倍的内存减少降低了精度要求，而知识蒸馏将能力转移到紧凑的网络以实现资源受限的部署。
- en: The Deep Compression pipeline ([Han, Mao, and Dally 2015a](ch058.xhtml#ref-han2015deep))
    exemplifies this systematic integration. Pruning, quantization, and coding combine
    for 10-50x compression ratios[7](#fn7). Operator fusion (combining conv-batchnorm-relu
    sequences) reduces memory bandwidth by 3x, demonstrating how algorithmic and systems
    optimizations compound when guided by the co-design imperative established in
    our foundational principles.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 深度压缩管道（[Han, Mao, and Dally 2015a](ch058.xhtml#ref-han2015deep)）是这种系统集成的例证。剪枝、量化和编码结合实现了10-50倍的压缩比率[7](#fn7)。算子融合（结合卷积-批量归一化-ReLU序列）将内存带宽减少了3倍，展示了算法和系统优化如何在我们的基础原则中确立的协同设计必要性指导下产生协同效应。
- en: 'These optimizations validate Principle 3’s core insight: identify the bottleneck
    (memory, compute, or energy), then optimize systematically rather than pursuing
    isolated improvements.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些优化验证了原则3的核心洞察：识别瓶颈（内存、计算或能源），然后系统性地优化，而不是追求孤立的改进。
- en: Hardware Acceleration and System Performance
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 硬件加速和系统性能
- en: '[Chapter 11](ch017.xhtml#sec-ai-acceleration) shows how specialized hardware
    transforms computational bottlenecks into acceleration opportunities. GPUs excel
    at parallel matrix operations, TPUs[8](#fn8) optimize for tensor workloads, and
    FPGAs[9](#fn9) provide reconfigurable acceleration for specific operators.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](ch017.xhtml#sec-ai-acceleration)展示了专用硬件如何将计算瓶颈转化为加速机会。GPU擅长并行矩阵运算，TPUs[8](#fn8)针对张量工作负载进行优化，而FPGAs[9](#fn9)为特定操作提供可重构的加速。'
- en: Building on the co-design framework established previously, software optimizations
    must align with hardware capabilities through kernel fusion, operator scheduling,
    and precision selection that balances accuracy with throughput.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前建立的协同设计框架的基础上，软件优化必须通过内核融合、操作调度和精度选择与硬件能力保持一致，以平衡准确性和吞吐量。
- en: '[Chapter 12](ch018.xhtml#sec-benchmarking-ai) establishes benchmarking as the
    essential feedback loop for performance engineering. MLPerf[10](#fn10) provides
    standardized metrics across hardware platforms, enabling data-driven decisions
    about deployment trade-offs.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](ch018.xhtml#sec-benchmarking-ai)将基准测试确立为性能工程的基本反馈循环。MLPerf[10](#fn10)在硬件平台之间提供标准化的指标，使数据驱动的部署权衡决策成为可能。'
- en: This performance engineering foundation enables new deployment paradigms that
    extend beyond centralized systems to edge and mobile environments.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个性能工程基础使新的部署范例得以扩展，超越了集中式系统，延伸到边缘和移动环境。
- en: Navigating Production Reality
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导航生产现实
- en: The third pillar addresses production deployment realities where all six principles
    converge under the constraint that systems must serve users reliably, securely,
    and responsibly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第三大支柱解决生产部署的现实，其中六个原则在系统必须可靠、安全、负责任地为用户提供服务的约束下汇聚。
- en: 'The operations and deployment landscape demonstrates how MLOps[11](#fn11) orchestrates
    the full system lifecycle, from continuous integration pipelines with quality
    gates to A/B testing frameworks for safe rollout. Edge deployment exemplifies
    the convergence of multiple principles: balancing privacy benefits against latency
    constraints while ensuring graceful degradation under network failures.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 运作和部署的格局展示了MLOps[11](#fn11)如何协调整个系统生命周期，从带有质量门的持续集成管道到安全的A/B测试框架。边缘部署体现了多个原则的融合：在平衡隐私利益和延迟约束的同时，确保在网络故障下能够优雅降级。
- en: Security and privacy considerations reveal ML’s unique vulnerabilities (model
    extraction, data poisoning, membership inference) requiring layered defenses.
    Differential privacy provides mathematical guarantees, federated learning enables
    secure collaboration, and adversarial training builds robustness against attacks
    that traditional software never faces.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 安全和隐私考虑揭示了机器学习独特的脆弱性（模型提取、数据中毒、成员推理），需要分层防御。差分隐私提供数学保证，联邦学习实现安全协作，对抗训练构建了对传统软件从未面临过的攻击的鲁棒性。
- en: 'Beyond technical concerns, responsible AI and sustainability considerations
    broaden cost consciousness beyond computation. Fairness metrics and explainability
    requirements shape architectural choices from inception. Environmental impact
    becomes a design constraint: GPT-3’s 1,287 MWh training cost ([Strubell, Ganesh,
    and McCallum 2019a](ch058.xhtml#ref-strubell2019energy)) equals powering 120 homes
    annually, making efficiency improvements on 6+ billion smartphones more impactful
    than datacenter optimizations.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 除了技术问题之外，负责任的AI和可持续性考虑将成本意识扩展到计算之外。公平性指标和可解释性要求从一开始就塑造了架构选择。环境影响成为设计约束：GPT-3的1,287
    MWh训练成本([Strubell, Ganesh, and McCallum 2019a](ch058.xhtml#ref-strubell2019energy))相当于每年为120个家庭供电，这使得在60多亿部智能手机上提高效率的影响比数据中心优化更为显著。
- en: Production reality validates that isolated technical excellence proves insufficient.
    Systems must integrate operational maturity, security defenses, ethical frameworks,
    and environmental responsibility to deliver sustained value.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 生产现实验证了孤立的技术卓越性是不够的。系统必须整合操作成熟度、安全防御、伦理框架和环境责任，以提供持续的价值。
- en: Future Directions and Emerging Opportunities
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未来方向和新兴机遇
- en: Having established technical foundations, engineered for performance, and navigated
    production realities, we examine emerging opportunities where the six principles
    guide future development.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立了技术基础、针对性能进行工程设计和应对生产现实之后，我们审视了那些由六个原则引导的未来发展中的新兴机遇。
- en: 'The convergence of technical foundations, performance engineering, and production
    reality reveals three emerging frontiers where our established principles face
    their greatest tests: near-term deployment across diverse contexts, building resilient
    systems for societal benefit, and engineering the path toward artificial general
    intelligence.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 技术基础、性能工程和生产现实的融合揭示了三个新兴前沿，我们的既定原则在这里面临最大的考验：在多样化环境中近期的部署、构建对社会有益的弹性系统，以及工程化通往通用人工智能的道路。
- en: Applying Principles to Emerging Deployment Contexts
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将原则应用于新兴部署环境
- en: 'As ML systems move beyond research labs, three deployment paradigms test different
    combinations of our established principles: resource-abundant cloud environments,
    resource-constrained edge devices, and emerging generative systems.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习系统走出研究实验室，三种部署范式测试了我们的既定原则的不同组合：资源丰富的云环境、资源受限的边缘设备，以及新兴的生成式系统。
- en: Cloud deployment prioritizes throughput and scalability, achieving high GPU
    utilization through kernel fusion, mixed precision training, and gradient compression
    techniques explored in [Chapter 10](ch016.xhtml#sec-model-optimizations) and [Chapter 8](ch014.xhtml#sec-ai-training).
    Success requires balancing performance optimization with cost efficiency at scale.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 云部署优先考虑吞吐量和可扩展性，通过内核融合、混合精度训练和梯度压缩技术（在第10章[ch016.xhtml#sec-model-optimizations]和第8章[ch014.xhtml#sec-ai-training]中探讨）实现高GPU利用率。成功需要平衡性能优化与规模成本效益。
- en: 'In contrast, mobile and edge systems face stringent power, memory, and latency
    constraints that demand sophisticated hardware-software co-design. The efficiency
    techniques from [Chapter 9](ch015.xhtml#sec-efficient-ai)—depthwise separable
    convolutions, neural architecture search, and quantization—enable deployment on
    devices with 100-1000x less computational power than data centers. Edge deployment
    represents AI’s democratization[12](#fn12): systems that cannot run on billions
    of edge devices cannot achieve global impact.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，移动和边缘系统面临着严格的功耗、内存和延迟限制，这要求进行复杂的软硬件协同设计。[第9章](ch015.xhtml#sec-efficient-ai)中提到的效率技术——深度可分离卷积、神经架构搜索和量化——使得在比数据中心少100-1000倍计算能力的设备上部署成为可能。边缘部署代表了AI的民主化[12](#fn12)：不能在数十亿边缘设备上运行的系统无法实现全球影响。
- en: Generative AI systems exemplify the principles at unprecedented scale, requiring
    novel approaches to autoregressive computation, dynamic model partitioning, and
    speculative decoding. These systems demonstrate how the measurement, optimization,
    and co-design principles from earlier sections apply to emerging technologies
    pushing infrastructure boundaries.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI系统以前所未有的规模展示了这些原则，需要新颖的方法来处理自回归计算、动态模型分区和推测性解码。这些系统展示了如何将前面章节中提到的测量、优化和协同设计原则应用于推动基础设施边界的新兴技术。
- en: 'Operating under even more extreme constraints, TinyML and embedded systems
    face kilobyte memory budgets, milliwatt power envelopes, and decade-long deployment
    lifecycles. Success in these contexts validates the full systems engineering approach:
    careful measurement reveals actual bottlenecks, hardware co-design maximizes efficiency,
    and planning for failure ensures reliability despite severe resource limitations.
    Mobile deployment constraints have driven breakthrough techniques like MobileNets
    and EfficientNets that benefit all AI deployment contexts, demonstrating how systems
    constraints catalyze algorithmic innovation.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在更加极端的限制下运行，TinyML和嵌入式系统面临着千字节内存预算、毫瓦特功率限制和长达数十年的部署生命周期。在这些环境中取得成功验证了全面系统工程方法的有效性：仔细的测量揭示了实际瓶颈，硬件协同设计最大化了效率，而针对故障的规划确保了在严重资源限制下的可靠性。移动部署的限制推动了MobileNets和EfficientNets等突破性技术的出现，这些技术对所有AI部署环境都有益，展示了系统限制如何催化算法创新。
- en: 'These deployment contexts validate our core thesis: success depends on applying
    the six systems engineering principles systematically rather than pursuing isolated
    optimizations.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些部署环境验证了我们的核心论点：成功取决于系统地应用六个系统工程原则，而不是追求孤立的优化。
- en: Building Robust AI Systems
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建鲁棒的AI系统
- en: '[Chapter 16](ch022.xhtml#sec-robust-ai) demonstrates that robustness requires
    designing for failure from the ground up, Principle 4’s core mandate. ML systems
    face unique failure modes: distribution shifts degrade accuracy, adversarial inputs
    exploit vulnerabilities, and edge cases reveal training data limitations. Resilient
    systems combine redundant hardware for fault tolerance ([Chapter 16](ch022.xhtml#sec-robust-ai)),
    ensemble methods to reduce single-point failures ([Chapter 16](ch022.xhtml#sec-robust-ai)),
    and uncertainty quantification to enable graceful degradation ([Chapter 16](ch022.xhtml#sec-robust-ai)).
    As AI systems take on increasingly autonomous roles, planning for failure becomes
    the difference between safe deployment and catastrophic failure.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[第16章](ch022.xhtml#sec-robust-ai)展示了鲁棒性需要从底层开始设计，这是第4个原则的核心要求。机器学习系统面临独特的故障模式：分布变化降低准确性，对抗性输入利用漏洞，边缘情况揭示训练数据限制。具有弹性的系统结合冗余硬件以实现容错性（[第16章](ch022.xhtml#sec-robust-ai)），集成方法以减少单点故障（[第16章](ch022.xhtml#sec-robust-ai)），以及不确定性量化以实现优雅降级（[第16章](ch022.xhtml#sec-robust-ai)）。随着人工智能系统承担越来越自主的角色，规划故障成为安全部署和灾难性失败之间的区别。'
- en: AI for Societal Benefit
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为社会利益而设计的AI
- en: '[Chapter 19](ch025.xhtml#sec-ai-good) demonstrates AI’s transformative potential
    across healthcare, climate science, education, and accessibility, domains where
    all six principles converge. Climate modeling requires efficient inference (Principle
    3: Optimize Bottleneck). Medical AI demands explainable decisions and continuous
    monitoring (Principle 1: Measure). Educational technology needs privacy-preserving
    personalization at global scale (Principles 2 & 4: Design for Scale, Plan for
    Failure). These applications validate that technical excellence alone proves insufficient.
    Success requires interdisciplinary collaboration among technologists, domain experts,
    policymakers, and affected communities.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[第19章](ch025.xhtml#sec-ai-good)展示了人工智能在医疗保健、气候科学、教育和可及性等领域的变革潜力，这些领域六个原则汇聚在一起。气候建模需要高效的推理（原则3：优化瓶颈）。医疗人工智能需要可解释的决策和持续监控（原则1：测量）。教育技术需要在全球范围内实现隐私保护的个人化（原则2和4：设计可扩展性，规划故障）。这些应用验证了仅凭技术卓越是不够的。成功需要技术专家、领域专家、政策制定者和受影响社区之间的跨学科合作。'
- en: The Path to AGI
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通向通用人工智能之路
- en: 'The compound AI systems[13](#fn13) framework provides the architectural blueprint
    for advanced intelligence: modular components that can be updated independently,
    specialized models optimized for specific tasks, and decomposable architectures
    that enable interpretability and safety through multiple validation layers.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 复合人工智能系统[13](#fn13)框架提供了高级智能的架构蓝图：可以独立更新的模块化组件，针对特定任务优化的专用模型，以及可分解的架构，通过多个验证层实现可解释性和安全性。
- en: The engineering challenges ahead require mastery across the full stack we have
    explored, from data engineering ([Chapter 5](ch011.xhtml#sec-ai-workflow)) and
    distributed training ([Chapter 8](ch014.xhtml#sec-ai-training)) to model optimization
    ([Chapter 10](ch016.xhtml#sec-model-optimizations)) and operational infrastructure
    ([Chapter 13](ch019.xhtml#sec-ml-operations)). These systems engineering principles,
    not algorithmic breakthroughs, define the path toward artificial general intelligence.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的工程挑战需要掌握我们探索的全栈技术，从数据工程（[第5章](ch011.xhtml#sec-ai-workflow)）和分布式训练（[第8章](ch014.xhtml#sec-ai-training)）到模型优化（[第10章](ch016.xhtml#sec-model-optimizations)）和运营基础设施（[第13章](ch019.xhtml#sec-ml-operations)）。这些系统工程原理，而非算法突破，定义了通往通用人工智能的道路。
- en: 'Your Journey Forward: Engineering Intelligence'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你前行的旅程：工程智能
- en: 'Twenty chapters ago, we began with a vision: artificial intelligence (AI) as
    a transformative force reshaping civilization. You now possess the systems engineering
    principles to make that vision reality.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在二十章之前，我们开始了一个愿景：人工智能（AI）作为一种变革力量，重塑文明。你现在拥有了将这一愿景变为现实的系统工程原理。
- en: 'Artificial general intelligence will be built by engineers who understand that
    intelligence is a systems property, emerging from the integration of components
    rather than any single breakthrough. Consider GPT-4’s success ([OpenAI et al.
    2023](ch058.xhtml#ref-openai2023gpt4)): it required robust data pipelines processing
    petabytes of text ([Chapter 5](ch011.xhtml#sec-ai-workflow)), distributed training
    infrastructure[14](#fn14) coordinating thousands of GPUs ([Chapter 8](ch014.xhtml#sec-ai-training)),
    efficient architectures leveraging attention mechanisms and mixture-of-experts
    ([Chapter 9](ch015.xhtml#sec-efficient-ai)), secure deployment preventing prompt
    injection attacks ([Chapter 17](ch023.xhtml#sec-responsible-ai)), and responsible
    governance implementing safety filters and usage policies ([Chapter 17](ch023.xhtml#sec-responsible-ai)).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通用人工智能将由那些理解智能是一个系统属性，它不是来自任何单一突破，而是来自组件集成的工程师构建。考虑GPT-4的成功（[OpenAI等，2023](ch058.xhtml#ref-openai2023gpt4)）：它需要处理PB级文本的稳健数据管道（[第5章](ch011.xhtml#sec-ai-workflow)），协调数千个GPU的分布式训练基础设施[14](#fn14)（[第8章](ch014.xhtml#sec-ai-training)），利用注意力机制和专家混合架构的高效架构（[第9章](ch015.xhtml#sec-efficient-ai)），防止提示注入攻击的安全部署（[第17章](ch023.xhtml#sec-responsible-ai)），以及实施安全过滤和用法政策的负责任治理（[第17章](ch023.xhtml#sec-responsible-ai)）。
- en: Every principle in this text, from measuring everything to co-designing for
    hardware, represents a tool for building that future.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章中的每一个原则，从测量一切到与硬件协同设计，都是构建那个未来的工具。
- en: The six principles you have mastered transcend specific technologies. As frameworks
    evolve, hardware advances, and new architectures emerge, these foundational concepts
    remain constant. They will guide you whether optimizing today’s production recommendation
    systems or architecting tomorrow’s compound AI systems approaching general intelligence.
    The compound AI framework, edge deployment paradigms, and efficiency optimization
    techniques you have explored represent current instantiations of enduring systems
    thinking.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你所掌握的六个原则超越了特定技术。随着框架的发展，硬件的进步，以及新架构的出现，这些基础概念保持不变。它们将指导你优化今天的生产推荐系统，或设计明天接近通用智能的复合人工智能系统。你所探索的复合人工智能框架、边缘部署范式和效率优化技术代表了持久系统思维的当前实现。
- en: 'But mastery of technical principles alone proves insufficient. The question
    confronting our generation is not whether artificial general intelligence will
    arrive, but whether it will be built well: efficiently enough to democratize access
    beyond wealthy institutions, securely enough to resist exploitation, sustainably
    enough to preserve our planet, and responsibly enough to serve all humanity equitably.
    These challenges demand the full stack of ML systems engineering, technical excellence
    unified with ethical commitment.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但仅仅掌握技术原理是远远不够的。我们这一代面临的问题不是通用人工智能是否会到来，而是它是否会被良好地构建：是否足够高效以使财富机构之外的人也能民主地获取，是否足够安全以抵御滥用，是否足够可持续以保护我们的地球，以及是否足够负责任以公平地为全人类服务。这些挑战需要完整的机器学习系统工程栈，将技术卓越与道德承诺相结合。
- en: 'As you apply these principles to your own engineering challenges, remember
    that ML systems engineering centers on serving users and society. Every architectural
    decision, every optimization technique, and every operational practice should
    ultimately make AI more beneficial, accessible, and trustworthy. Measure your
    success not only in reduced latency or improved accuracy, but in real-world impact:
    lives improved, problems solved, capabilities democratized.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将这些原则应用于自己的工程挑战时，请记住，机器学习系统工程的核心是服务于用户和社会。每一个架构决策，每一个优化技术，以及每一个运营实践，最终都应该使人工智能更加有益、易于获取和值得信赖。衡量你的成功不仅在于降低延迟或提高准确性，还在于现实世界的影响：生活得到改善，问题得到解决，能力得到普及。
- en: 'The intelligent systems that will define the coming century (from climate models
    predicting extreme weather to medical AI diagnosing rare diseases, from educational
    systems personalizing learning to assistive technologies empowering billions)
    await your engineering expertise. You now possess the knowledge to build them:
    the principles to guide design, the techniques to ensure efficiency, the frameworks
    to guarantee safety, and the wisdom to deploy responsibly.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 将定义未来一个世纪的智能系统（从预测极端天气的气候模型到诊断罕见疾病的医疗人工智能，从个性化学习的教育系统到赋能数十亿人的辅助技术）等待着你的工程专业知识。你现在拥有构建它们的知识：指导设计的原则，确保效率的技术，保证安全的框架，以及负责任部署的智慧。
- en: Your journey as an ML systems engineer begins now. Take the principles you have
    mastered. Apply them to challenges that matter. Build systems that scale. Create
    solutions that endure. Engineer intelligence that serves humanity.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名机器学习系统工程师的旅程现在开始了。运用你已掌握的原则。将它们应用于重要的挑战。构建可扩展的系统。创造持久的解决方案。设计服务于人类的智能。
- en: The future of intelligence is not something we will simply witness; it is something
    we must build. Go build it well.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 智能的未来不是我们简单见证的东西；这是我们必须要去构建的。去好好构建它吧。
- en: '*Prof. Vijay Janapa Reddi, Harvard University*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*哈佛大学维贾伊·贾纳帕·雷迪教授*'
- en: '* * *'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
