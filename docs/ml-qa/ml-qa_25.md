## 第二十一章：**数据中心化 AI**

![Image](img/common.jpg)

什么是数据中心化 AI，它与传统的建模范式有何不同，以及我们如何判断它是否适合一个项目？

数据中心化 AI 是一种范式或工作流，其中我们保持模型训练过程不变，并在数据集上反复迭代，以提高模型的预测性能。以下部分将更详细地定义数据中心化 AI 的含义，并将其与传统的模型中心化方法进行比较。

### **数据中心化与模型中心化 AI**

在数据中心化 AI 的背景下，我们可以将传统的工作流，通常是学术出版中的一部分，视为模型中心化 AI。然而，在学术研究环境中，我们通常更关注开发新方法（例如，神经网络架构或损失函数）。在这里，我们考虑使用现有的基准数据集，将新方法与先前的方案进行比较，并判断它是否优于现状。

图 21-1 总结了数据中心化与模型中心化工作流的区别。

![Image](img/21fig01.jpg)

*图 21-1：数据中心化与模型中心化机器学习工作流*

尽管*数据中心化 AI*是一个相对较新的术语，但其背后的理念并不新鲜。我与许多人交流过，他们表示，在这个术语被创造之前，他们的项目中已经使用了数据中心化的方法。在我看来，数据中心化 AI 的出现是为了重新吸引人们“关心数据质量”，因为数据收集和数据整理通常被认为是单调乏味或得不到应有回报的。这类似于“深度学习”一词在 2010 年代初期使得神经网络重新引起兴趣。

我们是否需要在数据中心化与模型中心化 AI 之间做出选择，还是可以同时依赖这两者？简而言之，数据中心化 AI 侧重于通过改变数据来提高性能，而模型中心化方法则侧重于修改模型以提高性能。在应用场景中，我们理想情况下应该同时使用这两种方法，以获得最佳的预测性能。然而，在研究环境或应用项目的探索阶段，同时处理过多的变量是混乱的。如果我们同时改变模型和数据，就很难明确指出哪个变化导致了性能的提升。

需要强调的是，数据中心化 AI 是一种范式和工作流，而不是一种特定的技术。因此，数据中心化 AI 隐含地包括以下内容：

+   训练数据的分析和修改，从去除异常值到缺失数据的填补

+   数据合成和数据增强技术

+   数据标注和标签清理方法

+   经典的主动学习设置，其中模型建议需要标注的数据点

如果我们只改变数据（使用这里列出的技术），而不改变建模流程的其他方面，那么我们就认为这是*数据中心化*的方法。

在机器学习和人工智能中，我们常用“垃圾进，垃圾出”这一说法，意思是低质量的数据会导致低质量的预测模型。换句话说，我们不能指望从低质量的数据集中得到一个表现良好的模型。

我在尝试用机器学习取代现有方法的应用学术项目中观察到一种常见模式。通常，研究人员只有一个小型数据集（比如几百个训练样本）。标注数据往往成本较高，或者被认为枯燥乏味，因此最好避免。在这些情况下，研究人员花费大量时间尝试不同的机器学习算法和模型调优。为了解决这个问题，投入更多时间或资源标注更多数据是值得的。

数据中心化人工智能的主要优势在于它将数据置于首位，这样如果我们投入资源创建更高质量的数据集，所有建模方法都会从中受益。

### **建议**

在应用项目中，采取数据中心化的方法通常是一个好主意，尤其是在我们希望提高预测性能以解决特定问题的情况下。在这种背景下，从建模基准开始，并改善数据集是有意义的，因为这通常比尝试更大、更昂贵的模型更值得投资。

如果我们的任务是开发一种新的或更好的方法论，比如新的神经网络架构或损失函数，基于模型的方法可能是一个更好的选择。使用已建立的基准数据集而不进行修改，使得将新的建模方法与以前的工作进行比较变得更加容易。增加模型的规模通常会提高性能，但增加训练样本数量也能带来类似的效果。假设对于分类、抽取式问答和多选任务来说，训练集较小（< 2*k*），增加一百个样本可能会带来与增加数十亿参数相同的性能提升。

在实际项目中，交替使用数据中心化和模型中心化的模式是非常有意义的。早期投资于数据质量将惠及所有模型。一旦获得了好的数据集，我们可以开始专注于模型调优以提升性能。

### **练习**

**21-1.** 最近的一个趋势是医疗保健领域对预测分析的日益重视。例如，假设一家医疗服务提供商开发了一个 AI 系统，分析患者的电子健康记录，并提供生活方式改变或预防措施的建议。为此，提供商要求患者每天监测并共享健康数据（如脉搏和血压）。这是数据中心化人工智能的一个例子吗？

**21-2.** 假设我们训练一个 ResNet-34 卷积神经网络，用于对 CIFAR-10 和 ImageNet 数据集中的图像进行分类。为了减少过拟合并提高分类准确性，我们实验了数据增强技术，如图像旋转和裁剪。这种方法算是数据中心化吗？

### **参考文献**

+   一个例子说明了增加更多训练数据如何比增加模型大小更能提升模型性能：Yuval Kirstain 等人，《更多示例可能比数十亿参数更有价值》（2021），*[`arxiv.org/abs/2110.04374`](https://arxiv.org/abs/2110.04374)*。

+   Cleanlab 是一个开源库，包含了在计算机视觉和自然语言处理领域中提高标签错误和数据质量的方法：*[`github.com/cleanlab/cleanlab`](https://github.com/cleanlab/cleanlab)*。
