## 附录：习题答案

### **第一章**

**1-1.** 输出层之前的最后一层（在这种情况下是第二个全连接层）可能对嵌入最为有用。然而，我们也可以使用所有其他中间层来创建嵌入。由于后面的层通常会学习更高层次的特征，这些层通常在语义上更有意义，更适合不同类型的任务，包括相关的分类任务。

**1-2.** 与嵌入（embeddings）不同的一种传统输入表示方法是独热编码（one-hot encoding），如第一章所讨论的那样。在这种方法中，每个类别变量使用一个二进制向量表示，其中只有一个值是“热”或激活的（例如，设为 1），而所有其他位置则保持不活跃（例如，设为 0）。

另一种不是嵌入的表示方式是直方图。一个典型的例子是图像直方图（参见 *[`en.wikipedia.org/wiki/Image_histogram`](https://en.wikipedia.org/wiki/Image_histogram)* 了解更多示例）。这些直方图提供了数字图像中色调分布的图形表示，捕捉了像素的强度分布。

此外，词袋模型提供了一种与嵌入不同的方法。在这种模型中，输入句子被表示为一个无序的词集合或“袋”，忽略了语法甚至词序。有关词袋模型的更多细节，请参见 *[`en.wikipedia.org/wiki/Bag-of-words_model`](https://en.wikipedia.org/wiki/Bag-of-words_model)*。

### **第二章**

**2-1.** 将自监督学习应用于视频数据的一种方法是预测视频中的下一帧。这类似于在 GPT 等大型语言模型中的下一词预测。这种方法挑战模型预测序列中的后续事件或动作，赋予它对内容的时间理解。

另一种方法是预测缺失或被遮盖的帧。这个想法受到了像 BERT 这样的巨大语言模型的启发，其中某些词被遮盖，模型的任务是预测这些词。在视频的情况下，可以遮盖整个帧，模型根据周围帧提供的上下文学习插值并预测被遮盖的帧。

图像修复（Inpainting）是视频自监督学习的另一种途径。在这种方法中，不是遮盖整个帧，而是遮盖帧中的特定像素区域。然后，模型被训练去预测缺失或被遮盖的部分，这有助于它掌握视频内容中的细粒度视觉细节和空间关系。

最后，可以使用一种着色技术，将视频转换为灰度图像，然后模型的任务是预测颜色。这不仅教会模型物体的原始颜色，还能提供对光照、阴影和场景整体氛围的理解。

**2-2.** 我们可以移除（掩码）特征值，并训练一个模型来预测这些值，类似于经典的数据插补方法。例如，使用这种方法的一个方法是 TabNet；参见 Sercan O. Arik 和 Tomas Pfister，《TabNet：通过注意力机制解释性学习表格数据》（2019）， *[`arxiv.org/abs/1908.07442`](https://arxiv.org/abs/1908.07442)*。

也可以通过在原始特征空间或嵌入空间中生成训练样本的增强版本来使用对比学习。例如，SAINT 和 SCARF 方法采用了这种方法。关于前者，请参阅 Gowthami Some-palli 等人，《SAINT：通过行注意力和对比预训练改进的表格数据神经网络》（2021）， *[`arxiv.org/abs/2106.01342`](https://arxiv.org/abs/2106.01342)*。关于后者，请参阅 Dara Bahri 等人，《SCARF：使用随机特征破坏的自监督对比学习》（2021）， *[`arxiv.org/abs/2106.15147`](https://arxiv.org/abs/2106.15147)*。

### **第三章**

**3-1.** 类似于监督学习方法，我们首先将数据集划分为训练集和测试集。然后，我们进一步将训练集和测试集划分为子集，每个子集包含一个来自每个类别的图像。为了设计训练任务，我们只考虑一个子集的类别，例如类别（数字）0、1、2、5、6、8、9。接下来，在测试时，我们使用剩余的类别 3、4、7。对于每个分类任务，神经网络每次接收一个图像示例。

**3-2.** 考虑一种稀有疾病的医学影像场景。训练数据集可能仅包含少数对应不同类型疾病的示例，而少样本系统可能只对新出现的稀有疾病（训练集中没有的疾病）有一例或几例案例。任务是根据这一有限的示例数量识别新的稀有疾病。

另一个少样本系统的例子是推荐系统，该系统只有有限数量的用户评分项。基于这些有限的示例，模型必须预测用户可能喜欢的未来产品。假设有一个仓库机器人，随着公司库存的增加，机器人必须学习识别新物品。机器人需要根据仅有的几个例子学习识别并适应这些新物品。

### **第四章**

**4-1.** 你可以尝试增加初始神经网络的大小。可能所选择的网络太小，无法包含适合的子网络。

另一个选择是尝试不同的随机初始化（例如，通过更改随机种子）。彩票假设认为，*某些* 随机初始化的网络包含可以通过剪枝获得的高度准确的子网络，但并非所有网络都有这样的子网络。

**4-2.** 当使用 ReLU 激活函数训练神经网络时，如果函数输入小于 0，特定的激活值将被设置为 0。这导致隐藏层中的某些节点不参与计算，这些节点有时被称为*死神经元*。虽然 ReLU 激活函数不会直接导致稀疏权重，但零激活输出有时会导致无法恢复的零权重。这一观察结果支持了彩票假说，该假说认为训练良好的网络可能包含具有稀疏且可训练权重的子网络，这些权重可以在不损失准确度的情况下进行修剪。

### **第五章**

**5-1.** XGBoost 是一个基于树的梯度提升实现，当前版本不支持迁移学习。与人工神经网络不同，XGBoost 是一个非参数模型，我们不能轻易地在新数据到达时更新它；因此，常规的迁移学习在这里是行不通的。

然而，我们可以将一个 XGBoost 模型在某个任务上训练得到的结果作为另一个 XGBoost 模型的特征。考虑两个数据集的特征集合重叠。例如，我们可以为合并后的数据集设计一个自监督的分类任务。然后，我们可以在目标数据集上训练第二个 XGBoost 模型，该模型以原始特征集作为输入，并结合第一个 XGBoost 模型的输出。

**5-2.** 在应用数据增强时，我们通常还需要增加训练时间；因此，可能需要更长时间来训练模型。

或者，我们可能应用了过多的数据增强。过度增强数据可能导致过度变化，这些变化并不反映数据中的自然变化，从而导致过拟合或对新数据的泛化能力差。以 MNIST 为例，这也可能包括对图像进行平移或裁剪，使得由于缺失部分而使数字变得无法识别。

另一种可能性是我们应用了过于简单、领域不一致的数据增强。例如，假设我们正在对图像进行垂直或水平翻转。如果是 MNIST 数据集，这样做就没有意义，因为将手写数字垂直或水平翻转会生成现实中不存在的数字。

### **第六章**

**6-1.** 调整训练周期数是一个更简单且更普遍的方法。这对于不支持模型检查点的旧框架尤为适用。因此，改变训练周期数可能是一个更容易的解决方案，尤其适用于小型数据集和模型，在这些情况下，每个超参数配置的运行和评估成本较低。此方法还避免了在训练过程中需要监控验证集性能，使得使用起来更加简单和直接。

提前停止和检查点方法对于训练成本高昂的模型特别有用。通常，它也是一种更灵活和更强健的防止过拟合的方法。然而，这种方法的一个缺点是，在噪声较大的训练环境下，我们可能会优先选择一个较早的训练周期，即使验证集的准确度并不能很好地估计泛化精度。

**6-2.** 集成方法的一个显而易见的缺点是计算成本增加。例如，如果我们建立一个包含五个神经网络的神经网络集成，那么这个集成的成本可能是单个模型的五倍。

尽管我们通常会考虑上述的推理成本，但存储成本的增加是另一个显著的限制因素。如今，大多数计算机视觉和语言模型拥有数百万甚至数十亿个参数，这些参数必须在分布式环境中存储。模型集成使得这一问题更加复杂。

使用模型集成时，降低可解释性是我们需要承担的另一个成本。理解和分析单个模型的预测已经是一个挑战。根据集成方法的不同，我们可能会增加额外的复杂度，从而降低可解释性。

### **第七章**

**7-1.** Adam 优化器实现了一种带有内部权重参数的自适应方法。Adam 每个模型参数有两个优化器参数（均值和方差），因此我们不仅需要拆分模型的权重张量，还需要拆分优化器的状态以应对内存限制。（请注意，这在大多数 DeepSpeed 并行化技术中已经实现。）

**7-2.** 数据并行性理论上可以在 CPU 上工作，但其好处将是有限的。例如，和在 CPU 内存中复制模型以并行训练多个不同数据批次的模型相比，增加数据吞吐量可能更为合理。

### **第八章**

**8-1.** 自注意力机制由于*n*对*n*的比较（其中*n*是输入序列的长度）而具有二次计算和内存复杂度，这使得与其他神经网络架构相比，变换器的计算成本较高。此外，像 GPT 这样的解码器风格变换器生成输出是一次生成一个标记，这在推理时不能并行化（尽管正如在第八章中讨论的那样，生成每个标记仍然是高度并行化的）。

**8-2.** 是的，我们可以将自注意力看作一种特征选择方式，尽管它与其他类型的特征选择存在差异。在这种情况下，区分硬注意力和软注意力非常重要。软注意力为所有输入计算重要性权重，而硬注意力则选择输入的一个子集。硬注意力更像是掩码操作，其中某些输入被设置为 0 或 1，而软注意力允许一个连续的范围的权重。注意力与特征选择的主要区别在于，特征选择通常是一个固定操作，而注意力权重是基于输入动态计算的。在特征选择算法中，选定的特征始终是相同的，而在注意力机制中，权重则可以根据输入变化。

### **第九章**

**9-1.** 自动化这种评估本身就很困难，目前的黄金标准仍然基于人工评估和判断。然而，也存在一些度量标准作为定量指标。

为了评估生成图像的多样性，可以比较生成样本的条件类别分布和边际类别分布，例如使用 Kullback–Leibler 散度（KL 散度）正则化项。这种度量方法在 VAE 中也用于使潜在空间向量类似于标准高斯分布。KL 散度项越高，生成的图像多样性越大。

还可以将生成图像的统计数据与真实图像进行比较，使用预训练模型的特征空间，如作为图像分类器训练的卷积网络。如果相似度很高（或距离很小），则表示这两个分布彼此接近，这通常是图像质量更好的标志。这种方法通常也被称为*Fréchet 起始距离方法*。

**9-2.** 像 GAN、VAE 或扩散模型的生成器一样，一致性模型也将从简单分布（如标准高斯分布）中采样的噪声张量作为输入，生成新的图像。

### **第十章**

**10-1.** 是的，我们可以通过设置*k* = 1 来使 top-*k*采样具有确定性，这样模型在生成输出文本时会始终选择具有最高概率分数的单词作为下一个单词。

我们还可以使核采样具有确定性，例如通过设置概率质量阈值*p*，使其仅包括一个项目，该项目要么恰好满足阈值，要么超过阈值。这将使模型始终选择具有最高概率的标记。

**10-2.** 在某些情况下，推理过程中丢弃层的随机行为是可以接受的，例如在使用单一模型构建模型集成时。（如果没有丢弃层中的随机行为，模型对于给定输入将始终产生相同的结果，这样集成模型就没有意义了。）

此外，dropout 中的随机推理行为对于鲁棒性测试非常有用。对于关键应用，如医疗保健或自动驾驶，理解模型的微小变化如何影响其预测至关重要。通过使用确定性 dropout 模式，我们可以模拟这些微小变化并测试模型的鲁棒性。

### **第十一章**

**11-1.** SGD 只有学习率作为超参数，但没有其他参数。因此，除了在反向传播过程中为每个权重参数计算的梯度（包括计算梯度所需的层激活值）之外，它不会增加任何额外的参数存储。

Adam 优化器更为复杂，且需要更多的存储。具体来说，Adam 会为每个参数保存过去梯度的指数衰减平均值（第一矩）和过去平方梯度的指数衰减平均值（第二原矩）。因此，对于网络中的每个参数，Adam 需要存储两个额外的值。如果网络中有 *n* 个参数，Adam 需要为 2*n* 个额外的参数分配存储空间。

如果网络中有 *n* 个可训练参数，Adam 会增加 2*n* 个参数用于跟踪。例如，在 AlexNet 中，网络包含 26,926 个参数（如练习 1-1 中所计算），因此 Adam 总共需要额外的 53,852 个值（2 *×* 26,926）。

**11-2.** 每个 BatchNorm 层在训练过程中学习两组参数：一组缩放系数（gamma）和一组偏移系数（beta）。这些系数的学习目的是让模型在发现标准化对学习不利时能够将其反转。每一组参数（gamma 和 beta）的大小与它们所标准化的层中的通道数（或神经元数）相同，因为这些参数是为每个通道（或神经元）单独学习的。

对于第一个 BatchNorm 层，它位于第一个卷积层之后，且有五个输出通道，这将增加 10 个额外的参数。对于第二个 BatchNorm 层，它位于第二个卷积层之后，且有 12 个输出通道，这将增加 24 个额外的参数。

第一个全连接层有 128 个输出通道，这意味着需要 256 个额外的 BatchNorm 参数。第二个全连接层没有伴随 BatchNorm 层，因为它是输出层。

因此，BatchNorm 向网络中添加了 10 + 24 + 256 = 290 个额外的参数。

### **第十二章**

**12-1.** 仅仅将步幅从 1 增加到 2（或更大的值）不应影响等价性，因为在这两种情况下，卷积核的大小都等于输入的大小，因此这里没有滑动窗口机制。

**12-2.** 将填充增加到大于 0 的值将影响结果。由于填充的输入，我们将进行滑动窗口卷积操作，在这种操作中，完全连接层的等价性不再成立。换句话说，填充会改变输入的空间维度，这将不再与卷积核的大小匹配，并且每个特征图会产生多个输出值。

### **第十三章**

**13-1.** 使用更小的补丁会增加给定输入图像的补丁数量，从而导致更多的标记被输入到变换器中。这会增加计算复杂度，因为变换器中的自注意力机制在输入标记数量上具有二次复杂度。因此，更小的输入补丁会使模型的计算成本更高。

**13-2.** 使用更大的输入补丁可能会导致输入图像中较精细的细节和局部结构的丢失，这可能会对模型的预测性能产生负面影响。感兴趣的读者可能会喜欢《FlexiViT》论文，该论文研究了补丁大小和数量对计算和预测性能的权衡（Lucas Beyer 等，“FlexiViT: One Model for All Patch Sizes” [2022]，*[`arxiv.org/abs/2212.08013`](https://arxiv.org/abs/2212.08013)*）。

### **第十四章**

**14-1.** 由于同音词具有不同的含义，我们预计它们会出现在其他上下文中，例如“there”和“their”在“I can see you over there”和“Their paper is very nice”中的使用。

由于分布假设认为具有相似含义的词应出现在相似的上下文中，因此同音词并不违背分布假设。

**14-2.** 分布假设的基本思想可以应用于其他领域，例如计算机视觉。在图像的情况下，出现在相似视觉上下文中的物体可能在语义上相关。在更低的层面，邻近的像素可能在语义上相关，因为它们是同一物体的一部分；这一思想被用于图像数据的自监督学习中的掩码自编码器。（我们在第二章中讨论了掩码自编码器。）

另一个例子是蛋白质建模。例如，研究人员表明，训练在蛋白质序列上的语言变换器（其中每个字母代表一个氨基酸的字符串表示，例如*MNGTEGPNFYVPFSNKTGVV . . .*）学习到的嵌入中，类似的氨基酸会聚集在一起（Alexander Rives 等，“Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences” [2019]，*[`www.biorxiv.org/content/10.1101/622803v1.full`](https://www.biorxiv.org/content/10.1101/622803v1.full)*）。例如，疏水性氨基酸如 V、I、L 和 M 出现在同一簇中，而芳香族氨基酸如 F、W 和 Y 出现在另一个簇中。在这个背景下，我们可以将氨基酸视为句子中的一个词。

### **第十五章**

**15-1.** 假设现有数据不存在隐私问题，数据增强有助于生成现有数据的变体，而无需收集额外的数据，这有助于解决隐私问题。

然而，如果原始数据包含个人可识别信息，即使是增强数据或合成数据也可能会与个人信息产生关联，特别是如果增强过程未能充分遮蔽或改变原始数据。

**15-2.** 如果原始数据集已经足够大且多样，以至于模型不会因为数据不足而出现过拟合或性能不足的情况，那么数据增强可能不那么有益。例如，在预训练大型语言模型（LLMs）时，通常会出现这种情况。高度专业化领域的模型（例如医学、法律和金融领域）可能会受到同义词替换和回译等技术的负面影响，因为这些技术可能会将领域特定术语替换为具有特定含义的词汇。一般来说，在那些对措辞选择非常敏感的任务背景中，数据增强必须格外小心地应用。

### **第十六章**

**16-1.** 自注意力机制具有二次时间和内存复杂度。更精确地说，我们可以将自注意力的时间和内存复杂度表示为 *O*(*N*² *× d*)，其中 *N* 是序列的长度，*d* 是序列中每个元素的嵌入维度。

这是因为自注意力机制涉及计算序列中每一对元素之间的相似度。例如，我们有一个输入矩阵 *X*，它有 *N* 个标记（行），其中每个标记是一个 *d* 维的嵌入向量（列）。

当我们计算每个标记嵌入与其他标记嵌入的点积时，我们进行 *XX^T* 乘法，结果是一个 *N×N* 的相似度矩阵。这种乘法对于单个标记对来说涉及 *d* 次乘法，而我们有 *N*² 对这样的标记对。因此，计算复杂度为 *O*(*N*²*×d*)。然后，*N×N* 的相似度矩阵被用来计算序列元素的加权平均值，最终得到一个 *N×d* 的输出表示。这使得自注意力机制在计算上非常昂贵，并且对内存要求较高，尤其是在长序列或 *d* 值较大的情况下。

**16-2.** 是的。有趣的是，自注意力机制可能部分受到用于图像处理的卷积神经网络中的空间注意力机制的启发（Kelvin Xu 等，“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention” [2015]，* [`arxiv.org/abs/1502.03044`](https://arxiv.org/abs/1502.03044) *）。空间注意力是一种机制，允许神经网络专注于图像中与给定任务相关的特定区域。它通过选择性地加权图像中不同空间位置的重要性，使网络能够“更多地关注”某些区域并忽略其他区域。

### **第十七章**

**17-1.** 要将预训练的 BERT 模型适应分类任务，您需要添加一个分类的输出层，通常称为*分类头*。

如前所述，BERT 在预训练时使用[CLS]标记进行下句预测任务。我们可以微调一个新的输出层来完成我们的目标预测任务，比如情感分类，而不是将其训练用于下句预测。

嵌入的[CLS]输出向量作为整个输入序列的摘要。我们可以将其视为特征向量，并在其上训练一个小型神经网络，通常是一个全连接层，后跟 softmax 激活函数，用于预测类别概率。全连接层的输出大小应与我们分类任务中的类别数量相匹配。然后，我们可以像往常一样使用反向传播进行训练。不同的微调策略（更新所有层与仅更新最后一层）可以用来在监督数据集上训练模型，例如。

**17-2.** 是的，我们可以对像 GPT 这样的仅解码器模型进行微调，以用于分类任务，尽管它可能不如使用基于编码器的模型（如 BERT）有效。与 BERT 不同，我们不需要使用特殊的[CLS]标记，但基本概念类似于对编码器风格模型进行微调以进行分类。我们添加一个分类头（一个全连接层和一个 softmax 激活函数），并在第一个生成的输出标记的嵌入（最终的隐藏状态）上进行训练。（这类似于使用[CLS]标记的嵌入。）

### **第十八章**

**18-1.** 如果我们无法访问模型，或者想将模型适应于其未被训练过的类似任务时，上下文学习是有用的。

相反，微调对于将模型适应新目标领域非常有用。例如，假设该模型是在一个通用语料库上预训练的，而我们想将其应用于金融数据或文档。在这种情况下，微调模型以适应该目标领域的数据是有意义的。

请注意，在微调模型时也可以使用上下文学习。例如，当一个预训练的语言模型在特定任务或领域上进行微调时，上下文学习会利用该模型根据输入中提供的上下文生成响应的能力，相较于没有微调的上下文学习，这可能会在目标领域中提供更准确的结果。

**18-2.** 这是隐式完成的。在前缀微调、适配器和 LoRA 中，预训练语言模型的原始知识通过保持核心模型参数冻结的方式得以保留，同时引入额外的可学习参数，这些参数适应新的任务。

### **第十九章**

**19-1.** 如果我们使用像 Word2Vec 这样的嵌入技术，它会独立处理每个词，那么我们会期望“cat”词嵌入之间的余弦相似度为 1.0。然而，在本例中，我们使用的是变换器模型来生成嵌入。变换器使用自注意力机制，在生成嵌入向量时考虑整个上下文（例如输入文本）。(有关自注意力的更多信息，请参见第十六章)。由于*cat*一词在两个不同的句子中出现，BERT 模型为这两个*cat*实例生成了不同的嵌入。

**19-2.** 切换候选文本和参考文本的效果与计算跨列的最大余弦相似度（如图 19-3 第 5 步所示）与跨行计算相似，这可能导致特定文本的 BERT-Score 不同。因此，BERTScore 通常在实践中计算为类似于 ROUGE 的 F1 分数。例如，我们先计算一种方式的 BERTScore（召回率），然后计算另一种方式（精准率），最后计算调和均值（F1 分数）。

### **第二十章**

**20-1.** 随机森林通常基于 CART 决策树，不能随着新数据的到来轻松更新。因此，无状态训练方法将是唯一可行的选择。另一方面，假设我们改为使用神经网络模型，例如递归神经网络，那么有状态方法可能更有意义，因为神经网络可以根据新数据进行即时更新。（然而，在开始时，比较有状态和无状态系统是个好主意，这样可以在决定使用哪种方法之前了解哪种方法最有效。）

**20-2.** 在这里，采用有状态重训练方法最为合理。与其在现有数据（包括用户反馈）的基础上训练一个新模型，更合理的做法是根据用户反馈更新模型。大型语言模型通常是通过自监督的方式预训练，然后通过监督学习进行微调。训练大型语言模型非常昂贵，因此通过有状态重训练来更新模型，而不是重新从头开始训练，是更合适的做法。

### **第二十一章**

**21-1.** 根据提供的信息，目前不清楚这是否是一个以数据为中心的方法。AI 系统在做出预测和推荐时，严重依赖数据输入，但这对于任何 AI 的机器学习方法来说都是如此。为了确定这种方法是否是数据中心的 AI 示例，我们需要知道 AI 系统是如何开发的。如果它是通过使用固定模型并精细化训练数据来开发的，那么这可能算作数据中心的方法；否则，它只是常规的机器学习和预测建模。

**21-2.** 如果我们保持模型不变——即重用相同的 ResNet-34 架构——并且仅改变数据增强方法以研究其对模型性能的影响，那么我们可以将其视为数据驱动的方法。然而，数据增强通常也是现代机器学习管道的一部分，单独使用数据增强并不能告诉我们某种方法是否以数据为中心。根据现代定义，数据驱动的方法意味着在保持其余建模和训练管道不变的情况下，积极研究不同数据集增强技术之间的差异。

### **第二十二章**

**22-1.** 使用多 GPU 策略进行推理的一个缺点是 GPU 之间的额外通信开销。然而，对于推理任务，由于不需要梯度计算和更新，相比训练，推理任务相对较小，GPU 之间的通信所需时间可能会超过并行化所节省的时间。

管理多个 GPU 也意味着更高的设备和能源成本。实际上，优化单 GPU 或 CPU 性能通常更具价值。如果有多个 GPU 可用，在不同 GPU 上并行处理多个样本通常比通过多个 GPU 处理同一样本更有意义。

**22-2.** 循环分块通常与向量化结合使用。例如，在应用循环分块后，每个块可以使用向量化操作进行处理。这使我们能够对已经在缓存中的数据使用 SIMD 指令，从而提高两种技术的效果。

### **第二十三章**

**23-1.** 问题在于重要性加权假设测试集分布与部署分布一致。然而，由于各种原因，如用户行为变化、产品特性演变或环境动态，这种假设通常不成立。

**23-2.** 常见的做法是监控分类准确率等指标，性能下降可能表明数据发生了变化。然而，如果我们无法访问新数据的标签，这种做法就不切实际。

在无法标记新到数据的情况下，我们可以使用统计学的两样本检验来确定示例是否来自相同的分布。我们还可以使用对抗验证，详见第二十九章。然而，这些方法无法帮助检测概念漂移，因为它们仅比较输入分布，而不是输入与输出之间的关系。

其他方法包括测量重构误差：如果我们有一个在源数据上训练的自编码器，我们可以监控新数据的重构误差。如果误差显著增加，这可能表明输入分布发生了变化。

异常值检测是另一种常见技术。在这里，数据点被识别为异常值的异常高比例可能表明数据分布发生了变化。

### **第二十四章**

**24-1.** 尝试预测一个球员进球数（例如基于过去赛季的数据）是一个泊松回归问题。另一方面，我们也可以应用有序回归模型对不同球员进行排名，按照他们将进球的数量进行排序。然而，由于进球差距是固定的并且可以量化（例如，3 和 4 个进球之间的差距与 15 和 16 个进球之间的差距是一样的），这并不是一个适合有序回归模型的问题。

**24-2.** 这是一个类似于有序回归问题的排名问题，但也有一些区别。由于我们仅知道电影的相对顺序，成对排名算法可能比有序回归模型更合适。

然而，如果让被评估者为每部电影分配数值标签（如 1 到 5 的评分尺度，类似于亚马逊上的星级评分系统），那么就可以对这种类型的数据训练并使用有序回归模型。

### **第二十五章**

**25-1.** 置信度水平（90%、95%、99%等）的选择会影响置信区间的宽度。较高的置信度水平会产生更宽的区间，因为我们需要撒出更大的网，以确保更有信心地捕捉到真实参数。

相反，较低的置信度会产生一个较窄的区间，反映出对于真实参数位置的不确定性较大。因此，90%的置信区间比 95%的置信区间要窄，反映出对于真实总体参数位置的更大不确定性。通俗来说，我们有 90%的把握认为真实参数位于一个较小的数值范围内。为了增加这种确定性，我们必须将宽度增加到 95%或 99%。

例如，假设我们有 90%的把握相信在未来两周内威斯康星州会下雨。如果我们希望在没有收集额外数据的情况下以 95%的置信度做出预测，我们需要增加时间间隔。例如，我们可以说我们有 95%的把握认为未来四周内会下雨，或者 99%的把握认为在未来两个月内会下雨。

**25-2.** 由于模型已经训练完成并且保持不变，将其应用于每个测试集会显得浪费。为了加速本节中描述的过程，我们从技术上来说只需要在原始测试集上应用模型一次。然后，我们可以直接对实际标签和预测标签进行自助抽样（而不是对原始样本进行抽样），以创建自助抽样的测试集。接着，我们可以基于每个集合中自助抽样的标签计算测试集的准确度。

### **第二十六章**

**26-1.** 预测集的大小可以告诉我们关于预测置信度的很多信息。如果预测集的大小较小（例如，在分类任务中为 1），这表明对预测有很高的信心。算法有足够的证据强烈推荐某个特定的结果。

如果预测集的大小较大（例如，在分类任务中为 3），这表示更多的不确定性。模型对预测的信心较低，并且认为多个结果都是可能的。在实际操作中，我们可以利用这一信息为预测集大小较大的样本分配更多资源。例如，我们可以将这些案例标记为需要人工验证，因为机器学习模型的信心较低。

**26-2.** 绝对正确。置信区间同样适用于回归模型，就像它们适用于分类模型一样。实际上，在回归的上下文中，它们甚至更为通用。例如，我们可以使用第二十五章中所示的方法计算模型性能的置信区间，如均方误差。（但我们也可以为个别预测和模型参数计算置信区间。如果你对模型参数的置信区间感兴趣，可以查看我的文章《可解释的机器学习——关于线性和逻辑回归作为可解释模型的书评与思考》，网址为 *[`sebastianraschka.com/blog/2020/interpretable-ml-1.html`](https://sebastianraschka.com/blog/2020/interpretable-ml-1.html)*。）

我们还可以为回归模型计算符合性预测区间。该区间是一个可能的目标值范围，而不是单一的点估计。对这样的预测区间的解释是，在假设未来与过去在统计上相似的前提下（例如，基于模型训练时的数据），新的实例的真实目标值将在该范围内，以一定的置信度，例如 95%。

### **第二十七章**

**27-1.** 由于 MAE 是基于距离的绝对值，它自然满足第一个标准：不能为负数。此外，如果我们交换 *y* 和 *ŷ* 的值，MAE 的结果保持不变，因此它满足第二个标准。那么，三角不等式如何呢？类似于 RMSE 与欧几里得距离或 L2 范数的关系，MAE 与两个向量之间的 L1 范数相似。由于所有向量范数都满足三角不等式（Horn 和 Johnson，《矩阵分析》，剑桥大学出版社，1990），所以我们的同事是错误的。

此外，即使 MAE 不是一个合适的度量标准，它仍然可以作为一个有用的模型评估指标；例如，考虑分类准确率。

**27-2.** MAE 对所有误差赋予相同的权重，而 RMSE 由于二次幂的关系，对较大绝对值的误差给予更多关注。因此，RMSE 总是至少与 MAE 一样大。然而，没有哪个指标在所有情况下都比另一个好，它们都在多年的无数研究中被用来评估模型性能。

如果你对 MAE 和 RMSE 之间的更多比较感兴趣，你可能会喜欢 Cort J. Willmott 和 Kenji Matsuura 的文章《在评估平均模型性能时，平均绝对误差（MAE）相对于均方根误差（RMSE）的优点》（2005），* [`www.int-res.com/abstracts/cr/v30/n1/p79-82`](https://www.int-res.com/abstracts/cr/v30/n1/p79-82)*。

### **Chapter 28**

**28-1.** 如果我们只关心平均表现，这就不是问题。例如，如果我们有一个包含 100 个训练样本的数据集，且模型在 100 个验证折叠中正确预测了 70 个，我们估计模型的准确率为 70%。然而，假设我们有兴趣分析不同折叠的估计值的方差。在这种情况下，LOOCV 就不太有用：因为每个折叠仅包含一个训练样本，我们无法计算每个折叠的方差并将其与其他折叠进行比较。

**28-2.** *k*折交叉验证的另一个使用场景是模型集成。例如，在 5 折交叉验证中，我们训练五个不同的模型，因为我们有五个稍微不同的训练集。然而，除了在整个训练集上训练最终模型之外，我们还可以将这五个模型组合成一个模型集成（这在 Kaggle 上特别流行）。有关这个过程的示意图，请参见图 6-3，位于第 34 页。

### **Chapter 29**

**29-1.** 作为性能基准，实施零规则分类器（例如多数类分类器）是一个好主意。因为我们通常拥有比测试数据更多的训练数据，我们可以计算一个总是预测*Is test? False*的模型的表现，如果我们将原始数据集划分为 70%的训练数据和 30%的测试数据，它应该会得到 70%的准确率。如果训练在对抗验证数据集上的模型的准确率明显超过这个基准（比如 80%），我们可能需要进一步调查一个严重的差异问题。

**29-2.** 总的来说，这不是一个大问题，因为我们主要关心是否存在偏离多数类预测基准的强偏差。例如，如果我们将对抗验证模型的准确率与基准进行比较（而不是 50%的准确率），则不应存在问题。然而，考虑像 Matthew 相关系数、ROC 或精确度-召回曲线下面积等评估指标可能更好，而不是分类准确率。

### **Chapter 30**

**30-1.** 虽然我们通常将自监督学习和迁移学习视为不同的方法，但它们并不一定是互斥的。例如，我们可以使用自监督学习在一个带标签或更大规模的未标记图像数据集上预训练模型（在这种情况下，未标记的图像可能对应于各种计算设备的数百万张图片）。

我们可以不从随机权重开始，而是使用自监督学习的神经网络权重，然后通过数千张带标签的智能手机图片进行迁移学习。由于智能手机与平板电脑相关，迁移学习在这里是一种非常有前景的方法。

最后，在自监督预训练和迁移学习之后，我们可以在目标任务的数百张带标签图片上进行微调，这些任务是与平板电脑相关的。

**30-2.** 除了针对神经网络输出层中过于自信的分数的缓解技术外，我们还可以考虑通过集成方法来获取置信度分数。例如，在推理过程中，我们可以利用丢弃法（dropout）来获得一个示例的多个不同预测，从而计算预测标签的不确定性，而不是在推理时禁用丢弃法。

另一种选择是使用* k *折交叉验证从训练集的不同部分构建模型集成，正如在第六章的集成部分中讨论的那样。

也可以将在第二十六章中讨论的符合性预测方法应用于主动学习。
