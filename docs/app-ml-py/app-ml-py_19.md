# çº¿æ€§å›å½’

> åŸæ–‡ï¼š[`geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_linear_regression.html`](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_linear_regression.html)

è¿ˆå…‹å°”Â·JÂ·çš®å°”èŒ¨ï¼Œæ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡

[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python ä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html) | [Python ä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/) | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)

ç”µå­ä¹¦â€œPython ä¸­åº”ç”¨æœºå™¨å­¦ä¹ ï¼šåŠ¨æ‰‹æŒ‡å—åŠä»£ç â€çš„ç« èŠ‚ã€‚

è¯·å°†æ­¤ç”µå­ä¹¦å¼•ç”¨å¦‚ä¸‹ï¼š

Pyrcz, M.J., 2024, *Python ä¸­åº”ç”¨æœºå™¨å­¦ä¹ ï¼šåŠ¨æ‰‹æŒ‡å—åŠä»£ç * [ç”µå­ä¹¦]. Zenodo. doi:10.5281/zenodo.15169138 ![DOI](https://doi.org/10.5281/zenodo.15169138)

æœ¬ä¹¦åŠæ›´å¤šå·¥ä½œæµç¨‹åœ¨æ­¤å¤„å¯ç”¨ï¼š

è¯·å°† MachineLearningDemos GitHub ä»“åº“å¼•ç”¨å¦‚ä¸‹ï¼š

Pyrcz, M.J., 2024, *MachineLearningDemos: Python æœºå™¨å­¦ä¹ æ¼”ç¤ºå·¥ä½œæµç¨‹å­˜å‚¨åº“* (0.0.3) [è½¯ä»¶]. Zenodo. DOI: 10.5281/zenodo.13835312\. GitHub ä»“åº“: [GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos) ![DOI](https://zenodo.org/doi/10.5281/zenodo.13835312)

ä½œè€…ï¼šè¿ˆå…‹å°”Â·JÂ·çš®å°”èŒ¨

Â© ç‰ˆæƒæ‰€æœ‰ 2024ã€‚

æœ¬ç« æ˜¯å…³äº**çº¿æ€§å›å½’**çš„æ•™ç¨‹å’Œæ¼”ç¤ºã€‚

**YouTube è®²åº§**ï¼šæŸ¥çœ‹æˆ‘åœ¨ä»¥ä¸‹æ–¹é¢çš„è®²åº§ï¼š

+   [æœºå™¨å­¦ä¹ ç®€ä»‹](https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl)

+   [çº¿æ€§å›å½’](https://youtu.be/0fzbyhWiP84)

+   [å²­å›å½’](https://youtu.be/pMGO40yXZ5Y?si=ygJAheyX-v2BmSiR)

+   [LASSO å›å½’](https://youtu.be/cVFYhlCCI_8?si=NbwIDaZj30vxezn2)

+   [è§„èŒƒ](https://youtu.be/JmxGlrurQp0?si=vuF1TXDbZkyRC1j-)

è¿™äº›è®²åº§éƒ½æ˜¯æˆ‘ YouTube ä¸Šçš„ [æœºå™¨å­¦ä¹ è¯¾ç¨‹](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI) çš„ä¸€éƒ¨åˆ†ï¼Œå…¶ä¸­åŒ…å«æœ‰è‰¯å¥½æ–‡æ¡£è®°å½•çš„ Python å·¥ä½œæµç¨‹å’Œäº¤äº’å¼ä»ªè¡¨æ¿ã€‚æˆ‘çš„ç›®æ ‡æ˜¯åˆ†äº«æ˜“äºè·å–ã€å¯æ“ä½œå’Œå¯é‡å¤çš„æ•™è‚²å†…å®¹ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æˆ‘çš„åŠ¨æœºï¼Œè¯·æŸ¥çœ‹ [è¿ˆå…‹å°”çš„æ•…äº‹](https://michaelpyrcz.com/my-story)ã€‚

## çº¿æ€§å›å½’çš„åŠ¨æœº

è¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„æµç¨‹ï¼Œæ¼”ç¤ºäº†åŸºäºæœºå™¨å­¦ä¹ çš„çº¿æ€§å›å½’é¢„æµ‹ã€‚ä¸ºä»€ä¹ˆä»çº¿æ€§å›å½’å¼€å§‹ï¼Ÿ

+   çº¿æ€§å›å½’æ˜¯æœ€ç®€å•çš„å‚æ•°åŒ–é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹

+   æˆ‘ä»¬é€šè¿‡ä»è®­ç»ƒ MSE çš„å¯¼æ•°è®¡ç®—å‡ºçš„è§£æè§£æ¥å­¦ä¹ è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

+   è®©æˆ‘ä»¬å¼€å§‹äº†è§£æŸå¤±å‡½æ•°å’ŒèŒƒæ•°æ¦‚å¿µ

+   æˆ‘ä»¬å¯ä»¥è®¿é—®æ¨¡å‹ä¸ç¡®å®šæ€§çš„ç½®ä¿¡åŒºé—´åˆ†æè¡¨è¾¾å¼ï¼Œä»¥åŠå‚æ•°æ˜¾è‘—æ€§çš„å‡è®¾æ£€éªŒ

è¿™é‡Œæ˜¯å…³äºçº¿æ€§å›å½’çš„ä¸€äº›åŸºæœ¬ç»†èŠ‚ã€‚

## çº¿æ€§å›å½’

ç”¨äºé¢„æµ‹çš„çº¿æ€§å›å½’ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹çœ‹ä¸€ç»„æ•°æ®æ‹Ÿåˆçš„çº¿æ€§æ¨¡å‹ã€‚

![](img/806bf5f702f9bb5a63e30d6e1f7969d9.png)

ç¤ºä¾‹çº¿æ€§å›å½’æ¨¡å‹ã€‚

è®©æˆ‘ä»¬å…ˆå®šä¹‰ä¸€äº›æœ¯è¯­ï¼Œ

+   **é¢„æµ‹ç‰¹å¾** - é¢„æµ‹æ¨¡å‹çš„è¾“å…¥ç‰¹å¾ï¼Œé‰´äºæˆ‘ä»¬åªè®¨è®ºçº¿æ€§å›å½’è€Œä¸è®¨è®ºå¤šå…ƒçº¿æ€§å›å½’ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ $x$ã€‚åœ¨æˆ‘ä»¬çš„å›¾è¡¨ï¼ˆåŒ…æ‹¬ä¸Šé¢çš„ï¼‰ä¸­ï¼Œé¢„æµ‹ç‰¹å¾ä½äº x è½´ä¸Šã€‚

+   **å“åº”ç‰¹å¾** - é¢„æµ‹æ¨¡å‹çš„è¾“å‡ºç‰¹å¾ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ$y$ã€‚åœ¨æˆ‘ä»¬çš„å›¾è¡¨ï¼ˆåŒ…æ‹¬ä¸Šé¢çš„ï¼‰ä¸­ï¼Œå“åº”ç‰¹å¾ä½äº y è½´ä¸Šã€‚

ç°åœ¨ï¼Œè¿™é‡Œæ˜¯çº¿æ€§å›å½’çš„ä¸€äº›å…³é”®æ–¹é¢ï¼š

**å‚æ•°æ¨¡å‹**

è¿™æ˜¯ä¸€ä¸ªå‚æ•°é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæˆ‘ä»¬æ¥å—ä¸€ä¸ªå…ˆéªŒçš„çº¿æ€§å‡è®¾ï¼Œç„¶åè·å¾—ä¸€ä¸ªéå¸¸ä½çš„å‚æ•°è¡¨ç¤ºï¼Œè¿™ä½¿å¾—åœ¨æ²¡æœ‰å¤§é‡æ•°æ®çš„æƒ…å†µä¸‹æ˜“äºè®­ç»ƒã€‚

+   é€‚é…æ¨¡å‹æ˜¯ä¸€ä¸ªåŸºäºæ‰€æœ‰å¯ç”¨ç‰¹å¾ $x_1,\ldots,x_m$ çš„ç®€å•åŠ æƒçº¿æ€§åŠ æ€§æ¨¡å‹ã€‚

+   å‚æ•°æ¨¡å‹çš„å½¢å¼ä¸ºï¼š

$$ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 $$

è¿™é‡Œæ˜¯çº¿æ€§æ¨¡å‹å‚æ•°çš„å¯è§†åŒ–ï¼Œ

![](img/ada2fcc2740c48478e79404563c91061.png)

çº¿æ€§æ¨¡å‹å‚æ•°ã€‚

**æœ€å°äºŒä¹˜æ³•**

å¯¹äº L2 èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œæ¨¡å‹å‚æ•° $b_1,\ldots,b_m,b_0$ çš„è§£æè§£æ˜¯å¯ç”¨çš„ï¼Œè¯¯å·®æ˜¯æ€»å’Œå¹¶å¹³æ–¹çš„ï¼Œå³æœ€å°äºŒä¹˜æ³•ã€‚

+   æˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®ä¸Šæœ€å°åŒ–è¯¯å·®ï¼Œæ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰ï¼š

$$ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0) \right)Â² $$

å…¶ä¸­ $y_i$ æ˜¯å®é™…å“åº”ç‰¹å¾å€¼ï¼Œ$\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0$ æ˜¯æ¨¡å‹é¢„æµ‹ï¼Œåœ¨ $\alpha = 1,\ldots,n$ çš„è®­ç»ƒæ•°æ®ä¸Šã€‚

è¿™é‡Œæ˜¯ L2 èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰çš„å¯è§†åŒ–ï¼Œ

![](img/835541b16e1038a4606f7d97b628c4f9.png)

çº¿æ€§æ¨¡å‹æŸå¤±å‡½æ•°ï¼Œå‡æ–¹è¯¯å·®ã€‚

+   è¿™å¯ä»¥ç®€åŒ–ä¸ºè®­ç»ƒæ•°æ®ä¸Šçš„å¹³æ–¹è¯¯å·®æ€»å’Œï¼Œ

\begin{equation} \sum_{i=1}^n (\Delta y_i)Â² \end{equation}

å…¶ä¸­ $\Delta y_i$ æ˜¯å®é™…å“åº”ç‰¹å¾è§‚å¯Ÿ $y_i$ å‡å»æ¨¡å‹é¢„æµ‹ $\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0$ï¼Œåœ¨ $i = 1,\ldots,n$ çš„è®­ç»ƒæ•°æ®ä¸Šã€‚

**å‡è®¾**

æˆ‘ä»¬çš„çº¿æ€§å›å½’æ¨¡å‹æœ‰ä¸€äº›é‡è¦çš„å‡è®¾ï¼Œ

+   **æ— è¯¯å·®** - é¢„æµ‹å˜é‡æ˜¯æ— è¯¯å·®çš„ï¼Œä¸æ˜¯éšæœºå˜é‡

+   **çº¿æ€§** - å“åº”æ˜¯ç‰¹å¾ï¼ˆsï¼‰çš„çº¿æ€§ç»„åˆ

+   **å¸¸æ•°æ–¹å·®** - å“åº”è¯¯å·®åœ¨é¢„æµ‹å€¼ä¸Šæ˜¯æ’å®šçš„

+   **è¯¯å·®ç‹¬ç«‹æ€§** - å“åº”è¯¯å·®ä¹‹é—´ä¸ç›¸å…³

+   **æ— å¤šé‡å…±çº¿æ€§** - æ²¡æœ‰ç‰¹å¾ä¸å…¶ä»–ç‰¹å¾å†—ä½™

## è§£æè§£

ç”±äºæŸå¤±æ˜¯ $LÂ²$ï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®ä¸€ä¸ªéè¿­ä»£ã€è§£æçš„è§£ï¼Œå³çº¿æ€§å›å½’æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–ã€‚

+   æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾ä½¿æŸå¤±å‡½æ•°æœ€å°åŒ–çš„æ¨¡å‹å‚æ•°

+   å½“æˆ‘ä»¬æœ‰ä¸€ä¸ªè§£æè§£æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æŸå¤±å‡½æ•°çš„ä¸€é˜¶å’ŒäºŒé˜¶å¯¼æ•°ï¼Œ

$$ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0) \right)Â² $$

å±€éƒ¨æˆ–å…¨å±€æŸå¤±æœ€å°å€¼å‘ç”Ÿåœ¨ï¼Œ

+   æŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°ä¸º 0.0 - é›¶æ–œç‡è¡¨ç¤ºå±€éƒ¨æœ€å°å€¼æˆ–æœ€å¤§å€¼

$$ \frac{\partial L(y_{\alpha}, F(X_{\alpha}))}{\partial b_1} = 0 $$

+   æŸå¤±å‡½æ•°çš„äºŒé˜¶å¯¼æ•°å¤§äº 0.0 - æ­£æ›²ç‡è¡¨ç¤ºå±€éƒ¨æœ€å°å€¼è€Œä¸æ˜¯æœ€å¤§å€¼

$$ \frac{\partialÂ² L(y_{\alpha}, F(X_{\alpha}))}{\partial b_1Â²} > 0 $$

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨è¿™ç§æ–¹æ³•æ¨å¯¼çº¿æ€§å›å½’çš„è§£ã€‚

## çº¿æ€§å›å½’è®­ç»ƒ

å¯¹äºæœ€å°äºŒä¹˜æ³•ï¼ˆL2ï¼‰èŒƒæ•°ï¼Œçº¿æ€§å›å½’æ¨¡å‹å‚æ•°å¯ä»¥é€šè¿‡å…·æœ‰è§£æè§£çš„è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒã€‚è®©æˆ‘ä»¬æ¨å¯¼å‡ºçº¿æ€§å›å½’è§£æè§£çš„æƒ…å†µï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ã€‚

ä¸ºäº†è®¡ç®—æ–œç‡ç³»æ•°ï¼Œ$b_1$ï¼Œæˆ‘ä»¬é¦–å…ˆä»æŸå¤±å‡½æ•°å¼€å§‹ï¼Œ

$$ RSS = \sum_{i=1}^n \left(y_i - \left( b_{1} x_{i} + b_0 \right) \right)Â² = \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² $$

ç°åœ¨æˆ‘ä»¬å¯¹æ¨¡å‹å‚æ•°ï¼Œ$b_1$ï¼Œæ±‚åå¯¼æ•°ï¼Œ

$$ \frac{\partial}{\partial b_1} \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² = \sum_{i=1}^n -2 \cdot x_i \left(y_i - b_0 -b_1 x_i \right) $$

ä¸ºäº†ä¼˜åŒ–ï¼Œæœ€å°åŒ–æŸå¤±ï¼Œæˆ‘ä»¬å°†å…³äºæ¨¡å‹å‚æ•°çš„åå¯¼æ•°ï¼Œ$b_1$ ç­‰äº 0.0ã€‚

$$ 0 = \sum_{i=1}^n -2 \cdot x_i \left(y_i - b_0 -b_1 x_i \right) $$

æˆ‘ä»¬å¯ä»¥ç®€åŒ–ï¼ˆä¸¤è¾¹é™¤ä»¥-2ï¼‰å¹¶åˆ†é…ä¹˜æ³•ä»¥å¾—åˆ°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - b_0 \cdot x_i -b_1 x_iÂ² $$

ç°åœ¨æˆ‘ä»¬å¯ä»¥ä»£å…¥ $b_0 = \overline{y} - b_1 \cdot \overline{x}$,

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \left(\overline{y} - b_1 \cdot \overline{x} \right) \cdot x_i - b_1 x_iÂ² $$

å†æ¬¡ç›¸ä¹˜å¾—åˆ°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i + b_1 \cdot \overline{x} \cdot x_i - b_1 x_iÂ² $$

æˆ‘ä»¬åˆ†å¼€æ±‚å’Œï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i + \sum_{i=1}^n b_1 \cdot \overline{x} \cdot x_i - b_1 x_iÂ² $$

æˆ‘ä»¬å¯ä»¥æå–å‡º $b_1$ å¸¸æ•°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i + b_1 \sum_{i=1}^n \overline{x} \cdot x_i - x_iÂ² $$

å¹¶ç¨ä½œæ’åºä»¥å¾—åˆ°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i - b_1 \sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i $$

ç§»åˆ°å¦ä¸€è¾¹ï¼Œ

$$ b_1 \sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i $$

å°†ä¸¤ä¸ªå°ºå¯¸é™¤ä»¥ $\sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i$,

$$ b_1 = \frac{\sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i}{\sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i} $$

æˆ‘ä»¬ç°åœ¨å¾—åˆ°äº†çº¿æ€§å›å½’ä¸­ $b_1$ æ–œç‡é¡¹çš„è§£æè§£ã€‚å¯ä»¥è¯æ˜è¿™ç­‰ä»·äºå¦ä¸€ç§å½¢å¼ï¼Œ

$$ b_1 = \frac{\sum_{i=1}^n \left( x_i - \overline{x} \right) \cdot \left( y_i - \overline{y} \right)}{\sum_{i=1}^n \left( x_i - \overline{x} \right)Â²} $$

æˆ‘æ›´å–œæ¬¢è¿™ç§å½¢å¼ï¼Œå› ä¸ºå®ƒå¯ä»¥å®¹æ˜“åœ°è§£é‡Šä¸º $X$ å’Œ $Y$ çš„åæ–¹å·® $C_{x,y}$ é™¤ä»¥ $X$ çš„æ–¹å·® $\sigma_{x}Â²$ã€‚

ç°åœ¨è®¡ç®—æˆªè·é¡¹ $b_0$ï¼Œæˆ‘ä»¬å›åˆ°æŸå¤±å‡½æ•°ï¼Œ

$$ RSS = \sum_{i=1}^n \left(y_i - \left( b_{1} x_{i} + b_0 \right) \right)Â² = \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² $$

è¿™æ¬¡æˆ‘ä»¬å¯¹ $b_0$ æ±‚åå¯¼æ•°ï¼Œ

$$ \frac{\partial}{\partial b_0} \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² = \sum_{i=1}^n -2 \left(y_i - b_0 -b_1 x_i \right) $$

ä¸ºäº†ä¼˜åŒ–ï¼Œæœ€å°åŒ–æŸå¤±ï¼Œæˆ‘ä»¬å°†å…³äºæ¨¡å‹å‚æ•° $b_0$ çš„åå¯¼æ•°è®¾ä¸º 0.0ã€‚

$$ 0 = \sum_{i=1}^n -2 \left(y_i - b_0 -b_1 x_i \right) $$

æˆ‘ä»¬å°†ä¸¤è¾¹é™¤ä»¥ -2ï¼Œ

$$ 0 = \sum_{i=1}^n y_i - b_0 -b_1 x_i $$

å¹¶å°†æ±‚å’Œå±•å¼€ï¼Œ

$$ 0 = \sum_{i=1}^n y_i - \sum_{i=1}^n b_0 - \sum_{i=1}^n b_1 x_i $$

å°†å¸¸æ•°é¡¹ç®€åŒ–ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œ$\sum_{i=1}^n b_0 = n \cdot b_0$ï¼Œ

$$ 0 = \sum_{i=1}^n y_i - n \cdot b_0 - \sum_{i=1}^n b_1 x_i $$

ç°åœ¨å°† $b_0$ é¡¹ç§»åˆ°å·¦è¾¹ï¼Œ

$$ n \cdot b_0 = \sum_{i=1}^n y_i - \sum_{i=1}^n b_1 x_i $$

ä»å’Œä¸­æå–å¸¸æ•° $b_1$ï¼Œ

$$ n \cdot b_0 = \sum_{i=1}^n y_i - b_1 \sum_{i=1}^n x_i $$

ä¸¤è¾¹åŒæ—¶é™¤ä»¥ $n$ï¼Œ

$$ b_0 = \frac{\sum_{i=1}^n y_i}{n} - b_1 \frac{\sum_{i=1}^n x_i}{n} $$

è¿™éå¸¸æœ‰è¶£ï¼Œæˆ‘ä»¬ç°åœ¨çœ‹åˆ°äº†ä¸¤ä¸ªç®—æœ¯å¹³å‡å€¼ï¼

$$ \frac{\sum_{i=1}^n y_i}{n} = \overline{y} \quad \quad \frac{\sum_{i=1}^n x_i}{n} = \overline{x} $$

å› æ­¤æˆ‘ä»¬çš„è§£å¾ˆç®€å•ï¼Œ

$$ b_0 = \overline{y} - b_1 \cdot \overline{x} $$

## æ£€æŸ¥æ¨¡å‹

å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬æœ‰å¼ºå¤§çš„æŒ‡æ ‡æ¥æ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå³ç¡®å®šç³»æ•°ï¼Œä¹Ÿç§°ä¸ºâ€œr-squaredâ€ï¼Œ$rÂ²$ã€‚

+   æ¨¡å‹è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹

+   è®¡ç®—ä¸ºè§£é‡Šæ–¹å·® $SS_{reg}$ é™¤ä»¥æ€»æ–¹å·® $SS_{tot}$ï¼Œ

$$ SS_{reg} = \sum_{i=1}^n \left(\hat{y}_i - \overline{y} \right)Â² \quad \quad SS_{tot} = \sum_{i=1}^n \left(y_i - \overline{y} \right)Â² $$

å…¶ä¸­ $\hat{y}_i$ æ˜¯ç¬¬ $i$ ä¸ªè®­ç»ƒæ•°æ®çš„æ¨¡å‹é¢„æµ‹ï¼Œ$\overline{y}$ æ˜¯æ ·æœ¬æ•°æ®çš„å¹³å‡å€¼ã€‚

+   $rÂ²$ å¯ä»¥ä»ç›¸å…³ç³»æ•°è®¡ç®—å¾—å‡ºï¼Œå› æ­¤ä½ å¯ä»¥åœ¨è®­ç»ƒä¹‹å‰äº†è§£çº¿æ€§å›å½’æ¨¡å‹çš„å¥½åï¼

$$ rÂ² = \left(\rho_{x,y} \right)Â² $$

æ³¨æ„ï¼Œ$rÂ²$åªèƒ½ç”¨äºçº¿æ€§æ¨¡å‹ï¼Œå…¶ä¸­ï¼Œ

$$ \sigmaÂ²_{tot} = \sigmaÂ²_{reg} + \sigmaÂ²_{res} $$

å…¶ä¸­ $\sigmaÂ²_{tot}$ æ˜¯å“åº”ç‰¹å¾çš„æ€»æ–¹å·®ï¼Œ$\sigmaÂ²_{reg}$ æ˜¯æ¨¡å‹é¢„æµ‹çš„æ–¹å·®ï¼Œ$\sigmaÂ²_{res}$ æ˜¯è¯¯å·®çš„æ–¹å·®ï¼Œå³æ®‹å·®ï¼Œ$\Delta y_i = y_i - \hat{y}_i$ã€‚

å¦‚ä½•è§£é‡Š $rÂ²$ï¼Ÿè®¾å®šç¡¬é˜ˆå€¼æ˜¯å±é™©çš„ï¼Œä½†æˆ‘å¯ä»¥æä¾›ä¸€äº›è½¯æ€§æŒ‡å¯¼ï¼Œ

+   $rÂ² \ge 0.98$ - æ¨¡å‹åœ¨ä½œå¼Šæˆ–è€…é—®é¢˜éå¸¸ç®€å•ï¼Œçº¿æ€§ï¼Œæ— å™ªå£°ä¸”é‡‡æ ·è‰¯å¥½

+   $0.0 \le rÂ² \le 0.6$ - æ¨¡å‹å·¥ä½œå¾—ä¸å¥½ï¼Œæ£€æŸ¥æ•°æ®å’Œæ¨¡å‹é€‰æ‹©

+   $rÂ² \lt 0.0$ - æ¨¡å‹èµ°å‘é”™è¯¯ï¼æ‚¨æœ€å¥½é€šè¿‡å…¨å±€å‡å€¼ï¼Œ$\overline{y}$è¿›è¡Œä¼°è®¡

## æ¨¡å‹ä¸ç¡®å®šæ€§

ä¸ºäº†ä¼ è¾¾æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œæˆ‘ä»¬ä¾èµ–äºæ¨¡å‹å‚æ•° $b_1$ å’Œ $b_0$ çš„ç½®ä¿¡åŒºé—´ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œè®©æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰ç½®ä¿¡åŒºé—´ï¼Œ

**ç½®ä¿¡åŒºé—´** - ä»¥èŒƒå›´ã€ä¸‹é™å’Œä¸Šé™è¡¨ç¤ºçš„æ€»ç»“ç»Ÿè®¡é‡/æ¨¡å‹/æ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§ï¼ŒåŸºäºæŒ‡å®šçš„æ¦‚ç‡åŒºé—´ï¼Œç§°ä¸ºç½®ä¿¡æ°´å¹³ã€‚

æˆ‘ä»¬è¿™æ ·ä¼ è¾¾ç½®ä¿¡åŒºé—´ï¼š

+   æœ‰ 95%çš„æ¦‚ç‡ï¼ˆæˆ–è€…è¯´ 20 æ¬¡ä¸­çš„ 19 æ¬¡ï¼‰æ¨¡å‹æ–œç‡åœ¨ 0.5 å’Œ 0.7 ä¹‹é—´ã€‚

æˆ‘ä»¬åœ¨è¿™é‡Œä»‹ç»åˆ†ææ–¹æ³•ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨æ›´çµæ´»çš„ Bootstrap æ–¹æ³•ã€‚

è¿™é‡Œå°±è¶³å¤Ÿäº†ï¼Œè®©æˆ‘ä»¬åŠ è½½æ•°æ®ï¼Œå¹¶åœ¨æ¼”ç¤ºçº¿æ€§å›å½’æ—¶è¿›è¡Œè§£é‡Šã€‚

## åŠ è½½æ‰€éœ€çš„åº“

æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›æ ‡å‡†åŒ…ã€‚è¿™äº›åŒ…åº”è¯¥å·²ç»ä¸ Anaconda 3 ä¸€èµ·å®‰è£…äº†ã€‚

```py
suppress_warnings = False                                     # select to suppress warnings
import os                                                     # to set current working directory 
import math                                                   # square root
import numpy as np                                            # arrays and matrix math
import scipy.stats as st                                      # statistical methods
import pandas as pd                                           # DataFrames
import matplotlib.pyplot as plt                               # for plotting
from matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks
from sklearn.preprocessing import MinMaxScaler                # min/max normalization
from sklearn.linear_model import LinearRegression             # linear regression
from sklearn.model_selection import train_test_split          # train and test split
cmap = plt.cm.inferno                                         # default color bar, no bias and friendly for color vision defeciency
plt.rc('axes', axisbelow=True)                                # grid behind plotting elements
if suppress_warnings == True:  
    import warnings                                           # suppress any warnings for this demonstration
    warnings.filterwarnings('ignore') 
```

å¦‚æœæ‚¨é‡åˆ°åŒ…å¯¼å…¥é”™è¯¯ï¼Œæ‚¨å¯èƒ½å¿…é¡»é¦–å…ˆå®‰è£…è¿™äº›åŒ…ä¸­çš„ä¸€äº›ã€‚è¿™é€šå¸¸å¯ä»¥é€šè¿‡åœ¨ Windows ä¸Šæ‰“å¼€å‘½ä»¤çª—å£ç„¶åè¾“å…¥â€˜python -m pip install [package-name]â€™æ¥å®Œæˆã€‚æœ‰å…³ç›¸åº”åŒ…çš„æ–‡æ¡£ï¼Œå¯ä»¥è·å¾—æ›´å¤šå¸®åŠ©ã€‚

## å£°æ˜å‡½æ•°

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥ç®€åŒ–å‘æˆ‘ä»¬çš„å›¾è¡¨æ·»åŠ æŒ‡å®šçš„ç™¾åˆ†ä½æ•°å’Œä¸»æ¬¡ç½‘æ ¼çº¿ã€‚

```py
def weighted_percentile(data, weights, perc):                 # calculate weighted percentile, iambr on StackOverflow 
    ix = np.argsort(data)                                     # https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049
    data = data[ix] 
    weights = weights[ix] 
    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) 
    return np.interp(perc, cdf, data)

def histogram_bounds(values,weights,color):                   # add uncertainty bounds to a histogram 
    p10 = weighted_percentile(values,weights,0.1); avg = np.average(values,weights=weights); p90 = weighted_percentile(values,weights,0.9)
    plt.plot([p10,p10],[0.0,45],color = color,linestyle='dashed')
    plt.plot([avg,avg],[0.0,45],color = color)
    plt.plot([p90,p90],[0.0,45],color = color,linestyle='dashed')

def add_grid():
    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids
    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)
    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks 
```

## è®¾ç½®å·¥ä½œç›®å½•

æˆ‘æ€»æ˜¯å–œæ¬¢è¿™æ ·åšï¼Œè¿™æ ·æˆ‘å°±ä¸ä¼šä¸¢å¤±æ–‡ä»¶ï¼Œå¹¶ä¸”å¯ä»¥ç®€åŒ–åç»­çš„è¯»å–å’Œå†™å…¥ï¼ˆé¿å…æ¯æ¬¡éƒ½åŒ…å«å®Œæ•´åœ°å€ï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·ç¡®ä¿å°†æ‰€éœ€çš„æ•°æ®æ–‡ä»¶ï¼ˆè§ä¸‹æ–‡ï¼‰æ”¾ç½®åœ¨æ­¤å·¥ä½œç›®å½•ä¸­ã€‚

```py
#os.chdir("C:\PGE337")                                        # set the working directory 
```

æ‚¨å¿…é¡»æ›´æ–°å¼•å·å†…çš„éƒ¨åˆ†ä»¥åŒ…å«æ‚¨è‡ªå·±çš„å·¥ä½œç›®å½•ï¼Œå¹¶ä¸”åœ¨ Mac ä¸Šæ ¼å¼ä¸åŒï¼ˆä¾‹å¦‚ï¼šâ€œ~/PGEâ€ï¼‰ã€‚

## åŠ è½½è¡¨æ ¼æ•°æ®

è¿™æ˜¯å°†æˆ‘ä»¬çš„é€—å·åˆ†éš”æ•°æ®æ–‡ä»¶åŠ è½½åˆ° Pandas DataFrame å¯¹è±¡çš„å‘½ä»¤ã€‚

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€ç©ºé—´æ•°æ®é›†â€˜unconv_MV.csvâ€™ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª 1,000 ä¸ªéå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   å¯†åº¦ ($g/cm^{3}$)

+   å­”éš™ç‡ï¼ˆä½“ç§¯%ï¼‰

æ³¨æ„ï¼Œæ•°æ®é›†æ˜¯åˆæˆçš„ã€‚

æˆ‘ä»¬ä½¿ç”¨ pandas çš„â€˜read_csvâ€™å‡½æ•°å°†å…¶åŠ è½½åˆ°æˆ‘ä»¬ç§°ä¸ºâ€˜my_dataâ€™çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚

```py
add_error = False                                             # add random error to the response feature for testing
std_error = 1.0; seed = 71071

yname = 'Porosity'; xname = 'Density'                         # specify the predictor features (x2) and response feature (x1)
xmin = 1.0; xmax = 2.5                                        # set minimums and maximums for visualization 
ymin = 0.0; ymax = 25.0    
yunit = '%'; xunit = '$g/cm^{3}$'    
Xlabelunit = xname + ' (' + xunit + ')'
ylabelunit = yname + ' (' + yunit + ')'

#df = pd.read_csv("Density_Por_data.csv")                     # load the data from local current directory
df = pd.read_csv(r"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/Density_Por_data.csv") # load the data from my github repo
df = df.sample(frac=.30, random_state = 73073); df = df.reset_index() # extract 30% random to reduce the number of data

if add_error == True:                                         # method to add error
    np.random.seed(seed=seed)                                 # set random number seed
    df[yname] = df[yname] + np.random.normal(loc = 0.0,scale=std_error,size=len(df)) # add noise
    values = df._get_numeric_data(); values[values < 0] = 0   # set negative to 0 in a shallow copy ndarray

dfy = pd.DataFrame(df[yname])                                 # extract selected features as X and y DataFrames
dfx = pd.DataFrame(df[xname])
df = pd.concat([dfx,dfy],axis=1)                              # make one DataFrame with both X and y (remove all other features)

y = df[yname].values.reshape(len(df))
x = df[xname].values.reshape(len(df))
dX = np.linspace(xmin,xmax,100)                               # values for plotting the model 
```

```py
df 
```

|  | å¯†åº¦ | å­”éš™ç‡ |
| --- | --- | --- |
| 0 | 1.906634 | 12.845691 |
| 1 | 1.404932 | 13.668073 |
| 2 | 1.795190 | 11.015021 |
| 3 | 1.705466 | 17.185360 |
| 4 | 1.821963 | 8.190405 |
| 5 | 1.708322 | 10.728462 |
| 6 | 1.897087 | 11.245838 |
| 7 | 1.864561 | 11.357547 |
| 8 | 2.119652 | 8.614564 |
| 9 | 1.301057 | 15.280571 |
| 10 | 1.774021 | 9.489298 |
| 11 | 1.410996 | 14.371990 |
| 12 | 1.697005 | 10.495092 |
| 13 | 0.996736 | 20.964941 |
| 14 | 1.783736 | 13.393518 |
| 15 | 1.743519 | 14.758068 |
| 16 | 1.348847 | 15.877907 |
| 17 | 2.331653 | 4.968240 |
| 18 | 1.438900 | 16.529857 |
| 19 | 1.766823 | 10.485052 |
| 20 | 1.802992 | 10.120258 |
| 21 | 1.750352 | 11.325941 |
| 22 | 1.885087 | 9.242607 |
| 23 | 2.044451 | 8.936061 |
| 24 | 1.778580 | 11.426343 |
| 25 | 1.552689 | 14.157303 |
| 26 | 2.022877 | 10.672887 |
| 27 | 1.530699 | 16.476751 |
| 28 | 1.753578 | 10.826057 |
| 29 | 1.791432 | 14.506748 |
| 30 | 1.830085 | 10.561222 |
| 31 | 1.479878 | 14.443138 |

## å¯è§†åŒ– DataFrame

å¯è§†åŒ– DataFrame æ˜¯æ•°æ®çš„ç¬¬ä¸€æ­¥æ£€æŸ¥ã€‚

+   è®¸å¤šäº‹æƒ…å¯èƒ½ä¼šå‡ºé”™ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬åŠ è½½äº†é”™è¯¯çš„æ•°æ®ï¼Œæ‰€æœ‰ç‰¹å¾éƒ½æ²¡æœ‰åŠ è½½ç­‰ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨â€˜headâ€™ DataFrame æˆå‘˜å‡½æ•°æ¥é¢„è§ˆï¼ˆæ ¼å¼æ•´æ´ï¼Œè§ä¸‹æ–‡ï¼‰ã€‚

+   æ·»åŠ å‚æ•°â€˜n=13â€™ä»¥æŸ¥çœ‹æ•°æ®é›†çš„å‰ 13 è¡Œã€‚

```py
df.head(n=13)                                                 # we could also use this command for a table preview 
```

|  | å¯†åº¦ | å­”éš™ç‡ |
| --- | --- | --- |
| 0 | 1.906634 | 12.845691 |
| 1 | 1.404932 | 13.668073 |
| 2 | 1.795190 | 11.015021 |
| 3 | 1.705466 | 17.185360 |
| 4 | 1.821963 | 8.190405 |
| 5 | 1.708322 | 10.728462 |
| 6 | 1.897087 | 11.245838 |
| 7 | 1.864561 | 11.357547 |
| 8 | 2.119652 | 8.614564 |
| 9 | 1.301057 | 15.280571 |
| 10 | 1.774021 | 9.489298 |
| 11 | 1.410996 | 14.371990 |
| 12 | 1.697005 | 10.495092 |

## è¡¨æ ¼æ•°æ®çš„æ‘˜è¦ç»Ÿè®¡

åœ¨ DataFrames ä¸­ï¼Œæœ‰è®¸å¤šé«˜æ•ˆçš„æ–¹æ³•å¯ä»¥è®¡ç®—è¡¨æ ¼æ•°æ®çš„æ‘˜è¦ç»Ÿè®¡ã€‚describe å‘½ä»¤æä¾›äº†è®¡æ•°ã€å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼å’Œå››åˆ†ä½æ•°ï¼Œå…¨éƒ¨åœ¨ä¸€ä¸ªæ•´æ´çš„æ•°æ®è¡¨ä¸­ã€‚

+   æˆ‘ä»¬ä½¿ç”¨è½¬ç½®åªæ˜¯ä¸ºäº†ç¿»è½¬è¡¨æ ¼ï¼Œä½¿å¾—ç‰¹å¾åœ¨è¡Œä¸Šï¼Œç»Ÿè®¡åœ¨åˆ—ä¸Šã€‚

```py
df.describe().transpose()                                     # summary statistics 
```

|  | count | mean | std | min | 25% | 50% | 75% | max |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| å¯†åº¦ | 32.0 | 1.719994 | 0.262314 | 0.996736 | 1.547192 | 1.770422 | 1.838704 | 2.331653 |
| å­”éš™ç‡ | 32.0 | 12.317525 | 3.224611 | 4.968240 | 10.492582 | 11.341744 | 14.459041 | 20.964941 |

## æ•°æ®å¯è§†åŒ–

æˆ‘ä»¬ä¹Ÿåº”è¯¥çœ‹çœ‹ç›´æ–¹å›¾ã€‚

+   è·å–æ¯ä¸ªç‰¹å¾çš„å–å€¼èŒƒå›´ã€ä¼—æ•°ã€ååº¦ã€å¼‚å¸¸å€¼ç­‰æ¦‚å¿µã€‚

```py
nbins = 20                                                    # number of histogram bins

plt.subplot(221)
freq,_,_ = plt.hist(x=df[xname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)
histogram_bounds(values=df[xname].values,weights=np.ones(len(df)),color='red')
plt.xlabel(xname + ' (' + xunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Density'); add_grid()  
plt.xlim([xmin,xmax])    

plt.subplot(222)
freq,_,_ = plt.hist(x=df[yname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)
histogram_bounds(values=df[yname].values,weights=np.ones(len(df)),color='red')
plt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Porosity'); add_grid()  
plt.xlim([ymin,ymax])  

plt.subplot(223)                                              # plot the model
plt.scatter(df[xname],df[yname],marker='o',label='data',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10)
plt.title('Porosity vs Density')
plt.xlabel(xname + ' (' + xunit + ')')
plt.ylabel(yname + ' (' + yunit + ')')
plt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])

plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)
#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') 
plt.show() 
```

![_images/98de0f9e6b4fc55ef535855f27875a0c49893f41a34ad00f9df6b7568c083cdf.png](img/a2eda54f1271413aca71673e74f3a116.png)

## çº¿æ€§å›å½’æ¨¡å‹

è®©æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ SciPy åŒ…çš„ stats æ¨¡å—è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹åˆ°æ‰€æœ‰æ•°æ®ã€‚

+   æˆ‘ä»¬å°†åœ¨ä»¥åä½¿ç”¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²æ¥å¼€å‘æ›´å¤æ‚çš„äº¤å‰éªŒè¯è®­ç»ƒå’Œè°ƒæ•´æ–¹æ³•ã€‚ç›®å‰ï¼Œæ‰€æœ‰æ•°æ®éƒ½ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚

+   å›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬ä¸Šé¢å°†æ¨¡å—å¯¼å…¥ä¸ºâ€˜stâ€™

```py
import scipy.stats as st                                    # statistical methods 
```

æˆ‘ä»¬åœ¨ä¸€è¡Œä»£ç ä¸­å®ä¾‹åŒ–ã€è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¹¶è·å–ç”¨äºç½®ä¿¡åŒºé—´å’Œå‡è®¾æ£€éªŒçš„æ¨¡å‹è¯Šæ–­ã€‚

```py
slope, intercept, r_value, p_value, std_err = st.linregress(x,y) # instantiate and fit a linear regression model

print('The model parameters are, slope (b1) = ' + str(round(slope,2)) + ', and the intercept (b0) = ' + str(round(intercept,2))) 
```

```py
The model parameters are, slope (b1) = -10.3, and the intercept (b0) = 30.03 
```

æ³¨æ„ï¼Œå½“æˆ‘ä»¬å®ä¾‹åŒ–å’Œæ‹Ÿåˆæˆ‘ä»¬çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æœ‰ 5 ä¸ªè¾“å‡ºã€‚

+   **æ–œç‡** - æˆ‘ä»¬çº¿æ€§æ¨¡å‹çš„æ–œç‡ï¼Œæ¨¡å‹ä¸­çš„ $b_1$ï¼Œ$y = b_1 x + b_0$

+   **æˆªè·** - æˆ‘ä»¬çº¿æ€§æ¨¡å‹çš„æˆªè·ï¼Œæ¨¡å‹ä¸­çš„ $b_0$ï¼Œ$y = b_1 x + b_0$

+   **r_value** - çš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œå¹³æ–¹æ˜¯ $rÂ²$ï¼Œè§£é‡Šçš„æ–¹å·®

+   **p_value** - å¯¹é›¶æ–œç‡æ¨¡å‹çš„å‡è®¾æ£€éªŒçš„ p å€¼

+   **stderr** - æ–œç‡å‚æ•°çš„æ ‡å‡†è¯¯å·®ï¼Œ$SE_{b_1}$

è®©æˆ‘ä»¬ç»˜åˆ¶æ•°æ®å’Œæ¨¡å‹ï¼Œä¸ºäº†å¾—åˆ°æˆ‘ä»¬çš„ä¼°è®¡ï¼Œæˆ‘ä»¬å°†é¢„æµ‹ç‰¹å¾å€¼ä»£å…¥æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```py
x_values = np.linspace(xmin,xmax,100)                         # return an array of density values 
y_model = slope * x_values + intercept                        # apply our linear regression model to estimate at the training data values

plt.subplot(111)                                              # plot the model
plt.plot(x, y, 'o', label='data', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black',zorder=10)
plt.plot(x_values, y_model, label='model', color = 'black',zorder=1)
plt.title('Linear Regression Model, Regression of ' + yname + ' on ' + xname)
plt.xlabel(xname + ' (' + xunit + ')')
plt.ylabel(yname + ' (' + yunit + ')')
plt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])

plt.annotate('Linear Regression Model',[1.25,5.7])
plt.annotate(r'    $\beta_1$ :' + str(round(slope,2)),[1.6,4.1])
plt.annotate(r'    $\beta_0$ :' + str(round(intercept,2)),[1.6,2.5])
plt.annotate(r'$N[\phi] = \beta_1 \times z + \beta_0$',[1.1,4.1])
plt.annotate(r'$N[\phi] = $' + str(round(slope,2)) + r' $\times$ $z$ + (' + str(round(intercept,2)) + ')',[1.1,2.5])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() 
```

![_images/d3fdafa548372646c151694b18b0c75982244b0b0a186248b71ef376c8584bc8.png](img/54afba2518c03ba22364ced82320385f.png)

æ¨¡å‹çœ‹èµ·æ¥æ˜¯åˆç†çš„ã€‚è®©æˆ‘ä»¬è¶…è¶Šè‚‰çœ¼æ£€æŸ¥ã€‚

## ä½¿ç”¨ $rÂ²$ å€¼è¿›è¡Œæ¨¡å‹æ£€æŸ¥

è®©æˆ‘ä»¬å…ˆè§£é‡Š $rÂ²$ï¼Œè§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ã€‚ä»¥ä¸‹æ˜¯æ¨¡å‹è§£é‡Šçš„æ–¹å·®ï¼š

\begin{equation} ğ‘ ğ‘ ğ‘Ÿğ‘’ğ‘” = \sum_{ğ‘–=1}^{ğ‘›}\left(\hat{y}_i - \overline{y}\right)Â² \end{equation}

ä»¥åŠæ¨¡å‹æœªè§£é‡Šçš„æ–¹å·®ï¼Œ

\begin{equation} ğ‘ ğ‘ ğ‘Ÿğ‘’ğ‘ ğ‘–ğ‘‘ = \sum_{ğ‘–=1}^{ğ‘›}\left(y_i - \hat{y}\right)Â² \end{equation}

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è§£é‡Šçš„æ–¹å·®ï¼Œ

\begin{equation} ğ‘ŸÂ² = \frac{ğ‘ ğ‘ _{ğ‘Ÿğ‘’ğ‘”}}{ğ‘ ğ‘ _{ğ‘Ÿğ‘’ğ‘”}+ğ‘ ğ‘ _{ğ‘Ÿğ‘’ğ‘ ğ‘–ğ‘‘}} = \frac{\text{è§£é‡Šçš„æ–¹å·®}}{\text{æ€»æ–¹å·®}} \end{equation}

è¿™æ˜¯å¯¹çº¿æ€§å›å½’æ¨¡å‹è‰¯å¥½åº¦çš„ä¸€ä¸ªå¸¸è§ä¸”ç›´è§‚çš„æŒ‡æ ‡ã€‚

## ä½¿ç”¨å‡è®¾æ£€éªŒè¿›è¡Œæ¨¡å‹æ£€æŸ¥

è®©æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹å‡è®¾æ£€éªŒæ¥æµ‹è¯•æ–œç‡ $b_1$ï¼Œ

\begin{equation} H_0: b_{1} = 0.0 \end{equation}

\begin{equation} H_1: b_{1} \ne 0.0 \end{equation}

å¹¶çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥æ‹’ç»è¿™ä¸ªå‡è®¾ï¼Œ$H_{0}$ ï¼Œå³æ–œç‡å‚æ•°ç­‰äº 0.0\. å¦‚æœæˆ‘ä»¬æ‹’ç»è¿™ä¸ªé›¶å‡è®¾ï¼Œæˆ‘ä»¬è¡¨æ˜æ–œç‡æ˜¯æœ‰æ„ä¹‰çš„ï¼Œå¯†åº¦å’Œå­”éš™ç‡ä¹‹é—´å­˜åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„çº¿æ€§å…³ç³»ã€‚

å¹¸è¿çš„æ˜¯ï¼Œæ¥è‡ª $stats$ åŒ…çš„ $linregress$ å‡½æ•°ä¸ºæˆ‘ä»¬æä¾›äº†è¿™ä¸ªæµ‹è¯•çš„åŒä¾§ p å€¼ã€‚

```py
print('Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = ' + str(p_value) + '.') 
```

```py
Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = 2.2197132981703346e-09. 
```

ç”±äº p å€¼å°äºä»»ä½•åˆç†çš„ $\alpha$ å€¼ï¼Œæˆ‘ä»¬æ‹’ç»é›¶å‡è®¾å¹¶é‡‡ç”¨å¤‡æ‹©å‡è®¾ï¼Œ$H_1$ ï¼Œå³æ–œç‡ä¸ç­‰äº 0.0ã€‚

æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡è®¡ç®—æ¥æ‰§è¡Œæ•´ä¸ªå‡è®¾æ£€éªŒï¼Œ

$$ t_{statistic} = \frac{b_1}{SE_{b_1}} $$

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ $t_{critical}$ å€¼ï¼Œç»™å®š $\alpha$ å’Œ $df = n-2$.

```py
alpha = 0.05
t_critical = st.t.ppf([alpha/2,1-alpha/2], df=len(x)-2)
print('The t-critical lower and upper values are ' + str(np.round(t_critical,2)))
print('and the t-statistic is ' + str(round(slope/std_err,2))) 
```

```py
The t-critical lower and upper values are [-2.04  2.04]
and the t-statistic is -8.4 
```

æˆ‘ä»¬çœ‹åˆ°ä¸ä¹‹å‰çš„å‡è®¾æ£€éªŒå’Œ p å€¼ä¸€è‡´çš„ç»“æœï¼Œå› ä¸º $t_{statistic}$ è½åœ¨ $t_{critical}$ çš„ä¸Šä¸‹åŒºé—´ä¹‹å¤–ï¼Œæˆ‘ä»¬æ‹’ç»é›¶å‡è®¾ï¼Œ$h_0$ ï¼Œå³æ–œç‡ $b_1$ ç­‰äº 0.0ã€‚

æˆ‘ä»¬è¿˜å¯ä»¥è§‚å¯Ÿç›¸å…³ç³»æ•°ï¼Œ$r$ å€¼ï¼Œä»¥åŠè¡¨ç¤ºæˆ‘ä»¬æ¨¡å‹æè¿°çš„æ–¹å·®æ¯”ä¾‹çš„ $rÂ²$ å€¼ã€‚

```py
print('The correlation coefficient is = ' + str(round(r_value,2)) + ' and the r-squared value = ', str(round(r_value**2,2))) 
```

```py
The correlation coefficient is = -0.84 and the r-squared value =  0.7 
```

## æ¨¡å‹ä¸ç¡®å®šæ€§çš„ç½®ä¿¡åŒºé—´

è®©æˆ‘ä»¬è®¡ç®—æ¨¡å‹æ–œç‡å‚æ•° $b_1$ çš„ 95%ç½®ä¿¡åŒºé—´ã€‚æˆ‘ä»¬åªéœ€è¦æˆ‘ä»¬çš„ $t_{critical}$ å’Œæ–œç‡çš„æ ‡å‡†è¯¯å·® $SE_{b_1}$ã€‚

```py
print('The slope confidence interval is ' + str(round(slope,2)) + ' +/- ' + str(round(t_critical[1] * std_err,2)))
CI_slope = slope + t_critical*std_err
print('The slope P02.5 and P97.5 are ' + str(np.round(CI_slope,2))) 
```

```py
The slope confidence interval is -10.3 +/- 2.5
The slope P02.5 and P97.5 are [-12.8  -7.8] 
```

è®©æˆ‘ä»¬é€šè¿‡æ–œç‡ä¸­çš„ç½®ä¿¡åŒºé—´æ¥å¯è§†åŒ–æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚

```py
alpha = 0.05
tstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)            # calculate t-stat for confidence interval
slope_lower,slope_upper = slope + tstat*std_err # calculate the lower and upper confidence interval for b1

plt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=10)
plt.plot(dX, intercept + slope*dX, 'black', label='linear regression model')
plt.plot(dX, intercept + slope_upper*dX, 'black',ls='--',lw=1,label=r'alpha = ' + str(alpha) + ' confidence interval')
plt.plot(dX, intercept + slope_lower*dX, 'black',ls='--',lw=1)
plt.annotate('The model parameters confidence intervals at ' + str(1-alpha) + ' significance level:',[1.3,24])
plt.annotate('Slope: P' + str(alpha/2*100) + ' = '+ str(round(slope_lower,2)) + ' , P' + str((1-alpha/2)*100) + ' = ' + str(round(slope_upper,2)),[1.5,23])
plt.fill_between(dX,intercept + slope_upper*dX,intercept + slope_lower*dX,color='red',alpha=0.3,zorder=1)
plt.title('Sample Data, Linear Regression Model and Slope Confidence Intervals'); plt.xlabel(r'Density ($g/cmÂ³$)'); plt.ylabel('Porosity (%)')
plt.legend(loc='lower left'); add_grid(); plt.ylim([ymin,ymax]); plt.xlim([xmin,xmax])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.1, hspace=0.2); plt.show() 
```

![_images/0bbbe3bf373fd68d3772e3c17b50ebbc962bfa52dfe9696bbbcf88f2260be693.png](img/d1ca1ce80b88510090621b7b2f30e375.png)

## æ¨¡å‹é¢„æµ‹åŒºé—´

è®©æˆ‘ä»¬è®¡ç®—é¢„æµ‹åŒºé—´ã€‚

\begin{equation} \hat{y}*{n+1} Â± t*{(\frac{\alpha}{2},n-2)} \sqrt{MSE}\ \times \sqrt{1+\frac{1}{n}+\frac{(x_{n+1}-\overline{x})Â²}{\sum_{i=1}^{n}(x_{i}-\overline{x})Â²} } \end{equation}

æ³¨æ„ï¼Œè¿™æ˜¯é¢„æµ‹çš„æ ‡å‡†è¯¯å·®ï¼Œ

\begin{equation} SE_{\hat{y}*{n+1}} = \sqrt{MSE}\ \times \sqrt{1+\frac{1}{n}+\frac{(x*{n+1}-\overline{x})Â²}{\sum_{i=1}^{n}(x_{i}-\overline{x})Â²} } \end{equation}

å…¶ä¸­ MSEï¼Œæ¨¡å‹å‡æ–¹è¯¯å·®ï¼Œè®¡ç®—å¦‚ä¸‹ï¼Œ

\begin{equation} MSE = \sum_{i=1}^n\frac{(y_i - \hat{y}*i)Â²}{n-2} = \sum*{i=1}^n \frac{\left(y_i - (b_1 x - b_0) \right)Â²}{n-2} \end{equation}

æ³¨æ„ï¼Œè¿™è¡¨æ˜é¢„æµ‹åŒºé—´éšç€æˆ‘ä»¬ç¦»é¢„æµ‹ç‰¹å¾å€¼å‡å€¼çš„ä¼°è®¡è¶Šæ¥è¶Šè¿œè€Œå˜å®½ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ¨¡å‹ MSEï¼ŒMSE å’Œä¼°è®¡æ ‡å‡†è¯¯å·® $SE_{\hat{y}_{n+1}}$ æ›¿æ¢æœ€ç»ˆå½¢å¼ï¼Œ

\begin{equation} \hat{y}*{n+1} Â± t*{(\frac{\alpha}{2},n-2)} \sqrt{\sum_{i=1}^n \frac{\left(y_i - (b_1 x - b_0) \right)Â²}{n-2}}\sqrt{1+\frac{1}{n}+\frac{(x_{n+1}-\overline{x})Â²}{\sum_{i=1}^{n}(x_{i}-\overline{x})Â²} } \end{equation}

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¼”ç¤ºä¸€ä¸ªé¢„æµ‹åŒºé—´ã€‚

+   é€‰æ‹©ä¸€ä¸ª X å€¼ï¼Œä¸‹é¢ä½œä¸ºè¾“å…¥çš„æ–° _Xï¼Œä»¥åŠé¢„æµ‹åŒºé—´çš„ alpha æ°´å¹³ï¼Œå³ alpha = 0.05 å¯¼è‡´ P025 å’Œ P975 ç»“æœæ¥å®šä¹‰åŒºé—´

```py
new_X = 2.00
alpha = 0.05

tstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)

yhat = intercept + slope*x
MSE = np.sum(np.power(y-yhat,2))/(len(y)-2) # mean square error
est_stderr = math.sqrt(MSE) \
      *math.sqrt(1 + 1/len(y) + np.power(new_X - np.average(x),2)/ \
      np.sum(np.power(x-np.average(x),2)))

y_pred_lower, y_pred_upper = intercept + slope*new_X + tstat*est_stderr

plt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=1)
plt.plot(dX, intercept + slope*dX, 'black', label='linear regression model',zorder=1)
plt.scatter(new_X, intercept + slope*new_X,s=80,color='yellow',edgecolor='black',label=r'prediction, $\hat{y}$',zorder=2)
plt.plot([new_X,new_X],[y_pred_lower,y_pred_upper],color='black',linestyle='dashed',zorder=1,label='prediction interval')
plt.title(r'Sample Data, Linear Regression Model and Prediction Interval, $\alpha = $' + str(alpha)); plt.xlabel(r'Density ($g/cmÂ³$)'); 
plt.ylabel('Porosity (%)')
plt.legend(); add_grid(); plt.ylim([4,22]); plt.xlim([1.0,2.4])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.4, wspace=0.1, hspace=0.2); plt.show() 
```

![_images/5a6dd7728637e0e475487e0a80b773a4446a401a945fb86809c1c1febb8c575d.png](img/19bd5fc3ca00501a930e17fc3ebb1e40.png)

## é¢„æµ‹

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ¨¡å‹åœ¨æ‰€æœ‰æ•°æ®ä½ç½®è¿›è¡Œé¢„æµ‹ã€‚

```py
y_hat = slope * x + intercept
plt.subplot(111)
plt.hist(y_hat, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(5,20,40))
plt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.title(yname + ' Predictions'); plt.xlim([ymin,ymax])
add_grid()
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() 
```

![_images/545490d4664e3ba1508005fe883dd6cea523f44e8aaadcd36f2307b474dab097.png](img/cfe742ca2d1f207ffbe6602e9f0b93b2.png)

## æ£€æŸ¥é¢„æµ‹è¯¯å·®

å°†å­”éš™ç‡çš„é¢„æµ‹ä¸è®­ç»ƒå­”éš™ç‡å¯¹å¯†åº¦æ•£ç‚¹å›¾ç»˜åˆ¶å‡ºæ¥æ˜¯æœ‰ç”¨çš„ã€‚

+   ä»è¿™ä¸ªå›¾ä¸­æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°æˆ‘ä»¬æ¨¡å‹çš„çº¿æ€§é™åˆ¶

+   å¹¶äº†è§£æœªè§£é‡Šçš„æ–¹å·® $\frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)Â²} {n-1}$

```py
plt.subplot(111)
plt.plot(x, y, 'o', label='training data',color = 'darkorange', alpha = 1.0, markeredgecolor = 'black',zorder=10)
plt.scatter(x, y_hat,s=10,marker='o',label='prediction',color = 'grey',edgecolor='black',alpha=1.0,zorder=10)
plt.plot(dX,dX*slope+intercept,color='red',lw=2,zorder=2,label='model')
for idata in range(0,len(x)):
    if idata == 0:
        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey',label=r'$\Delta_{y_i}$',zorder=1)
    else:  
        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey')
plt.title('Comparison of Training Data vs. Model')
plt.xlabel(xname + ' (' + xunit + ')')
plt.ylabel(yname + ' (' + yunit + ')')
plt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() 
```

![_images/c0b53c83c8aa3c23ee1636d164da4a46e45d2410df17b6670670dd5d04980935.png](img/bf66aa77a321545828b548c07857ba83.png)

çœ‹çœ‹ç»˜åˆ¶çš„è¯¯å·®æ®‹å·®ï¼Œ

$$ \Delta y_i = y_i - \hat{y}_i $$

å…¶ä¸­ $y_i$ æ˜¯çœŸå®å“åº”å€¼ï¼Œ$\hat{y}_i$ æ˜¯ä¼°è®¡çš„å“åº”å€¼ã€‚

å¥½å¥½æ£€æŸ¥è¯¯å·®æ®‹å·®åˆ†å¸ƒæ˜¯æœ‰ç”¨çš„ï¼Œ

+   å¹³å‡å€¼æ¥è¿‘ 0.0

+   å½¢çŠ¶ä¸æ˜¯åæ–œçš„

+   æ²¡æœ‰å¼‚å¸¸å€¼

è®©æˆ‘ä»¬çœ‹çœ‹è¯¯å·®æ®‹å·®åˆ†å¸ƒã€‚

```py
residual = y - y_hat

plt.subplot(111)
plt.hist(residual, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(-4,4,30))
plt.title("Error Residual at Training Data"); plt.xlabel(yname + ' True - Estimate (%)');plt.ylabel('Frequency'); add_grid()
plt.vlines(0,0,4.2,color='red',lw=2,zorder=1); plt.vlines(np.average(residual),0,4.2,color='black',ls='--',zorder=10); plt.ylim([0,4.2])
plt.annotate('Residual Average = ' + str(np.round(np.average(residual),2)),[np.average(residual)-0.2,2.5],rotation=90.0)
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show()

print('The average of the residuals is ' + str(round(np.mean(residual),2))) 
```

![_images/1bc994acb07d204d76581a13525e09733c2f17f2105bbd67f0005fbc0001ac0e.png](img/3b7dc57b47ae0c681e96fc44088f5a7b.png)

```py
The average of the residuals is 0.0 
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥çœŸå®å€¼ä¸ä¼°è®¡å€¼çš„æ•£ç‚¹å›¾ï¼Œä»¥åŠäº¤å‰éªŒè¯æ®‹å·®å›¾ï¼Œæ®‹å·®ä¸æ‹Ÿåˆå€¼çš„å…³ç³»ã€‚

+   é€šè¿‡è¿™äº›å›¾ï¼Œæˆ‘ä»¬æ£€æŸ¥è¯¯å·®æ˜¯å¦åœ¨æ‹Ÿåˆå€¼èŒƒå›´å†…ä¸€è‡´

+   ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªå›¾æ¥è¯†åˆ«ç‰¹å®šæ‹Ÿåˆå€¼èŒƒå›´å†…çš„æ›´é«˜è¯¯å·®æˆ–ç³»ç»Ÿæ€§çš„é«˜ä¼°æˆ–ä½ä¼°

```py
slope_cross, intercept_cross, _, _, _ = st.linregress(y_hat,y) # check for conditional bias with a linear fit to the cross validation plot

plt.subplot(121)
plt.plot(y_hat, y, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')
plt.plot([ymin,ymax], [ymin,ymax], 'black',lw=2.0)
plt.plot(np.linspace(ymin,ymax,100), slope_cross*np.linspace(ymin,ymax,100)+intercept_cross, 
         alpha = 0.8, color = 'red',ls='--',lw=1.0)
plt.title('Cross Validation Plot: Truth vs. Estimated Value')
plt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Truth (%)'); add_grid(); plt.xlim([ymin,ymax]); plt.ylim([ymin,ymax])

plt.subplot(122)
plt.plot(y_hat, residual, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')
plt.plot([ymin,ymax], [0,0], 'black')
plt.title('Cross Validation Residual Plot: Residual vs. Estimated Value')
plt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Residual: True - Estimate (%)'); add_grid()
plt.xlim([ymin,ymax]); plt.ylim([-10,10])

plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() 
```

![å›¾ç‰‡](img/eb662574297fc05b3c1cced939dbb806.png)

å¯¹äºæ¼”ç¤ºæ¡ˆä¾‹ï¼Œåœ¨å€¼èŒƒå›´å†…ä¼°è®¡æ²¡æœ‰æ˜æ˜¾çš„æ¡ä»¶åå·®ã€‚

## åœ¨æ–°æ•°æ®é›†ä¸Šçš„å®è·µ

å¥½çš„ï¼Œæ˜¯æ—¶å€™å¼€å§‹å·¥ä½œäº†ã€‚è®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªæ•°æ®é›†å¹¶ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹ï¼Œ

+   ç´§å‡‘çš„ä»£ç 

+   åŸºæœ¬å¯è§†åŒ–

+   ä¿å­˜è¾“å‡º

æ‚¨å¯ä»¥é€‰æ‹©è¿™äº›æ•°æ®é›†ä¹‹ä¸€ï¼Œæˆ–ä¿®æ”¹ä»£ç å¹¶æ·»åŠ æ‚¨è‡ªå·±çš„æ•°æ®é›†æ¥å®Œæˆæ­¤æ“ä½œã€‚

### æ•°æ®é›† 0ï¼Œéå¸¸è§„å¤šå…ƒ v4

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒæ•°æ®é›† [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…æ‹¬æ¥è‡ª 1,000 å£éå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   äº•å¹³å‡å­”éš™ç‡

+   æ¸—é€ç‡çš„å¯¹æ•°å˜æ¢ï¼ˆä»¥çº¿æ€§åŒ–ä¸å…¶ä»–å˜é‡çš„å…³ç³»ï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/mÂ³ x m/s x 10â¶ï¼‰

+   å‰ªåˆ‡æ¯”ï¼ˆ%ï¼‰

+   æ€»æœ‰æœºç¢³ï¼ˆ%ï¼‰

+   ç»ç’ƒè´¨åå°„ç‡ï¼ˆ%ï¼‰

+   åˆå§‹ 90 å¤©å¹³å‡äº§é‡ï¼ˆMCFPDï¼‰ã€‚

### æ•°æ®é›† 1ï¼ŒåäºŒï¼Œ12

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒï¼ŒäºŒç»´ç©ºé—´æ•°æ®é›† [12_sample_data.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/12_sample_data.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…æ‹¬æ¥è‡ª 480 å£éå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   Xï¼ˆmï¼‰ï¼ŒYï¼ˆmï¼‰ä½ç½®åæ ‡

+   ç›¸ï¼ˆ0 - ç ‚å²©ï¼Œ1 - ç ‚ï¼‰

+   å­”éš™ç‡ï¼ˆ%ï¼‰å•ä½è½¬æ¢å

+   æ¸—é€ç‡ï¼ˆmDï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/mÂ³ x m/s x 10â¶ï¼‰

### æ•°æ®é›† 2ï¼Œå‚¨å±‚ 21

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒï¼Œä¸‰ç»´ç©ºé—´æ•°æ®é›† [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…æ‹¬åœ¨ 10,000m x 10,000m x 50 m å‚¨å±‚å•å…ƒä¸Šçš„ 73 å£å‚ç›´äº•çš„å˜é‡ï¼š

+   äº•ï¼ˆIDï¼‰

+   Xï¼ˆmï¼‰ï¼ŒYï¼ˆmï¼‰ï¼Œæ·±åº¦ï¼ˆmï¼‰ä½ç½®åæ ‡

+   å•ä½è½¬æ¢åçš„å­”éš™ç‡ï¼ˆ%ï¼‰

+   æ¸—é€ç‡ï¼ˆmDï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/m2s*10â¶ï¼‰å•ä½è½¬æ¢å

+   ç›¸ï¼ˆåˆ†ç±»ï¼‰ - æœ‰åºï¼Œä»é¡µå²©ã€ç ‚è´¨é¡µå²©ã€é¡µå²©ç ‚åˆ°ç ‚å²©ã€‚

+   å¯†åº¦ï¼ˆg/cmÂ³ï¼‰

+   å¯å‹ç¼©é€Ÿåº¦ï¼ˆm/sï¼‰

+   æ¨æ°æ¨¡é‡ï¼ˆGPaï¼‰

+   å‰ªåˆ‡æ³¢é€Ÿï¼ˆm/sï¼‰

+   å‰ªåˆ‡æ¨¡é‡ï¼ˆGPaï¼‰

+   3 å¹´ç´¯è®¡æ²¹äº§é‡ï¼ˆMbblï¼‰

æˆ‘ä»¬ä½¿ç”¨ pandas çš„â€˜read_csvâ€™å‡½æ•°å°†è¡¨æ ¼æ•°æ®åŠ è½½åˆ°æˆ‘ä»¬ç§°ä¸ºâ€˜my_dataâ€™çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚

+   æˆ‘ä»¬è¿˜ç”¨æ•°æ®èŒƒå›´å’Œæ ‡ç­¾å¡«å……åˆ—è¡¨ï¼Œä»¥ä¾¿äºç»˜å›¾

åŠ è½½æ•°æ®å¹¶æ ¼å¼åŒ–ï¼Œ

+   åˆ é™¤å“åº”ç‰¹å¾

+   æ ¹æ®éœ€è¦é‡æ–°æ ¼å¼åŒ–ç‰¹å¾

+   æ­¤å¤–ï¼Œæˆ‘å–œæ¬¢å°†å…ƒæ•°æ®å­˜å‚¨åœ¨åˆ—è¡¨ä¸­

```py
idata = 0                                                     # select the dataset

if idata == 0:
    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['Well'],axis=1,inplace=True)                 # remove well index and response feature

    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax_new = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting
    ymin_new = 0.0; ymax_new = 10000.0
    xlabel_new = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10â¶)','Brittleness Ratio (%)', # set the names for plotting
             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']

    ylabel_new = 'Production (MCFPD)'

    xtitle_new = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting
             'Total Organic Carbon','Vitrinite Reflectance']

    ytitle_new = 'Production'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

elif idata == 1:
    names = {'Porosity':'Por'}

    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['X','Y','Unnamed: 0','Facies'],axis=1,inplace=True)   # remove response feature
    df_new = df_new.rename(columns=names)
    df_new['Por'] = df_new['Por'] * 100.0; df_new['AI'] = df_new['AI'] / 1000.0
    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [4.0,0.0]; xmax_new = [19.0,500.0] # set the minimum and maximum values for plotting

    ymin_new = 1.60; ymax_new = 6.20

    xlabel_new = ['Porosity (fraction)','Permeability (mD)'] # set the names for plotting

    ylabel_new = 'Acoustic Impedance (kg/m2s*10â¶)'

    xtitle_new = ['Porosity','Permeability']

    ytitle_new = 'Acoustic Impedance (kg/m2s*10â¶)'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

elif idata == 2:  
    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['Well_ID','X','Y'],axis=1,inplace=True) # remove Well Index, X and Y coordinates, and response feature
    df_new = df_new.dropna(how='any',inplace=False)

    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax_new = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting

    ymin_new = 0.0; ymax_new = 1600.0

    xlabel_new = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10â¶)','Facies (categorical)',
              'Density (g/cmÂ³)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting

    ylabel_new = 'Production (Mbbl)'

    xtitle_new = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',
              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']

    ytitle_new = 'Production'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

df_new.head(n=13) 
```

|  | å­” | æ¸— | AI | å‰ª | TOC | VR | äº§ |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |
| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |
| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |
| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |
| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |
| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |
| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |
| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |
| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |
| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |
| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |
| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |
| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |

```py
df_select = df_new.loc[:,['Por','Perm','AI']]
df_select 
```

|  | Por | Perm | AI |
| --- | --- | --- |
| 0 | 12.08 | 2.92 | 2.80 |
| 1 | 12.38 | 3.53 | 3.22 |
| 2 | 14.02 | 2.59 | 4.01 |
| 3 | 17.67 | 6.75 | 2.63 |
| 4 | 17.52 | 4.57 | 3.18 |
| ... | ... | ... | ... |
| 195 | 11.95 | 3.13 | 2.97 |
| 196 | 17.99 | 9.87 | 3.38 |
| 197 | 12.12 | 2.27 | 3.52 |
| 198 | 15.55 | 4.48 | 2.48 |
| 199 | 20.89 | 7.54 | 3.23 |

200 rows Ã— 3 columns

### æ„å»ºå’Œæ£€æŸ¥æ¨¡å‹

```py
test_prop = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_prop, random_state=seed) # train and test split
linear_model_new = LinearRegression().fit(X_train,y_train)    # instantiate and train linear regression model, no hyperparmeters

train_pred = linear_model_new.predict(X_train); test_pred = linear_model_new.predict(X_test) # predict at train and test samples 

plt.scatter(y_train,train_pred,color='green',edgecolor='black',label='Training') # cross validation plot
plt.scatter(y_test,test_pred,color='white',edgecolor='black',label='Testing')
plt.plot([ymin_new,ymax_new],[ymin_new,ymax_new],color='black',zorder=-1)
plt.xlim(ymin_new,ymax_new); plt.ylim(ymin_new,ymax_new); add_grid() 
plt.xlabel('Truth: ' + ylabel_new); plt.ylabel('Estimate: ' + ylabel_new)
plt.title('Linear Model Cross Validation'); plt.legend(loc='upper left')

plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() 
```

![_images/3a7d23260a411f4894d7f9270056b8ff28820241bf7e6859bae42ed471f22fa3.png](img/dcda56f7f818f02921fd7cfe954f1f2a.png)

```py
X_train 
```

|  | Por | Perm | AI | Brittle | TOC | VR |
| --- | --- | --- | --- | --- | --- | --- |
| 16 | 19.55 | 8.41 | 3.08 | 35.49 | 1.34 | 1.95 |
| 15 | 11.34 | 2.72 | 3.43 | 58.03 | 0.57 | 2.15 |
| 179 | 7.22 | 1.42 | 3.60 | 63.09 | -0.03 | 1.67 |
| 109 | 15.19 | 5.05 | 3.11 | 57.97 | 1.15 | 2.16 |
| 134 | 12.83 | 2.69 | 3.67 | 17.20 | 0.61 | 2.01 |
| ... | ... | ... | ... | ... | ... | ... |
| 32 | 12.55 | 3.22 | 3.43 | 56.93 | 0.79 | 2.27 |
| 182 | 9.88 | 2.72 | 3.64 | 55.19 | 0.52 | 2.16 |
| 71 | 14.17 | 3.94 | 2.92 | 59.30 | 0.91 | 1.91 |
| 112 | 18.24 | 4.31 | 2.85 | 44.53 | 1.39 | 2.06 |
| 163 | 11.60 | 1.73 | 2.18 | 53.54 | 0.60 | 1.50 |

160 rows Ã— 6 columns

## è¯„è®º

è¿™æ˜¯å¯¹çº¿æ€§å›å½’çš„åŸºæœ¬å¤„ç†ã€‚å¯ä»¥åšå’Œè®¨è®ºçš„è¿˜æœ‰å¾ˆå¤šï¼Œæˆ‘æœ‰å¾ˆå¤šæ›´å¤šçš„èµ„æºã€‚æŸ¥çœ‹æˆ‘çš„[èµ„æºå…±äº«æ¸…å•](https://michaelpyrcz.com/my-resources)ä»¥åŠæœ¬ç« å¼€å¤´å¸¦æœ‰èµ„æºé“¾æ¥çš„ YouTube è®²åº§é“¾æ¥ã€‚

æˆ‘å¸Œæœ›è¿™ä¼šæœ‰æ‰€å¸®åŠ©ï¼Œ

*Michael*

## å…³äºä½œè€…

![](img/eb709b2c0a0c715da01ae0165efdf3b2.png)

å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ 40 è‹±äº©æ ¡å›­å†…ï¼Œè¿ˆå…‹å°”Â·çš®å°”å¥‡å…¹æ•™æˆçš„åŠå…¬å®¤ã€‚

è¿ˆå…‹å°”Â·çš®å°”å¥‡å…¹ï¼ˆMichael Pyrczï¼‰æ˜¯å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡[Cockrell å·¥ç¨‹å­¦é™¢](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)å’Œ[Jackson åœ°çƒç§‘å­¦å­¦é™¢](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)çš„æ•™æˆï¼Œåœ¨é‚£é‡Œä»–ç ”ç©¶å¹¶æ•™æˆåœ°ä¸‹ã€ç©ºé—´æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ã€‚è¿ˆå…‹å°”è¿˜æ˜¯ï¼Œ

+   [èƒ½æºåˆ†æ](https://fri.cns.utexas.edu/energy-analytics)æ–°ç”Ÿç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡è‡ªç„¶ç§‘å­¦é™¢æœºå™¨å­¦ä¹ å®éªŒå®¤çš„æ ¸å¿ƒæ•™å‘˜ã€‚

+   [è®¡ç®—æœºä¸åœ°å­¦](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)çš„å‰¯ç¼–è¾‘ï¼Œä»¥åŠå›½é™…æ•°å­¦åœ°å­¦åä¼š[æ•°å­¦åœ°å­¦](https://link.springer.com/journal/11004/editorial-board)çš„è‘£äº‹ä¼šæˆå‘˜ã€‚

è¿ˆå…‹å°”å·²ç»æ’°å†™äº† 70 å¤šç¯‡[åŒè¡Œè¯„å®¡çš„å‡ºç‰ˆç‰©](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)ï¼Œä¸€ä¸ªç”¨äºç©ºé—´æ•°æ®åˆ†æçš„[Python åŒ…](https://pypi.org/project/geostatspy/)ï¼Œåˆè‘—äº†ä¸€æœ¬å…³äºç©ºé—´æ•°æ®åˆ†æçš„æ•™ç§‘ä¹¦[åœ°ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)ï¼Œå¹¶æ˜¯ä¸¤æœ¬æœ€è¿‘å‘å¸ƒçš„ç”µå­ä¹¦çš„ä½œè€…ï¼Œ[Python åº”ç”¨åœ°ç»Ÿè®¡å­¦ï¼šGeostatsPy å®è·µæŒ‡å—](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)å’Œ[Python åº”ç”¨æœºå™¨å­¦ä¹ ï¼šå¸¦ä»£ç çš„å®è·µæŒ‡å—](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)ã€‚

è¿ˆå…‹å°”çš„æ‰€æœ‰å¤§å­¦è®²åº§éƒ½å¯ä»¥åœ¨ä»–çš„[YouTube é¢‘é“](https://www.youtube.com/@GeostatsGuyLectures)ä¸Šæ‰¾åˆ°ï¼Œå…¶ä¸­åŒ…å« 100 å¤šä¸ª Python äº¤äº’å¼ä»ªè¡¨æ¿å’Œ 40 å¤šä¸ª GitHub è´¦æˆ·ä¸Šçš„è¯¦ç»†æ–‡æ¡£å·¥ä½œæµç¨‹ï¼Œä»¥æ”¯æŒä»»ä½•æ„Ÿå…´è¶£çš„å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«ï¼Œæä¾›å¸¸é’å†…å®¹ã€‚æƒ³äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„å·¥ä½œå’Œå…±äº«æ•™è‚²èµ„æºï¼Œè¯·è®¿é—®ä»–çš„ç½‘ç«™ã€‚

## æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ

æˆ‘å¸Œæœ›è¿™äº›å†…å®¹å¯¹é‚£äº›æƒ³äº†è§£æ›´å¤šå…³äºåœ°å­¦å»ºæ¨¡ã€æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«æ¬¢è¿å‚åŠ ã€‚

+   æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼

+   æƒ³è¦åˆä½œï¼Œæ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°å­¦æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººæ˜¯çº¦ç¿°Â·ç¦æ–¯ç‰¹æ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶å°†æ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µç›¸ç»“åˆï¼Œä»¥å¼€å‘æ–°çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ï¼Œå¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å­¦é—®é¢˜ï¼

+   æ‚¨å¯ä»¥é€šè¿‡ mpyrcz@austin.utexas.edu è”ç³»æˆ‘ã€‚

æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è®¨è®ºï¼Œ

*è¿ˆå…‹å°”*

è¿ˆå…‹å°”Â·çš®å°”å¥‡ï¼Œåšå£«ï¼Œå·¥ç¨‹å¸ˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ Cockrell å·¥ç¨‹å­¦é™¢å’Œ Jackson åœ°çƒç§‘å­¦å­¦é™¢æ•™æˆ

æ›´å¤šèµ„æºå¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python ä¸­åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html) | [Python ä¸­åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/) | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)

## çº¿æ€§å›å½’çš„åŠ¨æœº

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’å·¥ä½œæµç¨‹ï¼Œç”¨äºåŸºäºæœºå™¨å­¦ä¹ çš„é¢„æµ‹æ¼”ç¤ºã€‚ä¸ºä»€ä¹ˆä»çº¿æ€§å›å½’å¼€å§‹ï¼Ÿ

+   çº¿æ€§å›å½’æ˜¯æœ€ç®€å•çš„å‚æ•°é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

+   æˆ‘ä»¬é€šè¿‡ä»è®­ç»ƒå‡æ–¹è¯¯å·®çš„å¯¼æ•°è®¡ç®—å‡ºçš„è§£æè§£æ¥å­¦ä¹ è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

+   è¿™ä½¿æˆ‘ä»¬å¼€å§‹äº†æŸå¤±å‡½æ•°å’ŒèŒƒæ•°çš„æ¦‚å¿µã€‚

+   æˆ‘ä»¬å¯ä»¥è®¿é—®æ¨¡å‹ä¸ç¡®å®šæ€§çš„ç½®ä¿¡åŒºé—´å’Œå‚æ•°æ˜¾è‘—æ€§çš„å‡è®¾æ£€éªŒçš„è§£æè¡¨è¾¾å¼ã€‚

è¿™æ˜¯å…³äºçº¿æ€§å›å½’çš„ä¸€äº›åŸºæœ¬ç»†èŠ‚ã€‚

## çº¿æ€§å›å½’

é¢„æµ‹çš„çº¿æ€§å›å½’ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹çœ‹ä¸€ç»„æ•°æ®æ‹Ÿåˆçš„çº¿æ€§æ¨¡å‹ã€‚

![](img/806bf5f702f9bb5a63e30d6e1f7969d9.png)

ä¸¾ä¾‹è¯´æ˜çº¿æ€§å›å½’æ¨¡å‹ã€‚

è®©æˆ‘ä»¬å…ˆå®šä¹‰ä¸€äº›æœ¯è¯­ï¼Œ

+   **é¢„æµ‹ç‰¹å¾** - é¢„æµ‹æ¨¡å‹çš„è¾“å…¥ç‰¹å¾ï¼Œé‰´äºæˆ‘ä»¬åªè®¨è®ºçº¿æ€§å›å½’è€Œä¸æ˜¯å¤šå…ƒçº¿æ€§å›å½’ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªé¢„æµ‹ç‰¹å¾ï¼Œ$x$ã€‚åœ¨æˆ‘ä»¬çš„å›¾è¡¨ï¼ˆåŒ…æ‹¬ä¸Šé¢çš„ï¼‰ä¸­ï¼Œé¢„æµ‹ç‰¹å¾ä½äº x è½´ä¸Šã€‚

+   **å“åº”ç‰¹å¾** - é¢„æµ‹æ¨¡å‹çš„è¾“å‡ºç‰¹å¾ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ$y$ã€‚åœ¨æˆ‘ä»¬çš„å›¾è¡¨ï¼ˆåŒ…æ‹¬ä¸Šé¢çš„ï¼‰ä¸­ï¼Œå“åº”ç‰¹å¾ä½äº y è½´ä¸Šã€‚

ç°åœ¨ï¼Œè¿™é‡Œæ˜¯çº¿æ€§å›å½’çš„ä¸€äº›å…³é”®æ–¹é¢ï¼š

**å‚æ•°æ¨¡å‹**

è¿™æ˜¯ä¸€ä¸ªå‚æ•°é¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæˆ‘ä»¬æ¥å—ä¸€ä¸ªå…ˆéªŒçš„çº¿æ€§å‡è®¾ï¼Œç„¶åè·å¾—ä¸€ä¸ªéå¸¸ä½çš„å‚æ•°è¡¨ç¤ºï¼Œè¿™ä½¿å¾—åœ¨æ²¡æœ‰å¤§é‡æ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿå®¹æ˜“è®­ç»ƒã€‚

+   æ‹Ÿåˆæ¨¡å‹æ˜¯ä¸€ä¸ªåŸºäºæ‰€æœ‰å¯ç”¨ç‰¹å¾ $x_1,\ldots,x_m$ çš„ç®€å•åŠ æƒçº¿æ€§åŠ æ€§æ¨¡å‹ã€‚

+   å‚æ•°æ¨¡å‹çš„å½¢å¼å¦‚ä¸‹ï¼š

$$ y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0 $$

è¿™æ˜¯çº¿æ€§æ¨¡å‹å‚æ•°çš„å¯è§†åŒ–ã€‚

![](img/ada2fcc2740c48478e79404563c91061.png)

çº¿æ€§æ¨¡å‹å‚æ•°ã€‚

**æœ€å°äºŒä¹˜æ³•**

æ¨¡å‹å‚æ•° $b_1,\ldots,b_m,b_0$ çš„è§£æè§£å¯¹äº L2 èŒƒæ•°æŸå¤±å‡½æ•°æ˜¯å¯ç”¨çš„ï¼Œè¯¯å·®æ˜¯ç´¯åŠ å¹¶å¹³æ–¹çš„ï¼Œå³æœ€å°äºŒä¹˜æ³•ã€‚

+   æˆ‘ä»¬æœ€å°åŒ–è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®ï¼Œå³æ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰ï¼š

$$ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0) \right)Â² $$

å…¶ä¸­ $y_i$ æ˜¯å®é™…å“åº”ç‰¹å¾å€¼ï¼Œ$\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0$ æ˜¯åœ¨ $\alpha = 1,\ldots,n$ çš„è®­ç»ƒæ•°æ®ä¸Šçš„æ¨¡å‹é¢„æµ‹ï¼Œã€‚

è¿™æ˜¯å¯¹ L2 èŒƒæ•°æŸå¤±å‡½æ•°ï¼Œå‡æ–¹è¯¯å·®çš„å¯è§†åŒ–ï¼Œ

![](img/835541b16e1038a4606f7d97b628c4f9.png)

çº¿æ€§æ¨¡å‹æŸå¤±å‡½æ•°ï¼Œå‡æ–¹è¯¯å·®ã€‚

+   è¿™å¯ä»¥ç®€åŒ–ä¸ºè®­ç»ƒæ•°æ®ä¸Šçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œï¼Œ

$$ \sum_{i=1}^n (\Delta y_i)Â² $$

å…¶ä¸­ $\Delta y_i$ æ˜¯å®é™…å“åº”ç‰¹å¾è§‚å¯Ÿ $y_i$ å‡å»æ¨¡å‹é¢„æµ‹ $\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0$ï¼Œåœ¨ $i = 1,\ldots,n$ çš„è®­ç»ƒæ•°æ®ä¸Šã€‚

**å‡è®¾**

æˆ‘ä»¬çš„çº¿æ€§å›å½’æ¨¡å‹æœ‰ä¸€äº›é‡è¦çš„å‡è®¾ï¼Œ

+   **æ— è¯¯å·®** - é¢„æµ‹å˜é‡æ— è¯¯å·®ï¼Œä¸æ˜¯éšæœºå˜é‡

+   **çº¿æ€§** - å“åº”æ˜¯ç‰¹å¾ï¼ˆsï¼‰çš„çº¿æ€§ç»„åˆ

+   **å¸¸æ•°æ–¹å·®** - å“åº”ä¸­çš„è¯¯å·®åœ¨é¢„æµ‹å˜é‡å€¼ä¸Šæ˜¯å¸¸æ•°

+   **è¯¯å·®ç‹¬ç«‹æ€§** - å“åº”ä¸­çš„è¯¯å·®å½¼æ­¤ä¸ç›¸å…³

+   **æ— å¤šé‡å…±çº¿æ€§** - æ²¡æœ‰ç‰¹å¾ä¸å…¶ä»–ç‰¹å¾å†—ä½™

## è§£æè§£

ç”±äºæŸå¤±æ˜¯ $LÂ²$ï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®ä¸€ä¸ªéè¿­ä»£ã€è§£æçš„è§£å†³æ–¹æ¡ˆï¼Œå³çº¿æ€§å›å½’æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–ã€‚

+   æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾æœ€å°åŒ–æŸå¤±å‡½æ•°çš„æ¨¡å‹å‚æ•°ï¼ˆsï¼‰

+   å½“æˆ‘ä»¬æœ‰è§£æè§£æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æŸå¤±å‡½æ•°çš„ä¸€é˜¶å’ŒäºŒé˜¶å¯¼æ•°ï¼Œ

$$ RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0) \right)Â² $$

å±€éƒ¨æˆ–å…¨å±€æŸå¤±æœ€å°å€¼å‘ç”Ÿåœ¨ä»¥ä¸‹ä½ç½®ï¼Œ

+   æŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°ä¸º 0.0 - é›¶æ–œç‡è¡¨ç¤ºå±€éƒ¨æœ€å°å€¼æˆ–æœ€å¤§å€¼

$$ \frac{\partial L(y_{\alpha}, F(X_{\alpha}))}{\partial b_1} = 0 $$

+   æŸå¤±å‡½æ•°çš„äºŒé˜¶å¯¼æ•°å¤§äº 0.0 - æ­£æ›²ç‡è¡¨ç¤ºå±€éƒ¨æœ€å°å€¼è€Œä¸æ˜¯æœ€å¤§å€¼

$$ \frac{\partialÂ² L(y_{\alpha}, F(X_{\alpha}))}{\partial b_1Â²} > 0 $$

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨è¿™ç§æ–¹æ³•æ¥æ¨å¯¼çº¿æ€§å›å½’çš„è§£ã€‚

## çº¿æ€§å›å½’è®­ç»ƒ

å¯¹äºæœ€å°äºŒä¹˜æ³•ï¼ˆL2ï¼‰èŒƒæ•°ï¼Œçº¿æ€§å›å½’æ¨¡å‹å‚æ•°å¯ä»¥ä½¿ç”¨å…·æœ‰è§£æè§£çš„è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒã€‚è®©æˆ‘ä»¬æ¨å¯¼å‡ºå…·æœ‰ 1 ä¸ªé¢„æµ‹ç‰¹å¾æƒ…å†µçš„çº¿æ€§å›å½’è§£æè§£ã€‚

ä¸ºäº†è®¡ç®—æ–œç‡ç³»æ•° $b_1$ï¼Œæˆ‘ä»¬ä»æŸå¤±å‡½æ•°å¼€å§‹ï¼Œ

$$ RSS = \sum_{i=1}^n \left(y_i - \left( b_{1} x_{i} + b_0 \right) \right)Â² = \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² $$

ç°åœ¨æˆ‘ä»¬å¯¹æ¨¡å‹å‚æ•° $b_1$ æ±‚åå¯¼æ•°ï¼Œ

$$ \frac{\partial}{\partial b_1} \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² = \sum_{i=1}^n -2 \cdot x_i \left(y_i - b_0 -b_1 x_i \right) $$

ä¸ºäº†ä¼˜åŒ–ï¼Œæœ€å°åŒ–æŸå¤±ï¼Œæˆ‘ä»¬å°†å…³äºæ¨¡å‹å‚æ•° $b_1$ çš„åå¯¼æ•°è®¾ä¸º 0.0ã€‚

$$ 0 = \sum_{i=1}^n -2 \cdot x_i \left(y_i - b_0 -b_1 x_i \right) $$

æˆ‘ä»¬å¯ä»¥ç®€åŒ–ï¼ˆä¸¤è¾¹éƒ½é™¤ä»¥ -2ï¼‰å¹¶åˆ†é…ä¹˜æ³•æ¥å¾—åˆ°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - b_0 \cdot x_i -b_1 x_iÂ² $$

ç°åœ¨æˆ‘ä»¬å¯ä»¥ä»£å…¥ $b_0 = \overline{y} - b_1 \cdot \overline{x}$,

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \left(\overline{y} - b_1 \cdot \overline{x} \right) \cdot x_i - b_1 x_iÂ² $$

å†æ¬¡ä¹˜ä»¥å¾—åˆ°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i + b_1 \cdot \overline{x} \cdot x_i - b_1 x_iÂ² $$

æˆ‘ä»¬å°†æ±‚å’Œåˆ†å¼€ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i + \sum_{i=1}^n b_1 \cdot \overline{x} \cdot x_i - b_1 x_iÂ² $$

å¹¶å¯ä»¥æå– $b_1$ å¸¸æ•°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i + b_1 \sum_{i=1}^n \overline{x} \cdot x_i - x_iÂ² $$

å¹¶ç¨ä½œæ’åºä»¥å¾—åˆ°ï¼Œ

$$ 0 = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i - b_1 \sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i $$

ç§»åˆ°å¦ä¸€è¾¹ï¼Œ

$$ b_1 \sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i = \sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i $$

å¹¶å°†ä¸¤è¾¹éƒ½é™¤ä»¥ $\sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i$,

$$ b_1 = \frac{\sum_{i=1}^n x_i \cdot y_i - \overline{y} \cdot x_i}{\sum_{i=1}^n x_iÂ² - \overline{x} \cdot x_i} $$

æˆ‘ä»¬ç°åœ¨æœ‰äº†çº¿æ€§å›å½’ä¸­ $b_1$ æ–œç‡é¡¹çš„è§£æè§£ã€‚å¯ä»¥è¯æ˜è¿™ç­‰ä»·äºå¦ä¸€ç§å½¢å¼ï¼Œ

$$ b_1 = \frac{\sum_{i=1}^n \left( x_i - \overline{x} \right) \cdot \left( y_i - \overline{y} \right)}{\sum_{i=1}^n \left( x_i - \overline{x} \right)Â²} $$

æˆ‘æ›´å–œæ¬¢è¿™ç§å½¢å¼ï¼Œå› ä¸ºå®ƒå¯ä»¥å¾ˆå®¹æ˜“åœ°è§£é‡Šä¸º $X$ å’Œ $Y$ çš„åæ–¹å·®ï¼Œ$C_{x,y}$ é™¤ä»¥ $X$ çš„æ–¹å·®ï¼Œ$\sigma_{x}Â²$ã€‚

ç°åœ¨å¯¹äºæˆªè·é¡¹ $b_0$ çš„è®¡ç®—ï¼Œæˆ‘ä»¬å›åˆ°æŸå¤±å‡½æ•°ï¼Œ

$$ RSS = \sum_{i=1}^n \left(y_i - \left( b_{1} x_{i} + b_0 \right) \right)Â² = \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² $$

è¿™æ¬¡æˆ‘ä»¬å¯¹ $b_0$ æ±‚åå¯¼æ•°ï¼Œ

$$ \frac{\partial}{\partial b_0} \sum_{i=1}^n \left(y_i - b_{1} x_{i} - b_0 \right)Â² = \sum_{i=1}^n -2 \left(y_i - b_0 -b_1 x_i \right) $$

ä¸ºäº†ä¼˜åŒ–ï¼Œæœ€å°åŒ–æŸå¤±ï¼Œæˆ‘ä»¬å°†æ¨¡å‹å‚æ•° $b_0$ çš„åå¯¼æ•°è®¾ä¸º 0.0ã€‚

$$ 0 = \sum_{i=1}^n -2 \left(y_i - b_0 -b_1 x_i \right) $$

æˆ‘ä»¬å°†ä¸¤è¾¹éƒ½é™¤ä»¥ -2ï¼Œ

$$ 0 = \sum_{i=1}^n y_i - b_0 -b_1 x_i $$

å¹¶æ‹†åˆ†æ±‚å’Œï¼Œ

$$ 0 = \sum_{i=1}^n y_i - \sum_{i=1}^n b_0 - \sum_{i=1}^n b_1 x_i $$

ç®€åŒ–ç®€å•é¡¹ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œ$\sum_{i=1}^n b_0 = n \cdot b_0$,

$$ 0 = \sum_{i=1}^n y_i - n \cdot b_0 - \sum_{i=1}^n b_1 x_i $$

ç°åœ¨å°† $b_0$ é¡¹ç§»åˆ°å·¦è¾¹ï¼Œ

$$ n \cdot b_0 = \sum_{i=1}^n y_i - \sum_{i=1}^n b_1 x_i $$

ä»æ±‚å’Œä¸­æå–å¸¸æ•° $b_1$ï¼Œ

$$ n \cdot b_0 = \sum_{i=1}^n y_i - b_1 \sum_{i=1}^n x_i $$

ä¸¤è¾¹éƒ½é™¤ä»¥ $n$ï¼Œ

$$ b_0 = \frac{\sum_{i=1}^n y_i}{n} - b_1 \frac{\sum_{i=1}^n x_i}{n} $$

è¿™éå¸¸æœ‰è¶£ï¼Œæˆ‘ä»¬ç°åœ¨çœ‹åˆ°äº†ä¸¤ä¸ªç®—æœ¯å¹³å‡å€¼ï¼

$$ \frac{\sum_{i=1}^n y_i}{n} = \overline{y} \quad \quad \frac{\sum_{i=1}^n x_i}{n} = \overline{x} $$

å› æ­¤ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå¾ˆç®€å•ï¼Œ

$$ b_0 = \overline{y} - b_1 \cdot \overline{x} $$

## æ£€æŸ¥æ¨¡å‹

å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬æœ‰å¼ºå¤§çš„æŒ‡æ ‡æ¥æ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå³ç¡®å®šç³»æ•°ï¼Œä¹Ÿç§°ä¸ºâ€œr-squaredâ€ï¼Œ$rÂ²$ã€‚

+   æ¨¡å‹è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹

+   è®¡ç®—ä¸ºè§£é‡Šæ–¹å·® $SS_{reg}$ é™¤ä»¥æ€»æ–¹å·® $SS_{tot}$ï¼Œ

$$ SS_{reg} = \sum_{i=1}^n \left(\hat{y}_i - \overline{y} \right)Â² \quad \quad SS_{tot} = \sum_{i=1}^n \left(y_i - \overline{y} \right)Â² $$

å…¶ä¸­ $\hat{y}_i$ æ˜¯ç¬¬ $i$ ä¸ªè®­ç»ƒæ•°æ®çš„æ¨¡å‹é¢„æµ‹ï¼Œ$\overline{y}$ æ˜¯æ ·æœ¬æ•°æ®çš„å¹³å‡å€¼ã€‚

+   $rÂ²$ å¯ä»¥ä»ç›¸å…³ç³»æ•°è®¡ç®—å¾—å‡ºï¼Œå› æ­¤ä½ å¯ä»¥åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰äº†è§£çº¿æ€§å›å½’æ¨¡å‹çš„å¥½åï¼

$$ rÂ² = \left(\rho_{x,y} \right)Â² $$

æ³¨æ„ï¼Œ$rÂ²$åªèƒ½ç”¨äºçº¿æ€§æ¨¡å‹ï¼Œ

$$ \sigmaÂ²_{tot} = \sigmaÂ²_{reg} + \sigmaÂ²_{res} $$

å…¶ä¸­ $\sigmaÂ²_{tot}$ æ˜¯å“åº”ç‰¹å¾çš„æ€»æ–¹å·®ï¼Œ$\sigmaÂ²_{reg}$ æ˜¯æ¨¡å‹é¢„æµ‹çš„æ–¹å·®ï¼Œ$\sigmaÂ²_{res}$ æ˜¯è¯¯å·®çš„æ–¹å·®ï¼Œå³æ®‹å·®ï¼Œ$\Delta y_i = y_i - \hat{y}_i$ã€‚

å¦‚ä½•è§£é‡Š $rÂ²$ï¼Ÿè®¾å®šç¡¬é˜ˆå€¼æ˜¯å±é™©çš„ï¼Œä½†æˆ‘å¯ä»¥æä¾›ä¸€äº›è½¯æ€§æŒ‡å¯¼ï¼Œ

+   $rÂ² \ge 0.98$ - æ¨¡å‹åœ¨ä½œå¼Šæˆ–è€…é—®é¢˜éå¸¸ç®€å•ï¼Œçº¿æ€§ï¼Œæ— å™ªå£°ä¸”é‡‡æ ·è‰¯å¥½

+   $0.0 \le rÂ² \le 0.6$ - æ¨¡å‹å·¥ä½œå¾—ä¸å¥½ï¼Œæ£€æŸ¥æ•°æ®å’Œæ¨¡å‹é€‰æ‹©

+   $rÂ² \lt 0.0$ - æ¨¡å‹èµ°å‘é”™è¯¯çš„æ–¹å‘ï¼ä½ æœ€å¥½é€šè¿‡å…¨å±€å‡å€¼$\overline{y}$æ¥ä¼°è®¡

## æ¨¡å‹ä¸ç¡®å®šæ€§

ä¸ºäº†ä¼ è¾¾æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œæˆ‘ä»¬ä¾èµ–äºæ¨¡å‹å‚æ•° $b_1$ å’Œ $b_0$ çš„ç½®ä¿¡åŒºé—´ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œè®©æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰ç½®ä¿¡åŒºé—´ï¼Œ

**ç½®ä¿¡åŒºé—´** - ä»¥èŒƒå›´ã€ä¸‹é™å’Œä¸Šé™è¡¨ç¤ºçš„æ€»ç»“ç»Ÿè®¡é‡/æ¨¡å‹/æ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§ï¼ŒåŸºäºæŒ‡å®šçš„æ¦‚ç‡åŒºé—´ï¼Œå³ç½®ä¿¡æ°´å¹³ã€‚

æˆ‘ä»¬è¿™æ ·ä¼ è¾¾ç½®ä¿¡åŒºé—´ï¼š

+   æœ‰ 95%çš„æ¦‚ç‡ï¼ˆæˆ–è€…è¯´ 20 æ¬¡ä¸­çš„ 19 æ¬¡ï¼‰æ¨¡å‹æ–œç‡åœ¨ 0.5 å’Œ 0.7 ä¹‹é—´ã€‚

æˆ‘ä»¬åœ¨è¿™é‡Œä»‹ç»åˆ†ææ–¹æ³•ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨æ›´çµæ´»çš„ Bootstrap æ–¹æ³•ã€‚

è¿™é‡Œå°±è¶³å¤Ÿäº†ï¼Œè®©æˆ‘ä»¬åŠ è½½æ•°æ®ï¼Œå¹¶åœ¨æ¼”ç¤ºçº¿æ€§å›å½’æ—¶è¿›ä¸€æ­¥è§£é‡Šã€‚

## åŠ è½½æ‰€éœ€çš„åº“

æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›æ ‡å‡†åŒ…ã€‚è¿™äº›åº”è¯¥å·²ç»éšç€ Anaconda 3 ä¸€èµ·å®‰è£…äº†ã€‚

```py
suppress_warnings = False                                     # select to suppress warnings
import os                                                     # to set current working directory 
import math                                                   # square root
import numpy as np                                            # arrays and matrix math
import scipy.stats as st                                      # statistical methods
import pandas as pd                                           # DataFrames
import matplotlib.pyplot as plt                               # for plotting
from matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks
from sklearn.preprocessing import MinMaxScaler                # min/max normalization
from sklearn.linear_model import LinearRegression             # linear regression
from sklearn.model_selection import train_test_split          # train and test split
cmap = plt.cm.inferno                                         # default color bar, no bias and friendly for color vision defeciency
plt.rc('axes', axisbelow=True)                                # grid behind plotting elements
if suppress_warnings == True:  
    import warnings                                           # suppress any warnings for this demonstration
    warnings.filterwarnings('ignore') 
```

å¦‚æœä½ é‡åˆ°åŒ…å¯¼å…¥é”™è¯¯ï¼Œä½ å¯èƒ½éœ€è¦é¦–å…ˆå®‰è£…è¿™äº›åŒ…ä¸­çš„æŸäº›ã€‚è¿™é€šå¸¸å¯ä»¥é€šè¿‡åœ¨ Windows ä¸Šæ‰“å¼€å‘½ä»¤çª—å£ç„¶åè¾“å…¥â€˜python -m pip install [package-name]â€™æ¥å®Œæˆã€‚æ›´å¤šå¸®åŠ©å¯ä»¥åœ¨ç›¸åº”çš„åŒ…æ–‡æ¡£ä¸­æ‰¾åˆ°ã€‚

## å£°æ˜å‡½æ•°

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥ç®€åŒ–å‘æˆ‘ä»¬çš„å›¾è¡¨æ·»åŠ æŒ‡å®šçš„ç™¾åˆ†ä½æ•°å’Œä¸»æ¬¡ç½‘æ ¼çº¿ã€‚

```py
def weighted_percentile(data, weights, perc):                 # calculate weighted percentile, iambr on StackOverflow 
    ix = np.argsort(data)                                     # https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049
    data = data[ix] 
    weights = weights[ix] 
    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) 
    return np.interp(perc, cdf, data)

def histogram_bounds(values,weights,color):                   # add uncertainty bounds to a histogram 
    p10 = weighted_percentile(values,weights,0.1); avg = np.average(values,weights=weights); p90 = weighted_percentile(values,weights,0.9)
    plt.plot([p10,p10],[0.0,45],color = color,linestyle='dashed')
    plt.plot([avg,avg],[0.0,45],color = color)
    plt.plot([p90,p90],[0.0,45],color = color,linestyle='dashed')

def add_grid():
    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids
    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)
    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks 
```

## è®¾ç½®å·¥ä½œç›®å½•

æˆ‘æ€»æ˜¯å–œæ¬¢è¿™æ ·åšï¼Œè¿™æ ·æˆ‘å°±ä¸ä¼šä¸¢å¤±æ–‡ä»¶ï¼Œå¹¶ä¸”å¯ä»¥ç®€åŒ–åç»­çš„è¯»å–å’Œå†™å…¥ï¼ˆé¿å…æ¯æ¬¡éƒ½åŒ…å«å®Œæ•´çš„åœ°å€ï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·ç¡®ä¿å°†æ‰€éœ€çš„æ•°æ®æ–‡ä»¶ï¼ˆè§ä¸‹æ–‡ï¼‰æ”¾ç½®åœ¨æ­¤å·¥ä½œç›®å½•ä¸­ã€‚

```py
#os.chdir("C:\PGE337")                                        # set the working directory 
```

æ‚¨éœ€è¦å°†å¼•å·å†…çš„éƒ¨åˆ†æ›´æ–°ä¸ºæ‚¨è‡ªå·±çš„å·¥ä½œç›®å½•ï¼Œåœ¨ Mac ä¸Šæ ¼å¼ä¸åŒï¼ˆä¾‹å¦‚ï¼šâ€œ~/PGEâ€ï¼‰ã€‚

## åŠ è½½è¡¨æ ¼æ•°æ®

è¿™æ˜¯å°†æˆ‘ä»¬çš„é€—å·åˆ†éš”æ•°æ®æ–‡ä»¶åŠ è½½åˆ° Pandas DataFrame å¯¹è±¡ä¸­çš„å‘½ä»¤ã€‚

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€ç©ºé—´æ•°æ®é›†â€˜unconv_MV.csvâ€™ã€‚æ­¤æ•°æ®é›†åŒ…å«æ¥è‡ª 1,000 ä¸ªéå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   å¯†åº¦ï¼ˆ$g/cm^{3}$ï¼‰

+   å­”éš™ç‡ï¼ˆä½“ç§¯%ï¼‰

æ³¨æ„ï¼Œæ•°æ®é›†æ˜¯åˆæˆçš„ã€‚

æˆ‘ä»¬ä½¿ç”¨ pandas çš„â€˜read_csvâ€™å‡½æ•°å°†å…¶åŠ è½½åˆ°åä¸ºâ€˜my_dataâ€™çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚

```py
add_error = False                                             # add random error to the response feature for testing
std_error = 1.0; seed = 71071

yname = 'Porosity'; xname = 'Density'                         # specify the predictor features (x2) and response feature (x1)
xmin = 1.0; xmax = 2.5                                        # set minimums and maximums for visualization 
ymin = 0.0; ymax = 25.0    
yunit = '%'; xunit = '$g/cm^{3}$'    
Xlabelunit = xname + ' (' + xunit + ')'
ylabelunit = yname + ' (' + yunit + ')'

#df = pd.read_csv("Density_Por_data.csv")                     # load the data from local current directory
df = pd.read_csv(r"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/Density_Por_data.csv") # load the data from my github repo
df = df.sample(frac=.30, random_state = 73073); df = df.reset_index() # extract 30% random to reduce the number of data

if add_error == True:                                         # method to add error
    np.random.seed(seed=seed)                                 # set random number seed
    df[yname] = df[yname] + np.random.normal(loc = 0.0,scale=std_error,size=len(df)) # add noise
    values = df._get_numeric_data(); values[values < 0] = 0   # set negative to 0 in a shallow copy ndarray

dfy = pd.DataFrame(df[yname])                                 # extract selected features as X and y DataFrames
dfx = pd.DataFrame(df[xname])
df = pd.concat([dfx,dfy],axis=1)                              # make one DataFrame with both X and y (remove all other features)

y = df[yname].values.reshape(len(df))
x = df[xname].values.reshape(len(df))
dX = np.linspace(xmin,xmax,100)                               # values for plotting the model 
```

```py
df 
```

|  | å¯†åº¦ | å­”éš™ç‡ |
| --- | --- | --- |
| 0 | 1.906634 | 12.845691 |
| 1 | 1.404932 | 13.668073 |
| 2 | 1.795190 | 11.015021 |
| 3 | 1.705466 | 17.185360 |
| 4 | 1.821963 | 8.190405 |
| 5 | 1.708322 | 10.728462 |
| 6 | 1.897087 | 11.245838 |
| 7 | 1.864561 | 11.357547 |
| 8 | 2.119652 | 8.614564 |
| 9 | 1.301057 | 15.280571 |
| 10 | 1.774021 | 9.489298 |
| 11 | 1.410996 | 14.371990 |
| 12 | 1.697005 | 10.495092 |
| 13 | 0.996736 | 20.964941 |
| 14 | 1.783736 | 13.393518 |
| 15 | 1.743519 | 14.758068 |
| 16 | 1.348847 | 15.877907 |
| 17 | 2.331653 | 4.968240 |
| 18 | 1.438900 | 16.529857 |
| 19 | 1.766823 | 10.485052 |
| 20 | 1.802992 | 10.120258 |
| 21 | 1.750352 | 11.325941 |
| 22 | 1.885087 | 9.242607 |
| 23 | 2.044451 | 8.936061 |
| 24 | 1.778580 | 11.426343 |
| 25 | 1.552689 | 14.157303 |
| 26 | 2.022877 | 10.672887 |
| 27 | 1.530699 | 16.476751 |
| 28 | 1.753578 | 10.826057 |
| 29 | 1.791432 | 14.506748 |
| 30 | 1.830085 | 10.561222 |
| 31 | 1.479878 | 14.443138 |

## å¯è§†åŒ– DataFrame

å¯è§†åŒ– DataFrame æ˜¯æ£€æŸ¥æ•°æ®çš„ç¬¬ä¸€æ­¥ã€‚

+   è®¸å¤šäº‹æƒ…å¯èƒ½ä¼šå‡ºé”™ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬åŠ è½½äº†é”™è¯¯çš„æ•°æ®ï¼Œæ‰€æœ‰ç‰¹å¾éƒ½æ²¡æœ‰åŠ è½½ç­‰ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨â€˜headâ€™ DataFrame æˆå‘˜å‡½æ•°æ¥é¢„è§ˆï¼ˆæ ¼å¼æ•´æ´ï¼Œè§ä¸‹æ–‡ï¼‰ã€‚

+   æ·»åŠ å‚æ•°â€˜n=13â€™ä»¥æŸ¥çœ‹æ•°æ®é›†çš„å‰ 13 è¡Œã€‚

```py
df.head(n=13)                                                 # we could also use this command for a table preview 
```

|  | å¯†åº¦ | å­”éš™ç‡ |
| --- | --- | --- |
| 0 | 1.906634 | 12.845691 |
| 1 | 1.404932 | 13.668073 |
| 2 | 1.795190 | 11.015021 |
| 3 | 1.705466 | 17.185360 |
| 4 | 1.821963 | 8.190405 |
| 5 | 1.708322 | 10.728462 |
| 6 | 1.897087 | 11.245838 |
| 7 | 1.864561 | 11.357547 |
| 8 | 2.119652 | 8.614564 |
| 9 | 1.301057 | 15.280571 |
| 10 | 1.774021 | 9.489298 |
| 11 | 1.410996 | 14.371990 |
| 12 | 1.697005 | 10.495092 |

## è¡¨æ ¼æ•°æ®çš„æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯

åœ¨ DataFrames ä¸­ï¼Œæœ‰è®¸å¤šé«˜æ•ˆçš„æ–¹æ³•å¯ä»¥è®¡ç®—è¡¨æ ¼æ•°æ®çš„æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯ã€‚describe å‘½ä»¤æä¾›äº†è®¡æ•°ã€å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼å’Œå››åˆ†ä½æ•°ï¼Œå…¨éƒ¨åœ¨ä¸€ä¸ªæ•´æ´çš„æ•°æ®è¡¨ä¸­ã€‚

+   æˆ‘ä»¬ä½¿ç”¨è½¬ç½®åªæ˜¯ç¿»è½¬è¡¨æ ¼ï¼Œä»¥ä¾¿ç‰¹å¾åœ¨è¡Œä¸Šï¼Œç»Ÿè®¡ä¿¡æ¯åœ¨åˆ—ä¸Šã€‚

```py
df.describe().transpose()                                     # summary statistics 
```

|  | count | mean | std | min | 25% | 50% | 75% | max |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| å¯†åº¦ | 32.0 | 1.719994 | 0.262314 | 0.996736 | 1.547192 | 1.770422 | 1.838704 | 2.331653 |
| å­”éš™ç‡ | 32.0 | 12.317525 | 3.224611 | 4.968240 | 10.492582 | 11.341744 | 14.459041 | 20.964941 |

## æ•°æ®å¯è§†åŒ–

æˆ‘ä»¬è¿˜åº”è¯¥çœ‹çœ‹ç›´æ–¹å›¾ã€‚

+   è·å¾—æ¯ä¸ªç‰¹å¾çš„å–å€¼èŒƒå›´ã€ä¼—æ•°ã€ååº¦ã€å¼‚å¸¸å€¼ç­‰æ„Ÿè§‰

```py
nbins = 20                                                    # number of histogram bins

plt.subplot(221)
freq,_,_ = plt.hist(x=df[xname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)
histogram_bounds(values=df[xname].values,weights=np.ones(len(df)),color='red')
plt.xlabel(xname + ' (' + xunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Density'); add_grid()  
plt.xlim([xmin,xmax])    

plt.subplot(222)
freq,_,_ = plt.hist(x=df[yname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)
histogram_bounds(values=df[yname].values,weights=np.ones(len(df)),color='red')
plt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Porosity'); add_grid()  
plt.xlim([ymin,ymax])  

plt.subplot(223)                                              # plot the model
plt.scatter(df[xname],df[yname],marker='o',label='data',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10)
plt.title('Porosity vs Density')
plt.xlabel(xname + ' (' + xunit + ')')
plt.ylabel(yname + ' (' + yunit + ')')
plt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])

plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)
#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') 
plt.show() 
```

![_images/98de0f9e6b4fc55ef535855f27875a0c49893f41a34ad00f9df6b7568c083cdf.png](img/a2eda54f1271413aca71673e74f3a116.png)

## çº¿æ€§å›å½’æ¨¡å‹

è®©æˆ‘ä»¬å…ˆä½¿ç”¨ SciPy åŒ…çš„ stats æ¨¡å—è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹åˆ°æ‰€æœ‰æˆ‘ä»¬çš„æ•°æ®ã€‚

+   æˆ‘ä»¬å°†åœ¨åç»­ä½¿ç”¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²æ¥å¼€å‘æ›´å¤æ‚çš„äº¤å‰éªŒè¯è®­ç»ƒå’Œè°ƒæ•´æ–¹æ³•ã€‚ç›®å‰ï¼Œæ‰€æœ‰æ•°æ®éƒ½ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚

+   å›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬ä¸Šé¢å°†æ¨¡å—å¯¼å…¥ä¸ºâ€˜stâ€™

```py
import scipy.stats as st                                    # statistical methods 
```

æˆ‘ä»¬å¯ä»¥åœ¨ä¸€è¡Œä»£ç ä¸­å®ä¾‹åŒ–ã€è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¹¶è·å–æ¨¡å‹è¯Šæ–­ï¼ŒåŒ…æ‹¬ç½®ä¿¡åŒºé—´å’Œå‡è®¾æ£€éªŒã€‚

```py
slope, intercept, r_value, p_value, std_err = st.linregress(x,y) # instantiate and fit a linear regression model

print('The model parameters are, slope (b1) = ' + str(round(slope,2)) + ', and the intercept (b0) = ' + str(round(intercept,2))) 
```

```py
The model parameters are, slope (b1) = -10.3, and the intercept (b0) = 30.03 
```

æ³¨æ„ï¼Œå½“æˆ‘ä»¬å®ä¾‹åŒ–å’Œæ‹Ÿåˆæˆ‘ä»¬çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æœ‰ 5 ä¸ªè¾“å‡ºã€‚

+   **slope** - æˆ‘ä»¬çº¿æ€§æ¨¡å‹çš„æ–œç‡ï¼Œæ¨¡å‹ä¸­çš„ $b_1$ï¼Œ$y = b_1 x + b_0$

+   **intercept** - æˆ‘ä»¬çº¿æ€§æ¨¡å‹çš„æˆªè·ï¼Œæ¨¡å‹ä¸­çš„ $b_0$ï¼Œ$y = b_1 x + b_0$

+   **r_value** - çš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œå¹³æ–¹æ˜¯ $rÂ²$ï¼Œè§£é‡Šçš„æ–¹å·®

+   **p_value** - å¯¹æ¨¡å‹æ–œç‡ä¸ºé›¶çš„å‡è®¾æ£€éªŒçš„ p å€¼

+   **stderr** - æ–œç‡å‚æ•°çš„æ ‡å‡†è¯¯å·®ï¼Œ$SE_{b_1}$

è®©æˆ‘ä»¬ç»˜åˆ¶æ•°æ®å’Œæ¨¡å‹ï¼Œä»¥è·å–æˆ‘ä»¬çš„ä¼°è®¡ï¼Œæˆ‘ä»¬å°†é¢„æµ‹ç‰¹å¾å€¼ä»£å…¥æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```py
x_values = np.linspace(xmin,xmax,100)                         # return an array of density values 
y_model = slope * x_values + intercept                        # apply our linear regression model to estimate at the training data values

plt.subplot(111)                                              # plot the model
plt.plot(x, y, 'o', label='data', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black',zorder=10)
plt.plot(x_values, y_model, label='model', color = 'black',zorder=1)
plt.title('Linear Regression Model, Regression of ' + yname + ' on ' + xname)
plt.xlabel(xname + ' (' + xunit + ')')
plt.ylabel(yname + ' (' + yunit + ')')
plt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])

plt.annotate('Linear Regression Model',[1.25,5.7])
plt.annotate(r'    $\beta_1$ :' + str(round(slope,2)),[1.6,4.1])
plt.annotate(r'    $\beta_0$ :' + str(round(intercept,2)),[1.6,2.5])
plt.annotate(r'$N[\phi] = \beta_1 \times z + \beta_0$',[1.1,4.1])
plt.annotate(r'$N[\phi] = $' + str(round(slope,2)) + r' $\times$ $z$ + (' + str(round(intercept,2)) + ')',[1.1,2.5])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() 
```

![_images/d3fdafa548372646c151694b18b0c75982244b0b0a186248b71ef376c8584bc8.png](img/54afba2518c03ba22364ced82320385f.png)

æ¨¡å‹çœ‹èµ·æ¥æ˜¯åˆç†çš„ã€‚è®©æˆ‘ä»¬è¶…è¶Šç›´è§‚æ£€æŸ¥ã€‚

## ä½¿ç”¨ $rÂ²$ å€¼è¿›è¡Œæ¨¡å‹æ£€æŸ¥

è®©æˆ‘ä»¬å…ˆè§£é‡Šä¸€ä¸‹ $rÂ²$ï¼Œå³è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ã€‚ä»¥ä¸‹æ˜¯æ¨¡å‹è§£é‡Šçš„æ–¹å·®ï¼š

\begin{equation} ğ‘ ğ‘ ğ‘Ÿğ‘’ğ‘” = \sum_{ğ‘–=1}^{ğ‘›}\left(\hat{y}_i - \overline{y}\right)Â² \end{equation}

ä»¥åŠæ¨¡å‹æœªè§£é‡Šçš„æ–¹å·®ï¼Œ

\begin{equation} ğ‘ ğ‘ ğ‘Ÿğ‘’sid = \sum_{ğ‘–=1}^{ğ‘›}\left(y_i - \hat{y}\right)Â² \end{equation}

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è§£é‡Šçš„æ–¹å·®ï¼Œ

\begin{equation} ğ‘ŸÂ² = \frac{ğ‘ ğ‘ _{ğ‘Ÿğ‘’ğ‘”}}{ğ‘ ğ‘ _{ğ‘Ÿğ‘’ğ‘”}+ğ‘ ğ‘ _{ğ‘Ÿğ‘’ğ‘ ğ‘–ğ‘‘}} = \frac{\text{variance explained}}{\text{total variance}} \end{equation}

è¿™æ˜¯ä¸€ç§è¡¡é‡çº¿æ€§å›å½’æ¨¡å‹å¥½åçš„å¸¸è§ä¸”ç›´è§‚çš„æŒ‡æ ‡ã€‚

## ä½¿ç”¨å‡è®¾æ£€éªŒè¿›è¡Œæ¨¡å‹æ£€æŸ¥

è®©æˆ‘ä»¬ç”¨ä»¥ä¸‹å‡è®¾æ£€éªŒæ¥æµ‹è¯•æ–œç‡ï¼Œ$b_1$ï¼Œ

\begin{equation} H_0: b_{1} = 0.0 \end{equation}

\begin{equation} H_1: b_{1} \ne 0.0 \end{equation}

å¹¶çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥æ‹’ç»è¿™ä¸ªå‡è®¾ï¼Œ$H_{0}$ï¼Œå³æ–œç‡å‚æ•°ç­‰äº 0.0ã€‚å¦‚æœæˆ‘ä»¬æ‹’ç»è¿™ä¸ªé›¶å‡è®¾ï¼Œæˆ‘ä»¬è¡¨æ˜æ–œç‡æ˜¯æœ‰æ„ä¹‰çš„ï¼Œå¯†åº¦å’Œå­”éš™ç‡ä¹‹é—´å­˜åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„çº¿æ€§å…³ç³»ã€‚

å¹¸è¿çš„æ˜¯ï¼Œ`stats`åŒ…ä¸­çš„`linregress`å‡½æ•°ä¸ºæˆ‘ä»¬æä¾›äº†è¿™ä¸ªæµ‹è¯•çš„åŒä¾§ p å€¼ã€‚

```py
print('Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = ' + str(p_value) + '.') 
```

```py
Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = 2.2197132981703346e-09. 
```

ç”±äº p å€¼å°äºä»»ä½•åˆç†çš„$\alpha$å€¼ï¼Œæˆ‘ä»¬æ‹’ç»åŸå‡è®¾ï¼Œé‡‡ç”¨å¤‡æ‹©å‡è®¾$H_1$ï¼Œå³æ–œç‡ä¸ç­‰äº 0.0ã€‚

æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡è®¡ç®—ä»¥ä¸‹å†…å®¹æ¥æ‰§è¡Œæ•´ä¸ªå‡è®¾æ£€éªŒï¼Œ

$$ t_{statistic} = \frac{b_1}{SE_{b_1}} $$

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦`t_{critical}`å€¼ï¼Œç»™å®š$\alpha$å’Œ$df = n-2$ã€‚

```py
alpha = 0.05
t_critical = st.t.ppf([alpha/2,1-alpha/2], df=len(x)-2)
print('The t-critical lower and upper values are ' + str(np.round(t_critical,2)))
print('and the t-statistic is ' + str(round(slope/std_err,2))) 
```

```py
The t-critical lower and upper values are [-2.04  2.04]
and the t-statistic is -8.4 
```

æˆ‘ä»¬çœ‹åˆ°ä¸ä¹‹å‰çš„å‡è®¾æ£€éªŒå…·æœ‰ä¸€è‡´çš„ç»“æœï¼Œå› ä¸º$t_{statistic}$ä½äº`t_{critical}`çš„ä¸Šä¸‹åŒºé—´ä¹‹å¤–ï¼Œæˆ‘ä»¬æ‹’ç»åŸå‡è®¾$h_0$ï¼Œå³æ–œç‡$b_1$ç­‰äº 0.0ã€‚

æˆ‘ä»¬è¿˜å¯ä»¥è§‚å¯Ÿåˆ°ç›¸å…³ç³»æ•°$r$å€¼å’Œ$rÂ²$å€¼ï¼Œè¿™è¡¨ç¤ºæ¨¡å‹æè¿°çš„æ–¹å·®æ¯”ä¾‹ã€‚

```py
print('The correlation coefficient is = ' + str(round(r_value,2)) + ' and the r-squared value = ', str(round(r_value**2,2))) 
```

```py
The correlation coefficient is = -0.84 and the r-squared value =  0.7 
```

## æ¨¡å‹ä¸ç¡®å®šæ€§çš„ç½®ä¿¡åŒºé—´

è®©æˆ‘ä»¬è®¡ç®—æ¨¡å‹æ–œç‡å‚æ•°$b_1$çš„ 95%ç½®ä¿¡åŒºé—´ã€‚æˆ‘ä»¬åªéœ€è¦æˆ‘ä»¬çš„`t_{critical}`å’Œæ–œç‡çš„æ ‡å‡†è¯¯å·®$SE_{b_1}$ã€‚

```py
print('The slope confidence interval is ' + str(round(slope,2)) + ' +/- ' + str(round(t_critical[1] * std_err,2)))
CI_slope = slope + t_critical*std_err
print('The slope P02.5 and P97.5 are ' + str(np.round(CI_slope,2))) 
```

```py
The slope confidence interval is -10.3 +/- 2.5
The slope P02.5 and P97.5 are [-12.8  -7.8] 
```

è®©æˆ‘ä»¬é€šè¿‡æ–œç‡çš„ç½®ä¿¡åŒºé—´æ¥å¯è§†åŒ–æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚

```py
alpha = 0.05
tstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)            # calculate t-stat for confidence interval
slope_lower,slope_upper = slope + tstat*std_err # calculate the lower and upper confidence interval for b1

plt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=10)
plt.plot(dX, intercept + slope*dX, 'black', label='linear regression model')
plt.plot(dX, intercept + slope_upper*dX, 'black',ls='--',lw=1,label=r'alpha = ' + str(alpha) + ' confidence interval')
plt.plot(dX, intercept + slope_lower*dX, 'black',ls='--',lw=1)
plt.annotate('The model parameters confidence intervals at ' + str(1-alpha) + ' significance level:',[1.3,24])
plt.annotate('Slope: P' + str(alpha/2*100) + ' = '+ str(round(slope_lower,2)) + ' , P' + str((1-alpha/2)*100) + ' = ' + str(round(slope_upper,2)),[1.5,23])
plt.fill_between(dX,intercept + slope_upper*dX,intercept + slope_lower*dX,color='red',alpha=0.3,zorder=1)
plt.title('Sample Data, Linear Regression Model and Slope Confidence Intervals'); plt.xlabel(r'Density ($g/cmÂ³$)'); plt.ylabel('Porosity (%)')
plt.legend(loc='lower left'); add_grid(); plt.ylim([ymin,ymax]); plt.xlim([xmin,xmax])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.1, hspace=0.2); plt.show() 
```

![_images/0bbbe3bf373fd68d3772e3c17b50ebbc962bfa52dfe9696bbbcf88f2260be693.png](img/d1ca1ce80b88510090621b7b2f30e375.png)

## æ¨¡å‹é¢„æµ‹åŒºé—´

è®©æˆ‘ä»¬è®¡ç®—é¢„æµ‹åŒºé—´ã€‚

\begin{equation} \hat{y}*{n+1} Â± t*{(\frac{\alpha}{2},n-2)} \sqrt{MSE}\ \times \sqrt{1+\frac{1}{n}+\frac{(x_{n+1}-\overline{x})Â²}{\sum_{i=1}^{n}(x_{i}-\overline{x})Â²} } \end{equation}

æ³¨æ„ï¼Œè¿™æ˜¯é¢„æµ‹çš„æ ‡å‡†è¯¯å·®ï¼Œ

\begin{equation} SE_{\hat{y}*{n+1}} = \sqrt{MSE}\ \times \sqrt{1+\frac{1}{n}+\frac{(x*{n+1}-\overline{x})Â²}{\sum_{i=1}^{n}(x_{i}-\overline{x})Â²} } \end{equation}

å…¶ä¸­ MSEï¼Œæ¨¡å‹å‡æ–¹è¯¯å·®ï¼Œè®¡ç®—å¦‚ä¸‹ï¼Œ

\begin{equation} MSE = \sum_{i=1}^n\frac{(y_i - \hat{y}*i)Â²}{n-2} = \sum*{i=1}^n \frac{\left(y_i - (b_1 x - b_0) \right)Â²}{n-2} \end{equation}

æ³¨æ„ï¼Œè¿™è¡¨æ˜é¢„æµ‹åŒºé—´éšç€æˆ‘ä»¬ç¦»é¢„æµ‹ç‰¹å¾å€¼å‡å€¼çš„ä¼°è®¡è¶Šæ¥è¶Šè¿œè€Œå˜å®½ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ¨¡å‹ MSEã€MSE å’Œä¼°è®¡çš„æ ‡å‡†è¯¯å·®$SE_{\hat{y}_{n+1}}$æ›¿æ¢æœ€ç»ˆå½¢å¼ï¼Œ

\begin{equation} \hat{y}*{n+1} Â± t*{(\frac{\alpha}{2},n-2)} \sqrt{\sum_{i=1}^n \frac{\left(y_i - (b_1 x - b_0) \right)Â²}{n-2}}\sqrt{1+\frac{1}{n}+\frac{(x_{n+1}-\overline{x})Â²}{\sum_{i=1}^{n}(x_{i}-\overline{x})Â²} } \end{equation}

ç°åœ¨è®©æˆ‘ä»¬æ¼”ç¤ºä¸€ä¸ªé¢„æµ‹åŒºé—´ã€‚

+   é€‰æ‹©ä¸€ä¸ª X å€¼ï¼Œä»¥ä¸‹çš„æ–° _X ä½œä¸ºè¾“å…¥ï¼Œä»¥åŠé¢„æµ‹åŒºé—´çš„ alpha æ°´å¹³ï¼Œå³ alpha = 0.05 ä¼šå¯¼è‡´ P025 å’Œ P975 ç»“æœæ¥å®šä¹‰åŒºé—´

```py
new_X = 2.00
alpha = 0.05

tstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)

yhat = intercept + slope*x
MSE = np.sum(np.power(y-yhat,2))/(len(y)-2) # mean square error
est_stderr = math.sqrt(MSE) \
      *math.sqrt(1 + 1/len(y) + np.power(new_X - np.average(x),2)/ \
      np.sum(np.power(x-np.average(x),2)))

y_pred_lower, y_pred_upper = intercept + slope*new_X + tstat*est_stderr

plt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=1)
plt.plot(dX, intercept + slope*dX, 'black', label='linear regression model',zorder=1)
plt.scatter(new_X, intercept + slope*new_X,s=80,color='yellow',edgecolor='black',label=r'prediction, $\hat{y}$',zorder=2)
plt.plot([new_X,new_X],[y_pred_lower,y_pred_upper],color='black',linestyle='dashed',zorder=1,label='prediction interval')
plt.title(r'Sample Data, Linear Regression Model and Prediction Interval, $\alpha = $' + str(alpha)); plt.xlabel(r'Density ($g/cmÂ³$)'); 
plt.ylabel('Porosity (%)')
plt.legend(); add_grid(); plt.ylim([4,22]); plt.xlim([1.0,2.4])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.4, wspace=0.1, hspace=0.2); plt.show() 
```

![_images/5a6dd7728637e0e475487e0a80b773a4446a401a945fb86809c1c1febb8c575d.png](img/19bd5fc3ca00501a930e17fc3ebb1e40.png)

## é¢„æµ‹

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ¨¡å‹åœ¨æ‰€æœ‰æ•°æ®ä½ç½®è¿›è¡Œé¢„æµ‹ã€‚

```py
y_hat = slope * x + intercept
plt.subplot(111)
plt.hist(y_hat, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(5,20,40))
plt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.title(yname + ' Predictions'); plt.xlim([ymin,ymax])
add_grid()
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() 
```

![å›¾ç‰‡](img/cfe742ca2d1f207ffbe6602e9f0b93b2.png)

## æ£€æŸ¥é¢„æµ‹è¯¯å·®

å°†å­”éš™ç‡çš„é¢„æµ‹å€¼ä¸è®­ç»ƒå­”éš™ç‡ä¸å¯†åº¦æ•£ç‚¹å›¾ç»˜åˆ¶åœ¨ä¸€èµ·æ˜¯æœ‰ç”¨çš„ã€‚

+   ä»è¿™ä¸ªå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°æˆ‘ä»¬æ¨¡å‹çš„çº¿æ€§é™åˆ¶

+   å¹¶äº†è§£æœªè§£é‡Šçš„æ–¹å·® $\frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)Â²} {n-1}$

```py
plt.subplot(111)
plt.plot(x, y, 'o', label='training data',color = 'darkorange', alpha = 1.0, markeredgecolor = 'black',zorder=10)
plt.scatter(x, y_hat,s=10,marker='o',label='prediction',color = 'grey',edgecolor='black',alpha=1.0,zorder=10)
plt.plot(dX,dX*slope+intercept,color='red',lw=2,zorder=2,label='model')
for idata in range(0,len(x)):
    if idata == 0:
        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey',label=r'$\Delta_{y_i}$',zorder=1)
    else:  
        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey')
plt.title('Comparison of Training Data vs. Model')
plt.xlabel(xname + ' (' + xunit + ')')
plt.ylabel(yname + ' (' + yunit + ')')
plt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() 
```

![å›¾ç‰‡](img/bf66aa77a321545828b548c07857ba83.png)

çœ‹çœ‹ç»˜åˆ¶çš„è¯¯å·®æ®‹å·®ï¼Œ

$$ \Delta y_i = y_i - \hat{y}_i $$

å…¶ä¸­ $y_i$ æ˜¯çœŸå®å“åº”å€¼ï¼Œ$\hat{y}_i$ æ˜¯ä¼°è®¡çš„å“åº”å€¼ã€‚

æ£€æŸ¥è¯¯å·®æ®‹å·®åˆ†å¸ƒæ˜¯å¾ˆæœ‰ç”¨çš„ï¼Œ

+   å¹³å‡å€¼æ¥è¿‘ 0.0

+   å½¢çŠ¶æ²¡æœ‰åæ–œ

+   æ²¡æœ‰å¼‚å¸¸å€¼

è®©æˆ‘ä»¬çœ‹çœ‹è¯¯å·®æ®‹å·®åˆ†å¸ƒã€‚

```py
residual = y - y_hat

plt.subplot(111)
plt.hist(residual, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(-4,4,30))
plt.title("Error Residual at Training Data"); plt.xlabel(yname + ' True - Estimate (%)');plt.ylabel('Frequency'); add_grid()
plt.vlines(0,0,4.2,color='red',lw=2,zorder=1); plt.vlines(np.average(residual),0,4.2,color='black',ls='--',zorder=10); plt.ylim([0,4.2])
plt.annotate('Residual Average = ' + str(np.round(np.average(residual),2)),[np.average(residual)-0.2,2.5],rotation=90.0)
plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show()

print('The average of the residuals is ' + str(round(np.mean(residual),2))) 
```

![å›¾ç‰‡](img/3b7dc57b47ae0c681e96fc44088f5a7b.png)

```py
The average of the residuals is 0.0 
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥çœŸå®å€¼ä¸ä¼°è®¡å€¼çš„æ•£ç‚¹å›¾ï¼Œä»¥åŠäº¤å‰éªŒè¯æ®‹å·®å›¾ï¼Œæ®‹å·®ä¸æ‹Ÿåˆå€¼çš„å…³ç³»ã€‚

+   é€šè¿‡è¿™äº›å›¾ï¼Œæˆ‘ä»¬æ£€æŸ¥è¯¯å·®æ˜¯å¦åœ¨æ‹Ÿåˆå€¼èŒƒå›´å†…ä¸€è‡´

+   ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªå›¾æ¥è¯†åˆ«ç‰¹å®šæ‹Ÿåˆå€¼èŒƒå›´å†…çš„æ›´é«˜è¯¯å·®æˆ–ç³»ç»Ÿæ€§çš„é«˜ä¼°æˆ–ä½ä¼°

```py
slope_cross, intercept_cross, _, _, _ = st.linregress(y_hat,y) # check for conditional bias with a linear fit to the cross validation plot

plt.subplot(121)
plt.plot(y_hat, y, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')
plt.plot([ymin,ymax], [ymin,ymax], 'black',lw=2.0)
plt.plot(np.linspace(ymin,ymax,100), slope_cross*np.linspace(ymin,ymax,100)+intercept_cross, 
         alpha = 0.8, color = 'red',ls='--',lw=1.0)
plt.title('Cross Validation Plot: Truth vs. Estimated Value')
plt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Truth (%)'); add_grid(); plt.xlim([ymin,ymax]); plt.ylim([ymin,ymax])

plt.subplot(122)
plt.plot(y_hat, residual, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')
plt.plot([ymin,ymax], [0,0], 'black')
plt.title('Cross Validation Residual Plot: Residual vs. Estimated Value')
plt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Residual: True - Estimate (%)'); add_grid()
plt.xlim([ymin,ymax]); plt.ylim([-10,10])

plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() 
```

![å›¾ç‰‡](img/eb662574297fc05b3c1cced939dbb806.png)

å¯¹äºæ¼”ç¤ºæ¡ˆä¾‹ï¼Œä¼°è®¡å€¼åœ¨å€¼èŒƒå›´å†…çš„æ¡ä»¶åå·®ä¸æ˜æ˜¾ã€‚

## åœ¨æ–°æ•°æ®é›†ä¸Šå®è·µ

å¥½çš„ï¼Œæ˜¯æ—¶å€™å¼€å§‹å·¥ä½œäº†ã€‚è®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªæ•°æ®é›†å¹¶ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ„å»ºçº¿æ€§å›å½’æ¨¡å‹ï¼Œ

+   ç´§å‡‘çš„ä»£ç 

+   åŸºæœ¬å¯è§†åŒ–

+   ä¿å­˜è¾“å‡º

æ‚¨å¯ä»¥é€‰æ‹©è¿™äº›æ•°æ®é›†ä¹‹ä¸€æˆ–ä¿®æ”¹ä»£ç å¹¶æ·»åŠ æ‚¨è‡ªå·±çš„æ•°æ®é›†æ¥å®Œæˆæ­¤æ“ä½œã€‚

### æ•°æ®é›† 0ï¼Œéå¸¸è§„å¤šå…ƒ v4

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒæ•°æ®é›† [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª 1000 å£éå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   äº•å¹³å‡å­”éš™ç‡

+   æ¸—é€ç‡çš„å¯¹æ•°å˜æ¢ï¼ˆä»¥çº¿æ€§åŒ–ä¸å…¶ä»–å˜é‡çš„å…³ç³»ï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/mÂ³ x m/s x 10â¶ï¼‰

+   å²©æ€§æ¯”ï¼ˆ%ï¼‰

+   æ€»æœ‰æœºç¢³ï¼ˆ%ï¼‰

+   ç»ç’ƒè´¨åå°„ç‡ï¼ˆ%ï¼‰

+   åˆå§‹ç”Ÿäº§ 90 å¤©å¹³å‡ï¼ˆMCFPDï¼‰ã€‚

### æ•°æ®é›† 1ï¼ŒåäºŒï¼Œ12

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒï¼ŒäºŒç»´ç©ºé—´æ•°æ®é›† [12_sample_data.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/12_sample_data.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª 480 å£éå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   X (m), Y (m) ä½ç½®åæ ‡

+   å²©æ€§ï¼ˆ0 - é¡µå²©ï¼Œ1 - ç ‚å²©ï¼‰

+   å•ä½è½¬æ¢åçš„å­”éš™ç‡ï¼ˆ%ï¼‰

+   æ¸—é€ç‡ï¼ˆmDï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/mÂ³ x m/s x 10â¶ï¼‰

### æ•°æ®é›† 2ï¼Œå‚¨å±‚ 21

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€3D ç©ºé—´æ•°æ®é›† [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv)ã€‚æ­¤æ•°æ®é›†åŒ…å« 73 ä¸ªå‚ç›´äº•åœ¨ 10,000m x 10,000m x 50 m å‚¨å±‚å•å…ƒçš„å˜é‡ï¼š

+   well (ID)

+   X (m), Y (m), Depth (m) ä½ç½®åæ ‡

+   å•ä½è½¬æ¢åçš„å­”éš™ç‡ (%)

+   æ¸—é€ç‡ (mD)

+   å•ä½è½¬æ¢åçš„å£°é˜»æŠ— (kg/m2s*10â¶)

+   ç›¸ï¼ˆåˆ†ç±»ï¼‰- æœ‰åºï¼Œä»é¡µå²©ã€æ²™è´¨é¡µå²©ã€é¡µå²©ç ‚åˆ°ç ‚å²©ã€‚

+   å¯†åº¦ (g/cmÂ³)

+   å¯å‹ç¼©é€Ÿåº¦ (m/s)

+   æ¨æ°æ¨¡é‡ (GPa)

+   å‰ªåˆ‡é€Ÿåº¦ (m/s)

+   å‰ªåˆ‡æ¨¡é‡ (GPa)

+   3 å¹´ç´¯è®¡çŸ³æ²¹äº§é‡ (Mbbl)

æˆ‘ä»¬ä½¿ç”¨ pandas çš„ â€˜read_csvâ€™ å‡½æ•°å°†è¡¨æ ¼æ•°æ®åŠ è½½åˆ°æˆ‘ä»¬ç§°ä¸º â€˜my_dataâ€™ çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆå®ƒä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚

+   æˆ‘ä»¬è¿˜ç”¨æ•°æ®èŒƒå›´å’Œæ ‡ç­¾å¡«å……åˆ—è¡¨ï¼Œä»¥ä¾¿äºç»˜å›¾

åŠ è½½æ•°æ®å¹¶æ ¼å¼åŒ–ï¼Œ

+   åˆ é™¤å“åº”ç‰¹å¾

+   æ ¹æ®éœ€è¦é‡æ–°æ ¼å¼åŒ–ç‰¹å¾

+   æ­¤å¤–ï¼Œæˆ‘ä¹Ÿå–œæ¬¢å°†å…ƒæ•°æ®å­˜å‚¨åœ¨åˆ—è¡¨ä¸­

```py
idata = 0                                                     # select the dataset

if idata == 0:
    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['Well'],axis=1,inplace=True)                 # remove well index and response feature

    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax_new = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting
    ymin_new = 0.0; ymax_new = 10000.0
    xlabel_new = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10â¶)','Brittleness Ratio (%)', # set the names for plotting
             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']

    ylabel_new = 'Production (MCFPD)'

    xtitle_new = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting
             'Total Organic Carbon','Vitrinite Reflectance']

    ytitle_new = 'Production'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

elif idata == 1:
    names = {'Porosity':'Por'}

    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['X','Y','Unnamed: 0','Facies'],axis=1,inplace=True)   # remove response feature
    df_new = df_new.rename(columns=names)
    df_new['Por'] = df_new['Por'] * 100.0; df_new['AI'] = df_new['AI'] / 1000.0
    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [4.0,0.0]; xmax_new = [19.0,500.0] # set the minimum and maximum values for plotting

    ymin_new = 1.60; ymax_new = 6.20

    xlabel_new = ['Porosity (fraction)','Permeability (mD)'] # set the names for plotting

    ylabel_new = 'Acoustic Impedance (kg/m2s*10â¶)'

    xtitle_new = ['Porosity','Permeability']

    ytitle_new = 'Acoustic Impedance (kg/m2s*10â¶)'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

elif idata == 2:  
    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['Well_ID','X','Y'],axis=1,inplace=True) # remove Well Index, X and Y coordinates, and response feature
    df_new = df_new.dropna(how='any',inplace=False)

    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax_new = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting

    ymin_new = 0.0; ymax_new = 1600.0

    xlabel_new = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10â¶)','Facies (categorical)',
              'Density (g/cmÂ³)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting

    ylabel_new = 'Production (Mbbl)'

    xtitle_new = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',
              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']

    ytitle_new = 'Production'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

df_new.head(n=13) 
```

|  | Por | Perm | AI | Brittle | TOC | VR | Prod |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |
| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |
| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |
| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |
| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |
| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |
| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |
| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |
| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |
| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |
| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |
| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |
| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |

```py
df_select = df_new.loc[:,['Por','Perm','AI']]
df_select 
```

|  | Por | Perm | AI |
| --- | --- | --- | --- |
| 0 | 12.08 | 2.92 | 2.80 |
| 1 | 12.38 | 3.53 | 3.22 |
| 2 | 14.02 | 2.59 | 4.01 |
| 3 | 17.67 | 6.75 | 2.63 |
| 4 | 17.52 | 4.57 | 3.18 |
| ... | ... | ... | ... |
| 195 | 11.95 | 3.13 | 2.97 |
| 196 | 17.99 | 9.87 | 3.38 |
| 197 | 12.12 | 2.27 | 3.52 |
| 198 | 15.55 | 4.48 | 2.48 |
| 199 | 20.89 | 7.54 | 3.23 |

200 è¡Œ Ã— 3 åˆ—

### æ„å»ºå’Œæ£€æŸ¥æ¨¡å‹

```py
test_prop = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_prop, random_state=seed) # train and test split
linear_model_new = LinearRegression().fit(X_train,y_train)    # instantiate and train linear regression model, no hyperparmeters

train_pred = linear_model_new.predict(X_train); test_pred = linear_model_new.predict(X_test) # predict at train and test samples 

plt.scatter(y_train,train_pred,color='green',edgecolor='black',label='Training') # cross validation plot
plt.scatter(y_test,test_pred,color='white',edgecolor='black',label='Testing')
plt.plot([ymin_new,ymax_new],[ymin_new,ymax_new],color='black',zorder=-1)
plt.xlim(ymin_new,ymax_new); plt.ylim(ymin_new,ymax_new); add_grid() 
plt.xlabel('Truth: ' + ylabel_new); plt.ylabel('Estimate: ' + ylabel_new)
plt.title('Linear Model Cross Validation'); plt.legend(loc='upper left')

plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() 
```

![_images/3a7d23260a411f4894d7f9270056b8ff28820241bf7e6859bae42ed471f22fa3.png](img/dcda56f7f818f02921fd7cfe954f1f2a.png)

```py
X_train 
```

|  | Por | Perm | AI | Brittle | TOC | VR |
| --- | --- | --- | --- | --- | --- | --- |
| 16 | 19.55 | 8.41 | 3.08 | 35.49 | 1.34 | 1.95 |
| 15 | 11.34 | 2.72 | 3.43 | 58.03 | 0.57 | 2.15 |
| 179 | 7.22 | 1.42 | 3.60 | 63.09 | -0.03 | 1.67 |
| 109 | 15.19 | 5.05 | 3.11 | 57.97 | 1.15 | 2.16 |
| 134 | 12.83 | 2.69 | 3.67 | 17.20 | 0.61 | 2.01 |
| ... | ... | ... | ... | ... | ... | ... |
| 32 | 12.55 | 3.22 | 3.43 | 56.93 | 0.79 | 2.27 |
| 182 | 9.88 | 2.72 | 3.64 | 55.19 | 0.52 | 2.16 |
| 71 | 14.17 | 3.94 | 2.92 | 59.30 | 0.91 | 1.91 |
| 112 | 18.24 | 4.31 | 2.85 | 44.53 | 1.39 | 2.06 |
| 163 | 11.60 | 1.73 | 2.18 | 53.54 | 0.60 | 1.50 |

160 è¡Œ Ã— 6 åˆ—

### æ•°æ®é›† 0ï¼Œéå¸¸è§„å¤šå…ƒ v4

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒæ•°æ®é›† [unconv_MV.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª 1,000 ä¸ªéå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   äº•å¹³å‡å­”éš™ç‡

+   æ¸—é€ç‡çš„å¯¹æ•°è½¬æ¢ï¼ˆä»¥çº¿æ€§åŒ–ä¸å…¶ä»–å˜é‡çš„å…³ç³»ï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/mÂ³ x m/s x 10â¶ï¼‰

+   å‰ªåˆ‡æ¯”ï¼ˆ%ï¼‰

+   æ€»æœ‰æœºç¢³ï¼ˆ%ï¼‰

+   ç»ç’ƒè´¨åå°„ç‡ï¼ˆ%ï¼‰

+   åˆå§‹ç”Ÿäº§ 90 å¤©å¹³å‡ï¼ˆMCFPDï¼‰ã€‚

### æ•°æ®é›† 1ï¼ŒåäºŒï¼Œ12

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€2D ç©ºé—´æ•°æ®é›† [12_sample_data.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/12_sample_data.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª 480 ä¸ªéå¸¸è§„äº•çš„å˜é‡ï¼ŒåŒ…æ‹¬ï¼š

+   Xï¼ˆmï¼‰ï¼ŒYï¼ˆmï¼‰ä½ç½®åæ ‡

+   ç›¸ï¼ˆ0 - é¡µå²©ï¼Œ1 - ç ‚å²©ï¼‰

+   å•ä½è½¬æ¢åçš„å­”éš™ç‡ï¼ˆ%ï¼‰

+   æ¸—é€ç‡ï¼ˆmDï¼‰

+   å£°é˜»æŠ—ï¼ˆkg/mÂ³ x m/s x 10â¶ï¼‰

### æ•°æ®é›† 2ï¼Œå‚¨å±‚ 21

è®©æˆ‘ä»¬åŠ è½½æä¾›çš„å¤šå…ƒã€3D ç©ºé—´æ•°æ®é›† [res21_wells.csv](https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv)ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«æ¥è‡ª 10,000m x 10,000m x 50 m å‚¨å±‚å•å…ƒçš„ 73 å£å‚ç›´äº•çš„å˜é‡ï¼š

+   äº•ï¼ˆIDï¼‰

+   Xï¼ˆmï¼‰ï¼ŒYï¼ˆmï¼‰ï¼Œæ·±åº¦ï¼ˆmï¼‰ä½ç½®åæ ‡

+   å•ä½è½¬æ¢åçš„å­”éš™ç‡ï¼ˆ%ï¼‰

+   æ¸—é€ç‡ï¼ˆmDï¼‰

+   å•ä½è½¬æ¢åçš„å£°é˜»æŠ—ï¼ˆkg/m2s*10â¶ï¼‰

+   ç›¸ï¼ˆåˆ†ç±»ï¼‰ - ä»é¡µå²©ã€æ²™è´¨é¡µå²©ã€é¡µå²©ç ‚åˆ°ç ‚å²©çš„é¡ºåºã€‚

+   å¯†åº¦ï¼ˆg/cmÂ³ï¼‰

+   å¯å‹ç¼©é€Ÿåº¦ï¼ˆm/sï¼‰

+   æ¨æ°æ¨¡é‡ï¼ˆGPaï¼‰

+   å‰ªåˆ‡é€Ÿåº¦ï¼ˆm/sï¼‰

+   å‰ªåˆ‡æ¨¡é‡ï¼ˆGPaï¼‰

+   3 å¹´ç´¯è®¡çŸ³æ²¹äº§é‡ï¼ˆMbblï¼‰

æˆ‘ä»¬ä½¿ç”¨ pandas çš„â€˜read_csvâ€™å‡½æ•°å°†è¡¨æ ¼æ•°æ®åŠ è½½åˆ°åä¸ºâ€˜my_dataâ€™çš„ DataFrame ä¸­ï¼Œç„¶åé¢„è§ˆä»¥ç¡®ä¿æ­£ç¡®åŠ è½½ã€‚

+   æˆ‘ä»¬è¿˜ç”¨æ•°æ®èŒƒå›´å’Œæ ‡ç­¾å¡«å……åˆ—è¡¨ï¼Œä»¥ä¾¿äºç»˜å›¾

åŠ è½½æ•°æ®å¹¶æ ¼å¼åŒ–ï¼Œ

+   åˆ é™¤å“åº”ç‰¹å¾

+   æ ¹æ®éœ€è¦é‡æ–°æ ¼å¼åŒ–ç‰¹å¾

+   æ­¤å¤–ï¼Œæˆ‘è¿˜å–œæ¬¢å°†å…ƒæ•°æ®å­˜å‚¨åœ¨åˆ—è¡¨ä¸­

```py
idata = 0                                                     # select the dataset

if idata == 0:
    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['Well'],axis=1,inplace=True)                 # remove well index and response feature

    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax_new = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting
    ymin_new = 0.0; ymax_new = 10000.0
    xlabel_new = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10â¶)','Brittleness Ratio (%)', # set the names for plotting
             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']

    ylabel_new = 'Production (MCFPD)'

    xtitle_new = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting
             'Total Organic Carbon','Vitrinite Reflectance']

    ytitle_new = 'Production'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

elif idata == 1:
    names = {'Porosity':'Por'}

    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['X','Y','Unnamed: 0','Facies'],axis=1,inplace=True)   # remove response feature
    df_new = df_new.rename(columns=names)
    df_new['Por'] = df_new['Por'] * 100.0; df_new['AI'] = df_new['AI'] / 1000.0
    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [4.0,0.0]; xmax_new = [19.0,500.0] # set the minimum and maximum values for plotting

    ymin_new = 1.60; ymax_new = 6.20

    xlabel_new = ['Porosity (fraction)','Permeability (mD)'] # set the names for plotting

    ylabel_new = 'Acoustic Impedance (kg/m2s*10â¶)'

    xtitle_new = ['Porosity','Permeability']

    ytitle_new = 'Acoustic Impedance (kg/m2s*10â¶)'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

elif idata == 2:  
    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository 
    df_new.drop(['Well_ID','X','Y'],axis=1,inplace=True) # remove Well Index, X and Y coordinates, and response feature
    df_new = df_new.dropna(how='any',inplace=False)

    features = df_new.columns.values.tolist()                 # store the names of the features

    xname = features[:-1]
    yname = [features[-1]]

    xmin_new = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax_new = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting

    ymin_new = 0.0; ymax_new = 1600.0

    xlabel_new = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10â¶)','Facies (categorical)',
              'Density (g/cmÂ³)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting

    ylabel_new = 'Production (Mbbl)'

    xtitle_new = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',
              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']

    ytitle_new = 'Production'

    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames 
    X = df_new[xname]

df_new.head(n=13) 
```

|  | Por | Perm | AI | Brittle | TOC | VR | Prod |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 12.08 | 2.92 | 2.80 | 81.40 | 1.16 | 2.31 | 1695.360819 |
| 1 | 12.38 | 3.53 | 3.22 | 46.17 | 0.89 | 1.88 | 3007.096063 |
| 2 | 14.02 | 2.59 | 4.01 | 72.80 | 0.89 | 2.72 | 2531.938259 |
| 3 | 17.67 | 6.75 | 2.63 | 39.81 | 1.08 | 1.88 | 5288.514854 |
| 4 | 17.52 | 4.57 | 3.18 | 10.94 | 1.51 | 1.90 | 2859.469624 |
| 5 | 14.53 | 4.81 | 2.69 | 53.60 | 0.94 | 1.67 | 4017.374438 |
| 6 | 13.49 | 3.60 | 2.93 | 63.71 | 0.80 | 1.85 | 2952.812773 |
| 7 | 11.58 | 3.03 | 3.25 | 53.00 | 0.69 | 1.93 | 2670.933846 |
| 8 | 12.52 | 2.72 | 2.43 | 65.77 | 0.95 | 1.98 | 2474.048178 |
| 9 | 13.25 | 3.94 | 3.71 | 66.20 | 1.14 | 2.65 | 2722.893266 |
| 10 | 15.04 | 4.39 | 2.22 | 61.11 | 1.08 | 1.77 | 3828.247174 |
| 11 | 16.19 | 6.30 | 2.29 | 49.10 | 1.53 | 1.86 | 5095.810104 |
| 12 | 16.82 | 5.42 | 2.80 | 66.65 | 1.17 | 1.98 | 4091.637316 |

```py
df_select = df_new.loc[:,['Por','Perm','AI']]
df_select 
```

|  | Por | Perm | AI |
| --- | --- | --- | --- |
| 0 | 12.08 | 2.92 | 2.80 |
| 1 | 12.38 | 3.53 | 3.22 |
| 2 | 14.02 | 2.59 | 4.01 |
| 3 | 17.67 | 6.75 | 2.63 |
| 4 | 17.52 | 4.57 | 3.18 |
| ... | ... | ... | ... | ... | ... | ... |
| 195 | 11.95 | 3.13 | 2.97 |
| 196 | 17.99 | 9.87 | 3.38 |
| 197 | 12.12 | 2.27 | 3.52 |
| 198 | 15.55 | 4.48 | 2.48 |
| 199 | 20.89 | 7.54 | 3.23 |

200 è¡Œ Ã— 3 åˆ—

### æ„å»ºå’Œæ£€æŸ¥æ¨¡å‹

```py
test_prop = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_prop, random_state=seed) # train and test split
linear_model_new = LinearRegression().fit(X_train,y_train)    # instantiate and train linear regression model, no hyperparmeters

train_pred = linear_model_new.predict(X_train); test_pred = linear_model_new.predict(X_test) # predict at train and test samples 

plt.scatter(y_train,train_pred,color='green',edgecolor='black',label='Training') # cross validation plot
plt.scatter(y_test,test_pred,color='white',edgecolor='black',label='Testing')
plt.plot([ymin_new,ymax_new],[ymin_new,ymax_new],color='black',zorder=-1)
plt.xlim(ymin_new,ymax_new); plt.ylim(ymin_new,ymax_new); add_grid() 
plt.xlabel('Truth: ' + ylabel_new); plt.ylabel('Estimate: ' + ylabel_new)
plt.title('Linear Model Cross Validation'); plt.legend(loc='upper left')

plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() 
```

![å›¾ç‰‡](img/dcda56f7f818f02921fd7cfe954f1f2a.png)

```py
X_train 
```

|  | Por | Perm | AI | Brittle | TOC | VR |
| --- | --- | --- | --- | --- | --- | --- |
| 16 | 19.55 | 8.41 | 3.08 | 35.49 | 1.34 | 1.95 |
| 15 | 11.34 | 2.72 | 3.43 | 58.03 | 0.57 | 2.15 |
| 179 | 7.22 | 1.42 | 3.60 | 63.09 | -0.03 | 1.67 |
| 109 | 15.19 | 5.05 | 3.11 | 57.97 | 1.15 | 2.16 |
| 134 | 12.83 | 2.69 | 3.67 | 17.20 | 0.61 | 2.01 |
| ... | ... | ... | ... | ... | ... | ... |
| 32 | 12.55 | 3.22 | 3.43 | 56.93 | 0.79 | 2.27 |
| 182 | 9.88 | 2.72 | 3.64 | 55.19 | 0.52 | 2.16 |
| 71 | 14.17 | 3.94 | 2.92 | 59.30 | 0.91 | 1.91 |
| 112 | 18.24 | 4.31 | 2.85 | 44.53 | 1.39 | 2.06 |
| 163 | 11.60 | 1.73 | 2.18 | 53.54 | 0.60 | 1.50 |

160 è¡Œ Ã— 6 åˆ—

## è¯„è®º

è¿™æ˜¯å¯¹çº¿æ€§å›å½’çš„åŸºæœ¬å¤„ç†ã€‚å¯ä»¥åšå’Œè®¨è®ºçš„è¿˜æœ‰å¾ˆå¤šï¼Œæˆ‘æœ‰å¾ˆå¤šæ›´å¤šçš„èµ„æºã€‚æŸ¥çœ‹æˆ‘çš„[å…±äº«èµ„æºæ¸…å•](https://michaelpyrcz.com/my-resources)ä»¥åŠæœ¬ç« å¼€å¤´å¸¦æœ‰èµ„æºé“¾æ¥çš„ YouTube è®²åº§é“¾æ¥ã€‚

æˆ‘å¸Œæœ›è¿™æœ‰æ‰€å¸®åŠ©ï¼Œ

*è¿ˆå…‹å°”*

## å…³äºä½œè€…

![å›¾ç‰‡](img/eb709b2c0a0c715da01ae0165efdf3b2.png)

å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ 40 è‹±äº©æ ¡å›­å†…ï¼Œè¿ˆå…‹å°”Â·çš®å°”å¥‡æ•™æˆçš„åŠå…¬å®¤ã€‚

è¿ˆå…‹å°”Â·çš®å°”å¥‡æ˜¯å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡[ç§‘å…‹é›·å°”å·¥ç¨‹å­¦é™¢](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)å’Œ[æ°å…‹é€Šåœ°çƒç§‘å­¦å­¦é™¢](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)çš„æ•™æˆï¼Œä»–åœ¨[å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡](https://www.utexas.edu/)ä»äº‹å’Œæ•™æˆåœ°ä¸‹ã€ç©ºé—´æ•°æ®åˆ†æã€åœ°ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ã€‚è¿ˆå…‹å°”è¿˜æ˜¯ï¼Œ

+   [èƒ½æºåˆ†æ](https://fri.cns.utexas.edu/energy-analytics)æ–°ç”Ÿç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œä»¥åŠå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡è‡ªç„¶ç§‘å­¦å­¦é™¢æœºå™¨å­¦ä¹ å®éªŒå®¤çš„æ ¸å¿ƒæ•™å‘˜

+   [è®¡ç®—æœºä¸åœ°çƒç§‘å­¦](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)çš„å‰¯ç¼–è¾‘ï¼Œ[æ•°å­¦åœ°çƒç§‘å­¦](https://link.springer.com/journal/11004/editorial-board)å›½é™…åä¼šçš„è‘£äº‹ä¼šæˆå‘˜ã€‚

è¿ˆå…‹å°”å·²ç»æ’°å†™äº† 70 å¤šç¯‡[åŒè¡Œè¯„å®¡çš„å‡ºç‰ˆç‰©](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)ï¼Œä¸€ä¸ªç”¨äºç©ºé—´æ•°æ®åˆ†æçš„[Python åŒ…](https://pypi.org/project/geostatspy/)ï¼Œåˆè‘—äº†ä¸€æœ¬å…³äºç©ºé—´æ•°æ®åˆ†æçš„æ•™ç§‘ä¹¦[åœ°ç»Ÿè®¡å­¦å‚¨å±‚å»ºæ¨¡](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)ï¼Œå¹¶æ˜¯ä¸¤æœ¬æ–°å‘å¸ƒçš„ç”µå­ä¹¦çš„ä½œè€…ï¼Œ[Python åº”ç”¨åœ°ç»Ÿè®¡å­¦ï¼šGeostatsPy å®è·µæŒ‡å—](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)å’Œ[Python åº”ç”¨æœºå™¨å­¦ä¹ ï¼šä»£ç å®è·µæŒ‡å—](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)ã€‚

è¿ˆå…‹å°”çš„æ‰€æœ‰å¤§å­¦è®²åº§éƒ½å¯ä»¥åœ¨ä»–çš„[YouTube é¢‘é“](https://www.youtube.com/@GeostatsGuyLectures)ä¸Šæ‰¾åˆ°ï¼Œå…¶ä¸­åŒ…å« 100 å¤šä¸ª Python äº¤äº’å¼ä»ªè¡¨æ¿å’Œ 40 å¤šä¸ª GitHub è´¦æˆ·ä¸Šçš„è¯¦ç»†æ–‡æ¡£å·¥ä½œæµç¨‹ï¼Œä»¥æ”¯æŒä»»ä½•æ„Ÿå…´è¶£çš„å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«ï¼Œæä¾›å¸¸é’å†…å®¹ã€‚æƒ³äº†è§£æ›´å¤šå…³äºè¿ˆå…‹å°”çš„å·¥ä½œå’Œå…±äº«æ•™è‚²èµ„æºï¼Œè¯·è®¿é—®ä»–çš„ç½‘ç«™ã€‚

## æƒ³ä¸€èµ·å·¥ä½œå—ï¼Ÿ

æˆ‘å¸Œæœ›è¿™äº›å†…å®¹å¯¹é‚£äº›æƒ³äº†è§£æ›´å¤šå…³äºåœ°ä¸‹å»ºæ¨¡ã€æ•°æ®åˆ†æå’Œå­¦ä¹ æœºå™¨å­¦ä¹ çš„äººæœ‰æ‰€å¸®åŠ©ã€‚å­¦ç”Ÿå’Œåœ¨èŒä¸“ä¸šäººå£«æ¬¢è¿å‚åŠ ã€‚

+   æƒ³é‚€è¯·æˆ‘åˆ°è´µå…¬å¸è¿›è¡ŒåŸ¹è®­ã€è¾…å¯¼ã€é¡¹ç›®å®¡æŸ¥ã€å·¥ä½œæµç¨‹è®¾è®¡å’Œ/æˆ–å’¨è¯¢å—ï¼Ÿæˆ‘å¾ˆä¹æ„æ‹œè®¿å¹¶ä¸æ‚¨åˆä½œï¼

+   æ„Ÿå…´è¶£åˆä½œã€æ”¯æŒæˆ‘çš„ç ”ç©¶ç”Ÿç ”ç©¶æˆ–æˆ‘çš„åœ°ä¸‹æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ è”ç›Ÿï¼ˆå…±åŒè´Ÿè´£äººæ˜¯çº¦ç¿°Â·ç¦æ–¯ç‰¹æ•™æˆï¼‰å—ï¼Ÿæˆ‘çš„ç ”ç©¶ç»“åˆæ•°æ®åˆ†æã€éšæœºå»ºæ¨¡å’Œæœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µï¼Œå¼€å‘æ–°é¢–çš„æ–¹æ³•å’Œå·¥ä½œæµç¨‹ä»¥å¢åŠ ä»·å€¼ã€‚æˆ‘ä»¬æ­£åœ¨è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°ä¸‹é—®é¢˜ï¼

+   æ‚¨å¯ä»¥é€šè¿‡ mpyrcz@austin.utexas.edu è”ç³»æˆ‘ã€‚

æˆ‘æ€»æ˜¯å¾ˆé«˜å…´è®¨è®ºï¼Œ

*è¿ˆå…‹å°”*

è¿ˆå…‹å°”Â·çš®å°”èŒ¨ï¼Œåšå£«ï¼ŒP.Eng.ï¼Œæ•™æˆï¼Œå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ Cockrell å·¥ç¨‹å­¦é™¢å’Œ Jackson åœ°çƒç§‘å­¦å­¦é™¢

æ›´å¤šèµ„æºè¯·è®¿é—®ï¼š[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [ç½‘ç«™](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [åœ°ç»Ÿè®¡å­¦ä¹¦ç±](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python åº”ç”¨åœ°ç»Ÿè®¡å­¦ç”µå­ä¹¦](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html) | [Python åº”ç”¨æœºå™¨å­¦ä¹ ç”µå­ä¹¦](https://geostatsguy.github.io/MachineLearningDemos_Book/) | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
