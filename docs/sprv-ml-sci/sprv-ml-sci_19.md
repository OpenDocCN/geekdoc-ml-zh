# 13 可复现性

> 原文：[`ml-science-book.com/reproducibility.html`](https://ml-science-book.com/reproducibility.html)

1.  将机器学习融入科学

1.  13 可复现性

代码之美：一旦编写，你可以随心所欲地使用它。如果设置正确，相同的代码应用于相同的数据将产生相同的结果。理想情况下，训练你的机器学习模型也是一样的：点击一下按钮，你就可以再次运行你的代码，并得到完全相同的机器学习模型。这被称为计算可复现性，它[带来了许多优势](https://book.the-turing-way.org/reproducible-research/overview/overview-benefit)。

+   可复现性使跟踪项目中的变化变得更容易。

+   你可以复现你的工作。当审稿人 2 要求你重新训练你的模型时，这会很有用。

+   人们会喜欢与你和你的美丽代码库一起工作。

+   其他研究人员可以基于你的工作继续研究。

+   可复现性允许你稍后把模型投入生产。

但使你的代码可复现比看起来要困难得多。由于不断变化的计算环境和机器学习的独特挑战，计算可复现性本质上是不稳定的。

*可复现性与可重复性* *你可能已经听说过社会科学中的可重复性危机 [[1]](references.html#ref-open2015estimating)：许多研究结果无法重复。可复现性关注一个更窄的目标：使用相同的代码在相同的数据上得到相同的结果（例如，相同的模型）。有关定义的概述，请参阅[Turing Way Book](https://book.the-turing-way.org/reproducible-research/overview/overview-definitions) [[2]](references.html#ref-arnold2019turing)。*  *可复现性不是二元的，而是一个连续体。本章将通过突出机器学习对可复现性提出的独特挑战，帮助你在这个连续体上前进。让我们深入探讨。*

暴风雨预测模型多年来一直工作得很好。直到它不再了。在一个炎热的夏日，服务器崩溃了，模型消失了。Rattle 带着丰富的财富提前退休了，但她的原始学习算法仍然坐在一台旧笔记本电脑上。嗯，应该是一个简单的再训练任务。或者他们是这样想的。他们面对的是一个奇怪的文件夹结构，神秘的文件名，以及不明确的说明。其他 ravens 的代码可能会很痛苦。

![](img/bab47648c997b411e3835973c0ac5751.png)

## 13.1 使任何编码项目可复现

可复现性对于任何编码项目来说都是一个挑战，即使没有机器学习也是如此。本章更多地关注机器学习特有的挑战，但如果我们不提及一些关于可复现性的通用技巧和窍门，它就不会完整 [[3]](references.html#ref-seibold_2024_12744715)：

+   创建一个清晰的文件夹结构。

+   为文件、文件夹和函数使用好的名称。

+   记录你的项目，包括 README、元数据和代码文档。

+   使用 git 等版本控制软件来跟踪代码和文本的变化。

+   使用 Conda 等环境管理工具和 Docker 等虚拟化工具来稳定计算环境和软件。

+   自动化计算，例如 Makefile、工作流程相关内容，并确保所有步骤都能通过代码进行复现。

+   发布你的工作。

你遵循的这些提示越多，你的项目就越具有可复现性和满意度。然而，这可能需要学习新的工具，如 git，并养成新的习惯，如记录代码——这是一次时间和精力的初始投资，但长远来看会得到回报。你的未来自我会感谢你。

现在让我们继续探讨机器学习特有的挑战。

## 13.2 处理非确定性代码

运行相同的代码两次可能会因为随机性而产生不同的结果。机器学习涉及大量的随机性：随机权重初始化、随机梯度下降、随机森林和随机数据分割。这不是错误，这是一个特性：随机性是学习的内在驱动力。例如，随机将数据分割为训练集和测试集模拟了“从同一分布中抽取”的过程，这是泛化的关键要素（参见第七章）和随机梯度下降通过其随机性质隐式地正则化模型 [[4]](references.html#ref-bottou2010largescale)。

为了将随机性引入编程逻辑的确定性世界，机器学习软件依赖于“随机数生成器”。这些生成器并非真正随机——它们基于伪随机过程，可以通过设置一个初始随机种子来控制。随机种子初始化随机数生成器，所有后续的“随机”数都是确定性的。

这个随机种子也是你实现具有随机性的代码可复现性的关键。没有随机种子，每次训练机器学习模型都会产生不同的模型。至少，两次得到相同结果的可能性很小。但通过设置随机种子，你可以使随机数生成可复现。有一些例外：当并行运行多个进程时，如果执行顺序不一致，设置随机种子可能仍然不能保证确定性结果。

除了你电脑的随机数生成器外，还有其他原因可能导致运行相同的代码两次产生不同的结果，即使你已经遵循了所有提示，比如确保你使用的是相同的软件：

+   在 GPU 上进行的操作可能是非确定性的，即使是像求和这样的简单操作（参见[这个 StackOverflow 问题](https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu)）。

+   外部系统可能会随时间变化（例如 API 调用）。

+   浮点运算在不同硬件和软件平台上可能会有所不同。

## 13.3 Jupyter Notebooks

Jupyter Notebooks 是研究中的祝福和诅咒。

*Jupyter Notebook* 这个术语既指软件也指文档，就像“Excel”可以指程序也可以指单个电子表格一样。Jupyter Notebooks（软件）本质上是一个 HTML 应用程序，您可以在其中管理多个笔记本（文档），创建新的，删除，编辑和运行它们。笔记本（文档）是一系列“单元格”。单元格可以包含 Markdown、代码或纯文本。Markdown 单元格被渲染，以便您可以像文档一样结构化笔记本，包括标题、粗体文本和其他格式。您可以执行代码单元格，结果会嵌入到文档中，无论是图表、代码警告还是打印输出。*  *Notebooks 让您可以实验，快速原型设计，探索数据；它们鼓励文档记录；它们非常适合报告结果。但它们使可重复性变得困难。在 Joel Grus 的挑衅性演讲[“我不喜欢 Notebooks”](https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI)中，他特别批评了“隐藏状态”，这使得可重复性变得困难：

+   您可以按任何顺序运行单元格。

+   您可以删除单元格，但创建的变量仍然保留在工作区中。

+   您可以在只运行旧版本的情况下更改单元格的内容。

想象您正在 Jupyter Notebook 中从事一个机器学习项目。您决定在训练之前标准化特征，但忘记运行更新的单元格。您保存了模型，但现在代码与模型不匹配，重新运行笔记本会产生不同的模型。

在另一种情况下，您在编写代码后不久意外删除了生成权重向量的单元格。但由于您已执行了该单元格，向量已存储在内存中。您完成了项目，将最新的更改提交到版本控制，然后结束工作。下一个参与项目的人会遇到关于缺失权重向量的错误。

笔记本还有更多问题：虽然您可以将其置于版本控制之下，但它们相当冗长，因为它们存储了所有 HTML 输出，实际上比较代码更改并不像这样有趣。

即使研究项目依赖于笔记本，也有可能使其可重复。但您必须非常严格地从第一个单元格到最后的单元格线性运行它们，并且始终使用一个新的 Python 会话。*  *## 13.4 API 和专有软件

在他人的硬件上训练机器学习算法可以使你的生活变得更加容易：你不必担心硬件和软件的安装。数百个机器学习即服务平台允许你上传数据并训练模型。问题是缺乏可重复性。机器学习软件背后的公司可以更改其软件而不通知你。即使他们没有这样做：你可能没有足够的控制权来使工作流程对他人完全可重复。可能不清楚平台使用的算法、设置和软件版本。或者公司可能简单地倒闭，你将失去访问你的训练设置。

随着生成式 AI 的发展，特别是像 ChatGPT 这样的大型语言模型，这个问题变得更加严重。无论你是为了研究 ChatGPT 的偏见还是用它来标注数据：背后的公司不断更新模型，一旦一个模型被退役，就没有人能够复制你的研究。

## 13.5 硬件特定挑战

即使你控制服务器或使用你的笔记本电脑并遵循了所有可重复性建议，你的项目可能仍然无法达到 100%的可重复性。至少当涉及到在不同的硬件上运行你的代码时是这样。问题是，我们无法完全抽象化训练等操作与硬件的关系。越来越，机器学习，尤其是深度学习，依赖于更具体的硬件，如 NVIDIA GPU 和 Google TPUs。你的设置越依赖于硬件，其他人复制你的模型就越困难。

## 13.6 无法访问的数据

数据可能由于多种原因而无法访问：它可能太大而无法共享，可能存在隐私问题（例如患者数据），或者可能是专有的。这使得可重复性变得困难。但是，即使在项目内部使其可重复也可能很困难，尤其是在处理大型数据集时。一个可能的“增量”解决方案是共享数据子集或模拟数据。

*可重复性与可重用性* 可重复性与可重用性不是同一回事：一个研究结果可以是可重复的，而不一定是可重用的。你可能能够复制他人的项目，但如果例如许多内容是硬编码的，那么适应你的用例将需要大量的努力。*## 13.7 可重复性与其他问题

可重复性不仅仅是确保其他人，包括你未来的自己，可以复制你的工作。它与我们在这本书中讨论的许多其他方面相关：

+   你可以将可重复性视为一种鲁棒性（参见第十一章）：一个可重复的模型对计算环境和随机数生成都是鲁棒的。

+   缺乏可重复性会引入不确定性（见第十二章）。比如说你忘记设置随机种子。这意味着下一次模型训练时，它将由于数据随机分割和其他基于随机数生成器的操作而面临不确定性。

+   出版（见第十四章）和可重复性都依赖于文档，并且相辅相成：如果你有良好的报告，你的项目也变得更易于重复。

[1]O. S. Collaboration, “Estimating the reproducibility of psychological science,” *Science*, vol. 349, no. 6251, p. aac4716, 2015, doi: [10.1126/science.aac4716](https://doi.org/10.1126/science.aac4716).[2]B. Arnold *et al.*, “The turing way: A handbook for reproducible data science,” *Zenodo*, 2019.[3]H. Seibold, *6 steps towards reproducible research*. Zenodo, 2024\. doi: [10.5281/zenodo.12744715](https://doi.org/10.5281/zenodo.12744715).[4]L. Bottou, “Large-Scale Machine Learning with Stochastic Gradient Descent,” in *Proceedings of COMPSTAT’2010*, Y. Lechevallier and G. Saporta, Eds., Heidelberg: Physica-Verlag HD, 2010, pp. 177–186\. doi: [10.1007/978-3-7908-2604-3_16](https://doi.org/10.1007/978-3-7908-2604-3_16).***
