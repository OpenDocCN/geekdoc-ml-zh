# 第五章 设计和构建管道

> 原文：[`ppml.dev/design-code.html`](https://ppml.dev/design-code.html)

当我们开始编写新的软件时，我们面临的第一大挑战之一是确定其逻辑组件以及它们之间的交互方式。然后我们可以将我们的软件*结构化*为一系列模块，无论是类、库还是完全独立的程序，以便以尽可能简单的方式实现这些逻辑组件。换句话说，我们*设计*软件是为了将复杂性分解成可管理的块，这样我们只需在任何给定时间面对其中的一小部分（Ousterhout 2018)。未能做到这一点会迅速导致软件难以理解和修改（第六章），进而使得部署（第七章）、文档（第八章）、测试或故障排除（第九章）变得困难，总的来说，难以保持运行。

在本章中，我们讨论定义机器学习软件设计的独特挑战：数据的作用（第 5.1 节）、技术债务的本质（第 5.2 节）以及机器学习管道的解剖结构（第 5.3 节）。

## 5.1 数据作为代码

![机器学习软件中角色反转（右）与其他软件（左）的比较](img/6221efc35fbad3a0e8b2a6aca4f3ff9d.png)

图 5.1：机器学习软件中角色反转（右）与其他软件（左）的比较。

机器学习软件在一点上与其他大多数软件有根本的不同：*它与数据紧密相连*（Arpteg 等人 2018）。一块传统软件的结构和行为¹¹源于从该领域专家那里获取的一些过程的组合，对期望输出的规范，以及我们可以用来支持其操作的技术集合（图 5.1，左侧）。我们负责设计产生所需行为的软件架构。例如，我们通过为不同任务建立程序来结构化网络服务，以指导用户导航模式，从某些数据库或各种供应商的 API 中检索信息，并生成通过某些仪表板（由人类）或 API（来自其他计算机系统）消费的输出。桌面应用程序通过窗口和对话框做同样的事情。显然，出于良好的原因（如性能要求、良好实践和可维护性）以及不良的原因（如不理想的要求、所选技术栈的限制和模糊的要求），我们在设计软件架构方面的自由度是有限的，但这仍然给我们留下了相当大的控制权。

另一方面，机器学习软件的行为既受我们训练模型所使用的数据的影响，也受我们的设计选择的影响。我们可能决定如何衡量模型性能，但最佳性能将由数据决定：数据中变量的分布及其概率结构将被某些模型比其他模型更好地捕捉。因此，我们可能会选择尝试，例如，随机森林、深度神经网络和一些层次贝叶斯模型，但最终，我们将使用数据表明最佳的那个模型，而不考虑我们的个人偏好。*数据中的信息通过模型编译到软件中*，这些模型自动编程软件：开发者并不完全在代码中编码其行为（图 5.1，右侧）。

这一认识导致了一个范式转变：**我们应该将数据视为代码**，因为数据在功能上取代了我们源代码的一部分，并且数据的变化可能会改变软件的行为。因此，我们应该**测试数据**以确保其特征不会随时间改变（第 5.2.1 节）。毕竟，如果数据发生变化，我们的模型可能不再适合使用，我们可能需要重新训练它们以保持适当的性能水平。在离线数据的情况下，这意味着**数据应该与代码一起进行版本控制**，并且它们中的任何变化都应触发持续集成工具的测试。在在线数据的情况下，我们还应该实施**实时监控和日志记录**新数据的特征和部署模型的性能（第 5.3.6 节）。一旦我们确信数据正如我们所期望的那样，我们就可以使用它们来测试我们的软件（实现）是否表现正确，并确保模型本身被正确指定（在其数学和概率公式中）。我们将在下一节和第九章中更详细地讨论数据和机器学习模型的故障排除和测试。

理想情况下，我们应该有一个配置管理平台（在这种情况下通常被称为“实验跟踪”或“实验管理”平台），使用版本控制（第 6.5 节）来跟踪硬件、源代码、环境配置、参数、超参数、模型特征、输入数据和所有模型训练和推理实例的输出。（包括我们用来探索数据的那些。）然后我们可以为每个开发和生产环境中的所有组件标记确切的版本，就像在传统的软件工程环境中做的那样。反过来，这意味着我们可以（重新）创建任何这些环境，如需要，这使得自动化部署成为可能（第七章），并极大地简化了故障排除。鉴于大多数机器学习模型（本质上都是黑盒）的可解释性和可解释性有限，只有接近可重复构建设置（Humble and Farley 2011）的解决方案才能希望实现深入的调试和根本原因分析。

## 5.2 技术债务

将数据视为代码意味着我们应该**考虑数据是潜在的技术债务来源**。由于模型依赖于数据，并且本身也是技术债务的来源，因此模型也可以是技术债务的来源。在实践中，数据和模型都是我们机器学习代码的依赖项：像所有依赖项一样，它们是潜在的负债，应该这样处理。

“技术债务”这个术语自从首次被提出以来（Cunningham 1992, 2011）通常带有负面含义：它强调了匆忙的设计选择如何导致意外的成本，这不仅从纯粹的经济角度出发，还通过引入潜在的复杂性，使得软件在随时间演进时更加困难。技术债务允许我们通过牺牲质量换取速度来更快地产生结果，但就像借来的钱一样，我们最终必须以（复利）利息的形式偿还它。当紧迫的截止日期减少了分析和设计所花费的时间（Evans 2003），导致的功能、代码质量或技术实现方面的次优解决方案时，这是不可避免的。在本书的第二部分**2**中建立并遵循我们倡导的实践是控制它并快速偿还以减少其时间的好方法。

机器学习模型及其底层的训练、测试和服务软件基础设施，我们将在第 5.3 节中将其称为*机器学习流水线*，结合了传统软件开发的所有复杂性以及数据分析实验性质产生的问题。（更多内容请见第六章。）因此，我们认为以统一、全面的方式重新思考机器学习软件中的技术债务性质是有用的。我们将它分为四个广泛的领域：*数据*、*模型*、*架构*（设计）和*代码*债务。这些领域涵盖了机器学习实践中各个部分的议题，例如数据收集、数据验证、特征提取、数据可视化和可观察性；以及我们用来与机器学习模型交互的软件，例如监控、配置、训练和服务基础设施。驱动模型的库，如 PyTorch（Paszke 等 2019）或 Scikit-learn（Scikit-learn 开发者 2022），通常非常稳定，我们很少发现它们是技术债务的来源。

### 5.2.1 在数据层面

第 5.1 节设计代码建议，数据可能因为三个原因成为负担。首先，它们可能来自*不受信任的来源*，无论是来自内部还是第三方系统。那些超出我们控制范围或没有严格质量标准的数据源应被视为未知量：数据可能会在形状（原始数据结构或类型变化）、总体质量（数据重复、缺失数据、空数据或错误归一化的数据）或相关性和统计属性（*数据*或*概念漂移*）上意外地随时间变化。这种情况对于以事件流形式出现或由聚合多个来源的数据生成的在线数据尤其如此。（更多内容请参阅第 9.1 节代码故障排除和第 9.4.3 节离线与在线。）为了防止此类异常影响模型的训练及其后续使用，我们应仅允许经过我们的软件测试套件（第 9.4 节代码故障排除）版本化和验证的数据进入机器学习流程。系统测试充当数据必须通过的质量门，才能进入后续处理阶段。数据漂移会使模型变得*过时*：随着它们将要执行推理的数据与用于训练的数据越来越不同，其准确性将降低（Gama 等人 2014 对该主题进行了广泛的回顾）。如果数据的一般质量随时间下降，也可能发生同样的事情。除非这种变化足够突然且足够明显，否则没有测试套件很难检测到其影响。这似乎是 Zillow（Sherman 2022）在线房地产公司所发生的情况：他们用来为购买房产定价的机器学习模型是在自我报告的数据上训练的，这些数据不受信任且难以验证，随着市场冷却，它被用来过高估计价格的时间过长。到 2021 年模型退役时，Zillow 不得不以亏损 60%至 85%的价格出售其购买的房产，并解雇 25%的员工以维持运营。

其次，数据可能来自*未追踪的来源*：我们应始终考虑到第三方来源可能是不稳定的，也可能突然变得不可用。如果这种情况发生在我们不知道我们依赖的数据源上，解决由此产生的问题可能具有挑战性。此外，未追踪的来源通常也不受信任，但与追踪来源不同，它们没有系统地版本化和验证：它们可能存在的问题可能长时间未被察觉。在这种情况下，数据来自何处以及它是如何产生的被称为*数据来源*或*数据血缘*（Cheney，Chiticariu 和 Tan 209AD）。

最后，我们在准备数据以用于管道时可能会引入数据。在许多应用中，我们只能收集 *未标记数据*，我们必须手动进行标注：这是一个昂贵、耗时且易出错的流程，需要一支领域专家团队。使用机器学习模型进行自动标注是一个较差的替代方案，因为它已知在自然语言处理和计算机视觉任务中的准确性比已知低 0.15–0.20（Wu 等人 2022）。缺乏真实标签使得很难发现这些错误，这反过来又影响了其他数据质量控制和模型训练。此外，手动标注速度太慢，使我们无法实时监控管道的输出，限制了检测数据漂移和模型过时的能力。因此，这个问题可能会在不同层面上产生难以检测的技术债务。

### 5.2.2 在模型层面

由数据或其他原因引起的模型性能问题不太可能仅限于单个模型。再次考虑数据漂移：如果机器学习模型 `A` 的任何输出被用作另一个机器学习模型 `B` 的输入，模型 `A` 的准确性下降将传播到模型 `B`，并且在过程中可能被放大。正如数据的情况一样，我们可以通过使用集成测试作为质量门来检测此类问题，以确保每个模型的输入和输出行为符合预期。这只有在我们跟踪模型之间的依赖关系时才可能实现，例如，通过在编排器配置中将它们记录为代码（第 7.1.4 节）或通过实施认证和授权机制来访问模型（例如，使用 OAuth2（ETF OAuth 工作组 2022））。

因此，我们可以这样说，模型层面的技术债务主要源于*特征和模型纠缠*：任何影响一个模型推理能力的问题都会传播到所有依赖它的下游模型，无论是直接还是间接的，这被称为*纠正级联*（章节 9.1.2）。在实际应用中，特征之间、模型之间以及特征和模型之间的纠缠是不可避免的：“改变任何东西都会改变一切”（Sculley et al. 2014）。特征很少完全独立于彼此，而像深度神经网络这样的黑盒模型（章节 9.2.2）故意以难以理解的方式“纠缠”它们。模型之间也相互纠缠，因为它们消费彼此的输出（章节 9.1.2）。这种复杂的相互作用不幸地意味着，即使我们观察到一些明显的迹象表明有问题（章节 9.3），我们可能也很难找到我们正在调试的问题的根本原因。

此外，模型与现实世界相互纠缠：例如，如果驱动推荐系统的模型提出的建议发生变化，系统用户的反应也会随之改变。这形成了一个*反馈循环*，因为用户消费模型的输出，同时为模型提供训练数据。这是否可取取决于具体的应用以及这个反馈循环是否有积极或消极的影响：不受控制的*直接反馈循环*可能导致偏差的放大，同时人为地提高模型的准确性。微软的 Tay 聊天机器人（Hunt 2016）就是一个很好的例子。2016 年在 Twitter 上推出，旨在“通过轻松愉快的对话参与和娱乐人们”的同时，从这些对话中自我训练，但几天后就被关闭，因为它发布的每条推文都包含阴谋论或种族主义、煽动性的言论。（也许它在这样做的同时最大化了一些抽象的参与度指标？）通过外生事件直接相互影响的*隐藏反馈循环*也是可能的，并且更难被发现。诸如拒绝推理（Crook and Banasik 2004）和上下文投币机（Dimakopoulou et al. 2018，2019）等技术，从用户和领域专家那里收集反馈（章节 5.3.4 和 5.3.5），以及包括额外的特征，可以通过探索新的模型并建议是否应该重新训练当前的模型来帮助打破这样的循环。

最后，当我们对一个预训练模型进行微调以适应不同的任务时，模型之间可能会相互纠缠。这种做法减少了计算需求并加快了模型开发速度：我们购买一个用于一般任务（例如，目标检测）的预训练模型 `A`，然后使用高度专注的数据集将其专门化为针对特定任务（例如，检测工业过程半成品中的杂质）的模型 `B`、`C` 等。然而，模型 `B`、`C` 等很可能会从 `A` 继承类似的故障模式，从而在无跟踪依赖关系的模型之间引入耦合，并在机器学习管道中产生意外的修正级联。此外，模型 `B`、`C` 等变得更加难以独立演进，因为我们在模型 `B` 中修复的任何错误也应该在模型 `A`、`C` 等中修复（或确认不会影响它们），并且所有模型的软件测试应同时更新。同样，对模型 `B` 有意义的任何增强可能对模型 `A`、`C` 等也有意义。我们可以通过使用配置管理平台来管理这些问题，正如我们在第 5.1 节中指出的，以跟踪模型之间的依赖关系以及模型与数据之间的依赖关系，对它们进行版本控制，并启用系统测试（第 9.4.2 节）。

### 5.2.3 在架构（设计）层面

机器学习管道的架构指导数据与模型如何交互以实现其目标：它被实现为一个 *编排系统*，该系统安排和协调各种任务，如数据摄取、数据验证、特征工程、模型训练和验证、在生产系统上部署模型以及服务。我们将在第 5.3 节中详细讨论这些内容。

机器学习管道本质上是具有许多动态部分的复杂系统，并且它们很容易隐藏*架构*（*设计*）*债务*。控制这种类型技术债务的关键是使用人类可读的数据序列化语言，如 XML、YAML 或 JSON 文件，*使所有配置方面都可见*。¹² 这些文件应该在配置管理解决方案中与数据（第 5.1 节）和模型（第 5.2.2 节）一起进行版本控制，以及出于类似原因。设计中的每个变化都可以在这些配置文件或使用环境变量中表达。配置文件应用于需要跨迭代完整版本控制的参数、选项和设置，例如数据集位置、训练超参数和模型参数。这些文件还可以链接到并补充架构文档，该文档使用更易于访问的通用语言描述管道（第 8.3 节）。环境变量应用于存储运行时配置，如日志级别（第 5.3.6 节）、功能标志（第 6.5 节）和目标测试或生产环境的标签。环境变量也常用于秘密管理，即存储凭证、证书和其他敏感信息。所有现代构建机器学习管道的软件解决方案都提供配置、覆盖和公开环境变量（包括秘密）的机制。只有通过全面的形式化描述管道及其所有组件，我们才可能在时间上不断发展和扩展，而不会意外地积累架构债务。跟踪和版本控制架构以及数据和模型可以减少在故障排除和调试上花费的时间，并使得实施高效的部署策略（第 7.2 节）和回滚有问题的模型（第 7.6 节）成为可能。另一种选择是手动执行这些操作，这既耗时又容易出错：Knight Capital（Seven 2014）通过在 45 分钟内烧毁 4.6 亿美元，证明了这一点，这是由于他们算法交易软件的手动部署失败。

不幸的是，我们无法像控制自己训练的模型那样轻松地控制和版本化第三方库或远程系统。因此，我们只能通过用 *粘合代码* 包装它们的 API 来将它们集成到机器学习管道的其余部分。粘合代码是一段临时代码，通常以一次性脚本的形式出现，其唯一功能就是使原本不兼容的软件兼容。它既是模型级别（如果包含在模型中）也是架构级别（如果以非标准方式将不同的模块绑定在一起）的技术债务的常见来源，它创造了所谓的“管道丛林”反模式（Bogner, Verdecchia, and Gerostathopoulos 2021)。

粘合代码也常用于包装库和远程 API，因为它允许我们快速以新的领域特定名称、接口和数据结构公开它们（第 8.2 节）。虽然这种做法可能看起来很方便，但它可能会将粘合代码与其包装的内容紧密耦合，导致当库或远程 API 更改其公共接口时，粘合代码会崩溃。我们只有在严格需要时才应使用粘合代码包装器，例如：为了调试目的对函数进行仪器化；为了向管道中的不同模块公开同一库的不同版本或不同功能；或者为了集成我们否则无法使用的遗留库或 API。

### 5.2.4 代码级别

至于 *代码债务*，我们应该避免在同一个机器学习管道中混合不同的解释器、编程语言和框架的版本。不幸的是，这通常有两个原因。首先，机器学习专家和数据科学家通常独立工作，没有共享的开发环境。其次，微服务和类似架构倾向于在同一个应用程序中使用多种编程语言，这被称为 *多语言编程*。虽然不同编程语言通常更适合管道的不同部分（第 6.1 节），但过多的多样性可能导致 *组织反模式*，如技能和技能水平的不平衡分布（例如，只有一个开发者精通关键框架）以及知识转移不足（因为技术太多难以跟踪）。从实际的角度来看，一个好的折衷方案是从一个小型、最新的技术集构建任何新的机器学习管道，并在引入新技术时让所有开发者参与。后者应谨慎进行：简历驱动的开发很少会有好结果。

相关问题之一是**软件库的 vendoring**，即在我们的代码库中包含第三方软件特定版本的源代码，而不是通过包管理器将其作为外部库来管理。Vendored 库成为未跟踪的依赖项（见第 6.3 节），通常使用粘合代码进行集成，并且由于包管理器和其它自动化工具不知道它们的存在，更新起来很麻烦。

另一个导致代码债务的来源是在创建机器学习模型过程中涉及的大量探索和实验。它很容易产生无效的实验代码路径，这些路径通常通过注释（见第 8.1 节）进行糟糕的文档记录，并且在我们试图实现代码覆盖率（见第 9.4.6 节）时可能导致浪费精力。它还可能限制我们从原型到生产级别改进代码质量的时间。代码审查（见第 6.6 节）和持续重构（见第 6.7 节）等实践可以解决这两个问题，我们将在下一章中讨论。它们还将帮助解决低质量代码，作为技术债务的来源，显著增加了错误数量和修复它们所需的时间，从而减慢了开发速度（Tornhill 和 Borg 2022）。

## 5.3 机器学习管道

自 2000 年代初以来，像敏捷（Beck 等人 2001）和 DevOps（Humble 和 Farley 2011）这样的现代软件开发学派一直在推动测试、发布管理和部署过程的自动化，这导致了**持续集成**/**持续交付**和**部署**（CI/CD）解决方案（Duvall, Matyas, 和 Glover 2007）的采用，以管理软件开发生命周期。持续集成是通过频繁提交小更改到版本控制仓库来开发代码的实践。每个更改都通过自动软件测试解决方案进行验证，手动审查，然后集成到主线分支，生产构建就是从这个分支创建的。因此，主线分支始终处于工作状态，代码更改对所有开发者都是立即可见的。（更多内容请见第六章。）持续交付和持续部署侧重于能够在任何时间发布软件的工作版本，并将其部署到生产系统上。（更多内容请见第七章。）在这两种情况下，重点都是使用自动化流程、版本控制、配置管理、软件测试和代码审查来实现轻松、快速和可靠的软件开发生命周期。

![机器学习管道的生命周期](img/49327be097cb9b8e87d715419cc5dac1.png)

图 5.2：机器学习管道的生命周期。

现在，我们有许多集成的 CI/CD 解决方案来构建机器学习管道（称为“MLOps”）。然而，当管道的开发从运行在某个开发者本地环境中的简单概念验证演变为由团队管理的大型软件并在多个系统上运行时，对其工作方式的完整理解变得至关重要。（大多数实际管道都足够复杂，需要团队来管理。）起初，我们探索一些样本数据，并尝试不同的模型来评估它们的性能，在软件测试上花费很少或没有时间。然后，开发管道变成图 5.2 中所示的迭代和越来越复杂的过程：从摄取阶段向现有模型提供新数据以验证、监控和故障排除；随着数据的变化生成新模型；部署模型并持续将其提供给下游模型或用户将访问的应用程序或服务。这就是我们所说的*机器学习管道*：将这些步骤编码成独立的、可重用的、模块化的部分，可以将它们组合在一起以协调数据流入和流出机器学习模型的数据流。¹³ MLOps 实践标准化并自动化了管道的开发方式，为我们带来了 CI/CD 带给传统软件工程的全部优势，并建立在相同的基础上：有效使用版本控制、配置管理、自动化测试、代码审查和自动化部署。持续集成除了测试和验证代码外，现在还包括测试和验证数据和模型。持续交付和持续部署扩展到整个机器学习管道的生产和部署，再次包括模型。这种扩展的 CI/CD 定义使我们能够专注于机器学习模型的开发、测试和验证，用基于行业标准的系统解决方案取代基于粘合代码的自建解决方案。

图 5.2 从图 1.2 中提取了软件开发生命周期的表示，并将其置于上下文中。它展示了可重复机器学习的关键逻辑步骤：我们应该注意哪些方面来构建一个稳固且可维护的流水线。一些方框代表开发阶段，一些是将成为我们流水线模块的实际软件组件，还有一些两者兼具。从广义上讲，我们可以将流水线中的模块分为四个阶段：*数据摄取*和*准备*；*模型训练*、*评估*和*验证*；*模型部署*和*服务*；以及*监控*、*日志记录*和*报告*。每个阶段提供的功能如何拆分为模块，是我们定义流水线范围时可以决定的事情；然后我们可以生成一个基线实现，以了解其规模和结构。然而，软件工程中确立的设计原则同样适用（Ousterhout 2018；Thomas and Hunt 2019）。每个模块应该只做一件事，并且做到完全（“单一职责原则”），封装尽可能多的复杂性，并通过一个简单的接口（“深度模块”）进行抽象。因此，我们可以通过避免*变更放大*（简单的更改需要修改代码的多个不同位置）和减少*认知负荷*（开发者需要知道多少才能成功进行更改）以及*未知未知*（哪些代码部分需要修改并不明显）来控制流水线的复杂性。简单的接口不太可能改变：如果我们限制依赖项的数量并避免常见的反模式，如隐式约束（例如，函数应按特定顺序调用）和包含各种无关信息的传递变量（例如，上下文对象中的整个全局状态），它们还可以减少模块之间的耦合。简单的接口还应通过暴露具有领域意义的方法和数据结构来反映领域知识，这些名称来自通用语言（第八章）和具有使常见情况易于实现的默认设置。这种方法可能产生一个模仿领域专家工作流程的流水线架构，这允许他们在“人机交互”设置中帮助验证模型和推理输出（Wu et al. 2022；Xin et al. 2018）。此外，模块化流水线可以很容易地由一个*编排器*管理，该编排器可以部署模块（第七章）、将它们分配到具有适当硬件资源的系统（第二章）并控制它们的执行。

### 5.3.1 项目范围定义

从图 5.2 的顶部开始，构建机器学习管道的第一步是理解它应该解决的问题、它可以使用哪些数据来完成这项任务、它应该产生什么输出，以及它的最终用户是谁。为了阐明这些点，我们首先应确定谁将参与开发管道或与之互动（即“利益相关者”）：软件开发者、机器学习专家、领域专家和用户。他们共同将拥有定义管道范围所需的所有信息。

确定机器学习管道及其底层系统（第二章）的范围涉及以下步骤：

1.  *确定我们想要解决的问题：*利益相关者应共同努力明确管道应解决的问题及其影响。领域专家应有一个具体的商业或学术需求需要解决，并且与其他利益相关者一起，他们应决定这个问题是否值得解决，以及解决它是否对足够多的人有价值。如果领域专家对可以使用机器学习有效解决的各类问题有所了解，这个过程会更加顺畅。

1.  *确定我们想要优化的目标：*利益相关者应决定成功解决问题的含义。为此，领域专家应设定可衡量的领域指标和可实现的阈值值来定义“成功”。这些指标应包括：

    +   在不同的数据、模型和技术解决方案之间具有可比性，以便对比不同的管道实现。

    +   容易理解和解释；

    +   足够简单，可以实时收集以进行日志记录和监控（第 5.3.6 节）；

    +   可执行的。

1.  *确定我们需要的数据*：数据是机器学习流程的一个关键组成部分，因为它们决定了其性能（第 5.1 节）。因此，确定我们想要使用的所有数据源、它们的所有者以及数据存储（文件、数据库或数据湖）和结构（数据模式）的技术细节至关重要。这使我们能够跟踪数据来源并减少技术债务（第 5.2.1 节）。特别是，我们应该警惕提供重叠信息的数据源，因为它们在流程中引入了隐藏的依赖关系。由于它们模式的不同（例如，相同的变量以不同的方式缩放或离散化），它们很容易不一致，即使它们是一致的，随着时间的推移也可能发生分歧（例如，一个数据源更改了模式，而其他没有）。一个常见的例子是部分预处理的 数据，它们应该始终与它们起源的原始数据保持一致，并存储在同一个版本化的存储库中。此外，我们应该遵循几十年来在调查抽样（Lohr 2021；Groves 等人 2009）和实验设计（Montgomery 20AD）中积累的最佳实践来收集数据，以确保我们收集的数据（第 5.3.4 节）用于训练机器学习模型，能够代表模型将执行推理的数据（第 5.3.5 节）。抽样偏差可能会对流程的性能产生不可预测的影响。

1.  *分析*：我们应该评估我们可以收集多少数据以及它们将包含哪些变量类型。有了这些信息，我们可以开始评估不同的模型，基于它们的样本大小要求、它们的概率假设以及它们支持的推理类型（预测、分类等）。作为一个一般规则，始终从更简单的模型开始总是更可取，因为它们允许快速反馈循环：如果简单的模型无法达到我们的目标，我们可以转向更复杂的模型，并将简单的模型用作基线。此外，我们还应考虑以下因素：

    +   模型对数据噪声、模型误指定和对抗性攻击的*鲁棒性*。

    +   **可解释性**和**可解释性**，即我们理解模型行为和输出的程度。一些模型由于其简单的结构（例如，回归模型）或构建方式（例如，贝叶斯网络（Scutari 和 Denis 2021））而内在可解释。对于其他模型（例如，深度神经网络），我们可以引入辅助模型来提供事后解释：其中一些是应用无关的（Linardatos，Papastefanopoulos 和 Kotsiantis 2021），而另一些则专门针对自然语言处理（Li 等人 2016）或计算机视觉（Simonyan，Vedaldi 和 Zisserman 2014）。

    +   模型输出的**公平性**，这不应该导致机器学习流程基于性别、种族或年龄等敏感属性歧视个人或群体。虽然关于这个主题的文献很多（Mehrabi 等人 2021），但对于如何衡量公平性并没有共识。大家普遍认同的是，机器学习模型可以轻易地吸收它们训练数据中存在的偏见。因此，我们应该仔细考虑数据的收集方式，并限制模型以限制或忽略已知敏感属性的歧视效应。未能做到这一点往往会导致新闻曝光：亚马逊的性别歧视招聘工具（BBC 2018）、Facebook 图像识别实验室将黑人男子标记为灵长类动物（BBC 2021a）和 Twitter 的种族主义预览裁剪（BBC 2021b）只是其中几个例子。

    +   对敏感数据的**隐私**和**安全**问题（Papernot 等人 2018）。机器学习模型擅长从数据中提取有用信息，但与此同时，它们应该通过不披露个人信息来保护隐私。如何实现这一点是一个开放性问题，研究正在调查诸如差分隐私（Gong 等人 2020）、对抗攻击防御和数据再识别（Narayanan 和 Shmatikov 2008）以及联邦学习（Li 等人 2021）和边缘计算（Khan 等人 2019）等分布式学习实现方法（第 2.3 节）。

机器学习管道通常跨越多个数据源和多个模型：因此，我们将根据项目的性质和执行该项目的组织的性质多次迭代这些步骤。最终，我们将拥有编制任务说明文档（第 8.4 节）和绘制架构布局（第 8.3 节）以及我们的软件测试套件（第 9.4.1 节）所需的信息。架构通常用有向无环图（DAG）表示：请参阅图 8.2 以了解一个说明性的例子。每个节点将对应于管道中的一个模块，输入和输出弧分别表示其输入和输出。因此，DAG 映射了管道的执行路径以及从数据摄取到训练、推理和报告的数据和信息流。对于特别复杂的管道，DAG 可能相当大：将其拆分为对应于管道不同部分的较小 DAG，并独立地处理它们可能更方便。

### 5.3.2 生成基线实现

如果有合适的硬件，数据验证、模型开发、调整、训练和验证最初由个别开发人员和机器学习专家在本地硬件上进行探索。经过实验后，他们最终将产生管道某一部分的最小、可工作的原型。这通常被称为*基线实现*或*概念验证*，它将只涉及允许我们检查是否能够实现目标的最小代码量。

对问题的初步探索通常不涉及上述以及第六章中讨论的所有 CI/CD 开发工作流程：在这个阶段，代码和模型太不稳定。然而，开发人员和机器学习专家至少应该就一个共同、统一的开发环境（软件依赖关系管理、构建过程和配置）达成一致。这个环境应该以可重复和可靠的方式进行构建，这需要配置管理，并且它应该尽可能接近我们的目标生产环境。为了方便起见，开发环境应该像管道一样模块化，这样我们就可以只运行我们正在工作的模块：通常不可能在开发工作站的整个管道上运行。

在确认我们的概念验证实现了所有目标之后，我们接下来：

1.  构建一套软件测试（第 9.4.2 节）并将其推送到我们的版本控制仓库，以开始利用持续集成。然后，我们可以通过逐步重构（第 6.7 节）和编写文档（第八章）来帮助代码审查（第 6.6 节），将概念验证逐步转化为生产质量的代码。

1.  提高可扩展性。通常，一个概念验证是通过使用可用数据的一小部分来构建的，因此我们必须确保其计算复杂度（第四章）足够小，以便在所有数据都用于生产时，学习和推理仍然是可行的。时间复杂度很重要，它允许及时重新训练模型以及在延迟约束下的推理；空间复杂度必须适合我们可用的机器学习系统（第二章）。如果我们的开发系统与生产系统相似，我们可以预期计算复杂度将以类似的方式转化为实际性能，并可靠地预测后者。

### 5.3.3 数据摄取和准备

在确定了管道的范围并实现了其部分的基础实现之后，我们可以以更结构化的方式开始设计和实现其模块。机器学习管道是数据处理工作流程的形式化。因此，管道的第一部分将包括一个或多个*数据摄取*模块，我们从各种来源收集数据，例如关系数据库、遗留的 OLTP/OLAP 系统以及现代内部或云数据湖。这些模块的性质取决于管道将运行的机器学习系统：它们的设计将受到诸如数据本地性（第 2.2 节和 2.3 节）、数据来源（第 5.2.1 节）、不同类型存储的可用性（第 2.1.2 节）以及符合美国 HIPAA 和 FCRA 或欧洲 GDPR 等隐私框架（第 5.3.1 节）等因素的严重影响。

数据采集之后是*数据准备*。准备和清洗数据是一个艰难但至关重要的步骤，涉及数据科学家、领域专家和机器学习专家（Kenett 和 Redman 2019）。数据准备模块建立在用于生成模型基线实现的探索性数据分析之上，这通常限于对汇总统计、图形可视化和一些基本特征选择的概述分析。它们的目的是以尽可能自动和可重复的方式清洗和提升数据质量，使管道的后续阶段更加可靠。除了验证每个特征的类型、可接受的值和统计分布之外，数据准备模块还应解决第 9.1 节中讨论的问题。它们还可以自动化特征选择和*特征工程*（即，将现有特征转换为更适合模型训练或从领域角度更有意义的新的特征）。当前的数据和机器学习管道的软件解决方案通过将处理函数和验证函数作为配置参数来灵活处理这些任务，这些函数检查现在已清洗的数据的性质。例如，前者可能移除异常值、填补缺失数据并对标签和特征进行排序；后者作为质量门（第 5.2.1 节）和基于属性的软件测试的核心（第 9.4.2 节）。

最后，数据被分成多个集合，用于后续作为训练集、验证集和测试集。确保避免数据泄露，见第 9.3 节。）每个数据集都附有关于其来源的信息以及用于提取和清洗它的代码版本，以跟踪数据来源。这些标签成为我们配置管理的一部分，数据作为版本控制下的工件存储，以供后续使用。

### 5.3.4 模型训练、评估和验证

在采集和准备之后，机器学习管道将数据传递给*模型训练*模块或*推理*模块（我们将在第 5.3.5 节中讨论）。然后，使用软件测试和人类专家判断对训练好的模型进行*评估*（在统计性能方面）和*验证*（在领域术语中），以确保它们是高效、可重复和可扩展的。只有统计和领域方面都表现良好的模型才会被认为适合部署和服务。

*训练*一个机器学习模型包括通过迭代应用特征工程、超参数调整和参数优化组合，在某个模型类（神经网络、随机森林等）中识别一个最优实例。这正是“机器学习”中的“学习”所指：计算机系统被训练从数据中包含的信息学习现实世界某个部分的运行模型。为此目的所使用的概率技术针对每个模型类都是特定的，并且超出了本书的范围：有关此主题的易于理解的讨论，请参阅 Kuhn 和 Johnson（M. Kuhn 和 Johnson 2013）。训练是一个计算密集型任务，尤其是在深度学习的情况下。管道的作用是在具有适当硬件能力的计算系统上安排训练工作负载（如第 2.4 节所述），并监控其进度。它还应简化具有预定义、常规超参数模式的模型的并行训练；并且它应该自动化实现基于属性的模型概率属性测试的软件测试（第 9.4.2 节）。

根据数据的性质，训练可以采取相当不同的形式（第 9.4.3 节）。在*静态学习*中，模型从零开始在对当前生产中观察到的数据进行代表性选择的基础上，在*冷*（离线）数据上进行训练。然后，其统计性能与一组单独的冷数据或一小部分生产数据进行比较。在两种情况下，数据都应由领域专家进行标记或验证，以解决第 5.2.1 节中讨论的问题，并最大化模型质量。在*动态学习*中，模型在实时收集的实时*流*生产数据上进行持续训练和评估。这需要实施细粒度监控（第 5.3.6 节）。如果数据漂移是渐进的，我们可能通过微调来防止模型过时（Gama 等人 2014）。另一方面，如果数据漂移是突然的，可能更倾向于使用最近的数据批次从头开始重新训练模型。

*模型评估*模块检查刚刚训练的模型的预测准确性在统计意义上是否优于当前生产中相应模型的准确性。为了同时评估这两个方面，我们可以执行一个*金丝雀部署*：在相同的数据上并行运行当前模型和新模型，以直接比较它们。（关于这一点，请参阅第七章。）在流数据的案例中，使用 A/B 测试（Amazon 2021；Zheng 2015）是标准做法，随机将新数据点分配给任一模型。同时，我们可以使用我们决定优化的指标来检查新模型在领域方面是否优于当前模型（第 5.3.1 节）。我们称之为*模型验证*，与仅从统计意义上评估模型相对。这两个方面可能相关，因为统计性能较差的模型通常不足以在实际应用中很好地编码领域知识。然而，统计性能良好的模型也不一定具有实际应用价值：特别是当模型训练以最小化的损失函数与业务或领域术语中预测错误成本所隐含的损失函数差异太大时。一般来说，选择匹配良好的领域指标和统计准确性度量以保持一致性更好。与可以通过软件测试和持续集成在很大程度上自动化的模型评估不同，模型验证应涉及领域专家。即使我们实践领域驱动开发（Evans 2003）并将他们纳入管道的设计（第六章）、实施（第六章）和文档化（第八章），他们仍会存在一些领域知识或直觉，无法传达给开发人员和机器学习专家。尽管听起来不太科学，但有些知识基本上无法用数字表示。因此，将会有一些我们无法编写测试的问题，但专家可以通过“直观判断”并在模型输出中标记出来，因为“它们看起来不正确”和“不太合理。”这种做法在文献中被称为“人机交互”，并且已知它可以提高跨任务和应用领域的机器学习质量（Wu et al. 2022；Xin et al. 2018)。

当模型最终在统计和领域方面都表现出良好的性能时，管道应触发 CI/CD 过程，生成包含模型和训练过程中所有相关信息的*工件*。工件可以是简单的，也可以是复杂的：

1.  一个（通常是二进制）文件，以标准化格式存储并在通用**工件注册库**中版本化。该格式可以是模型无关的，如 ONNX（ONNX 2021），或者特定于用于训练的机器学习框架。

1.  一个（通常是 Docker（Docker 2022a））容器，它嵌入模型并使用提供推理、健康检查和监控 API 的应用代码将其封装。然后，该容器被存储并版本化在**容器注册库**中。

1.  一个上传到**模型注册库**的带注释文件，它提供实验跟踪、模型服务、监控以及模型之间的版本比较。

类似于 GitHub 和 GitLab 这样的平台集成了通用工件注册库（GitHub 2022b；GitLab 2022a）和容器注册库（GitHub 2022c；GitLab 2022b），Nexus（Sonatype 2022）也是如此。像 TensorFlow Extended (TFX)（TensorFlow 2021b）这样的 MLOps 平台实现了实验跟踪和其他机器学习特定功能。我们将在第 7.1 节中回到这个话题。

不论其形式如何，工件应该是**不可变的**：一旦生成后就不能更改，这样它们就可以作为模型的唯一真相来源。数据工件（第 5.3.3 节）、代码（第 6.5 节）以及通常其他软件工件也作为不可变工件存储并版本化。当它们的版本被链接时，我们就有一个完整的配置管理解决方案，允许对管道中曾经使用过的任何开发、测试或生产环境进行可重复构建。

### 5.3.5 部署、服务与推理

我们生产的并非所有工件都会立即**部署**，或者根本不会部署：持续交付只能确保我们始终准备好部署最新的模型。在学术界，我们无法在一系列实验中途对管道进行任何更改，否则可能会引入结果中的混淆。在商业领域，我们可能与客户签订了服务级别协议，这使得在没有充分理由的情况下部署新模型变得风险很高。工件也可能因安全原因被发现不适合部署：例如，我们可能会发现一个容器包含易受攻击的依赖项或配置错误（第 7.1.4 节）。

模型部署不是作为一个模块实现的：相反，它是管道编排的一部分，使得模型能够部署到目标环境。在生产环境中部署的模型将被 *提供* 服务，以便用户、应用程序或其他模型可以访问其推理能力。部署到测试环境的模型将通过软件测试和专家判断进行评估，而部署到开发环境的模型可以用于调试错误或进一步调查数据。

机器学习模型的部署方式取决于它如何被打包成工件以及如何使用。文件工件可以是嵌入到暴露本地推理方法的软件库中，或者通过合适的远程 API 和协议（如 RESTful 或，当我们需要低延迟时，gRPC（Ganiev 等 2021）从模型注册表中提供“作为服务”。容器工件可以通过所有通用编排平台部署，这些平台提供内置的硬件和软件指标（负载、内存和 I/O 使用）监控以及故障排除设施。尽管容器工件本质上更复杂，但它们更容易部署，因为它们是短暂的且高度可移植的，并且我们可以以代码的方式管理它们的运行时依赖和配置。我们将在第 7.1.4 节和 7.2 节中详细讨论这一主题，以 Dockerfile 作为参考。

### 5.3.6 监控、日志记录和报告

*监控* 模块收集我们在范围阶段（第 5.3.1 节）中确定的指标，以跟踪管道是否始终达到所需的统计和领域性能水平。这些指标应描述整个管道以及各个模块，以便我们能够确定任何可能需要解决的任何问题的来源。特别是：

+   数据摄取和准备模块（第 5.3.3 节）：我们应该监控与基于属性的软件测试中检查的相同数据指标，以防止数据漂移和数据退化。

+   训练模块（第 5.3.4 节）：我们应该一致地监控所有模型在管道中使用的相同指标，以区分单个模型的问题和数据引起的问题。特别是当使用在线数据时。

+   服务和推理模块（第 5.3.5 节）：我们应该监控与训练期间相同的指标，以确保性能没有随时间退化（所谓的“训练-服务偏差”）。并且我们应该对所有推理请求（可能是在小批量中进行）进行监控，以确保输出始终与我们的目标保持一致。这对于通过领域专家进行人工验证黑盒模型至关重要，这些模型的故障模式大多未知且难以测试。

监控设施的覆盖范围之所以重要，与测试覆盖范围之所以重要的原因相同：两者都负责识别数据（第 9.1 节）、模型（第 9.2 节）和管道（第 9.2.4 节）的广泛问题，以足够的精确度进行根本原因分析。软件测试在开发和部署时执行此功能；监控在运行时执行此功能。

在实践中，我们可以使用 Prometheus（Prometheus Authors and The Linux Foundation 2022）等客户端-服务器软件来实现监控。管道中的每个模块都会内部生成所有相关指标，将它们标记以跟踪来源（哪个模块，以及如果有多个副本并行运行，哪个模块的实例）并通过客户端接口以结构化格式提供。监控模块随后提供相应的服务器，从所有客户端拉取指标并将它们保存到*事件存储*数据库中。它们还将过滤指标，净化它们，并频繁检查异常。如果发现任何异常，监控模块可以触发警报并将故障报告发送给相关人员，例如使用 Alertmanager（它是 Prometheus 的一部分）或 PagerDuty（PagerDuty 2022）。如果我们的管道足够自动化，我们还可以同时自动触发模型重新训练。这是及时处理异常并保证管道输出质量保证的唯一方法。将事件存储中的信息与我们的配置管理系统中的信息进行交叉引用，对于比较我们当前生产环境与过去（现在不可用）环境的性能非常有价值。相同的指标也可能有助于解决基础设施问题，如计算资源、内存和 I/O 的过度消耗，以及影响下游服务和模型的服务问题，如就绪状态（是否特定的 API 准备好接受请求）和过度的推理延迟（API 响应所需的时间）。

*日志*模块通过记录单个模块或管道编排中发生的事件的相关信息来补充监控，捕获异常和错误。通常，至少部分机器学习管道是在远程系统上运行的：由于我们无法直接访问它们，尤其是在云实例的情况下（第 2.3 节），我们在调试和解决问题方面的能力受到限制。通过记录每个模块在一系列带有时戳的*日志消息*中执行的操作，日志记录使这个问题不那么严重，这些消息从简单的纯文本消息（我们可能自己生成）到更结构化的 JSON 或二进制对象（来自框架或语言解释器）。每个日志消息都有一个“级别”，它决定了其严重性，并允许我们控制每个模块想要记录多少：例如，一组标签如`DEBUG`、`INFO`、`WARNING`、`ERROR`和`CRITICAL`。每个日志消息还带有其来源的标签，这允许我们区分：

+   系统日志，提供了有关机器学习系统负载、运行时环境和相关依赖项版本的信息。

+   训练日志，描述了模型结构、其与数据的拟合程度以及每个训练迭代的参数和超参数的值；

+   推理日志，描述了每个请求和每个 API 的输入、输出、准确率和延迟。

因此，日志在通常情况下提供了可观察性的度量：所有模块都应该尽可能多地实现日志记录，就像监控一样。然而，我们生成的消息越多，日志记录所需的资源就越多：这给我们可以负担的日志记录量设置了实际限制，尤其是在生产系统中。在开发环境中，我们可能只是将日志消息追加到文件中。在生产环境中，我们应该将整个管道的日志消息聚合到一个远程日志收集器，而不是本地。日志收集器可以标准化日志消息，使它们易于浏览，并使关联不同模块中发生的事件成为可能。

与监控模块类似，日志模块使用客户端-服务器软件（如 FluentdFluentd 项目[2022]）实现，辅以搜索引擎（如 Elasticsearch2022）和 Web 前端（如 Kibana2022）。这两个软件堆栈有一些明显的相似之处：两者都有一个远程服务器从模块内部的客户端聚合信息。这种架构的潜在原因是，我们应该将服务器放置在一个完全独立于机器学习管道运行的系统上：当后者崩溃时，我们需要能够访问监控和日志服务器存储的信息，以调查其最后已知的状态并决定如何最佳地恢复它。

然而，监控和日志记录有两个关键的技术差异。首先，日志记录应支持非结构化数据，而监控仅处理 `{key, type, value}` 三元组形式的数据。日志记录为我们编写的代码实现模块之外的观察性提供了信息，报告的信息是我们没有直接产生且其格式我们可能无法控制的信息。监控从内部提供观察性：我们将客户端组件集成到我们的代码中，并给它访问其内部状态的能力。因此，我们向监控服务器公开的信息必然以各种数据类型和数据结构进行结构化（第三章）。其次，日志是随着生成而推送到服务器的，而监控服务器定期从模块的客户端拉取指标。因此，日志服务器使用的数据库是通用的事件存储，而用于监控的数据库是针对时间序列数据进行优化的。定期访问所有模块的内部状态的能力使监控服务器非常适合观察机器学习管道中的任何逐渐退化。

*报告* 模块实现了图形界面，显示监控和日志记录模块收集的信息。基于数据科学领域的最佳实践（Kenett 和 Redman 2019），它们提供了具有直观、交互式 *仪表板* 的网络界面，这些界面可供开发者、机器学习专家和领域专家使用。常用的图形显示包括：

+   数据摄取和准备模块（第 5.3.3 节）：

    +   实验分布图，包括单个特征和特征对的分布，如直方图、箱线图、热图和成对散点图（对于连续特征）或条形图和镶嵌图（对于离散特征）。

    +   从简单的线性回归等最小统计模型中提取的关键摘要图，以评估特征之间关系的大小和符号，并探索潜在的公平性问题。

+   训练模块（第 5.3.4 节）：

    +   模型性能在训练过程期间和结束时的情况图，例如深度神经网络损失函数随时间步长的轮廓图以及由分类模型生成的混淆矩阵的热图。

    +   帮助解释模型行为的图，显示其参数或解释性方法（如 LIME（Ribeiro, Singh, 和 Guestrin 2016）和 SHAP（Lundberg 和 Lee 2017））的输出。

    +   对于计算密集度较低的模式，可以触发模型训练的交互式仪表板，带有滑块以动态选择超参数。

+   服务和推理模块（第 5.3.5 节）：

    +   输入数据的经验分布与历史数据的对比图，以检测数据漂移。

    +   用于模型验证的准确度度量指标和用于模型评估的指标的时间序列图，以检测模型何时变得过时。

    +   滞后和就绪状态的时间序列图。

所有图表也应包括置信区间，以传达它们显示的每个数量的可能值范围，只要合理。

像自然语言处理和计算机视觉这样的领域可能除了上述内容外还需要专门的图形界面：例如，在自然语言处理中可视化词语的相关性（Li 等人 2016）和在计算机视觉中可视化像素的相关性（Simonyan，Vedaldi 和 Zisserman 2014）或根据语义意义将图像分割成层（Ribeiro，Singh 和 Guestrin 2016）。这样的界面对于让领域专家参与验证模型训练和推理模块的输出非常有用。然后可以对未正确分类或预测的实例进行视觉检查、标记并用于重新训练机器学习模型。

### 参考文献

Amazon. 2021\. *Dynamic A/B Testing for Machine Learning Models with Amazon SageMaker MLOps Projects*. [`aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/`](https://aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/).

Arpteg, A., B. Brinne, L. Crnkovic-Friis, and J. Bosch. 2018\. “Software Engineering Challenges of Deep Learning.” In *Euromicro Conference on Software Engineering and Advanced Applications*, 50–59\. IEEE.

BBC. 2018\. *Amazon Scrapped “Sexist AI” Tool*. [`www.bbc.com/news/technology-45809919`](https://www.bbc.com/news/technology-45809919).

BBC. 2021a. *Facebook Apology as AI Labels Black Men “Primates”*. [`www.bbc.com/news/technology-58462511`](https://www.bbc.com/news/technology-58462511).

BBC. 2021b. *Twitter Finds Racial Bias in Image-Cropping AI*. [`www.bbc.com/news/technology-57192898`](https://www.bbc.com/news/technology-57192898).

Beck, K., M. Beedle, A. Van Bennekum, A. Cockburn, W. Cunningham, M. Fowler, J. Grenning, et al. 2001\. *The Agile Manifesto*. [`www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf`](https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf).

Bogner, J., R. Verdecchia, and I. Gerostathopoulos. 2021\. “Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study.” In *2021 IEEE/ACM International Conference on Technical Debt (TechDebt)*, 64–73.

Cheney, J., L. Chiticariu, and W.-C. Tan. 209AD. “Provenance in Databases: Why, How and Where.” *Foundations and Trends in Databases* 1 (4): 379–474.

Crook, J., 和 J. Banasik. 2004\. “拒绝推断是否真的提高了应用评分模型的性能？” *银行与金融杂志* 28: 857–74.

Cunningham, W. 1992\. “WyCash 投资组合管理系统补充。” 在 *ACM 面向对象编程、系统、语言与应用会议补充程序* 中，第 29-30 页。

Cunningham, W. 2011\. *沃德解释债务隐喻*. [`wiki.c2.com/?WardExplainsDebtMetaphor`](https://wiki.c2.com/?WardExplainsDebtMetaphor).

Dimakopoulou, M., Z. Zhou, S. Athey, 和 G. Imbens. 2018\. *情境性赌博中的估计考虑*. [`arxiv.org/abs/1711.07077`](https://arxiv.org/abs/1711.07077).

Dimakopoulou, M., Z. Zhou, S. Athey, 和 G. Imbens. 2018\. *情境性赌博中的估计考虑*. [`arxiv.org/abs/1711.07077`](https://arxiv.org/abs/1711.07077).

2019\. “平衡线性情境性赌博。” 在 *AAAI 人工智能会议论文集* 中，第 3445–53 页。

Docker. 2022a. *Docker*. [`www.docker.com/`](https://www.docker.com/).

Duvall, P. M., S. Matyas, 和 A. Glover. 2007\. *持续集成：提高软件质量和降低风险*. Addison-Wesley.

Elasticsearch. 2022\. *免费和开源搜索：Elasticsearch、ELK 和 Kibana 的创造者*. [`www.elastic.co/`](https://www.elastic.co/).

ETF OAuth 工作组. 2022\. *OAuth 2.0*. [`oauth.net/2/`](https://oauth.net/2/).

Evans, E. 2003\. *领域驱动设计：软件核心的复杂性处理*. Addison-Wesley.

Gama, J., I. Žliobaitè, A. Bifet, M. Pechenizkiy, 和 A. Bouchachia. 2014\. “关于概念漂移适应的综述。” *ACM 计算调查* 46 (4): 44.

Ganiev, A., C. Chapin, A. Andrade, 和 C. Liu. 2021\. “用于加速基于 Transformer 的语言模型大规模推理的架构。” 在 *北美计算语言学协会 2021 年会议论文集* 中，第 163–69 页。

GitHub. 2022b. *将工作流程数据存储为工件*. [`docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts`](https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts).

GitHub. 2022c. *与容器注册库一起工作*. [`docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry`](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry).

GitLab. 2022a. *GitLab 工件*.

GitLab. 2022b. *GitLab 容器注册库*. [`docs.gitlab.com/ee/user/packages/container_registry/`](https://docs.gitlab.com/ee/user/packages/container_registry/).

Gong, M., Y. Xie, K. Pan, 和 K. Feng. 2020\. “关于差分隐私机器学习的综述。” *IEEE 计算智能杂志* 15 (2): 49–64.

Groves, R. M., F. J. Fowler, M. P. Couper, J. M. Lepkowski, E. Singer, 和 R. Tourangeau. 2009\. *调查方法*. Wiley.

Humble, J., and D. Farley. 2011\. *持续交付*. Addison Wesley.

Hunt, E. 2016\. *泰，微软的 AI 聊天机器人，从推特上接受了种族主义的速成课程*. [`www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter`](https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter).

Kenett, R. S., and T. C. Redman. 2019\. *数据科学的真实工作*. Wiley.

Khan, W. Z., E. Ahmed, S. Hakak, I. Yaqoob, and A. Ahmed. 2019\. “边缘计算：综述.” *未来计算机系统* 97: 219–35.

Kuhn, M., and K. Johnson. 2013\. *应用预测建模*. Springer.

Li, J., X. Chen, E. Hovy, and D. Jurafsky. 2016\. “在自然语言处理中可视化和理解神经网络模型.” 在 *2016 年北美计算语言学协会分会会议：人机语言技术* 论文中, 681–91\. 计算语言学协会.

Li, Q., Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He. 2021\. “联邦学习系统综述：数据隐私和保护愿景、炒作和现实.” *IEEE 知识和数据工程 Transactions* 早期发布.

Linardatos, P., V. Papastefanopoulos, and S. Kotsiantis. 2021\. “可解释人工智能：机器学习可解释性方法的综述.” *熵* 23 (1): 18.

Lohr, S. L. 2021\. *抽样：设计和分析*. 第 3 版. CRC Press.

Lundberg, S. M., and S.-I. Lee. 2017\. “一种统一的方法来解释模型预测.” 在 *神经信息处理系统（NIPS）的进展* 中, 4765–74.

Mehrabi, N., F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan. 2021\. “机器学习中的偏差和公平性综述.” *ACM 计算机调查* 54 (6): 115.

Montgomery, D. C. 20AD. *实验设计和分析*. 第 10 版. Wiley.

Narayanan, A., and V. Shmatikov. 2008\. “大型稀疏数据集的鲁棒去匿名化.” 在 *IEEE 安全与隐私研讨会论文集* 中, 111–25.

ONNX. 2021\. *开放神经网络交换*. [`github.com/onnx/onnx`](https://github.com/onnx/onnx).

Ousterhout, J. 2018\. *软件设计的哲学*. Yaknyam Press.

PagerDuty. 2022\. *PagerDuty：上线即金钱*. [`www.pagerduty.com/`](https://www.pagerduty.com/).

Papernot, N., P. McDaniel, A. Sinha, and M. P. Wellman. 2018\. “SoK：机器学习中的安全和隐私.” 在 *IEEE 欧洲安全与隐私研讨会论文集* 中, 399–414.

Paszke, A., S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, et al. 2019\. “PyTorch：一种命令式风格、高性能深度学习库.” 在 *神经信息处理系统（NIPS）的进展* 中, 32:8026–37.

Prometheus 作者，以及 Linux 基金会. 2022\. *Prometheus：监控系统和时间序列数据库*. [`prometheus.io/`](https://prometheus.io/).

Ribeiro, M. T., S. Singh, 和 C. Guestrin. 2016. “为什么我应该相信你？解释任何分类器的预测.” 在 *第 22 届 ACM SIGKDD 国际知识发现和数据挖掘会议论文集*，第 1135–44 页. ACM.

Scikit-learn 开发者. 2022. *Scikit-learn: Python 中的机器学习*. [`scikit-learn.org/`](https://scikit-learn.org/).

Sculley, D., G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary, 和 M. Young. 2014. “机器学习：技术债务的高息信用卡.” 在 *SE4ML: 机器学习的软件工程 (NIPS 2014 工作坊)* 中.

Scutari, M. 和 J.-B. Denis. 2021. *带有 R 示例的贝叶斯网络*. 第 2 版. Chapman & Hall.

.Seven, D. 2014. *《骑士噩梦：DevOps 警示故事》*. [`dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/`](https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/).

Sherman, E. 2022. *Zillow 失败算法对数据科学未来的影响*. [`fortune.com/education/business/articles/2022/02/01/what-zillows-failed-algorithm-means-for-the-future-of-data-science/`](https://fortune.com/education/business/articles/2022/02/01/what-zillows-failed-algorithm-means-for-the-future-of-data-science/).

Simonyan, K., A. Vedaldi, 和 A. Zisserman. 2014. “卷积网络的内部：可视化图像分类模型和显著性图.” 在 *第 2 届国际学习表示会议 (ICLR) 工作坊轨道* 中.

Sonatype. 2022. *Nexus 仓库管理器*. [`www.sonatype.com/products/nexus-repository`](https://www.sonatype.com/products/nexus-repository).

TensorFlow. 2021b. *TensorFlow Extended (TFX)*. [`www.tensorflow.org/tfx/`](https://www.tensorflow.org/tfx/).

The Fluentd Project. 2022. *Fluentd: 开源数据收集器*. [`www.fluentd.org/`](https://www.fluentd.org/).

Thomas, D. 和 A. Hunt. 2019. *《实用程序员：你的精通之旅》*. 周年纪念版. Addison-Wesley.

Tornhill, A. 和 M. Borg. 2022. “代码红色：代码质量对业务的影响：对 39 个专有生产代码库的定量研究.” 在 *国际技术债务会议论文集*，第 1–10 页.

Wu, X., L. Xiao, Y. Sun, J. Zhang, T. Ma, 和 L. He. 2022. “机器学习中的闭环：综述.” *未来计算机系统* 135: 364–81.

Xin, D., L. Ma, J. Liu, S. Song, 和 A. Parameswaran. 2018. “加速闭环机器学习：挑战与机遇.” 在 *端到端机器学习数据管理第二次研讨会论文集*，第 1–4 页.

Zheng, A. 2015. *评估机器学习模型*. O’Reilly.

* * *

1.  通过“传统软件”，我们指的是任何与分析、数据科学或机器学习无关的软件。↩︎

1.  语言的选择通常由编排软件决定。然而，由于其可读性、可移植性和成熟度，YAML 正成为事实上的标准。↩︎

1.  在软件工程中，“pipeline”一词用来指代开发和交付软件的过程：CI/CD 就是一个 pipeline。在这本书中，我们用它来指代开发和部署机器学习模型的软件基础设施，以及扩展到构建和运营该过程。↩︎
