# 第一章 这本书是关于什么的？

> 原文：[`ppml.dev/intro.html`](https://ppml.dev/intro.html)

现代数据分析的实践是由许多学科的汇聚所塑造的，每个学科都有其自己的历史：信息理论、计算机科学、优化、概率和统计学等。机器学习和数据科学可以被认为是它们的最新形态，继承了过去被称为“数据分析”的衣钵。软件工程应被视为这个列表中的关键补充。为什么我们需要它来高效有效地实施现代数据分析？

## 1.1 机器学习

机器学习有许多定义。广义上讲，它是一门旨在创建计算机系统和算法的学科，这些系统和算法可以在没有（或较少）人类监督的情况下学习现实的结构化表示，以便与之互动（Russell 和 Norvig 2009)。在光谱的一端，我们可以将其视为一种狭义的人工通用智能版本，我们希望我们的计算机系统能够独立学习智力任务并将它们推广到新的问题，就像人类一样。在光谱的另一端，我们可以将机器学习视为学习概率模型的能力，这些模型提供了对特定现象的简化表示，以执行特定任务（Ghahramani 2015)，例如预测感兴趣的结果（监督学习）或发现数据中的有意义模式（无监督学习）。在这两个极端之间，存在专家系统（Castillo, Gutiérrez, 和 Hadi 1997)，它们“捕捉了专家在特定领域思考和推理的能力”，并能提供“对一个不完整指定问题的有意义答案。”

广义上讲，为了做到这一点：

1.  我们需要一个描述任务及其环境、计算机可以理解的世界工作模型。

1.  我们需要一个目标：我们如何衡量模型的性能？因为这是我们优化的目标！通常，这是预测新事件的能力。

1.  我们将我们对世界的知识编码，从训练数据、专家或两者中获取信息。

1.  计算机系统使用模型作为现实的代理，随着新输入的到来，进行推理并决定是否以及如何执行分配的任务。

![按信息来源分组的数据分析方法：数据或模型者做出的假设。](img/47b1fcf345d2602e495775c4af2bab7a.png)

图 1.1：按信息来源分组的数据分析方法：数据或模型者做出的假设。

这些元素的确切形式将取决于我们试图表示的领域以及我们将使用的模型。机器学习在其核心上，是一系列来自优化、统计学、概率和信息理论中的模型和算法的集合，它们处理抽象问题：从简单的线性回归模型（Weisberg 2014），到贝叶斯网络（Scutari and Denis 2021），再到更复杂的模型，如深度神经网络（Goodfellow, Bengio, and Courville 2016）和高斯过程（Rasmussen and Williams 2006）。这些算法可以应用于各种领域，从医疗保健（van der Schaar et al. 2021）到自然语言处理（Aggarwal 2018）和计算机视觉（Voulodimos et al. 2018），其中某些算法和领域的组合可能比其他组合效果更好。

在经典统计学中（图 1.1，右下角），分析数据需要模型师指定生成这些数据的概率模型，以便从有限的数据点中得出推论。这样的模型必然具有简单的结构，原因有两个：因为模型师必须手动解释它们的属性和输出，以及由于缺乏任何实质性的计算能力来估计它们的参数。这种方法将所有负担都放在了模型师身上：模型的大部分效用将来自于模型师将他所建模的内容提炼成简单数学的能力，以及将任何可用的先验信息纳入模型结构的能力。结果是，现代统计学早期部分强调封闭形式的结果、低阶近似和渐近性。

然而，有许多现象无法以这种方式进行研究。首先，当手动构建模型时，人类模型师在编码复杂行为方面的能力是有限的。这些限制很容易被涉及大量变量或变量之间非线性的、不很规则或事先未知的交互作用的现象所超过。其次，可能没有足够的信息来甚至尝试构建一个概率模型。第三，将我们的模型选择限制在可以写成封闭形式的模型，以便模型师可以手动拟合、解释和使用它们，而不需要显著使用计算能力，并不一定确保这些模型易于解释。例如，有许多关于解释逻辑回归（Mood 2010；Ranganathan, Pramesh, and Aggarwal 2017）的记录，这可能是实现分类的最简单方式。

贝叶斯统计的经典应用（图 1.1，右上角）解决了这些局限性中的某些问题。建模者仍然需要构建一个涵盖数据和它们行为的任何先验信念的模型，但后验概率可以通过马尔可夫链蒙特卡洛（MCMC）算法进行估计。

相比之下（Breiman 2001b），算法方法将负担从建模者转移到了数据收集和计算机软件（图 1.1，左上角）。建模者在构建概率模型中的作用受到限制，并且大部分被一个通过大量数据筛选的计算机系统所取代：因此得名“机器学习”。模型的架构是从数据中学习的，几乎没有关于其外观的限制。例如，神经网络和高斯过程是通用逼近器。几乎所有的信息都来自数据，而不是由建模者通过先验信息进行中介，这就是为什么机器学习方法对数据如此渴求。

## 1.2 数据科学

数据科学同样是以数据驱动（图 1.1，左上角），但专注于从原始数据中提取洞察力并以图形方式呈现，以支持基于原则的决策制定。Kenett 和 Redman（Kenett and Redman 2019）这样描述它：“数据科学家的真正工作涉及帮助人们在近期内就重要问题做出更好的决策，并在长期内建立更强大的组织”。这需要数据科学家在商业的所有领域都有强烈的参与，将重点从计算机系统转移到人。尽管如此，数据科学家使用统计和机器学习模型作为获得这些洞察力的手段。

与经典统计学相比，当数据丰富（大数据！（Katal, Wazid, and Goudar 2013））时，我们实际上并不需要从先验知识中构建它们的生成过程。数据包含足够的信息，让我们“让他们为自己发声”并获得有用的洞察力，这是我们主要感兴趣的东西。当然，专家的先验信息仍然有用：包含它的模型往往能更好地产生可操作的洞察力。

因此，数据科学非常重视数据质量，这在处理来自多个来源（数据融合）或非表格数据（自然语言处理和计算机视觉）时往往是有问题的。数据通常定义不清，简单错误，或者最终与收集它们的目的无关。专家知识对于评估它们、整合它们以及在可能的情况下修复它们至关重要。机器学习也广泛应用于文本和图像，但直到最近，主要关注建模它们的隐藏结构，那时可解释性成为了一个热门话题（例如，参见 Li et al. 2016; Simonyan, Vedaldi, and Zisserman 2014)。

计算机系统对于数据科学至关重要，尽管在机器学习中的角色不同。存储和访问大量数据，交互式地探索它们，构建分析它们的软件管道，处理由此产生的峰值工作量：这些都是需要复杂地使用硬件和软件的任务。

## 1.3 软件工程

软件工程是对软件生命周期所有阶段的系统应用良好的工程原则：设计、开发、维护、测试和评估（van Vliet 2008）。其核心原则是掌握开发大型软件固有的复杂性，这些软件是可靠且高效的；是可用的，并且可以随着时间的推移而发展；并且在成本和努力方面都是可行的（Ousterhout 2018)。

软件工程的早期定义建议我们将它视为一个像土木工程这样的传统工程学科。结果是*瀑布模型*（Royce 1987），它将软件开发描述为从收集需求开始，以部署最终产品结束的一系列步骤。然而，现代实践认识到，这个模型在几个方面是有缺陷的。首先，土木工程源于并受物理定律的约束，而我们在开发软件时创造了自己的世界，有自己的规则；这些规则会随着时间的推移而改变，物理定律则不会。其次，软件旨在执行的任务会随着时间的推移而改变，我们对这个任务的定义也会随之改变。土木工程主要处理定义明确的问题，这些问题在项目持续期间保持明确。最后，在大型建筑完成后对其进行修改是非常困难的，但我们通常会对软件这样做。软件生命周期的大部分工作通常是在维护和演进它。

![软件开发生命周期阶段的示意图](img/f18887b0ce6e7fa7f6992fea404e8480.png)

图 1.2：软件开发生命周期阶段的示意图。

当前的软件工程实践持相反的观点，认为软件开发是一个开放式的（“软件永远不会完成”）、迭代的（“软件生命周期”）过程：这是“敏捷宣言”的核心（Beck 等人 2001）。从高层次来看，它组织结构如图 1.2 所示：一个持续的循环，包括规划、分析、设计、实施、测试和维护。软件的设计受到其运行领域的强烈影响（领域驱动开发，Evans 2003）。它使用测试（测试驱动开发，Beck 2002）、重构（Fowler 2018）和持续集成（Duvall, Matyas, 和 Glover 2007）来整合新功能、及时修复错误并保持代码“整洁”。诚然，所有这些方法都被吹捧为银弹，以至于它们变成了时髦词汇，而且它们的实际实施往往扭曲了它们，使得软件开发变得更糟。然而，敏捷的关键思想是值得称道的，我们将在本书中讨论并适度应用它们。它们非常适合构建机器学习管道的结构，这些管道建立在可变模型和输入数据组合的基础上。

## 1.4 它们是如何结合在一起的？

计算在机器学习和数据科学中的核心地位使得软件工程实践在现代数据分析中变得至关重要：大部分工作都是由计算机系统完成的，这些系统由软件驱动。¹ 编码数据、高效存储和检索数据、实现机器学习模型、将它们与其他系统连接起来：这些任务中的每一个都足够复杂，只有良好的工程实践才能确保我们整体工作的正确性。这在学术研究和工业应用中都是真实的，不同的方式。正如 Kenett 和 Redman（Kenett 和 Redman 2019）所说，用汽车类比：

> “如果数据是新的石油，技术就是新的引擎。引擎驱动汽车，没有技术进步，数据和分析驱动的转型将不可能实现。技术包括数据库、通信系统和协议、支持数据存储和处理的软件应用，以及驱动这一切的原始计算能力（其中大部分现在在云端）。”

在学术界，普遍认为新颖方法的软件实现可以被视为“一次性脚本”。“我们只需要运行一次来写这篇论文，重构和重新设计它没有意义。”这是一种令人沮丧的常见观点。同样，不共享代码以“保持竞争优势”。然而，使用机器学习的科研和应用论文依赖于它们所使用的软件质量，因为：

1.  模型本身往往是黑盒，其数学行为并不完全为人所理解（第 9.2 节）。

1.  数据足够复杂，以至于来自这些领域的专家也难以完全解释它们（第 9.1 节）。

如果我们不完全理解数据和模型，那么在软件中找出问题就变得非常困难：软件中的意外行为可能被误认为是数据或模型本身的特性。因此，通过应用我们所能利用的所有最佳工程实践来最小化这种情况的发生是至关重要的。过去和现在未能做到这一点导致了诸如药物研究（Prinz, Schlange, 和 Asadullah 2011，20-25% 可重复）、比较心理学（Stevens 2017，36% 可重复）、金融（Chang 和 Li 2015，43% 可重复）和计算神经科学（Miłkowski, Hensel, 和 Hohol 2018，只有 12% 的论文提供了数据和代码）等众多领域普遍存在的“可重复性危机”。机器学习和人工智能研究也处于类似的不幸状态：“当原始作者向可重复性研究者提供帮助时，85% 的结果被成功重复，而作者没有回应时，只有 4% 的结果被成功重复” (Pineau 等人 2021) *确实*表明还有改进的空间。幸运的是，近年来科学家们普遍接受这是一个问题（Nature 2016)，机器学习社区也达成了一些关于如何应对这一问题的共识（Tatman, VanderPlas, 和 Dane 2018)。

在工业界，糟糕的工程会导致实际和计算性能降低，以及技术债务的快速积累（Sculley 等人 2015，以及第 5.2 节）。糟糕的数据工程可能不会以可用的形式包含我们正在寻找的信息；未良好打包的模型可能部署缓慢且难以回滚；数据可能包含偏差，或者随着时间的推移以使模型无声失败的方式变化；或者机器学习软件可能成为一个难以解释的黑盒，其输出无法解释，使得故障排除变得不可能。

总结来说，我们认为坚实的机器学习应用和研究建立在三个支柱之上：

1.  机器学习的基础（数学、概率、计算机科学），它们为模型的有效工作提供保证。

1.  软件工程，它为模型实现的有效性和效率提供保证。

1.  数据的质量，从特征、大小、公平性以及它们是如何收集的方面来看。

在这本书中，我们将专注于软件工程方面，简要地涉及一些数据方面。我们不会讨论机器学习的理论或方法论方面，这些方面在迄今为止出版的大量专业文献中已有更好的覆盖（例如，Hastie、Tibshirani 和 Friedman 2009；Russell 和 Norvig 2009；Goodfellow、Bengio 和 Courville 2016；Gelman 等人 2013；Rasmussen 和 Williams 2006 以及许多其他人）。
