# 第八章 记录管道

> 原文：[`ppml.dev/documenting-code.html`](https://ppml.dev/documenting-code.html)

理想情况下，我们编写的代码应该是自我解释的：每个人都应该能够仅通过阅读就能理解其工作原理以及为什么以这种方式实现。在实践中，即使我们尽力使代码尽可能清晰（第六章），对于任何具有一定规模的现实世界代码库来说，实现这一目标也是不可能的。因此，我们需要*文档*：对机器学习系统和与其一起演变的管道的活生生的、自然语言解释。

文档不是一个单一实体，而是一系列具有不同范围、详细程度、技术水平和受众的信息集合：注释解释代码的不同部分“是什么”以及特别是“为什么”（第 8.1 节）；描述每个模块的公共接口及其使用方法的文档（第 8.2 节）；对管道的整体结构和其部分如何相互配合的描述（第 8.3 节）；详细说明已经实现哪些机器学习模型以及为什么实现，以及它们解决的业务或学术需求（第 8.4 节）。为了补充这些信息，我们应该展示我们如何设想机器学习管道将在实际日常操作中应用（第 8.5 节）。

## 8.1 注释

软件工程师们对于在代码中包含注释的需求、注释的频率和内容并没有达成共识。有些人认为“注释充其量是必要的恶……用以弥补我们在代码中表达自己的失败”（马丁 2008）；有些人认为“注释过多和过少一样糟糕，你可以通过经济的方式达到一个中间地带”（麦康奈尔 2004）；还有其他人认为“好的代码有很多注释……将低级知识保留在代码中，它属于的地方，并将注释留给其他，高级的解释”（托马斯和亨特 2019）。唯一大家一致认同的是，注释可能会随着时间的推移而变得过时，因为它们所引用的代码会发生变化，以及那些不提供任何额外信息的注释是多余的。

机器学习管道可以从三个不同的角度进行推理（第 5.3.1 节）：它们操作的领域，例如生成要处理的数据的商业运营或学术领域；软件架构，即组织软件为独立的模块的工程努力，这些模块可以高效地工作，并且具有明确的目的；以及通过它们的概率属性为它们提供动力的模型。这些角度之间的相互作用决定了低级和高级设计决策，这些决策在代码中很难表示。我们选择机器学习模型时考虑它们将要处理的数据的特征；性能优化（第 2.2 节和 2.4 节）可能（或可能不）值得，这取决于模型和计算系统的组合；并且我们努力将软件结构化为模块（第 5.3 节）和数据结构（第 3.3 节和 3.4 节）的努力必须协调表示抽象数学概念和现实世界领域概念的冲突目标。

因此，关于注释应该专注于通过说明“为什么”（例如，特定设计决策的理由以及非显而易见的低级优化如何工作以及为什么需要它们）来补充代码，而代码本身应该用来说明“是什么”（例如，产生函数输出的步骤序列）的想法，在企业和学术软件中都要比这更加微妙。在这两种情况下，现代开发实践确保领域专家和软件工程师对关键领域概念有一个共享的概念模型，并在这样做的过程中，建立一个*通用语言*（Evans 2003)来识别和讨论它们。这种语言贯穿于所有文档和代码（命名类、方法和变量）中，以便所有相关人员都能对代码所做之事的“是什么”和“为什么”有一个共同的理解。然而，在机器学习软件的背景下建立这样的通用语言是困难的（第 6.2 节），因为涉及人员的背景更加多样化：在任何给定时间，很少有人有足够广泛的背景，能够从领域、软件和机器学习角度很好地理解机器学习系统和软件。领域（数据）分析师（领域 + 机器学习）和机器学习工程师（软件工程 + 机器学习）等专业人物的出现，可以从两个不同的角度工作，部分是对这一问题的回应。

因此，我们认为在代码中添加注释，描述“是什么”和“为什么”，虽然是从与代码编写不同的角度出发，但这样做是有价值的。实现模型的代码（第 5.3.4 节）应该结构良好，以便机器学习工程师能够清楚地理解其行为：注释应侧重于模型的参数及其输出如何映射到领域概念，并且也可以说明为了优化模型以适应计算系统的硬件而使用特定数据结构的原因。预处理机器学习管道输入的代码（第 5.3.3 节）和为第三方消费其输出的后处理代码（第 5.3.5 节和第 5.3.6 节）应该对领域专家来说是清晰的，因为这只是将领域概念编码到数据结构中，反之亦然；但值得注释的是，我们期望这些输入和输出具有的统计特性，并将它们与它们产生的或输入到其中的机器学习模型联系起来。最后，协调管道中模块的代码（无论是直接还是通过配置第三方 MLOps 解决方案，见第 5.3 节）应从领域和机器学习两个角度都是清晰的，因为它是在领域工作流程之后设计的用于数据处理管道中连接不同模型。然而，特定模型的算法复杂性和运行模型的计算系统的硬件特性可能会影响代码如何组织成模块以及模块之间如何相互连接，这些应该被记录下来，因为它们可能并不明显。

除了这些，关于如何编写注释的建议（Ousterhout 2018；Fowler 2018；Thomas and Hunt 2019；Evans 2003）同样适用于机器学习软件。注释的目标是确保软件的结构和行为对读者来说是显而易见的：其他开发者，以便他们可以快速且自信地修改代码，以及用户，以便他们可以理解并适当地使用它。读者最终可以通过阅读代码来推断这样的信息，但这个过程会耗费时间且容易出错：尤其是当他们从与代码编写者不同的角度接近代码时。注释应该简短且靠近代码：例如，在执行特定任务的代码块前加上对考虑的实现问题和塑造它的概率结果的描述。（这也有助于将测试与代码联系起来，见第 9.4.2 节。）不属于代码中任何单一位置的信息可能可以在提交信息中找到，如第 6.5 节所述。它们应该在代码之前或与代码同时编写，以确保它们首先被编写，并且任何设计问题都仍然在开发者的脑海中是新鲜的。出于同样的原因，每当代码被修改时，它们应该与代码一起更新。这种方法也可能有助于在早期就完善代码架构（见 5.3.1 和 5.3.2 节），通过使讨论不同设计的优缺点变得更容易，并允许领域专家在一定程度上查看关键领域概念的实现。最后，在代码和注释中从不同角度表达相同的思想，可以带来与代码审查（见 6.6 节）相似的好处，因为它迫使开发者从软件用户的角度重新思考他们正在做的事情。

## 8.2 记录公共接口

除了增强函数和模块内部的代码块外，我们还应该使用注释来记录模块接口、它们的方法以及它们的一般行为。特别是，每个模块都应该包含一个高级描述，说明它做什么以及何时使用它是合理的。这两者都应该从潜在用户的角度来写：在抽象复杂性和减少认知负担的精神下，用户应该能够在不阅读其实施细节的情况下使用该模块（Ousterhout 2018）。如前所述，从事和使用机器学习管道工作的人来自各种背景，许多人可能难以阅读与他们自身视角相差甚远的代码。因此，模块接口前面的注释应该从所有相关角度描述它们，以便它们像其他注释一样易于接近（第 8.1 节）。这些描述，连同方法签名，应该提供有关模块的所有必要信息：方法及其参数的含义，以及它们可能具有的任何约束、副作用和先决条件。如果我们发现很难以清晰简洁的方式将这些信息写成文字，那么可能是因为接口不是一个好的抽象，该模块应该被重构（第 6.7 节）以赋予它更好的目的感。描述它的文档也应同时更改，以保持最新。

以类似的方式记录单个函数可能对那些不完全封装在单个模块内的少数函数有意义。其他函数要么对模块用户不可见，因此它们只需要按照该模块的开发者所需的方式进行记录；要么对模块用户可见，并且它们应该在其方法中记录。

为了使此类文档与所引用的代码保持紧密，以便更容易保持两者同步，我们可以为每个模块添加一个包含上述信息的长格式注释。这些注释应采用标准格式，可能还有额外的内部约定，以确保一致性并使编写它们更加直接。例如，Doxygen（van Heesch 2022）可以强制所有在机器学习管道中通常找到的编程语言的注释格式（即 C、R 和 Python），这很方便，因为不同的模块可能用不同的语言实现（第 6.1 节）。它们还可以从注释生成常见的格式文档，如 HTML、PDF 和 DOCX。这对于在接口更改时保持文档更新特别方便，因为我们只需更新注释和代码，并在需要时重新生成这些文档。如果机器学习管道中任一语言占主导地位，我们还可以使用特定语言的工具，如 R 中的 Roxygen（Wickham, Danenberg, et al. 2022）或 Python 中的 Sphinx（Brandl and the Sphinx Team 2022）。

实际上我们应该在这些长格式注释中写些什么？

1.  我们可以期待从模块中获得什么：方法的签名、其语义以及在成功和失败场景中的行为。这包括导出变量的含义和数据类型，以及所有可能的错误条件及其处理方式。

1.  该模块解决了什么问题，以及为什么以这种方式设计它的简要概述。这可能包括对已评估和舍弃的替代解决方案的讨论（第 5.3.1 节），以避免在除非我们以根本方式更改模块的情况下重新评估它们。然而，此类决策通常跨越模块边界，并在架构文档（第 8.3 节）中更好地记录。

1.  模块的使用简例，可能与其他模块结合使用，也是很有用的。

1.  指向技术文档相关部分的链接（第 8.4 节）以及描述模块中使用的算法的书籍或论文。

流行的开源机器学习软件提供了许多如何做好这件事的示例。以 Scikit-learn 为例。我们可以通过其网站首页上的一个标记为“API”的链接访问其模块接口的文档（Scikit-learn Developers 2022）。所有模块都按字母顺序列出，从`sklearn.base`一直到`sklearn.utils`。对于每一个模块，我们都有一个简短的描述，总结它实现了哪些算法、模型或通用功能，提供了指向详细文档的链接，这些文档提供了更多细节并展示了典型的使用模式，以及它导出的所有属性和函数的列表。每个类的文档页面进一步详细说明了其方法和它们的参数，以及它导出的任何变量。所有这些文档都是由 Sphinx 从 Scikit-learn 代码中的注释生成的。包含注释的源文件链接在每个页面上，这使得探索页面描述的代码变得容易。

![Sphinx 从 Scikit-learn 的 DBSCAN 模块注释中生成的在线文档的简略版](img/259eef0937fcf1ecc0ddef18f04139b6.png)

图 8.1：Sphinx 从 Scikit-learn 的 DBSCAN 模块注释中生成的在线文档的简略版。

例如，考虑实现 DBSCAN 聚类算法的模块的文档（Schubert 等 2017）。在线文档如图 8.1 所示。模块描述由 Sphinx 生成的注释出现在其声明之前，并用三重双引号（`"""`）包围。部分标题由十个短横线（`-----------`）标记，参数和属性的列表使用缩进来格式化。

```py
class DBSCAN(ClusterMixin, BaseEstimator):
 """Perform DBSCAN clustering from vector array or distance
 matrix.

 DBSCAN - Density-Based Spatial Clustering of Applications with
 Noise. Finds core samples of high density and expands clusters
 from them. Good for data which contains clusters of similar
 density.

 Read more in the :ref:`User Guide <dbscan>`.

 Parameters
 ----------
 eps : float, default=0.5
 [...]

 Attributes
 ----------
 core_sample_indices_ : ndarray of shape (n_core_samples,)
 [...]

 See Also
 --------
 OPTICS : A similar clustering at multiple values of eps. Our
 implementation is optimized for memory usage.

 Notes
 -----
 [...]

 References
 ----------
 [...]

 Examples
 --------
 [...]
 """
```

“注释”部分提供了更多示例，并说明了 DBSCAN 的计算复杂性（第四章），补充了指向 OPTICS 模块中类似功能的指针以及用户指南中对 DBSCAN 工作原理的通俗解释。

此外，DBSCAN 的文档提供了一个所有导出方法的列表，以及每个方法实现的内容的简短描述，它的参数（包括它们的类型和默认值）以及它的返回值。例如，生成`fit()`方法文档的注释如下。

```py
def fit(self, X, y=None, sample_weight=None):
 """Perform DBSCAN clustering from features, or distance matrix.
 Parameters
 ----------
 X : {array-like, sparse matrix} of shape (n_samples, \
 n_features), or (n_samples, n_samples)
 Training instances to cluster, or distances between instances
 if ``metric='precomputed'``. If a sparse matrix is provided,
 it will be converted into a sparse ``csr_matrix``.
 y : Ignored
 Not used, present here for API consistency by convention.
 sample_weight : array-like of shape (n_samples,), default=None
 Weight of each sample, such that a sample with a weight of at
 least ``min_samples`` is by itself a core sample; a sample
 with a negative weight may inhibit its eps-neighbor from
 being core. Note that weights are absolute, and default to 1.
 Returns
 -------
 self : object
 Returns a fitted instance of self.
 """
```

不幸的是，注释将函数参数与底层模型和算法的参数混淆：这并不理想，因为它暗示它们可以相互替换地推理（例如，对于浮点变量来说这不是真的，参见第 3.1.2 节），并且因为它暗示函数参数应该一对一地映射到参数（这完全取决于机器学习管道的结构，特别是参见第 5.2.3、5.2.4 和 5.3.4 节）。然而，从好的方面来看，它指定了所有参数的预期类型，这对于 Python 这样的动态类型语言中的模块用户来说是一个有用的细节。可以使用类型检查器（如 mypy2014）强制执行类型，从而有效地将 Python 转换为具有类型注解的静态类型语言。

在大规模文档接口的一个例子是 CRAN（CRAN 团队 2022）用于分发和执行 R 包质量标准的架构。每个包在 CRAN 网站上都有一个专门的网页，其中包括该包提供的功能的简要描述，以及指向其变更日志、相关网页和参考手册的链接。其条目遵循基于 LaTeX 子集的“R 文档”格式，具有预定义的章节（“描述”、“参数”、“细节”、“示例”、“参考文献”），包作者必须为从包中导出的每个函数填写这些章节。R 文档文件可以通过在代码中包含 Doxygen 格式的注释并使用 Roxygen 进行处理来生成：CRAN 不要求这样做，但它会交叉检查函数名称和参数在代码和文档之间的一致性，并执行所有示例以确保它们可以运行。此外，CRAN 在其网页上报告了与包一起分发的任何测试的状态。包的网页还链接到长篇文档，这些文档提供了有关相关算法和模型的更多详细信息，并通过综合示例展示它们。这些长篇文档被称为*vignettes*，它们是混合了 R 代码和 Markdown 或 LaTeX 文本的笔记本，其源代码是包的一部分。CRAN 将编译它们，以便与包源代码一起提供。

包含所有这些类型文档的流行 R 包是 rstanarm（Muth, Oravecz 和 Gabry 2018），它实现了在 Stan（Carpenter 等人 2017）之上的贝叶斯回归模型集。作者提供了参考手册和一系列示例说明如何使用它。它在 CRAN 上的网页链接了 GitHub 仓库，我们可以轻松地看到参考手册是从中创建的 Doxygen 注释。例如，`stan_mvmer()`函数前的注释如下。

```py
#' Bayesian multivariate generalized linear models with correlated
#' group-specific terms via Stan
#'
#' Bayesian inference for multivariate GLMs with group-specific
#' coefficients that are assumed to be correlated across the GLM
#' submodels.
#'
#' @export
#' [...]
#'
#' @param formula A two-sided linear formula object describing both
#'   the fixed-effects and random-effects parts of the longitudinal
#'   submodel similar in vein to formula specification in the
#'   \strong{lme4} package (see \code{\link[lme4]{glmer}} or the
#'   \strong{lme4} vignette for details). [...]
#' [...]
#' @param data A data frame containing the variables specified in
#'   \code{formula}. For a multivariate GLM, this can be either a
#'   single data frame which contains the data for all GLM
#'   submodels, or it can be a list of data frames where each
#'   element of the list provides the data for one of the GLM
#'   submodels.
#' [...]
#'
#' @details The \code{stan_mvmer} function can be used to fit a
#'   multivariate generalized linear model (GLM) with group-specific
#"   terms. The model consists of distinct GLM submodels, each which
#'   contains group-specific terms; within a grouping factor (for
#'   example, patient ID) the grouping-specific terms are assumed
#'   to be correlated across the different GLM submodels. It is
#'   possible to specify a different outcome type (for example a
#'   different family and/or link function) for each of the GLM
#'   submodels. [...]
#'
#' @return A \link[=stanreg-objects]{stanmvreg} object is returned.
#'
#' @seealso \code{\link{stan_glmer}}, \code{\link{stan_jm}}, [...]
#'
#' @examples
#' [...]
```

Doxygen 注释可以通过每个行首的单引号来识别。第一段给出了参考手册中该函数条目的标题，该标题被`@export`声明为公共的。第二段是“描述”，`@params`是“参数”，而`@return`描述了函数的返回值。在`@details`之后的文本最终会出现在“详细信息”部分，而`@examples`之后的代码提供了简短的示例。

长篇示例和过于繁琐而无法包含在参考手册中的技术讨论以一系列示例的形式提供，对于 rstanarm 来说，这些示例是 R Markdown 文档。与参考手册不同，示例可以包含 LaTeX 排版的图表和数学公式，并且可以使用 knitr 包（Xie 2015）轻松地将它们转换为 PDF、HTML 和 DOCX 文档。R Markdown 格式与纯 Markdown 的不同之处仅在于其 YAML 标题，它告诉 knitr 文件应该编译成哪种类型的文档以及一些元数据。例如，在`glmer.Rmd`中：

```py
---
title: "Estimating Generalized (Non-)Linear Models with" >
 "Group-Specific Terms with rstanarm"
author: "Jonah Gabry and Ben Goodrich"
date: "`r Sys.Date()`"
output:
 html_vignette:
 toc: yes
---
```

代码块由三个反引号分隔，后跟语言标签（在这种情况下是 R）以及 knitr 在编译文档时将评估的选项列表。

```py
```{r, results = "hide"}\n',

post1 <- stan_nlmer(circumference ~ SSlogis(age, Asym, xmid, scal)

~ Asym|Tree,

data = Orange, cores = 2, seed = 12345, init_r = 0.5)

```py
```

注意，默认情况下，knitr 在每次编译文档时都会执行所有代码，按照它们出现的顺序。因此，我们不会遇到影响 Jupyter 笔记本（Project Jupyter 2022）（第 10.2.2 节）的执行顺序不一致和状态不一致的问题。

## 8.3 记录架构和设计

架构文档将各个模块的公共接口文档结合起来，从而提供一个整体视图，展示机器学习系统和流水线是如何作为一个整体来构建的。它总结了在设计时所做的决策的合理性，它们的（硬件和软件）组件的性质及其相互作用，以及它们如何与流水线的要求（Clements 等人 2011)（第 5.3.1 节）相关。所有这些都应该用与注释和模块接口文档相同的通用语言来编写，并且出于相同的原因：架构是评估流水线和底层系统工作方式、它们是否可以以特定方式修改以及它们是否满足当前或新要求的首要手段。这些活动必然涉及领域专家、软件工程师和机器学习专家之间的讨论，而这些讨论从通用语言带来的清晰性中受益匪浅。特别是，架构文档应该记录所有那些不属于任何单个模块接口文档的跨模块设计决策：一个典型的例子是胶水代码的设计和工作原理（第 5.2.3 节和 9.2.4 节），这通常是机器学习流水线中最少文档化的部分。

记录机器学习流水线的架构和设计的一个自然起点是描述其执行路径的 DAG（第 5.3 节）。DAG 中的节点代表实现数据经过的不同处理阶段的模块，它们在流水线中的角色解释应该链接到相应的接口文档。节点之间存在的弧线表明相应的模块已被设计为可互操作的，使其成为可能的设计决策也应予以记录。此外，弧线确定了处理阶段的时序，可能与事件触发器（例如，当模型可用时拉取更新模型）、计划任务（例如，在获得一定量的新数据后重新训练模型）或人工输入（例如，用于模型验证）相关联。适应尚未以 DAG 中弧线形式明确表达的未来需求可能影响了模块接口的设计，这些考虑也应予以记录。

然而，这只是我们可以描述机器学习管道的可能视角之一。其设计可能受到它运行的本地和远程计算系统的组合的影响，或者它可能在未来运行，因为各个模块将有不同的需求（第 2.4 节）。管道的整体功能如何结构化成模块可能受到其运营的领域或业务的影响。例如，一个使用计算机视觉来支持临床医生从医学图像中诊断疾病（如第 8.5 节中的用例示例）的机器学习管道可能具有类似于不同专家执行的任务和诊断过程中的临床信息进展的 DAG 模式。或者，在商业环境中，管道的不同部分可能由公司内部的不同部门监督，有明确的边界以避免因人员和预算原因而重叠。模型和各种算法在概率层面的相互作用为机器学习管道提供了一个更全面的视角，作为一个总体上、层次化的模型，其组件可能与代码组织成模块的方式有关或无关。

对机器学习管道的架构及其背后的设计决策进行彻底的文档记录将自然地包括一系列从不同角度撰写的文档，以提供不同的概念视图。在所有文档中使用普遍语言（第 8.1 节）将有助于交叉引用它们，并使所有在开发或使用不同模块的人员都能访问它们。将文档相互之间以及与每个模块的接口文档进行交叉引用将允许读者导航它们，并从一个文档跳转到另一个文档以查看相关信息。在单个文档中描述一个真实世界的管道及其运行的系统是不切实际的：结果将难以管理且难以保持更新。

总体而言，DAG 可以提供一个适合整个机器学习流程文档结构的概要以及导航它的地图。类似于图 2.1 的系统图可以用于记录机器学习系统，起到类似的作用。领域概念可以通过某种类型的图表非正式地组织起来；很少有必要使用如 UML（Fowler 2003）这样的正式图形规范。理想情况下，所有这些图形表示应具有一些相似之处，并对所有领域专家、机器学习专家和软件工程师都有意义。如果领域专家不理解系统的架构，那么可能存在问题：他们可以使用通用的语言来沟通任何问题，并在我们迭代项目范围（第 5.3.1 节）和原型设计（第 5.3.2 节）时讨论这些问题，直到每个人都对设计感到满意。

由于明显的原因，很难找到公开的、详细的文档设计示例，因为公司认为他们的机器学习流程是宝贵的资产，可以给他们带来竞争优势。然而，大量此类信息可在 Uber（Uber Technologies 2022）和 Spotify（Spotify 2022b）等公司的工程博客上找到。我们将使用它们作为来源，概述设计文档和使命宣言（第 8.4 节）应该如何组织。

![基于\cite{uber-fraud}的 Uber 早期欺诈检测机器学习流程，包括领域 DAG（顶部）、机器学习 DAG（中部）和软件架构 DAG（底部）](img/860a9e5c01568e080ccd724dce2c664d.png)

图 8.2：基于以下内容的 Uber 早期欺诈检测机器学习流程：领域 DAG（顶部）、机器学习 DAG（中部）和软件架构 DAG（底部）。

考虑 Uber（Zelvenskiy 等人 2022）早期欺诈检测的机器学习流程。在简要描述该流程解决的业务问题后，博客文章从领域、机器学习和软件架构的视角分别阐述了该流程。我们在图 8.2 中展示了它们：

+   领域视角（顶部面板）：Uber 从其客户那里接收一个持续不断的订单流，这些订单最初将由机器学习模型进行欺诈筛查。如果发现可疑，它们将被传递给人类专家进行人工验证，并批准或拒绝（见第 5.3.6 节）。然后，人类专家做出的决策将被反馈到进行自动筛查的机器学习模型中，以随着时间的推移提高其性能并防止数据漂移问题（参见第 5.2.1 节和第 9.1.3 节）。

+   机器学习视角（中间面板）：数据流经不同的预处理算法，包括特征选择，然后传递给负责检测可疑交易的模型。这些相同的模型将优先处理此类交易，并安排它们进行人工审核。

+   软件架构视角（底部面板）：DAG 中的每个节点都是一段软件（可能运行在特定的硬件上），它实现了在前一个流程中找到的算法和模型，存储数据或移动信息。

对于具有不同背景的人来说，这些流程将更容易理解，并且可以用来提供有关数据处理步骤、模型或与单个节点关联的模块的更详细信息。所有流程都跨越相同的四个阶段（数据摄取和准备、自动筛查、人工筛查、结果），但提供了关于如何实施欺诈检测的非常不同的视角和见解。例如，第二个和第三个流程突出了将模型重新训练与人工审核联系起来的反馈循环，这既是数据标注步骤，也是数据中相关特征统计分布的统计分布。然而，并排查看这些流程使得可以关联它们的不同视角以及在不同 DAG 中出现在同一阶段但节点不同的关系。从某种意义上说，DAGs 提供了无处不在的语言背后的概念模型的视觉表示。它们的主要局限性是无法有效地描述弧的语义意义，就像 UML 的情况一样：这些信息就是架构文档中各种文档提供的信息，补充了我们从 DAGs 中可以看到的内容。

## 8.4 记录算法和业务案例

单个模块的文档以及它们在机器学习流程中如何协同工作的文档，应该由另外两个文档来补充：

1.  一份*技术报告*，详细说明了机器学习模型的相关概率和统计特性；以及

1.  一份*使命宣言*，从领域或业务的角度，高层次地描述机器学习流程的目标。

准备一份技术报告，涵盖算法和模型的相关事实，有几个原因。首先，我们可以建立一个连贯的数学符号体系，它符合无处不在的语言（第 8.1 节）以及我们模块使用的变量命名方案（第 6.2 节），并且可以与任何我们可能使用的第三方库的符号体系相关联。科学文献的不同部分有不同的符号习惯：相同的概念可能用不同的符号表达，或者有不同的定义，或者相同的符号可能有不同的含义。这可能会因为涉及现实世界机器学习管道的各种方法而引起一些混淆。其次，技术报告将减少访问学术文献的需求，随着时间的推移，这可能变得困难，因为期刊论文、会议论文及其补充材料可能被付费墙锁定，或者当作者更换雇主时简单地从互联网上消失。第三，我们可以限制自己只关注与我们相关的模型和算法的性质，并且我们可以专注于以易于理解的方式详细记录这些性质。（对于模型的规范参考通常是它最清晰的说明，这在机器学习中尤其如此，因为 8 页的会议论文在文献中占有一席之地！）特别是，我们可以专注于我们评估的任何模型和算法在特定领域内的优缺点，这个领域与我们相关。这将比基于文献中的参考数据集的大多数基准测试工作更有信息量。最后，我们可以轻松地将技术报告与模块接口（第 8.2 节）和设计文档（第 8.3 节）进行交叉引用。

任务声明，Clements 等人（2011）称之为“领域愿景声明”，是一份 1-2 页的简短文档，用于确定机器学习管道的核心领域及其在项目范围规划（第 5.3.1 节）期间确立的目标。它有两个目的：评估管道是否适合其预期用途，并在战略层面指导其演变。通过陈述其目的，任务声明告诉我们应该评估什么样的结果。反过来，这使我们能够根据管道如何有效地和高效地实现其目的，定义一个从“表现不佳”到“表现良好”的测量范围。同时，它还可以作为其演变的指导方针。构建管道的计算系统、机器学习模型以及其基于的领域概念将不可避免地随时间而变化。每次变化时，我们都可以在战术层面制定计划，通过确定哪些组件需要更新以及如何更新来演变它。然而，所有这些局部变化都应该与确保管道随着时间的推移作为一个整体连贯演变的长期战略保持一致。换句话说，任务声明是更技术性的设计文档（第 8.3 节）和更实际的使用案例（第 8.5 节）的“理想”对应物。

例如，考虑 Spotify 首页背后推动机器学习管道的任务声明（Edmundson 2021）。首先：

> “在 Spotify，我们的目标是连接听众与创作者，我们实现这一目标的一种方式是在首页推荐高质量的音乐和播客。机器学习是我们个性化首页用户体验并将听众与最相关的创作者连接起来的核心。”

该管道是一个推荐系统，将用户与内容相匹配。这需要跟踪用户的收听数据和 Spotify 的音乐和播客目录，这在管道中的硬件、数据摄取和数据处理能力方面有影响。用户数据和目录都将随时间而变化，它们的功能也是如此：因此，预测用户可能喜欢哪些音乐和哪些播客的模型应该定期更新。更新的频率将取决于目录的变化速度、用户收听数据规模的增长速度以及我们将使用的模型，因此不适宜也不可能为更新制定一个时间表。同样地，用于提供推荐的数据特征也没有明确说明。此外，“质量”和“相关”的确切定义将取决于将它们转化为数字的具体技术标准，取决于如何衡量参与度，取决于模型以及它们的准确度指标如何与收入相关。

其次，以领域术语介绍管道的两个最终输出：

> “第一阶段：候选人生成：为每位听众选择最佳的专辑、播放列表、艺术家和播客。第二阶段：排名：为每位听众按最佳顺序排列候选人。”

预期管道将向用户提供按（预测）偏好排序的推荐。再次，诸如推荐多少项以及如何排序等细节是实施细节，这些细节随着时间的推移可能会发生变化，因此不属于使命声明。然后更详细地描述输出：

> “播客模型：预测听众可能在‘你可能喜欢的节目’架子上收听的播客。快捷方式模型：预测听众在快捷方式功能中的下一次熟悉的收听。播放列表模型：预测新听众可能在‘尝试其他内容’架子上收听的播放列表。”

该声明没有指定将使用哪些模型，也没有说明数量。甚至没有声明它们将是机器学习模型：实际上，它后来表示“一些内容是通过启发式和规则生成的，一些内容是由编辑手动策划的。”哪些模型或启发式方法合适将取决于数据中可用的哪些特征，从文献中可获得的哪些最先进模型，以及提供实时推荐所需的软件和硬件。

第三，如何向用户展示管道的输出：

> “主页由卡片组成——代表专辑、播放列表等的方形项目——以及货架——包含多个卡片的水平行。”

注意声明如何引入用户界面将基于的隐喻，但没有描述任何实现细节。在这里这样做是不合适的：我们希望随着时间的推移根据任何来自可用性研究和由遥测收集的使用模式获得的见解来改变界面。此外，不同的平台和操作系统将具有不同的功能，并且至少需要一些级别的定制。例如，在移动和桌面系统中设计具有良好人体工程学的用户界面通常是不可行的。

## 8.5 展示实际应用案例

最后但同样重要的是，展示机器学习流程实际应用的典型案例可以非常有价值。流程是为了满足某些需求而构建的，比如自动化和加速分析或改进产品：最好的方式是展示它们能够有效地、高效地在目标用户所在的领域或业务线中满足这些需求。这样，用户就能与机器学习流程所解决的问题产生共鸣，并且能够欣赏使用它的优势。前几节中展示的文档类型要么过于技术化，要么过于抽象，要么过于关注流程的内部运作，不适合这个目的。

一个非常有效的用例示例是来自微软研究剑桥（英国）的 InnerEye 项目（2022），该项目旨在开发用于医学成像的机器学习流程。参考中链接的视频讨论了在计划接受放射疗法的癌症患者身上进行 3D 医学图像分割的具体应用。

1.  *它以临床术语说明了需求*：在磁共振（MR）和计算机断层扫描（CT）中加快分割速度，同时保持足够的精度。

1.  *它以潜在用户能够理解的方式陈述了问题*：放射科医生手动进行分割，使用视觉工具在一系列数十个横截面图像中勾勒出肿瘤的轮廓。这是一个缓慢的过程，轮廓的精度有限。将肿瘤和健康组织映射到目标治疗以及限制后者暴露需要数小时准备。

1.  *它从用户的角度说明了机器学习流程如何满足需求*：自动或人工辅助的分割。视频展示了放射科医生将使用的用户界面，让他们感受到它将如何融入他们的日常工作。这使得能够实时对比手动、自动和人工辅助分割所需的时间以及分割的详细程度和精度。

1.  *它向用户说明了解决方案的价值*：为患者准备一个具有所需精度的治疗方案只需几分钟，而不是数小时。此外，相同的工具还可以用来跟踪癌症对治疗的反应。这些改进将导致更好的治疗和更好的结果。

注意，视频没有就运行时间或分割的统计准确性做出任何定量陈述，因为这两者对放射科医生来说都不容易解释。相反，InnerEye 项目有一个网页链接所有科学出版物，我们可以从中找到这些数字。机器学习工程师可以使用它们从自己学科的角度评估管道。此外，InnerEye 项目的新闻页面强调，机器学习管道已被部署，并且目前在剑桥的 Addenbrooke 医院的实际患者中使用。它获得了监管批准，并且放射科部门认为它值得使用，这些都是强有力的迹象，表明机器学习管道不是一个学术项目，而是一个在现实世界临床实践中提供价值的实体。

最后，我们想指出，实际用例也可能在收集潜在用户的反馈方面起到重要作用。展示这些用例将为用户提供一个自然的环境来讨论机器学习管道的实用性（或不实用性）以及从他们的角度来看，其优点（或缺点）似乎是什么。

### 参考文献

Brandl, G., and the Sphinx Team. 2022\. *Sphinx: Python Documentation Generator*. [`www.sphinx-doc.org/en/master/`](https://www.sphinx-doc.org/en/master/).

Carpenter, B., A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt, M. Brubaker, J. Guo, P. Li, and A. Riddell. 2017\. “Stan: A Probabilistic Programming Language.” *Journal of Statistical Software* 76 (1): 1–32.

Clements, P., F. Bachmann, L. Bass, D. Garlan, J. Ivers, R. Little, P. Merson, R. Nord, and J. Stafford. 2011\. *Documenting Software Architectures: Views and Beyond*. 2nd ed. Addison-Wesley.

CRAN Team. 2022\. *The Comprehensive R Archive Network*. [`cran.r-project.org/`](https://cran.r-project.org/).

Edmundson, A. 2021\. *The Rise (and Lessons Learned) of ML Models to Personalize Content on Home*.

Evans, E. 2003\. *Domain-Driven Design: Tackling Complexity in the Heart of Software*. Addison-Wesley.

Fowler, M. 2003\. *UML Distilled*. 3rd ed. Addison-Wesley.

Fowler, M. 2018\. *Refactoring: Improving the Design of Existing Code*. 2nd ed. Addison-Wesley.

Martin, R. C. 2008\. *Clean Code*. Prentice Hall.

McConnell, S. 2004\. *Code Complete*. 2nd ed. Microsoft Press.

微软研究院剑桥分院. 2022\. *Project InnerEye–Democratizing Medical Imaging AI*.

Muth, C., Z. Oravecz, and J. Gabry. 2018\. “User-Friendly Bayesian Regression Modeling: A Tutorial with rstanarm and shinystan.” *The Quantitative Methods for Psychology* 14 (2): 99–119.

Ousterhout, J. 2018\. *A Philosophy of Software Design*. Yaknyam Press.

Project Jupyter. 2022\. *Jupyter*. [`jupyter.org/`](https://jupyter.org/).

施布特, E., J. 桑德, M. 埃斯特, H. P. 克里格尔, 和 X 徐. 2017. “DBSCAN 重访，再重访：为什么以及如何（仍然）使用 DBSCAN.” *ACM 数据库系统事务* 42 (3): 19.

Scikit-learn 开发者. 2022. *Scikit-learn: Python 中的机器学习*. [`scikit-learn.org/`](https://scikit-learn.org/).

Spotify. 2022b. *Spotify 工程博客*. [`engineering.atspotify.com/`](https://engineering.atspotify.com/).

mypy 项目. 2014. *mypy：Python 的可选静态类型*. [`mypy-lang.org/`](http://mypy-lang.org/).

托马斯, D., 和 A. 汉特. 2019. *实用程序员：你的精通之旅*. 周年纪念版. 奥德赛出版社.

Uber 技术公司. 2022. *Uber 工程博客*. [`eng.uber.com/`](https://eng.uber.com/).

范希施，D. 2022. *Doxygen*. [`www.doxygen.nl/index.html`](https://www.doxygen.nl/index.html).

惠克姆, H., P. 丹内伯格, G. 卡尔迪, M. 尤格斯特, 和 RStudio. 2022. *roxygen2：R 的内联文档*.

谢宇. 2015. *使用 R 和 knitr 创建动态文档*. 2 版. CRC 压力出版社.

泽尔文斯基，S., G. 哈里桑尼, T. 余, E. 邱, 和 R. 韦. 2022. *Project Radar：智能早期欺诈检测*. [`eng.uber.com/project-radar-intelligent-early-fraud-detection/`](https://eng.uber.com/project-radar-intelligent-early-fraud-detection/).
