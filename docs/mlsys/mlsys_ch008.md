# 机器学习系统

*DALL·E 3 提示：以矩形格式展示嵌入式系统与嵌入式人工智能融合的插图。图像的左侧展示了传统的嵌入式系统，包括微控制器和处理器，细节丰富且精确。右侧展示了人工智能的世界，以抽象的形式展示了机器学习模型、神经元和数据流。两部分明显分开，强调嵌入式技术和人工智能的个体重要性，但在中心和谐地结合在一起。*

![图片](img/file18.png)

## 目的

*机器学习运行的环境如何塑造这些系统的本质，是什么推动了它们在计算平台上的广泛应用？*

机器学习系统必须适应截然不同的计算环境，每个环境都施加独特的约束和机遇。云部署利用庞大的计算资源，但面临网络延迟，而移动设备提供用户接近性，但受到严重的电源限制。嵌入式系统通过本地处理最小化延迟，但限制了模型复杂性，而小型设备使广泛感知成为可能，但将内存限制在千字节。这些部署环境从根本上决定了系统架构、算法选择和性能权衡。了解特定环境的要求为机器学习系统中的工程决策奠定了基础。这种知识使工程师能够选择适当的部署范式并设计在计算平台之间平衡性能、效率和实用性的架构。

**学习目标**

+   解释物理约束（光速、功率墙、内存墙）如何导致多样化的机器学习部署范式

+   通过资源配置和最佳用例区分云、边缘、移动和 TinyML 范式

+   分析资源权衡（计算能力、延迟、隐私、能源效率），以确定特定应用的适当部署策略

+   应用系统部署决策框架，评估机器学习应用的隐私、延迟、计算和成本需求

+   设计集成多个部署范式的混合机器学习架构

+   评估现实世界的机器学习系统，以确定正在使用哪些部署范式并评估其有效性

+   批判常见的部署谬误和误解，以避免在机器学习系统设计中做出不良的架构决策

+   综合通用设计原则，创建在部署环境中有效平衡性能、效率和实用性的机器学习系统

## 部署范式框架

前面的介绍将机器学习系统确立为包含三个基本组成部分：数据、算法和计算基础设施。虽然这个三重框架提供了一个理论基础，但从概念理解到实际应用的过渡引入了一个关键维度，这一维度从根本上决定了系统设计：部署环境。本章分析了计算环境如何塑造机器学习系统中的架构决策，为以部署为导向的设计原则建立了理论基础。

当代机器学习应用展示了由部署限制驱动的显著架构多样性。以计算机视觉领域 1 为例：用于图像分类的卷积神经网络在部署到不同环境时表现为截然不同的系统。在基于云的医疗影像中，系统利用几乎无限的计算资源来实现集成方法 2 和复杂的预处理流程。当部署在移动设备上进行实时目标检测时，相同的根本算法经过架构转换以满足严格的延迟要求，同时保持可接受的准确性。在工厂自动化应用中，设计空间进一步受到限制，优先考虑能源效率和确定性的响应时间，而不是模型复杂性。这些变化代表了针对同一计算问题的不同架构解决方案，这些解决方案由环境限制而不是算法考虑所塑造。

本章提出了机器学习部署范例的系统分类法，分析了涵盖从云数据中心到基于微控制器的嵌入式系统的计算谱系的四个主要类别。每个范例都源于不同的操作要求：计算资源可用性、功耗限制、延迟规格、隐私要求以及网络连接假设。这里开发的框架为在生产机器学习系统中做出明智的架构决策提供了分析基础。

现代部署策略超越了传统集中式和分布式处理的二分法。当代应用越来越多地实施混合架构，战略性地在多个范式之间分配计算任务，以优化系统级性能。语音识别系统是这种架构复杂性的例证：唤醒词检测在超低功耗嵌入式处理器上运行，以实现持续监控，语音到文本转换使用移动处理器以保持隐私并最小化延迟，而语义理解则利用云基础设施进行复杂自然语言处理。这种多范式方法反映了工程现实，即最佳的机器学习系统需要架构异质性。

部署范式空间展现出清晰的维度结构。云机器学习在接受网络引入的延迟约束的同时，最大化计算能力。边缘计算在延迟要求不允许基于云的处理时，将推理计算定位在数据源附近。移动机器学习将计算能力扩展到个人设备，其中用户接近性和离线操作是关键要求。微型机器学习使资源受限的设备能够实现分布式智能，其中能效优于计算复杂性。

通过对这些部署范式的全面分析，本章发展了设计有效平衡算法能力和操作约束的机器学习架构所需的系统工程视角。这种以系统为导向的方法为将理论机器学习进步转化为在生产系统中展示可靠性能的规模化系统提供了基本方法论基础。分析以混合架构的范式集成策略和识别所有机器学习部署环境中起主导作用的核心设计原则告终。

图 2.1 展示了计算资源、延迟要求和部署约束如何创建这种部署频谱。虽然第七章探讨了使机器学习跨越这些范式成为可能的软件工具，而第十一章则考察了推动它们的专用硬件，但本章重点讨论了支配系统架构决策的基本部署权衡。后续分析系统地处理每个范式，旨在理解它们如何整合到现代机器学习系统中。

## 部署频谱

从云到嵌入式系统的部署范围并非出于选择，而是由物理定律强加于计算系统的必要性所决定的。这些不可改变的约束创造了无法被工程进步克服的硬边界，迫使专门部署范例的演变，这些范例针对不同的操作环境进行了优化。

**光速**确立了绝对的最小延迟，这限制了实时应用。光在光纤中传播的速度约为每秒 200,000 公里，在加利福尼亚和弗吉尼亚之间理论上最小的往返时间为 40 毫秒。互联网路由、DNS 解析和处理开销通常会增加另外 60-460 毫秒，导致云服务的总延迟为 100-500 毫秒。这种由物理定律造成的延迟使得对于需要低于 10 毫秒响应时间的安全关键应用，如自动驾驶车辆的紧急制动或工业机器人的精确控制，云部署变得不可能。

**功耗墙**，由于 2005 年左右 Dennard 缩放效应的崩溃而形成，改变了计算的经济性。晶体管缩小不再降低功率密度，这意味着芯片不能在功率消耗和热量生成成比例增加的情况下任意加速。这种限制迫使在计算性能和能源效率之间进行权衡，直接推动了在移动和嵌入式系统中对专用低功耗架构的需求。数据中心现在将 30-40%的电力预算用于冷却，而移动设备必须实施热管理以防止组件损坏。

**内存墙**代表了处理器速度和内存带宽之间不断扩大的差距。虽然计算能力通过增加处理单元线性扩展，但由于物理布线限制，内存带宽大约与芯片面积的平方根成正比。这导致处理器成为数据饥渴，花费更多时间等待内存传输而不是进行计算，从而形成了越来越严重的瓶颈。大型机器学习模型加剧了这个问题，需要的数据集参数量远远超过可用的内存带宽。

**规模经济**产生了显著的单位成本差异，这为不同的部署方法提供了合理性。一台成本为 50,000 美元的云服务器可以通过虚拟化支持成千上万的用户，实现每个用户的成本低于 50 美元。然而，需要保证响应时间或私人数据处理的应用程序不能共享资源，消除了这种经济优势。与此同时，成本在 5-50 美元之间的嵌入式处理器使得在数十亿个端点部署成为可能，而单个云连接在经济上是不切实际的。

这些物理约束不是暂时的工程挑战，而是塑造计算景观的永久性限制。理解这些边界解释了为什么存在部署范围，并为在机器学习系统中做出明智的架构决策提供了理论基础。

![](img/file19.svg)

图 2.1：**分布式智能频谱**：机器学习系统设计涉及计算资源、延迟和连接性的权衡，从而产生从集中式云基础设施到资源受限的边缘和微型机器学习设备的部署选项频谱。此图映射了这些选项，突出显示每种方法如何平衡处理位置与设备能力和网络依赖性。来源：(ABI Research 2024)。

### 部署范式基础

图 2.1 中所示的部署范围并非出于设计偏好，而是由不可变的物理和硬件约束驱动的必要性。理解这些限制揭示了为什么机器学习系统不能采用统一的方法，而必须跨越从云到嵌入式设备的完整部署范围。

第一章 建立了机器学习系统（数据、算法和基础设施）的三个基础组件作为一个统一的框架，这些部署范式现在基于物理约束不同地优化。云机器学习通过丰富的基础设施优先考虑算法复杂性，而移动机器学习强调数据局部性，在受限的基础设施下，而微型机器学习在极端基础设施限制下最大化算法效率。

现代计算中最关键的瓶颈源于内存带宽扩展速度与计算能力不同。虽然计算能力通过额外的处理单元线性扩展，但由于物理路由约束，内存带宽大约以芯片面积的平方根扩展。这创造了一个逐渐恶化的瓶颈，处理器变得数据匮乏。在实践中，这表现为机器学习模型花费更多时间等待内存传输而不是进行计算，这对需要比能高效传输的数据更多的 3 大型模型尤其成问题。

在这些内存挑战的基础上，Dennard 缩放 4 的崩溃在 2005 年左右改变了计算约束，当时晶体管缩小停止了降低功率密度的过程。现在，每单位面积的功耗保持不变或随着每一代技术的进步而增加，为计算密度设定了硬性限制。对于移动设备来说，这意味着当持续计算产生过多热量时，性能会降低，即热管理。数据中心在规模上也面临类似的约束，需要大量的冷却基础设施，这可能消耗总电力预算的 30-40%。这些功率密度限制直接推动了在移动和嵌入式环境中对专用低功耗架构的需求，并解释了为什么在电力预算受限时边缘部署变得必要。

除了功率考虑之外，物理限制设定了无法通过工程优化克服的最小延迟。光速在加利福尼亚和弗吉尼亚之间建立了固有的 80ms 往返时间，而互联网路由、DNS 解析和处理开销通常又贡献了额外的 20-420ms。这 100-500ms 的总延迟使得纯云部署中的实时应用变得不可行。网络带宽面临物理限制：光纤电缆有理论上的限制，而无线通信仍然受限于频谱可用性和信号传播物理。这些通信约束创造了硬边界，需要为延迟敏感型应用进行本地处理，并推动边缘部署决策。

随着计算密度的增加，散热成为另一个限制因素。移动设备必须降低性能以防止组件损坏并保持用户舒适，而数据中心需要广泛的冷却系统，这限制了放置选项并增加了运营成本。热约束会产生级联效应：高温降低半导体可靠性，增加错误率，并加速组件老化。这些热现实需要在计算性能和可持续运行之间进行权衡，推动云环境中的专用冷却解决方案和嵌入式系统中的超低功耗设计。

这些基本约束推动了本概述中概述的四种不同部署范例的演变（第 2.2 节）。理解这些核心约束对于选择适当的部署范例和建立现实性能预期至关重要。

这些理论限制在部署谱系中表现为具体的硬件差异。为了理解这些物理限制的实际影响，表 2.1 提供了每个类别的代表性硬件平台。这些示例展示了 ML 系统谱系中的计算资源、功耗和成本考虑的范围 5，说明了每种部署方法的实际影响。6

这些定量阈值反映了计算需求、能耗和部署可行性之间的基本关系。这些缩放关系决定了分布式云部署相对于边缘或移动替代方案何时具有优势。理解这些定量权衡，能够使从业者在对 ML 系统谱系进行部署决策时做出明智的选择。

图 2.2 展示了云 ML、边缘 ML、移动 ML 和 Tiny ML 在硬件规格、延迟特性、连接要求、功耗和模型复杂度约束方面的差异。随着系统从云过渡到边缘再到 Tiny ML，可用资源急剧减少，这对机器学习模型的部署提出了重大挑战。这种资源差异在将 ML 模型部署到微控制器（Tiny ML 的主要硬件平台）时尤为明显。这些设备具有严重受限的内存和存储容量，对于传统的复杂 ML 模型来说是不够的。

表 2.1：**硬件谱系**：机器学习系统设计需要在计算资源、功耗和成本之间进行权衡，正如适用于云、边缘、移动和 TinyML 部署的多样化硬件平台所例证。此表量化了这些权衡，揭示了从云数据中心中的专用 ML 加速器到嵌入式系统中的低功耗微控制器，设备能力如何塑造每个平台可以有效地支持的模式和任务。这些定量阈值提供了具体的决策标准，以帮助从业者确定他们应用的最合适的部署范式。

| **类别** | **示例设备** | **处理器** | **内存** | **存储** | **功耗** | **价格范围** | **示例模型/任务** | **定量阈值** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **云 ML** | Google TPU v4 Pod | 4,096x TPU v4 芯片（峰值 1.1 exaflops） | 131 TB HBM2 | 云规模（PB 规模） | ~3 MW | 云服务（仅限租赁） | 大型语言模型、大规模训练 | >1000 TFLOPS 计算、实时视频处理、>100GB/s 内存带宽、PUE 1.1-1.3，100-500ms 延迟 |
| **Edge ML** | NVIDIA DGX Spark | GB10 Grace Blackwell Superchip (20-core Arm, 1 PFLOPS AI) | 128 GB LPDDR5x | 4 TB NVMe | ~200 W | ~$5,000 | 模型微调，本地推理，原型开发 | ~1 PFLOPS AI 计算，>270 GB/s 内存带宽，桌面部署，本地处理 |
| **Mobile ML** | iPhone 15 Pro | A17 Pro (6-core CPU, 6-core GPU) | 8 GB RAM | 128 GB-1 TB | 3-5 W | $999+ | 面容识别，计算摄影，语音识别 | 1-10 TOPS 计算，<2W 持续功率，<50ms UI 响应 |
| **Tiny ML** | ESP32-CAM | 双核 @ 240MHz | 520 KB RAM | 4 MB Flash | 0.05-0.25 W | $10 | 图像分类，运动检测 | <1 TOPS 计算，<1mW 功耗，微秒级响应时间 |

![](img/file20.svg)

图 2.2：**设备内存限制**：AI 模型部署跨越了具有截然不同内存容量的广泛设备，从 16 GB 的云服务器到只有 320 kb 的基于微控制器的系统。这种进步需要专门的优化技术和高效的架构，以在有限的资源下实现设备上的智能。来源：(Ji Lin, Zhu, et al. 2023)。

## 云 ML：最大化计算能力

在确定了塑造 ML 部署范例的约束和进化进程之后，本分析系统地处理每个范例，从云 ML 开始，这是其他范例出现的基石。这种方法在接受延迟约束的同时最大化计算资源，当计算能力比响应时间更重要时提供最佳选择。云部署对于可以容忍网络延迟的复杂训练任务和推理工作负载来说证明是理想的。

云机器学习利用集中基础设施的扩展性和能力 7 来处理计算密集型任务：大规模数据处理、协作模型开发以及高级分析。云数据中心利用分布式架构和专用资源来训练复杂模型并支持多样化的应用，从推荐系统到自然语言处理 8。后续分析将讨论使云 ML 系统适用于大规模应用的部署特性。

***云机器学习（Cloud ML）*** 是在 *集中数据中心基础设施* 上部署机器学习模型，以 *巨大的计算能力* 和 *可扩展性* 来降低训练和部署复杂模型的成本，但代价是 *网络延迟* 和 *连接依赖性*。

图 2.3 提供了云 ML 功能的概述，我们将在本节中详细讨论。

![](img/file21.svg)

图 2.3：**云机器学习能力**：云机器学习系统通过集中式计算基础设施和专用硬件解决与规模、复杂性和资源管理相关的挑战。此图概述了在云中部署模型的关键考虑因素，包括需要可靠的基础设施和高效的资源分配，以处理大型数据集和复杂的计算。

### 云基础设施和规模

要理解云机器学习在部署谱系中的位置，我们首先必须考虑其定义特征。云机器学习的主要区别特征是其集中式基础设施，在前所未有的规模上运行。图 2.4 通过谷歌云 TPU9 数据中心的一个例子来说明这一概念。正如表 2.1 中详细说明的那样，像谷歌的 TPU v4 Pod 这样的云系统，与移动设备相比，具有 100-1000 倍的计算优势，拥有>1000 TFLOPS 的计算能力和兆瓦级功耗。云服务提供商在全球分布的数据中心中提供具有>100GB/s 内存带宽的虚拟平台 10。这些集中式设施使得在资源受限的设备上无法完成的计算工作成为可能。然而，这种集中化引入了关键的权衡：100-500ms 的网络往返延迟消除了实时应用，而运营成本与使用量成线性增长。

![图片](img/file22.jpg)

图 2.4：**云数据中心规模**：大规模机器学习系统需要具有巨大计算资源和存储容量的集中式基础设施。谷歌的云 TPU 数据中心提供了这一需求，拥有专门的人工智能加速器硬件，以高效地管理训练和部署复杂模型的需求。来源：(DeepMind 2024))。

云机器学习在处理大量数据方面表现出色，通过并行化架构。通过第十章中详细说明的技术，跨数百个 GPU 的分布式训练使得在单个设备上需要数月的处理可以在短时间内完成，而第十一章涵盖了支撑这一性能的内存带宽分析。这使得在需要数百 PB 存储和 PFLOPS 计算的数据库上进行训练成为可能，这些资源在受限设备上是不可能实现的。

集中式基础设施通过云 API11 创造了卓越的部署灵活性，使得训练好的模型可以通过移动、Web 和物联网平台在全球范围内访问。无缝协作使得多个团队可以同时访问项目，并使用集成版本控制。按需付费的定价模式 12 消除了前期资本支出，同时资源可以根据需求弹性扩展。

一个常见的误解是认为云机器学习庞大的计算资源使其在所有替代部署方法中普遍优于其他方法。云基础设施提供了卓越的计算能力和存储，但这种优势并不自动转化为所有应用的理想解决方案。云部署引入了显著的权衡，包括网络延迟（通常是 100-500 毫秒的往返延迟）、传输敏感数据时的隐私问题、随着使用量增加的持续运营成本，以及对网络连接的完全依赖。边缘和嵌入式部署在需要实时响应的场景中表现卓越（自动驾驶汽车需要低于 10 毫秒的决策制定），在需要严格数据隐私（处理患者数据的医疗设备）、可预测的成本（一次性硬件投资与持续云费用）、或在断开连接的环境中运行（偏远地区的工业设备）方面表现出色。最佳的部署范式取决于具体的应用需求，而不是原始的计算能力。

### 云机器学习权衡与限制

云机器学习（Cloud ML）的显著优势伴随着固有的权衡，这些权衡影响着部署决策。延迟是最大的物理限制。网络往返延迟通常在 100-500 毫秒之间，这使得云处理不适合需要低于 10 毫秒响应时间的实时应用，例如自动驾驶汽车和工业控制系统。除了基本的定时限制外，不可预测的响应时间使得在地理上分布的基础设施中进行性能监控和调试变得复杂。

在采用云部署时，隐私和安全问题带来了重大挑战。将敏感数据传输到远程数据中心可能产生潜在的安全漏洞并使合规性复杂化。处理受 GDPR13 或 HIPAA14 等法规约束的数据的组织必须实施包括加密、严格的访问控制和持续监控在内的全面安全措施，以满足严格的数据处理要求。

成本管理随着支出的增加而引入了运营复杂性。考虑一个每天处理 100 万次推理的生产系统，每次推理的费用为 0.001 美元：年费用达到 365,000 美元，而一次性购买等效边缘硬件的费用为 100,000 美元。盈亏平衡点出现在大约 100,000-1,000,000 次请求时，这直接影响部署策略。不可预测的使用高峰进一步复杂化了预算编制，需要复杂的监控和成本治理框架。

网络依赖性创造了另一个关键约束。任何连接中断都会直接影响系统可用性，在网络访问受限或不稳定的地方尤其成问题。供应商锁定进一步复杂化了这一局面，因为对特定工具和 API 的依赖在切换提供商时创造了可移植性和互操作性挑战。组织必须根据应用需求和风险承受能力，仔细权衡这些约束与云的好处，并在第十六章中详细阐述弹性策略。

### 大规模训练和推理

云机器学习的计算优势在面向消费者的应用中表现得最为明显，这些应用需要巨大的规模。Siri 和 Alexa 等虚拟助手展示了云机器学习处理计算密集型自然语言处理的能力，利用广泛的计算资源处理大量并发交互，并通过接触不同的语言模式和用例不断改进。

Netflix 和 Amazon 部署的推荐引擎展示了云资源另一个令人信服的应用。这些系统使用协同过滤 15 和其他机器学习技术处理大量数据集，以揭示用户偏好和行为中的模式。随着用户数据的增长，云计算资源能够实现持续更新和优化，Netflix 每天处理超过 1000 亿个数据点，以提供个性化的内容推荐，这些推荐直接增强了用户参与度。

金融机构通过云机器学习能力实现了欺诈检测的革命。通过实时分析大量交易数据，基于历史欺诈模式训练的机器学习算法可以检测数百万账户中的异常和可疑行为，从而实现主动的欺诈预防，最大限度地减少财务损失。

这些应用展示了云机器学习的计算优势如何转化为大规模、复杂处理任务的变革性能力。除了这些旗舰应用之外，云机器学习通过社交媒体上的个性化广告、电子邮件服务中的预测文本、电子商务中的产品推荐、增强的搜索结果以及连续监控大规模网络威胁的安全异常检测系统，渗透到日常在线体验中。

## Edge ML：降低延迟和隐私风险

云机器学习的计算优势伴随着固有的权衡，这限制了其在许多现实场景中的应用。我们考察的 100-500 毫秒延迟和隐私问题为需要即时响应或本地数据处理的应用创造了基本障碍。Edge ML 作为对这些特定限制的直接回应出现，将计算更靠近数据源，以 100 毫秒以下的延迟和本地数据主权为代价，换取了无限的计算资源。

这种范式转变对于云的 100-500 毫秒往返延迟被认为不可接受的应用至关重要。需要瞬间决策的自主系统和要求实时响应的工业物联网 16 应用不能容忍网络延迟。同样，受到严格数据隐私法规约束的应用必须在本地处理信息，而不是将其传输到远程数据中心。边缘设备（网关和物联网中心 17）在部署谱中占据中间位置，在中间资源约束下保持可接受的性能。

***边缘机器学习（Edge ML）***是在网络边缘的本地基础设施上部署机器学习模型，通过在网关和工业控制器等静止设备上本地计算，实现*低延迟处理*和*数据隐私*。

图 2.5 提供了 Edge ML 关键维度的概述，本分析将详细阐述这些维度。

![图片](img/file23.svg)

图 2.5：**边缘机器学习维度**：此图概述了边缘机器学习的关键考虑因素，对比了挑战与好处，并提供了代表性的示例和特征。理解这些维度有助于在资源受限的设备上设计和部署有效的 AI 解决方案。

### 分布式处理架构

边缘机器学习（Edge ML）的多样性涵盖了可穿戴设备、工业传感器和智能家居设备，这些设备在本地 18 处理数据而不依赖于中央服务器（图 2.6）。边缘设备在计算资源、功耗和成本方面介于云系统和移动设备之间。25-100 GB/s 的内存带宽使得需要 100MB-1GB 参数的模型能够通过优化技术（第十章）实现与云模型相比 2-4 倍的加速。本地处理消除了网络往返延迟，实现了<100 毫秒的响应时间，同时产生了大量的带宽节省：本地处理 1000 个摄像头流避免了 1Gbps 的上行成本，并每年减少 10,000-100,000 美元的云费用。

### 边缘机器学习（Edge ML）的好处和部署挑战

边缘机器学习提供了可量化的好处，解决了关键云限制。从云部署中的 100-500ms 延迟降低到边缘的 1-50ms 延迟，使得需要实时响应的安全关键应用 19 成为可能。带宽节省同样显著：一家拥有 50 个摄像头的零售店通过本地处理和仅传输元数据，可以将带宽需求从 100 Mbps（每月成本 1,000-2,000 美元）降低到不到 1 Mbps，减少了 99%。通过本地处理，隐私得到改善，消除了传输风险并简化了合规性。运营弹性确保系统在网络中断期间继续运行，这对于制造、医疗保健和建筑管理应用至关重要。

这些好处伴随着相应的限制。有限的计算资源 20 显著限制了模型复杂性：边缘服务器通常提供的处理能力比云基础设施低 10-100 倍，将可部署的模型限制在数百万参数而不是数十亿参数。管理分布式网络引入的复杂性随着部署规模的非线性增长。在数千台设备上协调版本控制和更新需要复杂的编排系统 21。随着物理可访问性的增加，安全挑战加剧——在零售店或公共基础设施中部署的边缘设备面临篡改风险，需要基于硬件的保护机制。硬件异构性进一步复杂化了部署，因为具有不同能力的各种平台需要不同的优化策略。边缘服务器的初始部署成本为 500-2,000 美元，创造了大量的资本需求。部署 1,000 个地点需要 50 万至 200 万美元的前期投资，尽管这些成本可以通过长期运营节省来抵消。

![图片](img/file24.jpg)

图 2.6：**边缘设备部署**：从可穿戴设备到家用电器，各种物联网设备通过本地执行推理，实现了去中心化机器学习，减少了对于云连接的依赖，并提高了响应时间。来源：Edge Impulse。

### 实时工业和物联网系统

行业在低延迟、数据隐私和运营弹性可以证明分布式处理额外复杂性的情况下广泛部署边缘机器学习。自动驾驶汽车可能是最具有挑战性的应用，其中基于无法传输到远程服务器的传感器数据，必须在毫秒内做出安全关键的决定。像特斯拉的全自动驾驶系统这样的系统通过定制的边缘硬件，以每秒 36 帧的速度处理来自八个摄像头的输入，在 10ms 以下的延迟下做出驾驶决策，这是由于网络延迟，使用云处理无法实现的物理上不可能的响应时间。

智能零售环境展示了边缘机器学习在隐私敏感、带宽密集型应用中的实际优势。亚马逊 Go 商店通过本地边缘服务器处理来自数百个摄像头的视频，跟踪顾客的移动和商品选择，以实现无结账购物。这种基于边缘的方法解决了技术和隐私方面的担忧：从数百个摄像头传输高分辨率视频需要超过 200 Mbps 的持续带宽，而本地处理确保顾客的视频永远不会离开场所，从而解决隐私问题和监管要求。

工业物联网 22 利用边缘机器学习，在毫秒级响应直接影响生产效率和工人安全的应用中。制造设施部署边缘机器学习系统进行实时质量控制，视觉系统以每分钟超过 60 个零件的速度检查焊接，以及监控每个设施超过 10,000 个工业资产的预测性维护 23 应用。这种方法在各种制造行业证明了 25-35%的不计划停机时间减少。

智能建筑利用边缘机器学习优化能源消耗，同时在网络中断期间保持运营连续性。配备基于边缘的建筑管理系统的商业建筑处理来自 5,000-10,000 个传感器的数据，监测温度、占用率、空气质量和能源使用，边缘处理将云传输需求减少了 95%，同时实现了亚秒级响应时间。医疗保健应用同样利用边缘机器学习进行患者监测和手术辅助，通过本地处理保持 HIPAA 合规性，同时实现实时手术指导的 100ms 以下延迟。

## 移动机器学习：个人和离线智能

虽然边缘机器学习解决了云部署的延迟和隐私限制，但它引入了新的限制：需要专用边缘基础设施、持续的网络安全连接和大量的前期硬件投资。数十亿个人计算设备（智能手机、平板电脑和可穿戴设备）的普及创造了将智能直接带到用户手中的机会，从而进一步扩展机器学习能力。移动机器学习代表了智能分布的下一步，优先考虑用户接近性、离线能力和个性化体验，同时在电池供电设备的严格功率和热限制下运行。

移动机器学习将机器学习直接集成到智能手机和平板电脑等便携式设备中，为用户提供实时、个性化的功能。当用户隐私、离线操作和即时响应比计算复杂性更重要时，这种范式表现卓越。移动机器学习支持语音识别 24、计算摄影 25 和健康监测等应用，同时通过设备端计算保持数据隐私。这些电池供电设备必须在性能和功耗、热管理之间取得平衡，使其成为频繁、短时 AI 任务的理想选择。

***移动机器学习（Mobile ML）*** 是将机器学习模型直接部署在*便携式、电池供电设备*上，在严格的能源和资源限制下实现*个性化*、*隐私*和*离线操作*。

本节从四个关键维度分析移动机器学习，揭示这一范式如何平衡能力和限制。图 2.7 提供了移动机器学习能力概述。

![](img/file25.svg)

图 2.7：**移动机器学习能力**：移动机器学习系统通过设备端处理、专用硬件加速和优化框架，在性能和资源限制之间取得平衡。此图概述了在移动设备上部署机器学习模型的关键考虑因素，包括计算效率、电池寿命和模型性能之间的权衡。

### 电池和热限制

移动设备体现了中间限制：8GB RAM、128GB-1TB 存储、1-10 TOPS 通过神经网络单元 26 进行 AI 计算，消耗 3-5W 功率。片上系统架构 27 将计算和内存集成以最小化能源成本。25-50 GB/s 的内存带宽限制了模型参数为 10-100MB，需要积极的优化(第十章)。电池限制（18-22Wh 容量）使能源优化变得至关重要：1W 连续的机器学习处理将设备寿命从 24 小时减少到 18 小时。专用框架（TensorFlow Lite28、Core ML29）提供硬件优化的推理，使 UI 响应时间低于 50ms。

### 移动机器学习优势和资源限制

移动机器学习在提供响应迅速、保护隐私的用户体验方面表现出色。实时处理实现了低于 10 毫秒的延迟，实现了几乎不可察觉的响应：人脸检测以 60fps 的速度运行，延迟低于 5 毫秒，而语音唤醒词检测在 2-3 毫秒内响应。通过设备上的处理实现完全的数据主权，确保了隐私保障：面部识别在硬件隔离的安全区域 30 内处理生物识别数据，键盘预测在用户数据上本地训练，健康监测无需复杂的基础设施即可保持 HIPAA 合规性。离线功能消除了对网络的依赖：Google Maps 在本地分析数百万个路段以进行导航，翻译 31 支持 40 多个语言对，使用 35-45MB 的模型实现 90%的云端准确性，音乐识别与设备数据库进行匹配。通过利用数月积累的行为数据，个性化达到了前所未有的深度：iOS 以 70-80%的准确性预测用户将打开哪个应用，通知管理根据个人模式优化交付时间，相机系统通过隐式反馈持续适应用户偏好。

这些好处需要接受重大的资源限制。旗舰手机只为单个机器学习应用分配了 100MB-1GB 的内存，仅占总内存的 0.5-5%，迫使模型保持低于 100-500MB，而云服务可以部署 350GB+的模型。电池寿命 32 使用深度估计和分割网络实现类似单反相机的散景效果，夜间模式通过基于机器学习的降噪技术捕捉并对齐 9-15 帧，降低噪声 10-20dB，而像 Google Pixel 这样的系统则对每张照片处理 10-15 个不同的机器学习模型，用于 HDR 合并、超分辨率和场景优化。

基于语音的交互展示了移动机器学习如何改变人机通信。这些系统结合了超低功耗的唤醒词检测，消耗不到 1mW，以及设备上的语音识别，简单命令的延迟低于 10ms。键盘预测已发展到上下文感知的神经网络模型，实现了 60-70%的短语预测准确性，减少了 30-40%的打字工作量。实时相机翻译在 15-30fps 的速度下处理超过 100 种语言，完全在设备上完成，无需互联网连接即可实现即时视觉翻译。

通过 Apple Watch 等可穿戴设备进行健康监测，从传感器数据中提取复杂的见解，同时保持完全的隐私。这些系统在活动检测中达到超过 95%的准确性，包括 FDA 批准的心房颤动检测，灵敏度超过 98%，完全在设备上处理极其敏感的健康数据，以保持 HIPAA 合规性。无障碍功能通过持续本地处理展示了变革性的社会影响：实时文本识别从摄像头流中检测和识别文本，声音识别通过触觉反馈提醒聋人用户环境提示，语音覆盖生成视觉内容的自然语言描述。

增强现实框架利用移动机器学习在 60fps 的速度下实现实时环境理解。ARCore 和 ARKit 以厘米级的精度追踪设备位置，同时绘制 3D 周围环境，实现手部追踪，提取 21 个关节的 3D 姿态和 50 多个地标网格的面部分析，以实现实时效果。这些应用需要保持 16ms 以下的帧时间，使得仅在设备上处理成为提供用户期望的无缝体验的唯一可行方案。

尽管移动机器学习已经展示了其能力，但一个常见的陷阱是试图直接将桌面训练的模型部署到移动或边缘设备上，而不进行架构修改。在强大的工作站上开发的模型在部署到资源受限的设备上时往往表现糟糕。一个需要 4GB 内存进行推理（包括激活和批量处理）和每推理 4 亿次浮点运算（FLOPs）的 ResNet-50 模型无法在具有 512MB RAM 和 1 GFLOP/s 处理器的设备上运行。除了简单的资源违规之外，桌面优化的模型可能使用移动硬件不支持的操作（专门的数学操作），假设嵌入式系统中不可用的浮点精度，或者需要与单样本推理不兼容的批量处理。成功的部署需要从一开始就进行架构感知设计，包括为移动设备专门设计的架构技术（A. G. Howard 等人 2017），仅使用整数的微控制器操作，以及保持准确性的同时减少计算量的优化策略。

## 微型机器学习：大规模无处不在的感知

从云到边缘再到移动机器学习的进步展示了智能在计算平台上的分布越来越广泛，然而每一步仍然需要大量的资源。即使是拥有复杂处理器和数 GB 内存的移动设备，在全球计算格局中也处于相对有利的地位，需要消耗瓦特的电力和数百美元的硬件投资。对于真正无处不在的智能（每个表面都有传感器，每台机器都有监控，每个物体都有智能），这些资源需求仍然具有阻碍性。微型机器学习通过将智能推向绝对极限，使用成本低于 10 美元且功耗低于 1 毫瓦的设备，从而完成了部署光谱。这种范式使得无处不在的感知不仅在技术上可行，而且在大规模上经济上也是实用的。

在移动机器学习仍然需要具有数 GB 内存和多核处理器的复杂硬件时，微型机器学习在具有千字节 RAM 和单价仅为数美元的微控制器上运行。这种极端的限制迫使我们在机器学习部署方法上发生重大转变，优先考虑超低功耗和最小成本，而不是计算复杂性。结果是使得在其它任何规模下都不可行的全新类别应用成为可能。

小型机器学习（Tiny ML）将智能带到最小的设备中，从微控制器 34 到嵌入式传感器，使在资源严重受限的环境中实现实时计算成为可能。这种范式在需要无处不在的感知、自主操作和极端能源效率的应用中表现出色。Tiny ML 系统为预测性维护、环境监测和简单的手势识别等应用提供动力，同时优化能源效率 35，通常在有限的电源，如纽扣电池 36 上运行数月或数年。这些系统在电力、连接性和维护访问不切实际的环境中提供可操作的见解。

***微型机器学习（Tiny ML）***是在*微控制器*和*超受限设备*上部署机器学习模型，使应用需要数年电池寿命时，能够以毫瓦级功耗实现*自主决策*。

本节通过四个关键维度分析 Tiny ML，这些维度定义了它在机器学习部署谱中的独特位置。图 2.8 概括了本节讨论的 Tiny ML 的关键方面。

![](img/file26.svg)

图 2.8：**TinyML 系统特性**：受限设备需要关注效率，在模型复杂度、准确性和能耗之间进行权衡，同时在嵌入式应用中实现本地智能和实时响应。此图概述了 TinyML 的关键方面，包括资源限制的挑战、示例应用和设备上机器学习的益处。

### 极端资源限制

TinyML 在硬件极端条件下运行：Arduino Nano 33 BLE Sense（256KB RAM，1MB 闪存，0.02-0.04W，$35）和 ESP32-CAM（520KB RAM，4MB 闪存，0.05-0.25W，$10）与云系统相比，内存减少了 30,000-50,000 倍，与图 2.9 相比，功耗降低了 160,000 倍。这些限制使设备能够实现数月或数年的自主运行 37，但需要专门的算法，在<1 TOPS 的计算能力和微秒级响应时间内提供可接受的性能。设备大小从手掌大小到 5x5mm 的芯片 38 不等，使在以前不可能的情境中实现无处不在的感知成为可能。

![](img/file27.png)

图 2.9：**TinyML 系统规模**：这些设备套件展示了 TinyML 能够实现的极端小型化，使机器学习能够在有限的电源和内存的受限设备上部署。这些紧凑的系统扩大了 ML 的应用范围，包括以前无法访问的边缘应用，如可穿戴传感器和嵌入式物联网设备。来源：(Warden 2018)

### TinyML 优势和操作权衡

TinyML 的极端资源限制使其在其它规模下无法实现的独特优势成为可能。微秒级延迟消除了所有传输开销，实现了 10-100μs 的响应时间，这使得需要亚毫秒级决策的应用成为可能：工业振动监测过程在低于 50μs 的延迟下进行 10kHz 采样，音频唤醒词检测在低于 100μs 下分析 16kHz 音频流，精密制造系统每分钟检查超过 1000 个部件。经济优势证明了大规模部署的变革性：完整的 ESP32-CAM 系统成本为 8-12 美元，使得 1000 个传感器的部署成本为 1 万美元，而基于蜂窝网络的替代方案成本为 50 万至 100 万美元。农业监测可以通过 5000 美元的设备进行，而基于摄像头的系统则需要超过 5 万美元，而城市规模的 10 万个传感器的网络在 100 万至 200 万美元的成本下变得经济可行，而边缘替代方案的成本为 5000 万至 1 亿美元。能源效率使得设备能够在仅消耗 1-10mW 的纽扣电池上运行 1-10 年，支持像野生动物追踪这样的应用数年无需重新捕获，在建设期间嵌入混凝土中的结构健康监测，以及在电力基础设施不存在的地区部署的农业传感器。甚至可以从太阳能、振动或热源中收集能量，从而实现永续运行。通过物理数据封装，隐私超越了所有其他范式——数据永远不会离开传感器，提供了在加密强度无论多强的情况下，网络化系统中不可能实现的数学保证。

这些能力需要巨大的权衡。计算限制施加了严格的限制：微控制器提供 256KB-2MB 的 RAM，而智能手机提供 12-24GB（相差 5,000-50,000 倍），迫使模型保持小于 100-500KB，参数在 10,000-100,000 之间，与移动设备的 1-1000 万个参数相比。开发复杂性需要跨越神经网络优化、硬件级内存管理、嵌入式工具链以及使用示波器和 JTAG 调试器在多种微控制器架构上进行专业调试的专家知识。模型精度因极端压缩而受损：TinyML 模型通常达到云模型精度的 70-85%，而移动设备为 90-95%，限制了其在需要高精度应用中的适用性。部署的不灵活性限制了适应性，因为设备通常运行单个固定的模型，需要耗电的固件更新，这些更新可能会损坏设备。设备的使用寿命跨越数年，初始部署决策变得至关重要。微控制器供应商和机器学习框架之间的生态系统碎片化 39 创造了巨大的开发开销和平台锁定挑战。

### 环境与健康监测

Tiny ML 在各个领域都取得了显著的成果，其独特的优势——超低功耗、最小成本和完全的数据隐私——使得其他范式无法实现的应用成为可能。工业预测性维护展示了 TinyML 通过分布式智能改造传统基础设施的能力。制造设施部署了成千上万的振动传感器，这些传感器在 5-10 年内连续运行，使用纽扣电池，平均功耗低于 2mW。这些传感器的成本为 15-50 美元，而传统的有线传感器每点的成本为 500-2,000 美元，将部署成本从 10,000 个监测点的 5-20 百万美元降低到 150,000-500,000 美元。本地异常检测提供了 7-14 天的设备故障预警，使公司能够将非计划停机时间减少 25-45%。

唤醒词检测代表了 TinyML 最明显的消费级应用，数十亿设备在低于 1mW 的持续功耗下使用始终倾听的功能。这些系统通过包含 5,000-20,000 个参数的神经网络处理 16kHz 音频，这些参数被压缩到 10-50KB，以超过 95%的准确率检测唤醒词。亚马逊 Echo 设备使用专门的 TinyML 芯片，如 AML05，检测功耗低于 10mW，仅在唤醒词触发时激活主处理器——将平均功耗降低了 10-20 倍 40。

精准农业利用了 TinyML 的经济优势，在传统解决方案成本过高的情况下。监测 100 公顷大约需要 1,000 个监测点，而 TinyML 只需 15,000-30,000 美元，相比之下，使用蜂窝连接的替代方案需要 100,000-200,000 美元以上。这些传感器在电池上运行 3-5 年，同时本地分析时间模式，仅传输可操作的见解而不是原始数据流。

野生动物保护展示了 TinyML 在远程环境监测方面的变革潜力。研究人员部署了太阳能供电的音频传感器，功耗为 100-500mW，这些传感器处理连续的音频流以进行物种识别。通过本地分析，这些系统将卫星传输需求从每天 4.3GB 减少到检测摘要的 400KB，减少了 10,000 倍，使得 100-1,000 个传感器的规模化部署在经济上可行。医疗可穿戴设备在 5mW 以下功耗下实现了 FDA 批准的心脏监测，灵敏度达到 95-98%，每秒处理 250-500 个 ECG 样本。这种效率使得连续监测时间从基于智能手机的替代方案的数小时延长到一周，同时将诊断成本从传统实验室研究的 2,000-5,000 美元降低到家庭测试的 100 美元以下。

## 混合架构：结合范式

我们对个别部署范式的考察——从云的强大计算能力到微型 ML 的超高效传感——揭示了一系列工程权衡，每个都有其独特的优势和局限性。云 ML 最大化算法的复杂性，但引入了延迟和隐私限制。边缘 ML 减少了延迟，但需要专用基础设施并限制了计算资源。移动 ML 优先考虑用户体验，但运行在严格的电池和热限制内。微型 ML 通过极端效率实现普遍性，但严重限制了模型复杂性。每个范式都占据一个独特的细分市场，针对特定的约束和使用案例进行了优化。

然而，在实践中，生产系统很少局限于单一范式，因为每种方法的局限性都为互补集成创造了机会。一个使用微型 ML 进行唤醒词检测、移动 ML 进行本地语音识别、边缘 ML 进行上下文处理和云 ML 进行复杂自然语言理解的语音助手，展示了一种更强大的方法。混合机器学习将这种集成策略形式化，创建了利用每个范式互补优势的同时减轻个别局限性的统一系统。

***混合机器学习（Hybrid ML）***是将多种部署范式集成到统一系统中，战略性地在计算层之间分配工作负载，以实现单范式方法无法实现的**可扩展性**、**隐私**和**性能**。

### 多层集成模式

混合机器学习（Hybrid ML）设计模式提供了可重用的架构解决方案，以有效地集成范式。每个模式代表了一种战略方法，用于在计算层之间分配机器学习工作负载，针对特定的延迟、隐私、资源效率和可扩展性权衡进行了优化。

该分析确定了五个基本模式，这些模式解决了混合机器学习系统中常见的集成挑战。

#### 训练-服务分离

最常见的混合模式之一是训练-服务分离，其中模型训练在云端进行，但推理发生在边缘、移动或小型设备上。这种模式利用云端的强大计算资源进行训练阶段，同时受益于设备端推理的低延迟和隐私优势 41。例如，智能家居设备通常使用在云端基于大型数据集训练的模型，但本地运行推理以确保快速响应时间和保护用户隐私。在实践中，这可能涉及在具有百亿级计算能力和数百 TB 内存的强大云系统（如 TPU Pods）上训练模型，然后再将优化版本部署到边缘服务器或嵌入式边缘设备上进行高效的推理。同样，用于计算摄影的移动视觉模型通常在强大的云基础设施上训练，但部署到手机硬件上以实现高效运行。

#### **分层处理**

**分层处理**创建了一个多级系统，其中数据和智能在机器学习堆栈的不同层级之间流动。这种模式有效地结合了云机器学习系统的能力（如前几节讨论的大规模训练基础设施）和多个边缘机器学习系统（如边缘服务器和我们的边缘部署示例中的嵌入式设备），以平衡中央处理能力和本地响应性。在工业物联网应用中，微型传感器可能执行基本的异常检测，边缘设备汇总并分析来自多个传感器的数据，而云系统处理复杂的分析和模型更新。例如，我们可能会看到 ESP32-CAM 设备（来自我们的小型机器学习示例）在传感器级别使用最小的 520 KB RAM 执行基本的图像分类，将数据传输到边缘服务器或嵌入式系统进行更复杂分析，并最终连接到云基础设施进行复杂分析和模型更新。

这种层次结构允许每个层级处理适合其能力的任务。小型机器学习设备处理即时、简单的决策；边缘设备管理本地协调；云系统处理复杂的分析和学习任务。智能城市安装通常使用这种模式，街级传感器将数据传输到社区级的边缘处理器，后者再连接到城市级的云分析。

#### **渐进式部署**

**渐进式部署**通过系统性地压缩模型，通过计算层级的适应性创建分层智能架构。一个模型可能从一个大型云版本开始，然后通过第十章中详细描述的技术逐步优化边缘服务器、移动设备和最终的小型传感器。

亚马逊 Alexa 是这种模式的例证：唤醒词检测在 TinyML 设备上使用<1KB 模型，消耗<1mW，边缘处理使用 1-10MB 模型在 1-10W 下处理简单命令，而复杂的自然语言理解则需要云基础设施中的 GB+模型。这种分层方法将云推理成本降低了 95%，同时保持了用户体验。

然而，渐进式部署引入了操作复杂性：层间的模型版本管理、确保各代之间的一致性、在连接丢失期间管理故障级联以及协调数百万设备之间的更新。生产团队必须维护涵盖小型机器学习优化、边缘编排和云扩展的专门专业知识。

#### **联邦学习**

**联邦学习**42 允许从分布式数据中学习同时保持隐私。谷歌的生产系统处理 60 亿个移动键盘，在保持输入文本本地化的同时训练改进的模型。每一轮训练涉及 100-10,000 个设备贡献模型更新，需要编排来管理设备可用性、网络条件和计算异构性。

生产部署面临重大的运营挑战：训练轮次中的设备掉线率高达 50-90%，网络带宽限制更新频率，以及差分隐私机制防止信息泄露。聚合服务器必须处理间歇性连接、不同的设备能力，并确保在非独立同分布数据分布的情况下实现收敛。这需要专门的监控基础设施来跟踪分布式训练进度并调试问题，而无需访问原始数据。

#### 协作学习

协作学习使得同一层级的设备之间能够进行点对点学习，通常补充了层次结构。43 例如，自动驾驶车队可以在车辆之间直接共享关于道路状况或交通模式的学习，同时与云基础设施进行通信。这种横向协作使得系统可以共享时间敏感信息，并从彼此的经验中学习，而无需始终通过中央服务器路由。

### 生产系统案例研究

现实世界的实现将多个设计模式整合成统一的解决方案，而不是孤立地应用它们。生产机器学习系统形成相互连接的网络，其中每个范式都扮演特定的角色，并与他人通信，遵循利用我们的四范式框架中确立的强项并解决局限性的集成模式（第 2.2 节）。

图 2.10 通过具体的连接类型说明了这些关键交互：“部署”路径显示了模型如何从云训练流向各种设备，“数据”和“结果”显示了信息如何从传感器通过处理阶段流动，“分析”显示了处理后的信息如何达到云分析，“同步”展示了设备协调。注意数据通常从传感器通过处理层向上流向云分析，而模型部署则从云训练向下流向各种推理点。这些交互并非严格分层。移动设备可以直接与云服务和微型传感器通信，而边缘系统可以帮助移动设备处理复杂的处理任务。

![图片](img/file28.svg)

图 2.10：**混合系统交互**：数据从传感器通过处理层向上流向云分析以获取洞察，而训练好的模型从云向下部署，以在边缘、移动和 Tiny ML 设备上实现推理。这些连接类型（部署、数据/结果、分析和同步）建立了一个分布式架构，其中每个范式都为整体机器学习系统贡献独特的功能。

生产系统在多种应用中展示了这些集成模式，在这些应用中，没有任何单一范式能够提供所需的功能。工业缺陷检测是模型部署模式的例证：云基础设施在多个设施的数据集上训练视觉模型，然后将优化的版本分发到管理工厂运营的边缘服务器、质量检查员使用的平板电脑以及制造设备上的嵌入式摄像头。这展示了单个机器学习解决方案如何从集中式训练流向多个计算规模上的推理点。

农业监测说明了分层数据流：土壤传感器执行本地异常检测，将结果传输到边缘处理器，这些处理器从数十个传感器汇总数据，然后将洞察传递到云基础设施进行农场范围的统计分析，同时更新农民的移动应用程序。信息通过处理层向上传递，每一层都添加了适合其计算资源的分析复杂性。

健身追踪器是 Tiny ML 和移动设备之间的网关模式的例证：可穿戴设备使用针对微控制器执行优化的算法持续监控活动，将处理后的数据同步到结合来自多个来源的指标的智能手机，然后定期将更新传输到云基础设施进行长期分析。这使得小型设备能够在缺乏直接网络连接的情况下参与大规模系统。

这些集成模式揭示了部署范式如何通过协调数据流、模型部署和跨层协助相互补充。工业系统将云、边缘、移动和 Tiny ML 的能力组合成分布式架构，同时优化延迟、隐私、成本和运营需求。范式之间的交互往往比单个组件的能力更能决定系统成功。

## 部署范式中的共享原则

尽管它们多样化，但所有机器学习部署范式都共享核心原则，这些原则使得系统性的理解和有效的混合组合成为可能。图 2.11 说明了从云到小型设备的实现如何汇聚到核心系统挑战：管理数据管道、平衡资源约束和实现可靠的架构。这种汇聚解释了为什么技术能够在范式之间有效转移，并且混合方法在实践中能够成功工作。

![图片](img/file29.svg)

图 2.11：**机器学习系统收敛**：不同的机器学习部署（云、边缘、移动和微型）在数据管道、资源管理和系统架构方面共享基础原则，使得混合解决方案和系统化设计方法成为可能。理解这些共享原则允许从业者跨不同范式调整技术，并在不同的约束和优化目标下构建一致、高效的机器学习工作流程。

图 2.11 揭示了三个不同的抽象层，这些层统一了不同部署环境下的机器学习系统设计。

顶层代表机器学习系统的实现——本章中检验的四个部署范式。云机器学习在数据中心进行大规模训练，边缘机器学习执行本地处理，专注于推理，移动机器学习在个人设备上运行，用于用户应用，而 TinyML 在资源受限的嵌入式系统上执行。尽管它们表面上存在差异，但这些实现共享更深层次的共同点，这些共同点在底层中显现出来。

中间层识别出将所有范式统一起来的核心系统原则。数据管道管理（第六章）控制着从收集到部署的信息流，无论是在云端数据中心处理 PB 级数据还是在微控制器上处理 KB 级数据，都保持一致的模式。资源管理在所有规模上创造着平衡计算、内存、能源和网络容量之间竞争需求的普遍挑战。系统架构原则指导着无论部署环境如何，模型、硬件和软件组件的集成。即使实施方式在可用资源上存在数量级的差异，这些基础原则仍然非常一致。

底层展示了系统考虑如何在实际维度上体现这些原则。优化和效率策略（第十章）在各个规模上采取不同的形式：云 GPU 集群训练、边缘模型压缩、移动热管理以及 TinyML 数值精度，但所有这些都在追求在可用资源内最大化性能。操作方面（第十三章）通过针对范式特定方法的部署、监控和更新来应对根本性相似挑战。可信赖的人工智能（第十七章，第十六章）对安全、隐私和可靠性的要求普遍适用，尽管实现技术必然要适应每个部署环境。

这种三层结构解释了为什么技术能够在不同规模之间有效转移。云训练的模型成功部署到边缘设备，因为训练和推理在不同的约束下优化了相似的目标。移动优化见解为云效率策略提供了信息，因为两者都管理着相同的根本资源权衡。TinyML 的创新推动了跨范例的进步，正是因为极端的限制迫使解决方案解决所有规模都存在的核心问题。混合方法（训练-服务拆分、分层处理、联邦学习）有效，因为底层原则在范例之间是一致的，即使在可用资源存在巨大差异的情况下也能实现无缝集成。

## 比较分析和选择框架

基于对共享原则的理解，对部署范例的系统比较揭示了应驱动部署决策的精确权衡，并突出了每个范例表现优异的场景，为从业者提供了解决方案分析框架，以便做出明智的架构选择。

计算资源与部署位置之间的关系构成了机器学习系统中最重要的比较之一。随着我们从云部署转向微型设备，我们观察到可用的计算能力、存储和能耗发生了显著下降。云机器学习系统凭借其数据中心基础设施，几乎可以无限制地利用资源，以 PB 级规模处理数据，并使用具有数十亿参数的模型进行训练。边缘机器学习系统虽然受到更多限制，但通过边缘 GPU 和神经处理单元等专用硬件，仍然提供了显著的计算能力。移动机器学习代表了中间地带，在智能手机和平板电脑等设备上平衡计算能力和能源效率。在光谱的另一端，TinyML 在严格的资源限制下运行，通常仅限于千字节级的内存和毫瓦级的能耗。

表 2.2：**部署位置**：机器学习系统的计算位置各不相同，从集中的云服务器到本地边缘设备，再到超低功耗的 TinyML 芯片，每个都影响着延迟、带宽和能耗。本表按处理位置和相关特征对这些部署进行分类，有助于做出关于系统架构和资源分配的明智决策。

| **方面** | **云机器学习** | **边缘机器学习** | **移动机器学习** | **TinyML** |
| --- | --- | --- | --- | --- |
| **性能** |  |  |  |  |
| **处理位置** | 集中云服务器（数据中心） | 本地边缘设备（网关、服务器） | 智能手机和平板电脑 | 超低功耗微控制器和嵌入式系统 |
| **延迟** | 高（100 ms-1000 ms+） | 中等（10-100 ms） | 低-中等（5-50 ms） | 非常低（1-10 ms） |
| **计算能力** | 非常高（多个 GPU/TPU） | 高（Edge GPU） | 中等（移动 NPUs/GPU） | 非常低（MCU/小型处理器） |
| **存储容量** | 无限（PB+） | 大（TB） | 中等（GB） | 非常有限（KB-MB） |
| **能源消耗** | 非常高（kW-MW 范围） | 高（100 s W） | 中等（1-10 W） | 非常低（mW 范围） |
| **可扩展性** | 极佳（几乎无限） | 良好（受边缘硬件限制） | 中等（按设备扩展） | 有限（固定硬件） |
| **操作** |  |  |  |  |
| **数据隐私** | 基本到中等（数据离开设备） | 高（数据留在本地网络） | 高（数据留在手机上） | 非常高（数据从不离开传感器） |
| **所需连接** | 持续高带宽 | 断续 | 可选 | 无需 |
| **离线能力** | 无 | 良好 | 极佳 | 完全 |
| **实时处理** | 依赖于网络 | 良好 | 非常良好 | 极佳 |
| **部署** |  |  |  |  |
| **成本** | 高（每月 1000 美元以上） | 中等（100-1000 美元） | 低（0-10 美元） | 非常低（1-10 美元） |
| **硬件要求** | 云基础设施 | Edge 服务器/网关 | 现代智能手机 | MCU/嵌入式系统 |
| **开发复杂性** | 高（需要云专业知识） | 中等到高（边缘+网络） | 中等（移动 SDK） | 高（嵌入式专业知识） |
| **部署速度** | 快速 | 中等 | 快速 | 慢速 |

表 2.2 在性能、操作和部署维度上量化了这些范式差异，揭示了延迟（云：100-1000ms → 边缘：10-100ms → 移动：5-50ms → 微型：1-10ms）和隐私保证（TinyML 的完全本地处理最强）的明显梯度。

图 2.12 通过雷达图展示了性能和操作特性。图 a)对比了计算能力和可扩展性（Cloud ML 的优势）与延迟和能源效率（TinyML 的优势），Edge 和 Mobile ML 位于中间位置。

![](img/file30.svg)

图 2.12: **ML 系统权衡**: 雷达图量化了云、边缘、移动和 Tiny ML 范式在性能和操作特性方面的差异，揭示了计算能力、延迟、能源消耗和可扩展性之间的固有权衡。这些可视化有助于根据特定应用的限制和优先级，选择最合适的部署方法。

图 b)强调了 TinyML 在操作维度上的优势（隐私、连接独立性、离线能力）与 Cloud ML 对集中式基础设施和持续连接的依赖。

开发复杂性随着硬件能力的增加而减少：云和 TinyML 需要深厚的专业知识（分别对应云基础设施和嵌入式系统），而移动和边缘则利用更易获取的 SDK 和工具。成本结构也显示出类似的反转：云产生持续的操作费用（每月 1000 美元以上），边缘需要适度的前期投资（100-1000 美元），移动利用现有设备（0-10 美元），而 TinyML 最小化硬件成本（1-10 美元）的同时，要求更高的开发投资。

理解这些权衡对于选择适当的部署策略至关重要，这些策略将应用需求与范式能力相一致。

部署选择中的一个关键陷阱是仅根据模型准确度指标选择范式，而不考虑系统级约束。团队通常通过单独比较模型准确度来选择部署策略，忽略了决定实际可行性的关键系统要求。如果一个云部署的模型达到 99%的准确度，但网络延迟超过了反应时间要求，那么它对自动驾驶紧急制动就毫无用处。同样，一个复杂的边缘模型可能在几分钟内耗尽移动设备的电池，尽管其准确度更高。成功的部署需要同时评估多个维度：延迟要求、电源预算、网络可靠性、数据隐私法规和总拥有成本。在模型开发之前建立这些约束，以避免在项目后期进行昂贵的架构调整。

## 部署选择决策框架

选择合适的部署范式需要系统地评估应用约束，而不是组织偏见或技术趋势。图 2.13 提供了一个分层决策框架，通过关键要求过滤选项：隐私（数据能否离开设备？）、延迟（需要低于 10 毫秒的响应？）、计算需求（需要大量处理？）和成本约束（预算限制？）。这种结构化方法确保部署决策源于应用需求，基于之前建立的物理约束（第 2.2.1 节）和定量比较（第 2.9 节）。

![图片](img/file31.svg)

图 2.13：**部署决策逻辑**：此流程图通过系统地评估隐私要求和处理约束，引导选择合适的机器学习部署范式，最终在性能、成本和数据安全之间取得平衡。通过导航决策树，帮助实践者确定云、边缘、移动或微型机器学习最适合特定应用。

该框架按顺序评估四个关键决策层。隐私限制形成第一个过滤器，确定数据是否可以外部传输。在 GDPR、HIPAA 或专有权限下处理敏感数据的应用程序要求本地处理，立即排除了仅限云的部署。延迟要求通过响应时间预算建立第二个限制：需要低于 10 毫秒响应时间的应用程序不能使用云处理，因为物理施加的网络延迟本身就超过了这个阈值。计算需求形成第三个评估层，评估应用程序是否需要只有云或边缘系统提供的高性能基础设施，或者它们是否可以在移动或微型设备的资源限制内运行。成本考虑通过在整个预期部署寿命内平衡资本支出、运营费用和能源效率来完成框架。

技术限制本身并不能证明部署决策的充分性。组织因素通过决定团队是否具备实施和维护所选范例的能力，对成功起着至关重要的作用。团队的专业技能必须与范例要求相一致：云机器学习需要分布式系统知识，边缘机器学习需要设备管理能力，移动机器学习需要特定平台的优化技能，而微型机器学习需要嵌入式系统专业知识。缺乏适当技能的组织将面临延长的发展周期和持续的维护挑战，从而削弱了技术优势。监控和维护能力同样通过其时间模式决定大规模的可行性：边缘部署需要分布式设备编排，而微型机器学习需要许多组织缺乏的专业固件管理。成本结构通过其时间模式进一步复杂化决策：云产生持续的经营费用，有利于不可预测的工作负载，边缘需要大量的前期投资，但通过较低的持续成本得到补偿，移动利用用户提供的设备以最小化基础设施费用，而微型机器学习最小化硬件和连接成本，同时要求显著的开发投资。

成功的部署来自于平衡技术优化与组织能力。范例选择代表了系统工程挑战，这些挑战远远超出了纯粹的技术要求，包括团队技能、运营能力和经济限制。这些决策仍然受到在第 9.3 节中探讨的基本扩展定律的限制，运营方面在第十三章中详细说明，而基准测试方法在第十二章中介绍。

## 谬误和陷阱

理解部署范式需要识别可能导致不良架构决策的常见误解。这些谬误通常源于对指导机器学习系统设计的核心权衡的过度简化思考。

**谬误：“一种范式适用于所有”** - 最普遍的误解是认为一种部署方法可以解决所有机器学习问题。团队往往在云、边缘或移动解决方案上标准化，而不考虑特定应用的约束。这种谬误忽略了在第 2.2.1 节中讨论的物理限制。实时机器人无法容忍云延迟，而复杂的语言模型超出了小型设备的处理能力。有效的系统通常需要混合架构，战略性地利用多个范式。

**谬误：“边缘计算总是减少延迟”** - 许多从业者认为边缘部署会自动提高响应时间。然而，边缘系统引入了处理延迟、负载平衡开销和可能的网络跳跃，这些可能超过直接云连接。设计不良、本地计算能力不足的边缘部署可能表现出比优化云服务更差的延迟。只有当本地处理时间加上减少的网络距离超过基础设施复杂性成本时，边缘优势才会显现。

**谬误：“移动设备可以通过优化处理任何工作负载”** - 这种误解低估了电池寿命和热管理带来的基本限制。团队常常假设模型压缩技术可以任意减少资源需求，同时保持性能。然而，移动设备面临硬性物理限制：电池容量与体积成正比，而计算需求与模型复杂性成正比。某些应用需要的计算资源，任何优化都无法在移动电源预算内适应。

**谬误：“小型机器学习只是更小的移动机器学习”** - 这种谬误误解了资源受限范式之间的定性差异。小型机器学习在如此严格的限制下运行，以至于需要不同的算法方法。微控制器环境施加的内存限制是以千字节计，而不是兆字节，需要使用量化等专门技术，这超出了移动优化的范畴。适用于小型机器学习的应用代表了一个根本不同的问题类别，而不仅仅是移动应用的缩小版。

**谬误：“成本优化等于资源最小化”** - 团队经常假设最小化计算资源会自动降低成本。这种观点忽略了运营复杂性、开发时间和基础设施开销。云部署可能会消耗更多的计算资源，但通过降低维护成本、自动扩展和共享基础设施，提供更低的总体拥有成本。最佳成本解决方案通常涉及接受更高的单位资源消耗，以换取简化操作和更快的开发周期。

## 摘要

本章分析了机器学习系统的多样化景观，揭示了部署环境如何直接影响系统设计的各个方面。从拥有大量计算资源的云环境到在极端限制下运行的微型设备，每个范式都提供了独特的机遇和挑战，这些机遇和挑战直接影响架构决策、算法选择和性能权衡。从云到边缘到移动再到微型机器学习的谱系，不仅仅代表了计算规模的不同，它反映了我们在计算基础设施上分布智能的重大演变。

从集中式云系统到分布式边缘和移动部署的演变展示了资源限制如何推动创新，而不仅仅是限制能力。每个范式都是为了解决其前辈的具体限制而出现的：云机器学习利用集中式力量进行复杂处理，但必须应对延迟和隐私问题。边缘机器学习将计算更靠近数据源，减少延迟，同时引入中间资源限制。移动机器学习将这些能力扩展到个人设备，平衡用户体验与电池寿命和热管理。微型机器学习将资源推向极限，使无处不在的感知和智能成为以前不可能部署环境中的可能。这一演变展示了深思熟虑的系统设计如何将限制转化为专门优化的机会。

**关键要点**

+   部署环境比算法偏好更多地驱动架构决策

+   资源限制创造了创新的机会，而不仅仅是限制

+   混合方法正在成为机器学习系统设计的未来

+   隐私和延迟考虑因素越来越有利于分布式智能

这些范例反映了向针对特定操作需求精细调优的系统转变的趋势，超越了“一刀切”的方法，转向了情境感知的系统设计。随着这些部署模型成熟，混合架构应运而生，结合了它们的优点：基于云的训练与边缘推理相结合，跨移动设备的联邦学习，以及优化整个频谱的分层处理。这一演变展示了部署情境将继续推动系统架构、训练方法和优化技术的创新，创造更加复杂和情境感知的机器学习系统。

然而，部署情境只是系统设计的一个维度。在这些环境中执行的计算算法同样影响资源需求、计算模式和优化策略。一个需要数 GB 内存和数十亿浮点运算的神经网络，与一个只需要数 KB 和整数比较的决策树相比，需要根本不同的部署方法。下一章（第三章）将探讨神经网络的数学基础，揭示为什么某些部署范例适合特定的算法，以及算法选择如何在整个系统堆栈中传播。

* * *
