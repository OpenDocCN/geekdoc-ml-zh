## 第七章：寻找一个好的超参数组合**

![Image](img/common.jpg)

如前几章所讨论的，特别是第 3.2.1 节，大多数分析师处理确定超参数的好值的方法是使用交叉验证。本章中，我们将学习使用`qeML`函数`qeFT()`，它极大地简化了这一过程。

### 7.1 超参数组合

请注意，通常我们讨论的是超参数的*集合*。举例来说，假设我们希望在 k-NN 设置中使用 PCA。那么我们有两个超参数：邻居数量*k*和主成分数量*m*。因此，我们关注的是找到一个好的*k*值和*m*值的*组合*。

在许多情况下，超参数的组合不仅仅是成对的。例如，在`qeDT()`中，有超参数`alpha`、`minsplit`、`minbucket`、`maxdepth`和`mtry`。因此，我们希望找到一个由五个超参数组成的良好组合。

许多机器学习方法有更多的超参数。机器学习方法的超参数越多，找到一个良好的组合值就越具挑战性。`qeML`函数`qeFT()`旨在帮助进行这一搜索。

**注意**

*在继续之前，请注意，尽管机器学习讨论——以及一些软件文档——通常会提到寻找**最佳**超参数组合，但这通常是一个幻觉。由于 p-hacking（请参见第 1.13 节），给定训练集的最佳组合可能并不是预测新数据的最佳组合，而后者才是关键。尽管如此，到本章结束时，您将掌握可靠地确定**良好**组合的工具。*

### 7.2 使用 qeFT()进行网格搜索

许多机器学习包包含用于进行*网格搜索*的函数，这意味着评估所有可能的超参数组合。然而，组合的数量通常非常庞大，进行完整的网格搜索需要耗费巨大的时间。

一些网格搜索软件库试图通过仅评估看似有前景的组合来解决这个问题，通过一个迭代搜索在网格的狭窄部分进行移动。在每次迭代中，算法会更新对下一步应该尝试什么的猜测。这节省了时间，但也可能走错方向，并且同样容易受到 p-hacking 问题的影响。

`qeML`函数`qeFT()`采取了更加谨慎的方法。它生成大量的随机超参数组合，数量由用户指定，并根据相关的损失准则（数值型*Y*设置使用 MAPE，分类设置使用 OME）评估这些组合。它会列出并显示结果，并包括图形显示选项。最重要且独特的是，它防止 p-hacking，稍后将对此进行解释。

`qeFT()`函数是一个`qe`系列的包装器，封装了`regtools`函数`fineTuning()`。回想一下，超参数的另一个术语是*调优参数*。这个函数名是对老式收音机时代的双关语，当时调整到你喜欢的电台的精确频率被称为“微调”。

#### ***7.2.1 如何调用 qeFT()***

这是基本的`qeFT()`调用格式：

```
qeFT(data,yName,qeftn,pars,nCombs=NULL,nTst,nXval,showProgress=TRUE)
```

让我们来看看这些参数的作用：

data   如同所有`qe*`系列中的情况，这是我们的输入数据。

yName   如同所有`qe*`系列中的情况，这是我们*Y*列的名称。

qeftn   ML 函数名称，例如`qeKNN`。

pars   R 列表，指定我们希望考虑的`qeftn`超参数值，例如 k-NN 中的*k*。

nCombs   要评估的超参数随机组合的数量。如果为`NULL`，则会运行所有可能的组合。

nTst   验证集的大小。

nXval   每个超参数组合运行的验证集数量。

showProgress   对于急躁的人；随着结果的生成，打印出来。

简而言之，我们对`nCombs`个超参数组合运行指定的 ML 函数`qeftn`，使用`pars`中显示的范围。对于每个组合，我们生成`nXval`个训练/测试数据划分，测试部分的大小为`nTst`。然后，我们统计所有超参数组合中结果的 MAPE 或 OME 值。

注意`qeFT()`和第 3.2.2 节中介绍的`replicMeans()`函数之间的区别。后者处理的是分析人员可能认为单一的验证集不足以准确评估性能的问题。`qeFT()`函数也做了这件事，通过参数`nXval`，但它做得更多，自动化了搜索过程。

### 7.3 示例：程序员与工程师数据

返回到 2000 年美国普查数据中关于程序员和工程师薪资的信息（见第 3.2.3 节），我们来找出合适的超参数以预测工资收入。

```
> set.seed(9999)
> ftout <- qeFT(data=pef,yName='wageinc',qeftn='qeKNN',
+    pars=list(k=5:25),nTst=1000,nXval=5)
> ftout
$outdf
    k  meanAcc       CI   bonfCI
1   5 22991.82 23402.16 23693.80
2   7 23168.20 24038.72 24657.43
3   9 23302.83 23829.56 24203.92
4  14 23384.68 23857.61 24193.75
5  10 23471.30 24095.60 24539.30
6   6 23635.61 24538.43 25180.09
7  25 23767.42 24651.47 25279.81
8  15 23843.55 24633.13 25194.31
9   8 23921.75 24846.51 25503.77
10 22 23924.46 24271.38 24517.95
11 16 24036.80 24784.32 25315.61
12 20 24120.60 24996.35 25618.78
13 11 24168.83 25639.28 26684.37
14 13 24192.18 24693.87 25050.43
15 12 24256.22 24690.67 24999.46
16 17 24261.34 24934.30 25412.59
17 18 24375.20 24576.41 24719.41
18 23 24376.66 25109.56 25630.46
19 24 24619.82 25249.43 25696.91
20 21 24693.10 25456.93 25999.81
21 19 24842.66 25564.61 26077.72

$nTst
[1] 1000
...
```

这里唯一的超参数是`k`。我们已将其范围指定为`5:25`——也就是说，我们依次尝试*k* = 5、*k* = 6，依此类推，一直到*k* = 25。由于我们没有提供`nCombs`参数，默认情况下会检查这 21 种组合。

`meanAcc`是主要结果，它给我们提供了所有交叉验证运行的`testAcc`均值。我们将在下一节中解释`CI`和`bonfCI`列。

#### ***7.3.1 置信区间***

起初看起来*k* = 5 个邻居是最佳选择。确实，这是我们对当前设置下最佳*k*的猜测（也就是说，这个*n*、这个特征集、这个采样的群体等等）。但我们应该小心。以下是原因。

从`qe*`系列函数输出的任何`testAcc`值都是随机的，因为验证集是随机的。使用`qeFT()`时，我们会查看多个验证集，并通过平均结果来获得`meanAcc`。由于所有的验证集都是随机的，因此`meanAcc`也是随机的。当然，`nXval`越大，准确度越好。

因此，`meanAcc` 列只是一个近似值。`CI` 列的作用是让我们大致了解这个近似值的准确性。具体来说，`CI` 列中的值是针对任何给定组合的真实平均准确度的 95% 置信区间的右端点。（对于那些懂统计学的人来说，这些是*单侧*置信区间，形式为 (− ∞, *a*)。）

在我们的这个例子中，7 个邻居的 `meanAcc` 值完全落在 5 个邻居的置信区间内。实际上，在使用 5 个或 7 个邻居之间几乎是一个抛硬币的选择，而且它们的 `meanAcc` 数字本来就没有太大差距。因此，我们不应该把 *k* = 5 的明显优越性当作字面意义来解读。

换句话说，`CI` 列“让我们保持诚实”，提醒我们 `meanAcc` 只是一个近似值，并且为我们提供了一个是否能够区分出那些看似表现最好的组合的提示。

但问题不仅仅是这样。当我们构建大量的置信区间时，由于 p-hacking，其总体有效性会下降（参见第 1.13 节）。在名义上的 95% 水平下单独设定的置信区间会有一个更低的总体置信水平。为了解释这一点，想象一下投掷 10 枚硬币。每枚硬币的正面概率是 0.5，但它们*全都*朝正面朝上的概率要小得多。同样，如果我们有十个 95% 的置信区间，它们*都*正确的概率远小于 95%。

`bonfCI` 列对这一点进行了调整，使用了一个叫做*Bonferroni−Dunn*的置信区间（CIs）。换句话说，该列为我们提供了考虑到我们在查看多个随机置信区间的情况下的置信区间。因此，我们实际上应该更关注该列，而不是`CI`列。

在我们的这个例子中，调整后的置信区间的界限仅比原始的略大。这意味着在这个简单的例子中，我们不太可能遇到 p-hacking 的问题。但正如在第 1.13 节中讨论的那样，对于有许多超参数的机器学习算法，这可能会成为一个问题。在这种情况下，我们很可能会抓住一个看似“最佳”的组合，实际上它并不具代表性，因此远不如其他一些选择。

我们当然无法知道情况是否如此，但一个好的经验法则是，在几个具有相似 `meanAcc` 值的组合之间，考虑选择更为中等的组合，而不是极大或极小的超参数值。

例如，考虑神经网络（我们将在第十一章中进一步讨论这些），它们通常有许多超参数，包括：

+   层数

+   每层的神经元数量

+   丢弃率

+   学习率

+   动量

+   初始权重

为了调查各种各样的超参数组合，我们需要将`qeFT()`中的`nCombs`参数设置为一个非常大的数字，这样我们就有很大风险找到一个实际上并不有效，但偶然看起来很好的组合。`bonfCI`列警告我们这一点；它与`CI`列之间的差异越大，风险越大。

另一方面，我们仅仅是在寻找一个*好的*超参数组合，而不是绝对最佳的组合。对于任何特定的组合，`bonfCI`数值为我们提供了一个合理的指示，告诉我们这个组合是否能很好地预测未来的案例。与机器学习中的许多事情一样，如何处理置信区间（CIs）没有固定的魔法公式，但它们可以作为我们思考的非正式辅助手段。

**注意**

*这是关于 Bonferroni−Dunn 区间的一些历史：传统上，只有 Bonferroni 这个名字被使用，以纪念开发了该概率不等式的意大利数学家，这个不等式对于置信区间至关重要。然而，作为 Olive Jean Dunn 教授的前学生，我很高兴发现现在她的名字也常常被包括在内，因为正是她提出了使用这个不等式来构建置信区间。*

#### ***7.3.2 网格搜索的要点***

这里的要点是，我们不能字面理解网格搜索结果的顺序。最初的几个“最佳”结果可能实际上是相似的。而且，表面上看似“最佳”的结果可能并不具有代表性。与其试图优化，不如选择一个“好”的组合，最好不要过于极端。

### 7.4 示例：程序员和工程师数据

让我们尝试预测职业而不是工资收入。

```
> ftout <- qeFT(data=pef,yName='occ',qeftn='qeKNN',pars=list(k=1:25),
   nTst=1000,nXval=5)
> ftout
$outdf
    k meanAcc        CI    bonfCI
1   4  0.4656 0.4774134 0.4862065
2   7  0.4688 0.4756510 0.4807504
3   3  0.4726 0.4850419 0.4943029
4   2  0.4746 0.4846176 0.4920740
5   1  0.4766 0.4866176 0.4940740
6   5  0.4782 0.4827307 0.4861032
7   8  0.4990 0.5082016 0.5150508
8   6  0.5016 0.5179475 0.5301156
9  11  0.5150 0.5273033 0.5364611
10  9  0.5162 0.5239988 0.5298037
11 10  0.5292 0.5376199 0.5438871
12 14  0.5326 0.5425630 0.5499789
13 13  0.5332 0.5411714 0.5471048
14 15  0.5374 0.5522555 0.5633130
15 12  0.5402 0.5546542 0.5654131
16 17  0.5416 0.5499582 0.5561795
17 16  0.5422 0.5568134 0.5676908
18 24  0.5514 0.5632823 0.5721268
19 18  0.5570 0.5706960 0.5808905
20 20  0.5576 0.5682114 0.5761100
21 19  0.5600 0.5699275 0.5773169
22 21  0.5656 0.5766019 0.5847911
23 22  0.5674 0.5797099 0.5888727
24 25  0.5738 0.5844089 0.5923055
25 23  0.5758 0.5904321 0.6013233
```

置信区间，特别是 Bonferroni−Dunn 置信区间——如前所述，更加可靠——表明，任何前`k`个值的预测能力大致相同。对于 4 个邻居的`bonfCI`值延伸至包括 5 个邻居的`meanAcc`值。

请注意这里`nXval`的作用。我们使用的交叉验证次数太少了。我们应该尝试更多的交叉验证次数，但如果不能，我们选择的`k`值（1、2、3、4 和 7）看起来差不多。保守地说，我们可能会选择使用 3 或 4 个邻居。

### 7.5 示例：音素数据

这个数据集包含在`regtools`包中，旨在根据五个声音测量值预测两种音素类型中的一种。我们来看看：

```
> head(phoneme)
         V1        V2        V3        V4        V5 lbl
0  0.489927 -0.451528 -1.047990 -0.598693 -0.020418   1
1 -0.641265  0.109245  0.292130 -0.916804  0.240223   1
2  0.870593 -0.459862  0.578159  0.806634  0.835248   1
3 -0.628439 -0.316284  1.934295 -1.427099 -0.136583   1
4 -0.596399  0.015938  2.043206 -1.688448 -0.948127   1
5  0.164735 -0.642728 -0.980619 -0.386415 -0.242046   1
> dim(phoneme)
[1] 5404    6
```

这里的*Y*列是`lbl`。如前所述，它有两个级别，所以这是一个二类分类问题。

让我们在这组数据上尝试`qeDT()`。如前所述，各种超参数之间是相互影响的，所以一开始我们可能不尝试使用所有超参数。我们可能只使用，比如，`alpha`、`minbucket`和`maxdepth`。

我们需要为这些参数指定我们希望调查的范围。同样，这没有一个固定的公式来决定，必须通过经验积累来获得洞察。但作为示例，我们可以尝试`alpha`的值为 0.01、0.05、0.10、0.25、0.50 和 1，`minbucket`的值为 1、5 和 10，等等，如调用中所示：

```
> z <- qeFT(phoneme,'lbl','qeDT',list(alpha=c(0.01,0.05,0.10,0.25,0.50,1),
   minbucket=c(1,5,10),maxdepth=c(3,8),minsplit=c(1,5,10),mtry=c(0,3)),
   50,1000,5,showProgress=T)
> z
$outdf
   alpha minbucket maxdepth minsplit mtry meanAcc        CI    bonfCI
1   1.00         1        8        5    0  0.1150 0.1284351 0.1401622
2   1.00         5        8       10    0  0.1176 0.1224275 0.1266412
3   1.00         5        8        1    0  0.1180 0.1238801 0.1290127
4   0.25         1        8        5    0  0.1218 0.1344352 0.1454640
5   1.00        10        8        1    3  0.1276 0.1403232 0.1514289
6   0.10         1        8        1    0  0.1310 0.1412380 0.1501744
7   1.00        10        8       10    3  0.1336 0.1380151 0.1418689
8   0.05         5        8       10    0  0.1338 0.1386500 0.1428834
9   0.05         5        8        1    0  0.1358 0.1429046 0.1491060
10  0.50         1        8        5    3  0.1362 0.1507200 0.1633940
11  0.01         1        8       10    0  0.1376 0.1416952 0.1452698
12  0.10        10        8       10    0  0.1408 0.1442374 0.1472378
13  0.50         5        8        5    3  0.1448 0.1543984 0.1627765
14  0.05         1        8        1    0  0.1466 0.1511066 0.1550404
15  0.25         5        8       10    3  0.1480 0.1609606 0.1722736
16  0.01         5        8       10    0  0.1486 0.1535665 0.1579015
17  0.10        10        8        1    3  0.1502 0.1631963 0.1745404
18  0.25        10        8        1    3  0.1536 0.1682711 0.1810770
19  0.25         5        8        5    3  0.1548 0.1731395 0.1891475
20  0.10         1        8        1    3  0.1552 0.1629286 0.1696747
...
46  0.50        10        3       10    3  0.2210 0.2279024 0.2339274
47  0.10        10        3       10    3  0.2216 0.2274476 0.2325518
48  0.50        10        3        1    3  0.2224 0.2302890 0.2371751
49  0.25         1        3       10    3  0.2228 0.2301494 0.2365645
50  0.01         5        3        5    3  0.2238 0.2333700 0.2417233
```

回想一下`nCombs`的作用。如果将其设置为`NULL`，则意味着我们希望`qeFT()`尝试所有可能的超参数组合范围。结果显示，共有 216 种组合（未展示）。但我们将`nCombs`设置为 50，因此`qeFT()`在 216 种组合中随机选择了 50 种进行测试，因此我们在此只看到 50 行输出。

一个机器学习算法的超参数越多，我们尝试的每个超参数值越多，我们就有更多的可能组合。在某些情况下，组合数实在太多，无法尝试所有可能的组合，因此需要使用非`NULL`的`nCombs`。

还要注意的是，我们运行的超参数组合越多，p-hacking 的风险就越大。此时，`bonfCI`列最为有用。事实上，在上面的输出中，`bonfCI`列在大多数情况下与`CI`列非常接近，这告诉我们 p-hacking 在这组数据中可能不是一个问题。

那么，我们能从这些输出中得出什么结论呢？

1.  超参数调优很重要。最低的 OME 值大约是最大 OME 值的一半。

1.  由于前面三个`CI`值非常接近，并且都在彼此的置信区间内，因此前三个超参数组合中的任何一个都应该是好的选择。

1.  前 20 个超参数组合的`maxdepth`值都为 8。这表明，值大于 8 的情况下可能会表现得更好。

1.  较大的`alpha`值似乎表现得更好。这表明我们可以尝试一些额外的大值。例如，我们没有尝试 0.50 到 1 之间的任何值，因此 0.75 可能值得一试。

1.  排名前三的组合的`mtry`值都为 0，而排名靠后的组合则在该超参数上取值为 3。我们可能应该在这里做更详细的调查。

1.  超参数确实存在相互作用。例如，看第 6 行。`alpha`的值比大多数最优行的值要小，这在一定程度上抑制了节点分裂过程，但通过设置较小的`minsplit`和`minbucket`，这种抑制得到了部分补偿，这两者有助于大量节点分裂。这种负面“相关性”在`qeFT()`的图形显示功能中非常明显（未展示）。

### 7.6 结论

毫无疑问，找到一组好的超参数是机器学习中的一个主要挑战。但在本章中，我们已经看到了可以用于这个目的的工具，我们可以合理地相信我们已经做出了一个好的选择。
