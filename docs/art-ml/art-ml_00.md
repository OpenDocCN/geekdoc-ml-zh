## 前言

![Image](img/common.jpg)

机器学习！以这样一个科幻感十足的名字，人们可能会认为它是技术，只适用于那些博学的专家。事实并非如此。

事实上，机器学习（ML）可以用常识性的术语来轻松解释，任何对图表、图形以及直线的斜率有一定了解的人都应该能够理解并有效地*使用*机器学习。当然，正如谚语所说，“魔鬼藏在细节中”，必须通过这些细节。然而，尽管机器学习是如此强大的工具，它并不是火箭科学。

### 0.1 什么是机器学习？

机器学习的核心是预测。一个病人是否患有某种疾病？一个客户是否会从当前的手机服务商换到别的？在这段听起来有些混乱的音频记录中，实际上说了什么？卫星观察到的那个亮点是森林火灾，还是仅仅是一个反射？

我们从一个或多个*特征*中预测一个*结果*。在疾病诊断的例子中，结果是是否患病，特征可能包括血液检查、家族病史等等。

所有机器学习方法都涉及一个简单的概念：相似性。在手机服务的例子中，我们如何预测某个客户的结果？我们查看过去的客户，选择与当前客户在特征（账单大小、延迟记录、年收入等）上最相似的那些客户。如果这些相似的客户大多数都离开了，我们就预测当前客户也会离开。当然，我们不能保证这个结果，但这是我们最好的猜测。

### 0.2 数学在机器学习理论与实践中的角色

许多机器学习方法基于优雅的数学理论，支持向量机（SVM）就是一个显著的例子。然而，掌握这些理论在实际应用中对应用支持向量机的能力几乎没有帮助。

诚然，良好的*直观*理解机器学习方法的工作原理对于在实践中有效使用机器学习至关重要。本书力求培养读者对直觉的敏锐理解，*不使用高等数学*。实际上，本书中几乎没有方程式。

### 0.3 为什么要另写一本机器学习书籍？

当然，市面上有很多很棒的机器学习书籍，但没有一本真正能够*赋能*读者在现实问题中有效使用机器学习。在很多情况下，问题在于书籍过于理论化，但我同样担心那些应用类书籍往往像“食谱书”（过于“按步骤操作”），以一种步骤 1、步骤 2、步骤 3 的方式来处理问题。它们的重点是机器学习软件的语法和语义，导致虽然读者可能熟悉软件，但他们并没有准备好去*有效使用*机器学习。

我写这本书是因为：

+   需要一本*使用*R 语言而不是*关于*R 的书。这是一本关于机器学习的书，恰好使用 R 作为示例，而不是一本关于 R 在机器学习中应用的书。

+   有一本机器学习书籍是必要的，它认识到*机器学习是一门艺术，而非一门科学*。（这也是本书标题的由来。）

+   目前缺少一本避免高阶数学却能够强调一个观点的机器学习书籍——即为了有效使用机器学习，*确实需要深入理解相关概念——机器学习方法的“为什么”和“如何”。* 大多数“应用型”机器学习书籍在这方面讲得不够。

这三点都回归到“反菜谱”主题。我的目标是：

我希望使用机器学习的人不仅知道随机森林的定义，还能清晰地解释随机森林中各个超参数如何影响过拟合。机器学习者还应该能够清楚地阐述特征工程中的“p-hacking”问题。

我们将*赋能*读者，提供强大的、*实用的*机器学习方法的现实世界知识——它们的优缺点，是什么让它们成功与失败，应该注意哪些问题。我们将避免复杂的数学形式，且肯定会采用实践导向的方法，使用流行的软件包在真实数据集上进行操作。但我们将以一种聪明的方式进行。我们将成为“知情的消费者”。

### 0.4 特殊的反复出现的章节

本书中有一些反复出现的主题和章节：

**偏差与方差**

许多段落具体说明——没有迷信！——这两个核心概念在每种具体的机器学习方法中如何体现。

**陷阱**

许多标有“陷阱”标题的章节提醒读者潜在的问题，并展示如何避免它们。

### 0.5 需要的背景知识

读者需要什么样的背景才能有效地使用本书？

+   本书不假设读者有机器学习或统计学的先前经验。

+   一般来说，关于数学，本书大部分内容没有正式的方程式。只要读者对基本图表（如直方图和散点图）以及简单的代数概念（如直线的斜率）感到熟悉，就足够了。

+   本书假设读者具备一定的 R 编程背景，例如对向量、因子、数据框和函数有所了解。本书贯穿使用 R 命令行（> 提示符，RStudio 控制台）。没有 R 背景的读者，或者希望复习的读者，可以参考我的 `fasteR` 教程：[*https://github.com/matloff/fasteR*](https://github.com/matloff/fasteR)。

+   确保你已经在电脑上安装了 R 和 `qeML` 包。对于该包，推荐的安装源是 GitHub，因为它总是包含该包的最新版本。你需要安装 `devtools` 包；如果尚未安装，可以输入：

    ```
    install.packages('devtools')
    ```

    然后，要安装 `qeML`，请输入：

    ```
    install_github('https://github.com/matloff/qeML')
    ```

    `qeML` 包也会在 CRAN R 代码库中提供，但更新频率较低。

### **0.6 qe*-Series 软件**

本书中大部分使用的软件将来自流行的 R 包：

+   `e1071`

+   `gbm`

+   `glmnet`

+   `keras`

+   `randomForest`

读者可以直接使用这些包。如果读者愿意，通常我们会使用这些包的函数封装，封装在我的包`qeML`中，这对于读者有很大帮助，主要体现在两个方面：

1.  包装器提供了一个统一的接口。

1.  这个统一接口也是***简单***的。

例如，考虑`day1`，这是本书中在多个地方使用的自行车租赁数据集。我们希望预测`tot`，即总骑行量。以下是我们如何使用随机森林来实现这一点的步骤，这是本书中介绍的机器学习话题：

```
qeRF(day1,'tot')
```

对于支持向量机，另一个重要话题，调用方法是：

```
qeSVM(day1,'tot')
```

等等。简单到不能再简单了！比如，没有必要编写定义模型的准备代码；只需调用`qe`函数之一，直接开始！前缀`qe`-代表“快速简便”。还可以指定特定方法的参数，我们也会这样做，但总的来说，依然非常简单。

对于非常高级的用法，本书展示了如何直接使用这些包。

### 0.7 本书的宏大计划

这里是我们将要走的路径。前面三章介绍了书中反复出现的一些通用概念以及具体的机器学习方法。上面提到的机器学习简要描述——基于相似案例进行预测——最容易通过一种叫做*k 近邻（k-NN）*的机器学习方法来实现。第一部分将承担两个角色。首先，它将详细介绍 k-NN。其次，它将向读者介绍适用于所有机器学习方法的通用概念，如*超参数*的选择。在 k-NN 中，通常表示为*k*的相似案例数量是超参数。对于 k-NN，什么是*k*的“黄金法则”值——既不太小也不太大？同样，超参数的选择在大多数机器学习方法中都至关重要，并将在 k-NN 中进行介绍。

第二部分将介绍 k-NN 的自然扩展——*基于树的方法*，具体是*随机森林*和*梯度提升*。这些方法以类似流程图的方式工作，逐个询问特征问题。在前面的疾病诊断示例中，第一个问题可能是，患者是否超过 50 岁？接下来的问题可能是，患者的体重指数是否低于 20.2？最终，这个过程将患者分成相似的小组，所以它有点像 k-NN。但这些组与 k-NN 的形式不同，树方法通常在预测准确性上超过 k-NN，并被认为是主要的机器学习工具。

第三部分讨论了基于线性关系的方法。有一定线性回归分析背景的读者可能会认出其中的一些内容，尽管再次强调，假设读者没有这方面的背景知识。本部分最后讨论了*LASSO*和*岭回归*，这两种方法有一个诱人的特点，即故意缩小一些经典线性回归的估计值。

第四部分涉及基于分隔线和平面的算法方法。再次考虑手机服务的例子。假设我们用蓝色在图表中绘制了离开服务的老客户的数据。然后，在同一张图上，我们用红色绘制了那些仍然忠诚的客户。我们能找到一条直线，将大部分蓝色点与大部分红色点分开吗？如果能，那么我们将通过检查新客户的案例在哪一侧来预测他的行为。这一描述不仅适用于*SVM*，在某种意义上，也适用于最著名的机器学习方法之一——*神经网络*，我们也将介绍它。

最后，第五部分介绍了几种特定类型的机器学习应用，比如*图像分类*。

常说，没有一种机器学习方法在所有应用中都表现最佳。的确如此，但希望本书的结构能帮助你理解不同方法之间的相似性和差异，理解每种方法在整体中的适用场景。

本书有一个网站，[*http://heather.cs.ucdavis.edu/artofml*](http://heather.cs.ucdavis.edu/artofml)，其中包含代码、更正、新示例等内容。

### 0.8 另一个要点

在阅读本书时，请记住，*文笔和代码同样重要*。避免仅专注于代码和图表。一个全是文字的页面——没有数学公式、没有图表、没有代码——可能是书中最重要的页面。在这一页，你将学习到机器学习中至关重要的*为什么*，比如为什么超参数的选择如此关键。文笔对你掌握机器学习的目标至关重要，它能帮助你获得最深刻的见解和预测能力！

请记住，你听到的那些令人眼花缭乱的机器学习成功案例，往往是在分析师经过仔细、长期的调优和思考后才出现的，这需要真正的洞察力。本书旨在培养这种洞察力。这里的正式数学内容最小化，但请注意，这意味着数学将让位于描述许多关键问题的文字。

那么，开始吧。祝你在机器学习中愉快！
