- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://dafriedman97.github.io/mlbook/content/c3/code.html](https://dafriedman97.github.io/mlbook/content/c3/code.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This section will demonstrate how to fit the discriminative classifiers discussed
    in this chapter with `scikit-learn`. Note that other libraries are frequently
    used—e.g. `statsmodels` for logistic regresssion and `tensorflow` for the perceptron.
  prefs: []
  type: TYPE_NORMAL
- en: For binary tasks, we’ll be using the [breast cancer](../appendix/data.html)
    dataset and for multiclass tasks, we’ll be using the [wine](../appendix/data.html)
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Logistic Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Binary Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A standard `scikit-learn` implementation of binary logistic regression is shown
    below. Note the two arguments set when instantiating the model: `C` is a regularization
    term where a higher `C` indicates *less* penalty on the magnitude of the coefficients
    and `max_iter` determines the maximum number of iterations the solver will use.
    We set `C` to be arbitrarily high such that there is effectively no regulariation
    and `max_iter` to be 1,000, which is enough for this model to converge.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`scikit-learn`’s logistic regression model can return two forms of predictions:
    the predicted classes or the predicted probabilities. The `.predict()` method
    predicts an observation for each class while `.predict_proba()` gives the probability
    for all classes included in the training set (in this case, just 0 and 1).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Multiclass Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Multiclass logistic regression can be fit in `scikit-learn` as below. In fact,
    no arguments need to be changed in order to fit a multiclass model versus a binary
    one. However, the implementation below adds one new argument. Setting `multiclass`
    equal to ‘multinomial’ tells the model explicitly to follow the algorithm introduced
    in the [concept section](s2/logistic_regression.html). This will be done by default
    for non-binary problems unless the `solver` is set to ‘liblinear’. In that case,
    it will fit a “[one-versus-rest](https://www.google.com/search?q=one+versus+rest+classifier&oq=one+versus+rest+classifier&aqs=chrome..69i57j0l4j69i64.3569j0j1&sourceid=chrome&ie=UTF-8)”
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Again, we can see the predicted classes and predicted probabilities for each
    class, as below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The Perceptron Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The perceptron algorithm is implemented below. This algorithm is rarely used
    in practice but serves as an important part of neural networks, the topic of Chapter
    7.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Fisher’s Linear Discriminant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we fit Fisher’s Linear Discriminant with the `LinearDiscriminantAnalysis`
    class from `scikit-learn`. This class can also be viewed as a generative model,
    which is discussed in the next chapter, but the implementation below reduces to
    the discriminative classifier derived in the concept section. Specifying `n_components
    = 1` tells the model to reduce the data to one dimension. This is the equivalent
    of generating the
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\bx_n) = \bbeta^\top \bx_n \]
  prefs: []
  type: TYPE_NORMAL
- en: transformations that we saw in the concept section. We can then see if the two
    classes are separated by checking that either 1) \(f(\bx_n) < f(\bx_m)\) for all
    \(n\) in class 0 and \(m\) in class 1 or 2) \(f(\bx_n) > f(\bx_m)\) for all \(n\)
    in class 0 and \(m\) in class 1\. Equivalently, we can see that the two classes
    are not separated in the histogram below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/code_20_0.png](../Images/19e8f02c59c9b29f4ab3056d2d3c0dec.png)'
  prefs: []
  type: TYPE_IMG
- en: Logistic Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Binary Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A standard `scikit-learn` implementation of binary logistic regression is shown
    below. Note the two arguments set when instantiating the model: `C` is a regularization
    term where a higher `C` indicates *less* penalty on the magnitude of the coefficients
    and `max_iter` determines the maximum number of iterations the solver will use.
    We set `C` to be arbitrarily high such that there is effectively no regulariation
    and `max_iter` to be 1,000, which is enough for this model to converge.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`scikit-learn`’s logistic regression model can return two forms of predictions:
    the predicted classes or the predicted probabilities. The `.predict()` method
    predicts an observation for each class while `.predict_proba()` gives the probability
    for all classes included in the training set (in this case, just 0 and 1).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Multiclass Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Multiclass logistic regression can be fit in `scikit-learn` as below. In fact,
    no arguments need to be changed in order to fit a multiclass model versus a binary
    one. However, the implementation below adds one new argument. Setting `multiclass`
    equal to ‘multinomial’ tells the model explicitly to follow the algorithm introduced
    in the [concept section](s2/logistic_regression.html). This will be done by default
    for non-binary problems unless the `solver` is set to ‘liblinear’. In that case,
    it will fit a “[one-versus-rest](https://www.google.com/search?q=one+versus+rest+classifier&oq=one+versus+rest+classifier&aqs=chrome..69i57j0l4j69i64.3569j0j1&sourceid=chrome&ie=UTF-8)”
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Again, we can see the predicted classes and predicted probabilities for each
    class, as below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Binary Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A standard `scikit-learn` implementation of binary logistic regression is shown
    below. Note the two arguments set when instantiating the model: `C` is a regularization
    term where a higher `C` indicates *less* penalty on the magnitude of the coefficients
    and `max_iter` determines the maximum number of iterations the solver will use.
    We set `C` to be arbitrarily high such that there is effectively no regulariation
    and `max_iter` to be 1,000, which is enough for this model to converge.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`scikit-learn`’s logistic regression model can return two forms of predictions:
    the predicted classes or the predicted probabilities. The `.predict()` method
    predicts an observation for each class while `.predict_proba()` gives the probability
    for all classes included in the training set (in this case, just 0 and 1).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Multiclass Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Multiclass logistic regression can be fit in `scikit-learn` as below. In fact,
    no arguments need to be changed in order to fit a multiclass model versus a binary
    one. However, the implementation below adds one new argument. Setting `multiclass`
    equal to ‘multinomial’ tells the model explicitly to follow the algorithm introduced
    in the [concept section](s2/logistic_regression.html). This will be done by default
    for non-binary problems unless the `solver` is set to ‘liblinear’. In that case,
    it will fit a “[one-versus-rest](https://www.google.com/search?q=one+versus+rest+classifier&oq=one+versus+rest+classifier&aqs=chrome..69i57j0l4j69i64.3569j0j1&sourceid=chrome&ie=UTF-8)”
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Again, we can see the predicted classes and predicted probabilities for each
    class, as below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The Perceptron Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The perceptron algorithm is implemented below. This algorithm is rarely used
    in practice but serves as an important part of neural networks, the topic of Chapter
    7.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Fisher’s Linear Discriminant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we fit Fisher’s Linear Discriminant with the `LinearDiscriminantAnalysis`
    class from `scikit-learn`. This class can also be viewed as a generative model,
    which is discussed in the next chapter, but the implementation below reduces to
    the discriminative classifier derived in the concept section. Specifying `n_components
    = 1` tells the model to reduce the data to one dimension. This is the equivalent
    of generating the
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\bx_n) = \bbeta^\top \bx_n \]
  prefs: []
  type: TYPE_NORMAL
- en: transformations that we saw in the concept section. We can then see if the two
    classes are separated by checking that either 1) \(f(\bx_n) < f(\bx_m)\) for all
    \(n\) in class 0 and \(m\) in class 1 or 2) \(f(\bx_n) > f(\bx_m)\) for all \(n\)
    in class 0 and \(m\) in class 1\. Equivalently, we can see that the two classes
    are not separated in the histogram below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/code_20_0.png](../Images/19e8f02c59c9b29f4ab3056d2d3c0dec.png)'
  prefs: []
  type: TYPE_IMG
