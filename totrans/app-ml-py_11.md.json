["```py\nignore_warnings = True                                        # ignore warnings?\nimport numpy as np                                            # ndarrays for gridded data\nimport pandas as pd                                           # DataFrames for tabular data\nfrom sklearn.impute import SimpleImputer                      # basic imputation method\nfrom sklearn.impute import KNNImputer                         # k-nearest neighbour imputation method\nfrom sklearn.experimental import enable_iterative_imputer     # required for MICE imputation\nfrom sklearn.impute import IterativeImputer                   # MICE imputation\nimport os                                                     # set working directory, run executables\nimport math                                                   # basic math operations\nimport random                                                 # for random numbers\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nfrom matplotlib.colors import ListedColormap                  # custom color maps\nimport matplotlib.ticker as mtick                             # control tick label formatting\nimport seaborn as sns                                         # for matrix scatter plots\nfrom scipy import stats                                       # summary statistics\nimport numpy.linalg as linalg                                 # for linear algebra\nimport scipy.spatial as sp                                    # for fast nearest neighbor search\nimport scipy.signal as signal                                 # kernel for moving window calculation\nfrom numba import jit                                         # for numerical speed up\nfrom statsmodels.stats.weightstats import DescrStatsW\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map\nseed = 73071                                                  # random seed\nnp.random.seed(seed=seed) \n```", "```py\ndef add_grid():                                               # add major and minor gridlines\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"c:/PGE383\")                                        # set the working directory \n```", "```py\nidata = 0\n\nif idata == 0:\n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n    df.drop('Prod',axis=1,inplace=True)\n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting\n\n    flabel = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\n\n    ftitle = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\n\nelif idata == 1:\n    names = {'Porosity':'Por'}\n\n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository \n    df = df.rename(columns=names)\n    df['Por'] = df['Por'] * 100.0; df['AI'] = df['AI'] / 1000.0; \n    df.drop('Unnamed: 0',axis=1,inplace=True) \n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [0.0,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax = [10000.0,10000.0,1.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    flabel = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ftitle = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']\n\nelif idata == 2:  \n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository \n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    flabel = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ftitle = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus'] \n```", "```py\nPormin = np.min(df['Por'].values)                             # extract ndarray of data table column\nPormax = np.max(df['Por'].values)                             # and calculate min and max \n```", "```py\ndf.head(n=13)                                                 # DataFrame preview \n```", "```py\nproportion_NaN = 0.1 \n```", "```py\nnp.random.random(df.shape) \n```", "```py\nremove = np.random.random(df.shape) < proportion_NaN \n```", "```py\ndf_mask = df.mask(remove) \n```", "```py\nif idata == 0 or idata == 1:\n    proportion_NaN = 0.1                                          # proportion of values in DataFrame to remove\n    np.random.seed(seed=seed)                                     # ensure repeatability\n    remove = np.random.random(df.shape) < proportion_NaN          # make the boolean array for removal\n    if idata == 1:\n        remove[:,df.columns.get_loc('Facies')] = False            # avoid categoical imputation at this time \n    print('Fraction of removed values in mask ndarray = ' + str(round(remove.sum()/remove.size,3)) + '.')\n\n    df_mask = df.mask(remove)\nelse:\n    df_mask = df.copy(deep = True)\n\nprint('Fraction of nan values in the DataFrame = ' + str(round(df_mask.isnull().sum().sum()/(df_mask.shape[0]*df_mask.shape[1]),3)) + '.') \n```", "```py\nFraction of removed values in mask ndarray = 0.093.\nFraction of nan values in the DataFrame = 0.093. \n```", "```py\ndf_mask.head(n=13)                                            # DataFrame preview \n```", "```py\ndf_mask.describe().transpose()                                # DataFrame summary statistics \n```", "```py\nplt.subplot(111)                                              # data completeness plot\n(df_mask.isnull().sum()/len(df)).plot(kind = 'bar',color='darkorange',edgecolor='black') \nplt.xlabel('Feature'); plt.ylabel('Percentage of Missing Values'); plt.title('Data Completeness'); plt.ylim([0.0,1.0])\nplt.plot([-0.5,df.shape[1]+0.5],[0.1,0.1],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\ndf_test = df_mask.drop('VR',axis = 1) \n```", "```py\nif idata == 0:\n    drop_features = ['Perm','VR']\nelif idata == 1:\n    drop_features = []\nelif idata == 2:\n    drop_features = ['Youngs','Shear']\n\ndf_test = df_mask.drop(drop_features,axis = 1)\n\nplt.subplot(111)\n(df_test.isnull().sum()/len(df)).plot(kind = 'bar',color='darkorange',edgecolor='black')                # calculate DataFrame with percentage missing by feature\nplt.xlabel('Feature'); plt.ylabel('Percentage of Missing Values'); plt.title('Data Completeness'); plt.ylim([0.0,1.0])\nplt.plot([-0.5,df.shape[1]+0.5],[0.1,0.1],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\n(df_mask.isnull().sum(axis=1)/len(df.columns)).plot(kind = 'bar',color='darkorange',edgecolor='black')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.2, top=1.2, wspace=0.2, hspace=0.2) # plot formatting\nplt.xlabel('Sample Index'); plt.ylabel('Percentage of Missing Records'); plt.title('Data Completeness')\nplt.xticks(np.arange(0,len(df_mask),10),np.arange(0,len(df_mask),10))\nplt.ylim([0,1.0])\nplt.plot([-0.5,len(df)+0.5],[0.2,0.2],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\ndf_test = df_mask.drop('Water',axis = 1) \n```", "```py\n(df_mask.isnull().sum(axis=1)/len(df.columns)) > max_proportion_missing_by_sample \n```", "```py\nindex_low_coverage_samples = np.asarray(np.where(low_coverage_samples == True))[0] \n```", "```py\ndf_test2 = df_mask.drop(index = index_low_coverage_samples,axis = 0) \n```", "```py\nmax_proportion_missing_by_sample = 0.2\n\nlow_coverage_samples = (df_mask.isnull().sum(axis=1)/len(df.columns)) > max_proportion_missing_by_sample \nindex_low_coverage_samples = np.asarray(np.where(low_coverage_samples == True))[0]\n\ndf_test2 = df_mask.drop(index = index_low_coverage_samples,axis = 0)\n\n(df_test2.isnull().sum(axis=1)/len(df_test2.columns)).plot(kind = 'bar',color='darkorange',edgecolor='black')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.2, top=1.2, wspace=0.2, hspace=0.2) # plot formatting\nplt.xlabel('Updated Sample Index'); plt.ylabel('Percentage of Missing Records'); plt.title('Data Completeness')\nplt.xticks(np.arange(0,len(df_mask),10),np.arange(0,len(df_mask),10))\nplt.ylim([0,1.0])\nplt.plot([-0.5,len(df)+0.5],[0.2,0.2],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\ndf_listwise = df_mask.dropna(how='any',inplace=False)\n\nsns.pairplot(df_listwise.iloc[:,:-1], plot_kws={'alpha':0.5,'s':20},corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\n# df_likewise.head(n = 13) \n```", "```py\ndf_mask['Imputed'] = (df_mask.isnull().sum(axis=1)) > 0\ndf_mask.head() \n```", "```py\ndf_constant = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nconstant_imputer = SimpleImputer(strategy='constant',fill_value = 0.01)\ndf_constant.iloc[:,:] = constant_imputer.fit_transform(df_constant)\n\nsns.pairplot(df_constant.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5) \n```", "```py\ndf_mean = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nmean_imputer = SimpleImputer(strategy='mean')\ndf_mean.iloc[:,:] = mean_imputer.fit_transform(df_mean)\n\nsns.pairplot(df_mean.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mean.head(n=5) \n```", "```py\ndf_mode = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nmode_imputer = SimpleImputer(strategy='most_frequent')\ndf_mode.iloc[:,:] = mode_imputer.fit_transform(df_mode)\n\nsns.pairplot(df_mode.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mode.head(n=5) \n```", "```py\ndf_knn = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\ndf_knn.iloc[:,:] = knn_imputer.fit_transform(df_knn)\n\nsns.pairplot(df_knn.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mode.head(n=5) \n```", "```py\ndf_mice = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nmice_imputer = IterativeImputer()\ndf_mice.iloc[:,:] = mice_imputer.fit_transform(df_mice)\n\nsns.pairplot(df_mice.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mode.head(n=5) \n```", "```py\nsave_imputed = False                                          # save the imputed DataFrame?\n\nif save_imputed == True:\n    df_imputed = df_knn.copy(deep = True)                     # select the imputation method\n\n    df_imputed.drop('Imputed',axis=1,inplace=True) \n    file_name = r'dataframe_imputed.csv'\n\n    df_imputed.to_csv(file_name, index=False) \n```", "```py\nignore_warnings = True                                        # ignore warnings?\nimport numpy as np                                            # ndarrays for gridded data\nimport pandas as pd                                           # DataFrames for tabular data\nfrom sklearn.impute import SimpleImputer                      # basic imputation method\nfrom sklearn.impute import KNNImputer                         # k-nearest neighbour imputation method\nfrom sklearn.experimental import enable_iterative_imputer     # required for MICE imputation\nfrom sklearn.impute import IterativeImputer                   # MICE imputation\nimport os                                                     # set working directory, run executables\nimport math                                                   # basic math operations\nimport random                                                 # for random numbers\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nfrom matplotlib.colors import ListedColormap                  # custom color maps\nimport matplotlib.ticker as mtick                             # control tick label formatting\nimport seaborn as sns                                         # for matrix scatter plots\nfrom scipy import stats                                       # summary statistics\nimport numpy.linalg as linalg                                 # for linear algebra\nimport scipy.spatial as sp                                    # for fast nearest neighbor search\nimport scipy.signal as signal                                 # kernel for moving window calculation\nfrom numba import jit                                         # for numerical speed up\nfrom statsmodels.stats.weightstats import DescrStatsW\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map\nseed = 73071                                                  # random seed\nnp.random.seed(seed=seed) \n```", "```py\ndef add_grid():                                               # add major and minor gridlines\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"c:/PGE383\")                                        # set the working directory \n```", "```py\nidata = 0\n\nif idata == 0:\n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n    df.drop('Prod',axis=1,inplace=True)\n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting\n\n    flabel = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\n\n    ftitle = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\n\nelif idata == 1:\n    names = {'Porosity':'Por'}\n\n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository \n    df = df.rename(columns=names)\n    df['Por'] = df['Por'] * 100.0; df['AI'] = df['AI'] / 1000.0; \n    df.drop('Unnamed: 0',axis=1,inplace=True) \n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [0.0,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax = [10000.0,10000.0,1.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    flabel = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ftitle = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']\n\nelif idata == 2:  \n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository \n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    flabel = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ftitle = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus'] \n```", "```py\nPormin = np.min(df['Por'].values)                             # extract ndarray of data table column\nPormax = np.max(df['Por'].values)                             # and calculate min and max \n```", "```py\nidata = 0\n\nif idata == 0:\n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n    df.drop('Prod',axis=1,inplace=True)\n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting\n\n    flabel = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\n\n    ftitle = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\n\nelif idata == 1:\n    names = {'Porosity':'Por'}\n\n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository \n    df = df.rename(columns=names)\n    df['Por'] = df['Por'] * 100.0; df['AI'] = df['AI'] / 1000.0; \n    df.drop('Unnamed: 0',axis=1,inplace=True) \n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [0.0,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax = [10000.0,10000.0,1.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    flabel = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ftitle = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']\n\nelif idata == 2:  \n    df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository \n\n    features = df.columns.values.tolist()                          # store the names of the features\n\n    xmin = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    flabel = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ftitle = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus'] \n```", "```py\nPormin = np.min(df['Por'].values)                             # extract ndarray of data table column\nPormax = np.max(df['Por'].values)                             # and calculate min and max \n```", "```py\ndf.head(n=13)                                                 # DataFrame preview \n```", "```py\nproportion_NaN = 0.1 \n```", "```py\nnp.random.random(df.shape) \n```", "```py\nremove = np.random.random(df.shape) < proportion_NaN \n```", "```py\ndf_mask = df.mask(remove) \n```", "```py\nif idata == 0 or idata == 1:\n    proportion_NaN = 0.1                                          # proportion of values in DataFrame to remove\n    np.random.seed(seed=seed)                                     # ensure repeatability\n    remove = np.random.random(df.shape) < proportion_NaN          # make the boolean array for removal\n    if idata == 1:\n        remove[:,df.columns.get_loc('Facies')] = False            # avoid categoical imputation at this time \n    print('Fraction of removed values in mask ndarray = ' + str(round(remove.sum()/remove.size,3)) + '.')\n\n    df_mask = df.mask(remove)\nelse:\n    df_mask = df.copy(deep = True)\n\nprint('Fraction of nan values in the DataFrame = ' + str(round(df_mask.isnull().sum().sum()/(df_mask.shape[0]*df_mask.shape[1]),3)) + '.') \n```", "```py\nFraction of removed values in mask ndarray = 0.093.\nFraction of nan values in the DataFrame = 0.093. \n```", "```py\ndf_mask.head(n=13)                                            # DataFrame preview \n```", "```py\ndf_mask.describe().transpose()                                # DataFrame summary statistics \n```", "```py\nplt.subplot(111)                                              # data completeness plot\n(df_mask.isnull().sum()/len(df)).plot(kind = 'bar',color='darkorange',edgecolor='black') \nplt.xlabel('Feature'); plt.ylabel('Percentage of Missing Values'); plt.title('Data Completeness'); plt.ylim([0.0,1.0])\nplt.plot([-0.5,df.shape[1]+0.5],[0.1,0.1],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\ndf_test = df_mask.drop('VR',axis = 1) \n```", "```py\nif idata == 0:\n    drop_features = ['Perm','VR']\nelif idata == 1:\n    drop_features = []\nelif idata == 2:\n    drop_features = ['Youngs','Shear']\n\ndf_test = df_mask.drop(drop_features,axis = 1)\n\nplt.subplot(111)\n(df_test.isnull().sum()/len(df)).plot(kind = 'bar',color='darkorange',edgecolor='black')                # calculate DataFrame with percentage missing by feature\nplt.xlabel('Feature'); plt.ylabel('Percentage of Missing Values'); plt.title('Data Completeness'); plt.ylim([0.0,1.0])\nplt.plot([-0.5,df.shape[1]+0.5],[0.1,0.1],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\n(df_mask.isnull().sum(axis=1)/len(df.columns)).plot(kind = 'bar',color='darkorange',edgecolor='black')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.2, top=1.2, wspace=0.2, hspace=0.2) # plot formatting\nplt.xlabel('Sample Index'); plt.ylabel('Percentage of Missing Records'); plt.title('Data Completeness')\nplt.xticks(np.arange(0,len(df_mask),10),np.arange(0,len(df_mask),10))\nplt.ylim([0,1.0])\nplt.plot([-0.5,len(df)+0.5],[0.2,0.2],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\ndf_test = df_mask.drop('Water',axis = 1) \n```", "```py\n(df_mask.isnull().sum(axis=1)/len(df.columns)) > max_proportion_missing_by_sample \n```", "```py\nindex_low_coverage_samples = np.asarray(np.where(low_coverage_samples == True))[0] \n```", "```py\ndf_test2 = df_mask.drop(index = index_low_coverage_samples,axis = 0) \n```", "```py\nmax_proportion_missing_by_sample = 0.2\n\nlow_coverage_samples = (df_mask.isnull().sum(axis=1)/len(df.columns)) > max_proportion_missing_by_sample \nindex_low_coverage_samples = np.asarray(np.where(low_coverage_samples == True))[0]\n\ndf_test2 = df_mask.drop(index = index_low_coverage_samples,axis = 0)\n\n(df_test2.isnull().sum(axis=1)/len(df_test2.columns)).plot(kind = 'bar',color='darkorange',edgecolor='black')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.2, top=1.2, wspace=0.2, hspace=0.2) # plot formatting\nplt.xlabel('Updated Sample Index'); plt.ylabel('Percentage of Missing Records'); plt.title('Data Completeness')\nplt.xticks(np.arange(0,len(df_mask),10),np.arange(0,len(df_mask),10))\nplt.ylim([0,1.0])\nplt.plot([-0.5,len(df)+0.5],[0.2,0.2],color='red',ls='--')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=0.8, wspace=0.2, hspace=0.2); add_grid(); plt.show() \n```", "```py\ndf_listwise = df_mask.dropna(how='any',inplace=False)\n\nsns.pairplot(df_listwise.iloc[:,:-1], plot_kws={'alpha':0.5,'s':20},corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\n# df_likewise.head(n = 13) \n```", "```py\ndf_mask['Imputed'] = (df_mask.isnull().sum(axis=1)) > 0\ndf_mask.head() \n```", "```py\ndf_constant = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nconstant_imputer = SimpleImputer(strategy='constant',fill_value = 0.01)\ndf_constant.iloc[:,:] = constant_imputer.fit_transform(df_constant)\n\nsns.pairplot(df_constant.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5) \n```", "```py\ndf_mean = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nmean_imputer = SimpleImputer(strategy='mean')\ndf_mean.iloc[:,:] = mean_imputer.fit_transform(df_mean)\n\nsns.pairplot(df_mean.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mean.head(n=5) \n```", "```py\ndf_mode = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nmode_imputer = SimpleImputer(strategy='most_frequent')\ndf_mode.iloc[:,:] = mode_imputer.fit_transform(df_mode)\n\nsns.pairplot(df_mode.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mode.head(n=5) \n```", "```py\ndf_knn = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\ndf_knn.iloc[:,:] = knn_imputer.fit_transform(df_knn)\n\nsns.pairplot(df_knn.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mode.head(n=5) \n```", "```py\ndf_mice = df_mask.copy(deep=True)                         # make a deep copy of the DataFrame\nmice_imputer = IterativeImputer()\ndf_mice.iloc[:,:] = mice_imputer.fit_transform(df_mice)\n\nsns.pairplot(df_mice.iloc[:,:], hue=\"Imputed\", plot_kws={'alpha':0.15,'s':20}, palette = 'gnuplot', corner=True)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.5, top=0.6, wspace=0.1, hspace=0.2)\ndf_constant.head(n=5)\ndf_mode.head(n=5) \n```", "```py\nsave_imputed = False                                          # save the imputed DataFrame?\n\nif save_imputed == True:\n    df_imputed = df_knn.copy(deep = True)                     # select the imputation method\n\n    df_imputed.drop('Imputed',axis=1,inplace=True) \n    file_name = r'dataframe_imputed.csv'\n\n    df_imputed.to_csv(file_name, index=False) \n```"]