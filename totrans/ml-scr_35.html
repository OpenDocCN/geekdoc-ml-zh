<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Common Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Common Methods</h1>
<blockquote>原文：<a href="https://dafriedman97.github.io/mlbook/content/appendix/methods.html">https://dafriedman97.github.io/mlbook/content/appendix/methods.html</a></blockquote>

<div class="math notranslate nohighlight">
\[
\newcommand{\sumN}{\sum_{n = 1}^N}
\newcommand{\sumn}{\sum_n}
\newcommand{\prodN}{\prod_{n = 1}^N}
\newcommand{\by}{\mathbf{y}} \newcommand{\bX}{\mathbf{X}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbetahat}{\boldsymbol{\hat{\beta}}}
\newcommand{\bthetahat}{\boldsymbol{\hat{\theta}}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\dadb}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\iid}{\overset{\small{\text{i.i.d.}}}{\sim}}
\]</div>
<p>This section will review two methods that are used to fit a variety of machine learning models: <em>gradient descent</em> and <em>cross validation</em>. These methods will be used repeatedly throughout this book.</p>
<div class="section" id="gradient-descent">
<h2>1. Gradient Descent</h2>
<p>Almost all the models discussed in this book aim to find a set of parameters that minimize a chosen loss function. Sometimes we can find the optimal parameters by taking the derivative of the loss function, setting it equal to 0, and solving. In situations for which no closed-form solution is available, however, we might turn to gradient descent. <strong>Gradient descent</strong> is an iterative approach to approximating the parameters that minimize a differentiable loss function.</p>
<div class="section" id="the-set-up">
<h3>The Set-Up</h3>
<p>Let’s first introduce a typical set-up for gradient descent. Suppose we have <span class="math notranslate nohighlight">\(N\)</span> observations where each observation has predictors <span class="math notranslate nohighlight">\(\bx_n\)</span> and target variable <span class="math notranslate nohighlight">\(y_n\)</span>. We decide to approximate <span class="math notranslate nohighlight">\(y_n\)</span> with <span class="math notranslate nohighlight">\(\hat{y}_n = f(\bx_n, \bbetahat)\)</span>, where <span class="math notranslate nohighlight">\(f()\)</span> is some differentiable function and <span class="math notranslate nohighlight">\(\bbetahat\)</span> is a set of parameter estimates. Next, we introduce a differentiable loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. For simplicity, let’s assume we can write the model’s entire loss as the sum of the individual losses across observations. That is,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = \sumN g(y_n, \hat{y}_n),
\]</div>
<p>where <span class="math notranslate nohighlight">\(g()\)</span> is some differentiable function representing an observation’s individual loss.</p>
<p>To fit this generic model, we want to find the values of <span class="math notranslate nohighlight">\(\bbetahat\)</span> that minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. We will likely start with the following derivative:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\dadb{\mathcal{L}}{\bbetahat} &amp;= \sumN\dadb{g(y_n, \hat{y}_n)}{\bbetahat} \\
&amp;= \sumN\dadb{g(y_n, \hat{y}_n)}{\hat{y}_n}\cdot\dadb{\hat{y}_n}{\bbetahat}. \\
\end{align}
\end{split}\]</div>
<p>Ideally, we can set the above derivative equal to 0 and solve for <span class="math notranslate nohighlight">\(\bbetahat\)</span>, giving our optimal solution. If this isn’t possible, we can iteratively search for the values of <span class="math notranslate nohighlight">\(\bbetahat\)</span> that minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. This is the process of gradient descent.</p>
</div>
<div class="section" id="an-intuitive-introduction">
<h3>An Intuitive Introduction</h3>
<p><img alt="gd" src="../Images/4e6b365fc23689963cccc975a25ccc23.png" data-original-src="https://dafriedman97.github.io/mlbook/_images/gd.jpg"/></p>
<p>To understand this process intuitively, consider the image above showing a model’s loss as a function of one parameter, <span class="math notranslate nohighlight">\(\beta\)</span>.  We start our search for the optimal <span class="math notranslate nohighlight">\(\beta\)</span> by randomly picking a value. Suppose we start with <span class="math notranslate nohighlight">\(\beta\)</span> at point <span class="math notranslate nohighlight">\(A\)</span>. From point <span class="math notranslate nohighlight">\(A\)</span> we ask “would the loss function decrease if I increased or decreased <span class="math notranslate nohighlight">\(\beta\)</span>”. To answer this question, we calculate the derivative of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> with respect to <span class="math notranslate nohighlight">\(\beta\)</span> evaluated at <span class="math notranslate nohighlight">\(\beta = A\)</span>. Since this derivative is negative, we know that increasing <span class="math notranslate nohighlight">\(\beta\)</span> some small amount will decrease the loss.</p>
<p>Now we know we want to increase <span class="math notranslate nohighlight">\(\beta\)</span>, but how much? Intuitively, the more negative the derivative, the more the loss will decrease with an increase in <span class="math notranslate nohighlight">\(\beta\)</span>. So, let’s increase <span class="math notranslate nohighlight">\(\beta\)</span> by an amount proportional to the negative of the derivative. Letting <span class="math notranslate nohighlight">\(\delta\)</span> be the derivative and <span class="math notranslate nohighlight">\(\eta\)</span> be a small constant learning rate, we might increase <span class="math notranslate nohighlight">\(\beta\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\beta \gets \beta - \eta\delta.
\]</div>
<p>The more negative <span class="math notranslate nohighlight">\(\delta\)</span> is, the more we increase <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>Now suppose we make the increase and wind up with <span class="math notranslate nohighlight">\(\beta = B\)</span>. Calculating the derivative again, we get a slightly positive number. This tells us that we went too far: increasing <span class="math notranslate nohighlight">\(\beta\)</span> will increase <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. However, since the derivative is only <em>slightly</em> positive, we want to only make a slight correction. Let’s again use the same adjustment, <span class="math notranslate nohighlight">\(\beta \gets \beta - \eta\delta\)</span>. Since <span class="math notranslate nohighlight">\(\delta\)</span> is now slightly positive, <span class="math notranslate nohighlight">\(\beta\)</span> will now decrease slightly. We will repeat this same process a fixed number of times or until <span class="math notranslate nohighlight">\(\beta\)</span> barely changes. And that is gradient descent!</p>
</div>
<div class="section" id="the-steps">
<h3>The Steps</h3>
<p>We can describe gradient descent more concretely with the following steps. Note here that <span class="math notranslate nohighlight">\(\bbetahat\)</span> can be a vector, rather than just a single parameter.</p>
<ol>
<li><p>Choose a small learning rate <span class="math notranslate nohighlight">\(\eta\)</span></p></li>
<li><p>Randomly instantiate <span class="math notranslate nohighlight">\(\bbetahat\)</span></p></li>
<li><p>For a fixed number of iterations or until some stopping rule is reached:</p>
<ol>
<li><p>Calculate <span class="math notranslate nohighlight">\(\boldsymbol{\delta} = \partial \mathcal{L}/\partial \bbetahat\)</span></p></li>
<li><p>Adjust <span class="math notranslate nohighlight">\(\bbetahat\)</span> with</p>
<div class="math notranslate nohighlight">
\[
      \bbetahat \gets \bbetahat - \eta \boldsymbol{\delta}.
      \]</div>
</li>
</ol>
</li>
</ol>
<p>A potential stopping rule might be a minimum change in the magnitude of <span class="math notranslate nohighlight">\(\bbetahat\)</span> or a minimum decrease in the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
</div>
<div class="section" id="an-example">
<h3>An Example</h3>
<p>As a simple example of gradient descent in action, let’s derive the ordinary least squares (OLS) regression estimates. (This problem does have a closed-form solution, but we’ll use gradient descent to demonstrate the approach). As discussed in <a class="reference internal" href="../c1/concept.html"><span class="doc">Chapter 1</span></a>, linear regression models <span class="math notranslate nohighlight">\(\hat{y}_n\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_n = \bx_n^\top \bbetahat,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\bx_n\)</span> is a vector of predictors appended with a leading 1 and <span class="math notranslate nohighlight">\(\bbetahat\)</span> is a vector of coefficients. The OLS loss function is defined with</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\bbetahat) = \frac{1}{2}\sumN(y_n - \hat{y}_n)^2 = \frac{1}{2}\sumN (y_n - \bx^\top_n \bbetahat)^2.
\]</div>
<p>After choosing <span class="math notranslate nohighlight">\(\eta\)</span> and randomly instantiating <span class="math notranslate nohighlight">\(\bbetahat\)</span>, we iteratively calculate the loss function’s gradient:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\delta} = \dadb{\mathcal{L}(\bbetahat)}{\bbetahat} =  -\sumN(y_n - \bx^\top_n \bbetahat)\cdot\bphi_n^\top,
\]</div>
<p>and adjust with</p>
<div class="math notranslate nohighlight">
\[
\bbetahat \gets \bbetahat - \eta\boldsymbol{\delta}.
\]</div>
<p>This is accomplished with the following code. Note that we can also calculate <span class="math notranslate nohighlight">\(\boldsymbol{\delta} = -\bX^\top(\by - \hat{\by})\)</span>, where <span class="math notranslate nohighlight">\(\bX\)</span> is the <a class="reference internal" href="../conventions_notation.html"><span class="doc">feature matrix</span></a>, <span class="math notranslate nohighlight">\(\by\)</span> is the vector of targets, and <span class="math notranslate nohighlight">\(\hat{\by}\)</span> is the vector of fitted values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">OLS_GD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eta</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mf">1e4</span><span class="p">,</span> <span class="n">add_intercept</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
  
  <span class="c1">## Add Intercept</span>
  <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    
  <span class="c1">## Instantiate</span>
  <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  
  <span class="c1">## Iterate</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iter</span><span class="p">)):</span>
    
    <span class="c1">## Calculate Derivative</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_hat</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span>
    <span class="n">beta_hat</span> <span class="o">-=</span> <span class="n">delta</span><span class="o">*</span><span class="n">eta</span>
    
</pre></div>
</div>
</div>
</div>
<div class="section" id="cross-validation">
<h2>2. Cross Validation</h2>
<p>Several of the models covered in this book require <em>hyperparameters</em> to be chosen exogenously (i.e. before the model is fit). The value of these hyperparameters affects the quality of the model’s fit. So how can we choose these values without fitting a model? The most common answer is cross validation.</p>
<p>Suppose we are deciding between several values of a hyperparameter, resulting in multiple competing models. One way to choose our model would be to split our data into a <em>training</em> set and a <em>validation</em> set, build each model on the training set, and see which performs better on the validation set. By splitting the data into training and validation, we avoid evaluating a model based on its in-sample performance.</p>
<p>The obvious problem with this set-up is that we are comparing the performance of models on just <em>one</em> dataset. Instead, we might choose between competing models with <strong>K-fold cross validation</strong>, outlined below.</p>
<ol class="simple">
<li><p>Split the original dataset into <span class="math notranslate nohighlight">\(K\)</span> <em>folds</em> or subsets.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(k = 1, \dots, K\)</span>, treat fold <span class="math notranslate nohighlight">\(k\)</span> as the validation set. Train each competing model on the data from the other <span class="math notranslate nohighlight">\(K-1\)</span> folds and evaluate it on the data from the <span class="math notranslate nohighlight">\(k^\text{th}\)</span>.</p></li>
<li><p>Select the model with the best average validation performance.</p></li>
</ol>
<p>As an example, let’s use cross validation to choose a penalty value for a <a class="reference internal" href="../c2/s1/regularized.html"><span class="doc">Ridge regression</span></a> model, discussed in chapter 2. This model constrains the magnitude of the regression coefficients; the higher the penalty term, the more the coefficients are constrained.</p>
<p>The example below uses the <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> class from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, which defines the penalty term with the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> argument. We will use the <a class="reference internal" href="data.html"><span class="doc">Boston housing</span></a> dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="c1">## Import packages </span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>

<span class="c1">## Import data</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1">## Choose alphas to consider</span>
<span class="n">potential_alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">error_by_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">potential_alphas</span><span class="p">))</span>

<span class="c1">## Choose the folds </span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>

<span class="c1">## Iterate through folds</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
  
  <span class="c1">## Split Train and Validation</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
  
  <span class="c1">## Iterate through Alphas</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">potential_alphas</span><span class="p">)):</span>
    
        <span class="c1">## Train on Training Set</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">potential_alphas</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1">## Calculate and Append Error</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">y_val</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
        <span class="n">error_by_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">error</span>
    
<span class="n">error_by_alpha</span> <span class="o">/=</span> <span class="n">N</span>
</pre></div>
</div>
<p>We can then check <code class="docutils literal notranslate"><span class="pre">error_by_alpha</span></code> and choose the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> corresponding to the lowest average error!</p>
</div>
&#13;

<h2>1. Gradient Descent</h2>
<p>Almost all the models discussed in this book aim to find a set of parameters that minimize a chosen loss function. Sometimes we can find the optimal parameters by taking the derivative of the loss function, setting it equal to 0, and solving. In situations for which no closed-form solution is available, however, we might turn to gradient descent. <strong>Gradient descent</strong> is an iterative approach to approximating the parameters that minimize a differentiable loss function.</p>
<div class="section" id="the-set-up">
<h3>The Set-Up</h3>
<p>Let’s first introduce a typical set-up for gradient descent. Suppose we have <span class="math notranslate nohighlight">\(N\)</span> observations where each observation has predictors <span class="math notranslate nohighlight">\(\bx_n\)</span> and target variable <span class="math notranslate nohighlight">\(y_n\)</span>. We decide to approximate <span class="math notranslate nohighlight">\(y_n\)</span> with <span class="math notranslate nohighlight">\(\hat{y}_n = f(\bx_n, \bbetahat)\)</span>, where <span class="math notranslate nohighlight">\(f()\)</span> is some differentiable function and <span class="math notranslate nohighlight">\(\bbetahat\)</span> is a set of parameter estimates. Next, we introduce a differentiable loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. For simplicity, let’s assume we can write the model’s entire loss as the sum of the individual losses across observations. That is,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = \sumN g(y_n, \hat{y}_n),
\]</div>
<p>where <span class="math notranslate nohighlight">\(g()\)</span> is some differentiable function representing an observation’s individual loss.</p>
<p>To fit this generic model, we want to find the values of <span class="math notranslate nohighlight">\(\bbetahat\)</span> that minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. We will likely start with the following derivative:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\dadb{\mathcal{L}}{\bbetahat} &amp;= \sumN\dadb{g(y_n, \hat{y}_n)}{\bbetahat} \\
&amp;= \sumN\dadb{g(y_n, \hat{y}_n)}{\hat{y}_n}\cdot\dadb{\hat{y}_n}{\bbetahat}. \\
\end{align}
\end{split}\]</div>
<p>Ideally, we can set the above derivative equal to 0 and solve for <span class="math notranslate nohighlight">\(\bbetahat\)</span>, giving our optimal solution. If this isn’t possible, we can iteratively search for the values of <span class="math notranslate nohighlight">\(\bbetahat\)</span> that minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. This is the process of gradient descent.</p>
</div>
<div class="section" id="an-intuitive-introduction">
<h3>An Intuitive Introduction</h3>
<p><img alt="gd" src="../Images/4e6b365fc23689963cccc975a25ccc23.png" data-original-src="https://dafriedman97.github.io/mlbook/_images/gd.jpg"/></p>
<p>To understand this process intuitively, consider the image above showing a model’s loss as a function of one parameter, <span class="math notranslate nohighlight">\(\beta\)</span>.  We start our search for the optimal <span class="math notranslate nohighlight">\(\beta\)</span> by randomly picking a value. Suppose we start with <span class="math notranslate nohighlight">\(\beta\)</span> at point <span class="math notranslate nohighlight">\(A\)</span>. From point <span class="math notranslate nohighlight">\(A\)</span> we ask “would the loss function decrease if I increased or decreased <span class="math notranslate nohighlight">\(\beta\)</span>”. To answer this question, we calculate the derivative of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> with respect to <span class="math notranslate nohighlight">\(\beta\)</span> evaluated at <span class="math notranslate nohighlight">\(\beta = A\)</span>. Since this derivative is negative, we know that increasing <span class="math notranslate nohighlight">\(\beta\)</span> some small amount will decrease the loss.</p>
<p>Now we know we want to increase <span class="math notranslate nohighlight">\(\beta\)</span>, but how much? Intuitively, the more negative the derivative, the more the loss will decrease with an increase in <span class="math notranslate nohighlight">\(\beta\)</span>. So, let’s increase <span class="math notranslate nohighlight">\(\beta\)</span> by an amount proportional to the negative of the derivative. Letting <span class="math notranslate nohighlight">\(\delta\)</span> be the derivative and <span class="math notranslate nohighlight">\(\eta\)</span> be a small constant learning rate, we might increase <span class="math notranslate nohighlight">\(\beta\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\beta \gets \beta - \eta\delta.
\]</div>
<p>The more negative <span class="math notranslate nohighlight">\(\delta\)</span> is, the more we increase <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>Now suppose we make the increase and wind up with <span class="math notranslate nohighlight">\(\beta = B\)</span>. Calculating the derivative again, we get a slightly positive number. This tells us that we went too far: increasing <span class="math notranslate nohighlight">\(\beta\)</span> will increase <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. However, since the derivative is only <em>slightly</em> positive, we want to only make a slight correction. Let’s again use the same adjustment, <span class="math notranslate nohighlight">\(\beta \gets \beta - \eta\delta\)</span>. Since <span class="math notranslate nohighlight">\(\delta\)</span> is now slightly positive, <span class="math notranslate nohighlight">\(\beta\)</span> will now decrease slightly. We will repeat this same process a fixed number of times or until <span class="math notranslate nohighlight">\(\beta\)</span> barely changes. And that is gradient descent!</p>
</div>
<div class="section" id="the-steps">
<h3>The Steps</h3>
<p>We can describe gradient descent more concretely with the following steps. Note here that <span class="math notranslate nohighlight">\(\bbetahat\)</span> can be a vector, rather than just a single parameter.</p>
<ol>
<li><p>Choose a small learning rate <span class="math notranslate nohighlight">\(\eta\)</span></p></li>
<li><p>Randomly instantiate <span class="math notranslate nohighlight">\(\bbetahat\)</span></p></li>
<li><p>For a fixed number of iterations or until some stopping rule is reached:</p>
<ol>
<li><p>Calculate <span class="math notranslate nohighlight">\(\boldsymbol{\delta} = \partial \mathcal{L}/\partial \bbetahat\)</span></p></li>
<li><p>Adjust <span class="math notranslate nohighlight">\(\bbetahat\)</span> with</p>
<div class="math notranslate nohighlight">
\[
      \bbetahat \gets \bbetahat - \eta \boldsymbol{\delta}.
      \]</div>
</li>
</ol>
</li>
</ol>
<p>A potential stopping rule might be a minimum change in the magnitude of <span class="math notranslate nohighlight">\(\bbetahat\)</span> or a minimum decrease in the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
</div>
<div class="section" id="an-example">
<h3>An Example</h3>
<p>As a simple example of gradient descent in action, let’s derive the ordinary least squares (OLS) regression estimates. (This problem does have a closed-form solution, but we’ll use gradient descent to demonstrate the approach). As discussed in <a class="reference internal" href="../c1/concept.html"><span class="doc">Chapter 1</span></a>, linear regression models <span class="math notranslate nohighlight">\(\hat{y}_n\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_n = \bx_n^\top \bbetahat,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\bx_n\)</span> is a vector of predictors appended with a leading 1 and <span class="math notranslate nohighlight">\(\bbetahat\)</span> is a vector of coefficients. The OLS loss function is defined with</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\bbetahat) = \frac{1}{2}\sumN(y_n - \hat{y}_n)^2 = \frac{1}{2}\sumN (y_n - \bx^\top_n \bbetahat)^2.
\]</div>
<p>After choosing <span class="math notranslate nohighlight">\(\eta\)</span> and randomly instantiating <span class="math notranslate nohighlight">\(\bbetahat\)</span>, we iteratively calculate the loss function’s gradient:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\delta} = \dadb{\mathcal{L}(\bbetahat)}{\bbetahat} =  -\sumN(y_n - \bx^\top_n \bbetahat)\cdot\bphi_n^\top,
\]</div>
<p>and adjust with</p>
<div class="math notranslate nohighlight">
\[
\bbetahat \gets \bbetahat - \eta\boldsymbol{\delta}.
\]</div>
<p>This is accomplished with the following code. Note that we can also calculate <span class="math notranslate nohighlight">\(\boldsymbol{\delta} = -\bX^\top(\by - \hat{\by})\)</span>, where <span class="math notranslate nohighlight">\(\bX\)</span> is the <a class="reference internal" href="../conventions_notation.html"><span class="doc">feature matrix</span></a>, <span class="math notranslate nohighlight">\(\by\)</span> is the vector of targets, and <span class="math notranslate nohighlight">\(\hat{\by}\)</span> is the vector of fitted values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">OLS_GD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eta</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mf">1e4</span><span class="p">,</span> <span class="n">add_intercept</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
  
  <span class="c1">## Add Intercept</span>
  <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    
  <span class="c1">## Instantiate</span>
  <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  
  <span class="c1">## Iterate</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iter</span><span class="p">)):</span>
    
    <span class="c1">## Calculate Derivative</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_hat</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span>
    <span class="n">beta_hat</span> <span class="o">-=</span> <span class="n">delta</span><span class="o">*</span><span class="n">eta</span>
    
</pre></div>
</div>
</div>
&#13;

<h3>The Set-Up</h3>
<p>Let’s first introduce a typical set-up for gradient descent. Suppose we have <span class="math notranslate nohighlight">\(N\)</span> observations where each observation has predictors <span class="math notranslate nohighlight">\(\bx_n\)</span> and target variable <span class="math notranslate nohighlight">\(y_n\)</span>. We decide to approximate <span class="math notranslate nohighlight">\(y_n\)</span> with <span class="math notranslate nohighlight">\(\hat{y}_n = f(\bx_n, \bbetahat)\)</span>, where <span class="math notranslate nohighlight">\(f()\)</span> is some differentiable function and <span class="math notranslate nohighlight">\(\bbetahat\)</span> is a set of parameter estimates. Next, we introduce a differentiable loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. For simplicity, let’s assume we can write the model’s entire loss as the sum of the individual losses across observations. That is,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = \sumN g(y_n, \hat{y}_n),
\]</div>
<p>where <span class="math notranslate nohighlight">\(g()\)</span> is some differentiable function representing an observation’s individual loss.</p>
<p>To fit this generic model, we want to find the values of <span class="math notranslate nohighlight">\(\bbetahat\)</span> that minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. We will likely start with the following derivative:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\dadb{\mathcal{L}}{\bbetahat} &amp;= \sumN\dadb{g(y_n, \hat{y}_n)}{\bbetahat} \\
&amp;= \sumN\dadb{g(y_n, \hat{y}_n)}{\hat{y}_n}\cdot\dadb{\hat{y}_n}{\bbetahat}. \\
\end{align}
\end{split}\]</div>
<p>Ideally, we can set the above derivative equal to 0 and solve for <span class="math notranslate nohighlight">\(\bbetahat\)</span>, giving our optimal solution. If this isn’t possible, we can iteratively search for the values of <span class="math notranslate nohighlight">\(\bbetahat\)</span> that minimize <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. This is the process of gradient descent.</p>
&#13;

<h3>An Intuitive Introduction</h3>
<p><img alt="gd" src="../Images/4e6b365fc23689963cccc975a25ccc23.png" data-original-src="https://dafriedman97.github.io/mlbook/_images/gd.jpg"/></p>
<p>To understand this process intuitively, consider the image above showing a model’s loss as a function of one parameter, <span class="math notranslate nohighlight">\(\beta\)</span>.  We start our search for the optimal <span class="math notranslate nohighlight">\(\beta\)</span> by randomly picking a value. Suppose we start with <span class="math notranslate nohighlight">\(\beta\)</span> at point <span class="math notranslate nohighlight">\(A\)</span>. From point <span class="math notranslate nohighlight">\(A\)</span> we ask “would the loss function decrease if I increased or decreased <span class="math notranslate nohighlight">\(\beta\)</span>”. To answer this question, we calculate the derivative of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> with respect to <span class="math notranslate nohighlight">\(\beta\)</span> evaluated at <span class="math notranslate nohighlight">\(\beta = A\)</span>. Since this derivative is negative, we know that increasing <span class="math notranslate nohighlight">\(\beta\)</span> some small amount will decrease the loss.</p>
<p>Now we know we want to increase <span class="math notranslate nohighlight">\(\beta\)</span>, but how much? Intuitively, the more negative the derivative, the more the loss will decrease with an increase in <span class="math notranslate nohighlight">\(\beta\)</span>. So, let’s increase <span class="math notranslate nohighlight">\(\beta\)</span> by an amount proportional to the negative of the derivative. Letting <span class="math notranslate nohighlight">\(\delta\)</span> be the derivative and <span class="math notranslate nohighlight">\(\eta\)</span> be a small constant learning rate, we might increase <span class="math notranslate nohighlight">\(\beta\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\beta \gets \beta - \eta\delta.
\]</div>
<p>The more negative <span class="math notranslate nohighlight">\(\delta\)</span> is, the more we increase <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>Now suppose we make the increase and wind up with <span class="math notranslate nohighlight">\(\beta = B\)</span>. Calculating the derivative again, we get a slightly positive number. This tells us that we went too far: increasing <span class="math notranslate nohighlight">\(\beta\)</span> will increase <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>. However, since the derivative is only <em>slightly</em> positive, we want to only make a slight correction. Let’s again use the same adjustment, <span class="math notranslate nohighlight">\(\beta \gets \beta - \eta\delta\)</span>. Since <span class="math notranslate nohighlight">\(\delta\)</span> is now slightly positive, <span class="math notranslate nohighlight">\(\beta\)</span> will now decrease slightly. We will repeat this same process a fixed number of times or until <span class="math notranslate nohighlight">\(\beta\)</span> barely changes. And that is gradient descent!</p>
&#13;

<h3>The Steps</h3>
<p>We can describe gradient descent more concretely with the following steps. Note here that <span class="math notranslate nohighlight">\(\bbetahat\)</span> can be a vector, rather than just a single parameter.</p>
<ol>
<li><p>Choose a small learning rate <span class="math notranslate nohighlight">\(\eta\)</span></p></li>
<li><p>Randomly instantiate <span class="math notranslate nohighlight">\(\bbetahat\)</span></p></li>
<li><p>For a fixed number of iterations or until some stopping rule is reached:</p>
<ol>
<li><p>Calculate <span class="math notranslate nohighlight">\(\boldsymbol{\delta} = \partial \mathcal{L}/\partial \bbetahat\)</span></p></li>
<li><p>Adjust <span class="math notranslate nohighlight">\(\bbetahat\)</span> with</p>
<div class="math notranslate nohighlight">
\[
      \bbetahat \gets \bbetahat - \eta \boldsymbol{\delta}.
      \]</div>
</li>
</ol>
</li>
</ol>
<p>A potential stopping rule might be a minimum change in the magnitude of <span class="math notranslate nohighlight">\(\bbetahat\)</span> or a minimum decrease in the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
&#13;

<h3>An Example</h3>
<p>As a simple example of gradient descent in action, let’s derive the ordinary least squares (OLS) regression estimates. (This problem does have a closed-form solution, but we’ll use gradient descent to demonstrate the approach). As discussed in <a class="reference internal" href="../c1/concept.html"><span class="doc">Chapter 1</span></a>, linear regression models <span class="math notranslate nohighlight">\(\hat{y}_n\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_n = \bx_n^\top \bbetahat,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\bx_n\)</span> is a vector of predictors appended with a leading 1 and <span class="math notranslate nohighlight">\(\bbetahat\)</span> is a vector of coefficients. The OLS loss function is defined with</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\bbetahat) = \frac{1}{2}\sumN(y_n - \hat{y}_n)^2 = \frac{1}{2}\sumN (y_n - \bx^\top_n \bbetahat)^2.
\]</div>
<p>After choosing <span class="math notranslate nohighlight">\(\eta\)</span> and randomly instantiating <span class="math notranslate nohighlight">\(\bbetahat\)</span>, we iteratively calculate the loss function’s gradient:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\delta} = \dadb{\mathcal{L}(\bbetahat)}{\bbetahat} =  -\sumN(y_n - \bx^\top_n \bbetahat)\cdot\bphi_n^\top,
\]</div>
<p>and adjust with</p>
<div class="math notranslate nohighlight">
\[
\bbetahat \gets \bbetahat - \eta\boldsymbol{\delta}.
\]</div>
<p>This is accomplished with the following code. Note that we can also calculate <span class="math notranslate nohighlight">\(\boldsymbol{\delta} = -\bX^\top(\by - \hat{\by})\)</span>, where <span class="math notranslate nohighlight">\(\bX\)</span> is the <a class="reference internal" href="../conventions_notation.html"><span class="doc">feature matrix</span></a>, <span class="math notranslate nohighlight">\(\by\)</span> is the vector of targets, and <span class="math notranslate nohighlight">\(\hat{\by}\)</span> is the vector of fitted values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">OLS_GD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eta</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mf">1e4</span><span class="p">,</span> <span class="n">add_intercept</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
  
  <span class="c1">## Add Intercept</span>
  <span class="k">if</span> <span class="n">add_intercept</span><span class="p">:</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    
  <span class="c1">## Instantiate</span>
  <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  
  <span class="c1">## Iterate</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iter</span><span class="p">)):</span>
    
    <span class="c1">## Calculate Derivative</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_hat</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span>
    <span class="n">beta_hat</span> <span class="o">-=</span> <span class="n">delta</span><span class="o">*</span><span class="n">eta</span>
    
</pre></div>
</div>
&#13;

<h2>2. Cross Validation</h2>
<p>Several of the models covered in this book require <em>hyperparameters</em> to be chosen exogenously (i.e. before the model is fit). The value of these hyperparameters affects the quality of the model’s fit. So how can we choose these values without fitting a model? The most common answer is cross validation.</p>
<p>Suppose we are deciding between several values of a hyperparameter, resulting in multiple competing models. One way to choose our model would be to split our data into a <em>training</em> set and a <em>validation</em> set, build each model on the training set, and see which performs better on the validation set. By splitting the data into training and validation, we avoid evaluating a model based on its in-sample performance.</p>
<p>The obvious problem with this set-up is that we are comparing the performance of models on just <em>one</em> dataset. Instead, we might choose between competing models with <strong>K-fold cross validation</strong>, outlined below.</p>
<ol class="simple">
<li><p>Split the original dataset into <span class="math notranslate nohighlight">\(K\)</span> <em>folds</em> or subsets.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(k = 1, \dots, K\)</span>, treat fold <span class="math notranslate nohighlight">\(k\)</span> as the validation set. Train each competing model on the data from the other <span class="math notranslate nohighlight">\(K-1\)</span> folds and evaluate it on the data from the <span class="math notranslate nohighlight">\(k^\text{th}\)</span>.</p></li>
<li><p>Select the model with the best average validation performance.</p></li>
</ol>
<p>As an example, let’s use cross validation to choose a penalty value for a <a class="reference internal" href="../c2/s1/regularized.html"><span class="doc">Ridge regression</span></a> model, discussed in chapter 2. This model constrains the magnitude of the regression coefficients; the higher the penalty term, the more the coefficients are constrained.</p>
<p>The example below uses the <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> class from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, which defines the penalty term with the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> argument. We will use the <a class="reference internal" href="data.html"><span class="doc">Boston housing</span></a> dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="c1">## Import packages </span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>

<span class="c1">## Import data</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1">## Choose alphas to consider</span>
<span class="n">potential_alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">error_by_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">potential_alphas</span><span class="p">))</span>

<span class="c1">## Choose the folds </span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>

<span class="c1">## Iterate through folds</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
  
  <span class="c1">## Split Train and Validation</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">folds</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
  
  <span class="c1">## Iterate through Alphas</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">potential_alphas</span><span class="p">)):</span>
    
        <span class="c1">## Train on Training Set</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">potential_alphas</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1">## Calculate and Append Error</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">y_val</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
        <span class="n">error_by_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">error</span>
    
<span class="n">error_by_alpha</span> <span class="o">/=</span> <span class="n">N</span>
</pre></div>
</div>
<p>We can then check <code class="docutils literal notranslate"><span class="pre">error_by_alpha</span></code> and choose the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> corresponding to the lowest average error!</p>
    
</body>
</html>