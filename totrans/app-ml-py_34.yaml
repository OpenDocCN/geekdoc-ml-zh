- en: Generative Adversarial Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: 原文：[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_GAN.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_GAN.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_GAN.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_GAN.html)
- en: Michael J. Pyrcz, Professor, The University of Texas at Austin
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Michael J. Pyrcz，教授，德克萨斯大学奥斯汀分校
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [网站](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [地统计学书籍](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python应用地统计学电子书](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Python应用机器学习电子书](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
- en: 'Chapter of e-book “Applied Machine Learning in Python: a Hands-on Guide with
    Code”.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 电子书“Python应用机器学习：带代码的手动指南”的一章。
- en: 'Cite this e-Book as:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 请将此电子书引用如下：
- en: 'Pyrcz, M.J., 2024, *Applied Machine Learning in Python: A Hands-on Guide with
    Code* [e-book]. Zenodo. doi:10.5281/zenodo.15169138 [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pyrcz, M.J., 2024, *Python应用机器学习：带代码的手动指南* [电子书]. Zenodo. doi:10.5281/zenodo.15169138
    [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)
- en: 'The workflows in this book and more are available here:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的工作流程以及更多内容在此处可用：
- en: 'Cite the MachineLearningDemos GitHub Repository as:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请将MachineLearningDemos GitHub仓库引用如下：
- en: 'Pyrcz, M.J., 2024, *MachineLearningDemos: Python Machine Learning Demonstration
    Workflows Repository* (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312\.
    GitHub repository: [GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'Pyrcz, M.J., 2024, *MachineLearningDemos: Python Machine Learning Demonstration
    Workflows Repository* (0.0.3) [软件]. Zenodo. DOI: 10.5281/zenodo.13835312\. GitHub
    仓库：[GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
- en: By Michael J. Pyrcz
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Michael J. Pyrcz
- en: © Copyright 2024.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: © 版权所有 2024。
- en: This chapter is a tutorial for / demonstration of **Generative Adversarial Networks**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是关于/演示**生成对抗网络**的教程。
- en: '**YouTube Lecture**: check out my lectures on:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**YouTube 讲座**：查看我在以下主题上的讲座：'
- en: '[Artificial Neural Networks](https://youtu.be/A9PiCMY_6nM?si=NxWSU_5RgQ4w55EL)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工神经网络](https://youtu.be/A9PiCMY_6nM?si=NxWSU_5RgQ4w55EL)'
- en: '[Convolutional Neural Networks](https://youtu.be/za2my_XDoOs?si=LeHU6p2_fc9dX4Yt)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络](https://youtu.be/za2my_XDoOs?si=LeHU6p2_fc9dX4Yt)'
- en: Generative Adversarial Networks (TBA)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络（待定）
- en: These lectures are all part of my [Machine Learning Course](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)
    on YouTube with linked well-documented Python workflows and interactive dashboards.
    My goal is to share accessible, actionable, and repeatable educational content.
    If you want to know about my motivation, check out [Michael’s Story](https://michaelpyrcz.com/my-story).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这些讲座都是我YouTube上的[机器学习课程](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)的一部分，其中包含有良好文档记录的Python工作流程和交互式仪表板。我的目标是分享易于理解、可操作和可重复的教育内容。如果您想了解我的动机，请查看[Michael的故事](https://michaelpyrcz.com/my-story)。
- en: Motivation
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动机
- en: What if we put together machines? Working in a competitive, adversarial manner?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将机器组合在一起，以竞争、对抗的方式工作呢？
- en: Could we make a more powerful machine learning model that learns its own loss
    function!
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否制作出一个更强大的机器学习模型，该模型能够学习自己的损失函数！
- en: Could we make images that don’t collapse to exact reproduction of the images
    in the training set?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否制作出不完全复制训练集中图像的图像？
- en: Generative neural networks are very powerful, nature inspired computing deep
    learning method to make fake, but realistic, images by application of convolutional
    neural networks, an analogy of visual cortex that extend the ability of our artificial
    neural networks to better work with images.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型神经网络非常强大，这是一种受自然界启发的深度学习方法，通过卷积神经网络的应用来制作逼真的图像，类似于视觉皮层的类比，从而扩展了我们的人工神经网络处理图像的能力。
- en: Nature inspired computing is looking to nature for inspiration to develop novel
    problem-solving methods,
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 受自然界启发的计算正在寻找自然界中的灵感来开发新的问题解决方法，
- en: '**artificial neural networks** are inspired by biological neural networks'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络**受生物神经网络的启发'
- en: '**nodes** in our model are artificial neurons, simple processors'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们模型中的**节点**是人工神经元，简单的处理器
- en: '**connections** between nodes are artificial synapses'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点之间的**连接**是人工突触
- en: '**perceptive fields** regularization to improve generalization and efficiency'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**感知野**正则化以改善泛化能力和效率'
- en: intelligence emerges from many connected simple processors. For the remainder
    of this chapter, I will used the terms nodes and connections to describe our convolutional
    neural network.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 智能是从许多连接的简单处理器中产生的。在本章的剩余部分，我将使用节点和连接这两个术语来描述我们的卷积神经网络。
- en: Artificial and Convolutional Neural Networks
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工神经网络和卷积神经网络
- en: If you have not, take this opportunity to review my previous chapters in the
    e-book on,
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有，请利用这个机会回顾电子书中的前几章，
- en: '[Artificial Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[人工神经网络](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)'
- en: The **main takeaways** from my artificial neural network chapter are as follows,
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我关于人工神经网络章节的主要收获如下，
- en: '**architecture of a neural network**, including its fundamental components,
    nodes (neurons) and the weighted connections between them.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络架构**，包括其基本组件、节点（神经元）以及它们之间的加权连接。'
- en: '**forward pass** computation through the network, where each node computes
    a weighted sum of its inputs (including a bias term), followed by the application
    of a nonlinear activation function.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正向传播**计算通过网络，其中每个节点计算其输入的加权和（包括偏差项），然后应用非线性激活函数。'
- en: '**computation of the error derivative**, which is then backpropagated through
    the network via the chain rule to determine the gradients of the loss function
    with respect to each weight and bias.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误差导数的计算**，然后通过链式法则反向传播通过网络，以确定损失函数相对于每个权重和偏差的梯度。'
- en: '**aggregation of these gradients** across all samples in a training batch,
    typically by averaging, to update the model parameters.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练批次的所有样本上**聚合这些梯度**，通常通过平均来更新模型参数。
- en: '**iterative training process**, where the model is trained over multiple batches
    and epochs (passes over all the data) to continually refine the weights and biases
    until the model achieves an acceptable error rate on the test data.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代训练过程**，模型在多个批次和多个epoch（遍历所有数据）上训练，以不断细化权重和偏差，直到模型在测试数据上达到可接受的错误率。'
- en: '[Convolutional Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_CNN.html)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[卷积神经网络](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_CNN.html)'
- en: The main takeaways from my convolutional neural network chapter are as follows,
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我关于卷积神经网络章节的主要收获如下，
- en: '**regularization** of image data with receptive fields to preserve spatial
    information and to avoid overfit.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用感受野对图像数据进行**正则化**以保留空间信息并避免过拟合。
- en: '**convolutional kernels** with learnable weights to extraction information
    from images.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有可学习权重的**卷积核**从图像中提取信息。
- en: For both of these chapters, I have included links to my recorded lectures and
    to neural networks built from scratch with NumPy only!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两个章节，我都包括了链接到我的录音讲座以及仅使用NumPy从头构建的神经网络！
- en: Generative Adversarial Networks
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: If we start with a convolutional neural network and we flip it, i.e., reverse
    the order of the operations,
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从卷积神经网络开始，并将其翻转，即反转操作顺序，
- en: we have a machine that maps from a 1D vector of values, to an image, i.e., we
    can generate fake images by randomly assigning latent values
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有一个将值的一维向量映射到图像的机器，即我们可以通过随机分配潜在值来生成假图像
- en: to accomplish this instead of convolution operations with activation, we have
    transpose convolution operations with activation to move to the next feature map
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们不是使用带有激活的卷积操作，而是使用带有激活的转置卷积操作来移动到下一个特征图
- en: recall we also perform non-linear activation at each feature map to prevent
    network collapse
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，我们还在每个特征图上执行非线性激活，以防止网络崩溃
- en: '![](../Images/edf859adfdeba17f094dbc0415d2bb06.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/edf859adfdeba17f094dbc0415d2bb06.png)'
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个翻转的卷积神经网络，将卷积替换为转置卷积，从1D随机潜在向量生成随机图像。
- en: But how do we train this flipped convolutional neural network to make good images?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们如何训练这个翻转卷积神经网络以生成好的图像呢？
- en: we could take training images and score the difference between our generated
    fake images, for example, with a pixel-wise squared error (L2 norm)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以用训练图像和评分我们生成的假图像之间的差异，例如，使用像素级的平方误差（L2范数）
- en: but if we did this, our machine learning model would only learn how to make
    this image or a limited set of training images and that would not be useful
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但如果我们这样做，我们的机器学习模型只会学习如何生成这个图像或有限的训练图像集合，这将没有用
- en: We want to make a diverse set of image realizations, that look and behave correctly.
    This is the simulation paradigm at the heart of geostatistics,
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要生成一组多样化的图像实现，它们看起来和行为都是正确的。这是地统计学核心的模拟范式，
- en: to learn more about the simulation paradigm from geostatistics, see my [Simulation
    Chapter](https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html)
    from my free, online e-book, [Applied Geostatistics in Python](https://geostatsguy.github.io/GeostatsPyDemos_Book).
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要了解更多关于来自地统计学的模拟范式，请参阅我的免费在线电子书[《Python中的应用地统计学》](https://geostatsguy.github.io/GeostatsPyDemos_Book)中的[模拟章节](https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html)。
- en: Instead of a typically loss function, we apply a classification convolutional
    neural network to map from the image to a probability of a real image, i.e., our
    loss function is effectively a network that learns to score the loss during training.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有使用典型的损失函数，而是应用了一个分类卷积神经网络，将图像映射到真实图像的概率，即，我们的损失函数实际上是一个在学习过程中学习评分损失的神经网络。
- en: We have 2 neural networks in our GAN,
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的GAN中，我们有2个神经网络，
- en: '**generator** - flipped convolutional neural network that makes random fake
    images'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器** - 生成随机假图像的翻转卷积神经网络'
- en: '**discriminator** - classification convolutional neural netwrok that calculates
    the probability that an image is real'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器** - 一个用于计算图像是否为真实的概率的分类卷积神经网络'
- en: '![](../Images/464dd59ea97be3602e14c9ece74a40a6.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/464dd59ea97be3602e14c9ece74a40a6.png)'
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个翻转的卷积神经网络，将卷积替换为转置卷积，从1D随机潜在向量生成随机图像。
- en: Indirect, Adversarial Learning
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 间接，对抗学习
- en: How do we train these two coupled networks? We call each network an agent and
    we train them competively, e.g., they compete while learning!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何训练这两个耦合的网络？我们将每个网络称为代理，并且我们以竞争的方式训练它们，例如，它们在学习的竞争中！
- en: agent 1, Generator, is not trained to minimize an loss function with respect
    to training data (training image), no MSE!
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理1，生成器，没有被训练来最小化与训练数据（训练图像）相关的损失函数，没有MSE！
- en: instead the agent 1, Generator, is trained to fool agent 2, Discriminator
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相反，代理1，生成器，被训练来欺骗代理2，判别器
- en: agent 2, Discriminator, is learning at the same time to tell the difference
    between the real training images and the fakes from agent 1, generator
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理2，判别器，同时学习区分真实训练图像和代理1，生成器产生的假图像
- en: Each agent has their own competitive goals,
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理都有自己的竞争目标，
- en: Generator – make fakes that Discriminator classifies as real
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器 – 生成判别器分类为真实的假图像
- en: Discriminator – correctly classify fake and real images
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器 – 正确分类假图像和真实图像
- en: Note, the generator never sees the real images, but by learning to fool the
    discriminator learns to make images like the real training images.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，生成器从未看到真实图像，但通过学习欺骗判别器，它学会了生成类似于真实训练图像的图像。
- en: The GAN loss function is stated as,
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的损失函数表述为，
- en: \[ \min_{\theta_G} \, \max_{\theta_D} \; \mathbb{E}_{\mathbf{y} \sim p_{\text{data}}}
    \left[ \log D_{\theta_D}(\mathbf{y}) \right] + \mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}}
    \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
    \]
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\theta_G} \, \max_{\theta_D} \; \mathbb{E}_{\mathbf{y} \sim p_{\text{data}}}
    \left[ \log D_{\theta_D}(\mathbf{y}) \right] + \mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}}
    \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
    \]
- en: where,
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\theta_D\) - parameters (weights, biases) of the **discriminator**
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\theta_D\) - **判别器**的参数（权重，偏差）
- en: \(\theta_G\) - parameters of the **generator**
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\theta_G\) - **生成器**的参数
- en: \(D_{\theta_D}(\cdot)\) - discriminator output, given the discriminator parameters
    \(\theta_D\) (probability input is real)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(D_{\theta_D}(\cdot)\) - 给定判别器参数 \(\theta_D\) 的判别器输出（输入是真实的概率）
- en: \(G_{\theta_G}(\mathbf{x})\) - output of the Generator output given latent input
    \(\mathbf{x}\)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(G_{\theta_G}(\mathbf{x})\) - 给定潜在输入 \(\mathbf{x}\) 的生成器输出
- en: \(\mathbf{y} \sim p_{\text{data}}\) - training images from the **real image
    set**
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbf{y} \sim p_{\text{data}}\) - 来自**真实图像集**的训练图像
- en: \(\mathbf{x} \sim p_{\mathbf{x}}\) - latent input sampled from known prior (e.g.
    uniform or normal)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbf{x} \sim p_{\mathbf{x}}\) - 从已知先验（例如均匀分布或正态分布）采样的潜在输入
- en: \(\mathbb{E}[\cdot]\) - expectation over data (i.e., average over all samples)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{E}[\cdot]\) - 对数据的期望（即对所有样本的平均）
- en: \(\log D(\cdot)\) - log-likelihood that the discriminator assigns input as real
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\log D(\cdot)\) - 判别器将输入分配为真实的对数似然
- en: \(\log(1 - D(G(\cdot)))\) - log-likelihood that discriminator assigns fake to
    generator’s output
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\log(1 - D(G(\cdot)))\) - 判别器将伪造分配给生成器输出的对数似然
- en: The discriminator wants to **maximize**,
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器想要**最大化**，
- en: \[ \log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x}))) \]
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x}))) \]
- en: tries to **correctly predicts real** training images as real, \(\log D(\mathbf{y})
    \rightarrow 0.0\)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**正确预测真实**训练图像为真实，\(\log D(\mathbf{y}) \rightarrow 0.0\)
- en: and to **correctly predicts generated** fake training images as not real, \(\log(1
    - D(G(\mathbf{x}))) \rightarrow 0.0\)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并且正确预测生成的伪造训练图像不是真实，\(\log(1 - D(G(\mathbf{x}))) \rightarrow 0.0\)
- en: The generator want to **minimize**,
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器想要**最小化**，
- en: \[ \log(1 - D(G(\mathbf{x}))) \]
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log(1 - D(G(\mathbf{x}))) \]
- en: tries to **fool the discriminator**, discriminator classifies fake training
    images as real, \(\log(1 - D(G(\mathbf{x}))) \rightarrow -\infty\)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**欺骗判别器**，判别器将伪造训练图像分类为真实，\(\log(1 - D(G(\mathbf{x}))) \rightarrow -\infty\)
- en: To assist with understanding the GAN loss function and the system of competing
    agents, consider these end members,
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助理解 GAN 损失函数和竞争代理系统，考虑这些极端情况，
- en: '**Perfect Discriminator** - if the discriminator is perfect,'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完美判别器** - 如果判别器是完美的，'
- en: all real training images are classified as real, \(D(\mathbf{y}) = 1\)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有真实训练图像都被分类为真实，\(D(\mathbf{y}) = 1\)
- en: all fake images from the generator are classified as real, \(D(G(\mathbf{x}))
    = 0\)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器产生的所有伪造图像都被分类为真实，\(D(G(\mathbf{x})) = 0\)
- en: \(\quad\) then the discriminator loss is,
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 然后判别器损失是，
- en: \[ \log(1) + \log(1 - 0) = 0 + \log(1) = 0 \]
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log(1) + \log(1 - 0) = 0 + \log(1) = 0 \]
- en: \(\quad\) this sounds like good news, i.e., the generator will then improve
    to catch up with the discriminator, but what actually happens is,
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 这听起来像是好消息，即生成器将提高以赶上判别器，但实际上发生的是，
- en: generator receives **no loss gradients**, because the generators gradients,
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器接收**没有损失梯度**，因为生成器的梯度，
- en: \[ \frac{\partial \log(1 - D(G(z)))}{\partial \theta_G} \]
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \log(1 - D(G(z)))}{\partial \theta_G} \]
- en: \(\quad\) if \(D(G(z)) \to 0\), this derivative becomes **zero**, so training
    stalls and **the generator doesn’t learn**,
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 如果 \(D(G(z)) \to 0\)，这个导数变为**零**，因此训练停滞，**生成器不学习**，
- en: this is practically solved by substituting **non-saturating generator loss**
    for the generator,
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这实际上是通过用**非饱和生成器损失**替换生成器来解决的，
- en: \[ L_G = -\mathbb{E}_{z \sim p_z}[\log D(G(z))] \]
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L_G = -\mathbb{E}_{z \sim p_z}[\log D(G(z))] \]
- en: \(\quad\) if \(D(G(z)) \to 0\), then \(\log D(G(z)) \to -\infty\), so the gradient
    becomes **large**, giving the generator a strong learning signal.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 如果 \(D(G(z)) \to 0\)，那么 \(\log D(G(z)) \to -\infty\)，因此梯度变得**很大**，给生成器一个强烈的信号。
- en: '**Perfect Generator** - if the generator is perfect,'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完美生成器** - 如果生成器是完美的，'
- en: all fake images have the same distribution as the real training images, \(G(\mathbf{x})
    \sim p_{\text{data}}\)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有伪造图像的分布与真实训练图像相同，\(G(\mathbf{x}) \sim p_{\text{data}}\)
- en: the best the discriminator can do is to assign a anive classification, \(D(\cdot)
    = 0.5\), for all fake and real training images
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器所能做到的最佳分类是，对所有伪造和真实训练图像分配一个平均分类，\(D(\cdot) = 0.5\)
- en: \(\quad\) then the loss is,
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 然后，损失是，
- en: \[ \log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4 \]
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4 \]
- en: discriminator is **maximally confused**
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器处于**最大困惑**状态
- en: this is a **Nash equilibrium** for the GAN, because no player can improve their
    outcome by unilaterally changing their strategy, assuming the other player’s strategy
    stays the same, generator is already making perfect images and discriminator can
    only guess naively, 50/50 real and fake.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是对 GAN 的一个**纳什均衡**，因为没有任何玩家可以通过单方面改变他们的策略来改善他们的结果，假设其他玩家的策略保持不变，生成器已经制作出完美的图像，判别器只能天真地猜测，50/50
    的真实和伪造。
- en: Import Required Packages
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入所需的包
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一些标准包。这些应该已经与 Anaconda 3 一起安装。
- en: recall our goal is to build a convolutional neural network by-hand with only
    basic math and array operations, so we only need NumPy along with matplotlib for
    plotting.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想我们的目标是手动构建卷积神经网络，只使用基本的数学和数组操作，所以我们只需要 NumPy 以及 matplotlib 用于绘图。
- en: '[PRE0]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing ‘python -m pip install [package-name]’. More assistance is available
    with the respective package docs.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遇到包导入错误，您可能首先需要安装这些包中的一些。这通常可以通过在 Windows 上打开命令窗口然后输入‘python -m pip install
    [package-name]’来完成。更多帮助可以在相应的包文档中找到。
- en: Declare Functions
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声明函数
- en: Here’s the functions to make, train and visualize our generative adversarial
    network, including the steps,
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是制作、训练和可视化我们的生成对抗网络的函数，包括步骤，
- en: make a simple set of synthetic data
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作一组简单的合成数据
- en: initialize the weights in our generator and discriminator
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化生成器和判别器的权重
- en: apply our generator and discrimintor
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用我们的生成器和判别器
- en: calculate the error derivative and update the generator and discriminator weights
    and biases
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算误差导数并更新生成器和判别器的权重和偏差
- en: Here’s a list of the functions,
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是函数列表，
- en: '**generate_real_data** - synthetic data generator'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**generate_real_data** - 合成数据生成器'
- en: '**initialize_generator_weights** - assign small random weights and bias for
    generator'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**initialize_generator_weights** - 为生成器分配小的随机权重和偏差'
- en: '**initialize_discriminator_weights** - assign small random weights and bias
    for discriminator'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**initialize_discriminator_weights** - 为判别器分配小的随机权重和偏差'
- en: '**generator_forward** - calculate a set of fake data with the generator given
    a set of latent values and the current weights and biases'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**generator_forward** - 根据给定的一组潜在值、当前权重和偏差，使用生成器计算一组伪造数据'
- en: '**discriminator_forward** - calculate the probability of a real image over
    a set of images and return a 1D ndarray of probabilities'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**discriminator_forward** - 计算一组图像中真实图像的概率并返回一个 1D 索引数组'
- en: '**sigmoid** - activation function to apply in the generator and discriminator'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**sigmoid** - 在生成器和判别器中应用的激活函数'
- en: '**generator_gradients** - compute generator gradients averaged over the batch'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**generator_gradients** - 计算生成器梯度，平均分布在批次上'
- en: '**discriminator_gradients** - compute generator gradients averaged over the
    batch'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**discriminator_gradients** - 计算生成器梯度，平均分布在批次上'
- en: Here are the functions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是函数列表。
- en: '[PRE1]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Set the Working Directory
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置工作目录
- en: I always like to do this so I don’t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是喜欢这样做，这样我就不会丢失文件，并且可以简化后续的读取和写入（避免每次都包含完整地址）。
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Visualize the Generative Adversarial Network
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化生成对抗网络
- en: We are implementing a minimal Generative Adversarial Network (GAN) with the
    2 agents,
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在实现一个最小的生成对抗网络（GAN），包含 2 个智能体，
- en: '**Generator** - that produces 3-node outputs (like tiny 1D images) from a single
    latent input'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器** - 从单个潜在输入产生 3 个节点输出（如微小的 1D 图像）'
- en: '**Discriminator** - that evaluates these outputs to distinguish between **real**
    and **fake** samples.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器** - 评估这些输出以区分**真实**和**伪造**样本。'
- en: Now let’s define the parts of the **Generator**,
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义**生成器**的部分，
- en: '**Latent Node** - \(L_1\), a single random value with uniform distribution,
    \(U[0.4,1.0]\). Note we set the minimum as 0.4 to stay away from 0.0 or negative
    values as these would remove the slope or flip the slope of the fakes.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在节点** - \(L_1\)，一个具有均匀分布的单个随机值，\(U[0.4,1.0]\)。注意我们设定最小值为 0.4 以避免 0.0 或负值，因为这些值会移除斜率或翻转伪造的斜率。'
- en: '**Generator Weights** - \(\lambda_{1,2}\), \(\lambda_{1,3}\) and \(\lambda_{1,4}\)
    for the connections from latent to each of the output nodes. This is the simplest
    possible tranpose convolution, with a kernel size is 3, output nodes is 3 and
    latent node is 1, so the kernel does not translate. I did this to greatly simplify
    the book keeping, but the concepts could be extended to a more realistic convolution
    / tranpose convolution architectures for more realistic images sizes problem.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器权重** - \(\lambda_{1,2}\), \(\lambda_{1,3}\) 和 \(\lambda_{1,4}\) 用于从潜在节点到每个输出节点的连接。这是可能的最简单的转置卷积，内核大小为3，输出节点为3，潜在节点为1，因此内核不进行平移。我这样做是为了极大地简化账目记录，但概念可以扩展到更现实的卷积/转置卷积架构，以解决更现实的图像尺寸问题。'
- en: '**Generator Bias** - \(b\), a single, constant bias over the output layer (output
    image), the nodes, \(O_2\), \(O_3\), and \(O_4\)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器偏差** - \(b\)，在输出层（输出图像）的单一、常数偏差，节点 \(O_2\), \(O_3\), 和 \(O_4\)。'
- en: '**Generator Output Nodes** - \(O_2\), \(O_3\), and \(O_4\), the single and
    last feature map in our very simple generator; therefore, the output a 1D image
    with 3 nodes or pixels that are passed to the **Discriminator** input nodes, \(I_5\),
    \(I_6\), and \(I_7\)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器输出节点** - \(O_2\), \(O_3\), 和 \(O_4\)，这是我们非常简单的生成器中的单个和最后一个特征图；因此，输出一个包含3个节点或像素的1D图像，这些节点或像素被传递到**判别器**输入节点
    \(I_5\), \(I_6\), 和 \(I_7\)。'
- en: '**Discriminator Input Nodes** - \(I_5\), \(I_6\), and \(I_7\), that receive
    the real images or the fake images from the generator output nodes, \(O_2\), \(O_3\),
    \(O_4\)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器输入节点** - \(I_5\), \(I_6\), 和 \(I_7\)，它们接收来自生成器输出节点 \(O_2\), \(O_3\), 和
    \(O_4\) 的真实图像或假图像。'
- en: '**Discriminator Weights** - \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\)
    for the connections from input nodes (input image) to the output (descision) node,
    \(D_8\)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器权重** - \(\lambda_{5,8}\), \(\lambda_{6,8}\), 和 \(\lambda_{7,8}\) 用于从输入节点（输入图像）到输出（决策）节点
    \(D_8\) 的连接。'
- en: '**Discriminator Bias** - \(c\), bias applied at the output (descision) node,
    \(D_8\)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器偏差** - \(c\)，在输出（决策）节点 \(D_8\) 应用偏差。'
- en: Now let’s visualize this very simple generative adversarial network.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来可视化这个非常简单的生成对抗网络。
- en: '[PRE3]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![_images/565edb7221aa6743a530bb98f80b562615b08280d5d3d4a52aee7ff15cefcaf2.png](../Images/cdcce92e4f0534109850166492b3b2ef.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/cdcce92e4f0534109850166492b3b2ef.png)'
- en: Just a couple more comments about my network nomenclature. My goal is to maximize
    simplicity and clarity,
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我的网络命名约定还有一些额外的注释。我的目标是最大化简洁性和清晰度，
- en: Comments on Network Nomenclature
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**网络命名约定**注释'
- en: '**Network Nodes and Connections** - I choose to use unique numbers for all
    nodes, \(L_1\), \(O_2\), \(O_3\), \(\ldots\) instead of \(L_1\), \(O_1\), \(O_2\),
    \(\ldots\) to simplify the notation for the weights; therefore, when I say \(\lambda_{5,8}\)
    you know exactly where this weight is applied in the network.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络节点和连接** - 我选择为所有节点使用唯一的数字，\(L_1\), \(O_2\), \(O_3\), \(\ldots\) 而不是 \(L_1\),
    \(O_1\), \(O_2\), \(\ldots\) 以简化权重的符号；因此，当我说 \(\lambda_{5,8}\) 时，你知道这个权重在网络的哪个位置应用。'
- en: '**Node Outputs** - I use the node label to also describe the output from the
    node, for example \(O_2\) is a node in the generator’s output layer and also the
    signal or value output from that node.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点输出** - 我使用节点标签来描述节点的输出，例如 \(O_2\) 是生成器输出层中的一个节点，也是从该节点输出的信号或值。'
- en: '**Pre- and Post-activation** - at our nodes \(O_2\), \(O_3\), \(O_4\), and
    \(D_8\) we have the node input before activation and the node output after activation,
    I use the notation \(O_{2_{in}}\), \(O_{3_{in}}\), \(O_{4_{in}}\) and \(D_{8_{in}}\)
    for the pre-activation input and \(O_2\), \(O_3\), \(O_4\), and \(D_8\) for the
    post-activation node output. This is important because with back propagation we
    have to step through the nodes, going from post-activation to pre-activation.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前激活和后激活** - 在我们的节点 \(O_2\), \(O_3\), \(O_4\), 和 \(D_8\) 上，我们有节点激活前的输入和激活后的节点输出，我使用符号
    \(O_{2_{in}}\), \(O_{3_{in}}\), \(O_{4_{in}}\) 和 \(D_{8_{in}}\) 表示前激活输入，以及 \(O_2\),
    \(O_3\), \(O_4\) 和 \(D_8\) 表示后激活节点输出。这很重要，因为在反向传播中，我们必须逐步通过节点，从后激活到前激活。'
- en: '**Latent** - while publications often use \(z\) notation for the latent values,
    to be consistent with my notion above, I use \(L_1\) for the latent value, i.e.,
    the output from my latent node, \(L_1\).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在** - 虽然出版物通常使用 \(z\) 符号表示潜在值，为了与上面的概念保持一致，我使用 \(L_1\) 表示潜在值，即我的潜在节点 \(L_1\)
    的输出。'
- en: Now let’s walk-through all the parts of our example GAN and show all the math.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来逐一介绍我们示例生成对抗网络（GAN）的所有部分，并展示所有的数学公式。
- en: Sigmoid Activation
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sigmoid 激活
- en: For reference, let’s visualize the sigmoid activation function,
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了参考，让我们可视化 sigmoid 激活函数，
- en: '**activation** - the non-linear transformation, this is the sigmoid activation'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活** - 非线性变换，这是 sigmoid 激活'
- en: \[ x_{out} = \sigma(x_{in}) = \dfrac{1}{1 + e^{-x_{in}}} \]
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_{out} = \sigma(x_{in}) = \dfrac{1}{1 + e^{-x_{in}}} \]
- en: '**activation derrivative** - essential for back propogation'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活导数** - 对于反向传播是必不可少的'
- en: \[ \sigma'(x_{in}) = \sigma(x_{out})(1 - \sigma(x_{out})) \]
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma'(x_{in}) = \sigma(x_{out})(1 - \sigma(x_{out})) \]
- en: note, for convenience the derrivative of the sigmoid activation function with
    respect to the input is posed for the output.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了方便起见，sigmoid 激活函数相对于输入的导数是针对输出给出的。
- en: as we back-propogate backwards over the activation function we can us the output
    to step back through the activated network node
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们反向传播通过激活函数时，我们可以使用输出逐步通过激活的网络节点
- en: '[PRE4]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![_images/f7323a3bf2b5671f3b7f629a5e2dd8966903903e490d8b510d1b437b922d20ad.png](../Images/6aef20df3b024801181a361544b98363.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![_images/f7323a3bf2b5671f3b7f629a5e2dd8966903903e490d8b510d1b437b922d20ad.png](../Images/6aef20df3b024801181a361544b98363.png)'
- en: Let’s make some observations about the sigmoid activation and its derrivative,
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们观察一下 sigmoid 激活及其导数，
- en: '**sigmoid outputs** - are bounded (0,1) approaching both limits asymptotically'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**sigmoid 输出** - 被限制在 (0,1) 范围内，渐进地接近两个极限'
- en: '**vanishing gradients** - as the'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度消失** - 随着'
- en: Generator Forward Pass
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器正向传播
- en: First, let’s walk through the generator to go from a latent value to a fake
    image. The generator takes a latent input,
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们逐步分析生成器，从潜在值到伪造图像。生成器接受一个潜在输入，
- en: \[ L_1 \sim \mathcal{U}(0.4, 1) \]
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L_1 \sim \mathcal{U}(0.4, 1) \]
- en: recall, our simple generator has only one layer \(L1\), with only 3 outputs,
    \(O_2\), \(O_3\), and \(O_4\), representing the fake image.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，我们的简单生成器只有一个层 \(L1\)，只有 3 个输出，\(O_2\)、\(O_3\) 和 \(O_4\)，代表伪造的图像。
- en: Then latent value, \(L_1\), is passed through the transpose convolution kernel
    to the output,
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，潜在值 \(L_1\) 通过转置卷积核传递到输出，
- en: our transpose convolution kernel has a size of 3, the same size as our output,
    so we don’t see it translate it, resulting in greatly simplified book keeping!
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的反转卷积核大小为 3，与我们的输出大小相同，因此我们看不到它转换，从而大大简化了账目！
- en: the tranpose convolution kernel weights are \(\lambda_{1,2}\), \(\lambda_{1,3}\),
    and \(\lambda_{1,4}\)
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转置卷积核权重是 \(\lambda_{1,2}\)、\(\lambda_{1,3}\) 和 \(\lambda_{1,4}\)
- en: We apply the sigmoid activation in each of the output nodes
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个输出节点应用 sigmoid 激活
- en: Each output is computed by applying a linear transformation followed by a **sigmoid**
    activation, \(\sigma\),
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 每个输出都是通过应用线性变换后跟一个 **sigmoid** 激活，\(\sigma\)，
- en: \[ O_2 = \sigma(\lambda_{1,2} \cdot z + b) \]\[ O_3 = \sigma(\lambda_{1,3} \cdot
    z + b) \]\[ O_4 = \sigma(\lambda_{1,4} \cdot z + b) \]
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: \[ O_2 = \sigma(\lambda_{1,2} \cdot z + b) \]\[ O_3 = \sigma(\lambda_{1,3} \cdot
    z + b) \]\[ O_4 = \sigma(\lambda_{1,4} \cdot z + b) \]
- en: where,
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: '**\(\lambda_{1,j}\)** - are the transpose convolution kernel weights'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**\(\lambda_{1,j}\)** - 是转置卷积核的权重'
- en: '**\(b\)** - is the shared bias, single bias term for the output layer'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**\(b\)** - 是共享偏差，输出层的单个偏差项'
- en: We can also write the generator forward pass in matrix notation as,
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以用矩阵符号写出生成器的正向传播，
- en: \[\begin{split} \begin{bmatrix} O_2 \\ O_3 \\ O_4 \end{bmatrix} = \sigma\left(
    \begin{bmatrix} \lambda_{1,2} \\ \lambda_{1,3} \\ \lambda_{1,4} \end{bmatrix}
    z + \begin{bmatrix} b \\ b \\ b \end{bmatrix} \right) \end{split}\]
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} O_2 \\ O_3 \\ O_4 \end{bmatrix} = \sigma\left(
    \begin{bmatrix} \lambda_{1,2} \\ \lambda_{1,3} \\ \lambda_{1,4} \end{bmatrix}
    z + \begin{bmatrix} b \\ b \\ b \end{bmatrix} \right) \end{split}\]
- en: where the sigmoid activation is applied element-wise.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 其中应用了逐元素 sigmoid 激活。
- en: Discriminator Forward Pass
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器正向传播
- en: Now let’s walk-through the discriminator, going from an image, real or fake,
    to a probability of real. The discriminator receives the image, over 3 input nodes,
    \(I_5\), \(I_6\), and \(I_7\). In the case of a fake image,
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐步分析判别器，从图像（真实或伪造）到真实概率。判别器接收图像，通过 3 个输入节点，\(I_5\)、\(I_6\) 和 \(I_7\)。在伪造图像的情况下，
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    O_2 \\ O_3 \\ O_4 \end{bmatrix} \end{split}\]
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    O_2 \\ O_3 \\ O_4 \end{bmatrix} \end{split}\]
- en: and in the case of a real image,
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实图像的情况下，
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    I_5^{real} \\ I_6^{real} \\ I_7^{real} \end{bmatrix} \end{split}\]
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    I_5^{real} \\ I_6^{real} \\ I_7^{real} \end{bmatrix} \end{split}\]
- en: Since we have only 1 layer and the convolution kernel is 3 with an input of
    3 once again there is no translation!
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只有一层，卷积核是3，输入也是3，所以没有平移！
- en: we just take input image, \(I_5\), \(I_6\), and \(I_7\), and apply the convolutional
    kernel weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\), and
    add the bias term, \(c\),
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只取输入图像，\(I_5\)，\(I_6\)，和\(I_7\)，并应用卷积核权重，\(\lambda_{5,8}\)，\(\lambda_{6,8}\)，和\(\lambda_{7,8}\)，然后加上偏置项，\(c\)，
- en: \[ D_8 = \sigma\left( \lambda_{5,8} \cdot I_5 + \lambda_{6,8} \cdot I_6 + \lambda_{7,8}
    \cdot I_7 + c \right) \]
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: \[ D_8 = \sigma\left( \lambda_{5,8} \cdot I_5 + \lambda_{6,8} \cdot I_6 + \lambda_{7,8}
    \cdot I_7 + c \right) \]
- en: where,
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\lambda_{i,8}\) are the convolutional kernel weights to go from input image
    to next feature map, only 1 value, our output probability
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\lambda_{i,8}\)是从输入图像到下一个特征图的卷积核权重，只有一个值，我们的输出概率
- en: \(c\) is the bias term
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(c\)是偏置项
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid activation function
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\)是sigmoid激活函数
- en: \(D_8 \in [0, 1]\) represents the probability assigned by the discriminator
    that the input is **real** (i.e. not a fake from the generator).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: \(D_8 \in [0, 1]\)表示判别器分配给输入是**真实**（即不是生成器的假图像）的概率。
- en: We can also write the discriminator forward pass in matrix notation as,
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将判别器前向传递写成矩阵形式，
- en: \[\begin{split} D_8 = \sigma\left( \begin{bmatrix} \lambda_{5,8} & \lambda_{6,8}
    & \lambda_{7,8} \end{bmatrix} \cdot \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix}
    + c \right) \end{split}\]
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D_8 = \sigma\left( \begin{bmatrix} \lambda_{5,8} & \lambda_{6,8}
    & \lambda_{7,8} \end{bmatrix} \cdot \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix}
    + c \right) \end{split}\]
- en: where,
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\) are scalar weights
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\)是标量权重
- en: \(I_5, I_6, I_7\) are the input values (i.e., outputs of the generator, \(O_2,
    O_3, O_4\))
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(I_5, I_6, I_7\)是输入值（即生成器的输出，\(O_2, O_3, O_4\)）
- en: \(c\) is the bias term
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(c\)是偏置项
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid function
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\)是sigmoid函数
- en: Discriminator Loss
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器损失
- en: Binary cross-entropy is a loss function used for binary classification tasks
    where the output is a probability between 0 and 1, and the target label is either
    0 or 1.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 二元交叉熵是一种用于二元分类任务的损失函数，其中输出是一个介于0和1之间的概率，目标标签是0或1。
- en: '**Prediction** (model output) - \(\hat{y} \in (0, 1)\), the output of \(D_8\),
    the discriminator’s classification, probability that the image is real'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**（模型输出）- \(\hat{y} \in (0, 1)\)，\(D_8\)的输出，判别器的分类，图像为真实的概率'
- en: \[ \hat{y} = D_8 \]
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = D_8 \]
- en: '**True label** (ground truth) - \(y \in \{0, 1\}\), 0 if the image is from
    the generator, fake, and 1 if the image is from the real training data'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真实标签**（地面实况）- \(y \in \{0, 1\}\)，如果图像来自生成器，则为假，如果图像来自真实训练数据，则为1'
- en: Now we can define the **binary cross-entropy loss** as,
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以定义**二元交叉熵损失**，
- en: \[ \mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1
    - y) \cdot \log(1 - \hat{y}) \right] \]
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1
    - y) \cdot \log(1 - \hat{y}) \right] \]
- en: now we can further specify,
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进一步指定，
- en: \(\log(\hat{y})\) is the log-likelihood of the positive prediction
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\log(\hat{y})\)是正预测的对数似然
- en: \(log(1 - \hat{y})\) is the log-likelihood of the negative prediction
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(log(1 - \hat{y})\)是负预测的对数似然
- en: how does binary cross-entropy behave?
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 二元交叉熵是如何表现的？
- en: 'if \(y = 1\) (real image), then:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果\(y = 1\)（真实图像），那么：
- en: \[ \mathcal{L} = -\log(\hat{y}) \quad \text{(we want } \hat{y} \to 1) \]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = -\log(\hat{y}) \quad \text{(我们希望 } \hat{y} \to 1) \]
- en: 'if \(y = 0\) (fake image from the generator), then:'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果\(y = 0\)（生成器的假图像），那么：
- en: \[ \mathcal{L} = -\log(1 - \hat{y}) \quad \text{(we want } \hat{y} \to 0) \]
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = -\log(1 - \hat{y}) \quad \text{(我们希望 } \hat{y} \to 0) \]
- en: We can summarize as,
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以总结为，
- en: the loss is **low** when the model’s prediction \(\hat{y}\) is **close to the
    true label**, low probability of real for a fake image and high probability of
    real for a real image
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当模型的预测\(\hat{y}\)接近真实标签时，损失是**低**的，对于假图像的真实概率低，对于真实图像的真实概率高
- en: the loss becomes **very large** if the model is **confident and wrong**, due
    to the logarithm, i.e., very low probability or real for a real image and very
    high probability of real for a fake image
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型**自信且错误**，损失会变得**非常大**，由于对数，即对于真实图像的真实概率非常低，对于假图像的真实概率非常高
- en: the sigmoid activation ensures that the output, \(\hat{y}\) is a valid probability
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: sigmoid激活确保输出，\(\hat{y}\)是一个有效的概率
- en: Discriminator Loss Derivative
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器损失导数
- en: To perform backpropagation we need to calculate the loss derivative. Let’s do
    this for the input of the activation function as our output node, \(D_8\),
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行反向传播，我们需要计算损失导数。让我们以激活函数的输入作为输出节点 \(D_8\)，来计算这个导数。
- en: \[ \frac{d\mathcal{L}}{dz} \]
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} \]
- en: define \(z\) as the input for the sigmoid activation as output node, \(D_8\).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义 \(z\) 为sigmoid激活函数的输出节点 \(D_8\) 的输入。
- en: as you see we do this because it results in a very simple, efficient result.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如你所见，我们这样做是因为它产生了一个非常简单、高效的结果。
- en: recall, the sigmoid function,
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，sigmoid函数，
- en: \[ \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \]
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \]
- en: We will use the chain rule, so we only need to solve the parts,
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用链式法则，所以我们只需要解决部分，
- en: \[ \frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
    \]
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
    \]
- en: \(\frac{d\mathcal{L}}{d\hat{y}}\) - partial derivative of binary cross-entropy
    loss given the discriminator output \(\hat{y}\) (\(D_8\))
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\frac{d\mathcal{L}}{d\hat{y}}\) - 给定判别器输出 \(\hat{y}\) (\(D_8\)) 的二元交叉熵损失的偏导数
- en: \(\frac{d\hat{y}}{dz}\) - partial derivative of the discriminator output \(\hat{y}\)
    (\(D_8\)) given the sigmoid activation input
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\frac{d\hat{y}}{dz}\) - 给定sigmoid激活输入的判别器输出 \(\hat{y}\) (\(D_8\)) 的偏导数
- en: Now we can solve the first part, partial derivative of loss with respect to
    the discriminator output, \(\hat{y}\)
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以解决第一部分，损失相对于判别器输出 \(\hat{y}\) 的偏导数
- en: \[ \frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1
    - \hat{y}} \right) \]
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1
    - \hat{y}} \right) \]
- en: now we can solve the second part, the partial derivative of the discriminator
    output \(\hat{y}\) (\(D_8\)) given the sigmoid activation input, it is just the
    sigmoid derivative,
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以解决第二部分，给定sigmoid激活输入的判别器输出 \(\hat{y}\) (\(D_8\)) 的偏导数，它就是sigmoid的导数，
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]
- en: and we can combine these by the chain rule as,
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过链式法则将它们结合起来，
- en: \[ \frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}
    \right) \cdot \hat{y}(1 - \hat{y}) \]
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}
    \right) \cdot \hat{y}(1 - \hat{y}) \]
- en: We are almost there, we only need to simplify the result, first we distribute,
    \(\hat{y}(1 - \hat{y})\),
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了，我们只需要简化结果，首先我们分配，\(\hat{y}(1 - \hat{y})\)，
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
    \]
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
    \]
- en: and then simplify it further,
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然后进一步简化它，
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
    = -\left[ y - \hat{y} \right] = \hat{y} - y \]
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
    = -\left[ y - \hat{y} \right] = \hat{y} - y \]
- en: I said this would get simple! Our partial derivative of our loss with respect
    to the input to the output node sigmoid activation function, \(z\), is,
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我说这会变得简单！我们关于输出节点sigmoid激活函数输入的损失的部分导数是，
- en: \[ \frac{d\mathcal{L}}{dz} = \hat{y} - y \]
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = \hat{y} - y \]
- en: This result shows the gradient is just the **error** — the difference between
    predicted and true values.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果表明梯度仅仅是**误差**——预测值和真实值之间的差异。
- en: Now we can make this simple interpretation,
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行这个简单的解释，
- en: if \(\hat{y} > y\), the model overestimates \(\rightarrow\) gradient is positive
    \(\rightarrow\) lower prediction by moving in the negative gradient
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 \(\hat{y} > y\)，模型高估了 \(\rightarrow\) 导数是正的 \(\rightarrow\) 通过向负梯度方向移动来降低预测
- en: if \(\hat{y} < y\), the model underestimates \(\rightarrow\) gradient is negative
    \(\rightarrow\) increase prediction by moving in the negative gradient
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 \(\hat{y} < y\)，模型低估了 \(\rightarrow\) 导数是负的 \(\rightarrow\) 通过向负梯度方向移动来增加预测
- en: I know that a title this section “Discriminator Loss Derivative”, but excuse
    me for performing just a little bit of backpropagation (to before sigmoid activation).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这个标题是“判别器损失导数”，但请原谅我进行一点反向传播（到sigmoid激活之前）。
- en: next we carry on with back propagation to the discriminator weights and biases
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们继续反向传播到判别器的权重和偏置
- en: Discriminator Back Propagation
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器反向传播
- en: For compact notation, let’s use matrix notation and define the input to the
    \(D_8\) activation, \(z\), as,
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 为了紧凑的表示，让我们使用矩阵表示法，并定义 \(D_8\) 激活的输入 \(z\)，
- en: \[ z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}}
    = \mathbf{x} \]
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}}
    = \mathbf{x} \]
- en: Now we can extend our use of the chain rule to,
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以扩展我们对链式法则的使用，
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}}
    = (\hat{y} - y) \cdot \mathbf{x} \]
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}}
    = (\hat{y} - y) \cdot \mathbf{x} \]
- en: So for each of our discriminator weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\),
    and \(\lambda_{7,8}\) we have,
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于我们的每个判别器权重，\(\lambda_{5,8}\)，\(\lambda_{6,8}\)，和 \(\lambda_{7,8}\)，我们都有，
- en: \[ \frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5 \]\[ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    = (\hat{y} - y) \cdot I_6 \]\[ \frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y}
    - y) \cdot I_7 \]
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5 \]\[ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    = (\hat{y} - y) \cdot I_6 \]\[ \frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y}
    - y) \cdot I_7 \]
- en: and for the bias, \(c\), we calculate the next component for the chain rule
    as,
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 对于偏置 \(c\)，我们计算链式法则的下一个组件，
- en: \[ \frac{dz}{dc} = 1 \]
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dz}{dc} = 1 \]
- en: so we have,
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有，
- en: \[ \frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y}
    - y) \cdot 1 = \hat{y} - y \]
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y}
    - y) \cdot 1 = \hat{y} - y \]
- en: The backpropagation for our very simple discriminator is quite simple, we can
    summarize for the weights,
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常简单的判别器的反向传播相当简单，我们可以总结权重，
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x} \]
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x} \]
- en: and for the bias,
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 对于偏置，
- en: \[ \frac{d\mathcal{L}}{dc} = \hat{y} - y \]
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dc} = \hat{y} - y \]
- en: Let’s write these out for all of our discriminators parameters, $\( \begin{aligned}
    \frac{d\mathcal{L}}{d\lambda_{5,8}} &= (\hat{y} - y) \cdot I_5 \\ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    &= (\hat{y} - y) \cdot I_6 \\ \frac{d\mathcal{L}}{d\lambda_{7,8}} &= (\hat{y}
    - y) \cdot I_7 \\ \frac{d\mathcal{L}}{dc} &= \hat{y} - y \end{aligned} \)$
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为所有判别器参数写出这些，$\( \begin{aligned} \frac{d\mathcal{L}}{d\lambda_{5,8}} &= (\hat{y}
    - y) \cdot I_5 \\ \frac{d\mathcal{L}}{d\lambda_{6,8}} &= (\hat{y} - y) \cdot I_6
    \\ \frac{d\mathcal{L}}{d\lambda_{7,8}} &= (\hat{y} - y) \cdot I_7 \\ \frac{d\mathcal{L}}{dc}
    &= \hat{y} - y \end{aligned} \)$
- en: Generator Loss Derivative and Back Propagation Through the Discriminator
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器损失导数和通过判别器的反向传播
- en: Recall that the goal of the generator is to make fake images the discriminator
    assigns as a high probability of a real image, i.e., to fool the discriminator
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，生成器的目标是使判别器分配给假图像的高概率为真实图像，即，欺骗判别器
- en: the generator produces a fake image,
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器生成一个假图像，
- en: \[ \tilde{\mathbf{x}} = G(z) \]
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \tilde{\mathbf{x}} = G(z) \]
- en: \(\quad\) where ( z ) is a latent vector (e.g., sampled from Uniform[0.4, 1]).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 其中 ( z ) 是一个潜在向量（例如，从 Uniform[0.4, 1] 中采样）。
- en: 'the discriminator evaluates this fake sample and returns:'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器评估这个假样本并返回：
- en: \[ \hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1) \]
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1) \]
- en: Now we can calculate the binary cross-entropy for the generator as,
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算生成器的二进制交叉熵，
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}_G = -\log(\hat{y}) \]
- en: where,
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\hat{y} = D(G(z))\), the discriminator’s evaluation of the generator’s fake
    image, \(z\)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{y} = D(G(z))\)，判别器对生成器假图像 \(z\) 的评估
- en: \(\hat{y}\) is the probability assigned by the discriminator to the fake being
    real
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{y}\) 是判别器分配给假图像为真实的概率
- en: This is equivalent to cross-entropy with **target label \(y = 1\)**, note here
    we do a trick, from the generator’s perspective it’s images are real, so we are
    using \(y=1\), i.e., real images for the fake images!
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当于具有**目标标签 \(y = 1\)** 的交叉熵，注意这里我们玩了一个小花招，从生成器的角度来看，它的图像是真实的，所以我们使用 \(y=1\)，即，对于假图像使用真实图像！
- en: You may get confused if you look at the original GAN loss above, this is called
    the non-saturating generator loss.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到上面的原始 GAN 损失，这被称为非饱和生成器损失。
- en: '| Loss Type | Expression | Comment |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 损失类型 | 表达式 | 注释 |'
- en: '| --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Original GAN** | \(\mathbb{E}[\log(1 - D(G(z)))]\) | Theoretical, can cause
    vanishing gradients |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| **原始 GAN** | \(\mathbb{E}[\log(1 - D(G(z)))]\) | 理论上，可能导致梯度消失 |'
- en: '| **Non-saturating** | \(-\mathbb{E}[\log(D(G(z)))]\) | Practical, stronger
    gradients, commonly used |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| **非饱和** | \(-\mathbb{E}[\log(D(G(z)))]\) | 实际应用，更强的梯度，常用 |'
- en: so instead of minimizing the original generator loss we are maximizing the non-saturating
    generator loss.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，我们不是最小化原始生成器损失，而是最大化非饱和生成器损失。
- en: Let’s show how to back propagate through the entire discriminator with the chain
    rule.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们展示如何使用链式法则通过整个判别器进行反向传播。
- en: we want the generator loss gradient with respect generator output,
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望得到生成器损失相对于生成器输出的梯度，
- en: Given \(\tilde{\mathbf{x}} = G(z)\), our fake image, we want the partial derivative
    of the loss given our fake image,
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 给定 \(\tilde{\mathbf{x}} = G(z)\)，我们的假图像，我们希望得到给定我们的假图像的损失函数的偏导数，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} \]
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} \]
- en: and by the chain rule,
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 通过链式法则，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}}
    \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}} \]
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}}
    \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}} \]
- en: This is how the discriminator’s belief \(\hat{y}\)​ about “fakeness” changes
    with changes in \(\tilde{\mathbf{x}}\) the fake image.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是判别器关于“伪造性”的信念 \(\hat{y}\) 随伪造图像 \(\tilde{\mathbf{x}}\) 的变化而变化的方式。
- en: Now we are ready to back propagate the generator loss through the discriminator,
    let’s start with our generator loss (from above),
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备通过判别器反向传播生成器损失，让我们从上面的生成器损失开始，
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}_G = -\log(\hat{y}) \]
- en: and when we perform the partial derivative,
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行偏导数运算时，
- en: \[ \frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}} \]
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}} \]
- en: Now, recall the discriminator’s forward pass is,
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回忆判别器的正向传播是，
- en: \[ \hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c) \]
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c) \]
- en: so we can calculate the partial derivative of the discriminator’s output with
    respect to the generator’s fake image as,
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算判别器输出相对于生成器伪造图像的偏导数，
- en: \[ \frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
    \]
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
    \]
- en: now we combine these with the chain rule as,
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将这些与链式法则结合起来，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \left( -\frac{1}{\hat{y}} \right)
    \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right) = -(1 - \hat{y}) \cdot
    \mathbf{w} \]
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \left( -\frac{1}{\hat{y}} \right)
    \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right) = -(1 - \hat{y}) \cdot
    \mathbf{w} \]
- en: The gradient of the generator’s loss with respect to the output image \(\tilde{\mathbf{x}}\)
    is,
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器损失相对于输出图像 \(\tilde{\mathbf{x}}\) 的梯度是，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
    \]
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
    \]
- en: We can add some interpretations of this result,
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对这个结果进行一些解释，
- en: when \(\hat{y}\) is close to 0 \(\rightarrow\) discriminator easily spots fake
    \(\rightarrow\) large gradient \(\rightarrow\) generator updates more.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 \(\hat{y}\) 接近 0 \(\rightarrow\) 判别器容易发现伪造 \(\rightarrow\) 大梯度 \(\rightarrow\)
    生成器更新更多。
- en: when \(\hat{y}\) is close to 1 \(\rightarrow\) generator is fooling the discriminator
    \(\rightarrow\) gradient is small.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 \(\hat{y}\) 接近 1 \(\rightarrow\) 生成器欺骗判别器 \(\rightarrow\) 梯度较小。
- en: This guides the generator to tweak its output to increase \(\hat{y}\) — i.e.,
    fool the discriminator.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这指导生成器调整其输出以增加 \(\hat{y}\) — 即欺骗判别器。
- en: To further clarify, for our example let’s compute how the discriminator’s output
    \(\hat{y}\) changes with respect to the generator outputs \(O_5, O_6, O_7\), instead
    of the \(w\) vector notation used above.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步阐明，以我们的例子为例，让我们计算判别器的输出 \(\hat{y}\) 如何随生成器输出 \(O_5, O_6, O_7\) 变化，而不是上面使用的
    \(w\) 向量表示法。
- en: if we apply the chain rule we get,
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们应用链式法则，我们得到，
- en: \[ \frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i} \]
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i} \]
- en: \(\quad\) for each of the components we have,
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 对于每个组成部分，我们有，
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]\[ \frac{dz}{dO_5} = \lambda_{5,8}
    \]\[ \frac{dz}{dO_6} = \lambda_{6,8} \]\[ \frac{dz}{dO_7} = \lambda_{7,8} \]
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]\[ \frac{dz}{dO_5} = \lambda_{5,8}
    \]\[ \frac{dz}{dO_6} = \lambda_{6,8} \]\[ \frac{dz}{dO_7} = \lambda_{7,8} \]
- en: \(\quad\) substituting in the chain rule we have,
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 代入链式法则，我们得到，
- en: \[ \frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8} \]\[ \frac{d\hat{y}}{dO_6}
    = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8} \]\[ \frac{d\hat{y}}{dO_7} = \hat{y}(1
    - \hat{y}) \cdot \lambda_{7,8} \]
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8} \]\[ \frac{d\hat{y}}{dO_6}
    = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8} \]\[ \frac{d\hat{y}}{dO_7} = \hat{y}(1
    - \hat{y}) \cdot \lambda_{7,8} \]
- en: Backpropagation Through Generator to Weights and Bias
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过生成器反向传播权重和偏差
- en: We now propagate through the generators sigmoid activation in each of the output
    nodes,
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在通过每个输出节点的生成器 sigmoid 激活传播，
- en: \[ \frac{dO_i}{dz_i} = O_i (1 - O_i) \]
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dO_i}{dz_i} = O_i (1 - O_i) \]
- en: \(O_i = \sigma(z_i)\), where \(z_i\) is the input for the output nodes, pre-activation,
    and \(O_i\) is output for the output nodes, post-activation
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(O_i = \sigma(z_i)\)，其中 \(z_i\) 是输出节点的输入，预激活，而 \(O_i\) 是输出节点的输出，后激活
- en: We Apply chain rule,
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用链式法则，
- en: \[ \frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
    = \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \]
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
    = \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \]
- en: Recall,
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆，
- en: \[ z_i = \lambda_{1,i} \cdot L_1 + b \]
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z_i = \lambda_{1,i} \cdot L_1 + b \]
- en: so we can calculate the generator’s weights partial derivatives as,
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算生成器权重的偏导数，
- en: \[ \frac{dz_i}{d\lambda_{1,i}} = L_1 \]
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dz_i}{d\lambda_{1,i}} = L_1 \]
- en: and the generator’s bias partial derivative as,
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 以及生成器偏差的偏导数，
- en: \[ \frac{dz_i}{db} = 1 \]
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dz_i}{db} = 1 \]
- en: Now we can put this all together with the chain rule, the partial derivatives
    of the generator loss with respect to the generator weights are,
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用链式法则，将生成器损失相对于生成器权重的偏导数放在一起，
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,i}} = \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{d\lambda_{1,i}} = \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \cdot L_1 \]
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,i}} = \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{d\lambda_{1,i}} = \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \cdot L_1 \]
- en: and the partial derivative of the generator loss with respect to the generator
    bias is,
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 以及生成器损失相对于生成器偏差的偏导数，
- en: \[ \frac{d\mathcal{L}_G}{db} = \sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{db} = \sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \]
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{db} = \sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{db} = \sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \]
- en: For clarity, let’s write this out for each of our generator’s weights,
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，让我们为我们的生成器每个权重写出这些内容，
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,2}} = -(1 - \hat{y}) \cdot \lambda_{5,8}
    \cdot O_5 (1 - O_5) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,3}} = -(1
    - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,4}}
    = -(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1 \]
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,2}} = -(1 - \hat{y}) \cdot \lambda_{5,8}
    \cdot O_5 (1 - O_5) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,3}} = -(1
    - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,4}}
    = -(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1 \]
- en: and for our generator’s bias,
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的生成器偏差，
- en: \[ \frac{d\mathcal{L}_G}{db} = -(1 - \hat{y}) \cdot \left[ \lambda_{5,8} \cdot
    O_5(1 - O_5) + \lambda_{6,8} \cdot O_6(1 - O_6) + \lambda_{7,8} \cdot O_7(1 -
    O_7) \right] \]
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{db} = -(1 - \hat{y}) \cdot \left[ \lambda_{5,8} \cdot
    O_5(1 - O_5) + \lambda_{6,8} \cdot O_6(1 - O_6) + \lambda_{7,8} \cdot O_7(1 -
    O_7) \right] \]
- en: Let’s make some interpretations,
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一些解释，
- en: the generator’s weights and bias gradients scale with how much the discriminator
    is fooled (\(1 - \hat{y}\))
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器的权重和偏差梯度与判别器被欺骗的程度（\(1 - \hat{y}\)）成比例
- en: the generator learns to tweak \(\lambda_{1,i}\) and \(b\) to push the fake images,
    \(O_5\), \(O_6\) and \(O_7\) in directions that increase \(\hat{y}\)
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器学习调整 \(\lambda_{1,i}\) 和 \(b\)，以推动假图像 \(O_5\)、\(O_6\) 和 \(O_7\) 的方向，从而增加
    \(\hat{y}\)
- en: this flow of error gives the generator a signal to **fool the discriminator
    more effectively** without ever seeing a real image!
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种错误流给生成器一个信号，使其能够更有效地**欺骗判别器**，而无需看到任何真实图像！
- en: Simple GAN Training Workflow
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单 GAN 训练流程
- en: We start with initialization of the generator and discriminator weights and
    bias and setting the training hyperparameters.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从初始化生成器和判别器的权重和偏差以及设置训练超参数开始。
- en: Generate the Synthethic, “Real Images” for training
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成用于训练的合成“真实图像”
- en: sample \(N\) real 3-node, 1D images \(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本 \(N\) 个真实 3 节点，1D 图像 \(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)
- en: 'use the synthetic training data function:'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用合成训练数据函数：
- en: \[ \text{Real images} \sim \text{linear decreasing trend} + \text{noise} \]
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Real images} \sim \text{linear decreasing trend} + \text{noise} \]
- en: '**Initialize generator weights and bias** - the weights,'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化生成器权重和偏差** - 权重，'
- en: \[ \{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small
    random values} \]
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small
    random values} \]
- en: \(\quad\) and the bias,
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 以及偏差，
- en: \[ b \leftarrow 0.0 \]
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: \[ b \leftarrow 0.0 \]
- en: '**Initialize discriminator weights and bias** - the weights,'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化判别器权重和偏差** - 权重，'
- en: \[ \{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small
    random values} \]
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small
    random values} \]
- en: \(\quad\) and the bias,
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 以及偏差，
- en: \[ c \leftarrow 0.0 \]
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: \[ c \leftarrow 0.0 \]
- en: '**Set model training hyperparameters** - this includes,'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置模型训练超参数** - 这包括，'
- en: Learning Rates - for the generator, \(\eta_G\), and discriminator, \(\eta_D\)
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率 - 对于生成器，\(\eta_G\)，和判别器，\(\eta_D\)
- en: Batch Size - in this example we are assuming batch size equal to the number
    of real images
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小 - 在这个例子中，我们假设批量大小等于真实图像的数量
- en: Epochs - number of training iterations
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮次 - 训练迭代次数
- en: '**Train the discriminator**'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练判别器**'
- en: combine real and fake inputs into a batch of size \(2N\) and inlcude labels
    \(y_i = 1\) for real, \(y_i = 0\) for fake
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将真实和假输入合并成一个大小为 \(2N\) 的批次，并包括标签 \(y_i = 1\) 表示真实，\(y_i = 0\) 表示假
- en: compute discriminator outputs \(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算判别器的输出 \(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)
- en: 'calculate discriminator loss and gradients using:'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下方法计算判别器损失和梯度：
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial
    \mathcal{L}}{\partial c} \]
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial
    \mathcal{L}}{\partial c} \]
- en: 'update discriminator weights and bias:'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新判别器的权重和偏差：
- en: \[ \lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    \lambda_{j,8}}, \quad c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    c} \]
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    \lambda_{j,8}}, \quad c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    c} \]
- en: '**Train the generator**'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练生成器**'
- en: Compute generator output fake images and pass to the discriminator to evaluate
    the outputs on these fakes, \(D_8\) same as \(y\)
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算生成器的输出假图像并将其传递给判别器以评估这些假图像的输出，\(D_8\) 与 \(y\) 相同
- en: Calculate generator loss gradients using,
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下方法计算生成器损失梯度，
- en: \[ \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial
    \mathcal{L}_G}{\partial b} \]
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial
    \mathcal{L}_G}{\partial b} \]
- en: Update generator weights and bias,
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新生成器的权重和偏差，
- en: \[ \lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    \lambda_{1,j}}, \quad b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    b} \]
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    \lambda_{1,j}}, \quad b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    b} \]
- en: '**Repeat Until Convergence** - or stop criteria is met, such as maximum number
    of training epochs, return to step 5.'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重复直到收敛** - 或者满足停止条件，例如最大训练轮数，返回到步骤 5。'
- en: Here a summary of the training loop,
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是对训练循环的总结，
- en: Generate real data batch
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成真实数据批次
- en: Generate fake data batch
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成假数据批次
- en: Update discriminator to better distinguish real/fake
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新判别器以更好地区分真实/假
- en: Update generator to fool discriminator
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新生成器以欺骗判别器
- en: Repeat
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复
- en: This adversarial training loop lets the generator learn to create data mimicking
    the real distribution, and the discriminator improve in spotting fakes.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对抗性训练循环让生成器学会创建模仿真实分布的数据，并让判别器在识别假图像方面得到改进。
- en: '[PRE5]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![_images/0e5b9d59df3b7c13cf96ada6a8409c005cf108794aa5c6d5da5188ad5ef20ded.png](../Images/686c89ab95fc15d0556a9ed4d7f3bed6.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/686c89ab95fc15d0556a9ed4d7f3bed6.png)'
- en: Visualize Real Images and Trained Generator Fake Images
  id: totrans-394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化真实图像和训练好的生成器生成的假图像
- en: Let’s check a set of fake images from our trained generator against the real
    images.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一组从训练好的生成器生成的假图像与真实图像的对比。
- en: recall the generator never saw these images, the discriminator saw the real
    and fake images and told the generator how good or bad were the generator’s fake
    images.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，生成器从未见过这些图像，判别器看到了真实和假图像，并告诉生成器生成器的假图像有多好或有多坏。
- en: '[PRE17]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![_images/765558367eae336a177e7a0b9b0a86037b878b20114ad05070fc072fd5f13404.png](../Images/5e411f7e4a786c08b02c80dadc431416.png)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5e411f7e4a786c08b02c80dadc431416.png)'
- en: Visualize Real Images and Generator Fake Images Over Training Epochs
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在训练轮次上可视化真实图像和生成器生成的假图像
- en: It is interesting to see how our generator’s fake images evolve over the training
    epochs.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 看看我们的生成器生成的假图像在训练轮次上的演变过程是非常有趣的。
- en: as first the fake images are random due to the random initialization of the
    generator’s weights and bias
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于生成器权重和偏差的随机初始化，最初的假图像是随机的
- en: as the training proceeds the generator learns to improve the fake images.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着训练的进行，生成器学会改进假图像。
- en: I include the real images at the end for comparison.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 我在最后包括了真实图像以供比较。
- en: '[PRE18]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![_images/c9fb21bf43af473100eacd88fe058bc353b01c81bec63e5cf3719df9229a386d.png](../Images/ad9bdf6d9a437102f9bba86e2f345ae0.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ad9bdf6d9a437102f9bba86e2f345ae0.png)'
- en: Comments
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注释
- en: This was a basic treatment of generative adversarial networks. Much more could
    be done and discussed, I have many more resources. Check out my [shared resource
    inventory](https://michaelpyrcz.com/my-resources) and the YouTube lecture links
    at the start of this chapter with resource links in the videos’ descriptions.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对生成对抗网络的基本介绍。还有更多可以做的和讨论的，我有很多更多的资源。查看我的[共享资源清单](https://michaelpyrcz.com/my-resources)以及本章开头YouTube讲座中的资源链接，视频描述中包含资源链接。
- en: I hope this is helpful,
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这能有所帮助，
- en: '*Michael*'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '*迈克尔*'
- en: About the Author
  id: totrans-410
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于作者
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·皮尔奇教授在德克萨斯大学奥斯汀分校40英亩校园的办公室。
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·皮尔奇是德克萨斯大学奥斯汀分校[ Cockrell工程学院](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)和[杰克逊地球科学学院](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)的教授，在那里他研究并教授地下、空间数据分析、地统计学和机器学习。迈克尔还是，
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[能源分析](https://fri.cns.utexas.edu/energy-analytics)新生研究项目的负责人，德克萨斯大学奥斯汀分校自然科学院机器学习实验室的核心教员'
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机与地球科学](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)的副编辑，以及国际数学地球科学协会[数学地球科学](https://link.springer.com/journal/11004/editorial-board)的董事会成员。'
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔已经撰写了超过70篇[同行评审的出版物](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)，一个用于空间数据分析的[Python包](https://pypi.org/project/geostatspy/)，合著了一本关于空间数据分析的教科书《[地统计学储层建模](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)》，并且是两本近期发布的电子书的作者，分别是《[Python应用地统计学：GeostatsPy实践指南](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)》和《[Python应用机器学习：代码实践指南](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)》。
- en: All of Michael’s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michael’s work and shared educational resources visit his
    Website.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔的所有大学讲座都可以在他的[YouTube频道](https://www.youtube.com/@GeostatsGuyLectures)上找到，其中包含100多个Python交互式仪表板和40多个存储库中的详细工作流程链接，这些存储库位于他的[GitHub账户](https://github.com/GeostatsGuy)，以支持任何感兴趣的学生和在职专业人士。要了解更多关于迈克尔的工作和共享教育资源，请访问他的网站。
- en: Want to Work Together?
  id: totrans-418
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 想要一起工作吗？
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这些内容对那些想了解更多关于地下建模、数据分析和学习机器的人来说有帮助。学生和在职专业人士都欢迎参与。
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? I’d be happy to drop by and work with you!
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想邀请我到贵公司进行培训、辅导、项目审查、工作流程设计和/或咨询？我很乐意拜访并与您合作！
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感兴趣合作、支持我的研究生研究或我的地下数据分析与机器学习联盟（共同负责人是约翰·福斯特教授）吗？我的研究结合了数据分析、随机建模和机器学习理论与实践，以开发新的方法和工作流程，增加价值。我们正在解决具有挑战性的地下问题！
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以通过[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)联系我。
- en: I’m always happy to discuss,
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是很高兴讨论，
- en: '*Michael*'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '*迈克尔*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·皮尔茨，博士，P.Eng. 教授，德克萨斯大学奥斯汀分校Cockrell工程学院和Jackson地球科学学院
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 更多资源可在以下链接获取：[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [网站](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [地统计学书籍](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python中应用地统计学电子书](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Python中应用机器学习电子书](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
- en: Motivation
  id: totrans-427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动机
- en: What if we put together machines? Working in a competitive, adversarial manner?
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将机器组合在一起呢？以竞争、对抗的方式工作？
- en: Could we make a more powerful machine learning model that learns its own loss
    function!
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否创建一个更强大的机器学习模型，该模型能够学习自己的损失函数！
- en: Could we make images that don’t collapse to exact reproduction of the images
    in the training set?
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否制作出不会退化到训练集中图像精确复制的图像？
- en: Generative neural networks are very powerful, nature inspired computing deep
    learning method to make fake, but realistic, images by application of convolutional
    neural networks, an analogy of visual cortex that extend the ability of our artificial
    neural networks to better work with images.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性神经网络非常强大，自然启发计算深度学习方法通过应用卷积神经网络，模拟视觉皮层，扩展了我们人工神经网络的图像处理能力，从而制作出逼真的图像。
- en: Nature inspired computing is looking to nature for inspiration to develop novel
    problem-solving methods,
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 自然启发计算正在从自然界中寻找灵感，以开发新的问题解决方法，
- en: '**artificial neural networks** are inspired by biological neural networks'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络**是受生物神经网络启发的'
- en: '**nodes** in our model are artificial neurons, simple processors'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们模型中的**节点**是人工神经元，简单的处理器
- en: '**connections** between nodes are artificial synapses'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点之间的**连接**是人工突触
- en: '**perceptive fields** regularization to improve generalization and efficiency'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**感知域**正则化以提高泛化能力和效率'
- en: intelligence emerges from many connected simple processors. For the remainder
    of this chapter, I will used the terms nodes and connections to describe our convolutional
    neural network.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 智能是从许多连接的简单处理器中产生的。在本章的剩余部分，我将使用节点和连接这两个术语来描述我们的卷积神经网络。
- en: Artificial and Convolutional Neural Networks
  id: totrans-438
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工和卷积神经网络
- en: If you have not, take this opportunity to review my previous chapters in the
    e-book on,
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有，请利用这个机会回顾电子书中的前几章，
- en: '[Artificial Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '[人工神经网络](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)'
- en: The **main takeaways** from my artificial neural network chapter are as follows,
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 我的人工神经网络章节的主要收获如下，
- en: '**architecture of a neural network**, including its fundamental components,
    nodes (neurons) and the weighted connections between them.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络架构**，包括其基本组件，节点（神经元）以及它们之间的加权连接。'
- en: '**forward pass** computation through the network, where each node computes
    a weighted sum of its inputs (including a bias term), followed by the application
    of a nonlinear activation function.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正向传播**计算通过网络，其中每个节点计算其输入的加权和（包括偏差项），然后应用非线性激活函数。'
- en: '**computation of the error derivative**, which is then backpropagated through
    the network via the chain rule to determine the gradients of the loss function
    with respect to each weight and bias.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算误差导数**，然后通过链式法则通过网络反向传播，以确定损失函数相对于每个权重和偏差的梯度。'
- en: '**aggregation of these gradients** across all samples in a training batch,
    typically by averaging, to update the model parameters.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合**这些梯度，通常通过平均，来更新模型参数。'
- en: '**iterative training process**, where the model is trained over multiple batches
    and epochs (passes over all the data) to continually refine the weights and biases
    until the model achieves an acceptable error rate on the test data.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代训练过程**，其中模型在多个批次和多个epoch（遍历所有数据）中训练，以不断细化权重和偏差，直到模型在测试数据上达到可接受的错误率。'
- en: '[Convolutional Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_CNN.html)'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '[卷积神经网络](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_CNN.html)'
- en: The main takeaways from my convolutional neural network chapter are as follows,
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 我卷积神经网络章节的主要收获如下，
- en: '**regularization** of image data with receptive fields to preserve spatial
    information and to avoid overfit.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用感受野对图像数据进行**正则化**以保留空间信息并避免过拟合。
- en: '**convolutional kernels** with learnable weights to extraction information
    from images.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积核**带有可学习的权重，用于从图像中提取信息。'
- en: For both of these chapters, I have included links to my recorded lectures and
    to neural networks built from scratch with NumPy only!
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两个章节，我都包括了链接到我的录音讲座以及仅使用NumPy从头构建的神经网络！
- en: Generative Adversarial Networks
  id: totrans-452
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: If we start with a convolutional neural network and we flip it, i.e., reverse
    the order of the operations,
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从卷积神经网络开始，并将其翻转，即反转操作顺序，
- en: we have a machine that maps from a 1D vector of values, to an image, i.e., we
    can generate fake images by randomly assigning latent values
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有一个将值的一维向量映射到图像的机器，即我们可以通过随机分配潜在值来生成假图像
- en: to accomplish this instead of convolution operations with activation, we have
    transpose convolution operations with activation to move to the next feature map
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们使用带有激活的转置卷积操作，而不是带有激活的卷积操作，以移动到下一个特征图
- en: recall we also perform non-linear activation at each feature map to prevent
    network collapse
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，我们还在每个特征图上执行非线性激活，以防止网络崩溃
- en: '![](../Images/edf859adfdeba17f094dbc0415d2bb06.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/edf859adfdeba17f094dbc0415d2bb06.png)'
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 一个翻转的卷积神经网络，将卷积替换为转置卷积，从一维随机潜在向量到随机图像。
- en: But how do we train this flipped convolutional neural network to make good images?
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们如何训练这个翻转的卷积神经网络以制作出好的图像呢？
- en: we could take training images and score the difference between our generated
    fake images, for example, with a pixel-wise squared error (L2 norm)
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以取训练图像并评估我们生成的假图像之间的差异，例如，使用像素级的平方误差（L2范数）
- en: but if we did this, our machine learning model would only learn how to make
    this image or a limited set of training images and that would not be useful
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 但如果我们这样做，我们的机器学习模型将只会学习如何制作这个图像或有限的训练图像集，这不会很有用
- en: We want to make a diverse set of image realizations, that look and behave correctly.
    This is the simulation paradigm at the heart of geostatistics,
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要制作一组多样化的图像实现，它们看起来和行为都是正确的。这是地统计学核心的模拟范式，
- en: to learn more about the simulation paradigm from geostatistics, see my [Simulation
    Chapter](https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html)
    from my free, online e-book, [Applied Geostatistics in Python](https://geostatsguy.github.io/GeostatsPyDemos_Book).
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要了解更多关于地统计学模拟范式的信息，请参阅我的免费在线电子书[《Python应用地统计学》](https://geostatsguy.github.io/GeostatsPyDemos_Book)中的[模拟章节](https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html)。
- en: Instead of a typically loss function, we apply a classification convolutional
    neural network to map from the image to a probability of a real image, i.e., our
    loss function is effectively a network that learns to score the loss during training.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是通常的损失函数，我们应用一个分类卷积神经网络来将图像映射到真实图像的概率，即，我们的损失函数实际上是一个在学习过程中学习评分损失的神经网络。
- en: We have 2 neural networks in our GAN,
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在GAN中有2个神经网络，
- en: '**generator** - flipped convolutional neural network that makes random fake
    images'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器** - 翻转卷积神经网络，生成随机的假图像'
- en: '**discriminator** - classification convolutional neural netwrok that calculates
    the probability that an image is real'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器** - 计算图像是否为真实的分类卷积神经网络'
- en: '![](../Images/464dd59ea97be3602e14c9ece74a40a6.png)'
  id: totrans-468
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/464dd59ea97be3602e14c9ece74a40a6.png)'
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 一个卷积神经网络翻转，并将卷积替换为转置卷积，从1D随机潜在向量到随机图像。
- en: Indirect, Adversarial Learning
  id: totrans-470
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 间接，对抗学习
- en: How do we train these two coupled networks? We call each network an agent and
    we train them competively, e.g., they compete while learning!
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何训练这两个耦合的网络？我们将每个网络称为一个代理，并且以竞争的方式训练它们，例如，它们在学习时相互竞争！
- en: agent 1, Generator, is not trained to minimize an loss function with respect
    to training data (training image), no MSE!
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理1，生成器，没有被训练来最小化与训练数据（训练图像）相关的损失函数（MSE！）
- en: instead the agent 1, Generator, is trained to fool agent 2, Discriminator
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而代理1，生成器，被训练来欺骗代理2，判别器
- en: agent 2, Discriminator, is learning at the same time to tell the difference
    between the real training images and the fakes from agent 1, generator
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理2，判别器，同时学习区分真实训练图像和代理1，生成器产生的假图像
- en: Each agent has their own competitive goals,
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理都有自己的竞争目标，
- en: Generator – make fakes that Discriminator classifies as real
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器 – 制作判别器分类为真实的假图像
- en: Discriminator – correctly classify fake and real images
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器 – 正确分类假图像和真实图像
- en: Note, the generator never sees the real images, but by learning to fool the
    discriminator learns to make images like the real training images.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，生成器从未见过真实图像，但通过学习欺骗判别器，学会了制作类似于真实训练图像的图像。
- en: The GAN loss function is stated as,
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: GAN损失函数表述为，
- en: \[ \min_{\theta_G} \, \max_{\theta_D} \; \mathbb{E}_{\mathbf{y} \sim p_{\text{data}}}
    \left[ \log D_{\theta_D}(\mathbf{y}) \right] + \mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}}
    \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
    \]
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\theta_G} \, \max_{\theta_D} \; \mathbb{E}_{\mathbf{y} \sim p_{\text{data}}}
    \left[ \log D_{\theta_D}(\mathbf{y}) \right] + \mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}}
    \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
    \]
- en: where,
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\theta_D\) - parameters (weights, biases) of the **discriminator**
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\theta_D\) - 判别器的参数（权重，偏差）
- en: \(\theta_G\) - parameters of the **generator**
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\theta_G\) - 生成器的参数
- en: \(D_{\theta_D}(\cdot)\) - discriminator output, given the discriminator parameters
    \(\theta_D\) (probability input is real)
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(D_{\theta_D}(\cdot)\) - 判别器输出，给定判别器参数 \(\theta_D\)（概率输入是真实的）
- en: \(G_{\theta_G}(\mathbf{x})\) - output of the Generator output given latent input
    \(\mathbf{x}\)
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(G_{\theta_G}(\mathbf{x})\) - 生成器输出，给定潜在输入 \(\mathbf{x}\)
- en: \(\mathbf{y} \sim p_{\text{data}}\) - training images from the **real image
    set**
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbf{y} \sim p_{\text{data}}\) - 来自真实图像集的训练图像
- en: \(\mathbf{x} \sim p_{\mathbf{x}}\) - latent input sampled from known prior (e.g.
    uniform or normal)
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbf{x} \sim p_{\mathbf{x}}\) - 从已知先验（例如均匀分布或正态分布）采样的潜在输入
- en: \(\mathbb{E}[\cdot]\) - expectation over data (i.e., average over all samples)
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{E}[\cdot]\) - 对数据的期望（即，对所有样本的平均）
- en: \(\log D(\cdot)\) - log-likelihood that the discriminator assigns input as real
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\log D(\cdot)\) - 判别器分配给输入的似然为真实的对数
- en: \(\log(1 - D(G(\cdot)))\) - log-likelihood that discriminator assigns fake to
    generator’s output
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\log(1 - D(G(\cdot)))\) - 判别器将假图像分配给生成器输出的似然为真实的对数
- en: The discriminator wants to **maximize**,
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器想要**最大化**，
- en: \[ \log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x}))) \]
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x}))) \]
- en: tries to **correctly predicts real** training images as real, \(\log D(\mathbf{y})
    \rightarrow 0.0\)
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**正确预测**真实训练图像为真实，\(\log D(\mathbf{y}) \rightarrow 0.0\)
- en: and to **correctly predicts generated** fake training images as not real, \(\log(1
    - D(G(\mathbf{x}))) \rightarrow 0.0\)
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并且正确预测生成的假训练图像为非真实，\(\log(1 - D(G(\mathbf{x}))) \rightarrow 0.0\)
- en: The generator want to **minimize**,
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器想要**最小化**，
- en: \[ \log(1 - D(G(\mathbf{x}))) \]
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log(1 - D(G(\mathbf{x}))) \]
- en: tries to **fool the discriminator**, discriminator classifies fake training
    images as real, \(\log(1 - D(G(\mathbf{x}))) \rightarrow -\infty\)
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**欺骗判别器**，判别器将伪造训练图像分类为真实，\(\log(1 - D(G(\mathbf{x}))) \rightarrow -\infty\)
- en: To assist with understanding the GAN loss function and the system of competing
    agents, consider these end members,
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助理解 GAN 损失函数和竞争代理系统，考虑这些极端情况，
- en: '**Perfect Discriminator** - if the discriminator is perfect,'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完美判别器** - 如果判别器是完美的，'
- en: all real training images are classified as real, \(D(\mathbf{y}) = 1\)
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有真实训练图像都被分类为真实，\(D(\mathbf{y}) = 1\)
- en: all fake images from the generator are classified as real, \(D(G(\mathbf{x}))
    = 0\)
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有来自生成器的伪造图像都被分类为真实，\(D(G(\mathbf{x})) = 0\)
- en: \(\quad\) then the discriminator loss is,
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 然后，判别器的损失是，
- en: \[ \log(1) + \log(1 - 0) = 0 + \log(1) = 0 \]
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log(1) + \log(1 - 0) = 0 + \log(1) = 0 \]
- en: \(\quad\) this sounds like good news, i.e., the generator will then improve
    to catch up with the discriminator, but what actually happens is,
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 这听起来是个好消息，即生成器将随后提高以赶上判别器，但实际上发生的是，
- en: generator receives **no loss gradients**, because the generators gradients,
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器接收**没有损失梯度**，因为生成器的梯度，
- en: \[ \frac{\partial \log(1 - D(G(z)))}{\partial \theta_G} \]
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \log(1 - D(G(z)))}{\partial \theta_G} \]
- en: \(\quad\) if \(D(G(z)) \to 0\), this derivative becomes **zero**, so training
    stalls and **the generator doesn’t learn**,
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 如果 \(D(G(z)) \to 0\)，这个导数变为**零**，因此训练停滞，**生成器没有学习**，
- en: this is practically solved by substituting **non-saturating generator loss**
    for the generator,
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这实际上是通过用**非饱和生成器损失**替换生成器来解决的，
- en: \[ L_G = -\mathbb{E}_{z \sim p_z}[\log D(G(z))] \]
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L_G = -\mathbb{E}_{z \sim p_z}[\log D(G(z))] \]
- en: \(\quad\) if \(D(G(z)) \to 0\), then \(\log D(G(z)) \to -\infty\), so the gradient
    becomes **large**, giving the generator a strong learning signal.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 如果 \(D(G(z)) \to 0\)，则 \(\log D(G(z)) \to -\infty\)，因此梯度变得**很大**，给生成器一个强烈的信号。
- en: '**Perfect Generator** - if the generator is perfect,'
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**完美生成器** - 如果生成器是完美的，'
- en: all fake images have the same distribution as the real training images, \(G(\mathbf{x})
    \sim p_{\text{data}}\)
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有伪造的图像与真实训练图像具有相同的分布，\(G(\mathbf{x}) \sim p_{\text{data}}\)
- en: the best the discriminator can do is to assign a anive classification, \(D(\cdot)
    = 0.5\), for all fake and real training images
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器能做的最好的事情是分配一个**平均分类**，\(D(\cdot) = 0.5\)，对所有伪造和真实训练图像
- en: \(\quad\) then the loss is,
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 然后，损失是，
- en: \[ \log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4 \]
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4 \]
- en: discriminator is **maximally confused**
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器处于**最大困惑**状态
- en: this is a **Nash equilibrium** for the GAN, because no player can improve their
    outcome by unilaterally changing their strategy, assuming the other player’s strategy
    stays the same, generator is already making perfect images and discriminator can
    only guess naively, 50/50 real and fake.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是对 GAN 的**纳什均衡**，因为没有任何玩家可以通过单方面改变策略来改善他们的结果，假设其他玩家的策略保持不变，生成器已经制作出完美的图像，判别器只能天真地猜测，50/50
    真实和伪造。
- en: Import Required Packages
  id: totrans-518
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入所需的包
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一些标准包。这些应该已经与 Anaconda 3 一起安装。
- en: recall our goal is to build a convolutional neural network by-hand with only
    basic math and array operations, so we only need NumPy along with matplotlib for
    plotting.
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想我们的目标是手动构建卷积神经网络，只使用基本的数学和数组运算，所以我们只需要 NumPy 以及 matplotlib 进行绘图。
- en: '[PRE19]'
  id: totrans-521
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing ‘python -m pip install [package-name]’. More assistance is available
    with the respective package docs.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遇到包导入错误，您可能必须首先安装这些包中的一些。这通常可以通过在 Windows 上打开命令窗口然后输入‘python -m pip install
    [package-name]’来完成。更多帮助可以在相应包的文档中找到。
- en: Declare Functions
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声明函数
- en: Here’s the functions to make, train and visualize our generative adversarial
    network, including the steps,
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是制作、训练和可视化我们的生成对抗网络的函数，包括步骤，
- en: make a simple set of synthetic data
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作一组简单的合成数据
- en: initialize the weights in our generator and discriminator
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化生成器和判别器中的权重
- en: apply our generator and discrimintor
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用我们的生成器和判别器
- en: calculate the error derivative and update the generator and discriminator weights
    and biases
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算误差导数并更新生成器和判别器的权重和偏差
- en: Here’s a list of the functions,
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个函数列表，
- en: '**generate_real_data** - synthetic data generator'
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**generate_real_data** - 生成合成数据'
- en: '**initialize_generator_weights** - assign small random weights and bias for
    generator'
  id: totrans-531
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**initialize_generator_weights** - 为生成器分配小的随机权重和偏差'
- en: '**initialize_discriminator_weights** - assign small random weights and bias
    for discriminator'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**initialize_discriminator_weights** - 为判别器分配小的随机权重和偏差'
- en: '**generator_forward** - calculate a set of fake data with the generator given
    a set of latent values and the current weights and biases'
  id: totrans-533
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**generator_forward** - 根据一组潜在值和当前的权重和偏差，使用生成器计算一组伪造数据'
- en: '**discriminator_forward** - calculate the probability of a real image over
    a set of images and return a 1D ndarray of probabilities'
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**discriminator_forward** - 计算一组图像中真实图像的概率，并返回一个包含概率的1D ndarray'
- en: '**sigmoid** - activation function to apply in the generator and discriminator'
  id: totrans-535
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**sigmoid** - 在生成器和判别器中应用的激活函数'
- en: '**generator_gradients** - compute generator gradients averaged over the batch'
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**generator_gradients** - 计算批次的生成器梯度'
- en: '**discriminator_gradients** - compute generator gradients averaged over the
    batch'
  id: totrans-537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**discriminator_gradients** - 计算批次的生成器梯度'
- en: Here are the functions.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这些函数。
- en: '[PRE20]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Set the Working Directory
  id: totrans-540
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置工作目录
- en: I always like to do this so I don’t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是喜欢这样做，这样我就不会丢失文件，并且简化后续的读取和写入（避免每次都包含完整地址）。
- en: '[PRE21]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Visualize the Generative Adversarial Network
  id: totrans-543
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化生成对抗网络
- en: We are implementing a minimal Generative Adversarial Network (GAN) with the
    2 agents,
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在实现一个最小化的生成对抗网络（GAN），包含2个智能体，
- en: '**Generator** - that produces 3-node outputs (like tiny 1D images) from a single
    latent input'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Generator** - 从单个潜在输入产生3节点输出（如微小的1D图像）'
- en: '**Discriminator** - that evaluates these outputs to distinguish between **real**
    and **fake** samples.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Discriminator** - 评估这些输出以区分**真实**和**伪造**样本。'
- en: Now let’s define the parts of the **Generator**,
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义**生成器**的部分，
- en: '**Latent Node** - \(L_1\), a single random value with uniform distribution,
    \(U[0.4,1.0]\). Note we set the minimum as 0.4 to stay away from 0.0 or negative
    values as these would remove the slope or flip the slope of the fakes.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Latent Node** - \(L_1\)，一个具有均匀分布的单个随机值，\(U[0.4,1.0]\)。注意我们设置最小值为0.4，以避免0.0或负值，因为这些值会移除斜率或翻转伪造的斜率。'
- en: '**Generator Weights** - \(\lambda_{1,2}\), \(\lambda_{1,3}\) and \(\lambda_{1,4}\)
    for the connections from latent to each of the output nodes. This is the simplest
    possible tranpose convolution, with a kernel size is 3, output nodes is 3 and
    latent node is 1, so the kernel does not translate. I did this to greatly simplify
    the book keeping, but the concepts could be extended to a more realistic convolution
    / tranpose convolution architectures for more realistic images sizes problem.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Generator Weights** - \(\lambda_{1,2}\), \(\lambda_{1,3}\) 和 \(\lambda_{1,4}\)
    用于从潜在节点到每个输出节点的连接。这是最简单的转置卷积，内核大小为3，输出节点为3，潜在节点为1，因此内核不进行平移。我这样做是为了极大地简化账目记录，但概念可以扩展到更现实的卷积/转置卷积架构，以解决更现实的图像尺寸问题。'
- en: '**Generator Bias** - \(b\), a single, constant bias over the output layer (output
    image), the nodes, \(O_2\), \(O_3\), and \(O_4\)'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Generator Bias** - \(b\)，输出层（输出图像）上的单个、常数偏差，节点，\(O_2\), \(O_3\), 和 \(O_4\)'
- en: '**Generator Output Nodes** - \(O_2\), \(O_3\), and \(O_4\), the single and
    last feature map in our very simple generator; therefore, the output a 1D image
    with 3 nodes or pixels that are passed to the **Discriminator** input nodes, \(I_5\),
    \(I_6\), and \(I_7\)'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Generator Output Nodes** - \(O_2\), \(O_3\), 和 \(O_4\)，我们非常简单的生成器中的单个和最后一个特征图；因此，输出一个包含3个节点或像素的1D图像，这些节点或像素传递到**判别器**输入节点，\(I_5\),
    \(I_6\), 和 \(I_7\)'
- en: '**Discriminator Input Nodes** - \(I_5\), \(I_6\), and \(I_7\), that receive
    the real images or the fake images from the generator output nodes, \(O_2\), \(O_3\),
    \(O_4\)'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Discriminator Input Nodes** - \(I_5\), \(I_6\), 和 \(I_7\)，接收来自生成器输出节点，\(O_2\),
    \(O_3\), 和 \(O_4\)的真实图像或伪造图像'
- en: '**Discriminator Weights** - \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\)
    for the connections from input nodes (input image) to the output (descision) node,
    \(D_8\)'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Discriminator Weights** - \(\lambda_{5,8}\), \(\lambda_{6,8}\), 和 \(\lambda_{7,8}\)
    用于从输入节点（输入图像）到输出（决策）节点，\(D_8\)的连接'
- en: '**Discriminator Bias** - \(c\), bias applied at the output (descision) node,
    \(D_8\)'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Discriminator Bias** - \(c\)，在输出（决策）节点，\(D_8\)上应用的偏差'
- en: Now let’s visualize this very simple generative adversarial network.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们可视化这个非常简单的生成对抗网络。
- en: '[PRE22]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![_images/565edb7221aa6743a530bb98f80b562615b08280d5d3d4a52aee7ff15cefcaf2.png](../Images/cdcce92e4f0534109850166492b3b2ef.png)'
  id: totrans-557
  prefs: []
  type: TYPE_IMG
  zh: '![_images/565edb7221aa6743a530bb98f80b562615b08280d5d3d4a52aee7ff15cefcaf2.png](../Images/cdcce92e4f0534109850166492b3b2ef.png)'
- en: Just a couple more comments about my network nomenclature. My goal is to maximize
    simplicity and clarity,
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我的网络命名约定，我追求的是最大程度的简洁和清晰，
- en: Comments on Network Nomenclature
  id: totrans-559
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于网络命名的注释
- en: '**Network Nodes and Connections** - I choose to use unique numbers for all
    nodes, \(L_1\), \(O_2\), \(O_3\), \(\ldots\) instead of \(L_1\), \(O_1\), \(O_2\),
    \(\ldots\) to simplify the notation for the weights; therefore, when I say \(\lambda_{5,8}\)
    you know exactly where this weight is applied in the network.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络节点和连接** - 我选择为所有节点使用唯一的数字，\(L_1\)、\(O_2\)、\(O_3\)、…… 而不是 \(L_1\)、\(O_1\)、\(O_2\)、……
    以简化权重的表示；因此，当我说 \(\lambda_{5,8}\) 时，你知道这个权重在网络的哪个位置被应用。'
- en: '**Node Outputs** - I use the node label to also describe the output from the
    node, for example \(O_2\) is a node in the generator’s output layer and also the
    signal or value output from that node.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点输出** - 我使用节点标签来描述节点输出的内容，例如 \(O_2\) 是发电机输出层中的一个节点，同时也是从该节点输出的信号或值。'
- en: '**Pre- and Post-activation** - at our nodes \(O_2\), \(O_3\), \(O_4\), and
    \(D_8\) we have the node input before activation and the node output after activation,
    I use the notation \(O_{2_{in}}\), \(O_{3_{in}}\), \(O_{4_{in}}\) and \(D_{8_{in}}\)
    for the pre-activation input and \(O_2\), \(O_3\), \(O_4\), and \(D_8\) for the
    post-activation node output. This is important because with back propagation we
    have to step through the nodes, going from post-activation to pre-activation.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前激活和后激活** - 在我们的节点 \(O_2\)、\(O_3\)、\(O_4\) 和 \(D_8\) 上，我们有激活前的节点输入和激活后的节点输出，我使用
    \(O_{2_{in}}\)、\(O_{3_{in}}\)、\(O_{4_{in}}\) 和 \(D_{8_{in}}\) 表示激活前的输入，\(O_2\)、\(O_3\)、\(O_4\)
    和 \(D_8\) 表示激活后的节点输出。这很重要，因为在反向传播中，我们必须逐步通过节点，从激活后的节点到激活前的节点。'
- en: '**Latent** - while publications often use \(z\) notation for the latent values,
    to be consistent with my notion above, I use \(L_1\) for the latent value, i.e.,
    the output from my latent node, \(L_1\).'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在** - 虽然出版物通常使用 \(z\) 符号表示潜在值，为了与上面的概念保持一致，我使用 \(L_1\) 表示潜在值，即我的潜在节点 \(L_1\)
    的输出。'
- en: Now let’s walk-through all the parts of our example GAN and show all the math.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐一介绍我们示例 GAN 的各个部分，并展示所有的数学公式。
- en: Sigmoid Activation
  id: totrans-565
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sigmoid 激活函数
- en: For reference, let’s visualize the sigmoid activation function,
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 为了参考，让我们可视化 sigmoid 激活函数，
- en: '**activation** - the non-linear transformation, this is the sigmoid activation'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活** - 非线性变换，这是 sigmoid 激活函数'
- en: \[ x_{out} = \sigma(x_{in}) = \dfrac{1}{1 + e^{-x_{in}}} \]
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: \[ x_{out} = \sigma(x_{in}) = \dfrac{1}{1 + e^{-x_{in}}} \]
- en: '**activation derrivative** - essential for back propogation'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活导数** - 对于反向传播至关重要'
- en: \[ \sigma'(x_{in}) = \sigma(x_{out})(1 - \sigma(x_{out})) \]
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma'(x_{in}) = \sigma(x_{out})(1 - \sigma(x_{out})) \]
- en: note, for convenience the derrivative of the sigmoid activation function with
    respect to the input is posed for the output.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了方便起见，sigmoid 激活函数关于输入的导数是以输出为基准给出的。
- en: as we back-propogate backwards over the activation function we can us the output
    to step back through the activated network node
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们反向传播激活函数时，我们可以使用输出逐步通过激活网络节点
- en: '[PRE23]'
  id: totrans-573
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![_images/f7323a3bf2b5671f3b7f629a5e2dd8966903903e490d8b510d1b437b922d20ad.png](../Images/6aef20df3b024801181a361544b98363.png)'
  id: totrans-574
  prefs: []
  type: TYPE_IMG
  zh: '![_images/f7323a3bf2b5671f3b7f629a5e2dd8966903903e490d8b510d1b437b922d20ad.png](../Images/6aef20df3b024801181a361544b98363.png)'
- en: Let’s make some observations about the sigmoid activation and its derrivative,
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对 sigmoid 激活函数及其导数进行一些观察，
- en: '**sigmoid outputs** - are bounded (0,1) approaching both limits asymptotically'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**sigmoid 输出** - 被限制在 (0,1) 范围内，并逐渐接近两个极限。'
- en: '**vanishing gradients** - as the'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度消失** - 随着'
- en: Generator Forward Pass
  id: totrans-578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器正向传播
- en: First, let’s walk through the generator to go from a latent value to a fake
    image. The generator takes a latent input,
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从潜在值到伪造图像的生成器过程进行概述。生成器接受一个潜在输入，
- en: \[ L_1 \sim \mathcal{U}(0.4, 1) \]
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L_1 \sim \mathcal{U}(0.4, 1) \]
- en: recall, our simple generator has only one layer \(L1\), with only 3 outputs,
    \(O_2\), \(O_3\), and \(O_4\), representing the fake image.
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，我们简单的生成器只有一个层 \(L1\)，只有 3 个输出，\(O_2\)、\(O_3\) 和 \(O_4\)，代表伪造的图像。
- en: Then latent value, \(L_1\), is passed through the transpose convolution kernel
    to the output,
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，潜在值 \(L_1\) 通过反转卷积核传递到输出，
- en: our transpose convolution kernel has a size of 3, the same size as our output,
    so we don’t see it translate it, resulting in greatly simplified book keeping!
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的反转卷积核大小为 3，与我们的输出大小相同，因此我们看不到它进行转换，从而大大简化了账目管理！
- en: the tranpose convolution kernel weights are \(\lambda_{1,2}\), \(\lambda_{1,3}\),
    and \(\lambda_{1,4}\)
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反转卷积核的权重是 \(\lambda_{1,2}\)、\(\lambda_{1,3}\) 和 \(\lambda_{1,4}\)
- en: We apply the sigmoid activation in each of the output nodes
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个输出节点应用 sigmoid 激活
- en: Each output is computed by applying a linear transformation followed by a **sigmoid**
    activation, \(\sigma\),
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 每个输出都是通过应用线性变换后跟一个 **sigmoid** 激活，\(\sigma\)，
- en: \[ O_2 = \sigma(\lambda_{1,2} \cdot z + b) \]\[ O_3 = \sigma(\lambda_{1,3} \cdot
    z + b) \]\[ O_4 = \sigma(\lambda_{1,4} \cdot z + b) \]
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: \[ O_2 = \sigma(\lambda_{1,2} \cdot z + b) \]\[ O_3 = \sigma(\lambda_{1,3} \cdot
    z + b) \]\[ O_4 = \sigma(\lambda_{1,4} \cdot z + b) \]
- en: where,
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: '**\(\lambda_{1,j}\)** - are the transpose convolution kernel weights'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**\(\lambda_{1,j}\)** - 是转置卷积核权重'
- en: '**\(b\)** - is the shared bias, single bias term for the output layer'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**\(b\)** - 是共享偏置，输出层的单个偏置项'
- en: We can also write the generator forward pass in matrix notation as,
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以用矩阵符号来表示生成器的正向传播，
- en: \[\begin{split} \begin{bmatrix} O_2 \\ O_3 \\ O_4 \end{bmatrix} = \sigma\left(
    \begin{bmatrix} \lambda_{1,2} \\ \lambda_{1,3} \\ \lambda_{1,4} \end{bmatrix}
    z + \begin{bmatrix} b \\ b \\ b \end{bmatrix} \right) \end{split}\]
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} O_2 \\ O_3 \\ O_4 \end{bmatrix} = \sigma\left(
    \begin{bmatrix} \lambda_{1,2} \\ \lambda_{1,3} \\ \lambda_{1,4} \end{bmatrix}
    z + \begin{bmatrix} b \\ b \\ b \end{bmatrix} \right) \end{split}\]
- en: where the sigmoid activation is applied element-wise.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 sigmoid 激活是逐元素应用的。
- en: Discriminator Forward Pass
  id: totrans-594
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器正向传播
- en: Now let’s walk-through the discriminator, going from an image, real or fake,
    to a probability of real. The discriminator receives the image, over 3 input nodes,
    \(I_5\), \(I_6\), and \(I_7\). In the case of a fake image,
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来逐步分析判别器，从图像（真实或假）到真实概率。判别器接收图像，通过3个输入节点，\(I_5\)，\(I_6\)，和 \(I_7\)。在假图像的情况下，
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    O_2 \\ O_3 \\ O_4 \end{bmatrix} \end{split}\]
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    O_2 \\ O_3 \\ O_4 \end{bmatrix} \end{split}\]
- en: and in the case of a real image,
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实图像的情况下，
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    I_5^{real} \\ I_6^{real} \\ I_7^{real} \end{bmatrix} \end{split}\]
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    I_5^{real} \\ I_6^{real} \\ I_7^{real} \end{bmatrix} \end{split}\]
- en: Since we have only 1 layer and the convolution kernel is 3 with an input of
    3 once again there is no translation!
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只有1层，卷积核是3，输入也是3，因此没有平移！
- en: we just take input image, \(I_5\), \(I_6\), and \(I_7\), and apply the convolutional
    kernel weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\), and
    add the bias term, \(c\),
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只取输入图像，\(I_5\)，\(I_6\)，和 \(I_7\)，并应用卷积核权重，\(\lambda_{5,8}\)，\(\lambda_{6,8}\)，和
    \(\lambda_{7,8}\)，并加上偏置项，\(c\)，
- en: \[ D_8 = \sigma\left( \lambda_{5,8} \cdot I_5 + \lambda_{6,8} \cdot I_6 + \lambda_{7,8}
    \cdot I_7 + c \right) \]
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: \[ D_8 = \sigma\left( \lambda_{5,8} \cdot I_5 + \lambda_{6,8} \cdot I_6 + \lambda_{7,8}
    \cdot I_7 + c \right) \]
- en: where,
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\lambda_{i,8}\) are the convolutional kernel weights to go from input image
    to next feature map, only 1 value, our output probability
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\lambda_{i,8}\) 是从输入图像到下一个特征图的卷积核权重，只有一个值，我们的输出概率
- en: \(c\) is the bias term
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(c\) 是偏置项
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid activation function
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) 是 sigmoid 激活函数
- en: \(D_8 \in [0, 1]\) represents the probability assigned by the discriminator
    that the input is **real** (i.e. not a fake from the generator).
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: \(D_8 \in [0, 1]\) 代表判别器分配给输入为 **真实**（即不是生成器生成的假图像）的概率。
- en: We can also write the discriminator forward pass in matrix notation as,
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以用矩阵符号来表示判别器的正向传播，
- en: \[\begin{split} D_8 = \sigma\left( \begin{bmatrix} \lambda_{5,8} & \lambda_{6,8}
    & \lambda_{7,8} \end{bmatrix} \cdot \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix}
    + c \right) \end{split}\]
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D_8 = \sigma\left( \begin{bmatrix} \lambda_{5,8} & \lambda_{6,8}
    & \lambda_{7,8} \end{bmatrix} \cdot \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix}
    + c \right) \end{split}\]
- en: where,
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\) are scalar weights
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\) 是标量权重
- en: \(I_5, I_6, I_7\) are the input values (i.e., outputs of the generator, \(O_2,
    O_3, O_4\))
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(I_5, I_6, I_7\) 是输入值（即生成器的输出，\(O_2, O_3, O_4\)）
- en: \(c\) is the bias term
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(c\) 是偏置项
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid function
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) 是 sigmoid 函数
- en: Discriminator Loss
  id: totrans-614
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器损失
- en: Binary cross-entropy is a loss function used for binary classification tasks
    where the output is a probability between 0 and 1, and the target label is either
    0 or 1.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 二元交叉熵损失函数用于二元分类任务，其中输出是0到1之间的概率，目标标签是0或1。
- en: '**Prediction** (model output) - \(\hat{y} \in (0, 1)\), the output of \(D_8\),
    the discriminator’s classification, probability that the image is real'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**（模型输出）- \(\hat{y} \in (0, 1)\)，\(D_8\) 的输出，判别器的分类，图像为真实的概率'
- en: \[ \hat{y} = D_8 \]
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = D_8 \]
- en: '**True label** (ground truth) - \(y \in \{0, 1\}\), 0 if the image is from
    the generator, fake, and 1 if the image is from the real training data'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真实标签**（地面实况）- \(y \in \{0, 1\}\)，如果图像来自生成器，则为假，如果图像来自真实训练数据，则为1'
- en: Now we can define the **binary cross-entropy loss** as,
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以定义**二元交叉熵损失**如下，
- en: \[ \mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1
    - y) \cdot \log(1 - \hat{y}) \right] \]
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1
    - y) \cdot \log(1 - \hat{y}) \right] \]
- en: now we can further specify,
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进一步具体化，
- en: \(\log(\hat{y})\) is the log-likelihood of the positive prediction
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\log(\hat{y})\) 是正预测的对数似然
- en: \(log(1 - \hat{y})\) is the log-likelihood of the negative prediction
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(log(1 - \hat{y})\) 是负预测的对数似然
- en: how does binary cross-entropy behave?
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 二元交叉熵是如何表现的？
- en: 'if \(y = 1\) (real image), then:'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 \(y = 1\)（真实图像），则：
- en: \[ \mathcal{L} = -\log(\hat{y}) \quad \text{(we want } \hat{y} \to 1) \]
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = -\log(\hat{y}) \quad \text{(我们希望 } \hat{y} \to 1) \]
- en: 'if \(y = 0\) (fake image from the generator), then:'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 \(y = 0\)（生成器的假图像），则：
- en: \[ \mathcal{L} = -\log(1 - \hat{y}) \quad \text{(we want } \hat{y} \to 0) \]
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = -\log(1 - \hat{y}) \quad \text{(我们希望 } \hat{y} \to 0) \]
- en: We can summarize as,
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以总结如下，
- en: the loss is **low** when the model’s prediction \(\hat{y}\) is **close to the
    true label**, low probability of real for a fake image and high probability of
    real for a real image
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当模型的预测 \(\hat{y}\) **接近真实标签**时，损失是**低**的，对于假图像的真实概率低，对于真实图像的真实概率高
- en: the loss becomes **very large** if the model is **confident and wrong**, due
    to the logarithm, i.e., very low probability or real for a real image and very
    high probability of real for a fake image
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型**自信且错误**，损失会变得**非常大**，由于对数，即对于真实图像非常低的概率或对于假图像非常高的概率
- en: the sigmoid activation ensures that the output, \(\hat{y}\) is a valid probability
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: sigmoid激活确保输出 \(\hat{y}\) 是一个有效的概率
- en: Discriminator Loss Derivative
  id: totrans-633
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器损失导数
- en: To perform backpropagation we need to calculate the loss derivative. Let’s do
    this for the input of the activation function as our output node, \(D_8\),
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行反向传播，我们需要计算损失导数。让我们以激活函数的输入作为我们的输出节点 \(D_8\) 来做这个计算，
- en: \[ \frac{d\mathcal{L}}{dz} \]
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} \]
- en: define \(z\) as the input for the sigmoid activation as output node, \(D_8\).
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义 \(z\) 为sigmoid激活作为输出节点 \(D_8\) 的输入。
- en: as you see we do this because it results in a very simple, efficient result.
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如你所见，我们这样做是因为它产生了一个非常简单、高效的结果。
- en: recall, the sigmoid function,
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想，sigmoid函数，
- en: \[ \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \]
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \]
- en: We will use the chain rule, so we only need to solve the parts,
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用链式法则，所以我们只需要解决部分，
- en: \[ \frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
    \]
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
    \]
- en: \(\frac{d\mathcal{L}}{d\hat{y}}\) - partial derivative of binary cross-entropy
    loss given the discriminator output \(\hat{y}\) (\(D_8\))
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\frac{d\mathcal{L}}{d\hat{y}}\) - 给定判别器输出 \(\hat{y}\) (\(D_8\)) 的二元交叉熵损失的偏导数
- en: \(\frac{d\hat{y}}{dz}\) - partial derivative of the discriminator output \(\hat{y}\)
    (\(D_8\)) given the sigmoid activation input
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\frac{d\hat{y}}{dz}\) - 给定sigmoid激活输入的判别器输出 \(\hat{y}\) (\(D_8\)) 的偏导数
- en: Now we can solve the first part, partial derivative of loss with respect to
    the discriminator output, \(\hat{y}\)
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以解决第一部分，损失相对于判别器输出 \(\hat{y}\) 的偏导数
- en: \[ \frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1
    - \hat{y}} \right) \]
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1
    - \hat{y}} \right) \]
- en: now we can solve the second part, the partial derivative of the discriminator
    output \(\hat{y}\) (\(D_8\)) given the sigmoid activation input, it is just the
    sigmoid derivative,
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以解决第二部分，给定sigmoid激活输入的判别器输出 \(\hat{y}\) (\(D_8\)) 的偏导数，它就是sigmoid的导数，
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]
- en: and we can combine these by the chain rule as,
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过链式法则将这些结合起来，
- en: \[ \frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}
    \right) \cdot \hat{y}(1 - \hat{y}) \]
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}
    \right) \cdot \hat{y}(1 - \hat{y}) \]
- en: We are almost there, we only need to simplify the result, first we distribute,
    \(\hat{y}(1 - \hat{y})\),
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了，我们只需要简化结果，首先我们分配 \(\hat{y}(1 - \hat{y})\)，
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
    \]
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
    \]
- en: and then simplify it further,
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 并进一步简化它，
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
    = -\left[ y - \hat{y} \right] = \hat{y} - y \]
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
    = -\left[ y - \hat{y} \right] = \hat{y} - y \]
- en: I said this would get simple! Our partial derivative of our loss with respect
    to the input to the output node sigmoid activation function, \(z\), is,
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 我说过这会变得简单！我们关于输出节点sigmoid激活函数输入 \(z\) 的损失函数的偏导数是，
- en: \[ \frac{d\mathcal{L}}{dz} = \hat{y} - y \]
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dz} = \hat{y} - y \]
- en: This result shows the gradient is just the **error** — the difference between
    predicted and true values.
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果表明梯度仅仅是**误差**——预测值和真实值之间的差异。
- en: Now we can make this simple interpretation,
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行这个简单的解释，
- en: if \(\hat{y} > y\), the model overestimates \(\rightarrow\) gradient is positive
    \(\rightarrow\) lower prediction by moving in the negative gradient
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 \(\hat{y} > y\)，模型高估了 \(\rightarrow\) 梯度是正的 \(\rightarrow\) 通过在负梯度方向上移动来降低预测
- en: if \(\hat{y} < y\), the model underestimates \(\rightarrow\) gradient is negative
    \(\rightarrow\) increase prediction by moving in the negative gradient
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 \(\hat{y} < y\)，模型低估了 \(\rightarrow\) 梯度是负的 \(\rightarrow\) 通过在负梯度方向上移动来增加预测
- en: I know that a title this section “Discriminator Loss Derivative”, but excuse
    me for performing just a little bit of backpropagation (to before sigmoid activation).
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这个标题是“判别器损失导数”，但请原谅我进行一点反向传播（到sigmoid激活之前）。
- en: next we carry on with back propagation to the discriminator weights and biases
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们继续对判别器权重和偏置进行反向传播
- en: Discriminator Back Propagation
  id: totrans-662
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判别器反向传播
- en: For compact notation, let’s use matrix notation and define the input to the
    \(D_8\) activation, \(z\), as,
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，让我们使用矩阵符号，并定义 \(D_8\) 激活函数的输入 \(z\) 为，
- en: \[ z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}}
    = \mathbf{x} \]
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}}
    = \mathbf{x} \]
- en: Now we can extend our use of the chain rule to,
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将链式法则的用法扩展到，
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}}
    = (\hat{y} - y) \cdot \mathbf{x} \]
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}}
    = (\hat{y} - y) \cdot \mathbf{x} \]
- en: So for each of our discriminator weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\),
    and \(\lambda_{7,8}\) we have,
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于我们的每个判别器权重 \(\lambda_{5,8}\)，\(\lambda_{6,8}\)，和 \(\lambda_{7,8}\)，我们有，
- en: \[ \frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5 \]\[ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    = (\hat{y} - y) \cdot I_6 \]\[ \frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y}
    - y) \cdot I_7 \]
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5 \]\[ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    = (\hat{y} - y) \cdot I_6 \]\[ \frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y}
    - y) \cdot I_7 \]
- en: and for the bias, \(c\), we calculate the next component for the chain rule
    as,
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 对于偏置 \(c\)，我们计算链式法则的下一个组成部分，
- en: \[ \frac{dz}{dc} = 1 \]
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dz}{dc} = 1 \]
- en: so we have,
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 因此我们有，
- en: \[ \frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y}
    - y) \cdot 1 = \hat{y} - y \]
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y}
    - y) \cdot 1 = \hat{y} - y \]
- en: The backpropagation for our very simple discriminator is quite simple, we can
    summarize for the weights,
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们非常简单的判别器，反向传播相当简单，我们可以总结权重，
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x} \]
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x} \]
- en: and for the bias,
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 对于偏置，
- en: \[ \frac{d\mathcal{L}}{dc} = \hat{y} - y \]
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}}{dc} = \hat{y} - y \]
- en: Let’s write these out for all of our discriminators parameters, $\( \begin{aligned}
    \frac{d\mathcal{L}}{d\lambda_{5,8}} &= (\hat{y} - y) \cdot I_5 \\ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    &= (\hat{y} - y) \cdot I_6 \\ \frac{d\mathcal{L}}{d\lambda_{7,8}} &= (\hat{y}
    - y) \cdot I_7 \\ \frac{d\mathcal{L}}{dc} &= \hat{y} - y \end{aligned} \)$
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些写出来，针对我们判别器参数的所有参数，\( \begin{aligned} \frac{d\mathcal{L}}{d\lambda_{5,8}}
    &= (\hat{y} - y) \cdot I_5 \\ \frac{d\mathcal{L}}{d\lambda_{6,8}} &= (\hat{y}
    - y) \cdot I_6 \\ \frac{d\mathcal{L}}{d\lambda_{7,8}} &= (\hat{y} - y) \cdot I_7
    \\ \frac{d\mathcal{L}}{dc} &= \hat{y} - y \end{aligned} \)$
- en: Generator Loss Derivative and Back Propagation Through the Discriminator
  id: totrans-678
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器损失导数和通过判别器的反向传播
- en: Recall that the goal of the generator is to make fake images the discriminator
    assigns as a high probability of a real image, i.e., to fool the discriminator
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，生成器的目标是生成假图像，使得判别器将其分配为具有高概率的真实图像，即欺骗判别器
- en: the generator produces a fake image,
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器生成一个假图像，
- en: \[ \tilde{\mathbf{x}} = G(z) \]
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \tilde{\mathbf{x}} = G(z) \]
- en: \(\quad\) where ( z ) is a latent vector (e.g., sampled from Uniform[0.4, 1]).
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 其中 \(z\) 是一个潜在向量（例如，从 Uniform[0.4, 1] 中采样）。
- en: 'the discriminator evaluates this fake sample and returns:'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器评估这个伪造样本并返回：
- en: \[ \hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1) \]
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1) \]
- en: Now we can calculate the binary cross-entropy for the generator as,
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算生成器的二元交叉熵，
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}_G = -\log(\hat{y}) \]
- en: where,
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: \(\hat{y} = D(G(z))\), the discriminator’s evaluation of the generator’s fake
    image, \(z\)
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{y} = D(G(z))\)，判别器对生成器伪造图像 \(z\) 的评估
- en: \(\hat{y}\) is the probability assigned by the discriminator to the fake being
    real
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{y}\) 是判别器分配给伪造图像为真实的概率
- en: This is equivalent to cross-entropy with **target label \(y = 1\)**, note here
    we do a trick, from the generator’s perspective it’s images are real, so we are
    using \(y=1\), i.e., real images for the fake images!
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当于具有**目标标签 \(y = 1\)** 的交叉熵，注意这里我们玩了一个小花招，从生成器的角度来看，它的图像是真实的，所以我们使用 \(y=1\)，即对于伪造图像使用真实图像！
- en: You may get confused if you look at the original GAN loss above, this is called
    the non-saturating generator loss.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看上面的原始 GAN 损失，这被称为非饱和生成器损失。
- en: '| Loss Type | Expression | Comment |'
  id: totrans-692
  prefs: []
  type: TYPE_TB
  zh: '| 损失类型 | 表达式 | 注释 |'
- en: '| --- | --- | --- |'
  id: totrans-693
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Original GAN** | \(\mathbb{E}[\log(1 - D(G(z)))]\) | Theoretical, can cause
    vanishing gradients |'
  id: totrans-694
  prefs: []
  type: TYPE_TB
  zh: '| **原始 GAN** | \(\mathbb{E}[\log(1 - D(G(z)))]\) | 理论，可能引起梯度消失 |'
- en: '| **Non-saturating** | \(-\mathbb{E}[\log(D(G(z)))]\) | Practical, stronger
    gradients, commonly used |'
  id: totrans-695
  prefs: []
  type: TYPE_TB
  zh: '| **非饱和** | \(-\mathbb{E}[\log(D(G(z)))]\) | 实用，更强的梯度，常用 |'
- en: so instead of minimizing the original generator loss we are maximizing the non-saturating
    generator loss.
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，我们不是最小化原始生成器损失，而是最大化非饱和生成器损失。
- en: Let’s show how to back propagate through the entire discriminator with the chain
    rule.
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们展示如何使用链式法则通过整个判别器反向传播。
- en: we want the generator loss gradient with respect generator output,
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要生成器损失相对于生成器输出的梯度，
- en: Given \(\tilde{\mathbf{x}} = G(z)\), our fake image, we want the partial derivative
    of the loss given our fake image,
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 给定 \(\tilde{\mathbf{x}} = G(z)\)，我们的伪造图像，我们想要给定伪造图像的损失的部分导数，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} \]
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} \]
- en: and by the chain rule,
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 根据链式法则，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}}
    \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}} \]
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}}
    \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}} \]
- en: This is how the discriminator’s belief \(\hat{y}\)​ about “fakeness” changes
    with changes in \(\tilde{\mathbf{x}}\) the fake image.
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是判别器对“伪造性”的信念 \(\hat{y}\) 随着伪造图像 \(\tilde{\mathbf{x}}\) 的变化而变化的方式。
- en: Now we are ready to back propagate the generator loss through the discriminator,
    let’s start with our generator loss (from above),
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备通过判别器反向传播生成器损失，让我们从上面的生成器损失开始，
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}_G = -\log(\hat{y}) \]
- en: and when we perform the partial derivative,
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行偏导数，
- en: \[ \frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}} \]
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}} \]
- en: Now, recall the discriminator’s forward pass is,
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回想一下判别器的正向传递是，
- en: \[ \hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c) \]
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c) \]
- en: so we can calculate the partial derivative of the discriminator’s output with
    respect to the generator’s fake image as,
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算判别器输出相对于生成器伪造图像的偏导数，
- en: \[ \frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
    \]
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
    \]
- en: now we combine these with the chain rule as,
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将这些与链式法则结合起来，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \left( -\frac{1}{\hat{y}} \right)
    \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right) = -(1 - \hat{y}) \cdot
    \mathbf{w} \]
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \left( -\frac{1}{\hat{y}} \right)
    \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right) = -(1 - \hat{y}) \cdot
    \mathbf{w} \]
- en: The gradient of the generator’s loss with respect to the output image \(\tilde{\mathbf{x}}\)
    is,
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器损失相对于输出图像 \(\tilde{\mathbf{x}}\) 的梯度是，
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
    \]
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
    \]
- en: We can add some interpretations of this result,
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对这个结果进行一些解释，
- en: when \(\hat{y}\) is close to 0 \(\rightarrow\) discriminator easily spots fake
    \(\rightarrow\) large gradient \(\rightarrow\) generator updates more.
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 \(\hat{y}\) 接近 0 \(\rightarrow\) 判别器容易识别出伪造 \(\rightarrow\) 大梯度 \(\rightarrow\)
    生成器更新更多。
- en: when \(\hat{y}\) is close to 1 \(\rightarrow\) generator is fooling the discriminator
    \(\rightarrow\) gradient is small.
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 \(\hat{y}\) 接近 1 \(\rightarrow\) 生成器欺骗判别器 \(\rightarrow\) 梯度很小。
- en: This guides the generator to tweak its output to increase \(\hat{y}\) — i.e.,
    fool the discriminator.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 这指导生成器调整其输出以增加 \(\hat{y}\) — 即，欺骗判别器。
- en: To further clarify, for our example let’s compute how the discriminator’s output
    \(\hat{y}\) changes with respect to the generator outputs \(O_5, O_6, O_7\), instead
    of the \(w\) vector notation used above.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步阐明，让我们以我们的例子来计算判别器的输出 \(\hat{y}\) 如何相对于生成器输出 \(O_5, O_6, O_7\) 发生变化，而不是上面使用的
    \(w\) 向量表示法。
- en: if we apply the chain rule we get,
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们应用链式法则，我们得到，
- en: \[ \frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i} \]
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i} \]
- en: \(\quad\) for each of the components we have,
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 对于每个组成部分，我们有，
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]\[ \frac{dz}{dO_5} = \lambda_{5,8}
    \]\[ \frac{dz}{dO_6} = \lambda_{6,8} \]\[ \frac{dz}{dO_7} = \lambda_{7,8} \]
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]\[ \frac{dz}{dO_5} = \lambda_{5,8}
    \]\[ \frac{dz}{dO_6} = \lambda_{6,8} \]\[ \frac{dz}{dO_7} = \lambda_{7,8} \]
- en: \(\quad\) substituting in the chain rule we have,
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 代入链式法则，我们有，
- en: \[ \frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8} \]\[ \frac{d\hat{y}}{dO_6}
    = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8} \]\[ \frac{d\hat{y}}{dO_7} = \hat{y}(1
    - \hat{y}) \cdot \lambda_{7,8} \]
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8} \]\[ \frac{d\hat{y}}{dO_6}
    = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8} \]\[ \frac{d\hat{y}}{dO_7} = \hat{y}(1
    - \hat{y}) \cdot \lambda_{7,8} \]
- en: Backpropagation Through Generator to Weights and Bias
  id: totrans-727
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过生成器反向传播到权重和偏差
- en: We now propagate through the generators sigmoid activation in each of the output
    nodes,
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们通过每个输出节点中的生成器的 sigmoid 激活函数传播，
- en: \[ \frac{dO_i}{dz_i} = O_i (1 - O_i) \]
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dO_i}{dz_i} = O_i (1 - O_i) \]
- en: \(O_i = \sigma(z_i)\), where \(z_i\) is the input for the output nodes, pre-activation,
    and \(O_i\) is output for the output nodes, post-activation
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(O_i = \sigma(z_i)\)，其中 \(z_i\) 是输出节点的输入，预激活，而 \(O_i\) 是输出节点的输出，后激活
- en: We Apply chain rule,
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用链式法则，
- en: \[ \frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
    = \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \]
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
    = \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \]
- en: Recall,
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 回想，
- en: \[ z_i = \lambda_{1,i} \cdot L_1 + b \]
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: \[ z_i = \lambda_{1,i} \cdot L_1 + b \]
- en: so we can calculate the generator’s weights partial derivatives as,
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算生成器权重的偏导数，
- en: \[ \frac{dz_i}{d\lambda_{1,i}} = L_1 \]
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dz_i}{d\lambda_{1,i}} = L_1 \]
- en: and the generator’s bias partial derivative as,
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 以及生成器偏差的偏导数是，
- en: \[ \frac{dz_i}{db} = 1 \]
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{dz_i}{db} = 1 \]
- en: Now we can put this all together with the chain rule, the partial derivatives
    of the generator loss with respect to the generator weights are,
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将所有这些与链式法则结合起来，生成器损失相对于生成器权重的偏导数是，
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,i}} = \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{d\lambda_{1,i}} = \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \cdot L_1 \]
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,i}} = \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{d\lambda_{1,i}} = \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \cdot L_1 \]
- en: and the partial derivative of the generator loss with respect to the generator
    bias is,
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 以及生成器损失相对于生成器偏差的偏导数是，
- en: \[ \frac{d\mathcal{L}_G}{db} = \sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{db} = \sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \]
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{db} = \sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{db} = \sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \]
- en: For clarity, let’s write this out for each of our generator’s weights,
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，让我们为我们的生成器权重中的每一个写出这个，
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,2}} = -(1 - \hat{y}) \cdot \lambda_{5,8}
    \cdot O_5 (1 - O_5) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,3}} = -(1
    - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,4}}
    = -(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1 \]
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,2}} = -(1 - \hat{y}) \cdot \lambda_{5,8}
    \cdot O_5 (1 - O_5) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,3}} = -(1
    - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,4}}
    = -(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1 \]
- en: and for our generator’s bias,
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 以及对于我们的生成器偏差，
- en: \[ \frac{d\mathcal{L}_G}{db} = -(1 - \hat{y}) \cdot \left[ \lambda_{5,8} \cdot
    O_5(1 - O_5) + \lambda_{6,8} \cdot O_6(1 - O_6) + \lambda_{7,8} \cdot O_7(1 -
    O_7) \right] \]
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d\mathcal{L}_G}{db} = -(1 - \hat{y}) \cdot \left[ \lambda_{5,8} \cdot
    O_5(1 - O_5) + \lambda_{6,8} \cdot O_6(1 - O_6) + \lambda_{7,8} \cdot O_7(1 -
    O_7) \right] \]
- en: Let’s make some interpretations,
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些解释，
- en: the generator’s weights and bias gradients scale with how much the discriminator
    is fooled (\(1 - \hat{y}\))
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器的权重和偏差梯度与判别器被欺骗的程度成正比（\(1 - \hat{y}\)）
- en: the generator learns to tweak \(\lambda_{1,i}\) and \(b\) to push the fake images,
    \(O_5\), \(O_6\) and \(O_7\) in directions that increase \(\hat{y}\)
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器学习调整 \(\lambda_{1,i}\) 和 \(b\)，以推动假图像 \(O_5\)、\(O_6\) 和 \(O_7\) 的方向，从而增加
    \(\hat{y}\)
- en: this flow of error gives the generator a signal to **fool the discriminator
    more effectively** without ever seeing a real image!
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种错误流为生成器提供了信号，使其能够**更有效地欺骗判别器**，而无需看到任何真实图像！
- en: Simple GAN Training Workflow
  id: totrans-751
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单 GAN 训练工作流程
- en: We start with initialization of the generator and discriminator weights and
    bias and setting the training hyperparameters.
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从初始化生成器和判别器的权重和偏差以及设置训练超参数开始。
- en: Generate the Synthethic, “Real Images” for training
  id: totrans-753
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成用于训练的合成“真实图像”
- en: sample \(N\) real 3-node, 1D images \(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采样 \(N\) 个真实 3 节点，1D 图像 \(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)
- en: 'use the synthetic training data function:'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用合成训练数据函数：
- en: \[ \text{Real images} \sim \text{linear decreasing trend} + \text{noise} \]
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Real images} \sim \text{linear decreasing trend} + \text{noise} \]
- en: '**Initialize generator weights and bias** - the weights,'
  id: totrans-757
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化生成器的权重和偏差** - 权重，'
- en: \[ \{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small
    random values} \]
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small
    random values} \]
- en: \(\quad\) and the bias,
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 以及偏差，
- en: \[ b \leftarrow 0.0 \]
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: \[ b \leftarrow 0.0 \]
- en: '**Initialize discriminator weights and bias** - the weights,'
  id: totrans-761
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化判别器的权重和偏差** - 权重，'
- en: \[ \{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small
    random values} \]
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small
    random values} \]
- en: \(\quad\) and the bias,
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: \(\quad\) 以及偏差，
- en: \[ c \leftarrow 0.0 \]
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: \[ c \leftarrow 0.0 \]
- en: '**Set model training hyperparameters** - this includes,'
  id: totrans-765
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置模型训练超参数** - 这包括，'
- en: Learning Rates - for the generator, \(\eta_G\), and discriminator, \(\eta_D\)
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率 - 对于生成器，\(\eta_G\)，和判别器，\(\eta_D\)
- en: Batch Size - in this example we are assuming batch size equal to the number
    of real images
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小 - 在这个例子中，我们假设批量大小等于真实图像的数量
- en: Epochs - number of training iterations
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮次 - 训练迭代的次数
- en: '**Train the discriminator**'
  id: totrans-769
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练判别器**'
- en: combine real and fake inputs into a batch of size \(2N\) and inlcude labels
    \(y_i = 1\) for real, \(y_i = 0\) for fake
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将真实和假输入合并为大小为 \(2N\) 的批量，并包括标签 \(y_i = 1\) 表示真实，\(y_i = 0\) 表示假
- en: compute discriminator outputs \(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算判别器的输出 \(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)
- en: 'calculate discriminator loss and gradients using:'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下方法计算判别器损失和梯度：
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial
    \mathcal{L}}{\partial c} \]
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial
    \mathcal{L}}{\partial c} \]
- en: 'update discriminator weights and bias:'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新判别器的权重和偏差：
- en: \[ \lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    \lambda_{j,8}}, \quad c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    c} \]
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    \lambda_{j,8}}, \quad c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    c} \]
- en: '**Train the generator**'
  id: totrans-776
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练生成器**'
- en: Compute generator output fake images and pass to the discriminator to evaluate
    the outputs on these fakes, \(D_8\) same as \(y\)
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算生成器的输出假图像并将其传递给判别器以评估这些假图像的输出，\(D_8\) 与 \(y\) 相同
- en: Calculate generator loss gradients using,
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下方法计算生成器损失梯度，
- en: \[ \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial
    \mathcal{L}_G}{\partial b} \]
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial
    \mathcal{L}_G}{\partial b} \]
- en: Update generator weights and bias,
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新生成器的权重和偏差，
- en: \[ \lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    \lambda_{1,j}}, \quad b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    b} \]
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    \lambda_{1,j}}, \quad b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    b} \]
- en: '**Repeat Until Convergence** - or stop criteria is met, such as maximum number
    of training epochs, return to step 5.'
  id: totrans-782
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重复直到收敛** - 或者满足停止条件，例如最大训练轮数，返回步骤5。'
- en: Here a summary of the training loop,
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是训练循环的摘要，
- en: Generate real data batch
  id: totrans-784
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成真实数据批量
- en: Generate fake data batch
  id: totrans-785
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成假数据批量
- en: Update discriminator to better distinguish real/fake
  id: totrans-786
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新判别器以更好地区分真实/假
- en: Update generator to fool discriminator
  id: totrans-787
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新生成器以欺骗判别器
- en: Repeat
  id: totrans-788
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复
- en: This adversarial training loop lets the generator learn to create data mimicking
    the real distribution, and the discriminator improve in spotting fakes.
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对抗性训练循环让生成器学会创建模仿真实分布的数据，并让判别器在识别假图像方面得到提升。
- en: '[PRE24]'
  id: totrans-790
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-791
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-792
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-793
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-794
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-795
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-796
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-797
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-798
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-799
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-800
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-801
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![_images/0e5b9d59df3b7c13cf96ada6a8409c005cf108794aa5c6d5da5188ad5ef20ded.png](../Images/686c89ab95fc15d0556a9ed4d7f3bed6.png)'
  id: totrans-802
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/686c89ab95fc15d0556a9ed4d7f3bed6.png)'
- en: Visualize Real Images and Trained Generator Fake Images
  id: totrans-803
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化真实图像和训练后的生成器假图像
- en: Let’s check a set of fake images from our trained generator against the real
    images.
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下从我们的训练生成器中生成的一组假图像与真实图像的对比。
- en: recall the generator never saw these images, the discriminator saw the real
    and fake images and told the generator how good or bad were the generator’s fake
    images.
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回想一下，生成器从未见过这些图像，判别器看到了真实和假图像，并告诉生成器生成器的假图像有多好或有多坏。
- en: '[PRE36]'
  id: totrans-806
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![_images/765558367eae336a177e7a0b9b0a86037b878b20114ad05070fc072fd5f13404.png](../Images/5e411f7e4a786c08b02c80dadc431416.png)'
  id: totrans-807
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5e411f7e4a786c08b02c80dadc431416.png)'
- en: Visualize Real Images and Generator Fake Images Over Training Epochs
  id: totrans-808
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化训练周期内的真实图像和生成器假图像
- en: It is interesting to see how our generator’s fake images evolve over the training
    epochs.
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 看看我们的生成器假图像在训练周期中的演变过程，这很有趣。
- en: as first the fake images are random due to the random initialization of the
    generator’s weights and bias
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于生成器权重的随机初始化和偏差的随机初始化，最初的假图像是随机的
- en: as the training proceeds the generator learns to improve the fake images.
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着训练的进行，生成器学会改进生成的假图像。
- en: I include the real images at the end for comparison.
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: 我在最后包括了真实图像以供比较。
- en: '[PRE37]'
  id: totrans-813
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![_images/c9fb21bf43af473100eacd88fe058bc353b01c81bec63e5cf3719df9229a386d.png](../Images/ad9bdf6d9a437102f9bba86e2f345ae0.png)'
  id: totrans-814
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ad9bdf6d9a437102f9bba86e2f345ae0.png)'
- en: Comments
  id: totrans-815
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评论
- en: This was a basic treatment of generative adversarial networks. Much more could
    be done and discussed, I have many more resources. Check out my [shared resource
    inventory](https://michaelpyrcz.com/my-resources) and the YouTube lecture links
    at the start of this chapter with resource links in the videos’ descriptions.
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对生成对抗网络的基本处理。可以做和讨论的还有很多，我有很多更多的资源。查看我的[共享资源清单](https://michaelpyrcz.com/my-resources)以及本章开头带有资源链接的YouTube讲座链接。
- en: I hope this is helpful,
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这有所帮助，
- en: '*Michael*'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: '*迈克尔*'
- en: About the Author
  id: totrans-819
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于作者
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  id: totrans-820
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·皮尔茨教授在德克萨斯大学奥斯汀分校40英亩校园的办公室。
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·皮尔茨是德克萨斯大学奥斯汀分校[科克雷尔工程学院](https://cockrell.utexas.edu/faculty-directory/alphabetical/p)和[杰克逊地球科学学院](https://www.jsg.utexas.edu/researcher/michael_pyrcz/)的教授，他在那里研究教学地下、空间数据分析、地统计学和机器学习。迈克尔还是，
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[能源分析](https://fri.cns.utexas.edu/energy-analytics)新生研究项目的首席研究员，以及德克萨斯大学奥斯汀分校自然科学院机器学习实验室的核心教员'
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机与地球科学](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board)的副编辑，以及国际数学地球科学协会[数学地球科学](https://link.springer.com/journal/11004/editorial-board)的董事会成员。'
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: '迈克尔已经撰写了70多篇[同行评审的出版物](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en)，一个用于空间数据分析的[Python包](https://pypi.org/project/geostatspy/)，合著了一本关于空间数据分析的教科书《地球统计学储层建模》（[Geostatistical
    Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)），并是两本新发布的电子书的作者，分别是《Python中应用地球统计学：GeostatsPy实践指南》（[Applied
    Geostatistics in Python: a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)）和《Python中应用机器学习：带代码的实践指南》（[Applied
    Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html)）。'
- en: All of Michael’s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michael’s work and shared educational resources visit his
    Website.
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔的所有大学讲座都可以在他的[YouTube频道](https://www.youtube.com/@GeostatsGuyLectures)上找到，其中包含100多个Python交互式仪表板和40多个GitHub账户上的详细工作流程，这些工作流程分布在40多个存储库中，旨在支持任何感兴趣的学生和在职专业人士，提供常青内容。想了解更多关于迈克尔的工作和共享教育资源，请访问他的网站。
- en: Want to Work Together?
  id: totrans-827
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 想一起工作吗？
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个内容对那些想了解更多关于地下建模、数据分析和机器学习的人有所帮助。学生和在职专业人士欢迎参加。
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? I’d be happy to drop by and work with you!
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想邀请我到贵公司进行培训、辅导、项目审查、工作流程设计和/或咨询吗？我很乐意拜访并与您合作！
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想要合作，支持我的研究生研究或我的地下数据分析与机器学习联盟（共同负责人是约翰·福斯特教授）吗？我的研究将数据分析、随机建模和机器学习理论与实践相结合，以开发新的方法和工作流程，增加价值。我们正在解决具有挑战性的地下问题！
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过[mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu)联系到我。
- en: I’m always happy to discuss,
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是很高兴讨论，
- en: '*Michael*'
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
  zh: '*迈克尔*'
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·皮尔茨，博士，工程师，德克萨斯大学奥斯汀分校Cockrell工程学院和Jackson地球科学学院教授
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 更多资源可在以下链接找到：[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [网站](http://michaelpyrcz.com) | [Google Scholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [地球统计学书籍](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Python中应用地球统计学电子书](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Python中应用机器学习电子书](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)
