- en: Generative Adversarial Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_GAN.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_GAN.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Michael J. Pyrcz, Professor, The University of Texas at Austin
  prefs: []
  type: TYPE_NORMAL
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter of e-book “Applied Machine Learning in Python: a Hands-on Guide with
    Code”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cite this e-Book as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pyrcz, M.J., 2024, *Applied Machine Learning in Python: A Hands-on Guide with
    Code* [e-book]. Zenodo. doi:10.5281/zenodo.15169138 [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflows in this book and more are available here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cite the MachineLearningDemos GitHub Repository as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pyrcz, M.J., 2024, *MachineLearningDemos: Python Machine Learning Demonstration
    Workflows Repository* (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312\.
    GitHub repository: [GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
  prefs: []
  type: TYPE_NORMAL
- en: By Michael J. Pyrcz
  prefs: []
  type: TYPE_NORMAL
- en: © Copyright 2024.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is a tutorial for / demonstration of **Generative Adversarial Networks**.
  prefs: []
  type: TYPE_NORMAL
- en: '**YouTube Lecture**: check out my lectures on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Artificial Neural Networks](https://youtu.be/A9PiCMY_6nM?si=NxWSU_5RgQ4w55EL)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convolutional Neural Networks](https://youtu.be/za2my_XDoOs?si=LeHU6p2_fc9dX4Yt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative Adversarial Networks (TBA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These lectures are all part of my [Machine Learning Course](https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&si=XonjO2wHdXffMpeI)
    on YouTube with linked well-documented Python workflows and interactive dashboards.
    My goal is to share accessible, actionable, and repeatable educational content.
    If you want to know about my motivation, check out [Michael’s Story](https://michaelpyrcz.com/my-story).
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if we put together machines? Working in a competitive, adversarial manner?
  prefs: []
  type: TYPE_NORMAL
- en: Could we make a more powerful machine learning model that learns its own loss
    function!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could we make images that don’t collapse to exact reproduction of the images
    in the training set?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative neural networks are very powerful, nature inspired computing deep
    learning method to make fake, but realistic, images by application of convolutional
    neural networks, an analogy of visual cortex that extend the ability of our artificial
    neural networks to better work with images.
  prefs: []
  type: TYPE_NORMAL
- en: Nature inspired computing is looking to nature for inspiration to develop novel
    problem-solving methods,
  prefs: []
  type: TYPE_NORMAL
- en: '**artificial neural networks** are inspired by biological neural networks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nodes** in our model are artificial neurons, simple processors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**connections** between nodes are artificial synapses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceptive fields** regularization to improve generalization and efficiency'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: intelligence emerges from many connected simple processors. For the remainder
    of this chapter, I will used the terms nodes and connections to describe our convolutional
    neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial and Convolutional Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have not, take this opportunity to review my previous chapters in the
    e-book on,
  prefs: []
  type: TYPE_NORMAL
- en: '[Artificial Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The **main takeaways** from my artificial neural network chapter are as follows,
  prefs: []
  type: TYPE_NORMAL
- en: '**architecture of a neural network**, including its fundamental components,
    nodes (neurons) and the weighted connections between them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**forward pass** computation through the network, where each node computes
    a weighted sum of its inputs (including a bias term), followed by the application
    of a nonlinear activation function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**computation of the error derivative**, which is then backpropagated through
    the network via the chain rule to determine the gradients of the loss function
    with respect to each weight and bias.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**aggregation of these gradients** across all samples in a training batch,
    typically by averaging, to update the model parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**iterative training process**, where the model is trained over multiple batches
    and epochs (passes over all the data) to continually refine the weights and biases
    until the model achieves an acceptable error rate on the test data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convolutional Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_CNN.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The main takeaways from my convolutional neural network chapter are as follows,
  prefs: []
  type: TYPE_NORMAL
- en: '**regularization** of image data with receptive fields to preserve spatial
    information and to avoid overfit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convolutional kernels** with learnable weights to extraction information
    from images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For both of these chapters, I have included links to my recorded lectures and
    to neural networks built from scratch with NumPy only!
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we start with a convolutional neural network and we flip it, i.e., reverse
    the order of the operations,
  prefs: []
  type: TYPE_NORMAL
- en: we have a machine that maps from a 1D vector of values, to an image, i.e., we
    can generate fake images by randomly assigning latent values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: to accomplish this instead of convolution operations with activation, we have
    transpose convolution operations with activation to move to the next feature map
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: recall we also perform non-linear activation at each feature map to prevent
    network collapse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/edf859adfdeba17f094dbc0415d2bb06.png)'
  prefs: []
  type: TYPE_IMG
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  prefs: []
  type: TYPE_NORMAL
- en: But how do we train this flipped convolutional neural network to make good images?
  prefs: []
  type: TYPE_NORMAL
- en: we could take training images and score the difference between our generated
    fake images, for example, with a pixel-wise squared error (L2 norm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: but if we did this, our machine learning model would only learn how to make
    this image or a limited set of training images and that would not be useful
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to make a diverse set of image realizations, that look and behave correctly.
    This is the simulation paradigm at the heart of geostatistics,
  prefs: []
  type: TYPE_NORMAL
- en: to learn more about the simulation paradigm from geostatistics, see my [Simulation
    Chapter](https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html)
    from my free, online e-book, [Applied Geostatistics in Python](https://geostatsguy.github.io/GeostatsPyDemos_Book).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of a typically loss function, we apply a classification convolutional
    neural network to map from the image to a probability of a real image, i.e., our
    loss function is effectively a network that learns to score the loss during training.
  prefs: []
  type: TYPE_NORMAL
- en: We have 2 neural networks in our GAN,
  prefs: []
  type: TYPE_NORMAL
- en: '**generator** - flipped convolutional neural network that makes random fake
    images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**discriminator** - classification convolutional neural netwrok that calculates
    the probability that an image is real'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/464dd59ea97be3602e14c9ece74a40a6.png)'
  prefs: []
  type: TYPE_IMG
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  prefs: []
  type: TYPE_NORMAL
- en: Indirect, Adversarial Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do we train these two coupled networks? We call each network an agent and
    we train them competively, e.g., they compete while learning!
  prefs: []
  type: TYPE_NORMAL
- en: agent 1, Generator, is not trained to minimize an loss function with respect
    to training data (training image), no MSE!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: instead the agent 1, Generator, is trained to fool agent 2, Discriminator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: agent 2, Discriminator, is learning at the same time to tell the difference
    between the real training images and the fakes from agent 1, generator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each agent has their own competitive goals,
  prefs: []
  type: TYPE_NORMAL
- en: Generator – make fakes that Discriminator classifies as real
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator – correctly classify fake and real images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note, the generator never sees the real images, but by learning to fool the
    discriminator learns to make images like the real training images.
  prefs: []
  type: TYPE_NORMAL
- en: The GAN loss function is stated as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min_{\theta_G} \, \max_{\theta_D} \; \mathbb{E}_{\mathbf{y} \sim p_{\text{data}}}
    \left[ \log D_{\theta_D}(\mathbf{y}) \right] + \mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}}
    \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\theta_D\) - parameters (weights, biases) of the **discriminator**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\theta_G\) - parameters of the **generator**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(D_{\theta_D}(\cdot)\) - discriminator output, given the discriminator parameters
    \(\theta_D\) (probability input is real)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(G_{\theta_G}(\mathbf{x})\) - output of the Generator output given latent input
    \(\mathbf{x}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\mathbf{y} \sim p_{\text{data}}\) - training images from the **real image
    set**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\mathbf{x} \sim p_{\mathbf{x}}\) - latent input sampled from known prior (e.g.
    uniform or normal)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\mathbb{E}[\cdot]\) - expectation over data (i.e., average over all samples)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\log D(\cdot)\) - log-likelihood that the discriminator assigns input as real
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\log(1 - D(G(\cdot)))\) - log-likelihood that discriminator assigns fake to
    generator’s output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator wants to **maximize**,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x}))) \]
  prefs: []
  type: TYPE_NORMAL
- en: tries to **correctly predicts real** training images as real, \(\log D(\mathbf{y})
    \rightarrow 0.0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and to **correctly predicts generated** fake training images as not real, \(\log(1
    - D(G(\mathbf{x}))) \rightarrow 0.0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generator want to **minimize**,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log(1 - D(G(\mathbf{x}))) \]
  prefs: []
  type: TYPE_NORMAL
- en: tries to **fool the discriminator**, discriminator classifies fake training
    images as real, \(\log(1 - D(G(\mathbf{x}))) \rightarrow -\infty\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To assist with understanding the GAN loss function and the system of competing
    agents, consider these end members,
  prefs: []
  type: TYPE_NORMAL
- en: '**Perfect Discriminator** - if the discriminator is perfect,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: all real training images are classified as real, \(D(\mathbf{y}) = 1\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: all fake images from the generator are classified as real, \(D(G(\mathbf{x}))
    = 0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\quad\) then the discriminator loss is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log(1) + \log(1 - 0) = 0 + \log(1) = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) this sounds like good news, i.e., the generator will then improve
    to catch up with the discriminator, but what actually happens is,
  prefs: []
  type: TYPE_NORMAL
- en: generator receives **no loss gradients**, because the generators gradients,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{\partial \log(1 - D(G(z)))}{\partial \theta_G} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) if \(D(G(z)) \to 0\), this derivative becomes **zero**, so training
    stalls and **the generator doesn’t learn**,
  prefs: []
  type: TYPE_NORMAL
- en: this is practically solved by substituting **non-saturating generator loss**
    for the generator,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ L_G = -\mathbb{E}_{z \sim p_z}[\log D(G(z))] \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) if \(D(G(z)) \to 0\), then \(\log D(G(z)) \to -\infty\), so the gradient
    becomes **large**, giving the generator a strong learning signal.
  prefs: []
  type: TYPE_NORMAL
- en: '**Perfect Generator** - if the generator is perfect,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: all fake images have the same distribution as the real training images, \(G(\mathbf{x})
    \sim p_{\text{data}}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the best the discriminator can do is to assign a anive classification, \(D(\cdot)
    = 0.5\), for all fake and real training images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\quad\) then the loss is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4 \]
  prefs: []
  type: TYPE_NORMAL
- en: discriminator is **maximally confused**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this is a **Nash equilibrium** for the GAN, because no player can improve their
    outcome by unilaterally changing their strategy, assuming the other player’s strategy
    stays the same, generator is already making perfect images and discriminator can
    only guess naively, 50/50 real and fake.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import Required Packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  prefs: []
  type: TYPE_NORMAL
- en: recall our goal is to build a convolutional neural network by-hand with only
    basic math and array operations, so we only need NumPy along with matplotlib for
    plotting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing ‘python -m pip install [package-name]’. More assistance is available
    with the respective package docs.
  prefs: []
  type: TYPE_NORMAL
- en: Declare Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here’s the functions to make, train and visualize our generative adversarial
    network, including the steps,
  prefs: []
  type: TYPE_NORMAL
- en: make a simple set of synthetic data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: initialize the weights in our generator and discriminator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: apply our generator and discrimintor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: calculate the error derivative and update the generator and discriminator weights
    and biases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here’s a list of the functions,
  prefs: []
  type: TYPE_NORMAL
- en: '**generate_real_data** - synthetic data generator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**initialize_generator_weights** - assign small random weights and bias for
    generator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**initialize_discriminator_weights** - assign small random weights and bias
    for discriminator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**generator_forward** - calculate a set of fake data with the generator given
    a set of latent values and the current weights and biases'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**discriminator_forward** - calculate the probability of a real image over
    a set of images and return a 1D ndarray of probabilities'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**sigmoid** - activation function to apply in the generator and discriminator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**generator_gradients** - compute generator gradients averaged over the batch'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**discriminator_gradients** - compute generator gradients averaged over the
    batch'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here are the functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Set the Working Directory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I always like to do this so I don’t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Visualize the Generative Adversarial Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are implementing a minimal Generative Adversarial Network (GAN) with the
    2 agents,
  prefs: []
  type: TYPE_NORMAL
- en: '**Generator** - that produces 3-node outputs (like tiny 1D images) from a single
    latent input'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator** - that evaluates these outputs to distinguish between **real**
    and **fake** samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s define the parts of the **Generator**,
  prefs: []
  type: TYPE_NORMAL
- en: '**Latent Node** - \(L_1\), a single random value with uniform distribution,
    \(U[0.4,1.0]\). Note we set the minimum as 0.4 to stay away from 0.0 or negative
    values as these would remove the slope or flip the slope of the fakes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generator Weights** - \(\lambda_{1,2}\), \(\lambda_{1,3}\) and \(\lambda_{1,4}\)
    for the connections from latent to each of the output nodes. This is the simplest
    possible tranpose convolution, with a kernel size is 3, output nodes is 3 and
    latent node is 1, so the kernel does not translate. I did this to greatly simplify
    the book keeping, but the concepts could be extended to a more realistic convolution
    / tranpose convolution architectures for more realistic images sizes problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generator Bias** - \(b\), a single, constant bias over the output layer (output
    image), the nodes, \(O_2\), \(O_3\), and \(O_4\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generator Output Nodes** - \(O_2\), \(O_3\), and \(O_4\), the single and
    last feature map in our very simple generator; therefore, the output a 1D image
    with 3 nodes or pixels that are passed to the **Discriminator** input nodes, \(I_5\),
    \(I_6\), and \(I_7\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator Input Nodes** - \(I_5\), \(I_6\), and \(I_7\), that receive
    the real images or the fake images from the generator output nodes, \(O_2\), \(O_3\),
    \(O_4\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator Weights** - \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\)
    for the connections from input nodes (input image) to the output (descision) node,
    \(D_8\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator Bias** - \(c\), bias applied at the output (descision) node,
    \(D_8\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s visualize this very simple generative adversarial network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/565edb7221aa6743a530bb98f80b562615b08280d5d3d4a52aee7ff15cefcaf2.png](../Images/cdcce92e4f0534109850166492b3b2ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Just a couple more comments about my network nomenclature. My goal is to maximize
    simplicity and clarity,
  prefs: []
  type: TYPE_NORMAL
- en: Comments on Network Nomenclature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Network Nodes and Connections** - I choose to use unique numbers for all
    nodes, \(L_1\), \(O_2\), \(O_3\), \(\ldots\) instead of \(L_1\), \(O_1\), \(O_2\),
    \(\ldots\) to simplify the notation for the weights; therefore, when I say \(\lambda_{5,8}\)
    you know exactly where this weight is applied in the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node Outputs** - I use the node label to also describe the output from the
    node, for example \(O_2\) is a node in the generator’s output layer and also the
    signal or value output from that node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre- and Post-activation** - at our nodes \(O_2\), \(O_3\), \(O_4\), and
    \(D_8\) we have the node input before activation and the node output after activation,
    I use the notation \(O_{2_{in}}\), \(O_{3_{in}}\), \(O_{4_{in}}\) and \(D_{8_{in}}\)
    for the pre-activation input and \(O_2\), \(O_3\), \(O_4\), and \(D_8\) for the
    post-activation node output. This is important because with back propagation we
    have to step through the nodes, going from post-activation to pre-activation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Latent** - while publications often use \(z\) notation for the latent values,
    to be consistent with my notion above, I use \(L_1\) for the latent value, i.e.,
    the output from my latent node, \(L_1\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s walk-through all the parts of our example GAN and show all the math.
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid Activation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For reference, let’s visualize the sigmoid activation function,
  prefs: []
  type: TYPE_NORMAL
- en: '**activation** - the non-linear transformation, this is the sigmoid activation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ x_{out} = \sigma(x_{in}) = \dfrac{1}{1 + e^{-x_{in}}} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**activation derrivative** - essential for back propogation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \sigma'(x_{in}) = \sigma(x_{out})(1 - \sigma(x_{out})) \]
  prefs: []
  type: TYPE_NORMAL
- en: note, for convenience the derrivative of the sigmoid activation function with
    respect to the input is posed for the output.
  prefs: []
  type: TYPE_NORMAL
- en: as we back-propogate backwards over the activation function we can us the output
    to step back through the activated network node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f7323a3bf2b5671f3b7f629a5e2dd8966903903e490d8b510d1b437b922d20ad.png](../Images/6aef20df3b024801181a361544b98363.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s make some observations about the sigmoid activation and its derrivative,
  prefs: []
  type: TYPE_NORMAL
- en: '**sigmoid outputs** - are bounded (0,1) approaching both limits asymptotically'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vanishing gradients** - as the'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generator Forward Pass
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s walk through the generator to go from a latent value to a fake
    image. The generator takes a latent input,
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_1 \sim \mathcal{U}(0.4, 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: recall, our simple generator has only one layer \(L1\), with only 3 outputs,
    \(O_2\), \(O_3\), and \(O_4\), representing the fake image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then latent value, \(L_1\), is passed through the transpose convolution kernel
    to the output,
  prefs: []
  type: TYPE_NORMAL
- en: our transpose convolution kernel has a size of 3, the same size as our output,
    so we don’t see it translate it, resulting in greatly simplified book keeping!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the tranpose convolution kernel weights are \(\lambda_{1,2}\), \(\lambda_{1,3}\),
    and \(\lambda_{1,4}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We apply the sigmoid activation in each of the output nodes
  prefs: []
  type: TYPE_NORMAL
- en: Each output is computed by applying a linear transformation followed by a **sigmoid**
    activation, \(\sigma\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ O_2 = \sigma(\lambda_{1,2} \cdot z + b) \]\[ O_3 = \sigma(\lambda_{1,3} \cdot
    z + b) \]\[ O_4 = \sigma(\lambda_{1,4} \cdot z + b) \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: '**\(\lambda_{1,j}\)** - are the transpose convolution kernel weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**\(b\)** - is the shared bias, single bias term for the output layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also write the generator forward pass in matrix notation as,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \begin{bmatrix} O_2 \\ O_3 \\ O_4 \end{bmatrix} = \sigma\left(
    \begin{bmatrix} \lambda_{1,2} \\ \lambda_{1,3} \\ \lambda_{1,4} \end{bmatrix}
    z + \begin{bmatrix} b \\ b \\ b \end{bmatrix} \right) \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where the sigmoid activation is applied element-wise.
  prefs: []
  type: TYPE_NORMAL
- en: Discriminator Forward Pass
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now let’s walk-through the discriminator, going from an image, real or fake,
    to a probability of real. The discriminator receives the image, over 3 input nodes,
    \(I_5\), \(I_6\), and \(I_7\). In the case of a fake image,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    O_2 \\ O_3 \\ O_4 \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: and in the case of a real image,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    I_5^{real} \\ I_6^{real} \\ I_7^{real} \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: Since we have only 1 layer and the convolution kernel is 3 with an input of
    3 once again there is no translation!
  prefs: []
  type: TYPE_NORMAL
- en: we just take input image, \(I_5\), \(I_6\), and \(I_7\), and apply the convolutional
    kernel weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\), and
    add the bias term, \(c\),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ D_8 = \sigma\left( \lambda_{5,8} \cdot I_5 + \lambda_{6,8} \cdot I_6 + \lambda_{7,8}
    \cdot I_7 + c \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\lambda_{i,8}\) are the convolutional kernel weights to go from input image
    to next feature map, only 1 value, our output probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(c\) is the bias term
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(D_8 \in [0, 1]\) represents the probability assigned by the discriminator
    that the input is **real** (i.e. not a fake from the generator).
  prefs: []
  type: TYPE_NORMAL
- en: We can also write the discriminator forward pass in matrix notation as,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} D_8 = \sigma\left( \begin{bmatrix} \lambda_{5,8} & \lambda_{6,8}
    & \lambda_{7,8} \end{bmatrix} \cdot \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix}
    + c \right) \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\) are scalar weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(I_5, I_6, I_7\) are the input values (i.e., outputs of the generator, \(O_2,
    O_3, O_4\))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(c\) is the bias term
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator Loss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Binary cross-entropy is a loss function used for binary classification tasks
    where the output is a probability between 0 and 1, and the target label is either
    0 or 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction** (model output) - \(\hat{y} \in (0, 1)\), the output of \(D_8\),
    the discriminator’s classification, probability that the image is real'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{y} = D_8 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**True label** (ground truth) - \(y \in \{0, 1\}\), 0 if the image is from
    the generator, fake, and 1 if the image is from the real training data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can define the **binary cross-entropy loss** as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1
    - y) \cdot \log(1 - \hat{y}) \right] \]
  prefs: []
  type: TYPE_NORMAL
- en: now we can further specify,
  prefs: []
  type: TYPE_NORMAL
- en: \(\log(\hat{y})\) is the log-likelihood of the positive prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(log(1 - \hat{y})\) is the log-likelihood of the negative prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how does binary cross-entropy behave?
  prefs: []
  type: TYPE_NORMAL
- en: 'if \(y = 1\) (real image), then:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \mathcal{L} = -\log(\hat{y}) \quad \text{(we want } \hat{y} \to 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'if \(y = 0\) (fake image from the generator), then:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \mathcal{L} = -\log(1 - \hat{y}) \quad \text{(we want } \hat{y} \to 0) \]
  prefs: []
  type: TYPE_NORMAL
- en: We can summarize as,
  prefs: []
  type: TYPE_NORMAL
- en: the loss is **low** when the model’s prediction \(\hat{y}\) is **close to the
    true label**, low probability of real for a fake image and high probability of
    real for a real image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the loss becomes **very large** if the model is **confident and wrong**, due
    to the logarithm, i.e., very low probability or real for a real image and very
    high probability of real for a fake image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the sigmoid activation ensures that the output, \(\hat{y}\) is a valid probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator Loss Derivative
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To perform backpropagation we need to calculate the loss derivative. Let’s do
    this for the input of the activation function as our output node, \(D_8\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} \]
  prefs: []
  type: TYPE_NORMAL
- en: define \(z\) as the input for the sigmoid activation as output node, \(D_8\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: as you see we do this because it results in a very simple, efficient result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: recall, the sigmoid function,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \]
  prefs: []
  type: TYPE_NORMAL
- en: We will use the chain rule, so we only need to solve the parts,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\frac{d\mathcal{L}}{d\hat{y}}\) - partial derivative of binary cross-entropy
    loss given the discriminator output \(\hat{y}\) (\(D_8\))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\frac{d\hat{y}}{dz}\) - partial derivative of the discriminator output \(\hat{y}\)
    (\(D_8\)) given the sigmoid activation input
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can solve the first part, partial derivative of loss with respect to
    the discriminator output, \(\hat{y}\)
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1
    - \hat{y}} \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: now we can solve the second part, the partial derivative of the discriminator
    output \(\hat{y}\) (\(D_8\)) given the sigmoid activation input, it is just the
    sigmoid derivative,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: and we can combine these by the chain rule as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}
    \right) \cdot \hat{y}(1 - \hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: We are almost there, we only need to simplify the result, first we distribute,
    \(\hat{y}(1 - \hat{y})\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
    \]
  prefs: []
  type: TYPE_NORMAL
- en: and then simplify it further,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
    = -\left[ y - \hat{y} \right] = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: I said this would get simple! Our partial derivative of our loss with respect
    to the input to the output node sigmoid activation function, \(z\), is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: This result shows the gradient is just the **error** — the difference between
    predicted and true values.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can make this simple interpretation,
  prefs: []
  type: TYPE_NORMAL
- en: if \(\hat{y} > y\), the model overestimates \(\rightarrow\) gradient is positive
    \(\rightarrow\) lower prediction by moving in the negative gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if \(\hat{y} < y\), the model underestimates \(\rightarrow\) gradient is negative
    \(\rightarrow\) increase prediction by moving in the negative gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I know that a title this section “Discriminator Loss Derivative”, but excuse
    me for performing just a little bit of backpropagation (to before sigmoid activation).
  prefs: []
  type: TYPE_NORMAL
- en: next we carry on with back propagation to the discriminator weights and biases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator Back Propagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For compact notation, let’s use matrix notation and define the input to the
    \(D_8\) activation, \(z\), as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}}
    = \mathbf{x} \]
  prefs: []
  type: TYPE_NORMAL
- en: Now we can extend our use of the chain rule to,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}}
    = (\hat{y} - y) \cdot \mathbf{x} \]
  prefs: []
  type: TYPE_NORMAL
- en: So for each of our discriminator weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\),
    and \(\lambda_{7,8}\) we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5 \]\[ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    = (\hat{y} - y) \cdot I_6 \]\[ \frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y}
    - y) \cdot I_7 \]
  prefs: []
  type: TYPE_NORMAL
- en: and for the bias, \(c\), we calculate the next component for the chain rule
    as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dz}{dc} = 1 \]
  prefs: []
  type: TYPE_NORMAL
- en: so we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y}
    - y) \cdot 1 = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: The backpropagation for our very simple discriminator is quite simple, we can
    summarize for the weights,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x} \]
  prefs: []
  type: TYPE_NORMAL
- en: and for the bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dc} = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: Let’s write these out for all of our discriminators parameters, $\( \begin{aligned}
    \frac{d\mathcal{L}}{d\lambda_{5,8}} &= (\hat{y} - y) \cdot I_5 \\ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    &= (\hat{y} - y) \cdot I_6 \\ \frac{d\mathcal{L}}{d\lambda_{7,8}} &= (\hat{y}
    - y) \cdot I_7 \\ \frac{d\mathcal{L}}{dc} &= \hat{y} - y \end{aligned} \)$
  prefs: []
  type: TYPE_NORMAL
- en: Generator Loss Derivative and Back Propagation Through the Discriminator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recall that the goal of the generator is to make fake images the discriminator
    assigns as a high probability of a real image, i.e., to fool the discriminator
  prefs: []
  type: TYPE_NORMAL
- en: the generator produces a fake image,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \tilde{\mathbf{x}} = G(z) \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) where ( z ) is a latent vector (e.g., sampled from Uniform[0.4, 1]).
  prefs: []
  type: TYPE_NORMAL
- en: 'the discriminator evaluates this fake sample and returns:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: Now we can calculate the binary cross-entropy for the generator as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\hat{y} = D(G(z))\), the discriminator’s evaluation of the generator’s fake
    image, \(z\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\hat{y}\) is the probability assigned by the discriminator to the fake being
    real
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is equivalent to cross-entropy with **target label \(y = 1\)**, note here
    we do a trick, from the generator’s perspective it’s images are real, so we are
    using \(y=1\), i.e., real images for the fake images!
  prefs: []
  type: TYPE_NORMAL
- en: You may get confused if you look at the original GAN loss above, this is called
    the non-saturating generator loss.
  prefs: []
  type: TYPE_NORMAL
- en: '| Loss Type | Expression | Comment |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Original GAN** | \(\mathbb{E}[\log(1 - D(G(z)))]\) | Theoretical, can cause
    vanishing gradients |'
  prefs: []
  type: TYPE_TB
- en: '| **Non-saturating** | \(-\mathbb{E}[\log(D(G(z)))]\) | Practical, stronger
    gradients, commonly used |'
  prefs: []
  type: TYPE_TB
- en: so instead of minimizing the original generator loss we are maximizing the non-saturating
    generator loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s show how to back propagate through the entire discriminator with the chain
    rule.
  prefs: []
  type: TYPE_NORMAL
- en: we want the generator loss gradient with respect generator output,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given \(\tilde{\mathbf{x}} = G(z)\), our fake image, we want the partial derivative
    of the loss given our fake image,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} \]
  prefs: []
  type: TYPE_NORMAL
- en: and by the chain rule,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}}
    \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}} \]
  prefs: []
  type: TYPE_NORMAL
- en: This is how the discriminator’s belief \(\hat{y}\)​ about “fakeness” changes
    with changes in \(\tilde{\mathbf{x}}\) the fake image.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are ready to back propagate the generator loss through the discriminator,
    let’s start with our generator loss (from above),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: and when we perform the partial derivative,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}} \]
  prefs: []
  type: TYPE_NORMAL
- en: Now, recall the discriminator’s forward pass is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c) \]
  prefs: []
  type: TYPE_NORMAL
- en: so we can calculate the partial derivative of the discriminator’s output with
    respect to the generator’s fake image as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: now we combine these with the chain rule as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \left( -\frac{1}{\hat{y}} \right)
    \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right) = -(1 - \hat{y}) \cdot
    \mathbf{w} \]
  prefs: []
  type: TYPE_NORMAL
- en: The gradient of the generator’s loss with respect to the output image \(\tilde{\mathbf{x}}\)
    is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: We can add some interpretations of this result,
  prefs: []
  type: TYPE_NORMAL
- en: when \(\hat{y}\) is close to 0 \(\rightarrow\) discriminator easily spots fake
    \(\rightarrow\) large gradient \(\rightarrow\) generator updates more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: when \(\hat{y}\) is close to 1 \(\rightarrow\) generator is fooling the discriminator
    \(\rightarrow\) gradient is small.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This guides the generator to tweak its output to increase \(\hat{y}\) — i.e.,
    fool the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: To further clarify, for our example let’s compute how the discriminator’s output
    \(\hat{y}\) changes with respect to the generator outputs \(O_5, O_6, O_7\), instead
    of the \(w\) vector notation used above.
  prefs: []
  type: TYPE_NORMAL
- en: if we apply the chain rule we get,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) for each of the components we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]\[ \frac{dz}{dO_5} = \lambda_{5,8}
    \]\[ \frac{dz}{dO_6} = \lambda_{6,8} \]\[ \frac{dz}{dO_7} = \lambda_{7,8} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) substituting in the chain rule we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8} \]\[ \frac{d\hat{y}}{dO_6}
    = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8} \]\[ \frac{d\hat{y}}{dO_7} = \hat{y}(1
    - \hat{y}) \cdot \lambda_{7,8} \]
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation Through Generator to Weights and Bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now propagate through the generators sigmoid activation in each of the output
    nodes,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dO_i}{dz_i} = O_i (1 - O_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: \(O_i = \sigma(z_i)\), where \(z_i\) is the input for the output nodes, pre-activation,
    and \(O_i\) is output for the output nodes, post-activation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We Apply chain rule,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
    = \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: Recall,
  prefs: []
  type: TYPE_NORMAL
- en: \[ z_i = \lambda_{1,i} \cdot L_1 + b \]
  prefs: []
  type: TYPE_NORMAL
- en: so we can calculate the generator’s weights partial derivatives as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dz_i}{d\lambda_{1,i}} = L_1 \]
  prefs: []
  type: TYPE_NORMAL
- en: and the generator’s bias partial derivative as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dz_i}{db} = 1 \]
  prefs: []
  type: TYPE_NORMAL
- en: Now we can put this all together with the chain rule, the partial derivatives
    of the generator loss with respect to the generator weights are,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,i}} = \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{d\lambda_{1,i}} = \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \cdot L_1 \]
  prefs: []
  type: TYPE_NORMAL
- en: and the partial derivative of the generator loss with respect to the generator
    bias is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{db} = \sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{db} = \sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: For clarity, let’s write this out for each of our generator’s weights,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,2}} = -(1 - \hat{y}) \cdot \lambda_{5,8}
    \cdot O_5 (1 - O_5) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,3}} = -(1
    - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,4}}
    = -(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1 \]
  prefs: []
  type: TYPE_NORMAL
- en: and for our generator’s bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{db} = -(1 - \hat{y}) \cdot \left[ \lambda_{5,8} \cdot
    O_5(1 - O_5) + \lambda_{6,8} \cdot O_6(1 - O_6) + \lambda_{7,8} \cdot O_7(1 -
    O_7) \right] \]
  prefs: []
  type: TYPE_NORMAL
- en: Let’s make some interpretations,
  prefs: []
  type: TYPE_NORMAL
- en: the generator’s weights and bias gradients scale with how much the discriminator
    is fooled (\(1 - \hat{y}\))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the generator learns to tweak \(\lambda_{1,i}\) and \(b\) to push the fake images,
    \(O_5\), \(O_6\) and \(O_7\) in directions that increase \(\hat{y}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this flow of error gives the generator a signal to **fool the discriminator
    more effectively** without ever seeing a real image!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple GAN Training Workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start with initialization of the generator and discriminator weights and
    bias and setting the training hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Generate the Synthethic, “Real Images” for training
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: sample \(N\) real 3-node, 1D images \(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'use the synthetic training data function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \text{Real images} \sim \text{linear decreasing trend} + \text{noise} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize generator weights and bias** - the weights,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small
    random values} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) and the bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ b \leftarrow 0.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize discriminator weights and bias** - the weights,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small
    random values} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) and the bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ c \leftarrow 0.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Set model training hyperparameters** - this includes,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Learning Rates - for the generator, \(\eta_G\), and discriminator, \(\eta_D\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batch Size - in this example we are assuming batch size equal to the number
    of real images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Epochs - number of training iterations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train the discriminator**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: combine real and fake inputs into a batch of size \(2N\) and inlcude labels
    \(y_i = 1\) for real, \(y_i = 0\) for fake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: compute discriminator outputs \(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'calculate discriminator loss and gradients using:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial
    \mathcal{L}}{\partial c} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'update discriminator weights and bias:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    \lambda_{j,8}}, \quad c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    c} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Train the generator**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute generator output fake images and pass to the discriminator to evaluate
    the outputs on these fakes, \(D_8\) same as \(y\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate generator loss gradients using,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial
    \mathcal{L}_G}{\partial b} \]
  prefs: []
  type: TYPE_NORMAL
- en: Update generator weights and bias,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    \lambda_{1,j}}, \quad b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    b} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Repeat Until Convergence** - or stop criteria is met, such as maximum number
    of training epochs, return to step 5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here a summary of the training loop,
  prefs: []
  type: TYPE_NORMAL
- en: Generate real data batch
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate fake data batch
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update discriminator to better distinguish real/fake
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update generator to fool discriminator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This adversarial training loop lets the generator learn to create data mimicking
    the real distribution, and the discriminator improve in spotting fakes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/0e5b9d59df3b7c13cf96ada6a8409c005cf108794aa5c6d5da5188ad5ef20ded.png](../Images/686c89ab95fc15d0556a9ed4d7f3bed6.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize Real Images and Trained Generator Fake Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s check a set of fake images from our trained generator against the real
    images.
  prefs: []
  type: TYPE_NORMAL
- en: recall the generator never saw these images, the discriminator saw the real
    and fake images and told the generator how good or bad were the generator’s fake
    images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/765558367eae336a177e7a0b9b0a86037b878b20114ad05070fc072fd5f13404.png](../Images/5e411f7e4a786c08b02c80dadc431416.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize Real Images and Generator Fake Images Over Training Epochs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is interesting to see how our generator’s fake images evolve over the training
    epochs.
  prefs: []
  type: TYPE_NORMAL
- en: as first the fake images are random due to the random initialization of the
    generator’s weights and bias
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: as the training proceeds the generator learns to improve the fake images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I include the real images at the end for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/c9fb21bf43af473100eacd88fe058bc353b01c81bec63e5cf3719df9229a386d.png](../Images/ad9bdf6d9a437102f9bba86e2f345ae0.png)'
  prefs: []
  type: TYPE_IMG
- en: Comments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was a basic treatment of generative adversarial networks. Much more could
    be done and discussed, I have many more resources. Check out my [shared resource
    inventory](https://michaelpyrcz.com/my-resources) and the YouTube lecture links
    at the start of this chapter with resource links in the videos’ descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this is helpful,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: About the Author
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  prefs: []
  type: TYPE_NORMAL
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  prefs: []
  type: TYPE_NORMAL
- en: All of Michael’s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michael’s work and shared educational resources visit his
    Website.
  prefs: []
  type: TYPE_NORMAL
- en: Want to Work Together?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  prefs: []
  type: TYPE_NORMAL
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? I’d be happy to drop by and work with you!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’m always happy to discuss,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  prefs: []
  type: TYPE_NORMAL
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  prefs: []
  type: TYPE_NORMAL
- en: Motivation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if we put together machines? Working in a competitive, adversarial manner?
  prefs: []
  type: TYPE_NORMAL
- en: Could we make a more powerful machine learning model that learns its own loss
    function!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could we make images that don’t collapse to exact reproduction of the images
    in the training set?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative neural networks are very powerful, nature inspired computing deep
    learning method to make fake, but realistic, images by application of convolutional
    neural networks, an analogy of visual cortex that extend the ability of our artificial
    neural networks to better work with images.
  prefs: []
  type: TYPE_NORMAL
- en: Nature inspired computing is looking to nature for inspiration to develop novel
    problem-solving methods,
  prefs: []
  type: TYPE_NORMAL
- en: '**artificial neural networks** are inspired by biological neural networks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nodes** in our model are artificial neurons, simple processors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**connections** between nodes are artificial synapses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**perceptive fields** regularization to improve generalization and efficiency'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: intelligence emerges from many connected simple processors. For the remainder
    of this chapter, I will used the terms nodes and connections to describe our convolutional
    neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial and Convolutional Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have not, take this opportunity to review my previous chapters in the
    e-book on,
  prefs: []
  type: TYPE_NORMAL
- en: '[Artificial Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_ANN.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The **main takeaways** from my artificial neural network chapter are as follows,
  prefs: []
  type: TYPE_NORMAL
- en: '**architecture of a neural network**, including its fundamental components,
    nodes (neurons) and the weighted connections between them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**forward pass** computation through the network, where each node computes
    a weighted sum of its inputs (including a bias term), followed by the application
    of a nonlinear activation function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**computation of the error derivative**, which is then backpropagated through
    the network via the chain rule to determine the gradients of the loss function
    with respect to each weight and bias.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**aggregation of these gradients** across all samples in a training batch,
    typically by averaging, to update the model parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**iterative training process**, where the model is trained over multiple batches
    and epochs (passes over all the data) to continually refine the weights and biases
    until the model achieves an acceptable error rate on the test data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convolutional Neural Networks](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_CNN.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The main takeaways from my convolutional neural network chapter are as follows,
  prefs: []
  type: TYPE_NORMAL
- en: '**regularization** of image data with receptive fields to preserve spatial
    information and to avoid overfit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**convolutional kernels** with learnable weights to extraction information
    from images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For both of these chapters, I have included links to my recorded lectures and
    to neural networks built from scratch with NumPy only!
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we start with a convolutional neural network and we flip it, i.e., reverse
    the order of the operations,
  prefs: []
  type: TYPE_NORMAL
- en: we have a machine that maps from a 1D vector of values, to an image, i.e., we
    can generate fake images by randomly assigning latent values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: to accomplish this instead of convolution operations with activation, we have
    transpose convolution operations with activation to move to the next feature map
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: recall we also perform non-linear activation at each feature map to prevent
    network collapse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/edf859adfdeba17f094dbc0415d2bb06.png)'
  prefs: []
  type: TYPE_IMG
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  prefs: []
  type: TYPE_NORMAL
- en: But how do we train this flipped convolutional neural network to make good images?
  prefs: []
  type: TYPE_NORMAL
- en: we could take training images and score the difference between our generated
    fake images, for example, with a pixel-wise squared error (L2 norm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: but if we did this, our machine learning model would only learn how to make
    this image or a limited set of training images and that would not be useful
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to make a diverse set of image realizations, that look and behave correctly.
    This is the simulation paradigm at the heart of geostatistics,
  prefs: []
  type: TYPE_NORMAL
- en: to learn more about the simulation paradigm from geostatistics, see my [Simulation
    Chapter](https://geostatsguy.github.io/GeostatsPyDemos_Book/GeostatsPy_simulation.html)
    from my free, online e-book, [Applied Geostatistics in Python](https://geostatsguy.github.io/GeostatsPyDemos_Book).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of a typically loss function, we apply a classification convolutional
    neural network to map from the image to a probability of a real image, i.e., our
    loss function is effectively a network that learns to score the loss during training.
  prefs: []
  type: TYPE_NORMAL
- en: We have 2 neural networks in our GAN,
  prefs: []
  type: TYPE_NORMAL
- en: '**generator** - flipped convolutional neural network that makes random fake
    images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**discriminator** - classification convolutional neural netwrok that calculates
    the probability that an image is real'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/464dd59ea97be3602e14c9ece74a40a6.png)'
  prefs: []
  type: TYPE_IMG
- en: A convolutional neural network flipped and convolution replaced with transpose
    convolution to go from a 1D random latent vector to a random image.
  prefs: []
  type: TYPE_NORMAL
- en: Indirect, Adversarial Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do we train these two coupled networks? We call each network an agent and
    we train them competively, e.g., they compete while learning!
  prefs: []
  type: TYPE_NORMAL
- en: agent 1, Generator, is not trained to minimize an loss function with respect
    to training data (training image), no MSE!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: instead the agent 1, Generator, is trained to fool agent 2, Discriminator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: agent 2, Discriminator, is learning at the same time to tell the difference
    between the real training images and the fakes from agent 1, generator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each agent has their own competitive goals,
  prefs: []
  type: TYPE_NORMAL
- en: Generator – make fakes that Discriminator classifies as real
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator – correctly classify fake and real images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note, the generator never sees the real images, but by learning to fool the
    discriminator learns to make images like the real training images.
  prefs: []
  type: TYPE_NORMAL
- en: The GAN loss function is stated as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min_{\theta_G} \, \max_{\theta_D} \; \mathbb{E}_{\mathbf{y} \sim p_{\text{data}}}
    \left[ \log D_{\theta_D}(\mathbf{y}) \right] + \mathbb{E}_{\mathbf{x} \sim p_{\mathbf{x}}}
    \left[ \log \left( 1 - D_{\theta_D}(G_{\theta_G}(\mathbf{x})) \right) \right]
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\theta_D\) - parameters (weights, biases) of the **discriminator**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\theta_G\) - parameters of the **generator**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(D_{\theta_D}(\cdot)\) - discriminator output, given the discriminator parameters
    \(\theta_D\) (probability input is real)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(G_{\theta_G}(\mathbf{x})\) - output of the Generator output given latent input
    \(\mathbf{x}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\mathbf{y} \sim p_{\text{data}}\) - training images from the **real image
    set**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\mathbf{x} \sim p_{\mathbf{x}}\) - latent input sampled from known prior (e.g.
    uniform or normal)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\mathbb{E}[\cdot]\) - expectation over data (i.e., average over all samples)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\log D(\cdot)\) - log-likelihood that the discriminator assigns input as real
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\log(1 - D(G(\cdot)))\) - log-likelihood that discriminator assigns fake to
    generator’s output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator wants to **maximize**,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log D(\mathbf{y}) + \log(1 - D(G(\mathbf{x}))) \]
  prefs: []
  type: TYPE_NORMAL
- en: tries to **correctly predicts real** training images as real, \(\log D(\mathbf{y})
    \rightarrow 0.0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and to **correctly predicts generated** fake training images as not real, \(\log(1
    - D(G(\mathbf{x}))) \rightarrow 0.0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generator want to **minimize**,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log(1 - D(G(\mathbf{x}))) \]
  prefs: []
  type: TYPE_NORMAL
- en: tries to **fool the discriminator**, discriminator classifies fake training
    images as real, \(\log(1 - D(G(\mathbf{x}))) \rightarrow -\infty\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To assist with understanding the GAN loss function and the system of competing
    agents, consider these end members,
  prefs: []
  type: TYPE_NORMAL
- en: '**Perfect Discriminator** - if the discriminator is perfect,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: all real training images are classified as real, \(D(\mathbf{y}) = 1\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: all fake images from the generator are classified as real, \(D(G(\mathbf{x}))
    = 0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\quad\) then the discriminator loss is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log(1) + \log(1 - 0) = 0 + \log(1) = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) this sounds like good news, i.e., the generator will then improve
    to catch up with the discriminator, but what actually happens is,
  prefs: []
  type: TYPE_NORMAL
- en: generator receives **no loss gradients**, because the generators gradients,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{\partial \log(1 - D(G(z)))}{\partial \theta_G} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) if \(D(G(z)) \to 0\), this derivative becomes **zero**, so training
    stalls and **the generator doesn’t learn**,
  prefs: []
  type: TYPE_NORMAL
- en: this is practically solved by substituting **non-saturating generator loss**
    for the generator,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ L_G = -\mathbb{E}_{z \sim p_z}[\log D(G(z))] \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) if \(D(G(z)) \to 0\), then \(\log D(G(z)) \to -\infty\), so the gradient
    becomes **large**, giving the generator a strong learning signal.
  prefs: []
  type: TYPE_NORMAL
- en: '**Perfect Generator** - if the generator is perfect,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: all fake images have the same distribution as the real training images, \(G(\mathbf{x})
    \sim p_{\text{data}}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the best the discriminator can do is to assign a anive classification, \(D(\cdot)
    = 0.5\), for all fake and real training images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\quad\) then the loss is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \log(0.5) + \log(1 - 0.5) = \log(0.5) + \log(0.5) = -\log 4 \]
  prefs: []
  type: TYPE_NORMAL
- en: discriminator is **maximally confused**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this is a **Nash equilibrium** for the GAN, because no player can improve their
    outcome by unilaterally changing their strategy, assuming the other player’s strategy
    stays the same, generator is already making perfect images and discriminator can
    only guess naively, 50/50 real and fake.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import Required Packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  prefs: []
  type: TYPE_NORMAL
- en: recall our goal is to build a convolutional neural network by-hand with only
    basic math and array operations, so we only need NumPy along with matplotlib for
    plotting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If you get a package import error, you may have to first install some of these
    packages. This can usually be accomplished by opening up a command window on Windows
    and then typing ‘python -m pip install [package-name]’. More assistance is available
    with the respective package docs.
  prefs: []
  type: TYPE_NORMAL
- en: Declare Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here’s the functions to make, train and visualize our generative adversarial
    network, including the steps,
  prefs: []
  type: TYPE_NORMAL
- en: make a simple set of synthetic data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: initialize the weights in our generator and discriminator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: apply our generator and discrimintor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: calculate the error derivative and update the generator and discriminator weights
    and biases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here’s a list of the functions,
  prefs: []
  type: TYPE_NORMAL
- en: '**generate_real_data** - synthetic data generator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**initialize_generator_weights** - assign small random weights and bias for
    generator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**initialize_discriminator_weights** - assign small random weights and bias
    for discriminator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**generator_forward** - calculate a set of fake data with the generator given
    a set of latent values and the current weights and biases'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**discriminator_forward** - calculate the probability of a real image over
    a set of images and return a 1D ndarray of probabilities'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**sigmoid** - activation function to apply in the generator and discriminator'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**generator_gradients** - compute generator gradients averaged over the batch'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**discriminator_gradients** - compute generator gradients averaged over the
    batch'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here are the functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Set the Working Directory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I always like to do this so I don’t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Visualize the Generative Adversarial Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are implementing a minimal Generative Adversarial Network (GAN) with the
    2 agents,
  prefs: []
  type: TYPE_NORMAL
- en: '**Generator** - that produces 3-node outputs (like tiny 1D images) from a single
    latent input'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator** - that evaluates these outputs to distinguish between **real**
    and **fake** samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s define the parts of the **Generator**,
  prefs: []
  type: TYPE_NORMAL
- en: '**Latent Node** - \(L_1\), a single random value with uniform distribution,
    \(U[0.4,1.0]\). Note we set the minimum as 0.4 to stay away from 0.0 or negative
    values as these would remove the slope or flip the slope of the fakes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generator Weights** - \(\lambda_{1,2}\), \(\lambda_{1,3}\) and \(\lambda_{1,4}\)
    for the connections from latent to each of the output nodes. This is the simplest
    possible tranpose convolution, with a kernel size is 3, output nodes is 3 and
    latent node is 1, so the kernel does not translate. I did this to greatly simplify
    the book keeping, but the concepts could be extended to a more realistic convolution
    / tranpose convolution architectures for more realistic images sizes problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generator Bias** - \(b\), a single, constant bias over the output layer (output
    image), the nodes, \(O_2\), \(O_3\), and \(O_4\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generator Output Nodes** - \(O_2\), \(O_3\), and \(O_4\), the single and
    last feature map in our very simple generator; therefore, the output a 1D image
    with 3 nodes or pixels that are passed to the **Discriminator** input nodes, \(I_5\),
    \(I_6\), and \(I_7\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator Input Nodes** - \(I_5\), \(I_6\), and \(I_7\), that receive
    the real images or the fake images from the generator output nodes, \(O_2\), \(O_3\),
    \(O_4\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator Weights** - \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\)
    for the connections from input nodes (input image) to the output (descision) node,
    \(D_8\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discriminator Bias** - \(c\), bias applied at the output (descision) node,
    \(D_8\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s visualize this very simple generative adversarial network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/565edb7221aa6743a530bb98f80b562615b08280d5d3d4a52aee7ff15cefcaf2.png](../Images/cdcce92e4f0534109850166492b3b2ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Just a couple more comments about my network nomenclature. My goal is to maximize
    simplicity and clarity,
  prefs: []
  type: TYPE_NORMAL
- en: Comments on Network Nomenclature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Network Nodes and Connections** - I choose to use unique numbers for all
    nodes, \(L_1\), \(O_2\), \(O_3\), \(\ldots\) instead of \(L_1\), \(O_1\), \(O_2\),
    \(\ldots\) to simplify the notation for the weights; therefore, when I say \(\lambda_{5,8}\)
    you know exactly where this weight is applied in the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node Outputs** - I use the node label to also describe the output from the
    node, for example \(O_2\) is a node in the generator’s output layer and also the
    signal or value output from that node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre- and Post-activation** - at our nodes \(O_2\), \(O_3\), \(O_4\), and
    \(D_8\) we have the node input before activation and the node output after activation,
    I use the notation \(O_{2_{in}}\), \(O_{3_{in}}\), \(O_{4_{in}}\) and \(D_{8_{in}}\)
    for the pre-activation input and \(O_2\), \(O_3\), \(O_4\), and \(D_8\) for the
    post-activation node output. This is important because with back propagation we
    have to step through the nodes, going from post-activation to pre-activation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Latent** - while publications often use \(z\) notation for the latent values,
    to be consistent with my notion above, I use \(L_1\) for the latent value, i.e.,
    the output from my latent node, \(L_1\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s walk-through all the parts of our example GAN and show all the math.
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid Activation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For reference, let’s visualize the sigmoid activation function,
  prefs: []
  type: TYPE_NORMAL
- en: '**activation** - the non-linear transformation, this is the sigmoid activation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ x_{out} = \sigma(x_{in}) = \dfrac{1}{1 + e^{-x_{in}}} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**activation derrivative** - essential for back propogation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \sigma'(x_{in}) = \sigma(x_{out})(1 - \sigma(x_{out})) \]
  prefs: []
  type: TYPE_NORMAL
- en: note, for convenience the derrivative of the sigmoid activation function with
    respect to the input is posed for the output.
  prefs: []
  type: TYPE_NORMAL
- en: as we back-propogate backwards over the activation function we can us the output
    to step back through the activated network node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f7323a3bf2b5671f3b7f629a5e2dd8966903903e490d8b510d1b437b922d20ad.png](../Images/6aef20df3b024801181a361544b98363.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s make some observations about the sigmoid activation and its derrivative,
  prefs: []
  type: TYPE_NORMAL
- en: '**sigmoid outputs** - are bounded (0,1) approaching both limits asymptotically'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vanishing gradients** - as the'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generator Forward Pass
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s walk through the generator to go from a latent value to a fake
    image. The generator takes a latent input,
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_1 \sim \mathcal{U}(0.4, 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: recall, our simple generator has only one layer \(L1\), with only 3 outputs,
    \(O_2\), \(O_3\), and \(O_4\), representing the fake image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then latent value, \(L_1\), is passed through the transpose convolution kernel
    to the output,
  prefs: []
  type: TYPE_NORMAL
- en: our transpose convolution kernel has a size of 3, the same size as our output,
    so we don’t see it translate it, resulting in greatly simplified book keeping!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the tranpose convolution kernel weights are \(\lambda_{1,2}\), \(\lambda_{1,3}\),
    and \(\lambda_{1,4}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We apply the sigmoid activation in each of the output nodes
  prefs: []
  type: TYPE_NORMAL
- en: Each output is computed by applying a linear transformation followed by a **sigmoid**
    activation, \(\sigma\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ O_2 = \sigma(\lambda_{1,2} \cdot z + b) \]\[ O_3 = \sigma(\lambda_{1,3} \cdot
    z + b) \]\[ O_4 = \sigma(\lambda_{1,4} \cdot z + b) \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: '**\(\lambda_{1,j}\)** - are the transpose convolution kernel weights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**\(b\)** - is the shared bias, single bias term for the output layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also write the generator forward pass in matrix notation as,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \begin{bmatrix} O_2 \\ O_3 \\ O_4 \end{bmatrix} = \sigma\left(
    \begin{bmatrix} \lambda_{1,2} \\ \lambda_{1,3} \\ \lambda_{1,4} \end{bmatrix}
    z + \begin{bmatrix} b \\ b \\ b \end{bmatrix} \right) \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where the sigmoid activation is applied element-wise.
  prefs: []
  type: TYPE_NORMAL
- en: Discriminator Forward Pass
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now let’s walk-through the discriminator, going from an image, real or fake,
    to a probability of real. The discriminator receives the image, over 3 input nodes,
    \(I_5\), \(I_6\), and \(I_7\). In the case of a fake image,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    O_2 \\ O_3 \\ O_4 \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: and in the case of a real image,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix} = \begin{bmatrix}
    I_5^{real} \\ I_6^{real} \\ I_7^{real} \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: Since we have only 1 layer and the convolution kernel is 3 with an input of
    3 once again there is no translation!
  prefs: []
  type: TYPE_NORMAL
- en: we just take input image, \(I_5\), \(I_6\), and \(I_7\), and apply the convolutional
    kernel weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\), and \(\lambda_{7,8}\), and
    add the bias term, \(c\),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ D_8 = \sigma\left( \lambda_{5,8} \cdot I_5 + \lambda_{6,8} \cdot I_6 + \lambda_{7,8}
    \cdot I_7 + c \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\lambda_{i,8}\) are the convolutional kernel weights to go from input image
    to next feature map, only 1 value, our output probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(c\) is the bias term
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(D_8 \in [0, 1]\) represents the probability assigned by the discriminator
    that the input is **real** (i.e. not a fake from the generator).
  prefs: []
  type: TYPE_NORMAL
- en: We can also write the discriminator forward pass in matrix notation as,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} D_8 = \sigma\left( \begin{bmatrix} \lambda_{5,8} & \lambda_{6,8}
    & \lambda_{7,8} \end{bmatrix} \cdot \begin{bmatrix} I_5 \\ I_6 \\ I_7 \end{bmatrix}
    + c \right) \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}\) are scalar weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(I_5, I_6, I_7\) are the input values (i.e., outputs of the generator, \(O_2,
    O_3, O_4\))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(c\) is the bias term
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\sigma(x) = \dfrac{1}{1 + e^{-x}}\) is the sigmoid function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator Loss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Binary cross-entropy is a loss function used for binary classification tasks
    where the output is a probability between 0 and 1, and the target label is either
    0 or 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction** (model output) - \(\hat{y} \in (0, 1)\), the output of \(D_8\),
    the discriminator’s classification, probability that the image is real'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{y} = D_8 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**True label** (ground truth) - \(y \in \{0, 1\}\), 0 if the image is from
    the generator, fake, and 1 if the image is from the real training data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can define the **binary cross-entropy loss** as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}_{\text{BCE}}(y, \hat{y}) = - \left[ y \cdot \log(\hat{y}) + (1
    - y) \cdot \log(1 - \hat{y}) \right] \]
  prefs: []
  type: TYPE_NORMAL
- en: now we can further specify,
  prefs: []
  type: TYPE_NORMAL
- en: \(\log(\hat{y})\) is the log-likelihood of the positive prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(log(1 - \hat{y})\) is the log-likelihood of the negative prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how does binary cross-entropy behave?
  prefs: []
  type: TYPE_NORMAL
- en: 'if \(y = 1\) (real image), then:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \mathcal{L} = -\log(\hat{y}) \quad \text{(we want } \hat{y} \to 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'if \(y = 0\) (fake image from the generator), then:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \mathcal{L} = -\log(1 - \hat{y}) \quad \text{(we want } \hat{y} \to 0) \]
  prefs: []
  type: TYPE_NORMAL
- en: We can summarize as,
  prefs: []
  type: TYPE_NORMAL
- en: the loss is **low** when the model’s prediction \(\hat{y}\) is **close to the
    true label**, low probability of real for a fake image and high probability of
    real for a real image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the loss becomes **very large** if the model is **confident and wrong**, due
    to the logarithm, i.e., very low probability or real for a real image and very
    high probability of real for a fake image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the sigmoid activation ensures that the output, \(\hat{y}\) is a valid probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator Loss Derivative
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To perform backpropagation we need to calculate the loss derivative. Let’s do
    this for the input of the activation function as our output node, \(D_8\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} \]
  prefs: []
  type: TYPE_NORMAL
- en: define \(z\) as the input for the sigmoid activation as output node, \(D_8\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: as you see we do this because it results in a very simple, efficient result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: recall, the sigmoid function,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \]
  prefs: []
  type: TYPE_NORMAL
- en: We will use the chain rule, so we only need to solve the parts,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = \frac{d\mathcal{L}}{d\hat{y}} \cdot \frac{d\hat{y}}{dz}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\frac{d\mathcal{L}}{d\hat{y}}\) - partial derivative of binary cross-entropy
    loss given the discriminator output \(\hat{y}\) (\(D_8\))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\frac{d\hat{y}}{dz}\) - partial derivative of the discriminator output \(\hat{y}\)
    (\(D_8\)) given the sigmoid activation input
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can solve the first part, partial derivative of loss with respect to
    the discriminator output, \(\hat{y}\)
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\hat{y}} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1
    - \hat{y}} \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: now we can solve the second part, the partial derivative of the discriminator
    output \(\hat{y}\) (\(D_8\)) given the sigmoid activation input, it is just the
    sigmoid derivative,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: and we can combine these by the chain rule as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = -\left( \frac{y}{\hat{y}} - \frac{1 - y}{1 - \hat{y}}
    \right) \cdot \hat{y}(1 - \hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: We are almost there, we only need to simplify the result, first we distribute,
    \(\hat{y}(1 - \hat{y})\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y(1 - \hat{y}) - (1 - y)\hat{y} \right]
    \]
  prefs: []
  type: TYPE_NORMAL
- en: and then simplify it further,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = -\left[ y - y\hat{y} - \hat{y} + y\hat{y} \right]
    = -\left[ y - \hat{y} \right] = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: I said this would get simple! Our partial derivative of our loss with respect
    to the input to the output node sigmoid activation function, \(z\), is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dz} = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: This result shows the gradient is just the **error** — the difference between
    predicted and true values.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can make this simple interpretation,
  prefs: []
  type: TYPE_NORMAL
- en: if \(\hat{y} > y\), the model overestimates \(\rightarrow\) gradient is positive
    \(\rightarrow\) lower prediction by moving in the negative gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if \(\hat{y} < y\), the model underestimates \(\rightarrow\) gradient is negative
    \(\rightarrow\) increase prediction by moving in the negative gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I know that a title this section “Discriminator Loss Derivative”, but excuse
    me for performing just a little bit of backpropagation (to before sigmoid activation).
  prefs: []
  type: TYPE_NORMAL
- en: next we carry on with back propagation to the discriminator weights and biases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator Back Propagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For compact notation, let’s use matrix notation and define the input to the
    \(D_8\) activation, \(z\), as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ z = \mathbf{w}^\top \mathbf{x} + c \quad \Rightarrow \quad \frac{dz}{d\mathbf{w}}
    = \mathbf{x} \]
  prefs: []
  type: TYPE_NORMAL
- en: Now we can extend our use of the chain rule to,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{d\mathbf{w}}
    = (\hat{y} - y) \cdot \mathbf{x} \]
  prefs: []
  type: TYPE_NORMAL
- en: So for each of our discriminator weights, \(\lambda_{5,8}\), \(\lambda_{6,8}\),
    and \(\lambda_{7,8}\) we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\lambda_{5,8}} = (\hat{y} - y) \cdot I_5 \]\[ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    = (\hat{y} - y) \cdot I_6 \]\[ \frac{d\mathcal{L}}{d\lambda_{7,8}} = (\hat{y}
    - y) \cdot I_7 \]
  prefs: []
  type: TYPE_NORMAL
- en: and for the bias, \(c\), we calculate the next component for the chain rule
    as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dz}{dc} = 1 \]
  prefs: []
  type: TYPE_NORMAL
- en: so we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dc} = \frac{d\mathcal{L}}{dz} \cdot \frac{dz}{dc} = (\hat{y}
    - y) \cdot 1 = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: The backpropagation for our very simple discriminator is quite simple, we can
    summarize for the weights,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{d\mathbf{w}} = (\hat{y} - y) \cdot \mathbf{x} \]
  prefs: []
  type: TYPE_NORMAL
- en: and for the bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}}{dc} = \hat{y} - y \]
  prefs: []
  type: TYPE_NORMAL
- en: Let’s write these out for all of our discriminators parameters, $\( \begin{aligned}
    \frac{d\mathcal{L}}{d\lambda_{5,8}} &= (\hat{y} - y) \cdot I_5 \\ \frac{d\mathcal{L}}{d\lambda_{6,8}}
    &= (\hat{y} - y) \cdot I_6 \\ \frac{d\mathcal{L}}{d\lambda_{7,8}} &= (\hat{y}
    - y) \cdot I_7 \\ \frac{d\mathcal{L}}{dc} &= \hat{y} - y \end{aligned} \)$
  prefs: []
  type: TYPE_NORMAL
- en: Generator Loss Derivative and Back Propagation Through the Discriminator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recall that the goal of the generator is to make fake images the discriminator
    assigns as a high probability of a real image, i.e., to fool the discriminator
  prefs: []
  type: TYPE_NORMAL
- en: the generator produces a fake image,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \tilde{\mathbf{x}} = G(z) \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) where ( z ) is a latent vector (e.g., sampled from Uniform[0.4, 1]).
  prefs: []
  type: TYPE_NORMAL
- en: 'the discriminator evaluates this fake sample and returns:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{y} = D(\tilde{\mathbf{x}}) \in (0, 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: Now we can calculate the binary cross-entropy for the generator as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: where,
  prefs: []
  type: TYPE_NORMAL
- en: \(\hat{y} = D(G(z))\), the discriminator’s evaluation of the generator’s fake
    image, \(z\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\hat{y}\) is the probability assigned by the discriminator to the fake being
    real
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is equivalent to cross-entropy with **target label \(y = 1\)**, note here
    we do a trick, from the generator’s perspective it’s images are real, so we are
    using \(y=1\), i.e., real images for the fake images!
  prefs: []
  type: TYPE_NORMAL
- en: You may get confused if you look at the original GAN loss above, this is called
    the non-saturating generator loss.
  prefs: []
  type: TYPE_NORMAL
- en: '| Loss Type | Expression | Comment |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Original GAN** | \(\mathbb{E}[\log(1 - D(G(z)))]\) | Theoretical, can cause
    vanishing gradients |'
  prefs: []
  type: TYPE_TB
- en: '| **Non-saturating** | \(-\mathbb{E}[\log(D(G(z)))]\) | Practical, stronger
    gradients, commonly used |'
  prefs: []
  type: TYPE_TB
- en: so instead of minimizing the original generator loss we are maximizing the non-saturating
    generator loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s show how to back propagate through the entire discriminator with the chain
    rule.
  prefs: []
  type: TYPE_NORMAL
- en: we want the generator loss gradient with respect generator output,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given \(\tilde{\mathbf{x}} = G(z)\), our fake image, we want the partial derivative
    of the loss given our fake image,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} \]
  prefs: []
  type: TYPE_NORMAL
- en: and by the chain rule,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \frac{d\mathcal{L}_G}{d\hat{y}}
    \cdot \frac{d\hat{y}}{d\tilde{\mathbf{x}}} \]
  prefs: []
  type: TYPE_NORMAL
- en: This is how the discriminator’s belief \(\hat{y}\)​ about “fakeness” changes
    with changes in \(\tilde{\mathbf{x}}\) the fake image.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are ready to back propagate the generator loss through the discriminator,
    let’s start with our generator loss (from above),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}_G = -\log(\hat{y}) \]
  prefs: []
  type: TYPE_NORMAL
- en: and when we perform the partial derivative,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\hat{y}} = -\frac{1}{\hat{y}} \]
  prefs: []
  type: TYPE_NORMAL
- en: Now, recall the discriminator’s forward pass is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat{y} = \sigma(\mathbf{w}^\top \tilde{\mathbf{x}} + c) \]
  prefs: []
  type: TYPE_NORMAL
- en: so we can calculate the partial derivative of the discriminator’s output with
    respect to the generator’s fake image as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{d\tilde{\mathbf{x}}} = \hat{y}(1 - \hat{y}) \cdot \mathbf{w}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: now we combine these with the chain rule as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = \left( -\frac{1}{\hat{y}} \right)
    \cdot \left( \hat{y}(1 - \hat{y}) \cdot \mathbf{w} \right) = -(1 - \hat{y}) \cdot
    \mathbf{w} \]
  prefs: []
  type: TYPE_NORMAL
- en: The gradient of the generator’s loss with respect to the output image \(\tilde{\mathbf{x}}\)
    is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\tilde{\mathbf{x}}} = -(1 - \hat{y}) \cdot \mathbf{w}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: We can add some interpretations of this result,
  prefs: []
  type: TYPE_NORMAL
- en: when \(\hat{y}\) is close to 0 \(\rightarrow\) discriminator easily spots fake
    \(\rightarrow\) large gradient \(\rightarrow\) generator updates more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: when \(\hat{y}\) is close to 1 \(\rightarrow\) generator is fooling the discriminator
    \(\rightarrow\) gradient is small.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This guides the generator to tweak its output to increase \(\hat{y}\) — i.e.,
    fool the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: To further clarify, for our example let’s compute how the discriminator’s output
    \(\hat{y}\) changes with respect to the generator outputs \(O_5, O_6, O_7\), instead
    of the \(w\) vector notation used above.
  prefs: []
  type: TYPE_NORMAL
- en: if we apply the chain rule we get,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dO_i} = \frac{d\hat{y}}{dz} \cdot \frac{dz}{dO_i} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) for each of the components we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dz} = \hat{y}(1 - \hat{y}) \]\[ \frac{dz}{dO_5} = \lambda_{5,8}
    \]\[ \frac{dz}{dO_6} = \lambda_{6,8} \]\[ \frac{dz}{dO_7} = \lambda_{7,8} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) substituting in the chain rule we have,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\hat{y}}{dO_5} = \hat{y}(1 - \hat{y}) \cdot \lambda_{5,8} \]\[ \frac{d\hat{y}}{dO_6}
    = \hat{y}(1 - \hat{y}) \cdot \lambda_{6,8} \]\[ \frac{d\hat{y}}{dO_7} = \hat{y}(1
    - \hat{y}) \cdot \lambda_{7,8} \]
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation Through Generator to Weights and Bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now propagate through the generators sigmoid activation in each of the output
    nodes,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dO_i}{dz_i} = O_i (1 - O_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: \(O_i = \sigma(z_i)\), where \(z_i\) is the input for the output nodes, pre-activation,
    and \(O_i\) is output for the output nodes, post-activation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We Apply chain rule,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{dz_i} = \frac{d\mathcal{L}_G}{dO_i} \cdot \frac{dO_i}{dz_i}
    = \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1 - O_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: Recall,
  prefs: []
  type: TYPE_NORMAL
- en: \[ z_i = \lambda_{1,i} \cdot L_1 + b \]
  prefs: []
  type: TYPE_NORMAL
- en: so we can calculate the generator’s weights partial derivatives as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dz_i}{d\lambda_{1,i}} = L_1 \]
  prefs: []
  type: TYPE_NORMAL
- en: and the generator’s bias partial derivative as,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{dz_i}{db} = 1 \]
  prefs: []
  type: TYPE_NORMAL
- en: Now we can put this all together with the chain rule, the partial derivatives
    of the generator loss with respect to the generator weights are,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,i}} = \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{d\lambda_{1,i}} = \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \cdot L_1 \]
  prefs: []
  type: TYPE_NORMAL
- en: and the partial derivative of the generator loss with respect to the generator
    bias is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{db} = \sum_{i=5}^7 \frac{d\mathcal{L}_G}{dz_i} \cdot
    \frac{dz_i}{db} = \sum_{i=5}^7 \left( \frac{d\mathcal{L}_G}{dO_i} \cdot O_i (1
    - O_i) \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: For clarity, let’s write this out for each of our generator’s weights,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{d\lambda_{1,2}} = -(1 - \hat{y}) \cdot \lambda_{5,8}
    \cdot O_5 (1 - O_5) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,3}} = -(1
    - \hat{y}) \cdot \lambda_{6,8} \cdot O_6 (1 - O_6) \cdot L_1 \]\[ \frac{d\mathcal{L}_G}{d\lambda_{1,4}}
    = -(1 - \hat{y}) \cdot \lambda_{7,8} \cdot O_7 (1 - O_7) \cdot L_1 \]
  prefs: []
  type: TYPE_NORMAL
- en: and for our generator’s bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d\mathcal{L}_G}{db} = -(1 - \hat{y}) \cdot \left[ \lambda_{5,8} \cdot
    O_5(1 - O_5) + \lambda_{6,8} \cdot O_6(1 - O_6) + \lambda_{7,8} \cdot O_7(1 -
    O_7) \right] \]
  prefs: []
  type: TYPE_NORMAL
- en: Let’s make some interpretations,
  prefs: []
  type: TYPE_NORMAL
- en: the generator’s weights and bias gradients scale with how much the discriminator
    is fooled (\(1 - \hat{y}\))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the generator learns to tweak \(\lambda_{1,i}\) and \(b\) to push the fake images,
    \(O_5\), \(O_6\) and \(O_7\) in directions that increase \(\hat{y}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this flow of error gives the generator a signal to **fool the discriminator
    more effectively** without ever seeing a real image!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple GAN Training Workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start with initialization of the generator and discriminator weights and
    bias and setting the training hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Generate the Synthethic, “Real Images” for training
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: sample \(N\) real 3-node, 1D images \(\mathbf{I} = \{(I_{5,i}, I_{6,i}, I_{7,i})\}_{i=1}^N\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'use the synthetic training data function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \text{Real images} \sim \text{linear decreasing trend} + \text{noise} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize generator weights and bias** - the weights,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \{\lambda_{1,2}, \lambda_{1,3}, \lambda_{1,4}, b\} \leftarrow \text{small
    random values} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) and the bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ b \leftarrow 0.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize discriminator weights and bias** - the weights,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \{\lambda_{5,8}, \lambda_{6,8}, \lambda_{7,8}, c\} \leftarrow \text{small
    random values} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\quad\) and the bias,
  prefs: []
  type: TYPE_NORMAL
- en: \[ c \leftarrow 0.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Set model training hyperparameters** - this includes,'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Learning Rates - for the generator, \(\eta_G\), and discriminator, \(\eta_D\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batch Size - in this example we are assuming batch size equal to the number
    of real images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Epochs - number of training iterations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train the discriminator**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: combine real and fake inputs into a batch of size \(2N\) and inlcude labels
    \(y_i = 1\) for real, \(y_i = 0\) for fake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: compute discriminator outputs \(\hat{y}_i = D(I_{5,i}, I_{6,i}, I_{7,i})\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'calculate discriminator loss and gradients using:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{\partial \mathcal{L}}{\partial \lambda_{j,8}}, \quad \frac{\partial
    \mathcal{L}}{\partial c} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'update discriminator weights and bias:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \lambda_{j,8} \leftarrow \lambda_{j,8} - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    \lambda_{j,8}}, \quad c \leftarrow c - \eta_D \times \frac{\partial \mathcal{L}}{\partial
    c} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Train the generator**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute generator output fake images and pass to the discriminator to evaluate
    the outputs on these fakes, \(D_8\) same as \(y\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate generator loss gradients using,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{\partial \mathcal{L}_G}{\partial \lambda_{1,j}}, \quad \frac{\partial
    \mathcal{L}_G}{\partial b} \]
  prefs: []
  type: TYPE_NORMAL
- en: Update generator weights and bias,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \lambda_{1,j} \leftarrow \lambda_{1,j} - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    \lambda_{1,j}}, \quad b \leftarrow b - \eta_G \times \frac{\partial \mathcal{L}_G}{\partial
    b} \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Repeat Until Convergence** - or stop criteria is met, such as maximum number
    of training epochs, return to step 5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here a summary of the training loop,
  prefs: []
  type: TYPE_NORMAL
- en: Generate real data batch
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate fake data batch
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update discriminator to better distinguish real/fake
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update generator to fool discriminator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This adversarial training loop lets the generator learn to create data mimicking
    the real distribution, and the discriminator improve in spotting fakes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/0e5b9d59df3b7c13cf96ada6a8409c005cf108794aa5c6d5da5188ad5ef20ded.png](../Images/686c89ab95fc15d0556a9ed4d7f3bed6.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize Real Images and Trained Generator Fake Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s check a set of fake images from our trained generator against the real
    images.
  prefs: []
  type: TYPE_NORMAL
- en: recall the generator never saw these images, the discriminator saw the real
    and fake images and told the generator how good or bad were the generator’s fake
    images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/765558367eae336a177e7a0b9b0a86037b878b20114ad05070fc072fd5f13404.png](../Images/5e411f7e4a786c08b02c80dadc431416.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualize Real Images and Generator Fake Images Over Training Epochs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is interesting to see how our generator’s fake images evolve over the training
    epochs.
  prefs: []
  type: TYPE_NORMAL
- en: as first the fake images are random due to the random initialization of the
    generator’s weights and bias
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: as the training proceeds the generator learns to improve the fake images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I include the real images at the end for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/c9fb21bf43af473100eacd88fe058bc353b01c81bec63e5cf3719df9229a386d.png](../Images/ad9bdf6d9a437102f9bba86e2f345ae0.png)'
  prefs: []
  type: TYPE_IMG
- en: Comments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was a basic treatment of generative adversarial networks. Much more could
    be done and discussed, I have many more resources. Check out my [shared resource
    inventory](https://michaelpyrcz.com/my-resources) and the YouTube lecture links
    at the start of this chapter with resource links in the videos’ descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this is helpful,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: About the Author
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  prefs: []
  type: TYPE_NORMAL
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  prefs: []
  type: TYPE_NORMAL
- en: All of Michael’s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michael’s work and shared educational resources visit his
    Website.
  prefs: []
  type: TYPE_NORMAL
- en: Want to Work Together?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  prefs: []
  type: TYPE_NORMAL
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? I’d be happy to drop by and work with you!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)?
    My research combines data analytics, stochastic modeling and machine learning
    theory with practice to develop novel methods and workflows to add value. We are
    solving challenging subsurface problems!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’m always happy to discuss,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  prefs: []
  type: TYPE_NORMAL
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  prefs: []
  type: TYPE_NORMAL
