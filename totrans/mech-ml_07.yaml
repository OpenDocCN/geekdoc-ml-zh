- en: 7 Exploring and Cleaning the Bulldozer Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 探索和清理推土机数据集
- en: 原文：[https://mlbook.explained.ai/bulldozer-intro.html](https://mlbook.explained.ai/bulldozer-intro.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mlbook.explained.ai/bulldozer-intro.html](https://mlbook.explained.ai/bulldozer-intro.html)
- en: '[Terence Parr](http://parrt.cs.usfca.edu) and [Jeremy Howard](http://www.fast.ai/about/#jeremy)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[特伦斯·帕特](http://parrt.cs.usfca.edu) 和 [杰里米·霍华德](http://www.fast.ai/about/#jeremy)'
- en: Copyright © 2018-2019 Terence Parr. All rights reserved.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 版权所有 © 2018-2019 特伦斯·帕特。保留所有权利。
- en: '*Please don''t replicate on web or redistribute in any way.*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*请勿在网络上复制或以任何方式重新分发。*'
- en: This book generated from markup+markdown+python+latex source with [Bookish](https://github.com/parrt/bookish).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书由 markup+markdown+python+latex 源代码生成，使用 [Bookish](https://github.com/parrt/bookish)。
- en: You can make **comments or annotate** this page by going to the annotated version
    of this page. You'll see existing annotated bits highlighted in yellow. They are
    *PUBLICLY VISIBLE*. Or, you can send comments, suggestions, or fixes directly
    to [Terence](mailto:parrt@cs.usfca.edu).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过访问此页面的注释版本来对此页进行**评论或标注**。您会看到现有的标注部分以黄色突出显示。它们是**公开可见的**。或者，您可以直接将评论、建议或修复发送给[特伦斯](mailto:parrt@cs.usfca.edu)。
- en: Contents
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 目录
- en: '[Loading the bulldozer data](#sec:7.1)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[加载推土机数据](#sec:7.1)'
- en: '[Taking an initial look at the data](#sec:7.2)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初步查看数据](#sec:7.2)'
- en: '[Baseline model](#sec:7.3)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基线模型](#sec:7.3)'
- en: '[Cleaning up](#sec:7.4)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[清理数据](#sec:7.4)'
- en: '[Dealing with missing data](#sec:missing)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理缺失数据](#sec:missing)'
- en: '[Replacing missing categorical values](#sec:7.5.1)'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[替换缺失的分类值](#sec:7.5.1)'
- en: '[Replacing missing numeric values](#sec:7.5.2)'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[替换缺失的数值值](#sec:7.5.2)'
- en: '[Training a model with all features](#sec:7.6)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用所有特征训练模型](#sec:7.6)'
- en: '[Summary](#sec:7.7)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[总结](#sec:7.7)'
- en: We've learned a great deal so far about preparing data, feature engineering,
    and training models, but the apartment rent dataset is relatively small with few
    features. Over the next few chapters, we're going to explore and build models
    for a [bulldozer auction prices dataset](https://www.kaggle.com/c/bluebook-for-bulldozers)
    from Kaggle that has 8 times as many observations and 52 features. A large dataset
    presents a new set of problems, such as figuring out which features to focus on
    for feature engineering and being able to train and test models quickly. The bulldozer
    dataset is also rife with missing values. After working through the process we've
    laid out for this dataset, though, your final model will perform near the top
    of the leaderboard for the (now closed) bulldozer competition.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学到了很多关于准备数据、特征工程和训练模型的知识，但公寓租金数据集相对较小，特征较少。在接下来的几章中，我们将探索并构建来自Kaggle的[推土机拍卖价格数据集](https://www.kaggle.com/c/bluebook-for-bulldozers)，该数据集有8倍多的观测值和52个特征。大数据集带来了一系列新的问题，例如确定哪些特征需要关注进行特征工程，以及能够快速训练和测试模型。推土机数据集也存在大量缺失值。尽管如此，在完成我们为该数据集制定的过程后，您的最终模型将在（现已关闭的）推土机竞赛的排行榜上名列前茅。
- en: Another wrinkle with this dataset is that records represent bulldozer sales,
    and prices can drift over time due to inflation, financial crises, and so on.
    As a general rule, we can't train and test models for time-sensitive data the
    same way we do for time-insensitive data. The out-of-bag (OOB) ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score isn't usually appropriate because OOB scores measure performance only within
    the training data period, not against future predictions. It's more appropriate
    to sort a dataset by date and then take the last, say, 20% as a hold-out validation
    set. That leaves the first 80% as the training set, which we use to train the
    model. Evaluating the performance of the model on the validation set gives a much
    more accurate estimate of model generality than the OOB score. That said, in order
    to tackle this bulldozer problem in pieces, we're going to start out measuring
    model performance using the OOB ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score, dramatically simplifying our process. Just keep in mind that the OOB score
    is overestimating model performance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集的另一个问题是，记录代表推土机的销售，价格可能会因通货膨胀、金融危机等因素随时间波动。一般来说，我们不能像处理非时间敏感数据那样训练和测试时间敏感数据。袋外（OOB）![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)的分数通常不合适，因为OOB分数只衡量训练数据期间的性能，而不是对未来预测的准确性。按日期排序数据集并取最后，比如说，20%作为保留验证集更为合适。这样，剩下的80%就作为训练集，我们用它来训练模型。在验证集上评估模型的性能比OOB分数更能准确估计模型的一般性。话虽如此，为了逐步解决这个推土机问题，我们将从使用OOB![图片](../Images/ec985123b9b52e80981e6500795e8d16.png)分数来衡量模型性能开始，这极大地简化了我们的过程。但请记住，OOB分数高估了模型性能。
- en: In this chapter, we'll examine the bulldozer data set, normalize and cleanup
    various values, fill in missing values, and then train an initial model. Next,
    in **Chapter 8** *Bulldozer Feature Engineering*, we'll learn a few more encodings
    for categorical variables and improve the features identified as important by
    the initial model. After we figure out how to prepare this dataset, we'll explore
    in **Chapter 9** *Train, Validate, Test* how to properly prepare validation and
    test sets for use in tuning the model and getting a true estimate of model generality.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将检查推土机数据集，对各种值进行归一化和清理，填补缺失值，然后训练一个初始模型。接下来，在第8章**推土机特征工程**中，我们将学习更多关于分类变量的编码，并改进初始模型识别出的重要特征。在我们弄清楚如何准备这个数据集之后，我们将在第9章**训练、验证、测试**中探讨如何正确准备验证集和测试集，以便用于调整模型并获得模型一般性的真实估计。
- en: 7.1 Loading the bulldozer data
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 加载推土机数据
- en: Our first step is to grab the bulldozer dataset from Kaggle's [Blue Book for
    Bulldozers](https://www.kaggle.com/c/bluebook-for-bulldozers/data) competition.
    Download files `Train.zip` (and uncompress), `Valid.csv`, and `ValidSolution.csv`
    into your `data` directory beneath the directory where you launch Jupyter. (You
    must be a registered Kaggle user and logged in.) The `Train.csv` file you get
    after uncompressing `Train.zip` is 116M, which takes about 35 seconds to load
    using Pandas' `read_csv()` function. That load time would be unbearably slow while
    staring at the screen and would make it harder to iterate quickly on our models.
    Instead, we're going to use the [feather data format](https://github.com/wesm/feather),
    which lets us load the data in about one second. The [prep-bulldozer.py](data/prep-bulldozer.py)
    script (from this book's [data](data/index.html) directory) loads the training
    CSV data (for the first and only time), splits out a validation set, and saves
    them both using the fast feather format. The script also merges `Valid.csv`, and
    `ValidSolution.csv` into a single test dataframe and saves it for later use. From
    the command-line and in your `data` directory, execute the following to create
    the data files we need.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是从Kaggle的[推土机蓝皮书](https://www.kaggle.com/c/bluebook-for-bulldozers/data)竞赛中获取推土机数据集。将解压后的`Train.zip`文件（以及解压）、`Valid.csv`和`ValidSolution.csv`下载到您启动Jupyter的目录下的`data`目录中。（您必须是注册的Kaggle用户并已登录。）解压`Train.zip`后得到的`Train.csv`文件大小为116M，使用Pandas的`read_csv()`函数加载大约需要35秒。这种加载时间在盯着屏幕时会让人难以忍受，并且会使我们快速迭代模型变得更加困难。因此，我们将使用[feather数据格式](https://github.com/wesm/feather)，它允许我们在大约一秒内加载数据。[prep-bulldozer.py](data/prep-bulldozer.py)脚本（来自本书的[data](data/index.html)目录）加载训练CSV数据（第一次也是唯一一次），分割出一个验证集，并使用快速feather格式保存它们。该脚本还将`Valid.csv`和`ValidSolution.csv`合并到一个单独的测试数据框中，并保存以供以后使用。在命令行和您的`data`目录中，执行以下命令以创建我们需要的文件。
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 1Don't forget the [notebooks](https://mlbook.explained.ai/notebooks/) aggregating
    the code snippets from the various chapters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 1别忘了[笔记本](https://mlbook.explained.ai/notebooks/)，它们汇总了各章节中的代码片段。
- en: For the next three chapters, we'll use `bulldozer-train.feather` as our data
    starting point. To start the coding process, create a notebook in the directory
    above `data` and paste in our usual preamble:1
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的三个章节中，我们将使用`bulldozer-train.feather`作为我们的数据起点。为了开始编码过程，在`data`目录的上一级创建一个笔记本，并粘贴我们常用的前言：1
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '2If you get an error “`read_feather() got an unexpected keyword argument ''nthreads''`,”
    then try:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 2如果您遇到错误“`read_feather() got an unexpected keyword argument 'nthreads'`”，那么请尝试：
- en: '`import feather`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`import feather`'
- en: '`feather.read_dataframe("data/bulldozer-train.feather")`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`feather.read_dataframe("data/bulldozer-train.feather")`'
- en: Anytime we need a fresh copy of the data, we can load it like this:2
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 任何需要数据的新副本时，我们可以这样加载：2
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It's a good idea to keep the original data around in `df_raw` so that we can
    undo any data transformations that end up being unhelpful.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 保留原始数据在`df_raw`中是个好主意，这样我们就可以撤销任何最终证明无用的数据转换。
- en: 7.2 Taking an initial look at the data
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 初步查看数据
- en: 'When inspecting a dataset for the first time, look for this key summary information:
    the column names, column datatypes, sample data elements, and how much data is
    missing. Here''s a handy function to sniff a dataframe and return a different
    dataframe containing a summary where each row describes a column in the original
    dataframe:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当首次检查数据集时，寻找以下关键摘要信息：列名、列数据类型、样本数据元素以及缺失数据量。这里有一个方便的函数可以嗅探数据框并返回一个包含摘要的数据框，其中每一行描述原始数据框中的一个列：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can call `sniff(df)` from your notebook to get a complete summary, but
    in the interest of space, here are just the first 14 entries:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从笔记本中调用`sniff(df)`以获取完整的摘要，但为了节省空间，这里只列出前14个条目：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|   | sample | data type | percent missing |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|   | 样本 | 数据类型 | 缺失百分比 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| SalesID | 1646770 | int64 | 0.0000 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| SalesID | 1646770 | int64 | 0.0000 |'
- en: '| SalePrice | 9500 | int64 | 0.0000 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| SalePrice | 9500 | int64 | 0.0000 |'
- en: '| MachineID | 1126363 | int64 | 0.0000 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| MachineID | 1126363 | int64 | 0.0000 |'
- en: '| ModelID | 8434 | int64 | 0.0000 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| ModelID | 8434 | int64 | 0.0000 |'
- en: '| datasource | 132 | int64 | 0.0000 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| datasource | 132 | int64 | 0.0000 |'
- en: '| YearMade | 1974 | int64 | 0.0000 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| YearMade | 1974 | int64 | 0.0000 |'
- en: '| auctioneerID | 18.0000 | float64 | 5.1747 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| auctioneerID | 18.0000 | float64 | 5.1747 |'
- en: '| MachineHoursCurrentMeter |  | float64 | 64.7178 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| MachineHoursCurrentMeter |  | float64 | 64.7178 |'
- en: '| saledate | 1989-01-17 00:00:00 | datetime64[ns] | 0.0000 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| saledate | 1989-01-17 00:00:00 | datetime64[ns] | 0.0000 |'
- en: '| Coupler |  | object | 46.8269 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 连接器 |  | 对象 | 46.8269 |'
- en: '| Tire_Size |  | object | 76.3297 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| Tire_Size |  | 对象 | 76.3297 |'
- en: '| Tip_Control |  | object | 93.6982 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Tip_Control |  | 对象 | 93.6982 |'
- en: '| Hydraulics | 2 Valve | object | 20.1663 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Hydraulics | 2 Valve | 对象 | 20.1663 |'
- en: '| Ripper | None or Unspecified | object | 73.9670 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Ripper | None or Unspecified | 对象 | 73.9670 |'
- en: 'We can learn a lot just from this quick sniff. There are three kinds of data:
    numeric, date time objects, and strings (`object`). Some columns are complete,
    but others have missing data, including column `Tip_Control` that is 94% missing.
    Some values are just plain missing (represented as either the `None` object or
    “not a number” `np.nan` in Python), but other “missing” values are actually physically-present
    strings like “`None or Unspecified`”.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 只从这次快速嗅探中，我们就能学到很多东西。数据有三种类型：数值、日期时间对象和字符串（`对象`）。有些列是完整的，但其他列有缺失数据，包括`Tip_Control`列，其缺失率高达94%。一些值只是简单地缺失（在Python中表示为`None`对象或“不是一个数字”`np.nan`），但其他“缺失”值实际上是物理存在的字符串，如“`None
    or Unspecified`”。
- en: 'Columns such as `SalesID` and `ModelID` are represented as integers (`int64`),
    but they are really nominal categorical variables. Model 8434 is not somehow greater
    than model 8433\. There are also columns represented as strings that contain numeric
    values, such as `Hydraulics` (“`2 Valve`”). Other columns are represented as strings
    but are actually purely numeric but with units such as feet or inches. For example,
    the values in column `Tire_Size` should be converted to just the number of inches:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如`SalesID`和`ModelID`这样的列被表示为整数（`int64`），但它们实际上是名义分类变量。型号8434并不比型号8433大。还有一些列被表示为字符串，但包含数值，如`Hydraulics`（“`2
    Valve`”）。其他列被表示为字符串，但实际上是纯数值，带有单位，如英尺或英寸。例如，`Tire_Size`列中的值应转换为英寸数：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[None ''14"'' ''None or Unspecified'' ''20.5'' ''23.5'' ''26.5'' ''17.5'' ''29.5''
    ''13"'' ''20.5"'' ''23.5"'' ''17.5"'' ''15.5'' ''15.5"'' ''7.0"'' ''23.1"'' ''10"''
    ''10 inch'']'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[None ''14"'' ''None or Unspecified'' ''20.5'' ''23.5'' ''26.5'' ''17.5'' ''29.5''
    ''13"'' ''20.5"'' ''23.5"'' ''17.5"'' ''15.5'' ''15.5"'' ''7.0"'' ''23.1"'' ''10"''
    ''10 inch'']'
- en: It's a good idea to look at the unique set of values for the other columns too
    as you experiment with this dataset. The next step in our exploration is to train
    a model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验这个数据集时，查看其他列的唯一值集也是一个好主意。我们探索的下一步是训练一个模型。
- en: 7.3 Baseline model
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 基线模型
- en: While we only have a few numeric columns out of the 52 total, and some of those
    values are missing, it's still a good idea to train a model early on in our process.
    First, it tells us how long training the model takes. If training time is significant,
    we should consider working with a subset of the data. Second, it gives us an initial
    appraisal of the strength of the relationship between numeric features and the
    `SalePrice` target variable. The OOB ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    from this initial model is our lower bound, so if it's pretty good, we can be
    optimistic about the performance of our model after feature engineering. Finally,
    a feature importance graph derived from the model helps to focus our cleanup efforts
    on the most predictive columns.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们只有52个总列中的少数几个是数值列，而且其中一些值是缺失的，但在我们的流程早期训练一个模型仍然是一个好主意。首先，它告诉我们训练模型需要多长时间。如果训练时间很重要，我们应该考虑使用数据子集。其次，它给出了数值特征与`SalePrice`目标变量之间关系的初步评估。这个初始模型的OOB分数是我们的下限，所以如果它相当不错，我们可以对我们的模型在特征工程后的性能持乐观态度。最后，从模型中得出的特征重要性图有助于我们将清理工作集中在最具预测性的列上。
- en: 'Let''s identify the features represented as numbers so far are:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确定到目前为止表示为数字的特征：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 3We've chosen to create RFs with 50 trees because it gives a stable and accurate
    ![](../Images/ec985123b9b52e80981e6500795e8d16.png) score while not requiring
    too much processing time.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择创建包含50棵树的随机森林（RF），因为它给出了稳定且准确的分数，同时不需要太多的处理时间。![](../Images/ec985123b9b52e80981e6500795e8d16.png)
- en: We can reuse the `test()` function from **Chapter 6** *Categorically Speaking*
    to train an RF and print the OOB ![](../Images/ec985123b9b52e80981e6500795e8d16.png)
    score:3
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重用**第6章** *Categorically Speaking* 中的`test()`函数来训练RF并打印OOB分数：![](../Images/ec985123b9b52e80981e6500795e8d16.png)
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Columns `auctioneerID` and `MachineHoursCurrentMeter` have some missing values,
    represented as Numpy `np.nan`, but we can flip missing values to zeros as an expedient
    with function call `fillna(0)`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 列`auctioneerID`和`MachineHoursCurrentMeter`有一些缺失值，用Numpy的`np.nan`表示，但我们可以通过调用`fillna(0)`函数将缺失值转换为零，作为一种权宜之计：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: OOB R^2 0.78075 using 22,500,374 tree nodes with 56.0 median tree height
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用22,500,374个树节点和56.0的中等树高，OOB R^2为0.78075
- en: That OOB score is not horrible and hints that there is a strong relationship
    to capture in this dataset.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 那个OOB分数并不糟糕，暗示了在这个数据集中存在一个强大的关系。
- en: 'Unfortunately, training the model via function `fit()` takes about 25 seconds,
    which would seem like an eternity as we repeatedly transformed data and retrained
    the model. To reduce training time, we could subsample the dataframe with `df.sample(n=100_000)`,
    and that''s how we''d do it if this were not time-sensitive data. Instead, let''s
    grab the last 100,000 records (which are sorted by date), taking advantage of
    the fact that more recent data will be better at predicting the near future:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，通过`fit()`函数训练模型需要大约25秒，在我们反复转换数据和重新训练模型的过程中，这似乎像永恒一样。为了减少训练时间，我们可以使用`df.sample(n=100_000)`对数据框进行子采样，如果不是时间敏感数据，我们会这样做。相反，让我们获取最后100,000条记录（按日期排序），利用事实，即最近的数据将更好地预测近未来的情况：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After reducing the size of the dataframe, repeat the steps to train the model:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在减小数据框的大小后，重复步骤来训练模型：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: OOB R^2 0.84512 using 5,556,904 tree nodes with 45.0 median tree height
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用5,556,904个树节点和45.0的中等树高，OOB R^2为0.84512
- en: Training the model now takes only about 5 seconds down from 25 seconds and,
    as a bonus, the ![](../Images/ec985123b9b52e80981e6500795e8d16.png) of 0.845 is
    much better than the previous 0.781.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练模型只需要大约5秒，而之前需要25秒，并且作为额外的好处，OOB的0.845比之前的0.781要好得多。
- en: 'Now, let''s see which features the model thinks are most predictive of bulldozer
    sale price:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看模型认为哪些特征最能预测推土机的销售价格：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![](../Images/c37407a99b8303f93c0bef383f309a2b.png)](images/bulldozer-intro/bulldozer-intro_sniff_14.svg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/c37407a99b8303f93c0bef383f309a2b.png)](images/bulldozer-intro/bulldozer-intro_sniff_14.svg)'
- en: 'The most important features are consistent with what we''d expect when evaluating
    a vehicle''s value: what kind (model) of bulldozer it is, when it was made, how
    long it''s been in use, etc.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的特征与我们评估车辆价值时预期的相符：它是哪种（型号）推土机，制造时间，使用时间等。
- en: Now that we have a good understanding of the data and a baseline model, let's
    start cleaning up the data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对数据有了很好的理解，并且有了基线模型，让我们开始清理数据。
- en: 7.4 Cleaning up
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 清理
- en: 'The easiest things to fix in the cleanup process are the small administrative
    details like changing column datatypes and deleting unusable columns, so let''s
    start with those. According to the data description at Kaggle, `SalesID` is a
    unique identifier for a particular transaction. This is clearly not predictive
    as a `SalesID` value will never be seen again as a feature, so we can remove it.
    We can also remove `MachineID` because this variable has [errors and inconsistencies](https://www.kaggle.com/c/bluebook-for-bulldozers/discussion/3694);
    besides, it''s not strongly-predictive according to our feature importance graph.
    Our first step is then:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在清理过程中最容易修复的是像更改列数据类型和删除不可用列这样的小行政细节，所以让我们从这里开始。根据Kaggle上的数据描述，`SalesID`是特定交易的唯一标识符。这显然不是预测性的，因为`SalesID`值永远不会再次作为特征出现，所以我们可以移除它。我们还可以移除`MachineID`，因为这个变量有[错误和不一致性](https://www.kaggle.com/c/bluebook-for-bulldozers/discussion/3694)；此外，根据我们的特征重要性图，它也不是强预测性的。我们的第一步是：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `auctioneerID` column values look like numbers, but they are really categorical
    variables, specifically nominal variables that have no order:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`auctioneerID`列的值看起来像数字，但它们实际上是分类变量，具体来说是没有任何顺序的命名变量：'
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[nan 5\. 2\. 27\. 1\. 23\. 3\. 4\. 20\. 7\. 8\. 12\. 10\. 6\. 21\. 13\. 9\.
    18. 99\. 16\. 14\. 19\. 28\. 15\. 22\. 25\. 17\. 11\. 24\. 26\. 0.]'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[nan 5.2.27.1.23.3.4.20.7.8.12.10.6.21.13.9.18.99.16.14.19.28.15.22.25.17.11.24.26.0.]'
- en: 'Just to make this clear, let''s change the data type to be string:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这一点更清晰，让我们将数据类型更改为字符串：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If we leave this as a number, our process below for dealing with missing numeric
    values would replace the missing `auctioneerID` values with the median auctioneer
    ID, which is clearly meaningless.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将其保留为数字，我们下面处理缺失数值的过程将用中值拍卖师ID替换缺失的`auctioneerID`值，这显然是没有意义的。
- en: 'So much for the numbers, let''s take a look at the string-valued columns. Some
    are nice and tidy such as:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数字的问题就这么多，让我们来看看字符串值列。其中一些很整洁，例如：
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[''TTT'' ''TEX'' ''WL'' ''SSL'' ''BL'' ''MG'']'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[''TTT'' ''TEX'' ''WL'' ''SSL'' ''BL'' ''MG'']'
- en: 'but others have missing values:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 但其他人有缺失值：
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[None ''Two Wheel Drive'' ''Four Wheel Drive'' ''No'' ''All Wheel Drive'']'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[None ''Two Wheel Drive'' ''Four Wheel Drive'' ''No'' ''All Wheel Drive'']'
- en: and others have physically-present strings to mean “missing:”
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以及其他人用物理存在的字符串来表示“缺失：”
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[''None or Unspecified'' None ''Yes'']'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[''None or Unspecified'' None ''Yes'']'
- en: 'Columns `fiSecondaryDesc` and `fiModelSeries` even have a value of “`#NAME?`”.
    This dataset has multiple ways to say “missing” or “unspecified,” but our model
    won''t be able to figure the equivalencies on its own. We need to normalize all
    of these strings so that `None`, `None or Unspecified`, and `#NAME?` all mean
    “missing.” Let''s encapsulate this equivalents in a function that transforms the
    dataframe so only `np.nan` means missing:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列`fiSecondaryDesc`和`fiModelSeries`甚至有“`#NAME?`”的值。这个数据集有多种表示“缺失”或“未指定”的方式，但我们的模型无法自己确定这些等价物。我们需要将这些字符串标准化，以便`None`、`None
    or Unspecified`和`#NAME?`都表示“缺失”。让我们将这些等价物封装在一个函数中，该函数将转换数据框，使得只有`np.nan`表示缺失：
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After calling `df_normalize_strings(df)`, all of the different ways to say
    none are collapsed to `np.nan` and strings all are lowercase:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用`df_normalize_strings(df)`之后，所有表示“无”的不同方式都被折叠为`np.nan`，并且所有字符串都转换为小写：
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[nan ''two wheel drive'' ''four wheel drive'' ''no'' ''all wheel drive''] [nan
    ''yes'']'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[nan ''two wheel drive'' ''four wheel drive'' ''no'' ''all wheel drive''] [nan
    ''yes'']'
- en: 'Some strings are actually numeric values, but include unit names or symbols
    that force the dataframe to treat them as strings:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一些字符串实际上是数值，但包含单位名称或符号，这迫使数据框将它们视为字符串：
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[nan ''26.5'' ''20.5'' ''17.5'' ''23.5'' ''14"'' ''13"'' ''29.5'' ''17.5"''
    ''15.5"'' ''20.5"'' ''15.5'' ''23.5"'' ''7.0"'' ''10"'' ''23.1"''] [nan ''36 inch''
    ''24 inch'' ''20 inch'' ''34 inch'' ''26 inch'' ''30 inch'' ''28 inch'' ''32 inch''
    ''16 inch'' ''31 inch'' ''18 inch'' ''22 inch'' ''33 inch'' ''14 inch'' ''27 inch''
    ''25 inch'' ''15 inch'']'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[nan ''26.5'' ''20.5'' ''17.5'' ''23.5'' ''14"'' ''13"'' ''29.5'' ''17.5"''
    ''15.5"'' ''20.5"'' ''15.5'' ''23.5"'' ''7.0"'' ''10"'' ''23.1"''] [nan ''36 inch''
    ''24 inch'' ''20 inch'' ''34 inch'' ''26 inch'' ''30 inch'' ''28 inch'' ''32 inch''
    ''16 inch'' ''31 inch'' ''18 inch'' ''22 inch'' ''33 inch'' ''14 inch'' ''27 inch''
    ''25 inch'' ''15 inch'']'
- en: 'It''s a simple matter to strip off the `"` and `inch` characters to convert
    these two columns to numeric values. Here''s a function to convert a column of
    strings to a numeric column by extracting any integer or floating-point numbers
    on the front of the string:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 将这两个列转换为数值很简单，只需去除`"`和`inch`字符即可。这里有一个函数，通过从字符串的前面提取任何整数或浮点数来将字符串列转换为数值列：
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[ nan 26.5 20.5 17.5 23.5 14\. 13\. 29.5 15.5 7\. 10\. 23.1] [nan 36\. 24\.
    20\. 34\. 26\. 30\. 28\. 32\. 16\. 31\. 18\. 22\. 33\. 14\. 27\. 25\. 15.]'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[nan 26.5 20.5 17.5 23.5 14. 13. 29.5 15.5 7. 10. 23.1] [nan 36. 24. 20. 34.
    26. 30. 28. 32. 16. 31. 18. 22. 33. 14. 27. 25. 15.]'
- en: 'There are two other columns that are numeric in nature but would be more complicated
    to parse apart (as they have both feet and inch units):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另外两列在本质上都是数值，但解析起来会更复杂（因为它们既有英尺也有英寸单位）：
- en: '[PRE23]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[nan "12''" "14''" "13''" "16''" "<12''"] [nan ''10\'' 6"'' ''9\'' 6"'' ''9\''
    7"'' ''10\'' 2"'' ''12\'' 8"'' ''12\'' 10"'' ''9\'' 10"'' ''9\'' 8"'' ''11\''
    0"'' ''10\'' 10"'' ''8\'' 6"'' ''9\'' 5"'' ''14\'' 1"'' ''11\'' 10"'' ''6\'' 3"''
    ''12\'' 4"'' ''8\'' 2"'' ''8\'' 10"'' ''8\'' 4"'' ''15\'' 9"'' ''13\'' 10"'' ''13\''
    7"'' ''15\'' 4"'' ''19\'' 8"'']'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[nan "12''" "14''" "13''" "16''" "<12''"] [nan ''10\'' 6"'' ''9\'' 6"'' ''9\''
    7"'' ''10\'' 2"'' ''12\'' 8"'' ''12\'' 10"'' ''9\'' 10"'' ''9\'' 8"'' ''11\''
    0"'' ''10\'' 10"'' ''8\'' 6"'' ''9\'' 5"'' ''14\'' 1"'' ''11\'' 10"'' ''6\'' 3"''
    ''12\'' 4"'' ''8\'' 2"'' ''8\'' 10"'' ''8\'' 4"'' ''15\'' 9"'' ''13\'' 10"'' ''13\''
    7"'' ''15\'' 4"'' ''19\'' 8"'']'
- en: The `Blade_Width` column even has a range in the form of `<12'`. It's better
    to leave these as strings, which we'll treat as categorical variables when prepping
    the data for use in a model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`Blade_Width`列甚至有一个以`<12''`形式表示的范围。最好将它们保留为字符串，在准备数据用于模型时，我们将它们视为分类变量。'
- en: 7.5 Dealing with missing data
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 处理缺失数据
- en: Missing data in CSV files is often indicated as physically missing (two commas
    in a row like “`,,`”), but some records use physically-present string values such
    as `None` or `Unspecified`. Some files use special indicator numbers to represent
    missing numeric values, such as -1 or 0\. Pandas uses Numpy's `np.nan` (“not a
    number”) to represent values missing from data files in memory, for both numeric
    and string data types. Pandas stores physically-present numeric and string values
    in files as-is in memory. The point is that the definition of missing is ambiguous
    and depends on the dataset. That's why we normalized strings in the previous section
    so that only `np.nan` indicates “missing.” We'll do the same for numeric indicator
    values in this section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件中的缺失数据通常以物理缺失（如“，，”这样的连续两个逗号）表示，但一些记录使用物理存在的字符串值，如`None`或`Unspecified`。一些文件使用特殊的指示数字来表示缺失的数值，如-1或0。Pandas使用Numpy的`np.nan`（“非数字”）来表示内存中数据文件中缺失的值，无论是数值还是字符串数据类型。Pandas将内存中物理存在的数值和字符串值按原样存储在文件中。关键是缺失的定义是模糊的，取决于数据集。这就是为什么我们在上一节中标准化了字符串，以便只有`np.nan`表示“缺失”。在本节中，我们将对数值指示值做同样的处理。
- en: 'Once the entire dataframe has a single definition of missing value, we still
    have to do something intelligent with these holes. Models can''t train on “not
    a number” values. Our recipe to handle missing values looks like this: For numeric
    columns, we replace missing values with the median of that column and introduce
    a new boolean column that is true for any record where we replace a missing value.
    (Statisticians call replacing missing values *imputation*.) The strategy for nonnumeric
    columns simply is to leave them as-is with `np.nan` values. Our default string/categorical
    variable encoding is to label encode them, which will automatically replace `np.nan`
    values with zeros. (Label encoding assigns a unique integer for every unique string
    or category value.) Dealing with missing nonnumeric values is easiest so let''s
    start by seeing how that works.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦整个数据框对缺失值有一个统一的定义，我们仍然需要对这些空缺进行一些智能处理。模型无法在“非数字”值上训练。我们处理缺失值的方案如下：对于数值列，我们用该列的中位数替换缺失值，并引入一个新布尔列，当替换缺失值时该列值为真。（统计学家将替换缺失值称为*插补*。）对于非数值列的策略简单来说就是保持原样，使用`np.nan`值。我们的默认字符串/分类变量编码是将它们进行标签编码，这将自动将`np.nan`值替换为零。（标签编码为每个唯一的字符串或类别值分配一个唯一的整数。）处理缺失的非数值值是最简单的，让我们先看看它是如何工作的。
- en: 7.5.1 Replacing missing categorical values
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.1 替换缺失的分类值
- en: 'In **Section 6.2** *Encoding categorical variables*, we converted the string
    `display_address` column to numeric values by converting the column to an ordered
    categorical column and then replacing the categories with their category integer
    codes + 1\. Pandas represents `np.nan` with category code -1 and so adding one
    shifts `np.nan` to 0 and all category codes to be 1 and above. For convenience,
    let''s create two functions that implement our label-encoding strategy:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第6.2节** *编码分类变量*中，我们将字符串`display_address`列转换为数值，通过将列转换为有序分类列，然后替换类别为它们的类别整数代码+1。Pandas用类别代码-1表示`np.nan`，所以加一将`np.nan`移到0，并将所有类别代码移到1以上。为了方便，让我们创建两个函数来实现我们的标签编码策略：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let''s see the mechanism in action on a toy dataset:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个玩具数据集上看看这个机制是如何起作用的：
- en: '[PRE25]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '|   | Name |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|    | 名称 |'
- en: '| --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|  |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: '| --- |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | Xue |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 学 |'
- en: '| 1 |  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 1 |  |'
- en: '| 2 | Tom |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Tom |'
- en: 'Converting the string column to a categorical variable means Pandas will replace
    each string with a unique integer representation, which we can include in the
    dataframe:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串列转换为分类变量意味着Pandas将每个字符串替换为唯一的整数表示，我们可以将其包含在数据框中：
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '|   | Name | catcodes |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|   | 名称 | catcodes |'
- en: '| --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: '| --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | Xue | 1 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 0 | Xue | 1 |'
- en: '| 1 |  | -1 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 1 |  | -1 |'
- en: '| 2 | Tom | 0 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Tom | 0 |'
- en: 'Pandas still displays the `Name` column values as strings because that''s more
    meaningful, but the `Name` column is now categorical:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas仍然将`名称`列的值显示为字符串，因为这更有意义，但`名称`列现在是分类的：
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Name category catcodes int8 dtype: object'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 名称 类别 catcodes int8 数据类型：对象
- en: 'To complete the label encoding, we call the second function to replace the
    category values with the integer codes:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成标签编码，我们调用第二个函数来将类别值替换为整数代码：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '|   | Name | catcodes |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|   | 名称 | catcodes |'
- en: '| --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: '| --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | 2 | 1 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 2 | 1 |'
- en: '| 1 | 0 | -1 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | -1 |'
- en: '| 2 | 1 | 0 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1 | 0 |'
- en: The `Name` column is one more than the `catcodes` column and so missing values
    become integer value 0 at the end of the encoding process.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`名称`列比`catcodes`列多一个，因此缺失值在编码过程的最后成为整数值0。'
- en: 'To handle all missing nonnumeric values and label-encode nonnumeric columns,
    takes just two function calls:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理所有缺失的非数值和非数值列的标签编码，只需两次函数调用：
- en: '[PRE29]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '|   | 289125 | 289126 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|   | 289125 | 289126 |'
- en: '| --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: '| --- |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| SalePrice | 8300 | 15500 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 销售价格 | 8300 | 15500 |'
- en: '| ModelID | 4663 | 11859 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 模型ID | 4663 | 11859 |'
- en: '| datasource | 136 | 132 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| datasource | 136 | 132 |'
- en: '| auctioneerID | 31 | 25 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 拍卖师ID | 31 | 25 |'
- en: '| YearMade | 1985 | 1995 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| YearMade | 1985 | 1995 |'
- en: '| MachineHoursCurrentMeter | 0.0000 |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| MachineHoursCurrentMeter | 0.0000 |  |'
- en: '| UsageBand | 0 | 0 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| UsageBand | 0 | 0 |'
- en: '| saledate | 2009-01-23 00:00:00 | 2009-01-23 00:00:00 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| saledate | 2009-01-23 00:00:00 | 2009-01-23 00:00:00 |'
- en: '| fiModelDesc | 654 | 3081 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| fiModelDesc | 654 | 3081 |'
- en: '| fiBaseModel | 211 | 1127 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| fiBaseModel | 211 | 1127 |'
- en: We've now converted all string columns to numbers and dealt with missing string
    values.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已将所有字符串列转换为数值并处理了缺失的字符串值。
- en: '**The unreasonable effectiveness of label encoding categorical variables**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签编码类别变量的不合理有效性**'
- en: You might be wondering why it's “legal” to convert all of those unordered (nominal)
    categorical variables to ordered integers. We know for sure that assuming an order
    between categories is wrong. The short answer is that RF models can still partition
    such converted categorical features in a way that is predictive, possibly at the
    cost of a more complex tree model. This is definitely not true for many models,
    such as linear regression models (which require so-called “dummy” boolean columns,
    one for each unique categorical value). In practice, we've found label encoding
    categorical variables surprisingly effective, even when it seems more advanced
    methods would work better.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道为什么将所有那些无序（名义）的类别变量转换为有序整数是“合法”的。我们确实知道假设类别之间存在顺序是错误的。简短的回答是，RF模型仍然可以以预测的方式对转换后的类别特征进行分区，这可能会以更复杂的树模型为代价。这绝对不适用于许多模型，例如线性回归模型（它需要所谓的“虚拟”布尔列，每个唯一的类别值一个）。在实践中，我们发现标签编码类别变量非常有效，即使更高级的方法似乎会更好。
- en: 7.5.2 Replacing missing numeric values
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.2 替换缺失的数值
- en: 'To handle missing numeric values, we recommend a two step process:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理缺失的数值，我们建议分两步进行：
- en: For column *x*, create a new boolean column *x*`_na` where *x*`[i]` is true
    if *x*`[i]` is missing.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于列 *x*，创建一个新的布尔列 *x*`_na`，其中 *x*`[i]` 为真表示 *x*`[i]` 缺失。
- en: Replace missing values in column *x* with the median of all *x* values in that
    column.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将列 *x* 中的缺失值替换为该列中所有 *x* 值的中位数。
- en: 'Those two steps have simple and direct equivalents in Python, thanks to Pandas:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个步骤在Python中有简单直接的等效操作，多亏了Pandas：
- en: '[PRE30]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s make a toy dataframe with a numeric column that''s missing a value:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个包含缺失值的数值列的玩具数据框：
- en: '[PRE31]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '|   | YearMade |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|   | YearMade |'
- en: '| --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: '| --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | 1995.0000 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1995.0000 |'
- en: '| 1 | 2001.0000 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2001.0000 |'
- en: '| 2 |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 2 |  |'
- en: 'and then run it through our function to see its effect on the dataframe:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将它通过我们的函数来查看其对数据框的影响：
- en: '[PRE32]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '|   | YearMade | YearMade_na |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|   | YearMade | YearMade_na |'
- en: '| --- | --- | --- |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: '| --- |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 0 | 1995.0000 | False |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1995.0000 | False |'
- en: '| 1 | 2001.0000 | False |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2001.0000 | False |'
- en: '| 2 | 1998.0000 | True |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1998.0000 | True |'
- en: The missing value in the third row has been replaced by 1998, the median of
    1995 and 2001, and there is a new column called `YearMade_na` indicating we replaced
    a value.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 第三行的缺失值已被替换为1998年，即1995年和2001年的中位数，并且有一个新列`YearMade_na`表示我们进行了替换。
- en: 'The logic behind using the median is that we have to choose a number and so
    we might as well choose a number that''s not going to skew the distribution of
    the data in that column. We also don''t want to choose an extreme value that the
    model might latch onto as predictive. But, we should include a column in our dataset
    that indicates we''ve done this replacement because sometimes missing values are
    strongly predictive. For example, a bulldozer with an unknown manufacturing date
    is presumably less valuable because of the uncertainty. This approach is supported
    by recent academic research: [On the consistency of supervised learning with missing
    values](https://hal.archives-ouvertes.fr/hal-02024202v2).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 使用中位数的逻辑是，我们必须选择一个数字，所以我们不妨选择一个不会扭曲该列数据分布的数字。我们也不想选择一个极端值，因为模型可能会将其作为预测因素。但是，我们应该在我们的数据集中包含一个列，表明我们已经进行了这种替换，因为有时缺失值具有很强的预测性。例如，制造日期不明的推土机由于不确定性而可能价值较低。这种做法得到了最近学术研究的支持：[关于带有缺失值的监督学习的一致性](https://hal.archives-ouvertes.fr/hal-02024202v2)。
- en: 'Turning back to the full dataset now, we previously converted `Tire_Size` from
    a string to a numeric column by parsing out the number of inches:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 回到完整的数据集，我们之前通过解析英寸数将`Tire_Size`从字符串转换为数值列：
- en: '[PRE33]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Values [ nan 26.5 20.5 17.5 23.5 14\. 13\. 29.5 15.5 7\. 10\. 23.1] Median 20.5
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 值 [ nan 26.5 20.5 17.5 23.5 14\. 13\. 29.5 15.5 7\. 10\. 23.1] 中位数 20.5
- en: 'That still leaves a lot of missing values:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然留下了很多缺失值：
- en: '[PRE34]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '|   | Tire_Size |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|   | Tire_Size |'
- en: '| --- | --- |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 289125 |  |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 289125 |  |'
- en: '| 289126 |  |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 289126 |  |'
- en: '| 289127 |  |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 289127 |  |'
- en: '| 289128 |  |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 289128 |  |'
- en: '| 289129 | 26.5000 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 289129 | 26.5000 |'
- en: '| 289130 |  |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 289130 |  |'
- en: 'After applying `fix_missing_num()`, all `np.nan`s representing missing values
    have been replaced with 20.5, the median of `Tire_Size`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 应用`fix_missing_num()`后，所有表示缺失值的`np.nan`都已被替换为`Tire_Size`的中位数20.5：
- en: '[PRE35]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '|   | Tire_Size |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|   | Tire_Size |'
- en: '| --- | --- |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 289125 | 20.5000 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 289125 | 20.5000 |'
- en: '| 289126 | 20.5000 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 289126 | 20.5000 |'
- en: '| 289127 | 20.5000 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 289127 | 20.5000 |'
- en: '| 289128 | 20.5000 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 289128 | 20.5000 |'
- en: '| 289129 | 26.5000 |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 289129 | 26.5000 |'
- en: '| 289130 | 20.5000 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 289130 | 20.5000 |'
- en: 'We also have to fix missing values in the other column we converted to numbers:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须修复我们转换成数字的其他列中的缺失值：
- en: '[PRE36]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Not all missing values are represented by `np.nan`. Sometimes people represent
    missing values by special indicator values during data entry or some conversion
    process. There are two numeric columns with such indicator values that we should
    fix because the feature importance graph suggests they are important.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有缺失值都由`np.nan`表示。有时人们在数据录入或某些转换过程中使用特殊的指示值来表示缺失值。有两个数值列具有这样的指示值，我们应该修复它们，因为特征重要性图表明它们很重要。
- en: 'One look at the relationship between `YearMade` and the bulldozer sale price
    shows that we have a problem:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一看`YearMade`与推土机售价之间的关系，我们就知道有问题：
- en: » *Generated by code to left*
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: » *由代码生成左侧*
- en: '[![](../Images/d0dcb507595e954eeee16778e1fcebec.png)](images/bulldozer-intro/bulldozer-intro_sniff_40.svg)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/d0dcb507595e954eeee16778e1fcebec.png)](images/bulldozer-intro/bulldozer-intro_sniff_40.svg)'
- en: '[PRE37]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'It''s unlikely that humans were manufacturing bulldozers in the year 1000\.
    Either the seller does not want to admit the age or does not know the age of the
    bulldozer. It''s unclear why someone chose an indicator value of 1000 instead
    of 0 or -1, but we can fix this problem by replacing 1000 with `np.nan`. Then,
    we can apply our standard procedure for missing numeric values:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在公元1000年人类制造推土机似乎不太可能。要么卖家不想承认推土机的年龄，要么不知道推土机的年龄。不清楚为什么有人选择1000作为指示值而不是0或-1，但我们可以通过将1000替换为`np.nan`来解决这个问题。然后，我们可以应用我们处理缺失数值的标准程序：
- en: '[PRE38]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[![](../Images/c083fbe0d280dd68192b2ec5c9d61b0a.png)](images/bulldozer-intro/bulldozer-intro_sniff_42.svg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/c083fbe0d280dd68192b2ec5c9d61b0a.png)](images/bulldozer-intro/bulldozer-intro_sniff_42.svg)'
- en: Now the manufacturing year versus sale price looks a lot more reasonable.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，制造年份与售价看起来要合理得多。
- en: 'There''s one last problem with this column. Some records indicate that the
    bulldozer was sold before it was made, although there is only one in the last
    100,000 records of our training subset:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列还有一个问题。一些记录表明推土机是在制造之前被出售的，尽管在我们的训练子集的最后10万条记录中只有一条：
- en: '[PRE39]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '|   | SalePrice | YearMade | saledate |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|   | SalePrice | YearMade | saledate |'
- en: '| --- | --- | --- | --- |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 344948 | 35000 | 2012.0000 | 2010-05-06 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 344948 | 35000 | 2012.0000 | 2010-05-06 |'
- en: 'That''s easy enough to fix by setting the `YearMade` to the year of the sale
    date (using the assumption that the sale date is more recent and likely more accurate
    than the manufacturing date):'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将`YearMade`设置为销售日期的年份（假设销售日期比制造日期更近且更准确），我们可以轻松解决这个问题：
- en: '[PRE40]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The other numeric column with a special value is `MachineHoursCurrentMeter`.
    At first glance, a bulldozer with 0 machine hours appears to be simply a new bulldozer.
    Let''s filter for records with 0 missing hours and look at the histogram of `YearMade`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个具有特殊值的数值列是`MachineHoursCurrentMeter`。乍一看，拥有0小时机器的推土机似乎只是一台新推土机。让我们筛选出缺失小时数为0的记录，并查看`YearMade`的直方图：
- en: » *Generated by code to left*
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: » *由代码生成左侧*
- en: '[![](../Images/3cba6205b22ef2147be900536cbfdb6c.png)](images/bulldozer-intro/bulldozer-intro_sniff_45.svg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/3cba6205b22ef2147be900536cbfdb6c.png)](images/bulldozer-intro/bulldozer-intro_sniff_45.svg)'
- en: '[PRE41]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Those manufacturing dates all precede 2009, which is the first sale year in
    our data subset. It''s unlikely that all of those bulldozers sat idle from the
    time of their manufacture until their sale date years later. From this, we can
    conclude that 0 must indicate an unknown or “you really don''t want to know” number
    of machine hours. Let''s flip those zeros to `np.nan` and call `fix_missing_num()`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这些制造日期都早于2009年，这是我们的数据子集中的第一年销售。不太可能所有这些推土机从制造时间起就闲置，直到多年后的销售日期。从这个角度来看，0必须表示未知或“你真的不想知道”的机器小时数。让我们将这些零转换为`np.nan`，并调用`fix_missing_num()`：
- en: '[PRE42]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'After handling these missing numeric values, there are three new columns on
    the end of the dataframe:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理这些缺失的数值后，数据框末尾出现了三个新的列：
- en: '[PRE43]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '|   | Undercarriage_Pad_Width_na | YearMade_na | MachineHoursCurrentMeter_na
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|   | Undercarriage_Pad_Width_na | YearMade_na | MachineHoursCurrentMeter_na
    |'
- en: '| --- | --- | --- | --- |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 289125 | True | False | True |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 289125 | True | False | True |'
- en: '| 289126 | True | False | True |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 289126 | True | False | True |'
- en: '| 289127 | True | False | True |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 289127 | True | False | True |'
- en: '| 289128 | False | False | True |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 289128 | False | False | True |'
- en: '| 289129 | True | False | True |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 289129 | True | False | True |'
- en: At this point all features are numeric, except for `saledate`, and missing values
    have been fixed.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有特征都是数值型的，除了`saledate`，缺失值也已修复。
- en: 7.6 Training a model with all features
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6 使用所有特征训练模型
- en: 'Now that we have the dataframe prepped as pure numbers, we can use all the
    features to train a model and compare its performance to the baseline. The one
    exception is that `saledate` is still a time stamp, but we''ll do something special
    with that in the next chapter. Here''s the usual training sequence:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据框准备成纯数字，我们可以使用所有特征来训练模型，并将其性能与基线进行比较。唯一的例外是`saledate`仍然是一个时间戳，但我们在下一章中会对它做些特别处理。以下是常规的训练序列：
- en: '[PRE44]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: OOB R^2 0.89871 using 5,151,648 tree nodes with 43.0 median tree height
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 使用5,151,648个树节点和43.0的中位树高，OOB R^2为0.89871
- en: 'That 0.899 is a big improvement upon our baseline score of 0.845, but we can
    do better through feature engineering, which is the subject of the next chapter.
    Let''s take a snapshot of this cleaned up dataset to avoid repeating the same
    process:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 0.899这个分数相较于我们的基线分数0.845有了很大的提升，但通过特征工程我们可以做得更好，这是下一章的主题。让我们对这个清理过的数据集进行快照，以避免重复同样的过程：
- en: '[PRE45]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[![](../Images/987f99d07829a600e5e6ade52713bcae.png)](images/bulldozer-intro/bulldozer-intro_sniff_52.svg)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/987f99d07829a600e5e6ade52713bcae.png)](images/bulldozer-intro/bulldozer-intro_sniff_52.svg)'
- en: To help focus our feature engineering efforts, let's check the feature importance
    graph (right gutter) to see what the model finds predictive. `YearMade` is still
    very important, but there's nothing left to do on that feature. Given their importance,
    we should take a close look at `ProductSize`, `fiProductClassDesc`, `Enclosure`,
    `Hydraulics_Flow`, `fiSecondaryDesc`, and so on. Also notice the long tail of
    unimportant features. These features could be truly unimportant or could be extremely
    important, but for a small subset of the records. The best strategy is to leave
    all features in the model until the end, and then gradually remove them until
    accuracy drops.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们集中特征工程的努力，让我们检查特征重要性图（右侧边栏）以查看模型认为哪些特征具有预测性。`YearMade`仍然非常重要，但在该特征上已经没有太多可以做的事情。考虑到它们的重要性，我们应该仔细查看`ProductSize`、`fiProductClassDesc`、`Enclosure`、`Hydraulics_Flow`、`fiSecondaryDesc`等特征。还要注意不重要特征的长期尾部。这些特征可能是真正不重要的，也可能是对于记录的小子集极端重要的。最佳策略是在模型中保留所有特征直到最后，然后逐渐移除它们直到准确率下降。
- en: 7.7 Summary
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.7 摘要
- en: In this chapter, we did a lot of cleanup work on the bulldozer data set, mostly
    related to converting column datatypes and dealing with missing numeric and string
    values. Part of the cleanup process was to identify physically-present numbers
    or strings that actually represent missing values. Our `df_normalize_strings()`
    function normalizes the notion of missing to `np.nan` for strings, but we had
    to identify indicators of missing values, such as medieval sale dates of 1000,
    manually.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们对推土机数据集进行了大量的清理工作，主要与转换列数据类型和处理缺失的数值型和字符串值有关。清理过程的一部分是识别物理上存在的数字或字符串，这些数字或字符串实际上代表缺失值。我们的`df_normalize_strings()`函数将字符串的缺失概念归一化为`np.nan`，但我们必须手动识别缺失值的指示符，例如1000年的中世纪销售日期。
- en: 'The most important lesson of this chapter is how to deal with missing values.
    Missing categorical values are dealt with automatically because of our recommended
    label-encoding process: Convert categories to unique integer values; missing values,
    `np.nan`, become category code 0 and all other categories are codes 1 and above.
    Dealing with missing numeric values requires a new column and replacement of `np.nan`s:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 本章最重要的教训是如何处理缺失值。由于我们推荐的标签编码过程，缺失的类别值会自动处理：将类别转换为唯一的整数值；缺失值，`np.nan`，变为类别代码0，而所有其他类别代码为1及以上。处理缺失的数值型值需要创建新列并替换`np.nan`：
- en: For column *x*, create a new boolean column *x*`_na` where *x*`[i]` is true
    if *x*`[i]` is missing.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于列*x*，创建一个新的布尔列*x*`_na`，其中*x*`[i]`为真表示*x*`[i]`是缺失的。
- en: Replace missing values in column *x* with the median of all *x* values in that
    column.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将列*x*中的缺失值替换为该列所有*x*值的平均值。
- en: At this point, you've got some good data cleaning skills, you know how to normalize
    and encode string columns as numeric values, and you know how to deal with missing
    values. That means you know how to prepare datasets for model training purposes.
    In the next chapter, were going to beef up your feature engineering skills.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经掌握了一些良好的数据清洗技能，你知道如何归一化和将字符串列编码为数值型值，也知道如何处理缺失值。这意味着你知道如何为模型训练准备数据集。在下一章，我们将加强你的特征工程技能。
