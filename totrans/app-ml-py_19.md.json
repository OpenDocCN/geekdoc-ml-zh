["```py\nsuppress_warnings = False                                     # select to suppress warnings\nimport os                                                     # to set current working directory \nimport math                                                   # square root\nimport numpy as np                                            # arrays and matrix math\nimport scipy.stats as st                                      # statistical methods\nimport pandas as pd                                           # DataFrames\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nfrom sklearn.preprocessing import MinMaxScaler                # min/max normalization\nfrom sklearn.linear_model import LinearRegression             # linear regression\nfrom sklearn.model_selection import train_test_split          # train and test split\ncmap = plt.cm.inferno                                         # default color bar, no bias and friendly for color vision defeciency\nplt.rc('axes', axisbelow=True)                                # grid behind plotting elements\nif suppress_warnings == True:  \n    import warnings                                           # suppress any warnings for this demonstration\n    warnings.filterwarnings('ignore') \n```", "```py\ndef weighted_percentile(data, weights, perc):                 # calculate weighted percentile, iambr on StackOverflow \n    ix = np.argsort(data)                                     # https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049\n    data = data[ix] \n    weights = weights[ix] \n    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) \n    return np.interp(perc, cdf, data)\n\ndef histogram_bounds(values,weights,color):                   # add uncertainty bounds to a histogram \n    p10 = weighted_percentile(values,weights,0.1); avg = np.average(values,weights=weights); p90 = weighted_percentile(values,weights,0.9)\n    plt.plot([p10,p10],[0.0,45],color = color,linestyle='dashed')\n    plt.plot([avg,avg],[0.0,45],color = color)\n    plt.plot([p90,p90],[0.0,45],color = color,linestyle='dashed')\n\ndef add_grid():\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"C:\\PGE337\")                                        # set the working directory \n```", "```py\nadd_error = False                                             # add random error to the response feature for testing\nstd_error = 1.0; seed = 71071\n\nyname = 'Porosity'; xname = 'Density'                         # specify the predictor features (x2) and response feature (x1)\nxmin = 1.0; xmax = 2.5                                        # set minimums and maximums for visualization \nymin = 0.0; ymax = 25.0    \nyunit = '%'; xunit = '$g/cm^{3}$'    \nXlabelunit = xname + ' (' + xunit + ')'\nylabelunit = yname + ' (' + yunit + ')'\n\n#df = pd.read_csv(\"Density_Por_data.csv\")                     # load the data from local current directory\ndf = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/Density_Por_data.csv\") # load the data from my github repo\ndf = df.sample(frac=.30, random_state = 73073); df = df.reset_index() # extract 30% random to reduce the number of data\n\nif add_error == True:                                         # method to add error\n    np.random.seed(seed=seed)                                 # set random number seed\n    df[yname] = df[yname] + np.random.normal(loc = 0.0,scale=std_error,size=len(df)) # add noise\n    values = df._get_numeric_data(); values[values < 0] = 0   # set negative to 0 in a shallow copy ndarray\n\ndfy = pd.DataFrame(df[yname])                                 # extract selected features as X and y DataFrames\ndfx = pd.DataFrame(df[xname])\ndf = pd.concat([dfx,dfy],axis=1)                              # make one DataFrame with both X and y (remove all other features)\n\ny = df[yname].values.reshape(len(df))\nx = df[xname].values.reshape(len(df))\ndX = np.linspace(xmin,xmax,100)                               # values for plotting the model \n```", "```py\ndf \n```", "```py\ndf.head(n=13)                                                 # we could also use this command for a table preview \n```", "```py\ndf.describe().transpose()                                     # summary statistics \n```", "```py\nnbins = 20                                                    # number of histogram bins\n\nplt.subplot(221)\nfreq,_,_ = plt.hist(x=df[xname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\nhistogram_bounds(values=df[xname].values,weights=np.ones(len(df)),color='red')\nplt.xlabel(xname + ' (' + xunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Density'); add_grid()  \nplt.xlim([xmin,xmax])    \n\nplt.subplot(222)\nfreq,_,_ = plt.hist(x=df[yname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\nhistogram_bounds(values=df[yname].values,weights=np.ones(len(df)),color='red')\nplt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Porosity'); add_grid()  \nplt.xlim([ymin,ymax])  \n\nplt.subplot(223)                                              # plot the model\nplt.scatter(df[xname],df[yname],marker='o',label='data',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10)\nplt.title('Porosity vs Density')\nplt.xlabel(xname + ' (' + xunit + ')')\nplt.ylabel(yname + ' (' + yunit + ')')\nplt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)\n#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') \nplt.show() \n```", "```py\nimport scipy.stats as st                                    # statistical methods \n```", "```py\nslope, intercept, r_value, p_value, std_err = st.linregress(x,y) # instantiate and fit a linear regression model\n\nprint('The model parameters are, slope (b1) = ' + str(round(slope,2)) + ', and the intercept (b0) = ' + str(round(intercept,2))) \n```", "```py\nThe model parameters are, slope (b1) = -10.3, and the intercept (b0) = 30.03 \n```", "```py\nx_values = np.linspace(xmin,xmax,100)                         # return an array of density values \ny_model = slope * x_values + intercept                        # apply our linear regression model to estimate at the training data values\n\nplt.subplot(111)                                              # plot the model\nplt.plot(x, y, 'o', label='data', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black',zorder=10)\nplt.plot(x_values, y_model, label='model', color = 'black',zorder=1)\nplt.title('Linear Regression Model, Regression of ' + yname + ' on ' + xname)\nplt.xlabel(xname + ' (' + xunit + ')')\nplt.ylabel(yname + ' (' + yunit + ')')\nplt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])\n\nplt.annotate('Linear Regression Model',[1.25,5.7])\nplt.annotate(r'    $\\beta_1$ :' + str(round(slope,2)),[1.6,4.1])\nplt.annotate(r'    $\\beta_0$ :' + str(round(intercept,2)),[1.6,2.5])\nplt.annotate(r'$N[\\phi] = \\beta_1 \\times z + \\beta_0$',[1.1,4.1])\nplt.annotate(r'$N[\\phi] = $' + str(round(slope,2)) + r' $\\times$ $z$ + (' + str(round(intercept,2)) + ')',[1.1,2.5])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nprint('Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = ' + str(p_value) + '.') \n```", "```py\nTwo-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = 2.2197132981703346e-09. \n```", "```py\nalpha = 0.05\nt_critical = st.t.ppf([alpha/2,1-alpha/2], df=len(x)-2)\nprint('The t-critical lower and upper values are ' + str(np.round(t_critical,2)))\nprint('and the t-statistic is ' + str(round(slope/std_err,2))) \n```", "```py\nThe t-critical lower and upper values are [-2.04  2.04]\nand the t-statistic is -8.4 \n```", "```py\nprint('The correlation coefficient is = ' + str(round(r_value,2)) + ' and the r-squared value = ', str(round(r_value**2,2))) \n```", "```py\nThe correlation coefficient is = -0.84 and the r-squared value =  0.7 \n```", "```py\nprint('The slope confidence interval is ' + str(round(slope,2)) + ' +/- ' + str(round(t_critical[1] * std_err,2)))\nCI_slope = slope + t_critical*std_err\nprint('The slope P02.5 and P97.5 are ' + str(np.round(CI_slope,2))) \n```", "```py\nThe slope confidence interval is -10.3 +/- 2.5\nThe slope P02.5 and P97.5 are [-12.8  -7.8] \n```", "```py\nalpha = 0.05\ntstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)            # calculate t-stat for confidence interval\nslope_lower,slope_upper = slope + tstat*std_err # calculate the lower and upper confidence interval for b1\n\nplt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=10)\nplt.plot(dX, intercept + slope*dX, 'black', label='linear regression model')\nplt.plot(dX, intercept + slope_upper*dX, 'black',ls='--',lw=1,label=r'alpha = ' + str(alpha) + ' confidence interval')\nplt.plot(dX, intercept + slope_lower*dX, 'black',ls='--',lw=1)\nplt.annotate('The model parameters confidence intervals at ' + str(1-alpha) + ' significance level:',[1.3,24])\nplt.annotate('Slope: P' + str(alpha/2*100) + ' = '+ str(round(slope_lower,2)) + ' , P' + str((1-alpha/2)*100) + ' = ' + str(round(slope_upper,2)),[1.5,23])\nplt.fill_between(dX,intercept + slope_upper*dX,intercept + slope_lower*dX,color='red',alpha=0.3,zorder=1)\nplt.title('Sample Data, Linear Regression Model and Slope Confidence Intervals'); plt.xlabel(r'Density ($g/cm^3$)'); plt.ylabel('Porosity (%)')\nplt.legend(loc='lower left'); add_grid(); plt.ylim([ymin,ymax]); plt.xlim([xmin,xmax])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.1, hspace=0.2); plt.show() \n```", "```py\nnew_X = 2.00\nalpha = 0.05\n\ntstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)\n\nyhat = intercept + slope*x\nMSE = np.sum(np.power(y-yhat,2))/(len(y)-2) # mean square error\nest_stderr = math.sqrt(MSE) \\\n      *math.sqrt(1 + 1/len(y) + np.power(new_X - np.average(x),2)/ \\\n      np.sum(np.power(x-np.average(x),2)))\n\ny_pred_lower, y_pred_upper = intercept + slope*new_X + tstat*est_stderr\n\nplt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=1)\nplt.plot(dX, intercept + slope*dX, 'black', label='linear regression model',zorder=1)\nplt.scatter(new_X, intercept + slope*new_X,s=80,color='yellow',edgecolor='black',label=r'prediction, $\\hat{y}$',zorder=2)\nplt.plot([new_X,new_X],[y_pred_lower,y_pred_upper],color='black',linestyle='dashed',zorder=1,label='prediction interval')\nplt.title(r'Sample Data, Linear Regression Model and Prediction Interval, $\\alpha = $' + str(alpha)); plt.xlabel(r'Density ($g/cm^3$)'); \nplt.ylabel('Porosity (%)')\nplt.legend(); add_grid(); plt.ylim([4,22]); plt.xlim([1.0,2.4])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.4, wspace=0.1, hspace=0.2); plt.show() \n```", "```py\ny_hat = slope * x + intercept\nplt.subplot(111)\nplt.hist(y_hat, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(5,20,40))\nplt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.title(yname + ' Predictions'); plt.xlim([ymin,ymax])\nadd_grid()\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nplt.subplot(111)\nplt.plot(x, y, 'o', label='training data',color = 'darkorange', alpha = 1.0, markeredgecolor = 'black',zorder=10)\nplt.scatter(x, y_hat,s=10,marker='o',label='prediction',color = 'grey',edgecolor='black',alpha=1.0,zorder=10)\nplt.plot(dX,dX*slope+intercept,color='red',lw=2,zorder=2,label='model')\nfor idata in range(0,len(x)):\n    if idata == 0:\n        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey',label=r'$\\Delta_{y_i}$',zorder=1)\n    else:  \n        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey')\nplt.title('Comparison of Training Data vs. Model')\nplt.xlabel(xname + ' (' + xunit + ')')\nplt.ylabel(yname + ' (' + yunit + ')')\nplt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nresidual = y - y_hat\n\nplt.subplot(111)\nplt.hist(residual, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(-4,4,30))\nplt.title(\"Error Residual at Training Data\"); plt.xlabel(yname + ' True - Estimate (%)');plt.ylabel('Frequency'); add_grid()\nplt.vlines(0,0,4.2,color='red',lw=2,zorder=1); plt.vlines(np.average(residual),0,4.2,color='black',ls='--',zorder=10); plt.ylim([0,4.2])\nplt.annotate('Residual Average = ' + str(np.round(np.average(residual),2)),[np.average(residual)-0.2,2.5],rotation=90.0)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show()\n\nprint('The average of the residuals is ' + str(round(np.mean(residual),2))) \n```", "```py\nThe average of the residuals is 0.0 \n```", "```py\nslope_cross, intercept_cross, _, _, _ = st.linregress(y_hat,y) # check for conditional bias with a linear fit to the cross validation plot\n\nplt.subplot(121)\nplt.plot(y_hat, y, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')\nplt.plot([ymin,ymax], [ymin,ymax], 'black',lw=2.0)\nplt.plot(np.linspace(ymin,ymax,100), slope_cross*np.linspace(ymin,ymax,100)+intercept_cross, \n         alpha = 0.8, color = 'red',ls='--',lw=1.0)\nplt.title('Cross Validation Plot: Truth vs. Estimated Value')\nplt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Truth (%)'); add_grid(); plt.xlim([ymin,ymax]); plt.ylim([ymin,ymax])\n\nplt.subplot(122)\nplt.plot(y_hat, residual, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')\nplt.plot([ymin,ymax], [0,0], 'black')\nplt.title('Cross Validation Residual Plot: Residual vs. Estimated Value')\nplt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Residual: True - Estimate (%)'); add_grid()\nplt.xlim([ymin,ymax]); plt.ylim([-10,10])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nidata = 0                                                     # select the dataset\n\nif idata == 0:\n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['Well'],axis=1,inplace=True)                 # remove well index and response feature\n\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax_new = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting\n    ymin_new = 0.0; ymax_new = 10000.0\n    xlabel_new = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\n\n    ylabel_new = 'Production (MCFPD)'\n\n    xtitle_new = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\n\n    ytitle_new = 'Production'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\nelif idata == 1:\n    names = {'Porosity':'Por'}\n\n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['X','Y','Unnamed: 0','Facies'],axis=1,inplace=True)   # remove response feature\n    df_new = df_new.rename(columns=names)\n    df_new['Por'] = df_new['Por'] * 100.0; df_new['AI'] = df_new['AI'] / 1000.0\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [4.0,0.0]; xmax_new = [19.0,500.0] # set the minimum and maximum values for plotting\n\n    ymin_new = 1.60; ymax_new = 6.20\n\n    xlabel_new = ['Porosity (fraction)','Permeability (mD)'] # set the names for plotting\n\n    ylabel_new = 'Acoustic Impedance (kg/m2s*10^6)'\n\n    xtitle_new = ['Porosity','Permeability']\n\n    ytitle_new = 'Acoustic Impedance (kg/m2s*10^6)'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\nelif idata == 2:  \n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['Well_ID','X','Y'],axis=1,inplace=True) # remove Well Index, X and Y coordinates, and response feature\n    df_new = df_new.dropna(how='any',inplace=False)\n\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax_new = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    ymin_new = 0.0; ymax_new = 1600.0\n\n    xlabel_new = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ylabel_new = 'Production (Mbbl)'\n\n    xtitle_new = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']\n\n    ytitle_new = 'Production'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\ndf_new.head(n=13) \n```", "```py\ndf_select = df_new.loc[:,['Por','Perm','AI']]\ndf_select \n```", "```py\ntest_prop = 0.2\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_prop, random_state=seed) # train and test split\nlinear_model_new = LinearRegression().fit(X_train,y_train)    # instantiate and train linear regression model, no hyperparmeters\n\ntrain_pred = linear_model_new.predict(X_train); test_pred = linear_model_new.predict(X_test) # predict at train and test samples \n\nplt.scatter(y_train,train_pred,color='green',edgecolor='black',label='Training') # cross validation plot\nplt.scatter(y_test,test_pred,color='white',edgecolor='black',label='Testing')\nplt.plot([ymin_new,ymax_new],[ymin_new,ymax_new],color='black',zorder=-1)\nplt.xlim(ymin_new,ymax_new); plt.ylim(ymin_new,ymax_new); add_grid() \nplt.xlabel('Truth: ' + ylabel_new); plt.ylabel('Estimate: ' + ylabel_new)\nplt.title('Linear Model Cross Validation'); plt.legend(loc='upper left')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nX_train \n```", "```py\nsuppress_warnings = False                                     # select to suppress warnings\nimport os                                                     # to set current working directory \nimport math                                                   # square root\nimport numpy as np                                            # arrays and matrix math\nimport scipy.stats as st                                      # statistical methods\nimport pandas as pd                                           # DataFrames\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nfrom sklearn.preprocessing import MinMaxScaler                # min/max normalization\nfrom sklearn.linear_model import LinearRegression             # linear regression\nfrom sklearn.model_selection import train_test_split          # train and test split\ncmap = plt.cm.inferno                                         # default color bar, no bias and friendly for color vision defeciency\nplt.rc('axes', axisbelow=True)                                # grid behind plotting elements\nif suppress_warnings == True:  \n    import warnings                                           # suppress any warnings for this demonstration\n    warnings.filterwarnings('ignore') \n```", "```py\ndef weighted_percentile(data, weights, perc):                 # calculate weighted percentile, iambr on StackOverflow \n    ix = np.argsort(data)                                     # https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049\n    data = data[ix] \n    weights = weights[ix] \n    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) \n    return np.interp(perc, cdf, data)\n\ndef histogram_bounds(values,weights,color):                   # add uncertainty bounds to a histogram \n    p10 = weighted_percentile(values,weights,0.1); avg = np.average(values,weights=weights); p90 = weighted_percentile(values,weights,0.9)\n    plt.plot([p10,p10],[0.0,45],color = color,linestyle='dashed')\n    plt.plot([avg,avg],[0.0,45],color = color)\n    plt.plot([p90,p90],[0.0,45],color = color,linestyle='dashed')\n\ndef add_grid():\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"C:\\PGE337\")                                        # set the working directory \n```", "```py\nadd_error = False                                             # add random error to the response feature for testing\nstd_error = 1.0; seed = 71071\n\nyname = 'Porosity'; xname = 'Density'                         # specify the predictor features (x2) and response feature (x1)\nxmin = 1.0; xmax = 2.5                                        # set minimums and maximums for visualization \nymin = 0.0; ymax = 25.0    \nyunit = '%'; xunit = '$g/cm^{3}$'    \nXlabelunit = xname + ' (' + xunit + ')'\nylabelunit = yname + ' (' + yunit + ')'\n\n#df = pd.read_csv(\"Density_Por_data.csv\")                     # load the data from local current directory\ndf = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/Density_Por_data.csv\") # load the data from my github repo\ndf = df.sample(frac=.30, random_state = 73073); df = df.reset_index() # extract 30% random to reduce the number of data\n\nif add_error == True:                                         # method to add error\n    np.random.seed(seed=seed)                                 # set random number seed\n    df[yname] = df[yname] + np.random.normal(loc = 0.0,scale=std_error,size=len(df)) # add noise\n    values = df._get_numeric_data(); values[values < 0] = 0   # set negative to 0 in a shallow copy ndarray\n\ndfy = pd.DataFrame(df[yname])                                 # extract selected features as X and y DataFrames\ndfx = pd.DataFrame(df[xname])\ndf = pd.concat([dfx,dfy],axis=1)                              # make one DataFrame with both X and y (remove all other features)\n\ny = df[yname].values.reshape(len(df))\nx = df[xname].values.reshape(len(df))\ndX = np.linspace(xmin,xmax,100)                               # values for plotting the model \n```", "```py\ndf \n```", "```py\ndf.head(n=13)                                                 # we could also use this command for a table preview \n```", "```py\ndf.describe().transpose()                                     # summary statistics \n```", "```py\nnbins = 20                                                    # number of histogram bins\n\nplt.subplot(221)\nfreq,_,_ = plt.hist(x=df[xname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\nhistogram_bounds(values=df[xname].values,weights=np.ones(len(df)),color='red')\nplt.xlabel(xname + ' (' + xunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Density'); add_grid()  \nplt.xlim([xmin,xmax])    \n\nplt.subplot(222)\nfreq,_,_ = plt.hist(x=df[yname],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\nhistogram_bounds(values=df[yname].values,weights=np.ones(len(df)),color='red')\nplt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.ylim([0.0,freq.max()*1.10]); plt.title('Porosity'); add_grid()  \nplt.xlim([ymin,ymax])  \n\nplt.subplot(223)                                              # plot the model\nplt.scatter(df[xname],df[yname],marker='o',label='data',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10)\nplt.title('Porosity vs Density')\nplt.xlabel(xname + ' (' + xunit + ')')\nplt.ylabel(yname + ' (' + yunit + ')')\nplt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)\n#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') \nplt.show() \n```", "```py\nimport scipy.stats as st                                    # statistical methods \n```", "```py\nslope, intercept, r_value, p_value, std_err = st.linregress(x,y) # instantiate and fit a linear regression model\n\nprint('The model parameters are, slope (b1) = ' + str(round(slope,2)) + ', and the intercept (b0) = ' + str(round(intercept,2))) \n```", "```py\nThe model parameters are, slope (b1) = -10.3, and the intercept (b0) = 30.03 \n```", "```py\nx_values = np.linspace(xmin,xmax,100)                         # return an array of density values \ny_model = slope * x_values + intercept                        # apply our linear regression model to estimate at the training data values\n\nplt.subplot(111)                                              # plot the model\nplt.plot(x, y, 'o', label='data', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black',zorder=10)\nplt.plot(x_values, y_model, label='model', color = 'black',zorder=1)\nplt.title('Linear Regression Model, Regression of ' + yname + ' on ' + xname)\nplt.xlabel(xname + ' (' + xunit + ')')\nplt.ylabel(yname + ' (' + yunit + ')')\nplt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])\n\nplt.annotate('Linear Regression Model',[1.25,5.7])\nplt.annotate(r'    $\\beta_1$ :' + str(round(slope,2)),[1.6,4.1])\nplt.annotate(r'    $\\beta_0$ :' + str(round(intercept,2)),[1.6,2.5])\nplt.annotate(r'$N[\\phi] = \\beta_1 \\times z + \\beta_0$',[1.1,4.1])\nplt.annotate(r'$N[\\phi] = $' + str(round(slope,2)) + r' $\\times$ $z$ + (' + str(round(intercept,2)) + ')',[1.1,2.5])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nprint('Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = ' + str(p_value) + '.') \n```", "```py\nTwo-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero = 2.2197132981703346e-09. \n```", "```py\nalpha = 0.05\nt_critical = st.t.ppf([alpha/2,1-alpha/2], df=len(x)-2)\nprint('The t-critical lower and upper values are ' + str(np.round(t_critical,2)))\nprint('and the t-statistic is ' + str(round(slope/std_err,2))) \n```", "```py\nThe t-critical lower and upper values are [-2.04  2.04]\nand the t-statistic is -8.4 \n```", "```py\nprint('The correlation coefficient is = ' + str(round(r_value,2)) + ' and the r-squared value = ', str(round(r_value**2,2))) \n```", "```py\nThe correlation coefficient is = -0.84 and the r-squared value =  0.7 \n```", "```py\nprint('The slope confidence interval is ' + str(round(slope,2)) + ' +/- ' + str(round(t_critical[1] * std_err,2)))\nCI_slope = slope + t_critical*std_err\nprint('The slope P02.5 and P97.5 are ' + str(np.round(CI_slope,2))) \n```", "```py\nThe slope confidence interval is -10.3 +/- 2.5\nThe slope P02.5 and P97.5 are [-12.8  -7.8] \n```", "```py\nalpha = 0.05\ntstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)            # calculate t-stat for confidence interval\nslope_lower,slope_upper = slope + tstat*std_err # calculate the lower and upper confidence interval for b1\n\nplt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=10)\nplt.plot(dX, intercept + slope*dX, 'black', label='linear regression model')\nplt.plot(dX, intercept + slope_upper*dX, 'black',ls='--',lw=1,label=r'alpha = ' + str(alpha) + ' confidence interval')\nplt.plot(dX, intercept + slope_lower*dX, 'black',ls='--',lw=1)\nplt.annotate('The model parameters confidence intervals at ' + str(1-alpha) + ' significance level:',[1.3,24])\nplt.annotate('Slope: P' + str(alpha/2*100) + ' = '+ str(round(slope_lower,2)) + ' , P' + str((1-alpha/2)*100) + ' = ' + str(round(slope_upper,2)),[1.5,23])\nplt.fill_between(dX,intercept + slope_upper*dX,intercept + slope_lower*dX,color='red',alpha=0.3,zorder=1)\nplt.title('Sample Data, Linear Regression Model and Slope Confidence Intervals'); plt.xlabel(r'Density ($g/cm^3$)'); plt.ylabel('Porosity (%)')\nplt.legend(loc='lower left'); add_grid(); plt.ylim([ymin,ymax]); plt.xlim([xmin,xmax])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.1, hspace=0.2); plt.show() \n```", "```py\nnew_X = 2.00\nalpha = 0.05\n\ntstat = st.t.ppf([alpha/2,1-alpha/2], len(x)-2)\n\nyhat = intercept + slope*x\nMSE = np.sum(np.power(y-yhat,2))/(len(y)-2) # mean square error\nest_stderr = math.sqrt(MSE) \\\n      *math.sqrt(1 + 1/len(y) + np.power(new_X - np.average(x),2)/ \\\n      np.sum(np.power(x-np.average(x),2)))\n\ny_pred_lower, y_pred_upper = intercept + slope*new_X + tstat*est_stderr\n\nplt.scatter(x, y, color = 'darkorange',edgecolor='black',alpha=0.8,label='sample data',zorder=1)\nplt.plot(dX, intercept + slope*dX, 'black', label='linear regression model',zorder=1)\nplt.scatter(new_X, intercept + slope*new_X,s=80,color='yellow',edgecolor='black',label=r'prediction, $\\hat{y}$',zorder=2)\nplt.plot([new_X,new_X],[y_pred_lower,y_pred_upper],color='black',linestyle='dashed',zorder=1,label='prediction interval')\nplt.title(r'Sample Data, Linear Regression Model and Prediction Interval, $\\alpha = $' + str(alpha)); plt.xlabel(r'Density ($g/cm^3$)'); \nplt.ylabel('Porosity (%)')\nplt.legend(); add_grid(); plt.ylim([4,22]); plt.xlim([1.0,2.4])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.4, wspace=0.1, hspace=0.2); plt.show() \n```", "```py\ny_hat = slope * x + intercept\nplt.subplot(111)\nplt.hist(y_hat, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(5,20,40))\nplt.xlabel(yname + ' (' + yunit + ')'); plt.ylabel('Frequency'); plt.title(yname + ' Predictions'); plt.xlim([ymin,ymax])\nadd_grid()\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nplt.subplot(111)\nplt.plot(x, y, 'o', label='training data',color = 'darkorange', alpha = 1.0, markeredgecolor = 'black',zorder=10)\nplt.scatter(x, y_hat,s=10,marker='o',label='prediction',color = 'grey',edgecolor='black',alpha=1.0,zorder=10)\nplt.plot(dX,dX*slope+intercept,color='red',lw=2,zorder=2,label='model')\nfor idata in range(0,len(x)):\n    if idata == 0:\n        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey',label=r'$\\Delta_{y_i}$',zorder=1)\n    else:  \n        plt.plot([x[idata],x[idata]],[y[idata],y_hat[idata]],color='grey')\nplt.title('Comparison of Training Data vs. Model')\nplt.xlabel(xname + ' (' + xunit + ')')\nplt.ylabel(yname + ' (' + yunit + ')')\nplt.legend(); add_grid(); plt.xlim([xmin,xmax]); plt.ylim([ymin,ymax])\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nresidual = y - y_hat\n\nplt.subplot(111)\nplt.hist(residual, color = 'darkorange', alpha = 0.8, edgecolor = 'black', bins = np.linspace(-4,4,30))\nplt.title(\"Error Residual at Training Data\"); plt.xlabel(yname + ' True - Estimate (%)');plt.ylabel('Frequency'); add_grid()\nplt.vlines(0,0,4.2,color='red',lw=2,zorder=1); plt.vlines(np.average(residual),0,4.2,color='black',ls='--',zorder=10); plt.ylim([0,4.2])\nplt.annotate('Residual Average = ' + str(np.round(np.average(residual),2)),[np.average(residual)-0.2,2.5],rotation=90.0)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.2); plt.show()\n\nprint('The average of the residuals is ' + str(round(np.mean(residual),2))) \n```", "```py\nThe average of the residuals is 0.0 \n```", "```py\nslope_cross, intercept_cross, _, _, _ = st.linregress(y_hat,y) # check for conditional bias with a linear fit to the cross validation plot\n\nplt.subplot(121)\nplt.plot(y_hat, y, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')\nplt.plot([ymin,ymax], [ymin,ymax], 'black',lw=2.0)\nplt.plot(np.linspace(ymin,ymax,100), slope_cross*np.linspace(ymin,ymax,100)+intercept_cross, \n         alpha = 0.8, color = 'red',ls='--',lw=1.0)\nplt.title('Cross Validation Plot: Truth vs. Estimated Value')\nplt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Truth (%)'); add_grid(); plt.xlim([ymin,ymax]); plt.ylim([ymin,ymax])\n\nplt.subplot(122)\nplt.plot(y_hat, residual, 'o', color = 'darkorange', alpha = 0.8, markeredgecolor = 'black')\nplt.plot([ymin,ymax], [0,0], 'black')\nplt.title('Cross Validation Residual Plot: Residual vs. Estimated Value')\nplt.xlabel(yname + ' Estimate (%)'); plt.ylabel(yname + ' Residual: True - Estimate (%)'); add_grid()\nplt.xlim([ymin,ymax]); plt.ylim([-10,10])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nidata = 0                                                     # select the dataset\n\nif idata == 0:\n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['Well'],axis=1,inplace=True)                 # remove well index and response feature\n\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax_new = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting\n    ymin_new = 0.0; ymax_new = 10000.0\n    xlabel_new = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\n\n    ylabel_new = 'Production (MCFPD)'\n\n    xtitle_new = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\n\n    ytitle_new = 'Production'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\nelif idata == 1:\n    names = {'Porosity':'Por'}\n\n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['X','Y','Unnamed: 0','Facies'],axis=1,inplace=True)   # remove response feature\n    df_new = df_new.rename(columns=names)\n    df_new['Por'] = df_new['Por'] * 100.0; df_new['AI'] = df_new['AI'] / 1000.0\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [4.0,0.0]; xmax_new = [19.0,500.0] # set the minimum and maximum values for plotting\n\n    ymin_new = 1.60; ymax_new = 6.20\n\n    xlabel_new = ['Porosity (fraction)','Permeability (mD)'] # set the names for plotting\n\n    ylabel_new = 'Acoustic Impedance (kg/m2s*10^6)'\n\n    xtitle_new = ['Porosity','Permeability']\n\n    ytitle_new = 'Acoustic Impedance (kg/m2s*10^6)'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\nelif idata == 2:  \n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['Well_ID','X','Y'],axis=1,inplace=True) # remove Well Index, X and Y coordinates, and response feature\n    df_new = df_new.dropna(how='any',inplace=False)\n\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax_new = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    ymin_new = 0.0; ymax_new = 1600.0\n\n    xlabel_new = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ylabel_new = 'Production (Mbbl)'\n\n    xtitle_new = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']\n\n    ytitle_new = 'Production'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\ndf_new.head(n=13) \n```", "```py\ndf_select = df_new.loc[:,['Por','Perm','AI']]\ndf_select \n```", "```py\ntest_prop = 0.2\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_prop, random_state=seed) # train and test split\nlinear_model_new = LinearRegression().fit(X_train,y_train)    # instantiate and train linear regression model, no hyperparmeters\n\ntrain_pred = linear_model_new.predict(X_train); test_pred = linear_model_new.predict(X_test) # predict at train and test samples \n\nplt.scatter(y_train,train_pred,color='green',edgecolor='black',label='Training') # cross validation plot\nplt.scatter(y_test,test_pred,color='white',edgecolor='black',label='Testing')\nplt.plot([ymin_new,ymax_new],[ymin_new,ymax_new],color='black',zorder=-1)\nplt.xlim(ymin_new,ymax_new); plt.ylim(ymin_new,ymax_new); add_grid() \nplt.xlabel('Truth: ' + ylabel_new); plt.ylabel('Estimate: ' + ylabel_new)\nplt.title('Linear Model Cross Validation'); plt.legend(loc='upper left')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nX_train \n```", "```py\nidata = 0                                                     # select the dataset\n\nif idata == 0:\n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['Well'],axis=1,inplace=True)                 # remove well index and response feature\n\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax_new = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minimum and maximum values for plotting\n    ymin_new = 0.0; ymax_new = 10000.0\n    xlabel_new = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\n\n    ylabel_new = 'Production (MCFPD)'\n\n    xtitle_new = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\n\n    ytitle_new = 'Production'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\nelif idata == 1:\n    names = {'Porosity':'Por'}\n\n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['X','Y','Unnamed: 0','Facies'],axis=1,inplace=True)   # remove response feature\n    df_new = df_new.rename(columns=names)\n    df_new['Por'] = df_new['Por'] * 100.0; df_new['AI'] = df_new['AI'] / 1000.0\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [4.0,0.0]; xmax_new = [19.0,500.0] # set the minimum and maximum values for plotting\n\n    ymin_new = 1.60; ymax_new = 6.20\n\n    xlabel_new = ['Porosity (fraction)','Permeability (mD)'] # set the names for plotting\n\n    ylabel_new = 'Acoustic Impedance (kg/m2s*10^6)'\n\n    xtitle_new = ['Porosity','Permeability']\n\n    ytitle_new = 'Acoustic Impedance (kg/m2s*10^6)'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\nelif idata == 2:  \n    df_new = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv') # load data from Dr. Pyrcz's GitHub repository \n    df_new.drop(['Well_ID','X','Y'],axis=1,inplace=True) # remove Well Index, X and Y coordinates, and response feature\n    df_new = df_new.dropna(how='any',inplace=False)\n\n    features = df_new.columns.values.tolist()                 # store the names of the features\n\n    xname = features[:-1]\n    yname = [features[-1]]\n\n    xmin_new = [1,0.0,0.0,4.0,0.0,6.5,1.4,1600.0,10.0,1300.0,1.6]; xmax_new = [73,10000.0,10000.0,19.0,500.0,8.3,3.6,6200.0,50.0,2000.0,12.0] # set the minimum and maximum values for plotting\n\n    ymin_new = 0.0; ymax_new = 1600.0\n\n    xlabel_new = ['Well (ID)','X (m)','Y (m)','Depth (m)','Porosity (fraction)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Facies (categorical)',\n              'Density (g/cm^3)','Compressible velocity (m/s)','Youngs modulus (GPa)', 'Shear velocity (m/s)', 'Shear modulus (GPa)'] # set the names for plotting\n\n    ylabel_new = 'Production (Mbbl)'\n\n    xtitle_new = ['Well','X','Y','Depth','Porosity','Permeability','Acoustic Impedance','Facies',\n              'Density','Compressible velocity','Youngs modulus', 'Shear velocity', 'Shear modulus']\n\n    ytitle_new = 'Production'\n\n    y = pd.DataFrame(df_new[yname])                              # extract selected features as X and y DataFrames \n    X = df_new[xname]\n\ndf_new.head(n=13) \n```", "```py\ndf_select = df_new.loc[:,['Por','Perm','AI']]\ndf_select \n```", "```py\ntest_prop = 0.2\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_prop, random_state=seed) # train and test split\nlinear_model_new = LinearRegression().fit(X_train,y_train)    # instantiate and train linear regression model, no hyperparmeters\n\ntrain_pred = linear_model_new.predict(X_train); test_pred = linear_model_new.predict(X_test) # predict at train and test samples \n\nplt.scatter(y_train,train_pred,color='green',edgecolor='black',label='Training') # cross validation plot\nplt.scatter(y_test,test_pred,color='white',edgecolor='black',label='Testing')\nplt.plot([ymin_new,ymax_new],[ymin_new,ymax_new],color='black',zorder=-1)\nplt.xlim(ymin_new,ymax_new); plt.ylim(ymin_new,ymax_new); add_grid() \nplt.xlabel('Truth: ' + ylabel_new); plt.ylabel('Estimate: ' + ylabel_new)\nplt.title('Linear Model Cross Validation'); plt.legend(loc='upper left')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nX_train \n```"]