- en: 7.3 Objective functions, metrics, and evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huyenchip.com/ml-interviews-book/contents/7.3-objective-functions,-metrics,-and-evaluation.html](https://huyenchip.com/ml-interviews-book/contents/7.3-objective-functions,-metrics,-and-evaluation.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Convergence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] When we say an algorithm converges, what does convergence mean?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] How do we know when a model has converged?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] Draw the loss curves for overfitting and underfitting.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bias-variance trade-off
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] What’s the bias-variance trade-off?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] How’s this tradeoff related to overfitting and underfitting?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] How do you know that your model is high variance, low bias? What would
    you do in this case?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] How do you know that your model is low variance, high bias? What would
    you do in this case?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Cross-validation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] Explain different methods for cross-validation.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] Why don’t we see more cross-validation in deep learning?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Train, valid, test splits.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] What’s wrong with training and testing a model on the same data?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] Why do we need a validation set on top of a train set and a test set?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] Your model’s loss curves on the train, valid, and test sets look like this.
    What might have been the cause of this? What would you do?![Problematic loss curves](../Images/d5852d1412ffaf6b2f4afe31c459b3f2.png
    "image_tooltip")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] Your team is building a system to aid doctors in predicting whether a patient
    has cancer or not from their X-ray scan. Your colleague announces that the problem
    is solved now that they’ve built a system that can predict with 99.99% accuracy.
    How would you respond to that claim?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: F1 score.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] What’s the benefit of F1 over the accuracy?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] Can we still use F1 for a problem with more than two classes. How?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Given a binary classifier that outputs the following confusion matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '|  | Predicted True | Predicted False |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Actual True | 30 | 20 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Actual False | 5 | 40 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '[E] Calculate the model’s precision, recall, and F1.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] What can we do to improve the model’s performance?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider a classification where 99% of data belongs to class A and 1% of data
    belongs to class B.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] If your model predicts A 100% of the time, what would the F1 score be?
    **Hint**: The F1 score when A is mapped to 0 and B to 1 is different from the
    F1 score when A is mapped to 1 and B to 0.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] If we have a model that predicts A and B at a random (uniformly), what
    would the expected F1 be?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] For logistic regression, why is log loss recommended over MSE (mean squared
    error)?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] When should we use RMSE (Root Mean Squared Error) over MAE (Mean Absolute
    Error) and vice versa?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] Show that the negative log-likelihood and cross-entropy are the same for
    binary classification tasks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] For classification tasks with more than two labels (e.g. MNIST with 10
    labels), why is cross-entropy a better loss function than MSE?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] Consider a language with an alphabet of 27 characters. What would be the
    maximal entropy of this language?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] A lot of machine learning models aim to approximate probability distributions.
    Let’s say P is the distribution of the data and Q is the distribution learned
    by our model. How do measure how close Q is to P?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: MPE (Most Probable Explanation) vs. MAP (Maximum A Posteriori)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] How do MPE and MAP differ?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] Give an example of when they would produce different results.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] Suppose you want to build a model to predict the price of a stock in the
    next 8 hours and that the predicted price should never be off more than 10% from
    the actual price. Which metric would you use?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Hint**: check out MAPE.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In case you need a refresh on information entropy, here's an explanation without
    any math.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Your parents are finally letting you adopt a pet! They spend the entire weekend
    taking you to various pet shelters to find a pet.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The first shelter has only dogs. Your mom covers your eyes when your dad picks
    out an animal for you. You don't need to open your eyes to know that this animal
    is a dog. It isn't hard to guess.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The second shelter has both dogs and cats. Again your mom covers your eyes and
    your dad picks out an email. This time, you have to think harder to guess which
    animal is that. You make a guess that it's a dog, and your dad says no. So you
    guess it's a cat and you're right. It takes you two guesses to know for sure what
    animal it is.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The next shelter is the biggest one of them all. They have so many different
    kinds of animals: dogs, cats, hamsters, fish, parrots, cute little pigs, bunnies,
    ferrets, hedgehogs, chickens, even the exotic bearded dragons! There must be close
    to a hundred different types of pets. Now it''s really hard for you to guess which
    one your dad brings you. It takes you a dozen guesses to guess the right animal.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Entropy is a measure of the "spread out" in diversity. The more spread out the
    diversity, the header it is to guess an item correctly. The first shelter has
    very low entropy. The second shelter has a little bit higher entropy. The third
    shelter has the highest entropy.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
