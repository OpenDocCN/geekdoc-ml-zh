<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch042.xhtml</title>
  <style>
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    /* Figure formatting */
    .quarto-layout-panel>figure>figcaption,
    .quarto-layout-panel>.panel-caption {
      margin-top: 10pt;
    }

    .quarto-layout-row {
      display: flex;
      align-items: flex-start;
    }

    .quarto-layout-valign-top {
      align-items: flex-start;
    }

    .quarto-layout-valign-bottom {
      align-items: flex-end;
    }

    .quarto-layout-valign-center {
      align-items: center;
    }

    .quarto-layout-cell {
      position: relative;
      margin-right: 20px;
    }

    .quarto-layout-cell:last-child {
      margin-right: 0;
    }

    .quarto-layout-cell figure,
    .quarto-layout-cell>p {
      margin: 0.2em;
    }

    .quarto-layout-cell .html-widget {
      width: 100% !important;
    }

    .quarto-layout-cell div figure p {
      margin: 0;
    }

    .quarto-layout-cell figure {
      display: inline-block;
      margin-inline-start: 0;
      margin-inline-end: 0;
    }

    .quarto-layout-cell table {
      display: inline-table;
    }

    .quarto-layout-cell-subref figcaption {
      font-style: italic;
      text-align: center;
    }

    .quarto-figure>figure {
      width: 100%;
    }

    .quarto-figure-left>figure>p {
      text-align: left;
    }

    .quarto-figure-center>figure>p {
      text-align: center;
    }

    .quarto-figure-right>figure>p {
      text-align: right;
    }

    figure>p:empty {
      display: none;
    }

    figure>p:first-child {
      margin-top: 0;
      margin-bottom: 0;
    }

    figure>figcaption {
      margin-top: 0.5em;
    }

    figcaption {
      font-size: 0.8em;
    }

    details {
      margin-bottom: 1em;
    }

    details[show] {
      margin-bottom: 0;
    }

    .quarto-unresolved-ref {
      font-weight: 600;
    }

    .quarto-cover-image {
      float: right;
      margin-left: 30px;
    }

    .cell-output-display {
      overflow-x: scroll;
    }

    .hidden {
      display: none;
    }
  </style>
</head>
<body epub:type="bodymatter">
<section id="keyword-spotting-kws-1" class="level1 unnumbered">
<h1 class="unnumbered">Keyword Spotting (KWS)</h1>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="../media/file622.png" alt="" /></p>
<figcaption><em>DALL·E prompt - 1950s style cartoon illustration based on a real image by Marcelo Rovai</em></figcaption>
</figure>
</div>
<section id="sec-keyword-spotting-kws-overview-4373" class="level2 unnumbered">
<h2 class="unnumbered">Overview</h2>
<p>Keyword Spotting (KWS) is integral to many voice recognition systems, enabling devices to respond to specific words or phrases. While this technology underpins popular devices like Google Assistant or Amazon Alexa, it’s equally applicable and achievable on smaller, low-power devices. This lab will guide you through implementing a KWS system using TinyML on the XIAO ESP32S3 microcontroller board.</p>
<p>The XIAO ESP32S3, equipped with Espressif’s ESP32-S3 chip, is a compact and potent microcontroller offering a dual-core Xtensa LX7 processor, integrated Wi-Fi, and Bluetooth. Its balance of computational power, energy efficiency, and versatile connectivity makes it a fantastic platform for TinyML applications. Also, with its expansion board, we will have access to the “sense” part of the device, which has a camera, an SD card slot, and a <strong>digital microphone</strong>. The integrated microphone and the SD card will be essential in this project.</p>
<p>We will use the <a href="https://www.edgeimpulse.com/">Edge Impulse Studio</a>, a powerful, user-friendly platform that simplifies creating and deploying machine learning models onto edge devices. We’ll train a KWS model step-by-step, optimizing and deploying it onto the XIAO ESP32S3 Sense.</p>
<p>Our model will be designed to recognize keywords that can trigger device wake-up or specific actions (in the case of “YES”), bringing your projects to life with voice-activated commands.</p>
<p>Leveraging our experience with TensorFlow Lite for Microcontrollers (the engine “under the hood” on the EI Studio), we’ll create a KWS system capable of real-time machine learning on the device.</p>
<p>As we progress through the lab, we’ll break down each process stage – from data collection and preparation to model training and deployment – to provide a comprehensive understanding of implementing a KWS system on a microcontroller.</p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Learning Objectives</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Understand Voice Assistant Architecture</strong> including cascaded detection systems and the role of edge-based keyword spotting as the first stage of voice processing pipelines</li>
<li><strong>Master Audio Data Collection Techniques</strong> using both offline methods (XIAO ESP32S3 microphone with SD card storage) and online methods (smartphone integration with Edge Impulse Studio)</li>
<li><strong>Implement Digital Signal Processing for Audio</strong> including I2S protocol fundamentals, audio sampling at 16kHz/16-bit, and conversion between time-domain audio signals and frequency-domain features using MFCC</li>
<li><strong>Train Convolutional Neural Networks for Audio Classification</strong> using transfer learning techniques, data augmentation strategies, and model optimization for four-class classification (YES, NO, NOISE, UNKNOWN)</li>
<li><strong>Deploy Optimized Models on Microcontrollers</strong> through quantization (INT8), memory management with PSRAM, and real-time inference optimization for embedded systems</li>
<li><strong>Develop Complete Post-Processing Pipelines</strong> including confidence thresholding, GPIO control for external devices, OLED display integration, and creating standalone AI sensor systems</li>
<li><strong>Compare Development Workflows</strong> between no-code platforms (Edge Impulse Studio) and traditional embedded programming (Arduino IDE) for TinyML applications</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sec-keyword-spotting-kws-kws-project-639f" class="level2 unnumbered">
<h2 class="unnumbered">The KWS Project</h2>
<section id="sec-keyword-spotting-kws-voice-assistant-work-dbbe" class="level3 unnumbered">
<h3 class="unnumbered">How does a voice assistant work?</h3>
<p>Keyword Spotting (KWS) is critical to many voice assistants, enabling devices to respond to specific words or phrases. To start, it is essential to realize that Voice Assistants on the market, like Google Home or Amazon Echo-Dot, only react to humans when they are “waked up” by particular keywords such as “ Hey Google” on the first one and “Alexa” on the second.</p>
<p> <img src="../media/file623.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
<p>In other words, recognizing voice commands is based on a multi-stage model or Cascade Detection.</p>
<p> <img src="../media/file624.png" alt="" /></p>
<p><strong>Stage 1</strong>: A smaller microprocessor inside the Echo Dot or Google Home <strong>continuously</strong> listens to the sound, waiting for the keyword to be spotted. For such detection, a TinyML model at the edge is used (KWS application).</p>
<p><strong>Stage 2</strong>: Only when triggered by the KWS application on Stage 1 is the data sent to the cloud and processed on a larger model.</p>
<p>The video below shows an example where I emulate a Google Assistant on a Raspberry Pi (Stage 2), having an Arduino Nano 33 BLE as the tinyML device (Stage 1).</p>
<blockquote>
<p>If you want to go deeper on the full project, please see my tutorial: <a href="https://www.hackster.io/mjrobot/building-an-intelligent-voice-assistant-from-scratch-2199c3">Building an Intelligent Voice Assistant From Scratch</a>.</p>
</blockquote>
<p>In this lab, we will focus on Stage 1 (KWS or Keyword Spotting), where we will use the XIAO ESP2S3 Sense, which has a digital microphone for spotting the keyword.</p>
</section>
<section id="sec-keyword-spotting-kws-inference-pipeline-df53" class="level3 unnumbered">
<h3 class="unnumbered">The Inference Pipeline</h3>
<p>The diagram below will give an idea of how the final KWS application should work (during inference):</p>
<p> <img src="../media/file625.png" alt="" /></p>
<p>Our KWS application will recognize four classes of sound:</p>
<ul>
<li><strong>YES</strong> (Keyword 1)</li>
<li><strong>NO</strong> (Keyword 2)</li>
<li><strong>NOISE</strong> (no keywords spoken, only background noise is present)</li>
<li><strong>UNKNOWN</strong> (a mix of different words than YES and NO)</li>
</ul>
<blockquote>
<p>Optionally for real-world projects, it is always advised to include different words than keywords, such as “Noise” (or Background) and “Unknown.”</p>
</blockquote>
</section>
<section id="sec-keyword-spotting-kws-machine-learning-workflow-17f6" class="level3 unnumbered">
<h3 class="unnumbered">The Machine Learning workflow</h3>
<p>The main component of the KWS application is its model. So, we must train such a model with our specific keywords, noise, and other words (the “unknown”):</p>
<p> <img src="../media/file626.png" alt="" /></p>
</section>
</section>
<section id="sec-keyword-spotting-kws-dataset-6ea2" class="level2 unnumbered">
<h2 class="unnumbered">Dataset</h2>
<p>The critical component of Machine Learning Workflow is the <strong>dataset</strong>. Once we have decided on specific keywords (<em>YES</em> and NO), we can take advantage of the dataset developed by Pete Warden, <a href="https://arxiv.org/pdf/1804.03209.pdf">“Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition</a>.” This dataset has 35 keywords (with +1,000 samples each), such as yes, no, stop, and go. In other words, we can get 1,500 samples of <em>yes</em> and <em>no</em>.</p>
<p>You can download a small portion of the dataset from Edge Studio (<a href="https://docs.edgeimpulse.com/docs/pre-built-datasets/keyword-spotting">Keyword spotting pre-built dataset</a>), which includes samples from the four classes we will use in this project: yes, no, noise, and background. For this, follow the steps below:</p>
<ul>
<li>Download the <a href="https://cdn.edgeimpulse.com/datasets/keywords2.zip">keywords dataset.</a></li>
<li>Unzip the file in a location of your choice.</li>
</ul>
<p>Although we have a lot of data from Pete’s dataset, collecting some words spoken by us is advised. When working with accelerometers, creating a dataset with data captured by the same type of sensor was essential. In the case of <em>sound</em>, the classification differs because it involves, in reality, <em>audio</em> data.</p>
<blockquote>
<p>The key difference between sound and audio is their form of energy. Sound is mechanical wave energy (longitudinal sound waves) that propagate through a medium causing variations in pressure within the medium. Audio is made of electrical energy (analog or digital signals) that represent sound electrically.</p>
</blockquote>
<p>The sound waves should be converted to audio data when we speak a keyword. The conversion should be done by sampling the signal generated by the microphone in 16 kHz with a 16-bit depth.</p>
<p>So, any device that can generate audio data with this basic specification (16 kHz/16 bits) will work fine. As a device, we can use the proper XIAO ESP32S3 Sense, a computer, or even your mobile phone.</p>
<p> <img src="../media/file627.png" alt="" /></p>
<p><strong>Capturing online Audio Data with Edge Impulse and a smartphone</strong></p>
<p>In the lab Motion Classification and Anomaly Detection, we connect our device directly to Edge Impulse Studio for data capturing (having a sampling frequency of 50 Hz to 100 Hz). For such low frequency, we could use the EI CLI function <em>Data Forwarder,</em> but according to Jan Jongboom, Edge Impulse CTO, <em>audio (</em>16 kHz) <em>goes too fast for the data forwarder to be captured.</em> So, once we have the digital data captured by the microphone, we can turn <em>it into a WAV file</em> to be sent to the Studio via Data Uploader (same as we will do with Pete’s dataset)<em>.</em></p>
<blockquote>
<p>If we want to collect audio data directly on the Studio, we can use any smartphone connected online with it. We will not explore this option here, but you can easily follow EI <a href="https://docs.edgeimpulse.com/docs/development-platforms/using-your-mobile-phone">documentation</a>.</p>
</blockquote>
<section id="sec-keyword-spotting-kws-capturing-offline-audio-data-xiao-esp32s3-sense-5dbc" class="level3 unnumbered">
<h3 class="unnumbered">Capturing (offline) Audio Data with the XIAO ESP32S3 Sense</h3>
<p>The built-in microphone is the <a href="https://files.seeedstudio.com/wiki/XIAO-BLE/mic-MSM261D3526H1CPM-ENG.pdf">MSM261D3526H1CPM</a>, a PDM digital output MEMS microphone with Multi-modes. Internally, it is connected to the ESP32S3 via an I2S bus using pins IO41 (Clock) and IO41 (Data).</p>
<p> <img src="../media/file628.png" alt="" /></p>
<p><strong>What is I2S?</strong></p>
<p>I2S, or Inter-IC Sound, is a standard protocol for transmitting digital audio from one device to another. It was initially developed by Philips Semiconductor (now NXP Semiconductors). It is commonly used in audio devices such as digital signal processors, digital audio processors, and, more recently, microcontrollers with digital audio capabilities (our case here).</p>
<p>The I2S protocol consists of at least three lines:</p>
<p> <img src="../media/file629.png" class="quarto-figure quarto-figure-center" style="width:60.0%" alt="" /></p>
<p><strong>1. Bit (or Serial) clock line (BCLK or CLK)</strong>: This line toggles to indicate the start of a new bit of data (pin IO42).</p>
<p><strong>2. Word select line (WS)</strong>: This line toggles to indicate the start of a new word (left channel or right channel). The Word select clock (WS) frequency defines the sample rate. In our case, L/R on the microphone is set to ground, meaning that we will use only the left channel (mono).</p>
<p><strong>3. Data line (SD)</strong>: This line carries the audio data (pin IO41)</p>
<p>In an I2S data stream, the data is sent as a sequence of frames, each containing a left-channel word and a right-channel word. This makes I2S particularly suited for transmitting stereo audio data. However, it can also be used for mono or multichannel audio with additional data lines.</p>
<p>Let’s start understanding how to capture raw data using the microphone. Go to the <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense">GitHub project</a> and download the sketch: <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/Mic_Test/XiaoEsp32s3_Mic_Test">XIAOEsp2s3_Mic_Test</a>:</p>
<blockquote>
<p>⚠️ <strong>Attention</strong></p>
<ul>
<li>The Xiao ESP32S3 <strong>MUST</strong> have the PSRAM enabled. You can check it on the Arduino IDE upper menu: <code>Tools</code>–&gt; <code>PSRAM:OPI PSRAM</code></li>
<li>The Arduino Library (<code>esp32 by Espressif Systems</code> should be <strong>version 2.017</strong>. Please do not update it.</li>
</ul>
</blockquote>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">/*</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co">  XIAO ESP32S3 Simple Mic Test</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">*/</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="pp">#include </span><span class="im">&lt;I2S.h&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="dt">void</span> setup<span class="op">()</span> <span class="op">{</span></span>
<span id="cb1-8"><a href="#cb1-8"></a>  Serial<span class="op">.</span>begin<span class="op">(</span><span class="dv">115200</span><span class="op">);</span></span>
<span id="cb1-9"><a href="#cb1-9"></a>  <span class="cf">while</span> <span class="op">(!</span>Serial<span class="op">)</span> <span class="op">{</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>  <span class="op">}</span></span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a>  <span class="co">// start I2S at 16 kHz with 16-bits per sample</span></span>
<span id="cb1-13"><a href="#cb1-13"></a>  I2S<span class="op">.</span>setAllPins<span class="op">(-</span><span class="dv">1</span><span class="op">,</span> <span class="dv">42</span><span class="op">,</span> <span class="dv">41</span><span class="op">,</span> <span class="op">-</span><span class="dv">1</span><span class="op">,</span> <span class="op">-</span><span class="dv">1</span><span class="op">);</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>  <span class="cf">if</span> <span class="op">(!</span>I2S<span class="op">.</span>begin<span class="op">(</span>PDM_MONO_MODE<span class="op">,</span> <span class="dv">16000</span><span class="op">,</span> <span class="dv">16</span><span class="op">))</span> <span class="op">{</span></span>
<span id="cb1-15"><a href="#cb1-15"></a>    Serial<span class="op">.</span>println<span class="op">(</span><span class="st">&quot;Failed to initialize I2S!&quot;</span><span class="op">);</span></span>
<span id="cb1-16"><a href="#cb1-16"></a>    <span class="cf">while</span> <span class="op">(</span><span class="dv">1</span><span class="op">);</span> <span class="co">// do nothing</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>  <span class="op">}</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="op">}</span></span>
<span id="cb1-19"><a href="#cb1-19"></a></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="dt">void</span> loop<span class="op">()</span> <span class="op">{</span></span>
<span id="cb1-21"><a href="#cb1-21"></a>  <span class="co">// read a sample</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>  <span class="dt">int</span> sample <span class="op">=</span> I2S<span class="op">.</span>read<span class="op">();</span></span>
<span id="cb1-23"><a href="#cb1-23"></a></span>
<span id="cb1-24"><a href="#cb1-24"></a>  <span class="cf">if</span> <span class="op">(</span>sample <span class="op">&amp;&amp;</span> sample <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span> <span class="op">&amp;&amp;</span> sample <span class="op">!=</span> <span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb1-25"><a href="#cb1-25"></a>    Serial<span class="op">.</span>println<span class="op">(</span>sample<span class="op">);</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>  <span class="op">}</span></span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="op">}</span></span></code></pre></div>
<p>This code is a simple microphone test for the XIAO ESP32S3 using the I2S (Inter-IC Sound) interface. It sets up the I2S interface to capture audio data at a sample rate of 16 kHz with 16 bits per sample and then continuously reads samples from the microphone and prints them to the serial monitor.</p>
<p>Let’s dig into the code’s main parts:</p>
<ul>
<li>Include the I2S library: This library provides functions to configure and use the <a href="https://espressif-docs.readthedocs-hosted.com/projects/arduino-esp32/en/latest/api/i2s.html">I2S interface</a>, which is a standard for connecting digital audio devices.</li>
<li>I2S.setAllPins(–1, 42, 41, –1, –1): This sets up the I2S pins. The parameters are (–1, 42, 41, –1, –1), where the second parameter (42) is the PIN for the I2S clock (CLK), and the third parameter (41) is the PIN for the I2S data (DATA) line. The other parameters are set to –1, meaning those pins are not used.</li>
<li>I2S.begin(PDM_MONO_MODE, 16000, 16): This initializes the I2S interface in Pulse Density Modulation (PDM) mono mode, with a sample rate of 16 kHz and 16 bits per sample. If the initialization fails, an error message is printed, and the program halts.</li>
<li>int sample = I2S.read(): This reads an audio sample from the I2S interface.</li>
</ul>
<p>If the sample is valid, it is printed on the Serial Monitor and Plotter.</p>
<p>Below is a test “whispering” in two different tones.</p>
<p> <img src="../media/file630.png" alt="" /></p>
</section>
<section id="sec-keyword-spotting-kws-save-recorded-sound-samples-3d1d" class="level3 unnumbered">
<h3 class="unnumbered">Save Recorded Sound Samples</h3>
<p>Let’s use the onboard SD Card reader to save .wav audio files; we must habilitate the XIAO PSRAM first.</p>
<blockquote>
<p>ESP32-S3 has only a few hundred kilobytes of internal RAM on the MCU chip. It can be insufficient for some purposes so that ESP32-S3 can use up to 16 MB of external PSRAM (Pseudo-static RAM) connected in parallel with the SPI flash chip. The external memory is incorporated in the memory map and, with certain restrictions, is usable in the same way as internal data RAM.</p>
</blockquote>
<p>For a start, Insert the SD Card on the XIAO as shown in the photo below (the SD Card should be formatted to FAT32).</p>
<p> <img src="../media/file631.png" class="quarto-figure quarto-figure-center" style="width:95.0%" alt="" /></p>
<p>Turn the PSRAM function of the ESP-32 chip on (Arduino IDE): Tools&gt;PSRAM: “OPI PSRAM”&gt;OPI PSRAM</p>
<p> <img src="../media/file632.png" class="quarto-figure quarto-figure-center" style="width:95.0%" alt="" /></p>
<ul>
<li>Download the sketch <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/Wav_Record_dataset">Wav_Record_dataset</a>, which you can find on the project’s GitHub.</li>
</ul>
<p>This code records audio using the I2S interface of the Seeed XIAO ESP32S3 Sense board, saves the recording as a.wav file on an SD card, and allows for control of the recording process through commands sent from the serial monitor. The name of the audio file is customizable (it should be the class labels to be used with the training), and multiple recordings can be made, each saved in a new file. The code also includes functionality to increase the volume of the recordings.</p>
<p>Let’s break down the most essential parts of it:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1"></a><span class="pp">#include </span><span class="im">&lt;I2S.h&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="pp">#include </span><span class="im">&quot;FS.h&quot;</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="pp">#include </span><span class="im">&quot;SD.h&quot;</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="pp">#include </span><span class="im">&quot;SPI.h&quot;</span></span></code></pre></div>
<p>Those are the necessary libraries for the program. I2S.h allows for audio input, FS.h provides file system handling capabilities, SD.h enables the program to interact with an SD card, and SPI.h handles the SPI communication with the SD card.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1"></a><span class="pp">#define RECORD_TIME   </span><span class="dv">10</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="pp">#define SAMPLE_RATE </span><span class="dv">16000</span><span class="bu">U</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="pp">#define SAMPLE_BITS </span><span class="dv">16</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="pp">#define WAV_HEADER_SIZE </span><span class="dv">44</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="pp">#define VOLUME_GAIN </span><span class="dv">2</span></span></code></pre></div>
<p>Here, various constants are defined for the program.</p>
<ul>
<li><strong>RECORD_TIME</strong> specifies the length of the audio recording in seconds.</li>
<li><strong>SAMPLE_RATE</strong> and <strong>SAMPLE_BITS</strong> define the audio quality of the recording.</li>
<li><strong>WAV_HEADER_SIZE</strong> specifies the size of the .wav file header.</li>
<li><strong>VOLUME_GAIN</strong> is used to increase the volume of the recording.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1"></a><span class="dt">int</span> fileNumber <span class="op">=</span> <span class="dv">1</span><span class="op">;</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>String baseFileName<span class="op">;</span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="dt">bool</span> isRecording <span class="op">=</span> <span class="kw">false</span><span class="op">;</span></span></code></pre></div>
<p>These variables keep track of the current file number (to create unique file names), the base file name, and whether the system is currently recording.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1"></a><span class="dt">void</span> setup<span class="op">()</span> <span class="op">{</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  Serial<span class="op">.</span>begin<span class="op">(</span><span class="dv">115200</span><span class="op">);</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span class="cf">while</span> <span class="op">(!</span>Serial<span class="op">);</span></span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a>  I2S<span class="op">.</span>setAllPins<span class="op">(-</span><span class="dv">1</span><span class="op">,</span> <span class="dv">42</span><span class="op">,</span> <span class="dv">41</span><span class="op">,</span> <span class="op">-</span><span class="dv">1</span><span class="op">,</span> <span class="op">-</span><span class="dv">1</span><span class="op">);</span></span>
<span id="cb5-6"><a href="#cb5-6"></a>  <span class="cf">if</span> <span class="op">(!</span>I2S<span class="op">.</span>begin<span class="op">(</span>PDM_MONO_MODE<span class="op">,</span> SAMPLE_RATE<span class="op">,</span> SAMPLE_BITS<span class="op">))</span> <span class="op">{</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>    Serial<span class="op">.</span>println<span class="op">(</span><span class="st">&quot;Failed to initialize I2S!&quot;</span><span class="op">);</span></span>
<span id="cb5-8"><a href="#cb5-8"></a>    <span class="cf">while</span> <span class="op">(</span><span class="dv">1</span><span class="op">);</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>  <span class="op">}</span></span>
<span id="cb5-10"><a href="#cb5-10"></a></span>
<span id="cb5-11"><a href="#cb5-11"></a>  <span class="cf">if</span><span class="op">(!</span>SD<span class="op">.</span>begin<span class="op">(</span><span class="dv">21</span><span class="op">)){</span></span>
<span id="cb5-12"><a href="#cb5-12"></a>    Serial<span class="op">.</span>println<span class="op">(</span><span class="st">&quot;Failed to mount SD Card!&quot;</span><span class="op">);</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>    <span class="cf">while</span> <span class="op">(</span><span class="dv">1</span><span class="op">);</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>  <span class="op">}</span></span>
<span id="cb5-15"><a href="#cb5-15"></a>  Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Enter with the label name</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb5-16"><a href="#cb5-16"></a><span class="op">}</span></span></code></pre></div>
<p>The setup function initializes the serial communication, I2S interface for audio input, and SD card interface. If the I2S did not initialize or the SD card fails to mount, it will print an error message and halt execution.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb6-1"><a href="#cb6-1"></a><span class="dt">void</span> loop<span class="op">()</span> <span class="op">{</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>  <span class="cf">if</span> <span class="op">(</span>Serial<span class="op">.</span>available<span class="op">()</span> <span class="op">&gt;</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>    String command <span class="op">=</span> Serial<span class="op">.</span>readStringUntil<span class="op">(</span><span class="ch">&#39;</span><span class="sc">\n</span><span class="ch">&#39;</span><span class="op">);</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>    command<span class="op">.</span>trim<span class="op">();</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span class="cf">if</span> <span class="op">(</span>command <span class="op">==</span> <span class="st">&quot;rec&quot;</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>      isRecording <span class="op">=</span> <span class="kw">true</span><span class="op">;</span></span>
<span id="cb6-7"><a href="#cb6-7"></a>    <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span></span>
<span id="cb6-8"><a href="#cb6-8"></a>      baseFileName <span class="op">=</span> command<span class="op">;</span></span>
<span id="cb6-9"><a href="#cb6-9"></a>      fileNumber <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> <span class="co">//reset file number each time a new</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>                        basefile name is set</span>
<span id="cb6-11"><a href="#cb6-11"></a>      Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Send rec for starting recording label </span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>    <span class="op">}</span></span>
<span id="cb6-13"><a href="#cb6-13"></a>  <span class="op">}</span></span>
<span id="cb6-14"><a href="#cb6-14"></a>  <span class="cf">if</span> <span class="op">(</span>isRecording <span class="op">&amp;&amp;</span> baseFileName <span class="op">!=</span> <span class="st">&quot;&quot;</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-15"><a href="#cb6-15"></a>    String fileName <span class="op">=</span> <span class="st">&quot;/&quot;</span> <span class="op">+</span> baseFileName <span class="op">+</span> <span class="st">&quot;.&quot;</span></span>
<span id="cb6-16"><a href="#cb6-16"></a>                      <span class="op">+</span> String<span class="op">(</span>fileNumber<span class="op">)</span> <span class="op">+</span> <span class="st">&quot;.wav&quot;</span><span class="op">;</span></span>
<span id="cb6-17"><a href="#cb6-17"></a>    fileNumber<span class="op">++;</span></span>
<span id="cb6-18"><a href="#cb6-18"></a>    record_wav<span class="op">(</span>fileName<span class="op">);</span></span>
<span id="cb6-19"><a href="#cb6-19"></a>    delay<span class="op">(</span><span class="dv">1000</span><span class="op">);</span> <span class="co">// delay to avoid recording multiple files</span></span>
<span id="cb6-20"><a href="#cb6-20"></a>                    at once</span>
<span id="cb6-21"><a href="#cb6-21"></a>    isRecording <span class="op">=</span> <span class="kw">false</span><span class="op">;</span></span>
<span id="cb6-22"><a href="#cb6-22"></a>  <span class="op">}</span></span>
<span id="cb6-23"><a href="#cb6-23"></a><span class="op">}</span></span></code></pre></div>
<p>In the main loop, the program waits for a command from the serial monitor. If the command is rec, the program starts recording. Otherwise, the command is assumed to be the base name for the .wav files. If it’s currently recording and a base file name is set, it records the audio and saves it as a.wav file. The file names are generated by appending the file number to the base file name.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb7-1"><a href="#cb7-1"></a><span class="dt">void</span> record_wav<span class="op">(</span>String fileName<span class="op">)</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="op">{</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span class="op">...</span></span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a>  File file <span class="op">=</span> SD<span class="op">.</span>open<span class="op">(</span>fileName<span class="op">.</span>c_str<span class="op">(),</span> FILE_WRITE<span class="op">);</span></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span class="op">...</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>  rec_buffer <span class="op">=</span> <span class="op">(</span><span class="dt">uint8_t</span> <span class="op">*)</span>ps_malloc<span class="op">(</span>record_size<span class="op">);</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>  <span class="op">...</span></span>
<span id="cb7-9"><a href="#cb7-9"></a></span>
<span id="cb7-10"><a href="#cb7-10"></a>  esp_i2s<span class="op">::</span>i2s_read<span class="op">(</span>esp_i2s<span class="op">::</span>I2S_NUM_0<span class="op">,</span></span>
<span id="cb7-11"><a href="#cb7-11"></a>                    rec_buffer<span class="op">,</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>                    record_size<span class="op">,</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>                    <span class="op">&amp;</span>sample_size<span class="op">,</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>                    portMAX_DELAY<span class="op">);</span></span>
<span id="cb7-15"><a href="#cb7-15"></a>  <span class="op">...</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="op">}</span></span></code></pre></div>
<p>This function records audio and saves it as a.wav file with the given name. It starts by initializing the sample_size and record_size variables. record_size is calculated based on the sample rate, size, and desired recording time. Let’s dig into the essential sections;</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb8-1"><a href="#cb8-1"></a>File file <span class="op">=</span> SD<span class="op">.</span>open<span class="op">(</span>fileName<span class="op">.</span>c_str<span class="op">(),</span> FILE_WRITE<span class="op">);</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="co">// Write the header to the WAV file</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="dt">uint8_t</span> wav_header<span class="op">[</span>WAV_HEADER_SIZE<span class="op">];</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>generate_wav_header<span class="op">(</span>wav_header<span class="op">,</span> record_size<span class="op">,</span> SAMPLE_RATE<span class="op">);</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>file<span class="op">.</span>write<span class="op">(</span>wav_header<span class="op">,</span> WAV_HEADER_SIZE<span class="op">);</span></span></code></pre></div>
<p>This section of the code opens the file on the SD card for writing and then generates the .wav file header using the generate_wav_header function. It then writes the header to the file.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">// PSRAM malloc for recording</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>rec_buffer <span class="op">=</span> <span class="op">(</span><span class="dt">uint8_t</span> <span class="op">*)</span>ps_malloc<span class="op">(</span>record_size<span class="op">);</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="cf">if</span> <span class="op">(</span>rec_buffer <span class="op">==</span> NULL<span class="op">)</span> <span class="op">{</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>  Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;malloc failed!</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>  <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">;</span></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="op">}</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Buffer: </span><span class="sc">%d</span><span class="st"> bytes</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">,</span> ESP<span class="op">.</span>getPsramSize<span class="op">()</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>               <span class="op">-</span> ESP<span class="op">.</span>getFreePsram<span class="op">());</span></span></code></pre></div>
<p>The ps_malloc function allocates memory in the PSRAM for the recording. If the allocation fails (i.e., rec_buffer is NULL), it prints an error message and halts execution.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb10-1"><a href="#cb10-1"></a><span class="co">// Start recording</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>esp_i2s<span class="op">::</span>i2s_read<span class="op">(</span>esp_i2s<span class="op">::</span>I2S_NUM_0<span class="op">,</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>         rec_buffer<span class="op">,</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>         record_size<span class="op">,</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>         <span class="op">&amp;</span>sample_size<span class="op">,</span></span>
<span id="cb10-6"><a href="#cb10-6"></a>         portMAX_DELAY<span class="op">);</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="cf">if</span> <span class="op">(</span>sample_size <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb10-8"><a href="#cb10-8"></a>  Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Record Failed!</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="op">}</span> <span class="cf">else</span> <span class="op">{</span></span>
<span id="cb10-10"><a href="#cb10-10"></a>    Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Record </span><span class="sc">%d</span><span class="st"> bytes</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">,</span> sample_size<span class="op">);</span></span>
<span id="cb10-11"><a href="#cb10-11"></a>  <span class="op">}</span></span></code></pre></div>
<p>The i2s_read function reads audio data from the microphone into rec_buffer. It prints an error message if no data is read (sample_size is 0).</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb11-1"><a href="#cb11-1"></a><span class="co">// Increase volume</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="cf">for</span> <span class="op">(</span><span class="dt">uint32_t</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> sample_size<span class="op">;</span> i <span class="op">+=</span> SAMPLE_BITS<span class="op">/</span><span class="dv">8</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb11-3"><a href="#cb11-3"></a>  <span class="op">(*(</span><span class="dt">uint16_t</span> <span class="op">*)(</span>rec_buffer<span class="op">+</span>i<span class="op">))</span> <span class="op">&lt;&lt;=</span> VOLUME_GAIN<span class="op">;</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="op">}</span></span></code></pre></div>
<p>This section of the code increases the recording volume by shifting the sample values by VOLUME_GAIN.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">// Write data to the WAV file</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Writing to the file ...</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="cf">if</span> <span class="op">(</span>file<span class="op">.</span>write<span class="op">(</span>rec_buffer<span class="op">,</span> record_size<span class="op">)</span> <span class="op">!=</span> record_size<span class="op">)</span></span>
<span id="cb12-4"><a href="#cb12-4"></a>  Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Write file Failed!</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a>free<span class="op">(</span>rec_buffer<span class="op">);</span></span>
<span id="cb12-7"><a href="#cb12-7"></a>file<span class="op">.</span>close<span class="op">();</span></span>
<span id="cb12-8"><a href="#cb12-8"></a>Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Recording complete: </span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb12-9"><a href="#cb12-9"></a>Serial<span class="op">.</span>printf<span class="op">(</span><span class="st">&quot;Send rec for a new sample or enter</span></span>
<span id="cb12-10"><a href="#cb12-10"></a>                a <span class="kw">new</span> label\n\n<span class="st">&quot;);</span></span></code></pre></div>
<p>Finally, the audio data is written to the .wav file. If the write operation fails, it prints an error message. After writing, the memory allocated for rec_buffer is freed, and the file is closed. The function finishes by printing a completion message and prompting the user to send a new command.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb13-1"><a href="#cb13-1"></a><span class="dt">void</span> generate_wav_header<span class="op">(</span><span class="dt">uint8_t</span> <span class="op">*</span>wav_header<span class="op">,</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>             <span class="dt">uint32_t</span> wav_size<span class="op">,</span></span>
<span id="cb13-3"><a href="#cb13-3"></a>             <span class="dt">uint32_t</span> sample_rate<span class="op">)</span></span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="op">{</span></span>
<span id="cb13-5"><a href="#cb13-5"></a>  <span class="op">...</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>  memcpy<span class="op">(</span>wav_header<span class="op">,</span> set_wav_header<span class="op">,</span> <span class="kw">sizeof</span><span class="op">(</span>set_wav_header<span class="op">));</span></span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="op">}</span></span></code></pre></div>
<p>The generate_wav_header function creates a.wav file header based on the parameters (wav_size and sample_rate). It generates an array of bytes according to the .wav file format, which includes fields for the file size, audio format, number of channels, sample rate, byte rate, block alignment, bits per sample, and data size. The generated header is then copied into the wav_header array passed to the function.</p>
<p>Now, upload the code to the XIAO and get samples from the keywords (yes and no). You can also capture noise and other words.</p>
<p>The Serial monitor will prompt you to receive the label to be recorded.</p>
<p> <img src="../media/file633.png" class="quarto-figure quarto-figure-center" style="width:72.0%" alt="" /></p>
<p>Send the label (for example, yes). The program will wait for another command: rec</p>
<p> <img src="../media/file634.png" class="quarto-figure quarto-figure-center" style="width:72.0%" alt="" /></p>
<p>And the program will start recording new samples every time a command rec is sent. The files will be saved as yes.1.wav, yes.2.wav, yes.3.wav, etc., until a new label (for example, no) is sent. In this case, you should send the command rec for each new sample, which will be saved as no.1.wav, no.2.wav, no.3.wav, etc.</p>
<p> <img src="../media/file635.png" class="quarto-figure quarto-figure-center" style="width:72.0%" alt="" /></p>
<p>Ultimately, we will get the saved files on the SD card.</p>
<p> <img src="../media/file636.png" class="quarto-figure quarto-figure-center" style="width:90.0%" alt="" /></p>
<p>The files are ready to be uploaded to Edge Impulse Studio</p>
</section>
<section id="sec-keyword-spotting-kws-capturing-offline-audio-data-apps-8900" class="level3 unnumbered">
<h3 class="unnumbered">Capturing (offline) Audio Data Apps</h3>
<p>There are many ways to capture audio data; the simplest one is to use a mobile phone or a PC as a <strong>connected device</strong> on the <a href="https://docs.edgeimpulse.com/docs/edge-ai-hardware/using-your-mobile-phone">Edge Impulse Studio</a>.</p>
<blockquote>
<p>The PC or smartphone should capture audio data with a sampling frequency of 16 kHz and a bit depth of 16 Bits.</p>
</blockquote>
<p>Another alternative is to use dedicated apps. A good app for that is <a href="https://www.bejbej.ca/app/voicerecordpro"><em>Voice Recorder Pro</em></a> <a href="https://www.bejbej.ca/app/voicerecordpro">(</a>IOS). You should save your records as .wav files and send them to your computer.</p>
<p> <img src="../media/file637.png" class="quarto-figure quarto-figure-center" style="width:90.0%" alt="" /></p>
</section>
</section>
<section id="sec-keyword-spotting-kws-training-model-edge-impulse-studio-804e" class="level2 unnumbered">
<h2 class="unnumbered">Training model with Edge Impulse Studio</h2>
<section id="sec-keyword-spotting-kws-uploading-data-36c8" class="level3 unnumbered">
<h3 class="unnumbered">Uploading the Data</h3>
<p>When the raw dataset is defined and collected (Pete’s dataset + recorded keywords), we should initiate a new project at Edge Impulse Studio:</p>
<p> <img src="../media/file638.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
<p>Once the project is created, select the Upload Existing Data tool in the Data Acquisition section. Choose the files to be uploaded:</p>
<p> <img src="../media/file639.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
<p>And upload them to the Studio (You can automatically split data in train/test). Repeat to all classes and all raw data.</p>
<p> <img src="../media/file640.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
<p>The samples will now appear in the Data acquisition section.</p>
<p> <img src="../media/file641.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<p>All data on Pete’s dataset have a 1 s length, but the samples recorded in the previous section have 10 s and must be split into 1s samples to be compatible.</p>
<p>Click on three dots after the sample name and select Split sample.</p>
<p> <img src="../media/file642.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<p>Once inside the tool, split the data into 1-second records. If necessary, add or remove segments:</p>
<p> <img src="../media/file643.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<p>This procedure should be repeated for all samples.</p>
<blockquote>
<p>Note: For longer audio files (minutes), first, split into 10-second segments and after that, use the tool again to get the final 1-second splits.</p>
</blockquote>
<p>Suppose we do not split data automatically in train/test during upload. In that case, we can do it manually (using the three dots menu, moving samples individually) or using Perform Train / Test Split on Dashboard – Danger Zone.</p>
<blockquote>
<p>We can optionally check all datasets using the tab Data Explorer.</p>
</blockquote>
</section>
<section id="sec-keyword-spotting-kws-creating-impulse-preprocess-model-definition-15b3" class="level3 unnumbered">
<h3 class="unnumbered">Creating Impulse (Pre-Process / Model definition)</h3>
<p><em>An</em> <strong>impulse</strong> <em>takes raw data, uses signal processing to extract features, and then uses a learning block to classify new data.</em></p>
<p> <img src="../media/file644.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<p>First, we will take the data points with a 1-second window, augmenting the data, sliding that window each 500 ms. Note that the option zero-pad data is set. It is essential to fill with zeros samples smaller than 1 second (in some cases, I reduced the 1000 ms window on the split tool to avoid noises and spikes).</p>
<p>Each 1-second audio sample should be pre-processed and converted to an image (for example, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>13</mn><mo>×</mo><mn>49</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">13\times 49\times 1</annotation></semantics></math>). We will use MFCC, which extracts features from audio signals using <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">Mel Frequency Cepstral Coefficients</a>, which are great for the human voice.</p>
<p> <img src="../media/file645.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<p>Next, we select KERAS for classification and build our model from scratch by doing Image Classification using Convolution Neural Network).</p>
</section>
<section id="sec-keyword-spotting-kws-preprocessing-mfcc-3788" class="level3 unnumbered">
<h3 class="unnumbered">Pre-Processing (MFCC)</h3>
<p>The next step is to create the images to be trained in the next phase:</p>
<p>We can keep the default parameter values or take advantage of the DSP Autotuneparameters option, which we will do.</p>
<p> <img src="../media/file646.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<p>The result will not spend much memory to pre-process data (only 16KB). Still, the estimated processing time is high, 675 ms for an Espressif ESP-EYE (the closest reference available), with a 240 kHz clock (same as our device), but with a smaller CPU (XTensa LX6, versus the LX7 on the ESP32S). The real inference time should be smaller.</p>
<p>Suppose we need to reduce the inference time later. In that case, we should return to the pre-processing stage and, for example, reduce the FFT length to 256, change the Number of coefficients, or another parameter.</p>
<p>For now, let’s keep the parameters defined by the Autotuning tool. Save parameters and generate the features.</p>
<p> <img src="../media/file647.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="" /></p>
<blockquote>
<p>If you want to go further with converting temporal serial data into images using FFT, Spectrogram, etc., you can play with this CoLab: <a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_24/IESTI01_Audio_Raw_Data_Analisys.ipynb">Audio Raw Data Analysis.</a></p>
</blockquote>
</section>
<section id="sec-keyword-spotting-kws-model-design-training-48a1" class="level3 unnumbered">
<h3 class="unnumbered">Model Design and Training</h3>
<p>We will use a Convolution Neural Network (CNN) model. The basic architecture is defined with two blocks of Conv1D + MaxPooling (with 8 and 16 neurons, respectively) and a 0.25 Dropout. And on the last layer, after Flattening four neurons, one for each class:</p>
<p> <img src="../media/file648.png" alt="" /></p>
<p>As hyper-parameters, we will have a Learning Rate of 0.005 and a model that will be trained by 100 epochs. We will also include data augmentation, as some noise. The result seems OK:</p>
<p> <img src="../media/file649.png" class="quarto-figure quarto-figure-center" style="width:75.0%" alt="" /></p>
<p>If you want to understand what is happening “under the hood,” you can download the dataset and run a Jupyter Notebook playing with the code. For example, you can analyze the accuracy by each epoch:</p>
<p> <img src="../media/file650.png" alt="" /></p>
<p>This CoLab Notebook can explain how you can go further: <a href="https://colab.research.google.com/github/Mjrovai/XIAO-ESP32S3-Sense/blob/main/KWS">KWS Classifier Project - Looking “Under the hood</a> Training/xiao_esp32s3_keyword_spotting_project_nn_classifier.ipynb).”</p>
</section>
</section>
<section id="sec-keyword-spotting-kws-testing-8a1c" class="level2 unnumbered">
<h2 class="unnumbered">Testing</h2>
<p>Testing the model with the data put apart before training (Test Data), we got an accuracy of approximately 87%.</p>
<p> <img src="../media/file651.png" class="quarto-figure quarto-figure-center" style="width:90.0%" alt="" /></p>
<p>Inspecting the F1 score, we can see that for YES, we got 0.95, an excellent result once we used this keyword to “trigger” our postprocessing stage (turn on the built-in LED). Even for NO, we got 0.90. The worst result is for unknown, what is OK.</p>
<p>We can proceed with the project, but it is possible to perform Live Classification using a smartphone before deployment on our device. Go to the Live Classification section and click on Connect a Development board:</p>
<p> <img src="../media/file652.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
<p>Point your phone to the barcode and select the link.</p>
<p> <img src="../media/file653.png" alt="" /></p>
<p>Your phone will be connected to the Studio. Select the option Classification on the app, and when it is running, start testing your keywords, confirming that the model is working with live and real data:</p>
<p> <img src="../media/file654.png" alt="" /></p>
</section>
<section id="sec-keyword-spotting-kws-deploy-inference-6b44" class="level2 unnumbered">
<h2 class="unnumbered">Deploy and Inference</h2>
<p>The Studio will package all the needed libraries, preprocessing functions, and trained models, downloading them to your computer. Select the Arduino Library option, then choose Quantized (Int8) from the bottom menu and press Build.</p>
<p> <img src="../media/file655.png" class="quarto-figure quarto-figure-center" style="width:90.0%" alt="" /></p>
<p>Now it is time for a real test. We will make inferences wholly disconnected from the Studio. Let’s change one of the ESP32 code examples created when you deploy the Arduino Library.</p>
<p>In your Arduino IDE, go to the File/Examples tab look for your project, and select esp32/esp32_microphone:</p>
<p> <img src="../media/file656.png" class="quarto-figure quarto-figure-center" style="width:90.0%" alt="" /></p>
<p>This code was created for the ESP-EYE built-in microphone, which should be adapted for our device.</p>
<p>Start changing the libraries to handle the I2S bus:</p>
<p> <img src="../media/file657.png" class="quarto-figure quarto-figure-center" style="width:60.0%" alt="" /></p>
<p>By:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb14-1"><a href="#cb14-1"></a><span class="pp">#include </span><span class="im">&lt;I2S.h&gt;</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="pp">#define SAMPLE_RATE </span><span class="dv">16000</span><span class="bu">U</span></span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="pp">#define SAMPLE_BITS </span><span class="dv">16</span></span></code></pre></div>
<p>Initialize the IS2 microphone at setup(), including the lines:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb15-1"><a href="#cb15-1"></a><span class="dt">void</span> setup<span class="op">()</span></span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="op">{</span></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="op">...</span></span>
<span id="cb15-4"><a href="#cb15-4"></a>    I2S<span class="op">.</span>setAllPins<span class="op">(-</span><span class="dv">1</span><span class="op">,</span> <span class="dv">42</span><span class="op">,</span> <span class="dv">41</span><span class="op">,</span> <span class="op">-</span><span class="dv">1</span><span class="op">,</span> <span class="op">-</span><span class="dv">1</span><span class="op">);</span></span>
<span id="cb15-5"><a href="#cb15-5"></a>    <span class="cf">if</span> <span class="op">(!</span>I2S<span class="op">.</span>begin<span class="op">(</span>PDM_MONO_MODE<span class="op">,</span> SAMPLE_RATE<span class="op">,</span> SAMPLE_BITS<span class="op">))</span> <span class="op">{</span></span>
<span id="cb15-6"><a href="#cb15-6"></a>      Serial<span class="op">.</span>println<span class="op">(</span><span class="st">&quot;Failed to initialize I2S!&quot;</span><span class="op">);</span></span>
<span id="cb15-7"><a href="#cb15-7"></a>    <span class="cf">while</span> <span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">;</span></span>
<span id="cb15-8"><a href="#cb15-8"></a><span class="op">...</span></span>
<span id="cb15-9"><a href="#cb15-9"></a><span class="op">}</span></span></code></pre></div>
<p>On the static void capture_samples(void* arg) function, replace the line 153 that reads data from I2S mic:</p>
<p> <img src="../media/file658.png" alt="" /></p>
<p>By:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb16-1"><a href="#cb16-1"></a><span class="co">/* read data at once from i2s */</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>esp_i2s<span class="op">::</span>i2s_read<span class="op">(</span>esp_i2s<span class="op">::</span>I2S_NUM_0<span class="op">,</span></span>
<span id="cb16-3"><a href="#cb16-3"></a>                 <span class="op">(</span><span class="dt">void</span><span class="op">*)</span>sampleBuffer<span class="op">,</span></span>
<span id="cb16-4"><a href="#cb16-4"></a>                 i2s_bytes_to_read<span class="op">,</span></span>
<span id="cb16-5"><a href="#cb16-5"></a>                 <span class="op">&amp;</span>bytes_read<span class="op">,</span> <span class="dv">100</span><span class="op">);</span></span></code></pre></div>
<p>On function static bool microphone_inference_start(uint32_t n_samples), we should comment or delete lines 198 to 200, where the microphone initialization function is called. This is unnecessary because the I2S microphone was already initialized during the setup().</p>
<p> <img src="../media/file659.png" alt="" /></p>
<p>Finally, on static void microphone_inference_end(void) function, replace line 243:</p>
<p> <img src="../media/file660.png" class="quarto-figure quarto-figure-center" style="width:60.0%" alt="" /></p>
<p>By:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb17-1"><a href="#cb17-1"></a><span class="at">static</span> <span class="dt">void</span> microphone_inference_end<span class="op">(</span><span class="dt">void</span><span class="op">)</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="op">{</span></span>
<span id="cb17-3"><a href="#cb17-3"></a>    free<span class="op">(</span>sampleBuffer<span class="op">);</span></span>
<span id="cb17-4"><a href="#cb17-4"></a>    ei_free<span class="op">(</span>inference<span class="op">.</span>buffer<span class="op">);</span></span>
<span id="cb17-5"><a href="#cb17-5"></a><span class="op">}</span></span></code></pre></div>
<p>You can find the complete code on the <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/xiao_esp32s3_microphone">project’s GitHub</a>. Upload the sketch to your board and test some real inferences:</p>
<blockquote>
<p>⚠️ <strong>Attention</strong></p>
<ul>
<li>The Xiao ESP32S3 <strong>MUST</strong> have the PSRAM enabled. You can check it on the Arduino IDE upper menu: <code>Tools</code>–&gt; <code>PSRAM:OPI PSRAM</code></li>
<li>The Arduino Library (<code>esp32 by Espressif Systems</code> should be <strong>version 2.017</strong>. Please do not update it.</li>
</ul>
</blockquote>
<p> <img src="../media/file661.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
</section>
<section id="sec-keyword-spotting-kws-postprocessing-d5e4" class="level2 unnumbered">
<h2 class="unnumbered">Postprocessing</h2>
<p>In edge AI applications, the inference result is only as valuable as our ability to act upon it. While serial output provides detailed information for debugging and development, real-world deployments require immediate, human-readable feedback that doesn’t depend on external monitors or connections.</p>
<p>Let’s explore two post-processing approaches. Using the internal XIAO’s LED and the OLED on the XIAOML Kit.</p>
<section id="sec-keyword-spotting-kws-led-6deb" class="level3 unnumbered">
<h3 class="unnumbered">With LED</h3>
<p>Now that we know the model is working by detecting our keywords, let’s modify the code to see the internal LED go on every time a YES is detected.</p>
<p>You should initialize the LED:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb18-1"><a href="#cb18-1"></a><span class="pp">#define LED_BUILT_IN </span><span class="dv">21</span></span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="op">...</span></span>
<span id="cb18-3"><a href="#cb18-3"></a><span class="dt">void</span> setup<span class="op">()</span></span>
<span id="cb18-4"><a href="#cb18-4"></a><span class="op">{</span></span>
<span id="cb18-5"><a href="#cb18-5"></a><span class="op">...</span></span>
<span id="cb18-6"><a href="#cb18-6"></a>  pinMode<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> OUTPUT<span class="op">);</span> <span class="co">// Set the pin as output</span></span>
<span id="cb18-7"><a href="#cb18-7"></a>  digitalWrite<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> HIGH<span class="op">);</span> <span class="co">//Turn off</span></span>
<span id="cb18-8"><a href="#cb18-8"></a><span class="op">...</span></span>
<span id="cb18-9"><a href="#cb18-9"></a><span class="op">}</span></span></code></pre></div>
<p>And change the // print the predictions portion of the previous code (on loop():</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource cpp number-lines"><code class="sourceCode cpp"><span id="cb19-1"><a href="#cb19-1"></a><span class="dt">int</span> pred_index <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>     <span class="co">// Initialize pred_index</span></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="dt">float</span> pred_value <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>   <span class="co">// Initialize pred_value</span></span>
<span id="cb19-3"><a href="#cb19-3"></a></span>
<span id="cb19-4"><a href="#cb19-4"></a><span class="co">// print the predictions</span></span>
<span id="cb19-5"><a href="#cb19-5"></a>ei_printf<span class="op">(</span><span class="st">&quot;Predictions &quot;</span><span class="op">);</span></span>
<span id="cb19-6"><a href="#cb19-6"></a>ei_printf<span class="op">(</span><span class="st">&quot;(DSP: </span><span class="sc">%d</span><span class="st"> ms., Classification: </span><span class="sc">%d</span><span class="st"> ms., Anomaly: </span><span class="sc">%d</span><span class="st"> ms.)&quot;</span><span class="op">,</span></span>
<span id="cb19-7"><a href="#cb19-7"></a>     result<span class="op">.</span>timing<span class="op">.</span>dsp<span class="op">,</span> result<span class="op">.</span>timing<span class="op">.</span>classification<span class="op">,</span></span>
<span id="cb19-8"><a href="#cb19-8"></a>     result<span class="op">.</span>timing<span class="op">.</span>anomaly<span class="op">);</span></span>
<span id="cb19-9"><a href="#cb19-9"></a>ei_printf<span class="op">(</span><span class="st">&quot;: </span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb19-10"><a href="#cb19-10"></a><span class="cf">for</span> <span class="op">(</span><span class="dt">size_t</span> ix <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> ix <span class="op">&lt;</span> EI_CLASSIFIER_LABEL_COUNT<span class="op">;</span> ix<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb19-11"><a href="#cb19-11"></a>      ei_printf<span class="op">(</span><span class="st">&quot;    </span><span class="sc">%s</span><span class="st">: &quot;</span><span class="op">,</span> result<span class="op">.</span>classification<span class="op">[</span>ix<span class="op">].</span>label<span class="op">);</span></span>
<span id="cb19-12"><a href="#cb19-12"></a>      ei_printf_float<span class="op">(</span>result<span class="op">.</span>classification<span class="op">[</span>ix<span class="op">].</span>value<span class="op">);</span></span>
<span id="cb19-13"><a href="#cb19-13"></a>      ei_printf<span class="op">(</span><span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">);</span></span>
<span id="cb19-14"><a href="#cb19-14"></a></span>
<span id="cb19-15"><a href="#cb19-15"></a>      <span class="cf">if</span> <span class="op">(</span>result<span class="op">.</span>classification<span class="op">[</span>ix<span class="op">].</span>value <span class="op">&gt;</span> pred_value<span class="op">){</span></span>
<span id="cb19-16"><a href="#cb19-16"></a>         pred_index <span class="op">=</span> ix<span class="op">;</span></span>
<span id="cb19-17"><a href="#cb19-17"></a>         pred_value <span class="op">=</span> result<span class="op">.</span>classification<span class="op">[</span>ix<span class="op">].</span>value<span class="op">;</span></span>
<span id="cb19-18"><a href="#cb19-18"></a>      <span class="op">}</span></span>
<span id="cb19-19"><a href="#cb19-19"></a><span class="op">}</span></span>
<span id="cb19-20"><a href="#cb19-20"></a></span>
<span id="cb19-21"><a href="#cb19-21"></a><span class="co">// show the inference result on LED</span></span>
<span id="cb19-22"><a href="#cb19-22"></a><span class="cf">if</span> <span class="op">(</span>pred_index <span class="op">==</span> <span class="dv">3</span><span class="op">){</span></span>
<span id="cb19-23"><a href="#cb19-23"></a>    digitalWrite<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> LOW<span class="op">);</span> <span class="co">//Turn on</span></span>
<span id="cb19-24"><a href="#cb19-24"></a><span class="op">}</span></span>
<span id="cb19-25"><a href="#cb19-25"></a><span class="cf">else</span><span class="op">{</span></span>
<span id="cb19-26"><a href="#cb19-26"></a>   digitalWrite<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> HIGH<span class="op">);</span> <span class="co">//Turn off</span></span>
<span id="cb19-27"><a href="#cb19-27"></a><span class="op">}</span></span></code></pre></div>
<p>You can find the complete code on the <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/xiao_esp32s3_microphone_led">project’s GitHub.</a> Upload the sketch to your board and test some real inferences:</p>
<p> <img src="../media/file662.png" class="quarto-figure quarto-figure-center" style="width:80.0%" alt="" /></p>
<p>The idea is that the LED will be ON whenever the keyword YES is detected. In the same way, instead of turning on an LED, this could be a “trigger” for an external device, as we saw in the introduction.</p>
</section>
<section id="sec-keyword-spotting-kws-oled-display-9676" class="level3 unnumbered">
<h3 class="unnumbered">With OLED Display</h3>
<p>The XIAOML Kit tiny 0.42” OLED display (72×40 pixels) serves as a crucial post-processing component that transforms raw ML inference results into immediate, human-readable feedback—displaying detected class names and confidence levels directly on the device, eliminating the need for external monitors and enabling truly standalone edge AI deployment in industrial, agricultural, or retail environments where instant visual confirmation of AI predictions is essential.</p>
<p>So, let’s modify the sketch to automatically adapt to the model trained on Edge Impulse by reading the class names and count directly from the model. Download the code from GitHub: <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/XIAOML_Kit_code/xiaoml-kit_kws_oled">xiaoml-kit_kws_oled</a>.</p>
<p>Running the code, we can see the result:</p>
<p> <img src="../media/file663.png" class="quarto-figure quarto-figure-center" style="width:90.0%" alt="" /></p>
</section>
</section>
<section id="sec-keyword-spotting-kws-summary-b181" class="level2 unnumbered">
<h2 class="unnumbered">Summary</h2>
<p>This lab demonstrated the complete development cycle of a keyword spotting system using the XIAOML Kit, showcasing how modern TinyML platforms make sophisticated audio AI accessible on resource-constrained devices. Through hands-on implementation, we’ve bridged the gap between theoretical machine learning concepts and practical embedded AI deployment.</p>
<p><strong>Technical Achievements:</strong></p>
<p>The project successfully implemented a complete audio processing pipeline from raw sound capture through real-time inference. Using the XIAO ESP32S3’s integrated digital microphone, we captured audio data at professional quality (16kHz/16-bit) and processed it using Mel Frequency Cepstral Coefficients (MFCC) for feature extraction. The deployed CNN model achieved excellent accuracy in distinguishing between our target keywords (“YES”, “NO”) and background conditions (“NOISE”, “UNKNOWN”), with inference times suitable for real-time applications.</p>
<p><strong>Platform Integration:</strong></p>
<p>Edge Impulse Studio proved invaluable as a comprehensive MLOps platform for embedded systems, handling everything from data collection and labeling through model training, optimization, and deployment. The seamless integration between cloud-based training and edge deployment exemplifies modern TinyML workflows, while the Arduino IDE provided the flexibility needed for custom post-processing implementations.</p>
<p><strong>Real-World Applications:</strong></p>
<p>The techniques learned extend far beyond simple keyword detection. Voice-activated control systems, industrial safety monitoring through sound classification, medical applications for respiratory analysis, and environmental monitoring for wildlife or equipment sounds all leverage similar audio processing approaches. The cascaded detection architecture demonstrated here—using edge-based KWS to trigger more complex cloud processing—is fundamental to modern voice assistant systems.</p>
<p><strong>Embedded AI Principles:</strong></p>
<p>This project highlighted crucial TinyML considerations, including power management, memory optimization through PSRAM utilization, and the trade-offs between model complexity and inference speed. The successful deployment of a neural network performing real-time audio analysis on a microcontroller demonstrates how AI capabilities, once requiring powerful desktop computers, can now operate on battery-powered devices.</p>
<p><strong>Development Methodology:</strong></p>
<p>We explored multiple development pathways, from data collection strategies (offline SD card storage versus online streaming) to deployment options (Edge Impulse’s automated library generation versus custom Arduino implementation). This flexibility is crucial for adapting to various project requirements and constraints.</p>
<p><strong>Future Directions:</strong></p>
<p>The foundation established here enables the exploration of more advanced audio AI applications. Multi-keyword recognition, speaker identification, emotion detection from voice, and environmental sound classification all build upon the same core techniques. The integration capabilities demonstrated with OLED displays and GPIO control illustrate how KWS can serve as the intelligent interface for broader IoT systems.</p>
<p>Consider that Sound Classification encompasses much more than just voice recognition. This project’s techniques apply across numerous domains:</p>
<ul>
<li><strong>Security Applications</strong>: Broken glass detection, intrusion monitoring, gunshot detection</li>
<li><strong>Industrial IoT</strong>: Machinery health monitoring, anomaly detection in manufacturing equipment</li>
<li><strong>Healthcare</strong>: Sleep disorder monitoring, respiratory condition assessment, elderly care systems</li>
<li><strong>Environmental Monitoring</strong>: Wildlife tracking, urban noise analysis, smart building acoustic management</li>
<li><strong>Smart Home Integration</strong>: Multi-room voice control, appliance status monitoring through sound signatures</li>
</ul>
<p><strong>Key Takeaways:</strong></p>
<p>The XIAOML Kit proves that professional-grade AI development is achievable with accessible tools and modest budgets. The combination of capable hardware (ESP32S3 with PSRAM and integrated sensors), mature development platforms (Edge Impulse Studio), and comprehensive software libraries creates an environment where complex AI concepts become tangible, working systems.</p>
<p>This lab demonstrates that the future of AI isn’t just in massive data centers, but in intelligent edge devices that can process, understand, and respond to their environment in real-time—opening possibilities for ubiquitous, privacy-preserving, and responsive artificial intelligence systems.</p>
</section>
<section id="sec-keyword-spotting-kws-resources-c867" class="level2 unnumbered">
<h2 class="unnumbered">Resources</h2>
<ul>
<li><p><a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense">XIAO ESP32S3 Codes</a></p></li>
<li><p><a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/XIAOML_Kit_code">XIAOML Kit Code</a></p></li>
<li><p><a href="https://cdn.edgeimpulse.com/datasets/keywords2.zip">Subset of Google Speech Commands Dataset</a></p></li>
<li><p><a href="https://colab.research.google.com/github/Mjrovai/Arduino_Nicla_Vision/blob/main/KWS/KWS_MFCC_Analysis.ipynb">KWS MFCC Analysis Colab Notebook</a></p></li>
<li><p><a href="https://colab.research.google.com/github/Mjrovai/Arduino_Nicla_Vision/blob/main/KWS/KWS_CNN_training.ipynb">KWS CNN training Colab Notebook</a></p></li>
<li><p><a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/xiao_esp32s3_microphone_led">XIAO ESP32S3 Post-processing Code</a></p></li>
<li><p><a href="https://studio.edgeimpulse.com/public/230109/live">Edge Impulse Project</a></p></li>
</ul>
</section>
</section>
</body>
</html>
