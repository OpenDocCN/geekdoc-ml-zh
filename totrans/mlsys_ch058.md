# 参考文献

0001, 天奇 陈, Thierry Moreau, 郑志恒, 郑连民, 艾迪·Q·严, 沈海辰, 梅根·考恩, 等人. 2018a. “TVM: 一种用于深度学习的自动端到端优化编译器.” 在 *第 13 届 USENIX 操作系统设计与实现研讨会 (OSDI 18)*, 578–94\. [`www.usenix.org/conference/osdi18/presentation/chen`](https://www.usenix.org/conference/osdi18/presentation/chen).———, 等人. 2018b. “TVM: 一种用于深度学习的自动端到端优化编译器.” 在 *OSDI*, 578–94\. [`www.usenix.org/conference/osdi18/presentation/chen`](https://www.usenix.org/conference/osdi18/presentation/chen).Abadi, Martín, Ashish Agarwal, Paul Barham, 等人. 2015\. “TensorFlow: 在异构系统上的大规模机器学习.” Google Brain.Abadi, Martín, Paul Barham, 钟建民, 陈志峰, 安迪·戴维斯, 杰弗里·迪恩, 马蒂厄·迪文, 等人. 2016\. “TensorFlow: 一个用于大规模机器学习的系统.” 在 *第 12 届 USENIX 操作系统设计与实现研讨会*, 265–83.Abadi, Martin, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, 和 李章. 2016\. “具有差分隐私的深度学习.” 在 *2016 年 ACM SIGSAC 计算机与通信安全会议论文集*, 308–18\. CCS ‘16\. 纽约，纽约，美国：ACM. [`doi.org/10.1145/2976749.2978318`](https://doi.org/10.1145/2976749.2978318).Abdelkhalik, Hamdy, Yehia Arafa, Nandakishore Santhi, 和 Abdel-Hameed A. Badawy. 2022\. “通过微基准测试和指令级分析揭开 Nvidia Ampere 架构的神秘面纱.” 在 *2022 年 IEEE 高性能极端计算会议 (HPEC)*. IEEE. [`doi.org/10.1109/hpec55821.2022.9926299`](https://doi.org/10.1109/hpec55821.2022.9926299).ABI Research. 2024\. “Tiny ML: 科技领域的下一个重大机遇.” 白皮书. ABI Research. [`go.abiresearch.com/lp-tiny-ml-the-next-big-opportunity-in-tech`](https://go.abiresearch.com/lp-tiny-ml-the-next-big-opportunity-in-tech).Addepalli, Sravanti, B. S. Vivek, Arya Baburaj, Gaurang Sriramanan, 和 R. Venkatesh Babu. 2020\. “通过在位平面间强制执行特征一致性来实现对抗鲁棒性.” 在 *2020 年 IEEE/CVF 计算机视觉与模式识别会议 (CVPR)*, 1020–29\. IEEE. [`doi.org/10.1109/cvpr42600.2020.00110`](https://doi.org/10.1109/cvpr42600.2020.00110).Adi, Yossi, Carsten Baum, Moustapha Cisse, Benny Pinkas, 和 Joseph Keshet. 2018\. “将弱点转化为优势：通过后门技术对深度神经网络进行水印.” 在 *第 27 届 USENIX 安全研讨会 (USENIX Security 18)*, 1615–31.Agrawal, Dakshi, Selcuk Baktir, Deniz Karakoyunlu, Pankaj Rohatgi, 和 Berk Sunar. 2007\. “使用 IC 指纹进行木马检测.” 在 *2007 年 IEEE 安全与隐私研讨会 (SP ‘07)*, 296–310\. Springer; IEEE. [`doi.org/10.1109/sp.2007.36`](https://doi.org/10.1109/sp.2007.36).Akidau, Tyler, Robert Bradshaw, Craig Chambers, Slava Chernyak, Rafael J. Fernández-Moctezuma, Reuven Lax, Sam McVeety, 等人. 2015\. “数据流模型：在无界、乱序大规模数据处理中平衡正确性、延迟和成本的实际方法.” *VLDB Endowment* 8 (12): 1792–1803\. [`doi.org/10.14778/2824032.2824076`](https://doi.org/10.14778/2824032.2824076).Altayeb, Moez, Marco Zennaro, 和 Marcelo Rovai. 2022\. “使用 TinyML 对蚊子翅膀拍打声进行分类.” 在 *2022 年 ACM 信息技术与社会公益会议论文集*, 132–37\. ACM. [`doi.org/10.1145/3524458.3547258`](https://doi.org/10.1145/3524458.3547258).Alvim, Mário S., Konstantinos Chatzikokolakis, Yusuke Kawamoto, 和 Catuscia Palamidessi. 2022\. “信息泄露游戏：将信息作为效用函数进行探索.” *ACM Transactions on Privacy and Security* 25 (3): 1–36\. [`doi.org/10.1145/3517330`](https://doi.org/10.1145/3517330).Amershi, Saleema, Andrew Begel, Christian Bird, Robert DeLine, Harald Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, 和 Thomas Zimmermann. 2019\. “机器学习软件工程：一个案例研究.” 在 *2019 年 IEEE/ACM 第 41 届国际软件工程会议：软件工程实践 (ICSE-SEIP)*, 291–300\. IEEE. [`doi.org/10.1109/icse-seip.2019.00042`](https://doi.org/10.1109/icse-seip.2019.00042).Amiel, Frederic, Christophe Clavier, 和 Michael Tunstall. 2006\. “对 DPA 抵抗算法的故障分析.” 在 *密码学中的故障诊断与容错*, 223–36\. Springer; Springer Berlin Heidelberg. [`doi.org/10.1007/11889700\_20`](https://doi.org/10.1007/11889700\_20).Amodei, Dario, Danny Hernandez, 等人. 2018\. “AI 和计算.” *OpenAI 博客*. [`openai.com/research/ai-and-compute`](https://openai.com/research/ai-and-compute).Amodei, Dario, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, 和 Dan Mané. 2016\. “人工智能安全中的具体问题.” *arXiv 预印本 arXiv:1606.06565*, 六月. [`arxiv.org/abs/1606.06565v2`](http://arxiv.org/abs/1606.06565v2).Angwin, Julia, Jeff Larson, Surya Mattu, 和 Lauren Kirchner. 2022\. “机器偏见：全国范围内用于预测未来罪犯的软件。它对黑人存在偏见.” 在 *数据与分析伦理*, 254–64\. Auerbach Publications. [`doi.org/10.1201/9781003278290-37`](https://doi.org/10.1201/9781003278290-37).Antonakakis, Manos, Tim April, Michael Bailey, Matt Bernhard, Elie Bursztein, Jaime Cochran, Zakir Durumeric, 等人. 2017\. “理解 Mirai 僵尸网络.” 在 *第 26 届 USENIX 安全研讨会 (USENIX Security 17)*, 16:1093–1110.Ardila, Rosana, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, 和 Gregor Weber. 2020\. “Common Voice：一个大规模多语言语音语料库.” 在 *第十二届语言资源与评估会议论文集*, 4218–22\. 马赛，法国：欧洲语言资源协会. [`aclanthology.org/2020.lrec-1.520`](https://aclanthology.org/2020.lrec-1.520).Arifeen, Tooba, Abdus Sami Hassan, 和 Jeong-A Lee. 2020\. “近似三模冗余：综述.” *IEEE Access* 8: 139851–67\. [`doi.org/10.1109/access.2020.3012673`](https://doi.org/10.1109/access.2020.3012673).Arivazhagan, Manoj Ghuhan, Vinay Aggarwal, Aaditya Kumar Singh, 和 Sunav Choudhary. 2019\. “具有个性化层的联邦学习.” *CoRR* abs/1912.00818 (十二月). [`arxiv.org/abs/1912.00818v1`](http://arxiv.org/abs/1912.00818v1).Arsene, Octavian, Ioan Dumitrache, 和 Ioana Mihu. 2015\. “使用软件代理进行医学诊断的专家系统.” *专家系统与应用* 42 (4): 1825–34\. [`doi.org/10.1016/j.eswa.2014.10.026`](https://doi.org/10.1016/j.eswa.2014.10.026).Asonov, D., 和 R. Agrawal. n.d. “键盘声发射.” 在 *2004 年 IEEE 安全与隐私研讨会，2004 年会议论文集*. 2004\. IEEE; IEEE. [`doi.org/10.1109/secpri.2004.1301311`](https://doi.org/10.1109/secpri.2004.1301311).Ateniese, Giuseppe, Luigi V. Mancini, Angelo Spognardi, Antonio Villani, Domenico Vitali, 和 Giovanni Felici. 2015\. “使用更智能的机器来破解智能机器：如何从机器学习分类器中提取有意义的数据.” *国际安全与网络杂志* 10 (3): 137\. [`doi.org/10.1504/ijsn.2015.071829`](https://doi.org/10.1504/ijsn.2015.071829).Aygun, Sercan, Ece Olcay Gunes, 和 Christophe De Vleeschouwer. 2021\. “二值化神经网络中的高效和鲁棒位流处理.” *电子学快报* 57 (5): 219–22\. [`doi.org/10.1049/ell2.12045`](https://doi.org/10.1049/ell2.12045).Azevedo, Frederico A. C., Ludmila R. B. Carvalho, Lea T. Grinberg, José Marcelo Farfel, Renata E. L. Ferretti, Renata E. P. Leite, Wilson Jacob Filho, Roberto Lent, 和 Suzana Herculano-Houzel. 2009\. “神经元和非神经元细胞数量相等使人类大脑成为等比例放大的灵长类动物大脑.” *比较神经学杂志* 513 (5): 532–41\. [`doi.org/10.1002/cne.21974`](https://doi.org/10.1002/cne.21974).Ba, Jimmy Lei, Jamie Ryan Kiros, 和 Geoffrey E. Hinton. 2016\. “层归一化.” *arXiv 预印本 arXiv:1607.06450*, 七月. [`arxiv.org/abs/1607.06450v1`](http://arxiv.org/abs/1607.06450v1).Bahdanau, Dzmitry, Kyunghyun Cho, 和 Yoshua Bengio. 2014\. “通过联合学习对齐和翻译进行神经机器翻译.” *arXiv 预印本 arXiv:1409.0473*, 九月. [`arxiv.org/abs/1409.0473v7`](http://arxiv.org/abs/1409.0473v7).Bai, Tao, Jinqi Luo, Jun Zhao, Bihan Wen, 和 Qian Wang. 2021\. “对抗训练在对抗鲁棒性方面的最新进展.” *arXiv 预印本 arXiv:2102.01356*, 二月. [`arxiv.org/abs/2102.01356v5`](http://arxiv.org/abs/2102.01356v5).Bai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, 等人. 2022\. “宪法 AI：从 AI 反馈中获得无害性.” *arXiv 预印本 arXiv:2212.08073*, 十二月. [`arxiv.org/abs/2212.08073v1`](http://arxiv.org/abs/2212.08073v1).Baker, Bowen, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew, 和 Igor Mordatch. 2019\. “从多智能体自定课程中涌现的工具使用.” *国际学习表示会议*, 九月. [`arxiv.org/abs/1909.07528v2`](http://arxiv.org/abs/1909.07528v2).Baldé, Cornelis P, Vanessa Forti, Vanessa Gray, Ruediger Kuehr, 和 Paul Stegmann. 2017\. “全球电子垃圾监测 2017：数量、流动和资源.” *联合国大学，国际电信联盟，国际固体废弃物协会*. [`www.itu.int/en/ITU-D/Climate-Change/Documents/GEM\%202017/Global-E-waste\%202017\%20.pdf`](https://www.itu.int/en/ITU-D/Climate-Change/Documents/GEM%202017/Global-E-waste%202017%20.pdf)

    https://www.itu.int/en/ITU-D/Climate-Change/Documents/GEM\%202017/Global-E-waste\%20Monitor\%202017\%20.pdf

    [Fairlearn：用于评估和改进 AI 中公平性的工具包](https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/)

Bishop, Christopher M. 2006\. *模式识别与机器学习*. Springer. Bobrow, Daniel G. 1964\. “为计算机问题解决系统提供自然语言输入。” *博士论文，麻省理工学院*. [`dspace.mit.edu/handle/1721.1/12962`](https://dspace.mit.edu/handle/1721.1/12962). Bolchini, Cristiana, Luca Cassano, Antonio Miele, and Alessandro Toschi. 2023\. “针对 CNN 的软错误快速且精确的错误模拟。” *IEEE 计算机 Transactions* 72 (4): 984–97\. [`doi.org/10.1109/tc.2022.3184274`](https://doi.org/10.1109/tc.2022.3184274). Bommasani, Rishi, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, et al. 2021\. “关于基础模型的机会与风险。” *arXiv 预印本 arXiv:2108.07258*, 八月. [`arxiv.org/abs/2108.07258v3`](http://arxiv.org/abs/2108.07258v3). Bonawitz, Keith, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, et al. 2019\. “迈向大规模联邦学习：系统设计，” 二月. [`arxiv.org/abs/1902.01046v2`](http://arxiv.org/abs/1902.01046v2). Borgeaud, Sebastian, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, et al. 2021\. “通过检索万亿个标记来改进语言模型。” *第 39 届国际机器学习会议论文集*，十二月. [`arxiv.org/abs/2112.04426v3`](http://arxiv.org/abs/2112.04426v3). Boroumand, Amirali, Saugata Ghose, Youngsok Kim, Rachata Ausavarungnirun, Eric Shiu, Rahul Thakur, Daehyun Kim, et al. 2018\. “面向消费设备的 Google 工作负载：缓解数据移动瓶颈。” 在 *第 23 届国际架构支持编程语言和操作系统会议论文集*，316–31\. ASPLOS ‘18\. ACM. [`doi.org/10.1145/3173162.3173177`](https://doi.org/10.1145/3173162.3173177). Bouri, Elie. 2015\. “一种扩展的方差因果方法来评估原油价格和约旦股市之间的风险动态。” *能源政策* 85 (十月): 271–79\. [`doi.org/10.1016/j.enpol.2015.06.001`](https://doi.org/10.1016/j.enpol.2015.06.001). Bourtoule, Lucas, Varun Chandrasekaran, Christopher A. Choquette-Choo, Hengrui Jia, Adelin Travers, Baiwu Zhang, David Lie, and Nicolas Papernot. 2021\. “机器反学习。” 在 *2021 IEEE 安全与隐私研讨会*，141–59\. IEEE; IEEE. [`doi.org/10.1109/sp40001.2021.00019`](https://doi.org/10.1109/sp40001.2021.00019). Bradbury, James, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, et al. 2018\. “JAX：Python+NumPy 程序的组合转换。” [`github.com/google/jax`](http://github.com/google/jax). Brain, Google. 2020\. “XLA：机器学习的优化编译器。” *TensorFlow 博客*。 [`www.tensorflow.org/xla`](https://www.tensorflow.org/xla). ——. 2022\. *TensorFlow 文档*。 [`www.tensorflow.org/`](https://www.tensorflow.org/). Brakerski, Zvika et al. 2022\. “联邦学习与边缘智能的兴起：挑战与机遇。” *ACM 通讯* 65 (8): 54–63. Breck, Eric, Shanqing Cai, Eric Nielsen, Michael Salib, and D. Sculley. 2017b. “ML 测试分数：ML 生产准备和技术债务减少的评分标准。” 在 *2017 IEEE 大数据国际会议*，6:1123–32\. 2\. IEEE. [`doi.org/10.1109/bigdata.2017.8258038`](https://doi.org/10.1109/bigdata.2017.8258038). ——. 2017a. “ML 测试分数：ML 生产准备和技术债务减少的评分标准。” 在 *2017 IEEE 大数据国际会议*，1123–32\. IEEE; IEEE. [`doi.org/10.1109/bigdata.2017.8258038`](https://doi.org/10.1109/bigdata.2017.8258038). Breier, Jakub, Xiaolu Hou, Dirmanto Jap, Lei Ma, Shivam Bhasin, and Yang Liu. 2018\. “DeepLaser：对深度神经网络的实用故障攻击。” *arXiv 预印本* abs/1806.05859 (六月): 619–33\. [`arxiv.org/abs/1806.05859v2`](http://arxiv.org/abs/1806.05859v2). Brohan, Anthony, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, et al. 2023\. “RT-2：将网络知识转移到机器人控制中的视觉-语言-动作模型，” 七月. [`arxiv.org/abs/2307.15818v1`](http://arxiv.org/abs/2307.15818v1). Brooks, R. 1986\. “一种用于移动机器人的鲁棒分层控制系统。” *IEEE 机器人与自动化杂志* 2 (1): 14–23\. [`doi.org/10.1109/jra.1986.1087032`](https://doi.org/10.1109/jra.1986.1087032). Brown, Samantha. 2021\. “长期软件支持：可持续 AI 硬件的关键因素。” *计算机伦理与可持续性* 14 (2): 112–30. Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Saxena, et al. 2020\. “语言模型是少样本学习者。” *神经信息处理系统进展* 33: 1877–1901. Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, et al. 2020\. “语言模型是少样本学习者。” *NeurIPS*，五月. [`arxiv.org/abs/2005.14165v4`](http://arxiv.org/abs/2005.14165v4). Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020\. “语言模型是少样本学习者。” *神经信息处理系统进展* 33: 1877–1901. Buolamwini, Joy, and Timnit Gebru. 2018\. “性别阴影：商业性别分类中的交叉准确性差异。” 在 *公平、问责制和透明度会议*，77–91\. PMLR. [`proceedings.mlr.press/v81/buolamwini18a.html`](http://proceedings.mlr.press/v81/buolamwini18a.html). Burnet, David, and Richard Thomas. 1989\. “间谍克星：真相的商品化。” *法律与社会杂志* 16 (2): 210\. [`doi.org/10.2307/1410360`](https://doi.org/10.2307/1410360). Bursztein, Elie, Luca Invernizzi, Karel Král, Daniel Moghimi, Jean-Michel Picod, and Marina Zhang. 2024b. “使用长距离深度学习对加密硬件进行泛化功率攻击。” *IACR 加密硬件与嵌入式系统交易* 2024 (3): 472–99\. [`doi.org/10.46586/tches.v2024.i3.472-499`](https://doi.org/10.46586/tches.v2024.i3.472-499). ——. 2024a. “使用长距离深度学习对加密硬件进行泛化功率攻击。” *IACR 加密硬件与嵌入式系统交易* 2024 (3): 472–99\. [`doi.org/10.46586/tches.v2024.i3.472-499`](https://doi.org/10.46586/tches.v2024.i3.472-499). Bushnell, Michael L, and Vishwani D Agrawal. 2002\. “内置自检。” *数字、存储和混合信号 VLSI 电路电子测试基础*，489–548. Cai, Carrie J., Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel Smilkov, Martin Wattenberg, et al. 2019\. “在医疗决策过程中应对不完美算法的人性化工具。” 在 *2019 CHI 会议关于人机交互系统中的因素*，由 Jennifer G. Dy 和 Andreas Krause 编辑，80:1–14\. 机器学习研究会议论文集。ACM. [`doi.org/10.1145/3290605.3300234`](https://doi.org/10.1145/3290605.3300234). Cai, Han, Chuang Gan, and Song Han. 2020\. “一次完成：训练一个网络并将其专门用于高效部署。” 在 *国际学习表示会议*。 Calvo, Rafael A., Dorian Peters, Karina Vold, and Richard M. Ryan. 2020\. “支持 AI 系统中人类自主性的框架：伦理探究框架。” 在 *数字福祉伦理*，31–54\. Springer 国际出版。 [`doi.org/10.1007/978-3-030-50585-1\_2`](https://doi.org/10.1007/978-3-030-50585-1\_2). Campbell, Murray, Jr. Hoane A.Joseph, and Feng-hsiung Hsu. 2002\. “Deep Blue。” *人工智能* 134 (1-2): 57–83\. [`doi.org/10.1016/s0004-3702(01)00129-1`](https://doi.org/10.1016/s0004-3702(01)00129-1). Carlini, Nicholas, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang 0001, Micah Sherr, Clay Shields, David A. Wagner 0001, and Wenchao Zhou. 2016\. “隐藏语音命令。” 在 *第 25 届 USENIX 安全研讨会*，513–30\. [`www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/carlini`](https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/carlini). Carlini, Nicholas, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, et al. 2024\. “窃取生产语言模型的一部分。” *arXiv 预印本 arXiv:2403.06634*，三月. [`arxiv.org/abs/2403.06634v2`](http://arxiv.org/abs/2403.06634v2). Carlini, Nicholas, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, et al. 2021\. “从大型语言模型中提取训练数据。” 在 *第 30 届 USENIX 安全研讨会*，2633–50\. USENIX 协会。 [`www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting`](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting). Carlini, Nicholas, and David Wagner. 2017\. “评估神经网络鲁棒性的方法。” 在 *2017 IEEE 安全与隐私研讨会*，39–57\. IEEE. [`doi.org/10.1109/sp.2017.49`](https://doi.org/10.1109/sp.2017.49). Center, Pew Research. 2023\. “美国人关于 AI、网络安全和大型科技的了解。” [`www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/`](https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/)

    https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/

) .Centers, Google Data. 2023\. “效率：我们是如何做到的。” [`www.google.com/about/datacenters/efficiency/`](https://www.google.com/about/datacenters/efficiency/).Chandola, Varun, Arindam Banerjee, and Vipin Kumar. 2009\. “异常检测：综述。” *ACM 计算机调查* 41 (3): 1–58\. [`doi.org/10.1145/1541880.1541882`](https://doi.org/10.1145/1541880.1541882).Chapelle, O., B. Scholkopf, and A. Zien Eds. 2009\. “半监督学习（Chapelle, o. 等，编；2006）[书评]。” *IEEE 交易神经网络* 20 (3): 542–42\. [`doi.org/10.1109/tnn.2009.2015974`](https://doi.org/10.1109/tnn.2009.2015974).Chapman, Pete, Julian Clinton, Randy Kerber, Thomas Khabaza, Thomas Reinartz, Colin Shearer, and Rudiger Wirth. 2000\. “CRISP-DM 1.0：逐步数据挖掘指南。” *SPSS Inc*，78\. [`www.the-modeling-agency.com/crisp-dm.pdf`](https://www.the-modeling-agency.com/crisp-dm.pdf).Chen, Andrew, Andy Chow, Aaron Davidson, Arjun DCunha, Ali Ghodsi, Sue Ann Hong, Andy Konwinski, et al. 2020\. “MLflow 的发展：一个加速机器学习生命周期的系统。” 在 *第四国际研讨会数据管理用于端到端机器学习*，1–4\. ACM。 [`doi.org/10.1145/3399579.3399867`](https://doi.org/10.1145/3399579.3399867)。Chen, Chaofan, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, and Jonathan Su. 2019\. “This Looks Like That：用于可解释图像识别的深度学习。” 在 *第 32 届神经信息处理系统年会：2019 年 12 月 8-14 日在加拿大不列颠哥伦比亚省温哥华举行的神经信息处理系统 2019 年年会，NeurIPS 2019*，由 Hanna M. Wallach，Hugo Larochelle，Alina Beygelzimer，Florence d’Alché-Buc，Emily B. Fox 和 Roman Garnett 编辑，8928–39\. [`proceedings.neurips.cc/paper/2019/hash/adf7ee2dcf142b0e11888e72b43fcb75-Abstract.html`](https://proceedings.neurips.cc/paper/2019/hash/adf7ee2dcf142b0e11888e72b43fcb75-Abstract.html)。Chen, Emma, Shvetank Prakash, Vijay Janapa Reddi, David Kim, and Pranav Rajpurkar. 2023\. “一个将人工智能临床护理与连续治疗监测集成的框架。” *自然生物医学工程* 9 (4): 445–54\. [`doi.org/10.1038/s41551-023-01115-0`](https://doi.org/10.1038/s41551-023-01115-0)。Chen, H.-W. 2006\. “来自台湾半导体制造区的地下水中的镓、铟和砷污染。” *环境污染与毒理学通报* 77 (2): 289–96\. [`doi.org/10.1007/s00128-006-1062-3`](https://doi.org/10.1007/s00128-006-1062-3)。Chen, Jonathan H. 和 Steven M. Asch. 2017\. “医学中的机器学习和预测——超越膨胀期望的顶峰。” *新英格兰医学杂志* 376 (26): 2507–9\. [`doi.org/10.1056/nejmp1702071`](https://doi.org/10.1056/nejmp1702071)。Chen, Mark, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, et al. 2021\. “评估在代码上训练的大型语言模型。” *arXiv 预印本 arXiv:2107.03374*，七月。 [`arxiv.org/abs/2107.03374v2`](http://arxiv.org/abs/2107.03374v2)。Chen, Tianqi, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, and Zheng Zhang. 2015\. “MXNet：用于异构分布式系统的灵活高效的机器学习库。” *arXiv 预印本 arXiv:1512.01274*，十二月。 [`arxiv.org/abs/1512.01274v1`](http://arxiv.org/abs/1512.01274v1)。Chen, Tianqi, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. 2016\. “以亚线性内存成本训练深度网络。” *CoRR* abs/1604.06174（四月）。 [`arxiv.org/abs/1604.06174v2`](http://arxiv.org/abs/1604.06174v2)。Chen, Yu-Hsin, Joel Emer, and Vivienne Sze. 2017\. “使用数据流优化深度神经网络加速器的能效。” *IEEE 微型* 37 (3): 12–21\. [`doi.org/10.1109/mm.2017.54`](https://doi.org/10.1109/mm.2017.54)。Chen, Yu-Hsin, Tushar Krishna, Joel S. Emer, and Vivienne Sze. 2016\. “Eyeriss：用于能量高效数据流的卷积神经网络的空间架构。” *IEEE 固态电路杂志* 51 (1): 186–98\. [`doi.org/10.1109/JSSC.2015.2488709`](https://doi.org/10.1109/JSSC.2015.2488709)。Chen, Zitao, Guanpeng Li, Karthik Pattabiraman, and Nathan DeBardeleben. 2019\. “<I>BinFI</i>：一个用于关键机器学习系统的有效故障注入器。” 在 *高性能计算、网络、存储和分析国际会议论文集*，1–23\. SC ‘19。纽约，纽约，美国：ACM。 [`doi.org/10.1145/3295500.3356177`](https://doi.org/10.1145/3295500.3356177)。Chen, Zitao, Niranjhana Narayanan, Bo Fang, Guanpeng Li, Karthik Pattabiraman, and Nathan DeBardeleben. 2020\. “TensorFI：一个用于 TensorFlow 应用的灵活故障注入框架。” 在 *2020 IEEE 第 31 届软件可靠性工程国际研讨会 (ISSRE)*，426–35\. IEEE；IEEE。 [`doi.org/10.1109/issre5003.2020.00047`](https://doi.org/10.1109/issre5003.2020.00047)。Cheng, Eric, Shahrzad Mirkhani, Lukasz G. Szafaryn, Chen-Yong Cher, Hyungmin Cho, Kevin Skadron, Mircea R. Stan, et al. 2016\. “CLEAR：<U>c</u> Ross <u>-l</u> Ayer <u>e</u> Xploration for <u>a</u> Rchitecting <u>r</u> Esilience - 结合硬件和软件技术以容忍处理器核心中的软错误。” 在 *第 53 届年度设计自动化会议论文集*，1–6\. ACM。 [`doi.org/10.1145/2897937.2897996`](https://doi.org/10.1145/2897937.2897996)。Cheng, Yu 等人。 2022\. “内存高效深度学习：模型压缩和稀疏化方面的进展。” *ACM 计算机调查*。Cheshire, David. 2021\. “循环经济和可持续人工智能：在技术行业中消除浪费。” 在 *建立循环经济的指南*，48–61\. RIBA 出版。 [`doi.org/10.4324/9781003212775-8`](https://doi.org/10.4324/9781003212775-8)。Chetlur, Sharan, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen, John Tran, Bryan Catanzaro, and Evan Shelhamer. 2014\. “cuDNN：深度学习的有效原语。” *arXiv 预印本 arXiv:1410.0759*，十月。 [`arxiv.org/abs/1410.0759v3`](http://arxiv.org/abs/1410.0759v3)。Chin-Purcell, Lia 和 America Chambers. 2021\. “调查使用卷积神经网络进行性别分类的准确性差异。” 在 *2021 IEEE 国际技术与社会研讨会 (ISTAS)*，81:1–7\. IEEE。 [`doi.org/10.1109/istas52410.2021.9629153`](https://doi.org/10.1109/istas52410.2021.9629153)。Cho, Kyunghyun, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014\. “关于神经机器翻译的性质：编码器-解码器方法。” 在 *第八次统计翻译语法、语义和结构研讨会 (SSST-8)*，103–11\. 计算机语言学协会。Choi, Jungwook, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang, Vijayalakshmi Srinivasan, and Kailash Gopalakrishnan. 2018\. “PACT：参数化剪裁激活用于量化神经网络。” *arXiv 预印本*，五月。 [`arxiv.org/abs/1805.06085v2`](http://arxiv.org/abs/1805.06085v2)。Choi, Sebin 和 Sungmin Yoon. 2024\. “基于 GPT 的数据驱动城市建筑能源建模 (GPT-UBEM)：概念、方法和案例研究。” *能源与建筑* 325（十二月）：115042\. [`doi.org/10.1016/j.enbuild.2024.115042`](https://doi.org/10.1016/j.enbuild.2024.115042)。Chollet, François 等人。 2015\. “Keras。” *GitHub 仓库*。 [`github.com/fchollet/keras`](https://github.com/fchollet/keras)。Chollet, François。 2019\. “关于智能的度量。” *arXiv 预印本 arXiv:1911.01547*，十一月。 [`arxiv.org/abs/1911.01547v2`](http://arxiv.org/abs/1911.01547v2)。Choquette, Jack。 2023a。 “NVIDIA Hopper H100 GPU：扩展性能。” *IEEE 微型* 43 (3): 9–17\. [`doi.org/10.1109/mm.2023.3256796`](https://doi.org/10.1109/mm.2023.3256796)。——。 2023b。 “NVIDIA Hopper H100 GPU：扩展性能。” *IEEE 微型* 43 (3): 9–17\. [`doi.org/10.1109/mm.2023.3256796`](https://doi.org/10.1109/mm.2023.3256796)。Choquette, Jack，Wishwesh Gandhi，Olivier Giroux，Nick Stam 和 Ronny Krashinsky。 2021\. “NVIDIA A100 Tensor Core GPU：性能和创新。” *IEEE 微型* 41 (2): 29–35\. [`doi.org/10.1109/mm.2021.3061394`](https://doi.org/10.1109/mm.2021.3061394)。Choudhary, Tejalal，Vipul Mishra，Anurag Goswami 和 Jagannathan Sarangapani。 2020\. “模型压缩和加速的全面调查。” *人工智能评论* 53 (7): 5113–55\. [`doi.org/10.1007/s10462-020-09816-7`](https://doi.org/10.1007/s10462-020-09816-7)。Chowdhery, Aakanksha，Sharan Narang，Jacob Devlin，Maarten Bosma，Gaurav Mishra，Adam Roberts，Paul Barham，等人。 2022\. “PaLM：通过路径扩展语言模型。” *arXiv 预印本 arXiv:2204.02311*，四月。 [`arxiv.org/abs/2204.02311v5`](http://arxiv.org/abs/2204.02311v5)。Chowdhery, Aakanksha，Anatoli Noy，Gaurav Misra，Zhuyun Dai，Quoc V. Le 和 Jeff Dean。 2021\. “Edge TPU：一个用于深度学习的边缘优化推理加速器。” 在 *国际计算机架构研讨会*。Chowdhury, Badrul H. 和 Chung-Li Tseng。 2007\. “分布式能源资源：问题和挑战。” *能源工程杂志* 133 (3): 109–10\. [`doi.org/10.1061/(asce)0733-9402(2007)133:3(109)`](https://doi.org/10.1061/(asce)0733-9402(2007)133:3(109))。Christiano, Paul，Jan Leike，Tom

    https://software.intel.com/content/www/us/en/develop/download/intel-architecture-instruction-set-extensions-programming-reference.html

) .Corporation, Thinking Machines. 1992\. *CM-5 技术摘要*. Thinking Machines Corporation.Costa, Tiago, Chen Shi, Kevin Tien, and Kenneth L. Shepard. 2019\. “一种用于神经调节的 CMOS 2D 发射波束成形器及其集成 PZT 超声波换能器。” 在 *2019 IEEE 自定义集成电路会议 (CICC)* 中，第 1-4 页。IEEE。 [`doi.org/10.1109/cicc.2019.8780236`](https://doi.org/10.1109/cicc.2019.8780236).Courbariaux, Matthieu, Yoshua Bengio, and Jean-Pierre David. 2016\. “BinaryConnect：在传播过程中使用二进制权重训练深度神经网络。” *神经信息处理系统 (NeurIPS)* 28: 3123–31.Courbariaux, Matthieu, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. 2016\. “二值化神经网络：使用权重和激活约束为 +1 或 -1 训练深度神经网络。” *arXiv 预印本 arXiv:1602.02830*，二月。 [`arxiv.org/abs/1602.02830v3`](http://arxiv.org/abs/1602.02830v3).Cover, Thomas M. 和 Joy A. Thomas. 2001\. *信息论基础*. 第 2 版。 Wiley。 [`doi.org/10.1002/0471200611`](https://doi.org/10.1002/0471200611).Crankshaw, Daniel, Xin Wang, Guilio Zhou, Michael J Franklin, Joseph E Gonzalez, 和 Ion Stoica. 2017\. “Clipper：一个 <semantics><mo stretchy="false" form="prefix">{</mo><annotation encoding="application/x-tex">\{</annotation></semantics>低延迟<semantics><mo stretchy="false" form="postfix">}</mo><annotation encoding="application/x-tex">\}</annotation></semantics> 在线预测服务系统。” 在 *第 14 届 USENIX 网络系统设计和实现研讨会 (NSDI 17)* 中，第 613-27 页。Crankshaw, Daniel, Xin Wang, Guilio Zhou, Michael J Franklin, Joseph E Gonzalez, 和 Ion Stoica. 2017\. “Clipper：一个 <semantics><mo stretchy="false" form="prefix">{</mo><annotation encoding="application/x-tex">\{</annotation></semantics>低延迟<semantics><mo stretchy="false" form="postfix">}</mo><annotation encoding="application/x-tex">\}</annotation></semantics> 在线预测服务系统。” 在 *第 14 届 USENIX 网络系统设计和实现研讨会 (NSDI 17)* 中，第 613-27 页。CrowdFlower. n.d. “补充信息 1：Matlab 分析的源代码，相关矩阵，Crowdflower 调查的 XML 代码。” *CrowdFlower Inc*。 PeerJ。 [`doi.org/10.7287/peerj.preprints.1069/supp-1`](https://doi.org/10.7287/peerj.preprints.1069/supp-1)。Cui, Hongyi, Jiajun Li, 和 Peng et al. Xie. 2019\. “机器学习编译器综述：分类、挑战和未来方向。” *ACM 计算评论* 52 (4): 1–39。Cybenko, G. 1989\. “使用 Sigmoid 函数的叠加逼近。” *控制、信号和系统数学* 2 (4): 303–14。 [`doi.org/10.1007/bf02551274`](https://doi.org/10.1007/bf02551274)。Dalal, N. 和 B. Triggs. n.d. “方向梯度直方图用于人类检测。” 在 *2005 IEEE 计算机视觉和模式识别会议 (CVPR’05)* 中，第 1:886–93。IEEE；IEEE。 [`doi.org/10.1109/cvpr.2005.177`](https://doi.org/10.1109/cvpr.2005.177)。Dally, William J.，Stephen W. Keckler 和 David B. Kirk. 2021\. “图形处理单元 (GPU) 的演变。” *IEEE 微型* 41 (6):

    [《大黑客：中国如何利用微型芯片渗透美国顶级公司》](https://www.bloomberg.com/news/features/2018-10-04/the-big-hack-how-china-used-a-tiny-chip-to-infiltrate-america-s-top-companies)

Rodio, Angelo, 和 Giovanni Neglia. 2024. “FedStale: 利用联邦学习中的过时客户端更新,” 五月. [`arxiv.org/abs/2405.04171v1`](http://arxiv.org/abs/2405.04171v1). Rolnick, David, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, 和 Greg Wayne. 2019. “经验回放用于持续学习.” 在 *Advances in Neural Information Processing Systems (NeurIPS)*. Romero, Francisco, Qian Li 0027, Neeraja J. Yadwadkar, 和 Christos Kozyrakis. 2021. “INFaaS: 自动化无模型推理服务.” 在 *2021 USENIX 年度技术会议 (USENIX ATC 21)*, 397–411. [`www.usenix.org/conference/atc21/presentation/romero`](https://www.usenix.org/conference/atc21/presentation/romero). Rosenblatt, F. 1958. “感知器：大脑中信息存储和组织的一种概率模型.” *心理学评论* 65 (6): 386–408. [`doi.org/10.1037/h0042519`](https://doi.org/10.1037/h0042519). Ross, Stéphane, Geoffrey J. Gordon, 和 Drew Bagnell. 2011. “将模仿学习和结构化预测简化为无后悔在线学习.” *国际人工智能与统计会议* 15: 627–35. [`proceedings.mlr.press/v15/ross11a.html`](http://proceedings.mlr.press/v15/ross11a.html). Royce, W. W. 1987. “管理大型软件系统的发展：概念和技术.” 在 *IEEE WESCON 会议论文集*, 26:328–39. IEEE. [`dl.acm.org/citation.cfm?id=41801`](http://dl.acm.org/citation.cfm?id=41801). Rudin, Cynthia. 2019. “停止解释黑盒机器学习模型用于高风险决策，而应使用可解释模型.” *自然机器智能* 1 (5): 206–15. [`doi.org/10.1038/s42256-019-0048-x`](https://doi.org/10.1038/s42256-019-0048-x). Rumelhart, David E., Geoffrey E. Hinton, 和 Ronald J. Williams. 1986. “通过反向传播错误学习表示.” *自然* 323 (6088): 533–36. [`doi.org/10.1038/323533a0`](https://doi.org/10.1038/323533a0). Russakovsky, Olga, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, 等人. 2015. “ImageNet 大规模视觉识别挑战.” *国际计算机视觉杂志* 115 (3): 211–52. [`doi.org/10.1007/s11263-015-0816-y`](https://doi.org/10.1007/s11263-015-0816-y). Russell, Mark. 2022. “技术行业趋势：硬件锁定及其可持续性影响.” *可持续计算杂志* 10 (1): 34–50. Russell, Stuart. 2021. “人类兼容的人工智能.” 在 *类似人类的机器智能*，3–23. 牛津大学出版社. [`doi.org/10.1093/oso/9780198862536.003.0001`](https://doi.org/10.1093/oso/9780198862536.003.0001). Ryan, Richard M., 和 Edward L. Deci. 2000. “自我决定理论及其对内在动机、社会发展和幸福感的促进作用.” *美国心理学家* 55 (1): 68–78. [`doi.org/10.1037/0003-066x.55.1.68`](https://doi.org/10.1037/0003-066x.55.1.68). Sabour, Sara, Nicholas Frosst, 和 Geoffrey E Hinton. 2017. “胶囊之间的动态路由.” 在 *Advances in Neural Information Processing Systems*. 第 30 卷. Sambasivan, Nithya, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, 和 Lora M

    [2022 年神经信息处理系统会议论文摘要](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html)

) .Weizenbaum, Joseph. 1966\. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” *Communications of the ACM* 9 (1): 36–45\. [`doi.org/10.1145/365153.365168`](https://doi.org/10.1145/365153.365168).Werchniak, Andrew, Roberto Barra Chicote, Yuriy Mishchenko, Jasha Droppo, Jeff Condal, Peng Liu, and Anish Shah. 2021\. “Exploring the Application of Synthetic Audio in Training Keyword Spotters.” In *ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, 7993–96\. IEEE; IEEE. [`doi.org/10.1109/icassp39728.2021.9413448`](https://doi.org/10.1109/icassp39728.2021.9413448).Widmer, Gerhard, and Miroslav Kubat. 1996\. “Learning in the Presence of Concept Drift and Hidden Contexts.” *Machine Learning* 23 (1): 69–101\. [`doi.org/10.1023/a:1018046501280`](https://doi.org/10.1023/a:1018046501280).Wiener, Norbert. 1960\. “Some Moral and Technical Consequences of Automation: As Machines Learn They May Develop Unforeseen Strategies at Rates That Baffle Their Programmers.” *Science* 131 (3410): 1355–58\. [`doi.org/10.1126/science.131.3410.1355`](https://doi.org/10.1126/science.131.3410.1355).Wilkening, Mark, Vilas Sridharan, Si Li, Fritz Previlon, Sudhanva Gurumurthi, and David R. Kaeli. 2014\. “Calculating Architectural Vulnerability Factors for Spatial Multi-Bit Transient Faults.” In *2014 47th Annual IEEE/ACM International Symposium on Microarchitecture*, 293–305\. IEEE; IEEE. [`doi.org/10.1109/micro.2014.15`](https://doi.org/10.1109/micro.2014.15).Witten, Ian H., and Eibe Frank. 2002\. “Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.” *ACM SIGMOD Record* 31 (1): 76–77\. [`doi.org/10.1145/507338.507355`](https://doi.org/10.1145/507338.507355).Wolfe, Jeremy M., Dennis M. Levi, Lori L. Holt, Linda M. Bartoshuk, Rachel S. Herz, Roberta L. Klatzky, and Daniel M. Merfeld. 2024\. “Perceiving and Recognizing Objects.” Technical Report. In *Sensation & Perception*. 85-460-1\. Cornell Aeronautical Laboratory; Oxford University Press. [`doi.org/10.1093/hesc/9780197663813.003.0005`](https://doi.org/10.1093/hesc/9780197663813.003.0005).Wolpert, D. H., and W. G. Macready. 1997\. “No Free Lunch Theorems for Optimization.” *IEEE Transactions on Evolutionary Computation* 1 (1): 67–82\. [`doi.org/10.1109/4235.585893`](https://doi.org/10.1109/4235.585893).MIT 未来工作任务小组. 2020\. “未来工作：在智能机器时代创造更好的工作。”麻省理工学院。[`workofthefuture.mit.edu/research-post/the-work-of-the-future-building-better-jobs-in-an-age-of-intelligent-machines/`](https://workofthefuture.mit.edu/research-post/the-work-of-the-future-building-better-jobs-in-an-age-of-intelligent-machines/)

    [未来工作的研究](https://workofthefuture.mit.edu/research-post/the-work-of-the-future-building-better-jobs-in-an-age-of-intelligent-machines/)

Wu, Bichen, Kurt Keutzer, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, and Yangqing Jia. 2019. “FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search.” In *2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 10726–34. IEEE. [`doi.org/10.1109/cvpr.2019.01099`](https://doi.org/10.1109/cvpr.2019.01099). Wu, Carole-Jean, David Brooks, Kevin Chen, Douglas Chen, Sy Choudhury, Marat Dukhan, Kim Hazelwood, et al. 2019. “Machine Learning at Facebook: Understanding Inference at the Edge.” In *2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)*, 331–44. IEEE; IEEE. [`doi.org/10.1109/hpca.2019.00048`](https://doi.org/10.1109/hpca.2019.00048). Wu, Carole-Jean, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, et al. 2022. “Sustainable Ai: Environmental Implications, Challenges and Opportunities.” *Proceedings of Machine Learning and Systems* 4: 795–813. Wu, Hao, Patrick Judd, Xiaojie Zhang, Mikhail Isaev, and Paulius Micikevicius. 2020. “Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation.” *arXiv Preprint arXiv:2004.09602* abs/2004.09602 (April). [`arxiv.org/abs/2004.09602v1`](http://arxiv.org/abs/2004.09602v1). Wu, Jian, Hao Cheng, and Yifan Zhang. 2019. “Fast Neural Networks: Efficient and Adaptive Computation for Inference.” In *Advances in Neural Information Processing Systems*. Wu, Jiaxiang, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng. 2016. “Quantized Convolutional Neural Networks for Mobile Devices.” In *2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 4820–28. IEEE. [`doi.org/10.1109/cvpr.2016.521`](https://doi.org/10.1109/cvpr.2016.521). Xin, Ji, Raphael Tang, Yaoliang Yu, and Jimmy Lin. 2021. “BERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression.” In *Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume*, edited by Paola Merlo, Jorg Tiedemann, and Reut Tsarfaty, 91–104. Online: Association for Computational Linguistics. [`doi.org/10.18653/v1/2021.eacl-main.8`](https://doi.org/10.18653/v1/2021.eacl-main.8). Xingyu, Huang et al. 2019. “Addressing the Memory Bottleneck in AI Accelerators.” *IEEE Micro*. Xu, Ruijie, Zengzhi Wang, Run-Ze Fan, and Pengfei Liu. 2024. “Benchmarking Benchmark Leakage in Large Language Models.” *arXiv Preprint arXiv:2404.18824*, April. [`arxiv.org/abs/2404.18824v1`](http://arxiv.org/abs/2404.18824v1). Xu, Xiaolong, Fan Li, Wei Zhang, Liang He, and Ruidong Li. 2021. “Edge Intelligence: Architectures, Challenges, and Applications.” *IEEE Internet of Things Journal* 8 (6): 4229–49. Yang, Le, Yizeng Han, Xi Chen, Shiji Song, Jifeng Dai, and Gao Huang. 2020. “Resolution Adaptive Networks for Efficient Inference.” In *2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2366–75. IEEE. [`doi.org/10.1109/cvpr42600.2020.00244`](https://doi.org/10.1109/cvpr42600.2020.00244). Yao, Zhewei, Amir Gholami, Sheng Shen, Kurt Keutzer, and Michael W. Mahoney. 2021. “HAWQ-V3: Dyadic Neural Network Quantization.” In *Proceedings of the 38th International Conference on Machine Learning (ICML)*, 11875–86. PMLR. Ye, Zirui, Bei Yao, Haoran Zheng, Li Tao, Ripeng Wang, Yankui Chang, Zhi Chen, Yingming Zhao, Wei Wei, and Xie George Xu. 2025. “Uncertainty Quantification for CT Dosimetry Based on 10 281 Subjects Using Automatic Image Segmentation and Fast Monte Carlo Calculations.” *Medical Physics* 52 (6): 4910–23. [`doi.org/10.1002/mp.17796`](https://doi.org/10.1002/mp.17796). Yeh, Y. C. n.d. “Triple-Triple Redundant 777 Primary Flight Computer.” In *1996 IEEE Aerospace Applications Conference. Proceedings*, 1:293–307. IEEE; IEEE. [`doi.org/10.1109/aero.1996.495891`](https://doi.org/10.1109/aero.1996.495891). Yosinski, Jason, Jeff Clune, Yoshua Bengio, and Hod Lipson. 2014. “How Transferable Are Features in Deep Neural Networks?” *Advances in Neural Information Processing Systems* 27. You, Jie, Jae-Won Chung, and Mosharaf Chowdhury. 2023. “Zeus: Understanding and Optimizing GPU Energy Consumption of DNN Training.” In *20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)*, 119–39. Boston, MA: USENIX Association. [`www.usenix.org/conference/nsdi23/presentation/you`](https://www.usenix.org/conference/nsdi23/presentation/you). You, Yang, Zhao Zhang, Cho-Jui Hsieh, James Demmel, and Kurt Keutzer. 2019. “Scaling SGD Batch Size to 32K for ImageNet Training.” In *Proceedings of Machine Learning and Systems*. Yu, Jun, Peng Li, and Zhenhua Wang. 2023. “Efficient Early Exiting Strategies for Neural Network Acceleration.” *IEEE Transactions on Neural Networks and Learning Systems*. Zafrir, Ofir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. 2019. “Q8BERT: Quantized 8Bit BERT.” In *2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS)*, 36–39. IEEE; IEEE. [`doi.org/10.1109/emc2-nips53020.2019.00016`](https://doi.org/10.1109/emc2-nips53020.2019.00016). Zaharia, Matei, Omar Chaudhury, Michael McCann, et al. 2024. “The Shift from Models to Compound AI Systems.” Berkeley Artificial Intelligence Research. [`bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/`](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/). Zhan, Ruiting, Zachary Oldenburg, and Lei Pan. 2018. “Recovery of Active Cathode Materials from Lithium-Ion Batteries Using Froth Flotation.” *Sustainable Materials and Technologies* 17 (September): e00062. [`doi.org/10.1016/j.susmat.2018.e00062`](https://doi.org/10.1016/j.susmat.2018.e00062). Zhang, Chengliang, Minchen Yu, Wei Wang 0030, and Feng Yan 0001. 2019. “MArk: Exploiting Cloud Services for Cost-Effective, SLO-Aware Machine Learning Inference Serving.” In *2019 USENIX Annual Technical Conference (USENIX ATC 19)*, 1049–62. [`www.usenix.org/conference/atc19/presentation/zhang-chengliang`](https://www.usenix.org/conference/atc19/presentation/zhang-chengliang). Zhang, Jeff Jun, Tianyu Gu, Kanad Basu, and Siddharth Garg. 2018. “Analyzing and Mitigating the Impact of Permanent Faults on a Systolic Array Based Neural Network Accelerator.” In *2018 IEEE 36th VLSI Test Symposium (VTS)*, 1–6. IEEE; IEEE. [`doi.org/10.1109/vts.2018.8368656`](https://doi.org/10.1109/vts.2018.8368656). Zhang, Jeff, Kartheek Rangineni, Zahra Ghodsi, and Siddharth Garg. 2018. “ThUnderVolt: Enabling Aggressive Voltage Underscaling and Timing Error Resilience for Energy Efficient Deep Learning Accelerators.” In *2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)*, 1–6. IEEE. [`doi.org/10.1109/dac.2018.8465918`](https://doi.org/10.1109/dac.2018.8465918). Zhang, Qingxue, Dian Zhou, and Xuan Zeng. 2017. “Highly Wearable Cuff-Less Blood Pressure and Heart Rate Monitoring with Single-Arm Electrocardiogram and Photoplethysmogram Signals.” *BioMedical Engineering OnLine* 16 (1): 23. [`doi.org/10.1186/s12938-017-0317-z`](https://doi.org/10.1186/s12938-017-0317-z). Zhang, Xitong, Jialin Song, and Dacheng Tao. 2020. “Efficient Task-Specific Adaptation for Deep Models.” In *International Conference on Learning Representations (ICLR)*. Zhang, Yi, Jianlei Yang, Linghao Song, Yiyu Shi, Yu Wang, and Yuan Xie. 2021. “Learning-Based Efficient Sparsity and Quantization for Neural Network Compression.” *IEEE Transactions on Neural Networks and Learning Systems* 32 (9): 3980–94. Zhang, Y., J. Li, and H. Ouyang. 2020. “Optimizing Memory Access for Deep Learning Workloads.” *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems* 39 (11): 2345–58. Zhao, Jiawei, Zhenyu Zhang, Beidi Chen, Zhangyang Wang, Anima Anandkumar, and Yuandong Tian. 2024. “GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection,” March. [`arxiv.org/abs/2403.03507v2`](http://arxiv.org/abs/2403.03507v2). Zhao, Mark, and G. Edward Suh. 2018. “FPGA-Based Remote Power Side-Channel Attacks.” In *2018 IEEE Symposium on Security and Privacy (SP)*, 229–44. IEEE; IEEE. [`doi.org/10.1109/sp.2018.00049`](https://doi.org/10.1109/sp.2018.00049). Zhao, Yue, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. 2018. “Federated Learning with Non-IID Data.” *CoRR* abs/1806.00582 (June). [`arxiv.org/abs/1806.00582v2`](http://arxiv.org/abs/1806.00582v2). Zheng, Lianmin, Ziheng Jia, Yida Gao, Jiacheng Lin, Song Han, Xuehai Geng, Eric Zhao, and Tianqi Wu. 2020. “Ansor: Generating High-Performance Tensor Programs for Deep Learning.” *USENIX Symposium on Operating Systems Design and Implementation (OSDI)*, 863–79. Zhou, Aojun, Yukun Ma, Junnan Zhu, Jianbo Liu, Zhijie Zhang, Kun Yuan, Wenxiu Sun, and Hongsheng Li. 2021. “Learning n:m Fine-Grained Structured Sparse Neural Networks from Scratch,” February. [`arxiv.org/abs/2102.04010v2`](http://arxiv.org/abs/2102.04010v2). Zhu, Chenzhuo, Song Han, Huizi Mao, and William J. Dally. 2017. “Trained Ternary Quantization.” *International Conference on Learning Representations (ICLR)*. Zimmermann, H. 2007. “Neural Signaling: It’s Jump Time.” *Science* 317 (5841): 1028–29. [`doi.org/10.1126/science.1147015`](https://doi.org/10.1126/science.1147015). Zoph, Barret, and Quoc V Le. 2017a. “Neural Architecture Search with Reinforcement Learning.” In *International Conference on Learning Representations (ICLR)*. Zoph, Barret, and Quoc V. Le. 2017b. “Neural Architecture Search with Reinforcement Learning.” In *International Conference on Learning Representations*.
