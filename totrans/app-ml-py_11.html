<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Feature Imputation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Feature Imputation</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_feature_imputation.html">https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_feature_imputation.html</a></blockquote>

<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book ‚ÄúApplied Machine Learning in Python: a Hands-on Guide with Code‚Äù.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, <em>Applied Machine Learning in Python: A Hands-on Guide with Code</em> [e-book]. Zenodo. doi:10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="../Images/7e4ea662f44af1eae87e87ecbb962ff4.png" data-original-src="https://zenodo.org/badge/863274676.svg"/></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, <em>MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository</em> (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312. GitHub repository: <a class="github reference external" href="https://github.com/GeostatsGuy/MachineLearningDemos">GeostatsGuy/MachineLearningDemos</a> <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="../Images/4e3a59c17d684b06a170c4af84e0f631.png" data-original-src="https://zenodo.org/badge/862519860.svg"/></a></p>
</div>
<p>By Michael J. Pyrcz <br/>
¬© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>Feature Imputation</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/embks9p4pb8?si=B2HXm_i0oMSWkBhN">Curse of Dimensionality, Dimensionality Reduction, Principal Component Analysis</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/Yt0o8ukIOKU?si=_ri1NPwKVdhYzgO3">Multidimensional Scaling and Random Projection</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/6QJjZoWknEI?si=p6vp811xWAmzWY3r">Feature Transformations</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/5Q0gemu-h3Q?si=ATG-ue0i2qcc-IVx">Feature Selection</a></p></li>
<li><p>Feature Imputation - To Be Recorded Soon</p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael‚Äôs Story</a>.</p>
<section id="motivation-for-feature-imputation">
<h2>Motivation for Feature Imputation</h2>
<p>Most spatial, subsurface datasets are not complete, missing values from the database.</p>
<ul class="simple">
<li><p>many data analytics and machine learning workflows require complete data, <span class="math notranslate nohighlight">\(ùë•_(1,ùëñ),\dots,ùë•_(ùëö,ùëñ)\)</span> for each of the data samples <span class="math notranslate nohighlight">\(ùëñ = 1,\ldots,ùëõ\)</span>.</p></li>
</ul>
<p><strong>Inferential Machine Learning</strong> - methods the require complete data, for example,</p>
<ol class="arabic simple">
<li><p>principal components analysis - require covariance matrix and covariance needs all feature values</p></li>
<li><p>multidimensional scaling - we cannot calculate the dissimilarity matrix without all features available</p></li>
<li><p>cluster analysis - we cannot calculate distances in feature space without all features values</p></li>
</ol>
<p><strong>Predictive Machine Learning</strong> - always require all features to train and test the model,</p>
<div class="math notranslate nohighlight">
\[
y = f(X_1,\ldots,X_m)
\]</div>
<p>Dealing with missing data is an essential part of feature / data engineering, prerequisite for data analytics and machine learning.</p>
<ul class="simple">
<li><p>it is important firstly to understand the cause and impact of the missing data.</p></li>
</ul>
</section>
<section id="cause-of-missing-feature-values">
<h2>Cause of Missing Feature Values</h2>
<p>Missing at random (MAR) is not common and is difficult to evaluated, in this case,</p>
<ul class="simple">
<li><p>global random omission may not result in data bias and bias in the resulting models</p></li>
</ul>
<p>MAR is not typically the case as missing data often is related to a confounding feature, for example,</p>
<ul class="simple">
<li><p><strong>sampling cost</strong> - for example, low permeability test takes too long</p></li>
<li><p><strong>rock rheology or other sample survivorship biases</strong> - for example, not possible to recover the mudstone samples</p></li>
<li><p><strong>sample design</strong> - sampling to reduce uncertainty and maximize profitability instead of statistical representativity, dual purpose samples for information and production</p></li>
<li><p><strong>sampling accessibility</strong> - there are locations in the subsurface that are difficult or impossible to samples, for example, near lakes or communities, or subsalt for seismic imaging</p></li>
</ul>
</section>
<section id="consequences-of-missing-feature-values">
<h2>Consequences of Missing Feature Values</h2>
<p>This will result in clustering of missing values over locations and feature space.</p>
<ul class="simple">
<li><p>omission of these feature values may bias global statistics, and degrade accuracy of local predictions</p></li>
<li><p>the use of global distributions for imputing missing values may not be reasonable</p></li>
</ul>
<p>More than reducing the amount of training and testing data, missing data, if not completely at random will result in:</p>
<ul class="simple">
<li><p>Biased sample statistics resulting in biased model training and testing</p></li>
<li><p>Biased models with biased predictions with potentially no indication of the bias!</p></li>
</ul>
<p>If you reread the above looking for solutions, I offer my Canadian, ‚ÄúI‚Äôm sorry‚Äù. Those who know us know that we say sorry a lot and have a cool pronunciation of the word.</p>
<p>I say all of the above as a cautionary note but,</p>
<ul class="simple">
<li><p>in some cases there are gaps in practice due to our data challenges, i.e., data paucity and nonstationarity.</p></li>
<li><p>I could spend an entire course teaching methods to address these challenges</p></li>
<li><p>the solutions integrate the entire subsurface, spatial project team, i.e., domain expertise is critical</p></li>
<li><p>I‚Äôm going to leave this at the level of awareness</p></li>
</ul>
<p>We must move beyond the commonly applied likewise deletion, removal of all samples with any missing features.</p>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries</h2>
<p>The following code loads the required libraries.</p>
<ul class="simple">
<li><p>These should have been installed with Anaconda 3.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">ignore_warnings</span> <span class="o">=</span> <span class="kc">True</span>                                        <span class="c1"># ignore warnings?</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># ndarrays for gridded data</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames for tabular data</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>                      <span class="c1"># basic imputation method</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">KNNImputer</span>                         <span class="c1"># k-nearest neighbour imputation method</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>     <span class="c1"># required for MICE imputation</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>                   <span class="c1"># MICE imputation</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># set working directory, run executables</span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># basic math operations</span>
<span class="kn">import</span> <span class="nn">random</span>                                                 <span class="c1"># for random numbers</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span> <span class="n">AutoMinorLocator</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">mtick</span>                             <span class="c1"># control tick label formatting</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>                                       <span class="c1"># summary statistics</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">linalg</span>                                 <span class="c1"># for linear algebra</span>
<span class="kn">import</span> <span class="nn">scipy.spatial</span> <span class="k">as</span> <span class="nn">sp</span>                                    <span class="c1"># for fast nearest neighbor search</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span> <span class="k">as</span> <span class="nn">signal</span>                                 <span class="c1"># kernel for moving window calculation</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>                                         <span class="c1"># for numerical speed up</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.weightstats</span> <span class="kn">import</span> <span class="n">DescrStatsW</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># plot all grids below the plot elements</span>
<span class="k">if</span> <span class="n">ignore_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>                                   
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># color map</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">73071</span>                                                  <span class="c1"># random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="declare-functions">
<h2>Declare Functions</h2>
<p>Here‚Äôs a function to assist with the plots:</p>
<ul class="simple">
<li><p><strong>add_grid</strong> - convenience function to add major and minor gridlines to improve plot interpretability</p></li>
</ul>
<p>Here is the function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>                                               <span class="c1"># add major and minor gridlines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the working directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
</section>
<section id="loading-tabular-data">
<h2>Loading Tabular Data</h2>
<p>Here‚Äôs the command to load our comma delimited data file in to a Pandas‚Äô DataFrame object.</p>
<section id="dataset-0-unconventional-multivariate-v4">
<h3>Dataset 0, Unconventional Multivariate v4</h3>
<p>Let‚Äôs load the provided multivariate, dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv">unconv_MV.csv</a>. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
</section>
<section id="dataset-1-twelve-12">
<h3>Dataset 1, Twelve, 12</h3>
<p>Let‚Äôs load the provided multivariate, 2D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/12_sample_data.csv">12_sample_data.csv</a>. This dataset has variables from 480 unconventional wells including:</p>
<ul class="simple">
<li><p>X (m), Y (m) location coordinates</p></li>
<li><p>porosity (%) after units conversion</p></li>
<li><p>permeability (mD)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
</ul>
</section>
<section id="dataset-2-reservoir-21">
<h3>Dataset 2, Reservoir 21</h3>
<p>Let‚Äôs load the provided multivariate, 3D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv">res21_wells.csv</a>. This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50 m reservoir unit:</p>
<ul class="simple">
<li><p>well (ID)</p></li>
<li><p>X (m), Y (m), Depth (m) location coordinates</p></li>
<li><p>Porosity (%) after units conversion</p></li>
<li><p>Permeability (mD)</p></li>
<li><p>Acoustic Impedance (kg/m2s*10^6) after units conversion</p></li>
<li><p>Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley Sand, to Sandstone.</p></li>
<li><p>Density (g/cm^3)</p></li>
<li><p>Compressible velocity (m/s)</p></li>
<li><p>Youngs modulus (GPa)</p></li>
<li><p>Shear velocity (m/s)</p></li>
<li><p>Shear modulus (GPa)</p></li>
</ul>
<p>We load the tabular data with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
<ul class="simple">
<li><p>we also populate lists with data ranges and labels for ease of plotting</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">idata</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Prod'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>
    
    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Porosity'</span><span class="p">:</span><span class="s1">'Por'</span><span class="p">}</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">;</span> <span class="n">df</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1000.0</span><span class="p">;</span> 
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Unnamed: 0'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>

    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    
    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>

    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    
    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We can also establish the feature ranges for plotting. We could calculate the feature range directly from the data with code like this:</p></li>
</ul>
<div class="highlight-p notranslate"><div class="highlight"><pre><span/>Pormin = np.min(df['Por'].values)                             # extract ndarray of data table column
Pormax = np.max(df['Por'].values)                             # and calculate min and max
</pre></div>
</div>
<p>but, this would not result in easy to understand color bars and axis scales, let‚Äôs pick convenient round numbers. We will also declare feature labels for ease of plotting.</p>
</section>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame</h2>
<p>Visualizing the DataFrame is useful first check of the data.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<ul class="simple">
<li><p>add parameter ‚Äòn=13‚Äô to see the first 13 rows of the dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>                                                 <span class="c1"># DataFrame preview</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>13.49</td>
      <td>3.60</td>
      <td>2.93</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>11.58</td>
      <td>3.03</td>
      <td>3.25</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>12.52</td>
      <td>2.72</td>
      <td>2.43</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>13.25</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>61.11</td>
      <td>1.08</td>
      <td>1.77</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12</td>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13</td>
      <td>16.82</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note, the first dataset idata = 0, is exhaustic without missing data, if you selected that one, let‚Äôs remove some data for the demonstrations below.</p>
</section>
<section id="remove-some-data">
<h2>Remove Some Data</h2>
<p>Let‚Äôs select a proportion of NaN values, values to set as missing,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">proportion_NaN</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</div>
<p>Then we can make a boolean array</p>
<ol class="arabic simple">
<li><p>make an ndarray of same shape (number rows and columns) as the DataFrame of uniform[0,1] distributed values</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>check condition of less than the identified proportion to make a boolean ndarray of same size, true if less than the proportion. The result will be the correct proportion (within error) of random true values.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">proportion_NaN</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>apply the mask to remove the identified values from the DataFrame</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">remove</span><span class="p">)</span>
</pre></div>
</div>
<p>Full disclosure, for this demonstration our data is missing at random, MAR, and this simplifies our task.</p>
<ul class="simple">
<li><p>this allows us to focus on the mechanics of feature imputation without the additional domain expertise topics. This is a good first step!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">proportion_NaN</span> <span class="o">=</span> <span class="mf">0.1</span>                                          <span class="c1"># proportion of values in DataFrame to remove</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>                                     <span class="c1"># ensure repeatability</span>
    <span class="n">remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">proportion_NaN</span>          <span class="c1"># make the boolean array for removal</span>
    <span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">remove</span><span class="p">[:,</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="s1">'Facies'</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">False</span>            <span class="c1"># avoid categoical imputation at this time          </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Fraction of removed values in mask ndarray = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">remove</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">remove</span><span class="o">.</span><span class="n">size</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>

    <span class="n">df_mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">remove</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">df_mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Fraction of nan values in the DataFrame = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">df_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Fraction of removed values in mask ndarray = 0.093.
Fraction of nan values in the DataFrame = 0.093.
</pre></div>
</div>
</div>
</div>
<p>We now have a new DataFrame with some missing data.</p>
<ul class="simple">
<li><p>Let‚Äôs do a .head() preview to observe the NaN values scattered throughout the dataset</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>                                            <span class="c1"># DataFrame preview</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>NaN</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.0</td>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.0</td>
      <td>13.49</td>
      <td>3.60</td>
      <td>NaN</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8.0</td>
      <td>11.58</td>
      <td>3.03</td>
      <td>NaN</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9.0</td>
      <td>NaN</td>
      <td>2.72</td>
      <td>NaN</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.0</td>
      <td>NaN</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11.0</td>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>NaN</td>
      <td>1.08</td>
      <td>1.77</td>
    </tr>
    <tr>
      <th>11</th>
      <td>NaN</td>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13.0</td>
      <td>NaN</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="evaluation-of-the-data-coverage">
<h2>Evaluation of the Data Coverage</h2>
<p>Let‚Äôs calculate the amount of missing data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                <span class="c1"># DataFrame summary statistics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Well</th>
      <td>182.0</td>
      <td>102.653846</td>
      <td>58.078019</td>
      <td>1.00</td>
      <td>53.2500</td>
      <td>104.000</td>
      <td>153.7500</td>
      <td>200.00</td>
    </tr>
    <tr>
      <th>Por</th>
      <td>184.0</td>
      <td>14.935978</td>
      <td>3.002142</td>
      <td>6.55</td>
      <td>12.8900</td>
      <td>15.055</td>
      <td>17.4225</td>
      <td>23.55</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>172.0</td>
      <td>4.319419</td>
      <td>1.684672</td>
      <td>1.13</td>
      <td>3.1300</td>
      <td>4.010</td>
      <td>5.1850</td>
      <td>9.78</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>184.0</td>
      <td>2.991630</td>
      <td>0.571569</td>
      <td>1.28</td>
      <td>2.5675</td>
      <td>2.975</td>
      <td>3.3950</td>
      <td>4.63</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>186.0</td>
      <td>47.793817</td>
      <td>13.781815</td>
      <td>10.94</td>
      <td>37.7450</td>
      <td>48.830</td>
      <td>58.0150</td>
      <td>81.40</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>186.0</td>
      <td>0.991882</td>
      <td>0.481896</td>
      <td>-0.19</td>
      <td>0.6225</td>
      <td>1.020</td>
      <td>1.3500</td>
      <td>2.18</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>176.0</td>
      <td>1.969602</td>
      <td>0.293877</td>
      <td>0.93</td>
      <td>1.7775</td>
      <td>1.970</td>
      <td>2.1100</td>
      <td>2.87</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see the counts of available values for each feature, less than the total number of samples due to missing values.</p>
<p>Let‚Äôs make a plot to indicate data completeness for each feature</p>
<ul class="simple">
<li><p>this is a useful summarization</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># data completeness plot</span>
<span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Feature'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Values'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6ed9df1de493bc38166372b4dd6106367dd7d5e2888e1c4ef601987fcd269bdd.png" src="../Images/8141a96c3a1d36a395c9bf10b9abc9ec.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/6ed9df1de493bc38166372b4dd6106367dd7d5e2888e1c4ef601987fcd269bdd.png"/>
</div>
</div>
<p>This leads to the first data imputation method, feature selection.</p>
</section>
<section id="imputation-method-1-feature-selection">
<h2>Imputation Method #1 - Feature Selection</h2>
<p>Data completeness should be considered in feature selection.</p>
<ul class="simple">
<li><p>if there is low data completeness, high percentage of missing samples, for a feature then the feature may be removed.</p></li>
</ul>
<p>One method is to use the .drop() DataFrame function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_test</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'VR'</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>We use axis = 1 to drop a feature (as above) to remove features with more than 10% of feature values missing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Perm'</span><span class="p">,</span><span class="s1">'VR'</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">drop_features</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Youngs'</span><span class="p">,</span><span class="s1">'Shear'</span><span class="p">]</span>

<span class="n">df_test</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>                <span class="c1"># calculate DataFrame with percentage missing by feature</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Feature'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Values'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4edcc8d4408f594794b18e3efca86c01b48c54a31a361f738633733dd7fdd54d.png" src="../Images/a9f7ba6bf3b50feec336b95e30cc7f10.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4edcc8d4408f594794b18e3efca86c01b48c54a31a361f738633733dd7fdd54d.png"/>
</div>
</div>
</section>
<section id="imputation-method-2-sample-selection">
<h2>Imputation Method #2 - Sample Selection</h2>
<p>There may be samples with more missing feature values.</p>
<ul class="simple">
<li><p>a specific vintage of data, for example, older data, or sample locations that experienced data collection problems</p></li>
</ul>
<p>Let‚Äôs check the coverage by sample in the DataFrame.</p>
<ul class="simple">
<li><p>we use the axis=1 parameter in the sum command to sum NaN values over the rows, samples, of the DataFrame.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># plot formatting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Sample Index'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Records'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1094c196d3204ba769ef70b04f78bd37049a2213377b9a61c94ba44b5e208fac.png" src="../Images/dd50b4d951d45dfccfe1a8f648f800e6.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/1094c196d3204ba769ef70b04f78bd37049a2213377b9a61c94ba44b5e208fac.png"/>
</div>
</div>
<p>If we identified samples with low data completeness, high percentage of missing samples, for a sample then the sample may be removed.</p>
<p>Once again we use the .drop() DataFrame function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_test</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Water'</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>This time we use axis = 0 to drop a list of samples and demonstrated below.</p>
<ol class="arabic simple">
<li><p>We need to make a list of the sample indices with too many missing samples</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">max_proportion_missing_by_sample</span> 
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>This is a tuple type, let‚Äôs convert it to a ndarray then we ensure strip it to just the 1D values</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">index_low_coverage_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">low_coverage_samples</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Now we are ready to apply our boolean array of length number of samples with True for too many missing values to remove these samples by index.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_test2</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="n">index_low_coverage_samples</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_proportion_missing_by_sample</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">low_coverage_samples</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">max_proportion_missing_by_sample</span> 
<span class="n">index_low_coverage_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">low_coverage_samples</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">df_test2</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="n">index_low_coverage_samples</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">df_test2</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_test2</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># plot formatting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Updated Sample Index'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Records'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/06a69f6e87268ae712b6a84cba7292734f89c46eafd1791c71fe0503461516dd.png" src="../Images/31d7badd11c070c12bcfdd1d9682913c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/06a69f6e87268ae712b6a84cba7292734f89c46eafd1791c71fe0503461516dd.png"/>
</div>
</div>
</section>
<section id="imputation-method-3-listwise-deletion">
<h2>Imputation Method #3 - Listwise Deletion</h2>
<p>This is the method of removing all samples that have any missing feature values.</p>
<ul class="simple">
<li><p>this approach ensures complete data while technically avoiding the need for imputation</p></li>
<li><p>no need for a imputation model decision</p></li>
<li><p>often removes important information</p></li>
<li><p>maximizes data bias if information is not missing at random (MAR)</p></li>
</ul>
<p>We must consider data completeness, coverage for each feature, as visualized above. Consider that,</p>
<ul class="simple">
<li><p>missing records in one feature may be different than the missing features in another feature</p></li>
<li><p>the union of missing over all features, may result in loss of much more than the largest proportion of missing over the features</p></li>
</ul>
<p>Also, if missing not at random (MNAR), the sample bias is maximized</p>
<ul class="simple">
<li><p>while likewise deletion is often applied, it is not recommended.</p></li>
</ul>
<p>We can use the dropna() function.</p>
<ul class="simple">
<li><p>with subset we can only consider a list of features</p></li>
<li><p>how can be set to ‚Äòany‚Äô for drop if any missing values and ‚Äòall‚Äô drop if all are missing</p></li>
<li><p>inplace true will overwrite the DataFrame and has no output while false will pass the new dataframe as a copy</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_listwise</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_listwise</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span><span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1"># df_likewise.head(n = 13)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/cd0f355d1b0b99db0bc0bdfc15b85d7c71f1e6e72bd6b0586bd0bdcc738b14c8.png" src="../Images/dbce84c00782b7a258ef46bddbe35881.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/cd0f355d1b0b99db0bc0bdfc15b85d7c71f1e6e72bd6b0586bd0bdcc738b14c8.png"/>
</div>
</div>
</section>
<section id="modeling-methods-for-imputation">
<h2>Modeling Methods for Imputation</h2>
<p>These are methods for feature imputation that treat feature imputation as a prediction problem, i.e., predict missing feature value with other available data, for example,</p>
<ul class="simple">
<li><p>the collocated other available feature values</p></li>
<li><p>the same feature values available at other sample locations</p></li>
</ul>
<p>There are many prediction methods applied for feature imputation,</p>
<ul class="simple">
<li><p>we start with the most simple prediction model possible, predicting with the global mean and proceed from there to more complicated models</p></li>
</ul>
<p>To help us visualize the results, let‚Äôs add a feature indicating if there are any missing feature values for a specific sample</p>
<ul class="simple">
<li><p>this way we can label the samples that have had features imputed for evaluation and visualization of the feature imputation results</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span><span class="p">[</span><span class="s1">'Imputed'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">df_mask</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>NaN</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="imputation-method-4-replace-with-a-constant">
<h2>Imputation Method #4 - Replace with a Constant</h2>
<p>This is the method of replacing the missing values with a constant value.</p>
<ul class="simple">
<li><p>here‚Äôs an example of replacing the missing feature values with a very low value</p></li>
</ul>
<p>This results in bias and should not be done.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_constant</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">constant_imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'constant'</span><span class="p">,</span><span class="n">fill_value</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">constant_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_constant</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_constant</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.00</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.00</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>0.01</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.01</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.00</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.00</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/26d51c63231cad2ab6a81f7ea33532841237c36c4d2ed2eadd7cc2d187de5b42.png" src="../Images/298f9bcf88d78b4cfab76adc592ff1cf.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/26d51c63231cad2ab6a81f7ea33532841237c36c4d2ed2eadd7cc2d187de5b42.png"/>
</div>
</div>
</section>
<section id="imputation-method-6-replace-with-the-mean">
<h2>Imputation Method #6 - Replace with the Mean</h2>
<p>This is the method of replacing the missing values with the mean, arithmetic average, over the feature.</p>
<div class="math notranslate nohighlight">
\[
ùë•_ùëñ = ùê∏\{ùëã_ùëñ\}
\]</div>
<ul class="simple">
<li><p>the global mean is globally unbiased, but may result in local bias, i.e., low values are overestimated and high values are underestimated</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mean</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">mean_imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
<span class="n">df_mean</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">mean_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_mean</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_mean</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mean</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.000000</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80000</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.000000</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.99163</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>102.653846</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01000</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.000000</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63000</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.000000</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18000</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/528e09249ebb432ddad9b71a908196dda11a47ea01b66b45c85c7f762352afbf.png" src="../Images/4299a66f1feb551c70f7ed3689f190e7.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/528e09249ebb432ddad9b71a908196dda11a47ea01b66b45c85c7f762352afbf.png"/>
</div>
</div>
</section>
<section id="imputation-method-6-replace-with-the-mode">
<h2>Imputation Method #6 - Replace with the Mode</h2>
<p>This is the method of replacing the missing values with the most frequent value, mode, over the feature.</p>
<ul class="simple">
<li><p>in the presence of outliers the mean may not be reliable. My recommendation is to first deal with outliers prior to feature imputation</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mode</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">mode_imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'most_frequent'</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">mode_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_mode</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_mode</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.45</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/5eaf7ed5b2d8fcf4a6bb53f0d7efe3463b5e18b51a7c7f09b044e579fb936aca.png" src="../Images/d0bd84a25bcc7b4485a3fc45fa350dfa.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/5eaf7ed5b2d8fcf4a6bb53f0d7efe3463b5e18b51a7c7f09b044e579fb936aca.png"/>
</div>
</div>
</section>
<section id="imputation-method-7-replace-with-the-n-nearest-neighbor-estimation">
<h2>Imputation Method #7 - Replace with the n-nearest Neighbor estimation</h2>
<p>This is the method of replacing the missing values with the k-nearest neighbour prediction model based on the other available collocated feature values</p>
<ul class="simple">
<li><p>see the k-nearest neighbour chapter in this e-book for explanation of the method, assumptions and hyperparameters</p></li>
<li><p>the available data is applied to predict at the missing values in features space</p></li>
</ul>
<p>Since the k-nearest neighbor method is a lazy learner, imputed values are calculated in a single pass over the missing values</p>
<ul class="simple">
<li><p>there is not a separate train and predict step</p></li>
</ul>
<p>This method should be globally unbiased and will reduce local bias relative to global mean feature imputation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_knn</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">knn_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s2">"uniform"</span><span class="p">)</span>
<span class="n">df_knn</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">knn_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_knn</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_knn</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.45</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/8f2542fc3c97e9623022bacaddaa28bf89c6d3f36b68ff0c6b0be81b5ade76b2.png" src="../Images/a00ad8045d28e8e20b2a119a285a84e9.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8f2542fc3c97e9623022bacaddaa28bf89c6d3f36b68ff0c6b0be81b5ade76b2.png"/>
</div>
</div>
</section>
<section id="imputation-method-8-multiple-imputation-by-chained-equations">
<h2>Imputation Method #8 - Multiple imputation by chained equations</h2>
<p>This is the method of replacing the missing values with the k-nearest neighbour prediction model</p>
<ol class="arabic simple">
<li><p>Substitute random values from <span class="math notranslate nohighlight">\(ùêπ_{ùëã_{ùëñ=1,\ldots,ùëö}}(ùëã_{ùëñ=1,\ldots,ùëö})\)</span> for missing values</p></li>
<li><p>Sequentially predict missing values for a feature with others</p></li>
<li><p>Iterative until convergence criteria, usually multivariate statistics</p></li>
<li><p>Repeat for multiple realizations of the dataset</p></li>
</ol>
<p>The default predictor is BayesianRidge().</p>
<ul class="simple">
<li><p>we can specify the maximum number of iterations. The last computed imputations are returned.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mice</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">mice_imputer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">()</span>
<span class="n">df_mice</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">mice_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_mice</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_mice</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.45</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/d930c573190c546f174a877996c13fd81fc9cbda6474c27840ba3b35e15b348d.png" src="../Images/feb8877973dcdfd81b91cf2afeff7039.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/d930c573190c546f174a877996c13fd81fc9cbda6474c27840ba3b35e15b348d.png"/>
</div>
</div>
</section>
<section id="save-the-imputed-dataframe">
<h2>Save the Imputed DataFrame</h2>
<p>Write out the imputed data file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">save_imputed</span> <span class="o">=</span> <span class="kc">False</span>                                          <span class="c1"># save the imputed DataFrame?</span>

<span class="k">if</span> <span class="n">save_imputed</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">df_imputed</span> <span class="o">=</span> <span class="n">df_knn</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>                     <span class="c1"># select the imputation method</span>

    <span class="n">df_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Imputed'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
    <span class="n">file_name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">'dataframe_imputed.csv'</span>

    <span class="n">df_imputed</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="comments">
<h2>Comments</h2>
<p>This was a basic treatment of feature imputation. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
&#13;

<h2>Motivation for Feature Imputation</h2>
<p>Most spatial, subsurface datasets are not complete, missing values from the database.</p>
<ul class="simple">
<li><p>many data analytics and machine learning workflows require complete data, <span class="math notranslate nohighlight">\(ùë•_(1,ùëñ),\dots,ùë•_(ùëö,ùëñ)\)</span> for each of the data samples <span class="math notranslate nohighlight">\(ùëñ = 1,\ldots,ùëõ\)</span>.</p></li>
</ul>
<p><strong>Inferential Machine Learning</strong> - methods the require complete data, for example,</p>
<ol class="arabic simple">
<li><p>principal components analysis - require covariance matrix and covariance needs all feature values</p></li>
<li><p>multidimensional scaling - we cannot calculate the dissimilarity matrix without all features available</p></li>
<li><p>cluster analysis - we cannot calculate distances in feature space without all features values</p></li>
</ol>
<p><strong>Predictive Machine Learning</strong> - always require all features to train and test the model,</p>
<div class="math notranslate nohighlight">
\[
y = f(X_1,\ldots,X_m)
\]</div>
<p>Dealing with missing data is an essential part of feature / data engineering, prerequisite for data analytics and machine learning.</p>
<ul class="simple">
<li><p>it is important firstly to understand the cause and impact of the missing data.</p></li>
</ul>
&#13;

<h2>Cause of Missing Feature Values</h2>
<p>Missing at random (MAR) is not common and is difficult to evaluated, in this case,</p>
<ul class="simple">
<li><p>global random omission may not result in data bias and bias in the resulting models</p></li>
</ul>
<p>MAR is not typically the case as missing data often is related to a confounding feature, for example,</p>
<ul class="simple">
<li><p><strong>sampling cost</strong> - for example, low permeability test takes too long</p></li>
<li><p><strong>rock rheology or other sample survivorship biases</strong> - for example, not possible to recover the mudstone samples</p></li>
<li><p><strong>sample design</strong> - sampling to reduce uncertainty and maximize profitability instead of statistical representativity, dual purpose samples for information and production</p></li>
<li><p><strong>sampling accessibility</strong> - there are locations in the subsurface that are difficult or impossible to samples, for example, near lakes or communities, or subsalt for seismic imaging</p></li>
</ul>
&#13;

<h2>Consequences of Missing Feature Values</h2>
<p>This will result in clustering of missing values over locations and feature space.</p>
<ul class="simple">
<li><p>omission of these feature values may bias global statistics, and degrade accuracy of local predictions</p></li>
<li><p>the use of global distributions for imputing missing values may not be reasonable</p></li>
</ul>
<p>More than reducing the amount of training and testing data, missing data, if not completely at random will result in:</p>
<ul class="simple">
<li><p>Biased sample statistics resulting in biased model training and testing</p></li>
<li><p>Biased models with biased predictions with potentially no indication of the bias!</p></li>
</ul>
<p>If you reread the above looking for solutions, I offer my Canadian, ‚ÄúI‚Äôm sorry‚Äù. Those who know us know that we say sorry a lot and have a cool pronunciation of the word.</p>
<p>I say all of the above as a cautionary note but,</p>
<ul class="simple">
<li><p>in some cases there are gaps in practice due to our data challenges, i.e., data paucity and nonstationarity.</p></li>
<li><p>I could spend an entire course teaching methods to address these challenges</p></li>
<li><p>the solutions integrate the entire subsurface, spatial project team, i.e., domain expertise is critical</p></li>
<li><p>I‚Äôm going to leave this at the level of awareness</p></li>
</ul>
<p>We must move beyond the commonly applied likewise deletion, removal of all samples with any missing features.</p>
&#13;

<h2>Load the Required Libraries</h2>
<p>The following code loads the required libraries.</p>
<ul class="simple">
<li><p>These should have been installed with Anaconda 3.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">ignore_warnings</span> <span class="o">=</span> <span class="kc">True</span>                                        <span class="c1"># ignore warnings?</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># ndarrays for gridded data</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames for tabular data</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>                      <span class="c1"># basic imputation method</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">KNNImputer</span>                         <span class="c1"># k-nearest neighbour imputation method</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>     <span class="c1"># required for MICE imputation</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>                   <span class="c1"># MICE imputation</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># set working directory, run executables</span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># basic math operations</span>
<span class="kn">import</span> <span class="nn">random</span>                                                 <span class="c1"># for random numbers</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span> <span class="n">AutoMinorLocator</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">mtick</span>                             <span class="c1"># control tick label formatting</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>                                       <span class="c1"># summary statistics</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">linalg</span>                                 <span class="c1"># for linear algebra</span>
<span class="kn">import</span> <span class="nn">scipy.spatial</span> <span class="k">as</span> <span class="nn">sp</span>                                    <span class="c1"># for fast nearest neighbor search</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span> <span class="k">as</span> <span class="nn">signal</span>                                 <span class="c1"># kernel for moving window calculation</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>                                         <span class="c1"># for numerical speed up</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.weightstats</span> <span class="kn">import</span> <span class="n">DescrStatsW</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># plot all grids below the plot elements</span>
<span class="k">if</span> <span class="n">ignore_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>                                   
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># color map</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">73071</span>                                                  <span class="c1"># random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Declare Functions</h2>
<p>Here‚Äôs a function to assist with the plots:</p>
<ul class="simple">
<li><p><strong>add_grid</strong> - convenience function to add major and minor gridlines to improve plot interpretability</p></li>
</ul>
<p>Here is the function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>                                               <span class="c1"># add major and minor gridlines</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Set the working directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
&#13;

<h2>Loading Tabular Data</h2>
<p>Here‚Äôs the command to load our comma delimited data file in to a Pandas‚Äô DataFrame object.</p>
<section id="dataset-0-unconventional-multivariate-v4">
<h3>Dataset 0, Unconventional Multivariate v4</h3>
<p>Let‚Äôs load the provided multivariate, dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv">unconv_MV.csv</a>. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
</section>
<section id="dataset-1-twelve-12">
<h3>Dataset 1, Twelve, 12</h3>
<p>Let‚Äôs load the provided multivariate, 2D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/12_sample_data.csv">12_sample_data.csv</a>. This dataset has variables from 480 unconventional wells including:</p>
<ul class="simple">
<li><p>X (m), Y (m) location coordinates</p></li>
<li><p>porosity (%) after units conversion</p></li>
<li><p>permeability (mD)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
</ul>
</section>
<section id="dataset-2-reservoir-21">
<h3>Dataset 2, Reservoir 21</h3>
<p>Let‚Äôs load the provided multivariate, 3D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv">res21_wells.csv</a>. This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50 m reservoir unit:</p>
<ul class="simple">
<li><p>well (ID)</p></li>
<li><p>X (m), Y (m), Depth (m) location coordinates</p></li>
<li><p>Porosity (%) after units conversion</p></li>
<li><p>Permeability (mD)</p></li>
<li><p>Acoustic Impedance (kg/m2s*10^6) after units conversion</p></li>
<li><p>Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley Sand, to Sandstone.</p></li>
<li><p>Density (g/cm^3)</p></li>
<li><p>Compressible velocity (m/s)</p></li>
<li><p>Youngs modulus (GPa)</p></li>
<li><p>Shear velocity (m/s)</p></li>
<li><p>Shear modulus (GPa)</p></li>
</ul>
<p>We load the tabular data with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
<ul class="simple">
<li><p>we also populate lists with data ranges and labels for ease of plotting</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">idata</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Prod'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>
    
    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Porosity'</span><span class="p">:</span><span class="s1">'Por'</span><span class="p">}</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">;</span> <span class="n">df</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1000.0</span><span class="p">;</span> 
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Unnamed: 0'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>

    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    
    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>

    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    
    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We can also establish the feature ranges for plotting. We could calculate the feature range directly from the data with code like this:</p></li>
</ul>
<div class="highlight-p notranslate"><div class="highlight"><pre><span/>Pormin = np.min(df['Por'].values)                             # extract ndarray of data table column
Pormax = np.max(df['Por'].values)                             # and calculate min and max
</pre></div>
</div>
<p>but, this would not result in easy to understand color bars and axis scales, let‚Äôs pick convenient round numbers. We will also declare feature labels for ease of plotting.</p>
</section>
&#13;

<h3>Dataset 0, Unconventional Multivariate v4</h3>
<p>Let‚Äôs load the provided multivariate, dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv">unconv_MV.csv</a>. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
&#13;

<h3>Dataset 1, Twelve, 12</h3>
<p>Let‚Äôs load the provided multivariate, 2D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/12_sample_data.csv">12_sample_data.csv</a>. This dataset has variables from 480 unconventional wells including:</p>
<ul class="simple">
<li><p>X (m), Y (m) location coordinates</p></li>
<li><p>porosity (%) after units conversion</p></li>
<li><p>permeability (mD)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
</ul>
&#13;

<h3>Dataset 2, Reservoir 21</h3>
<p>Let‚Äôs load the provided multivariate, 3D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv">res21_wells.csv</a>. This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50 m reservoir unit:</p>
<ul class="simple">
<li><p>well (ID)</p></li>
<li><p>X (m), Y (m), Depth (m) location coordinates</p></li>
<li><p>Porosity (%) after units conversion</p></li>
<li><p>Permeability (mD)</p></li>
<li><p>Acoustic Impedance (kg/m2s*10^6) after units conversion</p></li>
<li><p>Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley Sand, to Sandstone.</p></li>
<li><p>Density (g/cm^3)</p></li>
<li><p>Compressible velocity (m/s)</p></li>
<li><p>Youngs modulus (GPa)</p></li>
<li><p>Shear velocity (m/s)</p></li>
<li><p>Shear modulus (GPa)</p></li>
</ul>
<p>We load the tabular data with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
<ul class="simple">
<li><p>we also populate lists with data ranges and labels for ease of plotting</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">idata</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Prod'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>
    
    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Porosity'</span><span class="p">:</span><span class="s1">'Por'</span><span class="p">}</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">;</span> <span class="n">df</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1000.0</span><span class="p">;</span> 
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Unnamed: 0'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>

    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    
    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    
    <span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                          <span class="c1"># store the names of the features</span>

    <span class="n">xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    
    <span class="n">flabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ftitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We can also establish the feature ranges for plotting. We could calculate the feature range directly from the data with code like this:</p></li>
</ul>
<div class="highlight-p notranslate"><div class="highlight"><pre><span/>Pormin = np.min(df['Por'].values)                             # extract ndarray of data table column
Pormax = np.max(df['Por'].values)                             # and calculate min and max
</pre></div>
</div>
<p>but, this would not result in easy to understand color bars and axis scales, let‚Äôs pick convenient round numbers. We will also declare feature labels for ease of plotting.</p>
&#13;

<h2>Visualize the DataFrame</h2>
<p>Visualizing the DataFrame is useful first check of the data.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<ul class="simple">
<li><p>add parameter ‚Äòn=13‚Äô to see the first 13 rows of the dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>                                                 <span class="c1"># DataFrame preview</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>13.49</td>
      <td>3.60</td>
      <td>2.93</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>11.58</td>
      <td>3.03</td>
      <td>3.25</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>12.52</td>
      <td>2.72</td>
      <td>2.43</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>13.25</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>61.11</td>
      <td>1.08</td>
      <td>1.77</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12</td>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13</td>
      <td>16.82</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note, the first dataset idata = 0, is exhaustic without missing data, if you selected that one, let‚Äôs remove some data for the demonstrations below.</p>
&#13;

<h2>Remove Some Data</h2>
<p>Let‚Äôs select a proportion of NaN values, values to set as missing,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">proportion_NaN</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</div>
<p>Then we can make a boolean array</p>
<ol class="arabic simple">
<li><p>make an ndarray of same shape (number rows and columns) as the DataFrame of uniform[0,1] distributed values</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>check condition of less than the identified proportion to make a boolean ndarray of same size, true if less than the proportion. The result will be the correct proportion (within error) of random true values.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">proportion_NaN</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>apply the mask to remove the identified values from the DataFrame</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">remove</span><span class="p">)</span>
</pre></div>
</div>
<p>Full disclosure, for this demonstration our data is missing at random, MAR, and this simplifies our task.</p>
<ul class="simple">
<li><p>this allows us to focus on the mechanics of feature imputation without the additional domain expertise topics. This is a good first step!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">proportion_NaN</span> <span class="o">=</span> <span class="mf">0.1</span>                                          <span class="c1"># proportion of values in DataFrame to remove</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>                                     <span class="c1"># ensure repeatability</span>
    <span class="n">remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">proportion_NaN</span>          <span class="c1"># make the boolean array for removal</span>
    <span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">remove</span><span class="p">[:,</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="s1">'Facies'</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">False</span>            <span class="c1"># avoid categoical imputation at this time          </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Fraction of removed values in mask ndarray = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">remove</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">remove</span><span class="o">.</span><span class="n">size</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>

    <span class="n">df_mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">remove</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">df_mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Fraction of nan values in the DataFrame = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">df_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Fraction of removed values in mask ndarray = 0.093.
Fraction of nan values in the DataFrame = 0.093.
</pre></div>
</div>
</div>
</div>
<p>We now have a new DataFrame with some missing data.</p>
<ul class="simple">
<li><p>Let‚Äôs do a .head() preview to observe the NaN values scattered throughout the dataset</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>                                            <span class="c1"># DataFrame preview</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>NaN</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.0</td>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.0</td>
      <td>13.49</td>
      <td>3.60</td>
      <td>NaN</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8.0</td>
      <td>11.58</td>
      <td>3.03</td>
      <td>NaN</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9.0</td>
      <td>NaN</td>
      <td>2.72</td>
      <td>NaN</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.0</td>
      <td>NaN</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11.0</td>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>NaN</td>
      <td>1.08</td>
      <td>1.77</td>
    </tr>
    <tr>
      <th>11</th>
      <td>NaN</td>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13.0</td>
      <td>NaN</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
&#13;

<h2>Evaluation of the Data Coverage</h2>
<p>Let‚Äôs calculate the amount of missing data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                <span class="c1"># DataFrame summary statistics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Well</th>
      <td>182.0</td>
      <td>102.653846</td>
      <td>58.078019</td>
      <td>1.00</td>
      <td>53.2500</td>
      <td>104.000</td>
      <td>153.7500</td>
      <td>200.00</td>
    </tr>
    <tr>
      <th>Por</th>
      <td>184.0</td>
      <td>14.935978</td>
      <td>3.002142</td>
      <td>6.55</td>
      <td>12.8900</td>
      <td>15.055</td>
      <td>17.4225</td>
      <td>23.55</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>172.0</td>
      <td>4.319419</td>
      <td>1.684672</td>
      <td>1.13</td>
      <td>3.1300</td>
      <td>4.010</td>
      <td>5.1850</td>
      <td>9.78</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>184.0</td>
      <td>2.991630</td>
      <td>0.571569</td>
      <td>1.28</td>
      <td>2.5675</td>
      <td>2.975</td>
      <td>3.3950</td>
      <td>4.63</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>186.0</td>
      <td>47.793817</td>
      <td>13.781815</td>
      <td>10.94</td>
      <td>37.7450</td>
      <td>48.830</td>
      <td>58.0150</td>
      <td>81.40</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>186.0</td>
      <td>0.991882</td>
      <td>0.481896</td>
      <td>-0.19</td>
      <td>0.6225</td>
      <td>1.020</td>
      <td>1.3500</td>
      <td>2.18</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>176.0</td>
      <td>1.969602</td>
      <td>0.293877</td>
      <td>0.93</td>
      <td>1.7775</td>
      <td>1.970</td>
      <td>2.1100</td>
      <td>2.87</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see the counts of available values for each feature, less than the total number of samples due to missing values.</p>
<p>Let‚Äôs make a plot to indicate data completeness for each feature</p>
<ul class="simple">
<li><p>this is a useful summarization</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># data completeness plot</span>
<span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Feature'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Values'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6ed9df1de493bc38166372b4dd6106367dd7d5e2888e1c4ef601987fcd269bdd.png" src="../Images/8141a96c3a1d36a395c9bf10b9abc9ec.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/6ed9df1de493bc38166372b4dd6106367dd7d5e2888e1c4ef601987fcd269bdd.png"/>
</div>
</div>
<p>This leads to the first data imputation method, feature selection.</p>
&#13;

<h2>Imputation Method #1 - Feature Selection</h2>
<p>Data completeness should be considered in feature selection.</p>
<ul class="simple">
<li><p>if there is low data completeness, high percentage of missing samples, for a feature then the feature may be removed.</p></li>
</ul>
<p>One method is to use the .drop() DataFrame function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_test</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'VR'</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>We use axis = 1 to drop a feature (as above) to remove features with more than 10% of feature values missing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Perm'</span><span class="p">,</span><span class="s1">'VR'</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">drop_features</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Youngs'</span><span class="p">,</span><span class="s1">'Shear'</span><span class="p">]</span>

<span class="n">df_test</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>                <span class="c1"># calculate DataFrame with percentage missing by feature</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Feature'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Values'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4edcc8d4408f594794b18e3efca86c01b48c54a31a361f738633733dd7fdd54d.png" src="../Images/a9f7ba6bf3b50feec336b95e30cc7f10.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4edcc8d4408f594794b18e3efca86c01b48c54a31a361f738633733dd7fdd54d.png"/>
</div>
</div>
&#13;

<h2>Imputation Method #2 - Sample Selection</h2>
<p>There may be samples with more missing feature values.</p>
<ul class="simple">
<li><p>a specific vintage of data, for example, older data, or sample locations that experienced data collection problems</p></li>
</ul>
<p>Let‚Äôs check the coverage by sample in the DataFrame.</p>
<ul class="simple">
<li><p>we use the axis=1 parameter in the sum command to sum NaN values over the rows, samples, of the DataFrame.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># plot formatting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Sample Index'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Records'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1094c196d3204ba769ef70b04f78bd37049a2213377b9a61c94ba44b5e208fac.png" src="../Images/dd50b4d951d45dfccfe1a8f648f800e6.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/1094c196d3204ba769ef70b04f78bd37049a2213377b9a61c94ba44b5e208fac.png"/>
</div>
</div>
<p>If we identified samples with low data completeness, high percentage of missing samples, for a sample then the sample may be removed.</p>
<p>Once again we use the .drop() DataFrame function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_test</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Water'</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>This time we use axis = 0 to drop a list of samples and demonstrated below.</p>
<ol class="arabic simple">
<li><p>We need to make a list of the sample indices with too many missing samples</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">max_proportion_missing_by_sample</span> 
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>This is a tuple type, let‚Äôs convert it to a ndarray then we ensure strip it to just the 1D values</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">index_low_coverage_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">low_coverage_samples</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Now we are ready to apply our boolean array of length number of samples with True for too many missing values to remove these samples by index.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df_test2</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="n">index_low_coverage_samples</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_proportion_missing_by_sample</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">low_coverage_samples</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">max_proportion_missing_by_sample</span> 
<span class="n">index_low_coverage_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">low_coverage_samples</span> <span class="o">==</span> <span class="kc">True</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">df_test2</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="n">index_low_coverage_samples</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="p">(</span><span class="n">df_test2</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_test2</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># plot formatting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Updated Sample Index'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Percentage of Missing Records'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data Completeness'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_mask</span><span class="p">),</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">+</span><span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/06a69f6e87268ae712b6a84cba7292734f89c46eafd1791c71fe0503461516dd.png" src="../Images/31d7badd11c070c12bcfdd1d9682913c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/06a69f6e87268ae712b6a84cba7292734f89c46eafd1791c71fe0503461516dd.png"/>
</div>
</div>
&#13;

<h2>Imputation Method #3 - Listwise Deletion</h2>
<p>This is the method of removing all samples that have any missing feature values.</p>
<ul class="simple">
<li><p>this approach ensures complete data while technically avoiding the need for imputation</p></li>
<li><p>no need for a imputation model decision</p></li>
<li><p>often removes important information</p></li>
<li><p>maximizes data bias if information is not missing at random (MAR)</p></li>
</ul>
<p>We must consider data completeness, coverage for each feature, as visualized above. Consider that,</p>
<ul class="simple">
<li><p>missing records in one feature may be different than the missing features in another feature</p></li>
<li><p>the union of missing over all features, may result in loss of much more than the largest proportion of missing over the features</p></li>
</ul>
<p>Also, if missing not at random (MNAR), the sample bias is maximized</p>
<ul class="simple">
<li><p>while likewise deletion is often applied, it is not recommended.</p></li>
</ul>
<p>We can use the dropna() function.</p>
<ul class="simple">
<li><p>with subset we can only consider a list of features</p></li>
<li><p>how can be set to ‚Äòany‚Äô for drop if any missing values and ‚Äòall‚Äô drop if all are missing</p></li>
<li><p>inplace true will overwrite the DataFrame and has no output while false will pass the new dataframe as a copy</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_listwise</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_listwise</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span><span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1"># df_likewise.head(n = 13)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/cd0f355d1b0b99db0bc0bdfc15b85d7c71f1e6e72bd6b0586bd0bdcc738b14c8.png" src="../Images/dbce84c00782b7a258ef46bddbe35881.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/cd0f355d1b0b99db0bc0bdfc15b85d7c71f1e6e72bd6b0586bd0bdcc738b14c8.png"/>
</div>
</div>
&#13;

<h2>Modeling Methods for Imputation</h2>
<p>These are methods for feature imputation that treat feature imputation as a prediction problem, i.e., predict missing feature value with other available data, for example,</p>
<ul class="simple">
<li><p>the collocated other available feature values</p></li>
<li><p>the same feature values available at other sample locations</p></li>
</ul>
<p>There are many prediction methods applied for feature imputation,</p>
<ul class="simple">
<li><p>we start with the most simple prediction model possible, predicting with the global mean and proceed from there to more complicated models</p></li>
</ul>
<p>To help us visualize the results, let‚Äôs add a feature indicating if there are any missing feature values for a specific sample</p>
<ul class="simple">
<li><p>this way we can label the samples that have had features imputed for evaluation and visualization of the feature imputation results</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mask</span><span class="p">[</span><span class="s1">'Imputed'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_mask</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">df_mask</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>NaN</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
&#13;

<h2>Imputation Method #4 - Replace with a Constant</h2>
<p>This is the method of replacing the missing values with a constant value.</p>
<ul class="simple">
<li><p>here‚Äôs an example of replacing the missing feature values with a very low value</p></li>
</ul>
<p>This results in bias and should not be done.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_constant</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">constant_imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'constant'</span><span class="p">,</span><span class="n">fill_value</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">constant_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_constant</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_constant</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.00</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.00</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>0.01</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.01</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.00</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.00</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/26d51c63231cad2ab6a81f7ea33532841237c36c4d2ed2eadd7cc2d187de5b42.png" src="../Images/298f9bcf88d78b4cfab76adc592ff1cf.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/26d51c63231cad2ab6a81f7ea33532841237c36c4d2ed2eadd7cc2d187de5b42.png"/>
</div>
</div>
&#13;

<h2>Imputation Method #6 - Replace with the Mean</h2>
<p>This is the method of replacing the missing values with the mean, arithmetic average, over the feature.</p>
<div class="math notranslate nohighlight">
\[
ùë•_ùëñ = ùê∏\{ùëã_ùëñ\}
\]</div>
<ul class="simple">
<li><p>the global mean is globally unbiased, but may result in local bias, i.e., low values are overestimated and high values are underestimated</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mean</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">mean_imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
<span class="n">df_mean</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">mean_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_mean</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_mean</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mean</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.000000</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80000</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.000000</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.99163</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>102.653846</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01000</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.000000</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63000</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.000000</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18000</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/528e09249ebb432ddad9b71a908196dda11a47ea01b66b45c85c7f762352afbf.png" src="../Images/4299a66f1feb551c70f7ed3689f190e7.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/528e09249ebb432ddad9b71a908196dda11a47ea01b66b45c85c7f762352afbf.png"/>
</div>
</div>
&#13;

<h2>Imputation Method #6 - Replace with the Mode</h2>
<p>This is the method of replacing the missing values with the most frequent value, mode, over the feature.</p>
<ul class="simple">
<li><p>in the presence of outliers the mean may not be reliable. My recommendation is to first deal with outliers prior to feature imputation</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mode</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">mode_imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'most_frequent'</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">mode_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_mode</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_mode</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.45</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/5eaf7ed5b2d8fcf4a6bb53f0d7efe3463b5e18b51a7c7f09b044e579fb936aca.png" src="../Images/d0bd84a25bcc7b4485a3fc45fa350dfa.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/5eaf7ed5b2d8fcf4a6bb53f0d7efe3463b5e18b51a7c7f09b044e579fb936aca.png"/>
</div>
</div>
&#13;

<h2>Imputation Method #7 - Replace with the n-nearest Neighbor estimation</h2>
<p>This is the method of replacing the missing values with the k-nearest neighbour prediction model based on the other available collocated feature values</p>
<ul class="simple">
<li><p>see the k-nearest neighbour chapter in this e-book for explanation of the method, assumptions and hyperparameters</p></li>
<li><p>the available data is applied to predict at the missing values in features space</p></li>
</ul>
<p>Since the k-nearest neighbor method is a lazy learner, imputed values are calculated in a single pass over the missing values</p>
<ul class="simple">
<li><p>there is not a separate train and predict step</p></li>
</ul>
<p>This method should be globally unbiased and will reduce local bias relative to global mean feature imputation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_knn</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">knn_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s2">"uniform"</span><span class="p">)</span>
<span class="n">df_knn</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">knn_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_knn</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_knn</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.45</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/8f2542fc3c97e9623022bacaddaa28bf89c6d3f36b68ff0c6b0be81b5ade76b2.png" src="../Images/a00ad8045d28e8e20b2a119a285a84e9.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8f2542fc3c97e9623022bacaddaa28bf89c6d3f36b68ff0c6b0be81b5ade76b2.png"/>
</div>
</div>
&#13;

<h2>Imputation Method #8 - Multiple imputation by chained equations</h2>
<p>This is the method of replacing the missing values with the k-nearest neighbour prediction model</p>
<ol class="arabic simple">
<li><p>Substitute random values from <span class="math notranslate nohighlight">\(ùêπ_{ùëã_{ùëñ=1,\ldots,ùëö}}(ùëã_{ùëñ=1,\ldots,ùëö})\)</span> for missing values</p></li>
<li><p>Sequentially predict missing values for a feature with others</p></li>
<li><p>Iterative until convergence criteria, usually multivariate statistics</p></li>
<li><p>Repeat for multiple realizations of the dataset</p></li>
</ol>
<p>The default predictor is BayesianRidge().</p>
<ul class="simple">
<li><p>we can specify the maximum number of iterations. The last computed imputations are returned.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_mice</span> <span class="o">=</span> <span class="n">df_mask</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                         <span class="c1"># make a deep copy of the DataFrame</span>
<span class="n">mice_imputer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">()</span>
<span class="n">df_mice</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:]</span> <span class="o">=</span> <span class="n">mice_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_mice</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_mice</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">"Imputed"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.15</span><span class="p">,</span><span class="s1">'s'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">palette</span> <span class="o">=</span> <span class="s1">'gnuplot'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df_constant</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">df_mode</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Well</th>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Imputed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>12.38</td>
      <td>3.53</td>
      <td>2.45</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/d930c573190c546f174a877996c13fd81fc9cbda6474c27840ba3b35e15b348d.png" src="../Images/feb8877973dcdfd81b91cf2afeff7039.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/d930c573190c546f174a877996c13fd81fc9cbda6474c27840ba3b35e15b348d.png"/>
</div>
</div>
&#13;

<h2>Save the Imputed DataFrame</h2>
<p>Write out the imputed data file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">save_imputed</span> <span class="o">=</span> <span class="kc">False</span>                                          <span class="c1"># save the imputed DataFrame?</span>

<span class="k">if</span> <span class="n">save_imputed</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">df_imputed</span> <span class="o">=</span> <span class="n">df_knn</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>                     <span class="c1"># select the imputation method</span>

    <span class="n">df_imputed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'Imputed'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
    <span class="n">file_name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">'dataframe_imputed.csv'</span>

    <span class="n">df_imputed</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Comments</h2>
<p>This was a basic treatment of feature imputation. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
&#13;

<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
&#13;

<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
    
</body>
</html>