- en: Univariate Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_univariate_analysis.html](https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_univariate_analysis.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Michael J. Pyrcz, Professor, The University of Texas at Austin
  prefs: []
  type: TYPE_NORMAL
- en: '[Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter of e-book â€œApplied Machine Learning in Python: a Hands-on Guide with
    Codeâ€.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cite this e-Book as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pyrcz, M.J., 2024, *Applied Machine Learning in Python: A Hands-on Guide with
    Code* [e-book]. Zenodo. doi:10.5281/zenodo.15169138 [![DOI](../Images/7e4ea662f44af1eae87e87ecbb962ff4.png)](https://doi.org/10.5281/zenodo.15169138)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflows in this book and more are available here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cite the MachineLearningDemos GitHub Repository as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pyrcz, M.J., 2024, *MachineLearningDemos: Python Machine Learning Demonstration
    Workflows Repository* (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312\.
    GitHub repository: [GeostatsGuy/MachineLearningDemos](https://github.com/GeostatsGuy/MachineLearningDemos)
    [![DOI](../Images/4e3a59c17d684b06a170c4af84e0f631.png)](https://zenodo.org/doi/10.5281/zenodo.13835312)'
  prefs: []
  type: TYPE_NORMAL
- en: By Michael J. Pyrcz
  prefs: []
  type: TYPE_NORMAL
- en: Â© Copyright 2024.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter is a tutorial for / demonstration of **Univariate Analysis** including:'
  prefs: []
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability Density Functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cumulative Distribution Functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**YouTube Lecture**: check out my lectures on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Univariate Distributions](https://youtu.be/TbqaMXdSV4I?si=tzPNssh5Qcqv6DY_)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Statistical Expectation](https://youtu.be/QVgMt3cPMmM?si=otR-qEN8xeEm2nbk)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Parametric Distributions](https://youtu.be/U7fGsqCLPHU?si=ekNqbNqUvrGdTjjG)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Joint, Marginal, and Conditional Probability](https://youtu.be/kxjnPVyuuo8?si=FI3Tiu72Wc5Neunm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For convenience hereâ€™s a summary of the salient points.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation for Univariate Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many reasons to include univariate analysis in an e-book on machine
    learning:'
  prefs: []
  type: TYPE_NORMAL
- en: univariate statistics are used to train, tune and predict with machine learning
    models, e.g., decision tree predictions for regression is average of the training
    data in the leaf node, classification decision trees predict with the mode of
    the training data in the leaf node, models are routinely trained to minimize the
    mean of the square error,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: histograms, probability density functions and cumulative distribution functions
    are applied in machine learning workflows, e.g., to evaluate overlap in feature
    values between cluster groups, to check for bias in predictive model error distributions,
    etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: univariate analysis is a prerequisite for the bivariate and multivariate analyses
    that are critical for feature selection, model calculation and model checking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: also, this provides us with more important tools for plotting and checking our
    steps in our workflows. In practice, I always plot and check the univariate distributions
    or at least check the mean of the predictions for unbiasedness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Definitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s start with some basic definitions with respect to univariate, bivariate
    and multivariate.
  prefs: []
  type: TYPE_NORMAL
- en: '**Univariate** - involving one variable (feature) or event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Univariate Statistics** - summary measures based on one feature measured
    over the samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Univariate Parameters** - summary measures inferred for one feature measured
    over the population'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We start with univariate, but we will cover bivariate, involving two variables
    (features) later. Note, joint probabilities and distributions are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bivariate** - regarding 2 variables (features)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multivariate** - the general term for \(> 1\) features, but often refers
    to \(\ge 3\) or more).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Massively Multivariate** - high dimensional, usually indicating 7 or more
    features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, letâ€™s describe the concept of a distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical Distribution** â€“ for a variable (feature) a description of the
    probability of occurrence over the range of possible values. What do we get from
    a statistical distribution?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: what is the minimum and maximum?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: do we have a lot of low values?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: do we have a lot of high values?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: do we have outliers (values that donâ€™t make sense and need an explanation)?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A histogram is a bar plot of frequency over an exhaustive set of bins or categories.
    A histogram is calculated with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Divide the continuous feature range of possible values into ğ¾ equal size bins,
    âˆ†ğ‘¥, or categories,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \Delta x = \left( \frac{X_{max}-x_{min}}{K} \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: Count the number of samples (frequency) in each bin, \(ğ‘›_(ğ‘˜),\quad \forall ğ‘˜=1,\ldots,ğ¾\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot bin probability versus midâ€range, \(\left( ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›} + \frac{\Delta x}{2}
    \right)\) if continuous or the categorical label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Typically, the bar chart bin width is set to \(\Delta x\) so the bars touch
    and extend over the entire range from \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) to \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) for each
    bin, \(k\).
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example histogram,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2458721bfda0cb84cdf97b2e1ff0056.png)'
  prefs: []
  type: TYPE_IMG
- en: Example histogram for porosity with 9 bins of width 2% from 0 to 18% porosity.
  prefs: []
  type: TYPE_NORMAL
- en: Normalized Histogram
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a normalized histogram, the frequencies are normalized to the probability
    by dividing by the total number of samples, \(n\).
  prefs: []
  type: TYPE_NORMAL
- en: the probability that an outcome exists within each bin, ğ‘˜.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ ğ‘_ğ‘˜ = \frac{ğ‘›_ğ‘˜}{ğ‘›}, \quad \forall \quad ğ‘˜=1,\ldots,ğ¾ \]
  prefs: []
  type: TYPE_NORMAL
- en: 'now for each bin we have probability:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ 0.0 \le ğ‘_ğ‘˜ \le 1.0, \quad \forall \quad ğ‘˜=1,\dots,ğ¾ \]
  prefs: []
  type: TYPE_NORMAL
- en: 'and by closure, the sum of all normalized histogram bins is one:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum^{K}_{k=1} p_k = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Normalized histogram is convenient because we can read probability from the
    plot. The steps to calculate a normalized histogram are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Divide data range (\(x_{max} â€ x_{min}\)) into desired number bins / classes
    / categories, \(K\), for continuous features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \Delta x = \left( \frac{X_{max}-x_{min}}{K} \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Count the number of data in bin, \(n_k\) and then compute the probability where
    \(n\) is the total number of data.:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ ğ‘_ğ‘˜ = \frac{ğ‘›_ğ‘˜}{ğ‘›}, \quad \forall \quad ğ‘˜=1,\ldots,ğ¾ \]
  prefs: []
  type: TYPE_NORMAL
- en: Plot bin probability versus midâ€range, \(\left( ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›} + \frac{\Delta x}{2}
    \right)\) if continuous or the categorical label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Typically, the bar chart bin width is set to \(\Delta x\) so the bars touch
    and extend over the entire range from \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) to \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) for each
    bin, \(k\).
  prefs: []
  type: TYPE_NORMAL
- en: Here is the previous histogram and the associated normalized histogram,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ca119a649f09b9798bac86d8e6a25817.png)'
  prefs: []
  type: TYPE_IMG
- en: Example histogram and normalized histogram for porosity with 9 bins of width
    2% from 0 to 18% porosity. The normalization is shown for a single bin.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram Bin Size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the impact of bin size?
  prefs: []
  type: TYPE_NORMAL
- en: '**too large bins / too few bins** - often smooth out, mask information lack
    resolution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**too small bins / too many bins** - are too noisy lack samples in each bin
    for stable assessment of frequency or probability (if normalized histogram)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The general guidance is to choose the highest resolution with lowest possible
    noise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: very large and very small bins will tend towards equal proportion in
    each bin (all samples in a single bin or one sample in each bin).'
  prefs: []
  type: TYPE_NORMAL
- en: the distribution may appear to approach a uniform distribution as the bin size
    approaches extremely too small or too large
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability Density Function (PDF)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A function, \(ğ‘“_x(ğ‘¥)\), of probability density across the range of all possible
    feature values, \(ğ‘¥\), with the following constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: non-negativity, note for continuous variables (features) density may be \(>
    1.0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ 0.0 \le f_x(x) \]
  prefs: []
  type: TYPE_NORMAL
- en: integrate to calculate probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ 0 \le \int^b_a f_x(ğ‘¥)ğ‘‘ğ‘¥ = ğ‘ƒ(ğ‘ \le ğ‘¥ \le ğ‘) \le 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'closure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]![](../Images/e2e23bc20035eba71f5a44edffa79376.png)
  prefs: []
  type: TYPE_NORMAL
- en: Example probability density function (PDF) for porosity from 0 - 18% porosity
    (red). Normalized histogram (grey) is superimposed for comparison (secondary y-axis
    in grey). Two y-axes are used on the because a PDF y-axis is density and a normalized
    histogram y-axis is probability.
  prefs: []
  type: TYPE_NORMAL
- en: For categorical features, the normalized histogram is the PDF.
  prefs: []
  type: TYPE_NORMAL
- en: Some comments on working with and interpreting the density measure from a probability
    density function, \(ğ’‡_x(ğ’™)\).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cd01429849b268519a818788c3b1527.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of probability density function (PDF) constraints.
  prefs: []
  type: TYPE_NORMAL
- en: '**Closure** - the area under the curve of a PDF is \(= 1.0\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Density** - is a measure of relative likelihood, may be \(\gt 1.0\), but
    cannot be negative!'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ f_x(x) \ge 0.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Probability** - is only available from the PDF by integration over an interval.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ P(a \le x \le b) = \int^b_a f_x(x) dx \]
  prefs: []
  type: TYPE_NORMAL
- en: To test you knowledge evaluate these schematic PDFs and determine the ones that
    are not valid.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1215aab7764ee32d2282909fac8e08b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of PDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s the solutions,
  prefs: []
  type: TYPE_NORMAL
- en: '**No** - a rough estimate of the area under the curve indicates it is well
    below 1.0, e.g. assuming a triangular shape.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ area_{triangle} = \frac{1}{2} \cdot w \cdot h = \frac{1}{2} \cdot 0.1 \cdot
    1.0 = 0.05 << 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Possible** - density can be greater than one as long as all possible intervals
    [a,b] have a valid probability and the total area under the curve is 1.0 and this
    look plausible.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Possible** - density can be greater than one and density of 0.0 indicates
    no values in the middle.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**No** - negative density indicates negative probability over the interval
    [a,b].'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/bf33e80088b2968151c62153a58f3edb.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of PDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating a PDF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For parametric cases the PDFâ€™s equation is known, but for the nonparametric
    case, the PDF is calculated from the data.
  prefs: []
  type: TYPE_NORMAL
- en: While a data-derived, nonparametric PDF could be calculated by differentiating
    a data-derived CDF (discussed next), generally this would be too noisy!
  prefs: []
  type: TYPE_NORMAL
- en: 'The common method to calculate a data-derived PDF is to fit a smooth model
    to the data. Kernel Density Estimation (KDE) Approach, fit smooth PDF to data:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace all data with a kernel, Gaussian is typical.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Standardize result to ensure closure,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: What is the impact of changing the kernel width?
  prefs: []
  type: TYPE_NORMAL
- en: analogous to changing the histogram bin size, attempt to smooth out noise while
    not removing information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/680ee4b014039611b6196079f591ddc0.png)'
  prefs: []
  type: TYPE_IMG
- en: For example PDFs with different kernel widths (black line) and normalized histogram
    (orange).
  prefs: []
  type: TYPE_NORMAL
- en: Cumulative Distribution Function (CDF)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The cumulative distribution function (CDF) is the sum of a discrete PDF or the
    integral of a continuous PDF.
  prefs: []
  type: TYPE_NORMAL
- en: the cumulative distribution function \(ğ‘­_ğ’™ (ğ’™)\) is the probability that a random
    sample, \(ğ‘¿\), is less than or equal to a value \(ğ’™\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ F_x (x) = P(X \le x) = \int^x_{-\infty} f(u) du \]
  prefs: []
  type: TYPE_NORMAL
- en: CDF is represented as a plot where the x axis is variable (feature) value and
    the y axis is cumulative probability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for CDF there is no bin assumption; therefore, graph is at the resolution of
    the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monotonically non-decreasing function, because a negative slope would indicate
    negative probability over an interval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To visualize the CDF, hereâ€™s an illustration of the cumulative representation
    of a normalized histogram.
  prefs: []
  type: TYPE_NORMAL
- en: add the bars to all subsequent bin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this bin-scale CDF, you can calculated these instead of the usual data-scale
    CDF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/e6b0a5d802b4b849f804259d4ec3e34a.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of a cumulative distribution function (CDF) from a normalized histogram.
  prefs: []
  type: TYPE_NORMAL
- en: Some comments on working with and interpreting the density measure from a cumulative
    distribution function, \(F_x(ğ’™)\).
  prefs: []
  type: TYPE_NORMAL
- en: 'To check for a valid CDF given these constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: non-negativity constraint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ F_x(x) = P(X \le x) \ge 0.0, \quad \forall \quad x \]
  prefs: []
  type: TYPE_NORMAL
- en: 'valid probability:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ 0.0 \le F_x(x) \le 1.0, \quad \forall \quad x \]
  prefs: []
  type: TYPE_NORMAL
- en: cannot have negative slope
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{dF_x(x)}{dx} \ge 0.0, \quad \forall \quad x \]
  prefs: []
  type: TYPE_NORMAL
- en: 'minimum and maximum (closure) values:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ min(F_x(x)) = 0.0 \quad \quad max(F_x(x)) = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'since the CDF does not have a negative slope we can use limits:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \lim\limits_{x \to -\infty} F_x(x) \rightarrow 0.0 \quad \quad \lim\limits_{x
    \to \infty} F_x(x) \rightarrow 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: To test you knowledge evaluate these schematic CDFs and determine the ones that
    are not valid.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bbf46b12f8b508d11a49e7ffecf9403a.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s the solutions,
  prefs: []
  type: TYPE_NORMAL
- en: '**No** - the CDF does not reach 1.0 at the maximum feature value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Yes** - the minimum is 0.0, the maximum is 1.0 and the slope is never negative
    over the permeability values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Yes** - the minimum is 0.0, the maximum is 1.0 and the slope is never negative
    over the permeability values. The zero slope interval is a gap in the dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**No** - negative slope over an interval of lithium values, indicating negative
    probability.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/4d82efa4bb99025874e7599a535f0dd0.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right and assessments of
    validity.
  prefs: []
  type: TYPE_NORMAL
- en: Look carefully, the CDFs above are from the PDFs in the previous example!
  prefs: []
  type: TYPE_NORMAL
- en: Now letâ€™s challenge ourselves with 1 last example, is this a valid CDF?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eac863b64a0d1e3fdbe912b359c77d7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s the solution,
  prefs: []
  type: TYPE_NORMAL
- en: '**Yes** - this is a data spike, 80% of the samples are 0.1 leading to a vertical
    segment in the CDF that extends for 0.8 cumulative probability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/b43b56c6b5719611152ad0b6fa4254f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right and assessments of
    validity.
  prefs: []
  type: TYPE_NORMAL
- en: Random Variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now it is time to introduce the concept of the random variable, since we need
    this to understand CDF notation above.
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Variable** - we do not know the value at a location / time, it can
    take on a range of possible values, fully described with a statistical distribution
    PDF / CDF. It is represented as an upper-case variable, e.g., \(ğ‘¿\), while possible
    outcomes or data measures are represented with lower case, e.g., \(ğ’™\). more latter
    on this!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load the Required Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following code loads the required libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Define Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a convenience function to add major and minor gridlines to improve plot
    interpretability.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Set the Working Directory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I always like to do this so I donâ€™t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Loading Tabular Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hereâ€™s the command to load our comma delimited data file in to a Pandasâ€™ DataFrame
    object. For fun try misspelling the name. You will get an ugly, long error.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Thatâ€™s Python, but thereâ€™s method to the madness. In general the error shows
    a trace from the initial command into all the nested programs involved until the
    actual error occurred. If you are debugging code (I know, Iâ€™m getting ahead of
    myself now), this is valuable for the detective work of figuring out what went
    wrong. Iâ€™ve spent days in C++ debugging one issue, this helps. So since youâ€™re
    working in Jupyter Notebook, the program just assumes you code. Fine. If you scroll
    to the bottom of the error you often get a summary statement *FileNotFoundError:
    File bâ€™sample_data_cow.csvâ€™ does not exist*. Ok, now you know that you donâ€™t have
    a file with that name in the working directory.'
  prefs: []
  type: TYPE_NORMAL
- en: Painful to leave that error in our workflow, eh? Every time I pass it while
    making this documented I wanted to fix it. Its a coder thingâ€¦ While we are at
    it, notice if you click the â€˜+â€™ you can add in a new block anywhere. Ok, letâ€™s
    spell the file name correctly and get back to work.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: No error now! It worked, we loaded our file into our DataFrame called â€˜dfâ€™.
    But how do you really know that it worked? Visualizing the DataFrame is always
    a good idea as a first order check.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can preview the DataFrame by printing a slice or by utilizing the â€˜headâ€™
    DataFrame member function (with a nice and clean format, see below). With the
    slice we could look at any subset of the data table and with the head command,
    add parameter â€˜n=13â€™ to see the first 13 rows of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '|  | X | Y | Facies | Porosity | Perm | AI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 100.0 | 900.0 | 1.0 | 0.100187 | 1.363890 | 5110.699751 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 100.0 | 800.0 | 0.0 | 0.107947 | 12.576845 | 4671.458560 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 100.0 | 700.0 | 0.0 | 0.085357 | 5.984520 | 6127.548006 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 100.0 | 600.0 | 0.0 | 0.108460 | 2.446678 | 5201.637996 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 100.0 | 500.0 | 0.0 | 0.102468 | 1.952264 | 3835.270322 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 100.0 | 400.0 | 0.0 | 0.110579 | 3.691908 | 5295.267191 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 100.0 | 300.0 | 0.0 | 0.088936 | 1.073582 | 6744.996106 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 100.0 | 200.0 | 0.0 | 0.102094 | 2.396189 | 5947.338115 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 100.0 | 100.0 | 1.0 | 0.137453 | 5.727603 | 5823.241783 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 200.0 | 900.0 | 1.0 | 0.137062 | 14.771314 | 5621.146994 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 200.0 | 800.0 | 1.0 | 0.125984 | 10.675436 | 4292.700500 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 200.0 | 700.0 | 0.0 | 0.121754 | 3.085825 | 5397.400218 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 200.0 | 600.0 | 0.0 | 0.095147 | 0.962565 | 4619.786478 |'
  prefs: []
  type: TYPE_TB
- en: Summary Univariate Statistics for Tabular Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The table includes X and Y coordinates (meters), Facies 1 and 2 (1 is sandstone
    and 0 interbedded sand and mudstone), Porosity (fraction), permeability as Perm
    (mDarcy) and acoustic impedance as AI (kg/m2s*10^6).
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of efficient methods to calculate summary statistics from tabular
    data in DataFrames. The describe command provides count, mean, minimum, maximum,
    and quartiles all in a nice data table. We use transpose just to flip the table
    so that features are on the rows and the statistics are on the columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '|  | X | Y | Facies | Porosity | Perm | AI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| count | 261.000000 | 261.000000 | 261.000000 | 261.000000 | 261.000000 |
    261.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| mean | 629.823755 | 488.344828 | 0.620690 | 0.150357 | 183.711554 | 4203.657220
    |'
  prefs: []
  type: TYPE_TB
- en: '| std | 341.200403 | 166.669352 | 0.486148 | 0.049783 | 344.959449 | 1317.753146
    |'
  prefs: []
  type: TYPE_TB
- en: '| min | 40.000000 | 29.000000 | 0.000000 | 0.058871 | 0.033611 | 1844.166880
    |'
  prefs: []
  type: TYPE_TB
- en: '| 25% | 241.000000 | 416.000000 | 0.000000 | 0.104893 | 2.186525 | 2947.867713
    |'
  prefs: []
  type: TYPE_TB
- en: '| 50% | 700.000000 | 479.000000 | 1.000000 | 0.137062 | 19.977020 | 4204.150893
    |'
  prefs: []
  type: TYPE_TB
- en: '| 75% | 955.000000 | 539.000000 | 1.000000 | 0.199108 | 246.215865 | 5397.400218
    |'
  prefs: []
  type: TYPE_TB
- en: '| max | 1005.000000 | 989.000000 | 1.000000 | 0.242298 | 2642.999829 | 7881.898531
    |'
  prefs: []
  type: TYPE_TB
- en: 'We can also use a wide variety of statistical summaries built into NumPyâ€™s
    ndarrays. When we use the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Pandaâ€™s DataFrame returns all the porosity data as a series and if we add â€˜valuesâ€™
    it returns a NumPy ndarray and we have access to a lot of NumPy methods. I also
    like to use the round function to round the answer to a limited number of digits
    for accurate reporting of precision and ease of reading.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, now we could use commands. like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Hereâ€™s some of the NumPy statistical functions that take ndarrays as an inputs.
    With these methods if you had a multidimensional array you could calculate the
    average by row (axis = 1) or by column (axis = 0) or over the entire array (no
    axis specified). We just have a 1D ndarray so this is not applicable here.
  prefs: []
  type: TYPE_NORMAL
- en: We calculate the inverse of the CDF, \(F^{-1}_x(x)\) with Numpy percentile function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We can calculate the CDF value, \(F_x(x)\), directly from the data.
  prefs: []
  type: TYPE_NORMAL
- en: we apply a conditional statement to our ndarray to calculate a boolean ndarray
    with the same size of the data and then count the cases that meet the condition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: note, we are assuming equal weighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Weighted Univariate Statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the declustering chapters I present methods to calculate weights and the
    motivation for weighted statistics.
  prefs: []
  type: TYPE_NORMAL
- en: The NumPy command average allows for weighted averages as in the case of statistical
    expectation and declustered statistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For demonstration, lets make a weighting array and apply it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Letâ€™s get fancy, we will modify the weights to be 0.5 if the porosity is greater
    than 13% and retain 1.0 if the porosity is less than or equal to 13%. The results
    should be a lower weighted average.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: I should note that SciPy stats functions provide a handy summary statistics
    function. The output is a â€˜listâ€™ of values (actually it is a SciPy.DescribeResult
    object). One can extract any one of them to use in a workflow as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s display some histograms. I reimplemented the hist function from GSLIB.
    Preview the parameters by typing the command without parameters.
  prefs: []
  type: TYPE_NORMAL
- en: also to learn about function parameters the alt-tab key combination with cursor
    in the function parentheses is often available to access the â€œdocstringsâ€ or check
    the Python package docs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Letâ€™s make a histogram for the porosity feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/0304aa89909daf44171bf2478f2a6eff12d730a183ab136dd23aa4c7b19a4407.png](../Images/bf8f28f9567c4f0f115f4f33c6cd7a39.png)'
  prefs: []
  type: TYPE_IMG
- en: Whatâ€™s going on here? Looks quite bimodal.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram Bins, Number of Bins and Bin Size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s explore with a few bins sizes to check the impact on the histogram.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/2dc49661a8b56262783386d2ba869f1b451207e4f8f6e097234fddff00d57fcd.png](../Images/dfc56a596f571037b3062c15abd14749.png)'
  prefs: []
  type: TYPE_IMG
- en: 'See what happens when we use:'
  prefs: []
  type: TYPE_NORMAL
- en: '**too large bins / too few bins** - often smooth out, removes information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**too small bins / too many bins** - often too noisy, obscures information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plotting a Histogram with the matplotlib Package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I donâ€™t want to suggest that matplotlib is hard to use. The GSLIB visualizations
    provide convenience and once again use the same parameters as the GSLIB methods.
    Particularly, the â€˜histâ€™ function is pretty easy to use, just a lot more code
    to write.
  prefs: []
  type: TYPE_NORMAL
- en: hereâ€™s how we can make the same histogram as above with matplotlib directly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/96216c8bd9f48f48989eed49badc33d47aeab7c6ead9e2ebbd3645190d0bd727.png](../Images/fa7b79121a261d9d4d332684c865a123.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we can demonstrate normalized histograms with matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: I didnâ€™t add this functionality to GeostatsPyâ€™s hist function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalized Histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Normalized histograms are convenient since we can read probability to be in
    each bin and observe closure by summing the probability for all bins is 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: to do this we need to explicitly set the weight for each data as \(\frac{1}{n}\)
    (assuming equal weighting)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f7ee58d3c8c274716b6853d5a0a9f5162818f92065ad4a07e55decee8eaf87fd.png](../Images/7d2b363deba1a64511bee311a224125b.png)'
  prefs: []
  type: TYPE_IMG
- en: Probability Density Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The practical way to calculate a probability density function (PDF) from data
    is to use of kernel density estimate (KDE).
  prefs: []
  type: TYPE_NORMAL
- en: we place a kernel, in this case a parametric Gaussian PDF, at each data value
    and then calculate the sum of all data kernels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: constrained for closure such that the area under the curve is 1.0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: differentiating the data CDF is usually too noisy to be useful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To demonstrate the KDE method, we calculate the KDE PDF for the first 2, 5,
    â€¦, 200 data.
  prefs: []
  type: TYPE_NORMAL
- en: when there are very few data you can see the individual Gaussian kernels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: with more data they start to smooth out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/8062528677f863eafec6bd486959e33ad4b0a9e10a157aa5962ab492c0ee06ec.png](../Images/1bf7aa34ec6fccaf8181eebbe990a131.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we can use the Seaborn Python package to calculate and plot the PDF from
    our data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/b3ff5f196410f884108fd2d18d9f73c6df5720ac471f50f5e52585a2eb074f92.png](../Images/16d3e9e0041b77e60db2d7c8a78fef14.png)'
  prefs: []
  type: TYPE_IMG
- en: What is the impact of changing the kernel width on the KDE PDF model?
  prefs: []
  type: TYPE_NORMAL
- en: letâ€™s loop over a variety of kernel sizes and observe the resulting PDF with
    the data histogram.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: note, kernel width is controlled by bandwidth, but the bandwidth parameter is
    poorly documented in Seaborn and seems to be related to original standard deviation.
    My hypothesis is the kernel standard deviation is the product of the bandwidth
    and the standard deviation of the feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f6a62a1f22dfbdf6789e75f38f49fc6b65b21b1a4bd58fdf3defc901fdee439f.png](../Images/ff54a8a9b2571ce22e35d90275c5d3b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Cumulative Distribution Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This method in GeostatsPy makes a cumulative histogram.
  prefs: []
  type: TYPE_NORMAL
- en: you could increase or decrease the number of bins, \(> n\) is data resolution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/c72d1594b60324d879e14b412eb498bd081f4d0e9f419bb9ad83c90cbcff316d.png](../Images/f860dd82661977668c018069752dfcb2.png)'
  prefs: []
  type: TYPE_IMG
- en: Plotting a CDF with the Matplotlib Package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hereâ€™s how we calculate and plot a CDF with matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: the y axis is cumulative probability with a minimum of 0.0 and maximum of 1.0
    as expected for a CDF.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: note after the initial hist command we can add a variety of elements such as
    labels to our plot as shown below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/80703732307b8817bbd969fa345dd8d42ee3b9ea5d10d506d22e72ed2e39c318.png](../Images/56deb24072507144fb784bfe83f2940c.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculating and Plotting a CDF â€˜by- Handâ€™
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s demonstrate the calculation and plotting of a non-parametric CDF by hand
  prefs: []
  type: TYPE_NORMAL
- en: make a copy of the feature as a 1D array (ndarray from NumPy)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: sort the data in ascending order
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: assign cumulative probabilities based on the tail assumptions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: plot cumulative probability vs. feature value
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/19ede3cedd6015fc106c70089ebb1d61c57e2c1dd2d65885bbcce8f7f1b6619e.png](../Images/b6d3d6f5ed253cd9058ab4133a72ddf2.png)'
  prefs: []
  type: TYPE_IMG
- en: In conclusion, letâ€™s finish with the histograms of all of our features!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/e9c1af8cc1be6f154910243636764bf843fa3b0e76903c39d976539d1cdc3663.png](../Images/c1a40a61ebeae336cc4d5504649bc2e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Comments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was a basic treatment of univariate analysis. Much more could be done and
    discussed, I have many more resources. Check out my [shared resource inventory](https://michaelpyrcz.com/my-resources)
    and the YouTube lecture links at the start of this chapter with resource links
    in the videosâ€™ descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this was helpful,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: About the Author
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  prefs: []
  type: TYPE_NORMAL
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  prefs: []
  type: TYPE_NORMAL
- en: All of Michaelâ€™s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michaelâ€™s work and shared educational resources visit his
    Website.
  prefs: []
  type: TYPE_NORMAL
- en: Want to Work Together?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  prefs: []
  type: TYPE_NORMAL
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster,
    Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling
    and machine learning theory with practice to develop novel methods and workflows
    to add value. We are solving challenging subsurface problems!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iâ€™m always happy to discuss,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  prefs: []
  type: TYPE_NORMAL
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  prefs: []
  type: TYPE_NORMAL
- en: Motivation for Univariate Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many reasons to include univariate analysis in an e-book on machine
    learning:'
  prefs: []
  type: TYPE_NORMAL
- en: univariate statistics are used to train, tune and predict with machine learning
    models, e.g., decision tree predictions for regression is average of the training
    data in the leaf node, classification decision trees predict with the mode of
    the training data in the leaf node, models are routinely trained to minimize the
    mean of the square error,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: histograms, probability density functions and cumulative distribution functions
    are applied in machine learning workflows, e.g., to evaluate overlap in feature
    values between cluster groups, to check for bias in predictive model error distributions,
    etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: univariate analysis is a prerequisite for the bivariate and multivariate analyses
    that are critical for feature selection, model calculation and model checking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: also, this provides us with more important tools for plotting and checking our
    steps in our workflows. In practice, I always plot and check the univariate distributions
    or at least check the mean of the predictions for unbiasedness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Definitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s start with some basic definitions with respect to univariate, bivariate
    and multivariate.
  prefs: []
  type: TYPE_NORMAL
- en: '**Univariate** - involving one variable (feature) or event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Univariate Statistics** - summary measures based on one feature measured
    over the samples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Univariate Parameters** - summary measures inferred for one feature measured
    over the population'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We start with univariate, but we will cover bivariate, involving two variables
    (features) later. Note, joint probabilities and distributions are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bivariate** - regarding 2 variables (features)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multivariate** - the general term for \(> 1\) features, but often refers
    to \(\ge 3\) or more).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Massively Multivariate** - high dimensional, usually indicating 7 or more
    features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, letâ€™s describe the concept of a distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical Distribution** â€“ for a variable (feature) a description of the
    probability of occurrence over the range of possible values. What do we get from
    a statistical distribution?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: what is the minimum and maximum?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: do we have a lot of low values?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: do we have a lot of high values?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: do we have outliers (values that donâ€™t make sense and need an explanation)?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A histogram is a bar plot of frequency over an exhaustive set of bins or categories.
    A histogram is calculated with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Divide the continuous feature range of possible values into ğ¾ equal size bins,
    âˆ†ğ‘¥, or categories,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \Delta x = \left( \frac{X_{max}-x_{min}}{K} \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: Count the number of samples (frequency) in each bin, \(ğ‘›_(ğ‘˜),\quad \forall ğ‘˜=1,\ldots,ğ¾\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot bin probability versus midâ€range, \(\left( ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›} + \frac{\Delta x}{2}
    \right)\) if continuous or the categorical label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Typically, the bar chart bin width is set to \(\Delta x\) so the bars touch
    and extend over the entire range from \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) to \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) for each
    bin, \(k\).
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example histogram,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2458721bfda0cb84cdf97b2e1ff0056.png)'
  prefs: []
  type: TYPE_IMG
- en: Example histogram for porosity with 9 bins of width 2% from 0 to 18% porosity.
  prefs: []
  type: TYPE_NORMAL
- en: Normalized Histogram
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a normalized histogram, the frequencies are normalized to the probability
    by dividing by the total number of samples, \(n\).
  prefs: []
  type: TYPE_NORMAL
- en: the probability that an outcome exists within each bin, ğ‘˜.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ ğ‘_ğ‘˜ = \frac{ğ‘›_ğ‘˜}{ğ‘›}, \quad \forall \quad ğ‘˜=1,\ldots,ğ¾ \]
  prefs: []
  type: TYPE_NORMAL
- en: 'now for each bin we have probability:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ 0.0 \le ğ‘_ğ‘˜ \le 1.0, \quad \forall \quad ğ‘˜=1,\dots,ğ¾ \]
  prefs: []
  type: TYPE_NORMAL
- en: 'and by closure, the sum of all normalized histogram bins is one:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum^{K}_{k=1} p_k = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Normalized histogram is convenient because we can read probability from the
    plot. The steps to calculate a normalized histogram are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Divide data range (\(x_{max} â€ x_{min}\)) into desired number bins / classes
    / categories, \(K\), for continuous features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \Delta x = \left( \frac{X_{max}-x_{min}}{K} \right) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Count the number of data in bin, \(n_k\) and then compute the probability where
    \(n\) is the total number of data.:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ ğ‘_ğ‘˜ = \frac{ğ‘›_ğ‘˜}{ğ‘›}, \quad \forall \quad ğ‘˜=1,\ldots,ğ¾ \]
  prefs: []
  type: TYPE_NORMAL
- en: Plot bin probability versus midâ€range, \(\left( ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›} + \frac{\Delta x}{2}
    \right)\) if continuous or the categorical label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Typically, the bar chart bin width is set to \(\Delta x\) so the bars touch
    and extend over the entire range from \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) to \(ğ‘¥_{ğ‘˜,ğ‘šğ‘–ğ‘›}\) for each
    bin, \(k\).
  prefs: []
  type: TYPE_NORMAL
- en: Here is the previous histogram and the associated normalized histogram,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ca119a649f09b9798bac86d8e6a25817.png)'
  prefs: []
  type: TYPE_IMG
- en: Example histogram and normalized histogram for porosity with 9 bins of width
    2% from 0 to 18% porosity. The normalization is shown for a single bin.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram Bin Size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the impact of bin size?
  prefs: []
  type: TYPE_NORMAL
- en: '**too large bins / too few bins** - often smooth out, mask information lack
    resolution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**too small bins / too many bins** - are too noisy lack samples in each bin
    for stable assessment of frequency or probability (if normalized histogram)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The general guidance is to choose the highest resolution with lowest possible
    noise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: very large and very small bins will tend towards equal proportion in
    each bin (all samples in a single bin or one sample in each bin).'
  prefs: []
  type: TYPE_NORMAL
- en: the distribution may appear to approach a uniform distribution as the bin size
    approaches extremely too small or too large
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability Density Function (PDF)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A function, \(ğ‘“_x(ğ‘¥)\), of probability density across the range of all possible
    feature values, \(ğ‘¥\), with the following constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: non-negativity, note for continuous variables (features) density may be \(>
    1.0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ 0.0 \le f_x(x) \]
  prefs: []
  type: TYPE_NORMAL
- en: integrate to calculate probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ 0 \le \int^b_a f_x(ğ‘¥)ğ‘‘ğ‘¥ = ğ‘ƒ(ğ‘ \le ğ‘¥ \le ğ‘) \le 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'closure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]![](../Images/e2e23bc20035eba71f5a44edffa79376.png)
  prefs: []
  type: TYPE_NORMAL
- en: Example probability density function (PDF) for porosity from 0 - 18% porosity
    (red). Normalized histogram (grey) is superimposed for comparison (secondary y-axis
    in grey). Two y-axes are used on the because a PDF y-axis is density and a normalized
    histogram y-axis is probability.
  prefs: []
  type: TYPE_NORMAL
- en: For categorical features, the normalized histogram is the PDF.
  prefs: []
  type: TYPE_NORMAL
- en: Some comments on working with and interpreting the density measure from a probability
    density function, \(ğ’‡_x(ğ’™)\).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2cd01429849b268519a818788c3b1527.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of probability density function (PDF) constraints.
  prefs: []
  type: TYPE_NORMAL
- en: '**Closure** - the area under the curve of a PDF is \(= 1.0\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Density** - is a measure of relative likelihood, may be \(\gt 1.0\), but
    cannot be negative!'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ f_x(x) \ge 0.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Probability** - is only available from the PDF by integration over an interval.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ P(a \le x \le b) = \int^b_a f_x(x) dx \]
  prefs: []
  type: TYPE_NORMAL
- en: To test you knowledge evaluate these schematic PDFs and determine the ones that
    are not valid.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1215aab7764ee32d2282909fac8e08b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of PDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s the solutions,
  prefs: []
  type: TYPE_NORMAL
- en: '**No** - a rough estimate of the area under the curve indicates it is well
    below 1.0, e.g. assuming a triangular shape.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ area_{triangle} = \frac{1}{2} \cdot w \cdot h = \frac{1}{2} \cdot 0.1 \cdot
    1.0 = 0.05 << 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '**Possible** - density can be greater than one as long as all possible intervals
    [a,b] have a valid probability and the total area under the curve is 1.0 and this
    look plausible.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Possible** - density can be greater than one and density of 0.0 indicates
    no values in the middle.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**No** - negative density indicates negative probability over the interval
    [a,b].'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/bf33e80088b2968151c62153a58f3edb.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of PDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating a PDF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For parametric cases the PDFâ€™s equation is known, but for the nonparametric
    case, the PDF is calculated from the data.
  prefs: []
  type: TYPE_NORMAL
- en: While a data-derived, nonparametric PDF could be calculated by differentiating
    a data-derived CDF (discussed next), generally this would be too noisy!
  prefs: []
  type: TYPE_NORMAL
- en: 'The common method to calculate a data-derived PDF is to fit a smooth model
    to the data. Kernel Density Estimation (KDE) Approach, fit smooth PDF to data:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace all data with a kernel, Gaussian is typical.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Standardize result to ensure closure,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: What is the impact of changing the kernel width?
  prefs: []
  type: TYPE_NORMAL
- en: analogous to changing the histogram bin size, attempt to smooth out noise while
    not removing information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/680ee4b014039611b6196079f591ddc0.png)'
  prefs: []
  type: TYPE_IMG
- en: For example PDFs with different kernel widths (black line) and normalized histogram
    (orange).
  prefs: []
  type: TYPE_NORMAL
- en: Calculating a PDF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For parametric cases the PDFâ€™s equation is known, but for the nonparametric
    case, the PDF is calculated from the data.
  prefs: []
  type: TYPE_NORMAL
- en: While a data-derived, nonparametric PDF could be calculated by differentiating
    a data-derived CDF (discussed next), generally this would be too noisy!
  prefs: []
  type: TYPE_NORMAL
- en: 'The common method to calculate a data-derived PDF is to fit a smooth model
    to the data. Kernel Density Estimation (KDE) Approach, fit smooth PDF to data:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace all data with a kernel, Gaussian is typical.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Standardize result to ensure closure,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \int^{\infty}_{-\infty} f_x(x)dx = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: What is the impact of changing the kernel width?
  prefs: []
  type: TYPE_NORMAL
- en: analogous to changing the histogram bin size, attempt to smooth out noise while
    not removing information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/680ee4b014039611b6196079f591ddc0.png)'
  prefs: []
  type: TYPE_IMG
- en: For example PDFs with different kernel widths (black line) and normalized histogram
    (orange).
  prefs: []
  type: TYPE_NORMAL
- en: Cumulative Distribution Function (CDF)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The cumulative distribution function (CDF) is the sum of a discrete PDF or the
    integral of a continuous PDF.
  prefs: []
  type: TYPE_NORMAL
- en: the cumulative distribution function \(ğ‘­_ğ’™ (ğ’™)\) is the probability that a random
    sample, \(ğ‘¿\), is less than or equal to a value \(ğ’™\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ F_x (x) = P(X \le x) = \int^x_{-\infty} f(u) du \]
  prefs: []
  type: TYPE_NORMAL
- en: CDF is represented as a plot where the x axis is variable (feature) value and
    the y axis is cumulative probability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for CDF there is no bin assumption; therefore, graph is at the resolution of
    the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: monotonically non-decreasing function, because a negative slope would indicate
    negative probability over an interval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To visualize the CDF, hereâ€™s an illustration of the cumulative representation
    of a normalized histogram.
  prefs: []
  type: TYPE_NORMAL
- en: add the bars to all subsequent bin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: this bin-scale CDF, you can calculated these instead of the usual data-scale
    CDF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/e6b0a5d802b4b849f804259d4ec3e34a.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of a cumulative distribution function (CDF) from a normalized histogram.
  prefs: []
  type: TYPE_NORMAL
- en: Some comments on working with and interpreting the density measure from a cumulative
    distribution function, \(F_x(ğ’™)\).
  prefs: []
  type: TYPE_NORMAL
- en: 'To check for a valid CDF given these constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: non-negativity constraint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ F_x(x) = P(X \le x) \ge 0.0, \quad \forall \quad x \]
  prefs: []
  type: TYPE_NORMAL
- en: 'valid probability:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ 0.0 \le F_x(x) \le 1.0, \quad \forall \quad x \]
  prefs: []
  type: TYPE_NORMAL
- en: cannot have negative slope
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \frac{dF_x(x)}{dx} \ge 0.0, \quad \forall \quad x \]
  prefs: []
  type: TYPE_NORMAL
- en: 'minimum and maximum (closure) values:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ min(F_x(x)) = 0.0 \quad \quad max(F_x(x)) = 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'since the CDF does not have a negative slope we can use limits:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \lim\limits_{x \to -\infty} F_x(x) \rightarrow 0.0 \quad \quad \lim\limits_{x
    \to \infty} F_x(x) \rightarrow 1.0 \]
  prefs: []
  type: TYPE_NORMAL
- en: To test you knowledge evaluate these schematic CDFs and determine the ones that
    are not valid.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bbf46b12f8b508d11a49e7ffecf9403a.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s the solutions,
  prefs: []
  type: TYPE_NORMAL
- en: '**No** - the CDF does not reach 1.0 at the maximum feature value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Yes** - the minimum is 0.0, the maximum is 1.0 and the slope is never negative
    over the permeability values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Yes** - the minimum is 0.0, the maximum is 1.0 and the slope is never negative
    over the permeability values. The zero slope interval is a gap in the dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**No** - negative slope over an interval of lithium values, indicating negative
    probability.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/4d82efa4bb99025874e7599a535f0dd0.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right and assessments of
    validity.
  prefs: []
  type: TYPE_NORMAL
- en: Look carefully, the CDFs above are from the PDFs in the previous example!
  prefs: []
  type: TYPE_NORMAL
- en: Now letâ€™s challenge ourselves with 1 last example, is this a valid CDF?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eac863b64a0d1e3fdbe912b359c77d7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right.
  prefs: []
  type: TYPE_NORMAL
- en: Hereâ€™s the solution,
  prefs: []
  type: TYPE_NORMAL
- en: '**Yes** - this is a data spike, 80% of the samples are 0.1 leading to a vertical
    segment in the CDF that extends for 0.8 cumulative probability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/b43b56c6b5719611152ad0b6fa4254f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Four schematics of CDFs, 1, 2, 3 and 4, from left to right and assessments of
    validity.
  prefs: []
  type: TYPE_NORMAL
- en: Random Variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now it is time to introduce the concept of the random variable, since we need
    this to understand CDF notation above.
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Variable** - we do not know the value at a location / time, it can
    take on a range of possible values, fully described with a statistical distribution
    PDF / CDF. It is represented as an upper-case variable, e.g., \(ğ‘¿\), while possible
    outcomes or data measures are represented with lower case, e.g., \(ğ’™\). more latter
    on this!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load the Required Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following code loads the required libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We will also need some standard packages. These should have been installed with
    Anaconda 3.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Define Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a convenience function to add major and minor gridlines to improve plot
    interpretability.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Set the Working Directory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I always like to do this so I donâ€™t lose files and to simplify subsequent read
    and writes (avoid including the full address each time).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Loading Tabular Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hereâ€™s the command to load our comma delimited data file in to a Pandasâ€™ DataFrame
    object. For fun try misspelling the name. You will get an ugly, long error.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Thatâ€™s Python, but thereâ€™s method to the madness. In general the error shows
    a trace from the initial command into all the nested programs involved until the
    actual error occurred. If you are debugging code (I know, Iâ€™m getting ahead of
    myself now), this is valuable for the detective work of figuring out what went
    wrong. Iâ€™ve spent days in C++ debugging one issue, this helps. So since youâ€™re
    working in Jupyter Notebook, the program just assumes you code. Fine. If you scroll
    to the bottom of the error you often get a summary statement *FileNotFoundError:
    File bâ€™sample_data_cow.csvâ€™ does not exist*. Ok, now you know that you donâ€™t have
    a file with that name in the working directory.'
  prefs: []
  type: TYPE_NORMAL
- en: Painful to leave that error in our workflow, eh? Every time I pass it while
    making this documented I wanted to fix it. Its a coder thingâ€¦ While we are at
    it, notice if you click the â€˜+â€™ you can add in a new block anywhere. Ok, letâ€™s
    spell the file name correctly and get back to work.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: No error now! It worked, we loaded our file into our DataFrame called â€˜dfâ€™.
    But how do you really know that it worked? Visualizing the DataFrame is always
    a good idea as a first order check.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can preview the DataFrame by printing a slice or by utilizing the â€˜headâ€™
    DataFrame member function (with a nice and clean format, see below). With the
    slice we could look at any subset of the data table and with the head command,
    add parameter â€˜n=13â€™ to see the first 13 rows of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '|  | X | Y | Facies | Porosity | Perm | AI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 100.0 | 900.0 | 1.0 | 0.100187 | 1.363890 | 5110.699751 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 100.0 | 800.0 | 0.0 | 0.107947 | 12.576845 | 4671.458560 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 100.0 | 700.0 | 0.0 | 0.085357 | 5.984520 | 6127.548006 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 100.0 | 600.0 | 0.0 | 0.108460 | 2.446678 | 5201.637996 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 100.0 | 500.0 | 0.0 | 0.102468 | 1.952264 | 3835.270322 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 100.0 | 400.0 | 0.0 | 0.110579 | 3.691908 | 5295.267191 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 100.0 | 300.0 | 0.0 | 0.088936 | 1.073582 | 6744.996106 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 100.0 | 200.0 | 0.0 | 0.102094 | 2.396189 | 5947.338115 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 100.0 | 100.0 | 1.0 | 0.137453 | 5.727603 | 5823.241783 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 200.0 | 900.0 | 1.0 | 0.137062 | 14.771314 | 5621.146994 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 200.0 | 800.0 | 1.0 | 0.125984 | 10.675436 | 4292.700500 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 200.0 | 700.0 | 0.0 | 0.121754 | 3.085825 | 5397.400218 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 200.0 | 600.0 | 0.0 | 0.095147 | 0.962565 | 4619.786478 |'
  prefs: []
  type: TYPE_TB
- en: Summary Univariate Statistics for Tabular Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The table includes X and Y coordinates (meters), Facies 1 and 2 (1 is sandstone
    and 0 interbedded sand and mudstone), Porosity (fraction), permeability as Perm
    (mDarcy) and acoustic impedance as AI (kg/m2s*10^6).
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of efficient methods to calculate summary statistics from tabular
    data in DataFrames. The describe command provides count, mean, minimum, maximum,
    and quartiles all in a nice data table. We use transpose just to flip the table
    so that features are on the rows and the statistics are on the columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '|  | X | Y | Facies | Porosity | Perm | AI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| count | 261.000000 | 261.000000 | 261.000000 | 261.000000 | 261.000000 |
    261.000000 |'
  prefs: []
  type: TYPE_TB
- en: '| mean | 629.823755 | 488.344828 | 0.620690 | 0.150357 | 183.711554 | 4203.657220
    |'
  prefs: []
  type: TYPE_TB
- en: '| std | 341.200403 | 166.669352 | 0.486148 | 0.049783 | 344.959449 | 1317.753146
    |'
  prefs: []
  type: TYPE_TB
- en: '| min | 40.000000 | 29.000000 | 0.000000 | 0.058871 | 0.033611 | 1844.166880
    |'
  prefs: []
  type: TYPE_TB
- en: '| 25% | 241.000000 | 416.000000 | 0.000000 | 0.104893 | 2.186525 | 2947.867713
    |'
  prefs: []
  type: TYPE_TB
- en: '| 50% | 700.000000 | 479.000000 | 1.000000 | 0.137062 | 19.977020 | 4204.150893
    |'
  prefs: []
  type: TYPE_TB
- en: '| 75% | 955.000000 | 539.000000 | 1.000000 | 0.199108 | 246.215865 | 5397.400218
    |'
  prefs: []
  type: TYPE_TB
- en: '| max | 1005.000000 | 989.000000 | 1.000000 | 0.242298 | 2642.999829 | 7881.898531
    |'
  prefs: []
  type: TYPE_TB
- en: 'We can also use a wide variety of statistical summaries built into NumPyâ€™s
    ndarrays. When we use the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Pandaâ€™s DataFrame returns all the porosity data as a series and if we add â€˜valuesâ€™
    it returns a NumPy ndarray and we have access to a lot of NumPy methods. I also
    like to use the round function to round the answer to a limited number of digits
    for accurate reporting of precision and ease of reading.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, now we could use commands. like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Hereâ€™s some of the NumPy statistical functions that take ndarrays as an inputs.
    With these methods if you had a multidimensional array you could calculate the
    average by row (axis = 1) or by column (axis = 0) or over the entire array (no
    axis specified). We just have a 1D ndarray so this is not applicable here.
  prefs: []
  type: TYPE_NORMAL
- en: We calculate the inverse of the CDF, \(F^{-1}_x(x)\) with Numpy percentile function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We can calculate the CDF value, \(F_x(x)\), directly from the data.
  prefs: []
  type: TYPE_NORMAL
- en: we apply a conditional statement to our ndarray to calculate a boolean ndarray
    with the same size of the data and then count the cases that meet the condition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: note, we are assuming equal weighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Weighted Univariate Statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the declustering chapters I present methods to calculate weights and the
    motivation for weighted statistics.
  prefs: []
  type: TYPE_NORMAL
- en: The NumPy command average allows for weighted averages as in the case of statistical
    expectation and declustered statistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For demonstration, lets make a weighting array and apply it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Letâ€™s get fancy, we will modify the weights to be 0.5 if the porosity is greater
    than 13% and retain 1.0 if the porosity is less than or equal to 13%. The results
    should be a lower weighted average.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: I should note that SciPy stats functions provide a handy summary statistics
    function. The output is a â€˜listâ€™ of values (actually it is a SciPy.DescribeResult
    object). One can extract any one of them to use in a workflow as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s display some histograms. I reimplemented the hist function from GSLIB.
    Preview the parameters by typing the command without parameters.
  prefs: []
  type: TYPE_NORMAL
- en: also to learn about function parameters the alt-tab key combination with cursor
    in the function parentheses is often available to access the â€œdocstringsâ€ or check
    the Python package docs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Letâ€™s make a histogram for the porosity feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/0304aa89909daf44171bf2478f2a6eff12d730a183ab136dd23aa4c7b19a4407.png](../Images/bf8f28f9567c4f0f115f4f33c6cd7a39.png)'
  prefs: []
  type: TYPE_IMG
- en: Whatâ€™s going on here? Looks quite bimodal.
  prefs: []
  type: TYPE_NORMAL
- en: Histogram Bins, Number of Bins and Bin Size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s explore with a few bins sizes to check the impact on the histogram.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/2dc49661a8b56262783386d2ba869f1b451207e4f8f6e097234fddff00d57fcd.png](../Images/dfc56a596f571037b3062c15abd14749.png)'
  prefs: []
  type: TYPE_IMG
- en: 'See what happens when we use:'
  prefs: []
  type: TYPE_NORMAL
- en: '**too large bins / too few bins** - often smooth out, removes information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**too small bins / too many bins** - often too noisy, obscures information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plotting a Histogram with the matplotlib Package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I donâ€™t want to suggest that matplotlib is hard to use. The GSLIB visualizations
    provide convenience and once again use the same parameters as the GSLIB methods.
    Particularly, the â€˜histâ€™ function is pretty easy to use, just a lot more code
    to write.
  prefs: []
  type: TYPE_NORMAL
- en: hereâ€™s how we can make the same histogram as above with matplotlib directly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/96216c8bd9f48f48989eed49badc33d47aeab7c6ead9e2ebbd3645190d0bd727.png](../Images/fa7b79121a261d9d4d332684c865a123.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we can demonstrate normalized histograms with matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: I didnâ€™t add this functionality to GeostatsPyâ€™s hist function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalized Histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Normalized histograms are convenient since we can read probability to be in
    each bin and observe closure by summing the probability for all bins is 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: to do this we need to explicitly set the weight for each data as \(\frac{1}{n}\)
    (assuming equal weighting)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f7ee58d3c8c274716b6853d5a0a9f5162818f92065ad4a07e55decee8eaf87fd.png](../Images/7d2b363deba1a64511bee311a224125b.png)'
  prefs: []
  type: TYPE_IMG
- en: Probability Density Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The practical way to calculate a probability density function (PDF) from data
    is to use of kernel density estimate (KDE).
  prefs: []
  type: TYPE_NORMAL
- en: we place a kernel, in this case a parametric Gaussian PDF, at each data value
    and then calculate the sum of all data kernels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: constrained for closure such that the area under the curve is 1.0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: differentiating the data CDF is usually too noisy to be useful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To demonstrate the KDE method, we calculate the KDE PDF for the first 2, 5,
    â€¦, 200 data.
  prefs: []
  type: TYPE_NORMAL
- en: when there are very few data you can see the individual Gaussian kernels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: with more data they start to smooth out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/8062528677f863eafec6bd486959e33ad4b0a9e10a157aa5962ab492c0ee06ec.png](../Images/1bf7aa34ec6fccaf8181eebbe990a131.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we can use the Seaborn Python package to calculate and plot the PDF from
    our data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/b3ff5f196410f884108fd2d18d9f73c6df5720ac471f50f5e52585a2eb074f92.png](../Images/16d3e9e0041b77e60db2d7c8a78fef14.png)'
  prefs: []
  type: TYPE_IMG
- en: What is the impact of changing the kernel width on the KDE PDF model?
  prefs: []
  type: TYPE_NORMAL
- en: letâ€™s loop over a variety of kernel sizes and observe the resulting PDF with
    the data histogram.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: note, kernel width is controlled by bandwidth, but the bandwidth parameter is
    poorly documented in Seaborn and seems to be related to original standard deviation.
    My hypothesis is the kernel standard deviation is the product of the bandwidth
    and the standard deviation of the feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/f6a62a1f22dfbdf6789e75f38f49fc6b65b21b1a4bd58fdf3defc901fdee439f.png](../Images/ff54a8a9b2571ce22e35d90275c5d3b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Cumulative Distribution Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This method in GeostatsPy makes a cumulative histogram.
  prefs: []
  type: TYPE_NORMAL
- en: you could increase or decrease the number of bins, \(> n\) is data resolution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/c72d1594b60324d879e14b412eb498bd081f4d0e9f419bb9ad83c90cbcff316d.png](../Images/f860dd82661977668c018069752dfcb2.png)'
  prefs: []
  type: TYPE_IMG
- en: Plotting a CDF with the Matplotlib Package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hereâ€™s how we calculate and plot a CDF with matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: the y axis is cumulative probability with a minimum of 0.0 and maximum of 1.0
    as expected for a CDF.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: note after the initial hist command we can add a variety of elements such as
    labels to our plot as shown below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/80703732307b8817bbd969fa345dd8d42ee3b9ea5d10d506d22e72ed2e39c318.png](../Images/56deb24072507144fb784bfe83f2940c.png)'
  prefs: []
  type: TYPE_IMG
- en: Calculating and Plotting a CDF â€˜by- Handâ€™
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Letâ€™s demonstrate the calculation and plotting of a non-parametric CDF by hand
  prefs: []
  type: TYPE_NORMAL
- en: make a copy of the feature as a 1D array (ndarray from NumPy)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: sort the data in ascending order
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: assign cumulative probabilities based on the tail assumptions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: plot cumulative probability vs. feature value
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/19ede3cedd6015fc106c70089ebb1d61c57e2c1dd2d65885bbcce8f7f1b6619e.png](../Images/b6d3d6f5ed253cd9058ab4133a72ddf2.png)'
  prefs: []
  type: TYPE_IMG
- en: In conclusion, letâ€™s finish with the histograms of all of our features!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/e9c1af8cc1be6f154910243636764bf843fa3b0e76903c39d976539d1cdc3663.png](../Images/c1a40a61ebeae336cc4d5504649bc2e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Comments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was a basic treatment of univariate analysis. Much more could be done and
    discussed, I have many more resources. Check out my [shared resource inventory](https://michaelpyrcz.com/my-resources)
    and the YouTube lecture links at the start of this chapter with resource links
    in the videosâ€™ descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this was helpful,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: About the Author
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/eb709b2c0a0c715da01ae0165efdf3b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Professor Michael Pyrcz in his office on the 40 acres, campus of The University
    of Texas at Austin.
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz is a professor in the [Cockrell School of Engineering](https://cockrell.utexas.edu/faculty-directory/alphabetical/p),
    and the [Jackson School of Geosciences](https://www.jsg.utexas.edu/researcher/michael_pyrcz/),
    at [The University of Texas at Austin](https://www.utexas.edu/), where he researches
    and teaches subsurface, spatial data analytics, geostatistics, and machine learning.
    Michael is also,
  prefs: []
  type: TYPE_NORMAL
- en: the principal investigator of the [Energy Analytics](https://fri.cns.utexas.edu/energy-analytics)
    freshmen research initiative and a core faculty in the Machine Learn Laboratory
    in the College of Natural Sciences, The University of Texas at Austin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: an associate editor for [Computers and Geosciences](https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board),
    and a board member for [Mathematical Geosciences](https://link.springer.com/journal/11004/editorial-board),
    the International Association for Mathematical Geosciences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michael has written over 70 [peer-reviewed publications](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en),
    a [Python package](https://pypi.org/project/geostatspy/) for spatial data analytics,
    co-authored a textbook on spatial data analytics, [Geostatistical Reservoir Modeling](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    and author of two recently released e-books, [Applied Geostatistics in Python:
    a Hands-on Guide with GeostatsPy](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    and [Applied Machine Learning in Python: a Hands-on Guide with Code](https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html).'
  prefs: []
  type: TYPE_NORMAL
- en: All of Michaelâ€™s university lectures are available on his [YouTube Channel](https://www.youtube.com/@GeostatsGuyLectures)
    with links to 100s of Python interactive dashboards and well-documented workflows
    in over 40 repositories on his [GitHub account](https://github.com/GeostatsGuy),
    to support any interested students and working professionals with evergreen content.
    To find out more about Michaelâ€™s work and shared educational resources visit his
    Website.
  prefs: []
  type: TYPE_NORMAL
- en: Want to Work Together?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I hope this content is helpful to those that want to learn more about subsurface
    modeling, data analytics and machine learning. Students and working professionals
    are welcome to participate.
  prefs: []
  type: TYPE_NORMAL
- en: Want to invite me to visit your company for training, mentoring, project review,
    workflow design and / or consulting? Iâ€™d be happy to drop by and work with you!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interested in partnering, supporting my graduate student research or my Subsurface
    Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster,
    Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling
    and machine learning theory with practice to develop novel methods and workflows
    to add value. We are solving challenging subsurface problems!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I can be reached at [mpyrcz@austin.utexas.edu](mailto:mpyrcz%40austin.utexas.edu).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iâ€™m always happy to discuss,
  prefs: []
  type: TYPE_NORMAL
- en: '*Michael*'
  prefs: []
  type: TYPE_NORMAL
- en: Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The
    Jackson School of Geosciences, The University of Texas at Austin
  prefs: []
  type: TYPE_NORMAL
- en: 'More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy)
    | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao)
    | [Geostatistics Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446)
    | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig) | [Applied
    Geostats in Python e-book](https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html)
    | [Applied Machine Learning in Python e-book](https://geostatsguy.github.io/MachineLearningDemos_Book/)
    | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)'
  prefs: []
  type: TYPE_NORMAL
