# 词汇表

这本综合词汇表包含了 ML 系统教材中使用的关键术语的定义。术语按字母顺序排列，并包括它们出现的章节引用。

**使用词汇表**

+   **术语按字母顺序排列**，便于查阅

+   **章节引用**显示术语的引入或讨论位置

+   **交叉引用**有助于您探索相关概念

+   **交互式工具提示**在您将鼠标悬停在书中的词汇表术语上时出现

## 3

**3dmark**

图形性能基准测试套件，评估实时 3D 渲染能力，测量三角形吞吐量、纹理填充率以及现代特性如光线追踪和 DLSS 性能。 *出现在：第十二章*

## A

**A/B 测试**

一种通过随机将用户分成组来比较系统或模型两个版本的控制实验方法，测量不同版本之间的性能差异 *出现在：第十三章，第五章*

**问责制**

个人或组织因 AI 系统结果而承担责任的方式，涉及可追溯性、文档、审计和纠正伤害的能力。 *出现在：第十七章*

**激活检查点**

一种内存优化技术，通过选择性地丢弃和重新计算激活而不是存储所有中间结果来减少反向传播期间的内存使用。 *出现在：第八章*

**激活函数**

应用到神经网络神经元输入加权总和的数学函数，以引入非线性，使网络能够学习超出简单线性组合的复杂模式。 *出现在：第三章，第四章，第七章，第八章*

**基于激活的剪枝**

一种评估神经元或过滤器在数据集上的平均激活值的方法，以识别并移除那些持续产生低激活并很少为网络决策过程提供信息的神经元。 *出现在：第十章*

**主动学习**

通过迭代选择最具信息量的样本进行标记，以最大化学习效率，与随机采样策略相比，在 50-90%的标记数据下实现目标性能 *出现在：第六章，第九章*

**adam 优化**

一种自适应学习率优化算法，通过保持每个参数的指数衰减平均梯度和平方梯度来结合动量和 RMSprop。 *出现在：第八章*

**适配器模块**

在预训练模型冻结层之间插入的小型可训练神经网络组件，以实现无需修改基础架构的轻量级适应。*出现在：第十四章*

**自适应资源模式**

一种设计模式，使系统能够根据不同的资源可用性动态调整其操作，通过根据计算负载、网络带宽和存储容量进行扩展或缩减，确保效率和弹性。*出现在：第十九章*

**对抗攻击**

一种攻击类型，精心设计的输入旨在使机器学习模型做出错误的预测，同时对于人类来说几乎与合法数据无法区分。*出现在：第十五章，第十六章*

**对抗样本**

一种恶意修改的输入，旨在欺骗机器学习模型做出错误的预测，通常通过向合法数据添加微小、难以察觉的扰动来创建。*出现在：第十五章，第十七章，第十六章*

**对抗训练**

一种防御技术，涉及在对抗样本上训练模型以提高其鲁棒性和正确分类对抗输入的能力。*出现在：第十五章，第十七章，第十六章*

**AGI**

通用人工智能 - 计算系统，在所有知识领域和推理能力上与人类认知能力相匹配或超越，能够在不同的问题领域进行泛化，而无需特定任务的训练。*出现在：第二十章*

**AI for Good**

针对解决重要社会和环境挑战、提高人类福祉、促进可持续性和贡献全球发展目标而设计和部署的机器学习系统。*出现在：第十九章*

**警报**

当指标超过预定义阈值或在生产机器学习系统中检测到异常时，通知团队的自动通知系统。*出现在：第十三章*

**AlexNet**

一种开创性的卷积神经网络架构，赢得了 2012 年 ImageNet 挑战赛，将错误率从 26%降低到 16%，引发了深度学习的复兴。*出现在：第十二章，第四章，第一章*

**算法效率**

算法设计和优化，以在给定的资源约束内最大化性能，重点关注模型压缩、架构优化和算法精炼等技术。*出现在：第九章*

**算法公平性**

自动化系统不应基于受保护属性（如种族、性别或年龄）不成比例地损害个人或群体的原则。*出现在：第十七章*

**All-reduce**

分布式计算中的集体通信操作，其中每个进程贡献数据，所有进程接收组合结果，常用于分布式训练中的梯度聚合。*出现在：第八章*

**AlphaFold**

DeepMind 开发的一个里程碑式的 AI 系统，该系统能够根据蛋白质的氨基酸序列预测其三维结构，解决了长达数十年的“蛋白质折叠问题”，并展示了大规模机器学习系统如何加速科学发现。*出现在：第一章*

**异常检测**

在数据中识别出不符合预期行为的模式，通常用于检测系统中的异常值、故障或恶意活动。*出现在：第十六章*

**匿名化**

从数据集中删除或修改个人可识别信息的过程，以保护个人隐私，尽管通常不足以抵御复杂的再识别攻击。*出现在：第十五章*

**Apache Kafka**

一个分布式流平台，使用发布-订阅消息系统处理实时数据流，常用于构建具有高吞吐量和容错性的机器学习数据管道。*出现在：第六章*

**Apache Spark**

一个开源的分布式计算框架，它使计算机集群能够进行大规模数据处理，通过内存计算能力革新了 ETL 操作。*出现在：第六章*

**专用集成电路**

为特定任务设计的专用芯片，通过放弃通用灵活性来实现最大效率，例如 Cerebras Wafer-Scale Engine 用于机器学习训练。*出现在：第八章*

**专用集成电路（ASIC**）

为特定计算任务设计的定制芯片，与通用处理器相比，提供卓越的性能和能效，例如谷歌的 TPU 和比特币挖矿 ASIC。*出现在：第十二章，第十一章*

**架构效率**

模型优化的维度，专注于在训练和推理过程中通过利用稀疏性、分解大型组件和根据输入复杂性动态调整计算，以高效地执行计算。*出现在：第十章*

**人工通用智能**

一种假设的 AI 形式，在所有领域内与人类认知能力相匹配或超过，代表着超越当前窄 AI 系统的 AI 研究的最终目标。*出现在：第二十章*

**人工智能**

计算机科学领域，专注于创建能够执行通常需要人类智能的任务的系统，如感知、推理、学习和决策。*出现在：第十二章，第二十一章，第三章，第一章，第二章，第十七章，第十八章*

**人工神经网络**

一种受生物神经网络启发的计算模型，由层状组织的相互连接的节点（神经元）组成，可以通过可调整的权重和偏差从数据中学习模式。*出现在：第三章*

**人工神经元**

神经网络中的基本计算单元，模仿生物神经元，接受多个输入，应用权重和偏差，并通过激活函数产生输出信号。*出现在：第一章*

**攻击分类法**

对针对机器学习系统的网络安全威胁和对抗性攻击的系统分类，按方法、目标和影响组织威胁，以指导防御策略。*出现在：第十六章*

**注意力机制**

一种神经网络组件，根据其内容计算加权连接，允许动态关注输入的相关部分而不是固定的架构连接。*出现在：第四章*

**自动编码器**

一种神经网络架构，通过最小化重建误差来学习压缩数据表示，常用于异常检测和降维。*出现在：第十六章*

**自动微分**

一种计算技术，通过在基本操作级别系统地应用链式法则，自动计算作为计算机程序实现的函数的精确导数，这对于通过基于梯度的优化训练神经网络是必不可少的。*出现在：第七章*

**自动混合精度**

一种训练技术，它自动管理不同数值精度（FP16，FP32）的使用，以优化内存使用和计算速度，同时保持模型精度。*出现在：第八章*

**自动化偏差**

即使存在明显的错误，人类也过度依赖自动化系统输出的倾向，这可能会损害人类监督。*出现在：第十七章*

**自动化机器学习**

使用机器学习来自动化模型设计决策的自动机器学习，包括架构搜索、超参数优化和特征选择，以创建无需人工干预的高效模型。*出现在：第九章，第二十章，第十章*

**自回归**

通过根据先前元素预测下一个元素来生成序列的模型类型，例如一次生成一个标记的 GPT 模型。*出现在：第九章*

**自动扩展**

根据工作负载需求动态调整计算资源，在高峰使用时自动扩展，在低使用时自动缩减，以优化成本和性能。*出现在：第十三章*

**可用性攻击**

一种数据中毒攻击类型，旨在通过在多个类别中引入噪声或损坏训练数据来降低机器学习模型的总体性能。*出现在：第十五章*

## B

**后门攻击**

一种数据中毒类型，其中隐藏的触发器嵌入在训练数据中，当在推理过程中遇到特定模式时，会导致模型表现出恶意行为。*出现在：第十五章，第十六章*

**反向传播**

一种通过在网络层中反向传播误差信号来计算损失函数相对于网络权重的梯度的算法，这使得在训练过程中能够进行系统的权重更新。*出现在：第三章，第四章，第七章，第十四章，第十八章，第八章*

**带宽**

在通信通道或内存接口上数据传输的最大速率，通常以每秒字节数衡量，对于优化 AI 加速器中的数据移动至关重要。*出现在：第十一章*

**批量推理**

使用训练好的机器学习模型对新、以前未见过的数据进行预测或决策的过程。*出现在：第十二章，第二章，第十三章*

**批量摄取**

一种数据处理模式，在预定的时间间隔内以分组或批量方式收集和处理数据，适用于实时处理不是关键的场景。*出现在：第六章*

**批量归一化**

一种将每层的输入归一化到具有零均值和单位方差的技术，这有助于稳定训练，并通常允许更高的学习率和更快的收敛速度。*出现在：第四章，第七章，第八章*

**批量处理**

同时处理多个数据样本的技术，以分摊计算和内存访问成本，提高神经网络训练和推理的整体吞吐量。*出现在：第十二章，第六章，第十一章*

**批量大小**

在神经网络训练的一次迭代中同时处理的训练样本数量，它影响计算效率和梯度估计质量。*出现在：第三章*

**批量吞吐量优化**

在处理多个输入的同时，通过利用并行性和批量效率来最大化每单位时间内处理的样本数量。*出现在：第十二章*

**批量操作**

矩阵计算同时处理多个输入，将矩阵-向量运算转换为更有效的矩阵-矩阵运算，以提高硬件利用率。*出现在：第八章*

**贝叶斯神经网络**

在其权重上包含概率分布的神经网络，使预测中的不确定性量化成为可能，并支持更稳健的决策。*出现在：第十六章*

**基准工程**

系统设计和开发性能评估框架，包括测试工具创建、指标选择和结果解释方法。*出现在：第十二章*

**基准测试工具**

系统基础设施组件，控制测试执行，管理输入交付，并在受控条件下收集性能测量，以确保可重复的评估。*出现在：第十二章*

**基准测试**

对机器学习系统中的计算性能、算法有效性和数据质量进行系统评估，以优化跨不同工作负载的性能并确保可重复性。*出现在：第十二章*

**BERT**

来自 Transformer 的双向编码表示，这是一种由谷歌在 2018 年引入的基于 Transformer 的语言模型，它通过掩码语言模型预训练彻底改变了自然语言处理。*出现在：第十二章*

**bfloat16**

谷歌大脑开发的一种 16 位浮点格式，与 FP32 具有相同的动态范围，但精度较低，特别适合深度学习训练。*出现在：第八章*

**偏差**

添加到每个神经元加权和中可学习的参数，允许激活函数进行偏移，为网络拟合复杂模式提供额外的灵活性。*出现在：第三章*

**偏差检测**

在机器学习系统输出中识别不同人口群体间不公平歧视或不同待遇的系统方法。*出现在：第十七章*

**偏差缓解**

设计用于减少机器学习系统中不公平歧视的技术和干预措施，在数据收集、模型训练或后处理阶段应用。*出现在：第十七章*

**偏差项**

神经网络中可学习的参数，它改变了激活函数，使得神经元即使在所有输入都为零的情况下也能激活，为拟合复杂模式提供了额外的灵活性。*出现在：第三章*

**仅偏差适应**

一种轻量级训练策略，冻结所有模型权重，仅更新标量偏差项，极大地减少了设备上学习的内存需求和计算开销。*出现在：第十四章*

**二值化**

一种极端的量化技术，将神经网络权重和激活降低到二进制值（通常是-1 和+1），实现最大压缩，但通常需要专门的训练程序和硬件支持。*出现在：第十章*

**生物多样性监测**

使用相机陷阱和传感器网络等技术对生物多样性进行系统观察和测量的过程，以追踪物种种群、栖息地变化和 conservation effectiveness。*出现在：第十九章*

**生物神经元**

神经系统中的一种细胞，通过电化学信号接收、处理和传输信息，作为人工神经网络的灵感来源。*出现在：第三章*

**位翻转**

一种硬件故障，其中内存或寄存器中的一个位意外地从 0 变为 1 或相反，可能会损坏数据或计算。*出现在：第十六章*

**黑盒**

一个系统，你可以观察输入和输出，但无法看到或理解其内部工作原理，这在 AI 中尤其成问题，因为系统在没有提供推理解释的情况下做出影响人们生活的重要决策。*出现在：第一章*

**黑盒攻击**

一种对抗性攻击，攻击者对模型的内部架构、参数或训练数据一无所知，必须完全依赖查询模型并观察输出。*出现在：第十五章*

**BLAS**

基本线性代数子程序，是一种用于执行常见线性代数操作的底层例程规范，如向量加法、标量乘法、点积和矩阵运算，构成了现代机器学习框架的计算基础。*出现在：第七章*

**边界框**

通过在感兴趣的每个对象周围绘制一个矩形来识别图像中对象位置的标注，通常用于计算机视觉训练数据集。*出现在：第六章*

**脑机接口**

脑与外部设备之间的直接通信路径，通过神经信号控制计算机或假肢，代表了机器学习与神经技术的融合。*出现在：第二十章*

**脆弱性**

规则型 AI 系统在遇到其编程场景之外的数据输入时完全失败的趋势，无论这些输入与它们设计处理的内容多么相似。*出现在：第一章*

**内置自检（bist）**

允许组件使用专用电路和预定义的测试模式自行测试故障的硬件测试机制。*出现在：第十六章*

## C

**缓存时序攻击**

一种侧信道攻击，利用内存缓存访问模式的变化来推断程序执行或数据中的敏感信息。*出现在：第十五章*

**缓存**

一种技术，用于在高速存储系统中存储频繁访问的数据，以减少检索延迟并提高机器学习管道中的系统性能。*出现在：第六章*

**校准**

在训练后量化过程中，分析代表性数据集以确定最佳量化参数的过程，包括比例因子和零点，以最小化从高精度到低精度的转换时的精度损失。*出现在：第十章*

**金丝雀部署**

渐进式推出策略，其中新模型版本服务于一小部分流量，在全面部署前监控性能，允许在生产环境中进行安全验证。*出现在：第十三章*

**碳足迹**

个人、组织、事件或产品直接和间接产生的温室气体排放总量，通常以二氧化碳当量衡量。*出现在：第十八章*

**碳感知调度**

一种基于电网碳强度调度 AI 工作负载的计算方法，在可再生能源最丰富时优先执行。*出现在：第十八章*

**灾难性遗忘**

当神经网络适应新任务时，会丢失之前学习到的知识的现象，这是持续设备学习场景中的关键挑战。*出现在：第十四章*

**cerebras 晶圆级引擎**

一种革命性的单晶圆处理器，包含 2.6 万亿个晶体管和 850,000 个核心，旨在消除大规模机器学习训练中的设备间通信瓶颈。*出现在：第八章*

**通道量化**

一种量化粒度方法，其中层的每个通道使用自己的量化参数集，比层间量化提供更精确的表示，同时保持硬件效率。*出现在：第十章*

**检查点和重启机制**

定期保存程序状态的技术，以便在失败后从最后保存的状态恢复，提高系统弹性。*出现在：第十六章*

**CI/CD 管道**

持续集成和持续交付自动化工作流程，通过集成测试、验证和部署过程来简化模型开发。*出现在：第十三章*

**cifar10**

加拿大高级研究研究所数据集，包含 10 个类别中的 60,000 个 32×32 彩色图像，尽管按现代标准图像尺寸较小，但作为计算机视觉中的标准基准。*出现在：第九章*

**分类标签**

简单的类别注释，将特定的标签或类别分配给数据示例，代表监督学习注释的最基本形式。*出现在：第六章*

**客户端调度**

基于可用性、数据质量和资源限制选择参与联邦学习轮次的设备过程，以确保代表性的模型更新。*出现在：第十四章*

**云机器学习**

利用云计算基础设施提供可扩展计算资源进行训练和推理的机器学习系统，通常提供高带宽连接和强大的处理能力。*出现在：第十九章*

**cloudsuite**

在 EPFL 开发的基准测试套件，针对现代数据中心工作负载，包括网络搜索、数据分析和中媒体流，测量网络、存储和计算维度的端到端性能。*出现在：第十二章*

**协同设计**

一种整体方法，其中模型架构、硬件平台和数据管道协同设计，以无缝协同工作，通过端到端优化来缓解权衡。*出现在：第九章*

**冷启动性能**

系统从空闲状态过渡到活动执行所需的时间，在按需加载模型的无服务器环境中尤为重要。*出现在：第十二章*

**组合逻辑**

数字逻辑电路，其输出仅取决于当前输入状态，而不取决于任何过去的状态或存储元件。*出现在：第十六章*

**复合人工智能系统**

结合多个专用模型和组件的人工智能架构，而不是依赖于单一的单块模型，从而实现模块化、专业化和改进的可解释性。*出现在：第二十一章，第二十章*

**计算图**

数学运算的有向无环图表示，其中节点表示运算或变量，边表示数据流，使自动微分和优化神经网络计算成为可能。*出现在：第七章*

**计算效率**

对计算资源的优化，包括硬件和能源利用，以最大化处理速度，同时在训练和部署过程中最小化资源消耗。*出现在：第九章*

**计算最优训练**

根据缩放定律，在模型大小和训练计算预算之间进行最优平衡的训练策略，在给定的计算预算下实现最大性能。*出现在：第九章*

**计算机工程**

一种在 20 世纪 60 年代末出现的工程学科，旨在解决集成硬件和软件系统日益增长的复杂性，结合电气工程和计算机科学的专业知识来设计和构建复杂的计算系统。*出现在：第一章*

**概念瓶颈模型**

神经网络架构，首先预测可解释的中间概念，然后再做出最终预测，将深度学习的能力与透明度相结合。*出现在：第十七章*

**概念漂移**

当输入特征与目标结果之间的基本关系随时间变化时发生的性能下降，需要模型重新训练 *出现在：第十三章，第十六章*

**条件计算**

一种动态优化技术，根据输入特征选择性地激活神经网络的不同部分，通过跳过特定输入的不必要计算来减少计算负载。*出现在：第十章*

**连接主义**

一种强调从简单的互联单元中涌现学习和智能的 AI 建模方法，作为神经网络的理论基础，并与符号 AI 方法形成对比。*出现在：第一章*

**共识标注**

一种质量控制方法，通过收集同一数据点的多个标注来识别有争议的案例，并通过标注者之间的协议提高标签可靠性。*出现在：第六章*

**保护技术**

设计用于保护和管理野生动物和生态系统的技术解决方案，包括用于跟踪动物行为和检测威胁的相机陷阱、传感器网络和卫星监控系统。*出现在：第十九章*

**宪法 AI**

一种训练方法，其中模型通过批判性地对比一组原则来学习改进自己的输出，从而实现迭代自我完善，在减少有害内容的同时保持有用性 *出现在：第二十章*

**容器化**

使用 Docker 等工具将应用程序及其依赖项打包到便携、隔离的容器中，以确保在不同环境中的一致执行。*出现在：第十三章*

**容器化微服务**

使用轻量级容器来打包单个服务，使 ML 系统在分布式环境中实现可扩展和可维护的部署。*出现在：第十三章*

**持续学习**

机器学习系统从数据流中持续学习并保留先前获得的知识的能力，解决神经网络中灾难性遗忘的挑战 *出现在：第二十章，第十四章，第十六章*

**持续集成**

一种软件开发实践，其中代码更改每天自动集成、测试和验证多次，以在开发周期早期检测问题。*出现在：第五章*

**卷积**

一种基本的数学运算，是卷积神经网络的核心，它将滤波器（核）应用于输入数据以提取边缘、纹理或模式等特征，特别适用于处理图像和空间数据。*出现在：第七章*

**卷积操作**

一种数学运算，通过在输入数据上滑动一个滤波器（核）来检测局部特征，形成空间模式识别卷积神经网络的基础。*出现在：第四章*

**卷积神经网络**

一种专门为处理网格状数据（如图像）而设计的神经网络架构，使用卷积层应用滤波器以检测局部特征。*出现在：第十二章、第三章、第四章*

**冷却效率**

数据中心冷却系统从计算设备中移除热量的效率，通常以移除的热量与冷却所消耗的能量之比来衡量。*出现在：第十八章*

**反事实解释**

描述如果修改特定输入特征，模型输出将如何变化的解释，特别有助于理解决策边界。*出现在：第十七章*

**协变量偏移**

一种输入分布发生变化，而输入和输出之间的条件关系保持稳定类型的分布偏移。*出现在：第十六章*

**CP 分解**

CANDECOMP/PARAFAC 分解，将张量表示为单秩分量的和，用于通过减少参数数量同时保持计算功能来压缩神经网络层。*出现在：第十章*

**crisp-dm**

数据挖掘的跨行业标准流程，1996 年开发的一种结构化方法，定义了数据项目的六个阶段：业务理解、数据理解、数据准备、建模、评估和部署。*出现在：第五章*

**交叉熵损失**

在分类任务中常用的一种损失函数，衡量预测概率分布与真实类别标签之间的差异，提供强大的梯度以实现有效学习。*出现在：第三章*

**众包**

一种协作数据收集方法，通过互联网利用分布式个体执行标注任务，通过像 Amazon Mechanical Turk 这样的平台实现可扩展的数据集创建。*出现在：第六章*

**cublas**

NVIDIA 的 CUDA 基本线性代数子程序库，它提供了标准线性代数运算的 GPU 加速实现，使得在 NVIDIA 图形处理单元上能够进行高性能矩阵计算。*出现在：第七章*

**CUDA**

NVIDIA 的并行计算平台和编程模型，它使通用计算在图形处理单元（GPU）上成为可能，允许机器学习框架利用大规模并行性来加速张量运算。*出现在：第七章*

**CUDA（计算统一设备架构）**

NVIDIA 的并行计算平台和编程模型，它使开发者能够使用 GPU 进行超出图形渲染的通用计算。*出现在：第十一章*

**课程学习**

训练策略，其中模型先从简单示例学习，然后再过渡到更难的示例，模仿人类教育，并通过提高收敛速度 25-50%来改进。*出现在：第九章*

## D

**达特茅斯会议**

1956 年在达特茅斯学院举办的传奇 8 周研讨会，在那里人工智能正式诞生，由约翰·麦卡锡、马文·明斯基、纳撒尼尔·罗切斯特和克劳德·香农组织，在那里首次提出了“人工智能”一词。*出现在：第一章*

**数据增强**

通过旋转、裁剪或噪声等变换人工扩展数据集，通过提高模型性能 5-15%并减少当标记数据稀缺时的过度拟合。*出现在：第六章，第九章*

**数据级联**

系统性失败，其中数据质量问题随着时间的推移而累积，导致下游负面后果，如模型故障、昂贵的重建或项目终止。*出现在：第六章*

**数据中心**

一个容纳计算机系统及其相关组件（如电信和存储系统）的设施，通常包含数千台服务器用于云计算操作。*出现在：第二章，第十八章*

**以数据为中心的 AI**

从以模型为中心到以数据为中心的开发范式的转变，该范式侧重于系统地提高数据质量，而不仅仅是模型架构，通常会产生更大的性能提升。*出现在：第九章*

**数据压缩**

通过编码、量化或特征提取等技术减少训练数据的大小和复杂性，以在内存受限的设备上实现高效的存储和处理。*出现在：第十四章*

**数据整理**

通过去除无关信息、纠正错误并确保数据满足机器学习应用的具体标准，选择、组织和维护高质量数据集的过程。*出现在：第五章*

**数据漂移**

输入数据的统计特性随时间变化的现象，即使底层代码保持不变，也会导致机器学习模型性能下降。*出现在：第十三章，第五章*

**数据效率**

优化训练机器学习模型所需的数据量和质量，重点关注在最小化所需数据量的同时最大化获得的信息。*出现在：第九章*

**数据治理**

确保在整个机器学习流程中数据安全、隐私、合规和道德使用的政策、程序和技术框架。*出现在：第六章*

**数据摄取**

从各种来源收集和导入原始数据到系统中，以便存储、处理和为机器学习应用做准备。*出现在：第六章，第五章*

**数据湖**

一种存储库，以原生格式存储结构化、半结构化和非结构化数据，使用读取时模式的方法进行灵活的数据分析。*出现在：第六章*

**数据血缘**

对数据流通过各种转换和过程的文档化和跟踪，提供对数据来源和修改的可见性，以支持合规性和调试。*出现在：第六章，第十三章*

**数据并行**

一种分布式训练策略，将数据集分割到多个设备上，同时每个设备保持模型完整副本，实现梯度的并行计算。*出现在：第十二章，第九章，第七章，第八章*

**数据管道**

基础设施和工作流程，自动化数据从来源到处理阶段再到最终存储或消费的移动和转换。*出现在：第六章*

**数据中毒**

一种攻击方法，攻击者将精心制作的恶意数据点注入训练数据集中，以针对或系统性地操纵模型行为。*出现在：第十五章，第十六章*

**数据质量**

数据满足准确性、完整性、一致性和及时性要求程度的程度，直接影响机器学习模型性能。*出现在：第六章*

**数据清理**

故意且永久地从存储在内存设备上的数据中删除或销毁数据，使其无法恢复，以确保数据安全。*出现在：第十六章*

**数据缩放制度**

模型训练的不同阶段，其中数据需求根据可预测的模式进行扩展，从而指导关于数据集大小与计算投资决策。*出现在：第九章*

**数据验证**

对收集到的数据进行系统验证，以确保其符合质量标准，格式正确，并包含适合机器学习模型训练和评估的准确信息。*出现在：第六章，第五章*

**数据版本控制**

跟踪和管理数据集不同版本随时间推移的实践，类似于代码版本控制，以确保可重复性和在需要时回滚到之前的数据状态。*出现在：第十三章，第五章*

**数据仓库**

优化用于分析查询（OLAP）的集中式存储库，它以标准模式存储来自多个来源的集成、结构化数据。*出现在：第六章*

**以数据为中心的方法**

一种机器学习范式，它优先考虑提高数据质量、多样性和管理，而不是仅仅关注模型架构改进以实现更好的性能。*出现在：第二十一章*

**数据流架构**

一种专门的计算架构，其中指令执行由数据可用性而不是程序计数器决定，从而实现神经网络操作的并行处理。*出现在：第十一章*

**数据流挑战**

在硬件加速器中管理数据移动和依赖关系的技术困难，包括内存带宽限制和同步要求。*出现在：第十一章*

**死信队列**

为处理失败的数据提供单独的存储机制，允许在后续分析和对问题数据的潜在重新处理时，不阻塞主管道。*出现在：第六章*

**深度学习**

机器学习的一个子领域，它使用多层人工神经网络自动从数据中学习层次化表示，而不需要显式特征工程。*出现在：第十二章，第三章，第四章，第十八章*

**防御蒸馏**

一种技术，通过使用软标签训练学生模型来模仿教师模型的行为，从而降低对对抗性扰动的敏感性。*出现在：第十六章*

**人口统计学平等**

一个公平性标准，要求接收积极预测的概率在受保护属性中的群体成员资格之间是独立的。*出现在：第十七章*

** Dennard 缩放**

历史观察表明，随着晶体管的变小，其功率密度保持大致恒定，这使得在不增加相应功耗的情况下可以增加更多的晶体管。*出现在：第十八章*

**密集层**

一个全连接神经网络层，其中每个神经元都从前一层的所有神经元接收输入，从而实现跨特征的综合信息集成。*出现在：第三章，第四章*

**密集矩阵-矩阵乘法**

神经网络中的基本计算操作，它决定了训练时间，在典型模型中占计算量的 60-90%。*出现在：第八章*

**部署限制**

操作限制，如硬件资源、网络连接、法规要求和集成要求，这些限制影响了机器学习模型在生产环境中的实现。*出现在：第五章*

**深度可分离卷积**

一种计算技术，将标准卷积分解为深度和点操作，对于移动优化架构，通过 8-9 倍减少参数和计算。*出现在：第十四章*

**devops**

将开发和运维团队结合起来的软件开发实践，以缩短开发周期并通过自动化和协作交付高质量的软件。*出现在：第十三章*

**dhrystone**

1984 年引入的基于整数的基准，用于衡量 DMIPS（Dhrystone MIPS）中的整数和字符串操作，旨在通过典型的编程结构补充浮点基准。*出现在：第十二章*

**糖尿病视网膜病变**

一种糖尿病并发症，损害视网膜中的血管，是可预防失明的首要原因，也是医疗 AI 筛查系统的主要应用领域。*出现在：第五章*

**差分隐私**

一种数学框架，通过向计算中添加校准噪声来提供正式的隐私保证，确保任何个人数据的包含或排除对输出的影响是可证明有限的。*出现在：第二十一章，第六章，第十四章，第十五章，第十七章*

**数字鸿沟**

拥有现代信息和通信技术的人与没有的人之间的差距，尤其是影响了弱势社区从数字解决方案中获益的能力。*出现在：第十九章*

**数字孪生**

一种使用实时数据和机器学习来模拟、预测和优化其物理对应物行为的物理系统的虚拟表示。*出现在：第二十章*

**灾害响应系统**

自动化系统使用机器学习通过卫星图像分析、传感器网络和资源分配优化来检测、预测和响应自然灾害。*出现在：第十九章*

**分布式计算**

一种在多台机器或处理器上同时处理数据的方法，通过 Apache Spark 等框架实现可扩展的大数据集处理。*出现在：第六章*

**分布式智能**

在多个设备和位置之间分配计算能力，而不是依赖于单一集中式系统，从而实现本地处理和决策。*出现在：第二章*

**分布式知识模式**

一种设计模式，解决去中心化节点之间的集体学习和推理，强调对等知识共享和协作模型改进，同时保持操作独立性。*出现在：第十九章*

**分布式训练**

一种在多台机器或设备上训练机器学习模型的方法，以处理更大的数据集和超出单设备计算或内存容量的模型。*出现在：第十二章，第二十一章，第十八章，第八章*

**分布偏移**

在模型部署期间遇到的数据与训练分布不同，这可能会降低模型性能。*出现在：第十七章，第十六章*

**分布偏移类型**

对数据分布变化进行正式分类，包括协变量偏移、标签偏移、概念漂移和领域偏移，每种都需要特定的适应技术。*出现在：第十六章*

**领域自适应**

机器学习技术，使在一个领域训练的模型能够在不同但相关的领域表现良好，解决分布不匹配的挑战。 *出现在：第十六章*

**特定领域人工智能应用**

定制化的机器学习解决方案，针对特定行业如医疗保健、农业、教育或灾害响应，旨在解决独特的挑战和限制。 *出现在：第十九章*

**特定领域架构**

专为优化特定计算工作负载而设计的硬件设计，通过提高性能和能源效率来换取与通用处理器相比的灵活性。 *出现在：第十一章*

**双模冗余 (dmr)**

一种容错技术，通过在两个独立的系统中复制计算来识别和纠正错误，通过比较来识别和纠正错误。 *出现在：第十六章*

**dropout**

一种正则化技术，在训练过程中随机将一部分输入单元设置为零，以防止过拟合并提高泛化能力。 *出现在：第四章*

**双重用途困境**

减缓具有积极和消极潜在应用的技术滥用的挑战，这在人工智能安全中尤其相关。 *出现在：第十六章*

**dying relu 问题**

一种现象，其中 ReLU 神经元永久性地不活跃，对所有输入输出为零，当加权输入持续产生负值时，它们无法在学习中做出贡献。 *出现在：第八章*

**动态图**

在程序执行过程中构建和修改的计算图，允许灵活的模型架构和更容易的调试，但与静态图相比，可能限制了优化机会。 *出现在：第七章*

**动态剪枝**

一种模型优化技术，在保持预测性能的同时从神经网络中移除不必要的参数，通过消除冗余权重、神经元或层来减少模型大小和计算成本。 *出现在：第十章*

**动态量化**

通过将高精度权重和激活映射到低比特表示来降低神经网络中的数值精度，这显著减少了内存使用和计算需求 *出现在：第十二章，第十章*

**动态随机存取存储器 (dram)**

一种易失性内存，在电容器中存储数据，需要周期性的刷新周期，通常用作计算机系统中的主存储器。 *出现在：第十一章*

**动态电压和频率缩放 (dvfs)**

根据工作负载需求调整处理器电压和时钟频率的电源管理技术，以优化能耗同时保持性能。*出现在：第十二章*

## E

**急切执行**

一种执行模式，其中操作在代码中调用时立即评估，提供直观的调试和开发体验，但可能牺牲一些在基于图的执行中可用的优化机会。*出现在：第七章*

**早期退出架构**

包含多个不同深度的预测头的神经网络设计，允许在可以做出自信预测时提前退出样本，从而降低每次推理的平均计算成本。*出现在：第十章*

**边缘人工智能**

在智能手机、物联网传感器和嵌入式系统等边缘设备上直接部署人工智能算法，实现无需云连接的实时处理。*出现在：第二十章*

**边缘计算**

一种分布式计算范式，将计算和数据存储更靠近数据源，从而降低延迟和带宽使用。*出现在：第十九章，第二十一章，第十一章，第二章，第十四章，第十八章*

**边缘部署**

一种部署策略，其中机器学习模型在网络的边缘设备上本地运行，而不是在集中式云服务器上运行，从而降低延迟并允许在没有持续互联网连接的情况下进行操作。*出现在：第五章*

**边缘机器学习**

在网络边缘执行推理和有时训练的机器学习系统，通常在智能手机或计算能力有限的嵌入式系统等资源受限的设备上。*出现在：第十九章*

**边缘训练**

在边缘设备上直接训练或微调机器学习模型的过程，无需将数据传输到云端服务器即可实现个性化适应。*出现在：第十四章*

**efficientnet**

通过神经网络架构搜索发现的一系列神经网络架构，通过使用复合缩放平衡网络深度、宽度和输入分辨率，实现了更好的精度-效率权衡。*出现在：第九章，第十章*

**电迁移**

在电场影响下导体中金属原子的移动，可能随着时间的推移导致永久性硬件故障。*出现在：第十六章*

**eliza**

1966 年，麻省理工学院约瑟夫·魏岑鲍姆（Joseph Weizenbaum）创建的第一个能够通过模式匹配和替换模拟人类对话的聊天机器人之一，值得注意的是，人们开始对这个简单的程序产生情感依恋。*出现在：第一章*

**elt（提取、加载、转换）**

一种数据处理范式，首先将原始数据加载到目标系统中，然后再应用转换，为不断发展的分析需求提供灵活性。*出现在：第六章*

**嵌入式系统**

在更大的机械或电气系统中具有专用功能的计算机系统，通常设计用于特定任务，并具有实时计算约束。*出现在：第二章*

**实体碳**

在产品开始运行之前，在制造、运输和安装过程中产生的总温室气体排放量。*出现在：第十八章*

**涌现行为**

由个别组件的交互产生的意外系统级模式或特征，通常只有在系统以规模或在实际条件下运行时才会变得明显。*出现在：第五章*

**涌现能力**

在特定参数阈值时突然出现在神经网络中的能力，例如推理和算术技能，这些能力是突然出现的，而不是随着规模的增加而逐渐提高。*出现在：第二十章*

**编码器-解码器**

一种架构模式，其中编码器将输入处理为压缩表示，解码器从该表示生成输出，常用于序列到序列任务。*出现在：第四章*

**端到端基准测试**

一种综合评估方法，评估整个 AI 系统管道，包括数据处理、模型执行、后处理和基础设施组件。*出现在：第十二章*

**能源效率**

每单位能耗完成的计算工作的度量，通常以每焦耳操作数表示，对于电池供电和数据中心的部署至关重要。*出现在：第十二章，第十一章，第十八章*

**能源之星**

美国环保署（EPA）认证计划，为计算设备建立能源效率标准，要求系统在运行和睡眠模式下满足严格的效率要求。*出现在：第十二章*

**集成方法**

结合多个模型以提高性能的技术，如随机森林和梯度提升，在深度学习之前主导了机器学习竞赛。*出现在：第九章，第十六章*

**环境影响测量**

系统跟踪和量化人工智能系统的生态影响，包括整个系统生命周期内的能源消耗、碳排放和资源耗竭。*出现在：第十八章*

**环境监测**

使用传感器网络和机器学习系统地收集和分析环境数据，以跟踪生态系统健康、污染水平和气候变化影响。*出现在：第十九章*

**纪元**

神经网络训练过程中对整个训练数据集的一次完整遍历，包括根据数据集大小和批量大小进行的多个批量迭代。*出现在：第三章，第七章*

**机会均等**

一个公平性标准，专注于确保组间真正率相等，保证无论组别成员资格如何，合格的个人都受到平等对待。*出现在：第十七章*

**均衡机会**

一个公平性定义，要求在不同人口群体中，真正率和假正率相等。*出现在：第十七章*

**纠错码**

在数据存储和传输中使用的用于检测和纠正错误的方法，提高系统可靠性和数据完整性。*出现在：第十六章*

**ESP32**

一种低成本微控制器单元，广泛应用于物联网应用，具有 240 MHz 的处理器和 520 KB 的 RAM，通常在资源受限的社会影响应用中部署。*出现在：第十九章*

**ETL（提取、转换、加载**）

一种传统的数据处理范式，在将数据加载到数据仓库之前对其进行转换，从而产生可查询的格式化数据。*出现在：第六章*

**精确模型窃取**

一种旨在提取机器学习模型精确内部结构、参数和架构的攻击，允许完全复制原始模型。*出现在：第十五章*

**经验回放**

一种基于记忆的技术，将过去的训练示例存储在缓冲区中，以防止灾难性遗忘并稳定流式或持续适应场景中的学习。*出现在：第十四章*

**实验跟踪**

系统记录和管理机器学习实验，包括超参数、模型版本、训练数据和性能指标，以实现比较和可重复性。*出现在：第十三章，第五章*

**专家崩溃**

在专家混合模型中的一种训练病理，其中只有少数专家接收到显著的训练信号，导致其他专家利用率不足，从而降低模型的有效容量。*出现在：第二十章*

**专家系统**

从 20 世纪 70 年代中期开始的人工智能系统，它们在特定领域捕获人类专家知识，例如 MYCIN 用于诊断血液感染，代表了从通用人工智能到特定应用领域的转变。*出现在：第一章*

**可解释性**

利益相关者通过事后解释技术理解机器学习模型如何产生其输出的能力。*出现在：第十七章*

**可解释人工智能**

设计用于提供其决策和预测的清晰、可解释的解释的人工智能系统，解决复杂机器学习模型的“黑盒”问题。*出现在：第二十章*

**外部内存**

允许神经网络访问和操作外部存储系统的机制，将它们的工作内存扩展到参数存储之外，以实现更复杂的推理和信息检索。*出现在：第二十章*

## F

**f1 分数**

一种将精确度和召回率结合成一个单一指标来衡量模型准确度的度量，计算为它们的调和平均值。*出现在：第十六章*

**公平性约束**

为确保机器学习系统中人口统计群体之间公平对待而设计的技术和政策限制。*出现在：第十七章*

**farmbeats**

一个微软研究院项目，将机器学习和物联网技术应用于农业，使用边缘计算收集土壤条件和作物健康的实时数据，同时在具有挑战性的现实世界环境中展示分布式人工智能系统。*出现在：第一章*

**快速梯度符号方法（fgsm）**

一种基于梯度的对抗攻击，通过在梯度方向添加小的扰动来生成对抗示例。*出现在：第十六章*

**故障注入攻击**

一种通过电压操纵或电磁干扰等技术故意破坏硬件操作，以诱导计算错误和损害系统完整性的物理攻击。*出现在：第十五章*

**容错性**

系统能够在部分组件失败或遇到错误的情况下继续正确运行的能力。*出现在：第十六章*

**特征工程**

从原始数据中手动设计和提取相关特征的过程，以提高机器学习模型性能，在深度学习系统中大部分是自动化的。*出现在：第六章，第三章*

**特征图**

卷积层的输出，表示学习到的滤波器对输入中不同空间位置的响应，捕捉在不同位置检测到的特征。*出现在：第四章*

**特征存储**

一种专门的数据存储系统，为机器学习提供标准化的、可重用的特征，使多个模型和团队之间能够共享特征。*出现在：第六章，第十三章*

**联邦平均**

联邦学习的标准算法，通过基于本地数据集大小的加权平均聚合客户端模型更新，以生成全局模型。*出现在：第十四章*

**联邦学习**

一种机器学习方法，在持有本地数据样本的分布式边缘设备或服务器上训练算法，而不交换原始数据。*出现在：第十九章，第二十一章，第七章，第二十章，第二章，第十四章，第十五章，第十七章，第十八章，第五章*

**反馈循环**

循环过程，其中机器学习生命周期的后期阶段的输出信息影响早期阶段的决策，从而实现系统的持续改进和适应。*出现在：第五章*

**前馈网络**

一种神经网络架构，信息从输入层流向输出层，没有循环，为许多深度学习模型奠定了基础。*出现在：第三章，第四章*

**少样本学习**

一种机器学习范式，允许模型仅使用少量标记示例来适应新任务，这对于数据稀疏的设备场景至关重要。*出现在：第十四章*

**现场可编程门阵列**

可编程硬件，可用于特定任务，在通用处理器和应用特定集成电路之间提供灵活性，对于定制机器学习加速很有用。*出现在：第八章*

**现场可编程门阵列（FPGA）**

一种可重构的集成电路，在制造后可以编程以实现自定义数字电路和专用计算。*出现在：第十一章*

**浮点运算单元 (fpu)**

一种专门设计的处理器组件，用于以高精度和效率执行浮点数算术运算。*出现在：第十一章*

**flops**

每秒浮点运算次数，这是一种衡量计算吞吐量的度量，它量化了系统可以执行的涉及小数的数学运算的数量。*出现在：第十二章，第三章，第九章，第十章，第十八章*

**前向传递**

计算阶段，其中输入数据流经神经网络层以产生输出，涉及矩阵乘法和激活函数的应用。*出现在：第八章*

**前向传播**

通过将输入数据通过连续的层进行计算，在每个阶段应用权重、偏置和激活函数的过程来计算神经网络预测。*出现在：第三章*

**基础模型**

在广泛数据上训练的大规模机器学习模型，可以适应广泛的下游任务，作为专用应用的基础。*出现在：第二章*

**基础模型**

在广泛数据上训练的大规模通用人工智能模型，可以适应许多任务，包括具有数十亿参数的 GPT-3、BERT 和 DALL-E 等模型。*出现在：第九章，第二十章*

**fp16**

一种 16 位浮点数数值表示，它减少了内存使用并加速了计算，同时保持了适用于许多机器学习应用的可接受精度。*出现在：第十二章*

**fp16 计算**

使用 16 位浮点数进行神经网络操作，以减少内存使用并提高现代硬件加速器的计算速度。*出现在：第八章*

**fp32**

32 位浮点数数值表示，为数学计算提供标准精度，但比低精度格式需要更多的内存和计算资源。*出现在：第十二章*

**fp32 到 int8**

一种常见的量化转换，将 32 位浮点权重和激活转换为 8 位整数，在保持许多模型可接受精度的同时，实现大约 4 倍的内存减少。*出现在：第十章*

**框架分解**

将神经网络框架系统性地分解为可映射到硬件的组件，使操作在处理元素之间高效分布。*出现在：第十一章*

## G

**gdpr**

欧洲联盟的一项法律，对个人数据处理提出严格的要求，并对保护隐私的机器学习设计产生重大影响。*出现在：第十四章，第十七章*

**gemm**

通用矩阵乘法运算，遵循 C = αAB + βC 的模式，代表大多数神经网络操作（包括全连接层和卷积层）背后的基本计算内核。*出现在：第七章*

**gemv**

通用矩阵-向量乘法运算，用于计算矩阵和向量的乘积，在神经网络计算中常用，需要仔细优化内存访问模式。*出现在：第七章*

**generalization**

机器学习模型在未见过的、与训练集不同的数据上表现良好的能力，通常通过多样化和高质量的训练数据得到改善。*出现在：第六章*

**generative adversarial networks**

一类机器学习系统，其中两个神经网络相互竞争，一个生成假数据，另一个试图检测它，从而实现高度逼真的合成数据生成。*出现在：第二十章*

**生成式 AI**

一类能够根据训练数据中学习到的模式创建新内容（如文本、图像、音频或视频）的人工智能系统。*出现在：第二十一章*

**glitches**

电压、电流或信号的暂时偏差，可能导致数字系统和电路操作错误。*出现在：第十六章*

**governance frameworks**

管理负责任 AI 开发的系统化方法，包括政策、程序、监督机制和问责结构。*出现在：第十七章*

**gpt3**

OpenAI 于 2020 年发布的 1750 亿参数语言模型，训练成本估计为 460 万美元，消耗约 1287 兆瓦时电力。*出现在：第九章*

**gpt4**

截至 2023 年 OpenAI 最先进的语言模型，据报道使用专家混合架构，具有约 180 亿参数，训练成本超过 1 亿美元。*出现在：第九章*

**gpu**

图形处理单元，一种专门设计的电子电路，用于快速操纵和改变内存，以加速图像创建和并行处理任务。*出现在：第十二章，第二章，第十八章*

**优雅降级**

一种系统设计原则，其中服务在面临部分故障或数据不可用时继续以降低的能力运行。*出现在：第六章*

**梯度累积**

一种技术，通过在更新模型参数之前累积来自多个较小批次的梯度来模拟更大的批次大小，从而实现内存受限下的训练。*出现在：第八章*

**梯度裁剪**

一种正则化技术，通过在反向传播期间限制梯度的幅度来防止梯度爆炸，通常通过在梯度的范数超过阈值时缩放梯度来实现。*出现在：第七章，第八章*

**梯度压缩**

一种在分布式训练中用于通过压缩计算节点之间交换的梯度信息来减少通信开销的技术。*出现在：第二十一章*

**梯度下降**

一种优化算法，通过迭代调整神经网络参数，使其朝向最小化损失函数的方向，使用梯度来确定更新方向和幅度。*出现在：第三章，第四章，第七章，第十四章，第八章*

**梯度同步**

分布式训练中的过程，其中本地计算的梯度在设备之间聚合，以确保所有设备一致地更新其参数。*出现在：第八章*

**基于梯度的剪枝**

一种在训练期间使用梯度信息来识别具有较小梯度幅度的神经元或滤波器（这些对减少损失函数的贡献较小，可以安全地移除）的剪枝方法。*出现在：第十章*

**图形处理单元**

一种最初为渲染图形而设计的专用处理器，它提供了对高效神经网络计算和训练至关重要的并行处理能力。*出现在：第三章，第八章*

**图形处理单元 (GPU**)

一种最初为图形渲染而设计的专用处理器，它提供了适合神经网络计算的强大并行计算能力。*出现在：第十一章*

**绿色人工智能指标**

专门的环境影响指标，用于衡量人工智能系统的环境影响，包括碳足迹、能源效率和整个机器学习生命周期中的资源利用。*出现在：第十八章*

**绿色计算**

以环境负责的方式设计、制造、使用和处置计算机和计算机系统的实践。*出现在：第十八章*

**绿色 500**

一种基于每瓦特浮点运算数（FLOPS）测量的能源效率来评估世界上最具计算能力的超级计算机的排名系统，而不是原始的计算性能。*出现在：第十二章*

**灰盒攻击**

一种对抗攻击，攻击者对模型有部分了解，例如知道架构但不知道具体的参数或训练数据。*出现在：第十五章*

**分组量化**

一种量化方法，其中参数被分成组，每组共享量化参数，通过提供比层方法更细粒度的控制，在压缩和精度之间提供平衡。*出现在：第十章*

**GRU**

Gated Recurrent Unit，一种简化的 LSTM 变体，使用较少的门控单元，同时保持捕捉序列数据中长期依赖关系的能力。*出现在：第四章*

## H

**硬件抽象**

在机器学习框架中提供统一接口的层，用于访问各种计算硬件（CPU、GPU、TPU、加速器），同时在幕后处理设备特定的优化和内存管理。*出现在：第七章*

**硬件加速**

使用专用计算硬件以比在通用处理器上运行的软件更快、更有效地执行某些操作。*出现在：第十一章*

**硬件加速器**

专为高效执行特定类型计算而设计的专用计算硬件，例如用于并行处理的 GPU 或用于机器学习工作负载的 TPU。*出现在：第十二章*

**硬件约束优化**

将机器学习算法和模型适应于移动和嵌入式设备内存、计算和功率限制的技术。*出现在：第十四章*

**硬件冗余**

通过投票机制复制关键硬件组件以提供备份功能并提高系统可靠性的做法。*出现在：第十六章*

**硬件木马**

在制造硬件组件时嵌入的恶意修改，在正常条件下可能保持休眠状态，但在满足特定条件时触发有害行为。*出现在：第十五章*

**硬件感知设计**

设计神经网络架构的实践，特别针对目标硬件平台进行优化，考虑因素包括内存层次、计算单元和数据移动模式，以最大化效率。*出现在：第十章*

**软硬件协同设计**

一种协同设计方法，其中硬件加速器和软件算法共同优化以达到最大效率和性能。*出现在：第九章*

**hdfs (hadoop 分布式文件系统)**

一种分布式文件系统，旨在跨多个商品硬件集群存储大数据集，为大数据应用提供可扩展性和容错性。*出现在：第六章*

**心跳机制**

在系统组件之间发送的周期性信号，用于监控健康和检测故障，使及时故障检测和恢复成为可能。*出现在：第十六章*

**隐藏层**

神经网络中输入层和输出层之间的一层中间层，通过通过学习权重和激活函数转换数据来学习抽象表示。*出现在：第三章*

**隐藏状态**

循环神经网络的内存储器，携带来自先前时间步的信息，使网络能够在顺序输入之间保持上下文。*出现在：第四章*

**分层处理**

一种多级系统架构，其中数据和智能在计算堆栈的不同级别之间流动，从传感器到边缘设备再到云系统。*出现在：第二章*

**分层处理模式**

一种设计模式，将系统组织成层（边缘、区域、云），这些层根据可用资源和能力共享责任，优化整个计算谱系中的资源使用。*出现在：第十九章*

**高带宽内存 (hbm)**

一种先进的内存技术，通过 3D 堆叠和宽接口提供比传统 DRAM 更高的带宽，这对于数据密集型人工智能工作负载至关重要。*出现在：第十一章*

**同态加密**

一种密码学技术，允许在加密数据上直接执行计算，而无需先解密它，从而实现隐私保护机器学习推理。*出现在：第十五章*

**水平扩展**

通过添加更多机器或实例来增加系统容量，而不是升级现有硬件，提供更好的容错性和负载分配。*出现在：第十三章*

**热备件**

备份组件保持就绪，以便在系统操作不受干扰的情况下立即替换故障组件，提供冗余。*出现在：第十六章*

**Huber 损失**

在回归中使用的鲁棒损失函数，与平方误差损失相比对异常值更不敏感，从而提高训练稳定性。*出现在：第十六章*

**人工监督**

应该由人类判断来监督、纠正或暂停自动化决策的原则，以保持对人工智能系统有意义的控制。*出现在：第十七章*

**人机协作**

人类与人工智能系统之间的协同伙伴关系，其中每个人贡献他们独特的优势，以比单独工作更有效地解决复杂问题。*出现在：第二十章*

**混合机器学习**

将多个机器学习范式（如云、边缘、移动和微型机器学习）集成，形成利用互补优势的统一分布式系统。*出现在：第二章*

**混合并行性**

一种分布式训练方法，结合数据并行性和模型并行性，以利用这两种策略训练非常大的模型的好处。*出现在：第八章*

**超参数**

一种控制学习过程但不是从数据中学习的配置设置，例如学习率、批量大小或网络架构选择。*出现在：第十二章，第三章，第七章*

**超参数优化**

寻找控制机器学习训练过程的最优超参数配置（学习率、批量大小、网络架构参数）的过程。*出现在：第十八章*

**超参数**

控制机器学习算法学习过程但不是从数据中学习的配置设置，例如学习率、批量大小和网络架构参数。*出现在：第五章*

**超大规模数据中心**

包含数千台服务器并覆盖大量楼面空间的大型数据中心设施，旨在高效支持大规模计算工作负载。*出现在：第二章*

## I

**ImageNet**

一个包含超过 1400 万张标记图像的巨大视觉数据库，跨越 20,000 多个类别，由斯坦福大学的李飞飞自 2009 年起创建，其年度挑战成为推动计算机视觉突破性进展的关键因素。*出现在：第十二章，第九章，第一章*

**影响评估框架**

评估人工智能在人道主义和发展环境中的潜在社会、经济和环境影响的系统方法。*出现在：第十九章*

**命令式编程**

一种编程范式，其中操作在代码中遇到时立即执行，允许自然控制流和更容易的调试，但可能限制了优化机会。*出现在：第七章*

**推理**

机器学习的阶段，训练好的模型对新输入数据进行预测，通常比训练需要更低的精度和计算资源。*出现在：第十一章，第十八章*

**基础设施即代码**

通过机器可读的配置文件而不是手动过程来管理和配置计算基础设施的实践，这使版本控制和自动化成为可能。*出现在：第十三章*

**指令集架构 (isa)**

定义处理器可以执行的一组指令的软件和硬件接口，包括数据类型和寻址模式。*出现在：第十一章*

**int8**

在量化神经网络中使用的 8 位整数数值表示，用于减少内存使用并加速推理，同时试图保持模型精度。*出现在：第十二章*

**int8 量化**

一种数值精度降低技术，使用 8 位整数而不是 32 位浮点数来表示模型权重和激活，减少内存使用并允许在专用硬件上更快地进行推理。*出现在：第十一章，第十章*

**间歇性故障**

隐现且不可预测地发生的硬件故障，出现和消失没有一致的模式，使得诊断变得困难。*出现在：第十六章*

**物联网**

一个嵌入传感器、软件和其他技术的物理对象网络，通过互联网与其他设备和系统连接和交换数据。*出现在：第二章*

**可解释性**

人类理解机器学习模型预测背后的推理程度，通常指内在透明的模型。*出现在：第十七章*

**物联网传感器**

物联网设备，收集和传输环境或行为数据，通常在有限的电源预算下运行，并使用低带宽通信协议。*出现在：第十九章*

**迭代剪枝**

一种逐步剪枝策略，通过多个阶段逐步移除参数，并在每个阶段之间进行微调，使模型能够适应降低的容量，并且通常比一次性剪枝实现更好的准确性。*出现在：第十章*

## J

**jax**

由谷歌研究开发的数值计算库，它将 NumPy 的 API 与函数式编程转换相结合，包括自动微分、即时编译和自动向量化，以实现高性能机器学习研究。*出现在：第七章*

**即时编译**

在运行时分析和优化代码的即时编译，使框架能够通过编译常用函数来平衡急切执行的灵活性和图优化的性能优势。*出现在：第七章*

## K

**k-匿名性**

一种隐私技术，通过泛化准标识符确保数据集中每个记录至少与其他 k-1 个记录不可区分。*出现在：第六章*

**内核**

在卷积层中使用的小型可学习权重矩阵，通过卷积操作检测特定特征，也称为过滤器。*出现在：第四章*

**内核融合**

一种优化技术，将多个计算操作组合成一个单一内核，以减少内存传输并提高并行处理器上的性能。*出现在：第十一章*

**关键绩效指标**

用于评估机器学习系统成功和有效性的具体、可衡量的指标，例如准确性、精确度、召回率、延迟和吞吐量。*出现在：第五章*

**关键字检测（kws）**

一种检测音频流中特定唤醒词或短语的检测技术，通常用于对功耗和延迟有限制的语音激活设备。*出现在：第六章*

**知识蒸馏**

一种模型压缩技术，其中较小的“学生”网络通过在教师网络的软输出概率上训练来学习模仿较大的“教师”网络的行为，而不是仅仅基于硬标签。*出现在：第二十一章，第九章，第十四章，第十章，第十八章*

## L

**l0-norm constraint**

一种正则化技术，用于计算模型中非零参数的数量，在结构化剪枝中通过惩罚活动权重的数量来直接控制模型稀疏度。*出现在：第十章*

**label shift**

一种分布偏移类型，其中目标标签的分布发生变化，而特征与标签之间的条件关系保持不变。*出现在：第十六章*

**lapack**

扩展 BLAS 的线性代数包，包括矩阵分解、特征值问题和线性系统求解等高级线性代数运算，为机器学习计算提供必要的数学基础。*出现在：第七章*

**large language models**

在庞大的文本语料库上训练的具有数十亿或数万亿参数的神经网络，能够在多个领域和任务中理解和生成类似人类的文本。*出现在：第二十章*

**latency**

请求数据和交付数据之间的时间延迟，在需要即时响应的实时应用中至关重要。*出现在：第十二章，第十一章，第二章*

**latency constraints**

限制模型推理最大可接受延迟的实时需求，驱动着在响应时间至关重要的部署场景中的优化决策。*出现在：第十章*

**layer normalization**

一种归一化技术，用于对每个样本的特征维度进行归一化，通常用于 transformer 架构中，以稳定训练。*出现在：第四章*

**layerwise quantization**

一种量化粒度，其中单个层内的所有参数共享相同的量化参数，提供计算效率，但与更细粒度的方法相比，可能限制了表示精度。*出现在：第十章*

**learning rate**

一个超参数，用于确定梯度下降优化过程中权重更新的步长，对训练稳定性和收敛速度有重要影响。*出现在：第三章，第七章*

**learning rate scheduling**

在训练过程中对学习率进行系统调整，使用如步长衰减、指数衰减或余弦退火等策略来提高收敛性和最终模型性能。*出现在：第八章*

**生命周期评估**

一种对产品或系统在其整个生命周期内（从原材料提取到处置）的环境影响进行评估的系统方法。*出现在：第十八章*

**生命周期一致性**

所有 ML 开发阶段都应与整体系统目标保持一致的原则，保持数据处理、模型架构和评估标准的一致性。*出现在：第五章*

**LINPACK**

在阿贡国家实验室开发的基准测试，通过解决密集线性方程组来衡量系统性能，因其用于 Top500 超级计算机排名而闻名。*出现在：第十二章*

**负载均衡**

混合专家模型中的技术，以确保计算负载和训练信号在专家之间均匀分布，防止专家崩溃并保持模型效率。*出现在：第二十章，第十三章*

**查找表**

一种数据结构，通过简单的数组索引操作来替换运行时计算，常用于性能优化。*出现在：第十六章*

**LoRA 技术**

一种长距离无线通信协议，使物联网设备能够在 15+公里的范围内以最小的功耗进行通信，非常适合农业和环境监测应用。*出现在：第十九章*

**损失函数**

一种数学函数，量化神经网络预测与真实标签之间的差异，为训练算法提供优化目标。*出现在：第三章*

**损失缩放**

在混合精度训练中使用的一种技术，在反向传播之前将损失乘以一个大的因子，以防止在降低精度格式中的梯度下溢。*出现在：第八章*

**彩票假设**

一种理论，认为大型神经网络包含稀疏子网络，当从适当的初始化中独立训练时，可以与完整网络达到相当的精度，同时体积显著更小。*出现在：第十章*

**低秩自适应**

一种参数高效的微调方法，使用低秩矩阵来近似权重更新，减少可训练参数同时保持适应能力。*出现在：第十四章*

**低秩分解**

一种矩阵分解技术，通过将大权重矩阵近似为较小矩阵的乘积来减少神经网络层所需的参数和计算操作数量。*出现在：第十章*

**LSTM**

长短期记忆，一种循环神经网络架构，通过控制信息流的门控机制来处理长期依赖关系。*出现在：第四章*

## M

**机器意识**

在人工系统中假设出现意识，代表着探索机器能否发展主观经验的前沿研究领域。*出现在：第二十章*

**机器学习**

人工智能的一个子集，它使系统能够通过经验和数据而不是显式编程来自动提高任务性能。*出现在：第十二章，第三章，第一章，第二章，第十八章*

**机器学习加速器 (ML Accelerator)**

专门设计的计算硬件，通过优化的矩阵运算、内存层次结构和并行处理单元来高效执行机器学习工作负载。*出现在：第十一章*

**机器学习框架**

一个软件平台，提供用于设计、训练和部署机器学习模型的工具和抽象，通过计算图、硬件优化和工作流程编排将用户应用与基础设施连接起来。*出现在：第七章*

**机器学习框架**

提供用于开发、训练和部署机器学习模型工具、API 和抽象的软件库和平台，例如 TensorFlow 和 PyTorch。*出现在：第二十一章*

**机器学习生命周期**

一个结构化、迭代的过程，涵盖了开发、部署和维护机器学习系统所涉及的所有阶段，从问题定义到持续监控和改进。*出现在：第十七章，第五章*

**机器学习操作**

专注于通过自动化、监控和管理整个机器学习管道（从开发到生产）来实施机器学习模型的实践和工具集。*出现在：第五章*

**机器学习操作 (MLOps)**

通过自动化管道可靠且高效地部署和维护机器学习模型的实践。*出现在：第十六章*

**机器学习安全**

在整个机器学习生命周期中保护数据、模型和基础设施免受未经授权的访问、操纵或中断。*出现在：第十五章*

**机器学习系统工程**

专注于在计算平台上构建可靠、高效和可扩展的 AI 系统，涵盖整个 AI 生命周期，从数据采集到部署和运营，强调资源感知和系统级优化。*出现在：第一章*

**机器反学习**

从训练模型中去除特定数据点的影响的技术，无需完全重新训练，支持数据删除权。*出现在：第十七章*

**宏观基准**

评估方法，评估完整的机器学习模型，以了解架构选择和组件交互如何影响整体系统行为和性能。*出现在：第十二章*

**基于幅度的剪枝**

最常见的剪枝方法，基于假设权重幅度较小的对模型输出的贡献较小，移除绝对值最小的参数。*出现在：第二十一章，第十章*

**映射优化**

将神经网络操作分配到硬件资源的过程，以最小化通信开销并最大化可用计算单元的利用率。*出现在：第十一章*

**掩码**

一种匿名化技术，通过改变或模糊敏感值，使其无法直接追溯到原始数据主体。*出现在：第六章*

**兆瓦时**

等于 1 兆瓦功率使用 1 小时的能量单位，常用于测量数据中心等大型设施的电耗。*出现在：第十八章*

**成员推理攻击**

通过分析模型的行为和输出，试图确定特定数据点是否包含在模型的训练数据集中的攻击。*出现在：第十五章*

**成员推理攻击**

通过分析模型行为，试图确定特定数据点是否包含在模型训练集中的隐私攻击。*出现在：第十七章*

**内存带宽**

从内存中读取或写入数据的速率，以每秒字节数衡量，在内存密集型机器学习工作负载中通常成为瓶颈。*出现在：第十二章*

**内存层次结构**

具有不同访问速度和容量的内存系统组织，从快速的片上缓存到较慢的片外主存储器。*出现在：第十一章*

**元学习**

学习如何学习的过程，其中模型被训练以快速适应新任务，并使用最少的数据，这在设备上系统的个性化中特别有用。*出现在：第二十章，第十四章*

**元数据**

关于数据集的描述性信息，包括数据收集的细节、质量指标、验证状态以及其他对数据管理至关重要的上下文信息。*出现在：第六章*

**微基准测试**

专门的评价工具，用于评估机器学习系统中的单个组件或特定操作，例如张量操作或神经网络层。*出现在：第十二章*

**微控制器**

单个集成电路上的小型计算机，包含处理器核心、内存和可编程输入/输出外围设备，常用于嵌入式系统。*出现在：第十九章，第二章*

**小批量梯度下降**

一种训练方法，它同时使用训练示例的小子集来计算梯度和更新权重，平衡计算效率与梯度估计质量。*出现在：第三章*

**小批量处理**

一种优化方法，它通过计算小批量的示例梯度，平衡批量处理的计算效率与随机方法的内存约束。*出现在：第八章*

**最小-最大**

在博弈论中使用的决策策略，试图最小化对抗场景中可能的最大损失。*出现在：第十六章*

**混合精度训练**

一种在神经网络训练的不同部分使用不同数值精度的技术，通常结合 16 位和 32 位浮点运算，以减少内存使用并提高训练速度。*出现在：第十八章*

**混合精度计算**

一种在计算的不同阶段使用不同数值精度的技术，例如矩阵乘法使用 FP16，累积使用 FP32。*出现在：第十一章*

**混合精度训练**

一种训练方法，结合不同的数值精度（通常是 FP16 和 FP32），以优化内存使用和计算速度，同时保持训练稳定性。*出现在：第十二章，第二十一章，第十章，第八章*

**专家混合**

一种架构方法，使用多个专门的子模型（专家）和门控机制将输入路由到最相关的专家，从而实现高效扩展并保持稀疏性。*出现在：第二十章*

**ml 生命周期**

指导机器学习系统开发、评估和持续改进的迭代过程，涉及从数据收集到模型监控的各个阶段，包括连续适应的反馈循环。*出现在：第一章*

**ml 系统**

集成计算系统，包含三个核心组件：指导算法行为的引导数据，从数据中提取模式的学习算法，以及支持训练和推理过程的计算基础设施。*出现在：第一章*

**ml 系统谱**

机器学习系统部署的范围，从资源丰富的基于云的系统到具有严格限制的微型嵌入式设备，每个都需要不同的优化策略和权衡。*出现在：第三章*

**mlcommons**

开发和维护机器学习系统行业标准基准的组织，包括用于训练和推理评估的 MLPerf 套件。*出现在：第十二章*

**mlops**

管理机器学习系统端到端生命周期的工程学科，将 ML 开发与运营实践相结合，以实现可靠的生产部署。*出现在：第二十一章，第十三章*

**mlperf**

提供标准化测试的行业标准基准套件，用于各种深度学习工作负载的训练和推理，使机器学习系统的比较更加公平。*出现在：第十二章*

**mlperf 推理**

评估不同部署环境中机器学习推理性能的基准框架，从云端数据中心到移动设备和嵌入式系统。*出现在：第十二章*

**mlperf 移动**

专门基准，将 MLPerf 评估扩展到智能手机和移动设备，在严格的电源和内存限制下测量延迟和响应性。*出现在：第十二章*

**mlperf 微型**

为嵌入式和超低功耗 AI 系统（如物联网设备、可穿戴设备和具有最小处理能力的微控制器）设计的基准。*出现在：第十二章*

**mlperf 训练**

标准化基准，通过测量不同硬件平台上的时间到准确性、吞吐量和资源利用率来评估机器学习训练性能。*出现在：第十二章*

**mnist**

改进的美国国家标准与技术研究院手写数字数据库，包含 70,000 个 28×28 像素图像，作为计算机视觉的“Hello World”。*出现在：第九章*

**移动机器学习**

在便携式、电池供电的设备（如智能手机和平板电脑）上直接执行机器学习模型，使个性化并响应的应用成为可能。*出现在：第二章*

**移动机器学习**

优化用于智能手机和平板电脑等移动设备的机器学习系统，在计算效率和推理准确性之间取得平衡，以实现设备上的处理。*出现在：第十九章*

**移动优化架构**

专门为移动部署设计的神经网络设计，强调参数效率、计算速度和节能。*出现在：第十四章*

**MobileNet**

使用深度可分离卷积的效率神经网络架构，与传统模型相比参数数量减少约 50 倍，同时实现智能手机部署。*出现在：第九章，第十四章*

**模式坍塌**

生成模型中的一种失败模式，其中模型仅产生有限种类的输出，忽略了训练数据中的多样性，未能捕捉到完整的分布。*出现在：第二十章*

**模型卡片**

提供有关机器学习模型结构化信息的文档框架，包括预期用途、性能特征和限制。*出现在：第十七章*

**模型压缩**

用于减少机器学习模型大小和计算需求的技术，同时保持准确性，使资源受限的设备能够部署。*出现在：第十九章，第二十一章，第二章，第十四章，第十三章，第十章，第十八章*

**模型部署**

将训练好的机器学习模型集成到生产系统中，使其能够对新数据进行预测并向最终用户提供价值。*出现在：第十三章，第五章*

**模型漂移**

由于数据模式、用户行为或环境条件的变化（与原始训练条件不同）导致机器学习模型性能随时间退化。*出现在：第十三章，第五章*

**模型评估**

使用各种指标和验证技术对机器学习模型性能进行系统评估，以确定模型是否符合要求并准备部署。*出现在：第五章*

**模型提取**

通过观察其输入输出行为，通常通过系统查询模型 API 来窃取或重新创建机器学习模型的过程。*出现在：第十五章*

**模型反演攻击**

一种攻击方式，通过分析模型的输出和置信度分数来重建训练数据或推断数据集的敏感信息。*出现在：第十五章*

**模型优化**

对机器学习模型进行系统优化，以提高其效率同时保持有效性，在准确性、计算成本、内存使用、延迟和能效之间平衡折衷。*出现在：第十章，第五章*

**模型并行**

一种分布式训练策略，将神经网络模型分割到多个设备上，每个设备负责计算网络的一部分。*出现在：第十二章，第二十一章，第九章，第七章，第八章*

**模型剪枝**

从训练好的神经网络中移除不必要的权重、神经元或连接的过程，以减少其大小和计算需求。*出现在：第十八章*

**模型量化**

减少机器学习模型中数值表示的精度，通常从 32 位整数减少到 8 位整数，以减小模型大小并提高推理速度。*出现在：第十九章，第二章*

**模型注册**

用于存储、版本控制和管理的集中式仓库，用于存储与关联元数据相关的训练机器学习模型，从而促进模型治理和部署。*出现在：第十三章*

**模型服务**

基础设施和系统通过 API 公开部署的机器学习模型，以适当的延迟和吞吐量处理大规模预测请求。*出现在：第十三章*

**模型训练**

使用机器学习算法从训练数据中学习模式的过程，调整模型参数以最小化预测误差并创建一个功能性的预测系统。*出现在：第五章*

**模型不确定性**

机器学习模型无法捕捉到数据生成过程的全部复杂性，导致预测不确定性。*出现在：第十六章*

**模型验证**

在独立数据集上测试机器学习模型的过程，以评估其泛化能力并确保它们在未见数据上可靠地执行。*出现在：第十三章，第五章*

**模型版本控制**

对机器学习模型的不同版本进行系统跟踪和管理，包括它们的参数、训练数据和性能指标，以实现比较和回滚功能。*出现在：第十三章，第五章*

**模型水印**

一种将可验证的所有权签名嵌入到机器学习模型中的技术，可用于检测未经授权的使用或证明知识产权盗窃。*出现在：第十五章*

**动量**

一种优化技术，通过迭代累积速度向量，帮助梯度下降在局部最小值之间导航并加速在一致梯度方向上的收敛。*出现在：第八章*

**监控**

对机器学习系统性能、数据质量和生产中的操作指标进行持续观察和测量，以检测问题并触发维护操作。*出现在：第五章*

**蒙特卡洛 dropout**

一种在推理时使用不同 dropout 掩码进行多次前向传递来估计预测不确定性的技术。*出现在：第十六章*

**摩尔定律**

观察到微芯片上晶体管的数量大约每两年翻一番，而计算机的成本减半。这是英特尔联合创始人戈登·摩尔在 1965 年提出的。硬件改进遵循这一趋势，而 AI 算法效率在 7 年内提高了 44 倍。*出现在：第十八章* *出现在：第九章*

**多代理方法**

系统架构，其中多个 AI 代理协作、协商或竞争以解决复杂问题，实现不同组件之间的劳动分工和专业技能的专门化。*出现在：第二十章*

**多头注意力**

一种注意力机制，使用多个并行注意力头，每个头关注输入的不同方面，以同时捕获多种类型的关系。*出现在：第四章*

**多层感知器**

一种前馈神经网络，在输入和输出之间有一个或多个隐藏层，能够通过密集连接和激活函数学习非线性映射。*出现在：第四章*

**多校准**

一种公平性技术，确保模型预测在交叉子组中保持校准，解决复杂的人口统计相互作用。*出现在：第十七章*

**多层感知器**

一个具有一个或多个隐藏层的前馈神经网络，这些隐藏层位于输入层和输出层之间，能够学习数据中的非线性关系。*出现在：第三章*

**多模态人工智能**

能够同时处理和理解多种类型的数据的人工智能系统，例如文本、图像、音频和视频，从而实现更全面的理解和交互。*出现在：第二十章*

**mycin**

1976 年斯坦福大学开发的第一批大规模专家系统之一，用于诊断血液感染，代表着将捕捉特定领域的人类专家知识转向而不是追求通用人工智能的转变。*出现在：第一章*

## N

**窄人工智能**

设计用于在特定、定义明确的任务中表现出色，但缺乏在多个问题领域泛化的能力的人工智能系统，与通用人工智能形成对比。*出现在：第二十章*

**NAS 生成的架构**

通过自动神经网络架构搜索而不是手动设计发现的神经网络架构，通常通过彻底探索设计空间来实现更好的效率-精度权衡。*出现在：第十章*

**网络结构修改**

改进神经网络效率的架构变化，包括深度可分离卷积、瓶颈层和高效的注意力机制等技术，这些技术可以降低计算复杂度。*出现在：第十章*

**神经网络架构搜索**

一种自动方法，使用机器学习算法通过搜索可能的层、连接和超参数组合来发现最优的神经网络架构，以满足特定的约束条件。*出现在：第九章，第二十章，第十章，第十八章*

**神经网络引擎**

专为机器学习推理和训练设计的专用硬件加速器，例如苹果的神经网络引擎或谷歌的边缘 TPU，针对设备上的 AI 工作负载进行了优化。*出现在：第十四章*

**神经网络**

由层状组织并相互连接的节点组成的计算模型，这些节点可以通过可调连接权重学习将输入映射到输出。*出现在：第十二章，第三章，第四章，第十八章*

**神经网络处理器（NPU）**

专门设计的处理器，旨在加速神经网络操作和机器学习计算，优化 AI 工作负载的并行处理。*出现在：第十二章，第十一章，第二章*

**神经形态计算**

受生物神经网络结构和功能启发的计算架构，旨在比传统数字计算机更有效地处理信息。*出现在：第二十一章，第二十章*

**非独立同分布数据**

非独立同分布数据，其中样本在设备或时间上分布不均匀，为联邦学习收敛和泛化带来挑战。*出现在：第十四章*

**nosql**

一种数据库系统类别，旨在处理大量非结构化或半结构化数据，具有灵活的模式，常用于大数据应用。*出现在：第六章*

**数值精度优化**

模型优化维度，涉及如何表示和处理数值，包括将高精度值映射到低比特表示的量化技术。*出现在：第十章*

## O

**可观察性**

一种全面的监控方法，通过指标、日志和跟踪提供对系统行为的洞察，使人们能够从外部输出理解内部状态。*出现在：第十三章*

**olap (在线分析处理**)

一种针对大型数据集复杂分析查询优化的数据库方法，通常用于商业智能中的数据仓库。*出现在：第六章*

**oltp (在线事务处理**)

一种针对频繁、短暂事务和实时处理优化的数据库方法，常用于操作应用。*出现在：第六章*

**片上内存**

直接集成到处理器芯片上的快速内存，包括缓存和暂存内存，提供高带宽和低延迟的数据访问。*出现在：第十一章*

**设备上学习**

在部署的硬件设备上直接对机器学习模型进行局部适应或训练，而不依赖于与集中式服务器的持续连接。*出现在：第二十一章，第十四章*

**一次性剪枝**

一种剪枝策略，在单步中移除大量参数，通常随后进行微调以恢复精度，提供简单性但可能需要更激进的微调。*出现在：第十章*

**在线推理**

实时预测服务，以低延迟处理单个请求，适用于需要即时响应的交互式应用。*出现在：第十三章*

**onnx**

开放神经网络交换，一种表示机器学习模型的标准化格式，它使得不同框架之间具有互操作性，允许在一个框架中训练的模型使用另一个框架部署。*出现在：第七章*

**onnx 运行时**

通过技术如算子融合和内核调整优化机器学习模型，以提高推理速度并减少计算开销的跨平台推理引擎。*出现在：第十二章*

**优化器**

在训练过程中调整模型参数以最小化损失函数的算法，常见的例子包括 SGD（随机梯度下降）、Adam 和 RMSprop，它们各自有不同的参数更新策略。*出现在：第七章*

**编排**

多个 AI 系统或代理协同工作的协调和管理，确保分布式智能系统中的适当排序、通信和资源分配。*出现在：第二十章，第十三章*

**异常检测**

识别与正常模式显著偏离的数据点的过程，这些点可能代表错误、异常或有价值罕见事件。*出现在：第六章*

**过拟合**

一种现象，模型对训练数据的特定细节学习得非常好，以至于它无法推广到新的、未见过的例子，通常表现为高训练准确率但验证性能差。*出现在：第三章*

**氧化物击穿**

由于过大的电场应力，晶体管中氧化层失效，导致永久性硬件故障。*出现在：第十六章*

## P

**填充**

卷积网络中的一种技术，通过在输入边界周围添加零或其他值来控制输出特征图的空间维度。*出现在：第四章*

**范式转变**

科学方法的基本变化，例如 20 世纪 90 年代从符号推理到人工智能中的统计学习，以及 2010 年代从浅层学习到深度学习的转变，要求研究人员放弃既定方法，采用根本不同的方法。*出现在：第一章*

**并行性**

同时执行多个计算任务或操作，这是在神经网络处理中实现高性能的基本要求。*出现在：第十一章*

**参数**

神经网络的可学习组件，包括权重和偏差，在训练过程中进行调整以最小化损失函数。*出现在：第三章，第十八章*

**参数高效微调**

类似于 LoRA 和 Adapters 的方法，在更新不到 1%的模型参数的同时实现完整的微调性能，将内存需求从千兆字节减少到兆字节。*出现在：第九章*

**分区**

一种数据库技术，根据特定标准将大型数据集划分为更小、更易于管理的段，以提高查询性能和系统可扩展性。*出现在：第六章*

**感知器**

神经网络的基本构建块，由加权输入、偏差项和一个产生单个输出的激活函数组成。*出现在：第三章，第一章*

**性能洞察**

从监控生产机器学习系统中得出的分析观察结果，揭示了在模型准确性、系统效率或用户体验方面的改进机会。*出现在：第五章*

**性能-效率缩放**

描述计算效率改进如何转化为不同模型架构和训练制度中性能提升的数学关系。*出现在：第九章*

**永久性故障**

持续到修复或组件更换的硬件缺陷，持续影响系统行为。*出现在：第十六章*

**困惑度**

衡量语言模型预测文本的能力，计算为 2 的交叉熵损失，值越低表示预测能力越好。*出现在：第九章*

**个性化层**

模型组件，通常是最终的分类层，在保持共享骨干层冻结的同时，针对用户特定的数据进行本地调整。*出现在：第十四章*

**物理攻击**

直接操作或篡改计算硬件以损害机器学习系统的安全和完整性，绕过传统的软件防御措施。*出现在：第十五章*

**管道丛林**

复杂、相互依赖的数据处理管道难以维护、调试和修改的反模式，导致技术债务和运营复杂性。*出现在：第十三章*

**管道并行性**

一种模型并行形式，将模型的不同层放置在不同的设备上，数据以管道方式通过它们，允许同时处理多个批次。*出现在：第七章，第八章*

**池化**

卷积网络中的下采样操作，在减少空间维度的同时保留重要特征，通常在局部区域使用最大值或平均值操作。*出现在：第四章*

**位置编码**

在 transformer 架构中用于注入关于序列中标记位置信息的方法，因为 transformer 缺乏固有的顺序处理能力。*出现在：第四章*

**事后解释**

在模型训练后应用的解释方法，将模型视为黑盒，并从输入输出行为中推断推理模式。*出现在：第十七章*

**训练后量化**

一种应用于已训练模型的量化方法，不修改训练过程，通常涉及在代表性数据上的校准，以确定最佳量化参数。*出现在：第十章*

**功率使用效率**

用于确定数据中心能源效率的指标，计算为总设施能耗与 IT 设备能耗之比。*出现在：第十八章*

**功率使用效率（PUE）**

数据中心中用于衡量能源效率的指标，计算为总设施能耗与 IT 设备能耗之比。*出现在：第十二章*

**精度**

在数值计算中，用于表示数字的位数，它影响着机器学习系统中计算精度和资源需求。*出现在：第十二章*

**精准农业**

使用包括 GPS、传感器和机器学习在内的技术，通过精确监控和管理作物投入（如水、肥料和杀虫剂）来优化农业实践。*出现在：第十九章*

**预取**

一种系统优化技术，在需要之前将数据加载到内存中，通过重叠数据加载与计算来减少空闲时间并提高训练吞吐量。*出现在：第八章*

**主成分分析**

一种降维技术，识别数据中最重要的变化方向，在保留 90%以上的数据方差的同时降低计算复杂度。*出现在：第九章*

**最小权限原则**

一种安全概念，用户被赋予完成其工作职能所需的最小访问级别，从而降低安全风险。*出现在：第十六章*

**隐私预算**

差分隐私中的一个概念，表示在所有查询或计算中允许的总隐私损失量，每个操作都消耗这部分有限的预算。*出现在：第十五章*

**隐私保护机器学习**

能够在保护用于训练或推理的数据所有者的隐私的同时实现机器学习的技术和方法。*出现在：第十五章*

**隐私保护技术**

设计用于在机器学习中保护个人隐私的方法，包括差分隐私、联邦学习和本地处理。*出现在：第十七章*

**隐私与效用权衡**

在保护个人隐私和保持数据对机器学习有用性之间存在的根本紧张关系，需要通过差分隐私等技术进行仔细平衡。*出现在：第十五章*

**问题定义**

机器学习发展的初始阶段，涉及明确指定目标、约束、成功指标和运营要求，以指导所有后续的开发决策。*出现在：第五章*

**程序逻辑控制器**

在制造和物联网环境中使用的工业控制系统，可以与 ML 模型集成，以在运营技术环境中实现自动化决策。*出现在：第十三章*

**渐进增强模式**

一种设计模式，在最小资源条件下建立基本功能，并在可用资源增加时逐步引入高级功能。*出现在：第十九章*

**提示工程**

设计和优化文本提示以有效地与大型语言模型进行沟通并从 AI 系统中获得期望输出的实践。*出现在：第二十章*

**蛋白质折叠问题**

从蛋白质的氨基酸序列预测其三维结构的科学挑战，这是一个困扰科学家数十年的问题，直到像 AlphaFold 这样的系统使用深度学习方法实现了突破性的准确性。*出现在：第一章*

**剪枝**

一种模型压缩技术，通过从神经网络中移除不必要的连接或神经元来减少模型大小和计算需求，而不会显著影响性能。*出现在：第九章，第十四章*

**匿名化**

一种隐私技术，用人工标识符替换直接标识符，同时保持追踪记录以进行分析的能力。*出现在：第六章*

**pytorch**

由 Facebook 的人工智能研究实验室开发的一个深度学习框架，强调动态计算图、即时执行和直观的 Python 集成，特别受研究和小规模实验的欢迎。*出现在：第七章*

## Q

**量化**

一种模型压缩技术，将模型参数和激活的精度从高精度格式（如 32 位浮点数）降低到低精度（如 8 位整数），显著减少内存使用和计算需求。*出现在：第二十一章，第九章，第七章，第十一章，第十四章，第十八章*

**量化粒度**

应用量化参数的水平，范围从每个张量（最粗）到每个通道或每个组（更细），通常更细的粒度可以保留更多的精度，但需要更多的存储空间。*出现在：第十章*

**量化感知训练**

一种训练方法，在训练过程中模拟量化效果，使模型能够适应降低的精度，通常比训练后量化达到更好的精度。*出现在：第十章*

**量子机器学习**

量子计算和机器学习的交汇点，探索量子算法和量子计算机如何增强或改变机器学习任务。*出现在：第二十章*

**每秒查询次数（qps）**

性能指标，衡量系统在一秒内可以处理多少个推理请求，通常用于评估生产部署中的吞吐量。*出现在：第十二章*

**查询键值**

注意力机制的三个组成部分，其中查询确定要查找的内容，键代表可用内容，值包含要加权和组合的实际信息。*出现在：第四章*

## R

**实时处理**

当数据可用时对其进行处理，保证响应时间满足严格的时序约束，以便进行即时决策。*出现在：第二章*

**感受野**

输入区域影响特定神经元输出的区域，决定了该神经元可以检测到的模式的空间范围。*出现在：第四章*

**修正线性单元**

一种激活函数，如果输入为正则输出输入，否则输出零，在现代神经网络中广泛使用，因其计算简单和避免梯度消失的能力。*出现在：第八章*

**循环神经网络**

一种专为序列数据处理设计的神经网络，其连接创建循环，允许信息在时间步之间持续存在。*出现在：第四章*

**正则化**

通过添加约束或惩罚来防止神经网络过拟合的技术，包括 dropout、权重衰减和数据增强等方法。*出现在：第四章，第十六章*

**ReLU**

定义为 f(x) = max(0,x) 的修正线性单元激活函数，在保持计算效率的同时引入非线性，并避免梯度消失问题。*出现在：第三章*

**可再生能源**

来自自然补充的可再生资源的能量，包括太阳能、风能、水力、地热能和生物质能。*出现在：第十八章*

**残差连接**

一种跳跃连接，将层的输入添加到其输出中，通过缓解梯度消失问题，使得训练非常深的网络成为可能。*出现在：第四章*

**残差网络**

残差网络，一种引入跳跃连接的深度卷积架构，使得训练具有数百层的网络成为可能，并实现了突破性的性能。*出现在：第十二章，第四章，第九章*

**资源悖论**

社会影响应用中的挑战，在这些应用中，最需要帮助的地区往往缺乏传统技术部署所需的基本基础设施，需要创新的工程解决方案。*出现在：第十九章*

**资源受限环境**

具有限制计算能力、网络带宽或电力可用性的部署环境，通常需要专门的系统设计和优化技术。*出现在：第十九章*

**负责任的人工智能**

以道德、公平、透明和有利于社会的方式开发和部署人工智能系统，同时最大限度地减少潜在的危害和偏见。*出现在：第二十章，第十七章*

**视网膜眼底照片**

眼睛内部表面的医学图像，包括视网膜、视盘和血管，常用于诊断眼病和训练医疗人工智能系统。*出现在：第五章*

**反向模式求导**

一种自动微分技术，通过逆序遍历计算图来计算梯度，对于输入多而输出少的函数非常高效，使其非常适合神经网络训练。*出现在：第七章*

**奖励黑客**

AI 系统利用奖励函数的非预期方面来最大化分数，同时违反预期目标的现象。*出现在：第十七章*

**rlhf**

从人类反馈中进行强化学习 - 一种使用人类偏好来引导模型行为的训练方法，使 AI 系统能够更好地与人类价值观和意图保持一致。*出现在：第二十章*

**rmsprop**

一种自适应学习率优化算法，在训练过程中维护平方梯度的移动平均值，以自动调整每个参数的学习率。*出现在：第八章*

**鲁棒 AI**

人工智能系统在内部错误、外部扰动和环境变化的情况下保持性能和可靠性的能力。*出现在：第十六章*

**鲁棒性**

模型在输入变化、环境变化或对抗条件下的稳定和一致性能。*出现在：第十七章*

**鲁棒性指标**

用于评估模型在各种扰动下稳定性的定量指标，包括对抗准确性、认证鲁棒性界限以及在分布变化下的性能。*出现在：第十六章*

**回滚**

当在生产中发现问题时，将模型或系统回滚到先前的稳定版本的过程，以确保服务连续性。*出现在：第十三章*

**屋顶线分析**

一种性能建模技术，通过绘制操作强度与峰值性能之间的关系来识别系统是内存受限还是计算受限，从而指导优化工作。*出现在：第二十一章*

## S

**可扩展性**

机器学习系统处理不断增加的数据、用户或计算需求的能力，而不会在性能或用户体验方面出现显著下降 *出现在：第十二章，第五章*

**缩放定律**

量化模型性能与训练资源之间相关性的经验关系，遵循与模型大小、数据集大小和计算预算相关的可预测幂律关系 *出现在：第九章，第二十章*

**扫描链**

处理器中的专用测试路径，提供访问内部寄存器和逻辑，以进行全面的硬件测试和故障检测。*出现在：第十六章*

**模式**

数据的结构和格式定义，指定数据类型、字段名称和关系，对于数据验证和处理一致性至关重要。*出现在：第六章*

**模式演变**

在保持向后兼容性和确保依赖系统和应用程序持续功能的同时，随着时间的推移修改数据模式的过程。*出现在：第六章*

**读取时模式**

在数据湖中采用的一种方法，其中数据结构在读取时而不是在存储时定义和强制执行，为不同数据类型提供灵活性。*出现在：第六章*

**范围 1 排放**

来自组织拥有或控制的来源的直接温室气体排放，例如现场燃料燃烧和公司车辆。*出现在：第十八章*

**范围 2 排放**

来自组织使用的购买的电力、蒸汽、供暖或冷却的间接温室气体排放。*出现在：第十八章*

**范围 3 排放**

组织价值链中发生的所有其他间接温室气体排放，包括制造、运输和产品生命周期结束处置。*出现在：第十八章*

**安全聚合**

一种加密协议，允许联邦学习服务器在不访问单个客户端贡献的情况下计算聚合模型更新，增强隐私保护。*出现在：第十四章，第十五章*

**安全计算**

允许多个当事人共同计算私有输入上的函数，而不向彼此透露这些输入的加密协议。*出现在：第十五章*

**安全多方计算**

一种加密方法，允许多个当事人共同计算其私有输入上的函数，而不向彼此透露这些输入。*出现在：第十五章*

**分割图**

在像素级别对对象进行分类的详细注释，提供最细粒度的标记信息，但需要显著更多的存储和处理资源。*出现在：第六章*

**选择性计算**

根据输入复杂度或当前需求动态分配处理资源的计算策略，通过避免不必要的计算来提高效率。*出现在：第二十章*

**自监督学习**

训练方法，其中模型从输入数据结构创建自己的标签，使从数十亿未标记示例中进行学习成为可能，并彻底改变了自然语言处理和计算机视觉。*出现在：第九章*

**自注意力**

一种注意力机制，其中查询、键和值都来自同一序列，允许每个位置关注包括自身在内的所有位置。*出现在：第四章*

**自我完善**

一种训练方法，模型通过批判和改进其初始响应来迭代地改进自己的输出，从而实现持续改进和更好地与期望行为对齐。*出现在：第二十章*

**自监督学习**

一种机器学习范式，模型通过从其他部分预测输入的一部分来从未标记的数据中学习表示，从而减少对人工标记数据集的依赖。*出现在：第二十章*

**半监督学习**

一种机器学习方法，使用标记和无标记数据训练，利用结构假设在有限的标记下提高模型性能。*出现在：第六章*

**顺序神经网络**

设计用于处理随时间发生的数据序列的神经网络架构，保持对先前输入的一种记忆形式，以提供当前决策的信息，这对于预测行人移动模式等任务至关重要。*出现在：第一章*

**无服务器**

云计算模型，其中基础设施由提供商自动管理，允许执行代码而不必担心服务器管理。*出现在：第十三章*

**服务水平协议 (SLA)**

规定生产服务最低性能标准和正常运行时间保证的正式合同，对不遵守规定的有处罚。*出现在：第十三章*

**服务水平目标 (SLO)**

服务可靠性和性能指标（如延迟、错误率和可用性）的内部目标，这些指标指导操作决策。*出现在：第十三章*

**影子部署**

测试策略，其中新模型版本与生产模型并行处理实时流量，而不影响用户界面结果，从而实现安全验证。*出现在：第十三章*

**浅层学习**

使用有限复杂性的算法的机器学习方法，例如支持向量机和决策树，这些方法需要精心设计的特征，但不能像深度学习方法那样自动发现层次表示。*出现在：第一章*

**侧信道攻击**

利用计算系统的物理实现中泄露的信息进行的攻击，例如功耗、电磁辐射或时间变化。*出现在：第十五章*

**Sigmoid**

一种将输入值映射到 0 到 1 之间的范围的激活函数，在历史上很受欢迎，但在深度网络中容易产生梯度消失问题。*出现在：第三章，第八章*

**静默数据损坏（sdc）**

在计算或数据传输过程中未检测到的错误，在系统层中传播而不会触发警报，可能损害结果。*出现在：第十六章*

**SIMD（单指令多数据）**

一种并行计算架构，它同时对多个数据元素应用相同的操作，对于常规的数据并行计算非常有效。*出现在：第十一章*

**SIMT（单指令多线程）**

SIMD（单指令多数据）的扩展，它允许跨多个独立的线程并行执行，每个线程保持自己的状态和程序计数器。*出现在：第十一章*

**单实例吞吐量**

性能测量，侧重于单个模型实例处理请求的速度，与批量吞吐量指标形成对比。*出现在：第十二章*

**奇异值分解**

一种矩阵分解技术，将矩阵分解为三个矩阵的乘积，常用于低秩近似，通过仅保留最重要的奇异值来压缩神经网络层。*出现在：第十章*

**跳过连接**

一种直接连接，绕过一层或多层，使梯度更容易通过深度网络流动，并使非常深的架构的训练更好。*出现在：第四章*

**小农**

在小于 2 公顷的耕地上经营，生产了全球粮食供应的重要部分，但通常缺乏接触现代农业技术和信贷。*出现在：第十九章*

**社会影响测量**

对人工智能应用如何影响社区和个人的系统性评估，包括可访问性、公平性、有效性和意外后果的指标。*出现在：第十九章*

**softmax**

一种将原始分数转换为输出总和为 1 的概率分布的激活函数，这对于多类分类任务至关重要。*出现在：第四章，第八章*

**软件故障**

由于缺陷、错误或设计疏忽导致的软件系统中的意外行为，可能会损害性能或危害安全。*出现在：第十六章*

**稀疏训练**

在整个训练过程中保持神经网络权重稀疏性的训练方法，减少计算需求和内存使用。*出现在：第十八章*

**稀疏更新**

一种训练策略，根据模型参数的重要性或对性能的贡献选择性地更新模型参数的子集，从而减少计算和内存开销。*出现在：第十四章*

**稀疏性**

神经网络的一个属性，其中许多权重为零或接近零，可以通过专用硬件支持和为稀疏操作设计的算法来利用，从而提高计算效率。*出现在：第十章*

**spec cpu**

由系统性能评估合作组织开发的标准化基准测试套件，使用真实世界应用程序而不是合成测试来衡量处理器性能。*出现在：第十二章*

**spec power**

测量服务器在不同工作负载水平上的能源效率的基准方法，使计算系统中的功率性能权衡的直接比较成为可能。*出现在：第十二章*

**规范游戏**

当 AI 系统以意外的方式获得高奖励，技术上满足目标函数但违反预期目的时。*出现在：第十七章*

**推测解码**

一种自回归语言模型的优化技术，其中较小的模型生成草稿标记，然后由较大的模型验证，从而加速推理同时保持质量。*出现在：第二十一章*

**推测执行**

处理器在确认指令需要执行之前执行指令的性能优化，这可能会无意中通过微架构的旁路通道暴露敏感数据。*出现在：第十五章*

**squeezenet**

实现与 AlexNet 相当准确率的同时参数数量减少 50 倍的紧凑型 CNN 架构，证明了巧妙的设计架构可以显著减小模型大小而不牺牲性能。*出现在：第九章*

**阶段特定指标**

适应个别生命周期阶段的性能指标，例如准备阶段的数据质量指标、建模阶段的训练收敛性和部署阶段的延迟指标。*出现在：第五章*

**状态空间模型**

通过维护压缩的内存表示并增量更新来处理序列的神经网络架构，在 transformer 注意力机制上提供线性缩放优势。*出现在：第二十章*

**静态图**

在执行开始前完全定义的计算图，允许全面优化和高效部署，但要求预先指定所有操作，限制了运行时灵活性。*出现在：第七章*

**静态图与动态图**

在机器学习框架中表示计算的两种基本方法：静态图在执行前定义，允许优化但限制了灵活性，而动态图在执行过程中构建，允许灵活的控制流但可能存在优化限制。*出现在：第七章*

**静态量化**

一种量化方法，在校准期间确定量化参数，并在推理期间保持固定，提供计算效率但比动态方法适应性差。*出现在：第十章*

**统计学习**

20 世纪 90 年代出现的机器学习时代，将重点从基于规则的符号 AI 转移到能够从数据中学习模式算法，为现代数据驱动的人工智能方法奠定了基础。*出现在：第一章*

**随机计算**

使用随机位和概率操作进行算术的计算技术，可能比传统方法提供更好的容错能力。*出现在：第十六章*

**随机梯度下降**

梯度下降的一种变体，使用单个训练示例或小批量而不是整个数据集来估计梯度，减少内存需求并实现在线学习。*出现在：第九章，第八章*

**流式摄取**

一种数据处理模式，实时处理到达的数据，对于需要即时处理和低延迟响应的应用至关重要。*出现在：第六章*

**流处理**

实时数据处理方法，处理连续的数据流，使其到达时立即响应事件和模式检测。*出现在：第六章*

**步长**

卷积滤波器在输入上移动的步长，控制输出空间维度和滤波器应用之间的重叠程度。*出现在：第四章*

**结构化剪枝**

一种剪枝方法，通过移除整个计算单元，如神经元、通道或层，生成更小、更密集的模型，比无结构剪枝产生的稀疏矩阵更易于硬件实现。*出现在：第十章*

**固定故障**

一种永久性硬件故障，其中信号线固定在逻辑 0 或 1，而不管输入如何，导致计算错误。*出现在：第十六章*

**学生系统**

1964 年由丹尼尔·鲍勃罗（Daniel Bobrow）编写的一个早期 AI 程序，通过将英语代数文字问题转换为数学方程式来展示自然语言理解，标志着符号 AI 的一个重要里程碑。*出现在：第一章*

**师生学习**

知识蒸馏的核心机制，其中较小的学生网络从较大的教师网络中学习，通常使用软目标，这些目标比硬分类标签提供更多信息。*出现在：第十章*

**监督学习**

一种机器学习方法，其中模型从标记的训练示例中学习，以对新、未标记的数据进行预测。*出现在：第三章*

**供应链攻击**

一种攻击，在制造、分销或集成过程中损害硬件或软件组件，可能影响多个下游系统。*出现在：第十五章*

**支持向量机**

使用“核技巧”寻找最优决策边界的机器学习算法，在深度学习获得突出地位之前一直主导着竞赛，直到大约 2010 年神经网络开始受到关注。*出现在：第九章*

**可持续 AI**

开发和部署人工智能系统，在保持有效性和可访问性的同时，最大限度地减少环境影响的做法。*出现在：第十八章*

**可持续发展目标**

联合国为解决到 2030 年紧迫的社会、经济和环境挑战而采用的 17 个全球目标，为 AI 在公益领域的应用提供了一个框架。*出现在：第十九章*

**群体智能**

从去中心化、自我组织的系统中产生的集体智能，通常受生物群的影响，应用于分布式机器学习和机器人系统。*出现在：第二十章*

**符号 AI**

早期的人工智能方法，试图通过符号操作和基于规则的系统来实现智能，例如 STUDENT 程序，它只能处理与其预编程模式匹配的输入。*出现在：第一章*

**符号编程**

一种编程范式，其中计算表示为抽象符号和表达式，这些符号和表达式首先构建然后执行，允许进行全面的优化，但需要显式的执行阶段。*出现在：第七章*

**合成基准**

人工测试程序，用于测量系统性能的特定方面，而不是基于现实世界应用程序和工作负载的基准。*出现在：第十二章*

**合成数据**

使用算法、模拟或生成模型创建的人工数据，用于补充现实世界的数据集，解决数据可用性或隐私问题。*出现在：第六章*

**合成数据生成**

创建人工数据集，这些数据集近似于真实数据的统计特性，同时降低隐私风险并避免直接暴露敏感信息。*出现在：第十五章*

**系统效率**

在算法、计算和数据效率维度上优化机器学习系统，以最小化计算、内存和能源需求，同时保持性能。*出现在：第九章*

**系统级芯片**

包含计算机或电子系统大部分或所有组件的集成电路，包括 CPU、GPU、内存和单芯片上的专用处理器。*出现在：第二章*

**系统级芯片（soc**）

包含计算机系统大部分或所有组件的集成电路，常用于移动设备和嵌入式系统，以提高空间和能源效率。*出现在：第十二章*

**系统级可持续性**

对环境责任的整体方法，考虑整个 AI 基础设施生态系统，从数据中心到边缘设备，而不是孤立地优化单个组件。*出现在：第十八章*

**系统集成**

将各种组件和子系统组合成一个统一、功能系统的过程，该系统能够作为一个整体高效、可靠地运行。*出现在：第二十一章*

**系统思维**

通过考虑单个组件如何相互作用并影响整个系统来理解复杂系统的方法，这在机器学习中尤为重要，因为数据、算法、硬件和部署环境必须有效协作。*出现在：第一章，第五章*

**收缩阵列**

一种专门的硬件架构，通过将数据流经处理元素网格来高效执行矩阵运算，最小化数据移动和能耗。*出现在：第十一章，第八章*

## T

**尾部延迟**

系统中的最坏情况响应时间，通常测量为 95%或 99%的分位数延迟，对于理解在峰值负载条件下的系统可靠性很重要。*出现在：第十二章*

**定制推理基准**

为特定部署环境或用例设计的专用性能测试，考虑到独特的约束和优化需求。*出现在：第十二章*

**tanh**

一种将输入映射到范围（-1,1）且输出以零为中心的激活函数，与 sigmoid 函数相比，有助于稳定基于梯度的优化。*出现在：第八章*

**针对性攻击**

一种旨在造成特定输入或类别误分类的数据中毒攻击，同时保持模型的整体性能基本不变。*出现在：第十五章*

**技术债务**

在开发过程中由于便捷的设计决策而积累的长期维护成本，在 ML 系统中尤其成问题，因为数据依赖性和模型复杂性。*出现在：第十三章*

**遥测**

从分布式系统中自动收集和传输性能数据和指标，使远程监控和分析成为可能。*出现在：第十三章*

**张量**

用于在神经网络中表示数据的多维数组，将标量（0D）、向量（1D）和矩阵（2D）推广到更高维度。*出现在：第十二章，第三章，第七章，第十一章*

**张量分解**

将矩阵分解扩展到高阶张量，用于通过将权重张量表示为具有较少参数的较小张量的组合来压缩神经网络层。*出现在：第十章*

**张量并行**

一种分布式计算技术，将单个张量和操作分配到多个设备上，通过协调并行执行来保持计算效率，同时降低每个设备的内存需求。*出现在：第七章*

**张量处理单元**

谷歌为机器学习工作负载专门设计的定制应用特定集成电路，针对矩阵操作进行优化，并具有脉动阵列架构。*出现在：第八章*

**张量处理单元（tpu**）

谷歌为神经网络机器学习专门设计的定制应用特定集成电路，针对 TensorFlow 操作进行优化。*出现在：第十二章，第十一章，第二章*

**tensorflow**

由谷歌开发的一个全面的机器学习框架，提供从研究到生产的整个 ML 管道的工具，具有急切执行和基于图的计算，并具有广泛的生态系统支持。*出现在：第七章*

**TensorRT**

NVIDIA 的推理优化库，应用如算子融合和精度降低等技术，以加速 GPU 硬件上的深度学习推理。*出现在：第十二章*

**三元化**

一种极端量化技术，将权重限制为三个值（通常是-1、0、+1），在提供比二进制量化更多表示能力的同时实现显著压缩。*出现在：第十章*

**测试时间计算**

推理过程中的动态资源分配，根据任务复杂度或重要性调整计算工作量，实现灵活的性能-准确度权衡。*出现在：第九章*

**热应力**

由于反复在高温和低温之间循环造成的硬件退化，导致材料疲劳和潜在的故障。*出现在：第十六章*

**激活阈值**

神经元开始产生显著输出的输入水平，由权重、偏差和所选激活函数的组合决定，控制神经元何时对网络的计算做出贡献。*出现在：第三章*

**吞吐量**

系统处理数据或完成操作的速率，通常以每秒操作数衡量，对于训练大型模型至关重要。*出现在：第十二章、第十一章*

**达到准确度的时间**

训练过程中机器学习模型达到预定义准确度阈值所需的时间，作为训练效率评估的关键指标。*出现在：第十二章*

**微型机器学习**

在超约束设备上执行机器学习模型，如微控制器和传感器，在毫瓦到亚瓦特功率范围内运行。*出现在：第二章*

**微型机器学习**

设计用于在资源极为受限的设备上运行的机器学习系统，如微控制器，通常模型小于 1MB，功耗小于 150 毫瓦。*出现在：第十九章*

**微型机器学习**

在内存小于 1KB-1MB 和功耗小于 1mW 的微控制器和边缘设备上进行的机器学习，使在物联网设备中实现传统部署成为可能。*出现在：第二十一章、第九章、第十四章*

**标记**

语言模型处理的文本单元，通常是单词或子词片段，现代模型如 GPT-3 在数千亿个标记上训练。*出现在：第九章*

**TOPS（每秒运算次数**）

每秒万亿操作，衡量计算性能的指标，表示系统在一秒内可以执行多少万亿次操作。*出现在：第十二章*

**tpu**

张量处理单元，谷歌专门为加速机器学习工作负载中的张量操作设计的定制应用特定集成电路（ASIC），与通用处理器相比，提供了显著的性能和能效提升。*出现在：第九章，第七章，第十八章*

**训练**

使用标记数据和优化算法调整神经网络参数的过程，以最小化预测误差并提高性能。*出现在：第十二章，第三章，第十一章，第二章，第十八章*

**训练-服务偏差**

在模型训练期间与服务期间使用的特征预处理逻辑不一致，导致生产性能下降。*出现在：第十三章*

**迁移学习**

一种机器学习技术，它利用从相关任务的预训练模型中获得的知识，通过重用学习到的特征和表示，允许在有限数据的新任务上更快地训练并获得更好的性能。*出现在：第二十一章，第六章，第九章，第七章，第二十章，第十四章，第十六章，第十八章，第五章*

**transformer**

一种完全基于注意力机制的神经网络架构，消除了递归和卷积，在许多领域实现了最先进的性能。*出现在：第十二章，第四章，第九章，第十八章*

**transformer 架构**

一种基于注意力机制的神经网络架构，它彻底改变了自然语言处理，并越来越多地应用于计算机视觉等其他领域。*出现在：第二十章*

**瞬态故障**

临时硬件故障，不会持续或造成永久性损害，但如果处理不当，可能导致计算错误。*出现在：第十六章*

**平移不变性**

卷积网络识别模式的能力，无论这些模式在输入中的位置如何，这是通过权重共享和池化操作实现的。*见：第四章*

**透明度**

对 AI 系统构建、训练、验证和部署的开放性，包括数据来源、设计假设和局限性的披露。*见：第十七章*

**三模冗余（TMR）**

一种容错技术，其中对计算执行三次，通过多数投票确定正确的结果。*见：第十六章*

**可信执行环境**

处理器内部的一个安全区域，为代码和数据提供基于硬件的保护，确保即使在特权系统软件下也能保证机密性和完整性。*见：第十五章*

**Tucker 分解**

一种张量分解方法，使用核心张量和因子矩阵将奇异值分解推广到高阶张量，通常用于压缩卷积神经网络层。*见：第十章*

**电视白空间**

未使用的广播频率，可以重新用于互联网连接，如 FarmBeats 系统所做的那样，以扩展网络访问到远程农业传感器和物联网设备。*见：第一章*

## U

**UCI 机器学习仓库**

加州大学欧文分校于 1987 年建立，是机器学习数据集最广泛使用的资源之一，包含超过 600 个数据集，这些数据集在数千篇研究论文中被引用。*见：第九章*

**均匀量化**

一种量化方法，其中值域被分为等间隔的区间，提供简单的实现，但对于非均匀值分布可能不是最优的。*见：第十章*

**万能逼近定理**

一个理论结果，证明具有足够宽度和非线性激活函数的神经网络可以在紧致域上逼近任何连续函数。*见：第四章*

**无结构剪枝**

一种剪枝方法，在保留整体网络架构的同时移除单个权重，创建需要专用硬件支持以实现计算优势的稀疏权重矩阵。*见：第十章*

**无结构稀疏性**

一种模型稀疏性形式，其中单个权重被设置为零，而不遵循任何特定模式，创建不规则稀疏模式，需要专用硬件支持以实现计算优势。*见：第十章*

## V

**验证问题**

在模型测试期间发现的问题，表明性能不佳、过拟合、数据质量问题或其他在部署前必须解决的问题。*出现在：第五章*

**价值观对齐**

AI 系统应追求与人类意图和伦理规范一致的目标的原则，解决在机器目标中编码人类价值观的挑战。*出现在：第十七章*

**价值观敏感设计**

通过系统利益相关者参与和考虑系统影响伦理的方法，将人类价值观融入技术设计。*出现在：第十七章*

**梯度消失**

深度神经网络中的一个问题，其中梯度在反向传播通过层时指数级减小，使得早期层难以有效学习。*出现在：第三章，第四章*

**梯度消失问题**

在训练深度神经网络时遇到的挑战，其中梯度在反向传播通过层时指数级减小，使得难以有效训练早期层。*出现在：第八章*

**向量运算**

同时处理多个数据元素的运算操作，使神经网络中元素级变换的并行执行变得高效。*出现在：第十一章*

**由载体传播的疾病**

由昆虫或其他载体传播的疾病，如由蚊子携带的疟疾，可以使用机器学习驱动的检测系统进行监测和控制。*出现在：第十九章*

**版本控制**

跟踪数据集、模型和管道随时间变化的实践，使机器学习系统具有可重复性、回滚能力和审计跟踪。*出现在：第六章*

**良性循环**

深度学习中的自我强化过程，其中数据可用性、算法和计算能力的改进各自使其他领域的进一步发展成为可能，从而加速整体进步。*出现在：第三章*

**视觉-语言模型**

能够同时理解和推理视觉和文本信息的 AI 系统，使图像字幕、视觉问答和多模态理解等任务成为可能。*出现在：第二十章*

**冯·诺依曼瓶颈**

传统计算机架构中处理器和内存之间共享总线造成的性能限制，其中数据移动比计算更昂贵。*出现在：第十一章*

## W

**看门狗定时器**

一种硬件组件，用于监控系统执行情况，并在系统无响应或卡住时触发恢复操作。*出现在：第十六章*

**水使用效率**

一个衡量数据中心用水效率的指标，计算为总用水量与 IT 设备能耗的比率。*出现在：第十八章*

**waymo**

Alphabet Inc. 的子公司，代表了在自动驾驶技术中机器学习系统最雄心勃勃的应用之一，展示了 ML 系统如何在安全关键环境中从嵌入式系统到云基础设施的跨越。*出现在：第一章*

**弱监督**

一种使用通过启发式方法、远程监督或程序性方法更高效获得的低质量标签的方法，而不是手动专家标注。*出现在：第六章*

**网络爬虫**

一种自动从网站提取数据以构建自定义数据集的技术，需要仔细考虑法律、伦理和技术限制。*出现在：第六章*

**权重**

一个可学习的参数，用于确定不同层之间神经元的连接强度，在训练过程中调整以最小化损失函数。*出现在：第三章*

**权重冻结**

一种在训练过程中固定大多数模型参数，同时只允许特定层或组件更新的技术，减少了设备上自适应的计算需求。*出现在：第十四章*

**权重矩阵**

在神经网络中连接一个层到另一个层的有序权重集合，通过矩阵运算实现高效计算。*出现在：第三章*

**权重共享**

在不同空间位置使用相同参数的实践，如在卷积网络中，减少参数数量同时保持模式检测能力。*出现在：第四章*

**whetstone**

1964 年早期引入的基准测试，测量了浮点运算性能（每秒千条指令，KIPS），成为第一个广泛采用的标准化性能测试。*出现在：第十二章*

**白盒攻击**

一种对抗攻击，攻击者对模型的架构、参数、训练数据和内部工作方式有完全的了解，从而能够实施高度有效的攻击策略。*出现在：第十五章*

**工作流程编排**

自动协调和管理复杂的机器学习管道序列，确保在分布式系统中正确执行顺序、依赖管理和错误处理。*出现在：第五章*

## X

**xla**

加速线性代数，一个针对线性代数操作的特定领域编译器，通过为包括 CPU、GPU 和 TPU 在内的各种硬件平台生成高效代码来优化 TensorFlow 和 JAX 的计算。*出现在：第七章*

## Z

**零日漏洞**

在开发者有机会创建和分发补丁之前，攻击者可以利用的软件或硬件中的先前未知的安全漏洞。*出现在：第十五章*

**零样本学习**

机器学习模型在训练期间执行从未见过的任务或分类对象的能力，通常通过复杂的表现学习或大规模预训练实现。*出现在：第二十章*

* * *

## 关于本词汇表

这个词汇表是从教科书中的章节特定词汇表中自动生成的，确保了一致性和完整性。每个术语都在机器学习系统的上下文中定义，并包括参考以帮助您探索相关概念。

**覆盖范围**：机器学习系统涵盖了从基础概念到前沿应用的完整机器学习系统范围，这个词汇表反映了这种全面的范围。

**更新**：该词汇表与教科书内容同步维护，以确保定义保持最新和准确。

*生成于 2025-10-08 09:10*
