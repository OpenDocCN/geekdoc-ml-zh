- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://dafriedman97.github.io/mlbook/content/c7/code.html](https://dafriedman97.github.io/mlbook/content/c7/code.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Several Python libraries allow for easy and efficient implementation of neural
    networks. Here, we’ll show examples with the very popular `tf.keras` submodule.
    This submodule integrates Keras, a user-friendly high-level API, into Tensorflow,
    a lower-level backend. Let’s start by loading Tensorflow, our visualization packages,
    and the [Boston](../appendix/data.html) housing dataset from `scikit-learn`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Neural networks in Keras can be fit through one of two APIs: the *sequential*
    or the *functional* API. For the type of models discussed in this chapter, either
    approach works.'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The Sequential API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fitting a network with the Keras sequential API can be broken down into four
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add layers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile model (and summarize)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An example of the code for these four steps is shown below. We first instantiate
    the network using `tf.keras.models.Sequential()`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we add layers to the network. Specifically, we have to add any hidden
    layers we like followed by a single output layer. The type of networks covered
    in this chapter use only `Dense` layers. A “dense” layer is one in which each
    neuron is a function of all the other neurons in the previous layer. We identify
    the number of neurons in the layer with the `units` argument and the activation
    function applied to the layer with the `activation` argument. For the first layer
    only, we must also identify the `input_shape`, or the number of neurons in the
    input layer. If our predictors are of length `D`, the input shape will be `(D,
    )` (which is the shape of a single observation, as we can see with `X[0].shape`).
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to compile the model. Compiling determines the configuration
    of the model; we specify the optimizer and loss function to be used as well as
    any metrics we would like to monitor. After compiling, we can also preview our
    model with `model.summary()`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we fit the model. Here is where we actually provide our training data.
    Two other important arguments are `epochs` and `batch_size`. Models in Keras are
    fit with *mini-batch gradient descent*, in which samples of the training data
    are looped through and individually used to calculate and update gradients. `batch_size`
    determines the size of these samples, and `epochs` determines how many times the
    gradient is calculated for each sample.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Predictions with the model built above are shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/code_8_01.png](../Images/92958b9a2375bcdb5723ba8fd688db7a.png)'
  prefs: []
  type: TYPE_IMG
- en: 2\. The Functional API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fitting models with the Functional API can again be broken into four steps,
    listed below.
  prefs: []
  type: TYPE_NORMAL
- en: Define layers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile model (and summarize)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While the sequential approach first defines the model and then adds layers,
    the functional approach does the opposite. We start by adding an input layer using
    `tf.keras.Input()`. Next, we add one or more hidden layers using `tf.keras.layers.Dense()`.
    Note that in this approach, we link layers directly. For instance, we indicate
    that the `hidden` layer below follows the `inputs` layer by adding `(inputs)`
    to the end of its definition.
  prefs: []
  type: TYPE_NORMAL
- en: After creating the layers, we can define our model. We do this by using `tf.keras.Model()`
    and identifying the input and output layers. Finally, we compile and fit our model
    as in the sequential API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Predictions formed with this model are shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/code_13_0.png](../Images/780d61e9d6ddfcc0c879e00f897defa6.png)'
  prefs: []
  type: TYPE_IMG
- en: 1\. The Sequential API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fitting a network with the Keras sequential API can be broken down into four
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add layers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile model (and summarize)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An example of the code for these four steps is shown below. We first instantiate
    the network using `tf.keras.models.Sequential()`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we add layers to the network. Specifically, we have to add any hidden
    layers we like followed by a single output layer. The type of networks covered
    in this chapter use only `Dense` layers. A “dense” layer is one in which each
    neuron is a function of all the other neurons in the previous layer. We identify
    the number of neurons in the layer with the `units` argument and the activation
    function applied to the layer with the `activation` argument. For the first layer
    only, we must also identify the `input_shape`, or the number of neurons in the
    input layer. If our predictors are of length `D`, the input shape will be `(D,
    )` (which is the shape of a single observation, as we can see with `X[0].shape`).
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to compile the model. Compiling determines the configuration
    of the model; we specify the optimizer and loss function to be used as well as
    any metrics we would like to monitor. After compiling, we can also preview our
    model with `model.summary()`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we fit the model. Here is where we actually provide our training data.
    Two other important arguments are `epochs` and `batch_size`. Models in Keras are
    fit with *mini-batch gradient descent*, in which samples of the training data
    are looped through and individually used to calculate and update gradients. `batch_size`
    determines the size of these samples, and `epochs` determines how many times the
    gradient is calculated for each sample.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Predictions with the model built above are shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/code_8_01.png](../Images/92958b9a2375bcdb5723ba8fd688db7a.png)'
  prefs: []
  type: TYPE_IMG
- en: 2\. The Functional API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fitting models with the Functional API can again be broken into four steps,
    listed below.
  prefs: []
  type: TYPE_NORMAL
- en: Define layers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile model (and summarize)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While the sequential approach first defines the model and then adds layers,
    the functional approach does the opposite. We start by adding an input layer using
    `tf.keras.Input()`. Next, we add one or more hidden layers using `tf.keras.layers.Dense()`.
    Note that in this approach, we link layers directly. For instance, we indicate
    that the `hidden` layer below follows the `inputs` layer by adding `(inputs)`
    to the end of its definition.
  prefs: []
  type: TYPE_NORMAL
- en: After creating the layers, we can define our model. We do this by using `tf.keras.Model()`
    and identifying the input and output layers. Finally, we compile and fit our model
    as in the sequential API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Predictions formed with this model are shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/code_13_0.png](../Images/780d61e9d6ddfcc0c879e00f897defa6.png)'
  prefs: []
  type: TYPE_IMG
