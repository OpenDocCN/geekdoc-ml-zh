- en: 7.2 Sampling and creating training data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7.2 样本和创建训练数据
- en: 原文：[https://huyenchip.com/ml-interviews-book/contents/7.2-sampling-and-creating-training-data.html](https://huyenchip.com/ml-interviews-book/contents/7.2-sampling-and-creating-training-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://huyenchip.com/ml-interviews-book/contents/7.2-sampling-and-creating-training-data.html](https://huyenchip.com/ml-interviews-book/contents/7.2-sampling-and-creating-training-data.html)
- en: '[E] If you have 6 shirts and 4 pairs of pants, how many ways are there to choose
    2 shirts and 1 pair of pants?'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E] 如果你有6件衬衫和4条裤子，有多少种方式可以选择2件衬衫和1条裤子？'
- en: '[M] What is the difference between sampling with vs. without replacement? Name
    an example of when you would use one rather than the other?'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 有放回和无放回采样的区别是什么？举例说明在什么情况下你会选择其中一种而不是另一种？'
- en: '[M] Explain Markov chain Monte Carlo sampling.'
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 解释马尔可夫链蒙特卡洛采样。'
- en: '[M] If you need to sample from high-dimensional data, which sampling method
    would you choose?'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 如果你需要从高维数据中采样，你会选择哪种采样方法？'
- en: '[H] Suppose we have a classification task with many classes. An example is
    when you have to predict the next word in a sentence -- the next word can be one
    of many, many possible words. If we have to calculate the probabilities for all
    classes, it’ll be prohibitively expensive. Instead, we can calculate the probabilities
    for a small set of candidate classes. This method is called candidate sampling.
    Name and explain some of the candidate sampling algorithms.'
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[H] 假设我们有一个具有许多类别的分类任务。一个例子是当你必须预测句子中的下一个单词时——下一个单词可以是许多可能单词中的一个。如果我们必须计算所有类别的概率，这将非常昂贵。相反，我们可以计算一小组候选类别的概率。这种方法被称为候选采样。命名并解释一些候选采样算法。'
- en: '**Hint**: check out this great [article](https://www.tensorflow.org/extras/candidate_sampling.pdf)
    on candidate sampling by the TensorFlow team.'
  id: totrans-7
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：查看TensorFlow团队关于候选采样的这篇优秀的文章[https://www.tensorflow.org/extras/candidate_sampling.pdf](https://www.tensorflow.org/extras/candidate_sampling.pdf)。'
- en: Suppose you want to build a model to classify whether a Reddit comment violates
    the website’s rule. You have 10 million unlabeled comments from 10K users over
    the last 24 months and you want to label 100K of them.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你想构建一个模型来分类Reddit评论是否违反了网站规则。你拥有过去24个月内来自1万名用户的1000万条未标记评论，并且你想要标记其中的10万条。
- en: '[M] How would you sample 100K comments to label?'
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 你会如何采样10万条评论进行标记？'
- en: '[M] Suppose you get back 100K labeled comments from 20 annotators and you want
    to look at some labels to estimate the quality of the labels. How many labels
    would you look at? How would you sample them?'
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 假设你从20个标注者那里收到了10万条标记好的评论，并且你想查看一些标签来估计标签的质量。你会查看多少个标签？你会如何采样它们？'
- en: '**Hint**: This [article](https://www.cloudresearch.com/resources/guides/sampling/pros-cons-of-different-sampling-methods/)
    on different sampling methods and their use cases might help.'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：这篇关于不同采样方法和它们用例的文章[https://www.cloudresearch.com/resources/guides/sampling/pros-cons-of-different-sampling-methods/](https://www.cloudresearch.com/resources/guides/sampling/pros-cons-of-different-sampling-methods/)可能有所帮助。'
- en: '[M] Suppose you work for a news site that historically has translated only
    1% of all its articles. Your coworker argues that we should translate more articles
    into Chinese because translations help with the readership. On average, your translated
    articles have twice as many views as your non-translated articles. What might
    be wrong with this argument?'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 假设你为一家新闻网站工作，该网站历史上只翻译了所有文章的1%。你的同事认为我们应该翻译更多文章到中文，因为翻译有助于提高读者群。平均而言，你的翻译文章的观看量是非翻译文章的两倍。这个论点可能有什么问题？'
- en: '**Hint**: think about selection bias.'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：考虑选择偏差。'
- en: '[M] How to determine whether two sets of samples (e.g. train and test splits)
    come from the same distribution?'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 如何确定两组样本（例如训练集和测试集分割）是否来自同一分布？'
- en: '[H] How do you know you’ve collected enough samples to train your ML model?'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[H] 你如何知道你已经收集了足够的样本来训练你的机器学习模型？'
- en: '[M] How to determine outliers in your data samples? What to do with them?'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 如何确定数据样本中的异常值？对它们应该怎么办？'
- en: Sample duplication
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本重复
- en: '[M] When should you remove duplicate training samples? When shouldn’t you?'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 应该在什么时候移除重复的训练样本？什么时候不应该？'
- en: '[M] What happens if we accidentally duplicate every data point in your train
    set or in your test set?'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 如果我们意外地重复了训练集或测试集中的每个数据点，会发生什么？'
- en: Missing data
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 缺失数据
- en: '[H] In your dataset, two out of 20 variables have more than 30% missing values.
    What would you do?'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[H] 在你的数据集中，20个变量中有两个变量的缺失值超过30%。你会怎么办？'
- en: '[M] How might techniques that handle missing data make selection bias worse?
    How do you handle this bias?'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 处理缺失数据的技术如何可能使选择偏差变得更糟？你如何处理这种偏差？'
- en: '[M] Why is randomization important when designing experiments (experimental
    design)?'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 为什么在实验设计（实验设计）中随机化很重要？'
- en: Class imbalance.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类别不平衡。
- en: '[E] How would class imbalance affect your model?'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E] 类别不平衡会如何影响你的模型？'
- en: '[E] Why is it hard for ML models to perform well on data with class imbalance?'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E] 为什么ML模型在类别不平衡的数据上表现良好很困难？'
- en: '[M] Imagine you want to build a model to detect skin legions from images. In
    your training dataset, only 1% of your images shows signs of legions. After training,
    your model seems to make a lot more false negatives than false positives. What
    are some of the techniques you''d use to improve your model?'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 想象一下，你想构建一个从图像中检测皮肤病变的模型。在你的训练数据集中，只有1%的图像显示出病变的迹象。训练后，你的模型似乎产生了比假阳性更多的假阴性。你将使用哪些技术来改进你的模型？'
- en: Training data leakage.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练数据泄露。
- en: '[M] Imagine you''re working with a binary task where the positive class accounts
    for only 1% of your data. You decide to oversample the rare class then split your
    data into train and test splits. Your model performs well on the test split but
    poorly in production. What might have happened?'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 想象一下，你正在处理一个二元任务，其中正类只占你数据的1%。你决定对稀有类别进行过采样，然后将数据分成训练集和测试集。你的模型在测试集上表现良好，但在生产环境中表现不佳。可能发生了什么？'
- en: '[M] You want to build a model to classify whether a comment is spam or not
    spam. You have a dataset of a million comments over the period of 7 days. You
    decide to randomly split all your data into the train and test splits. Your co-worker
    points out that this can lead to data leakage. How?'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 你想构建一个模型来分类评论是否为垃圾邮件。在7天的时间里，你有一个包含一百万条评论的数据集。你决定将所有数据随机分成训练集和测试集。你的同事指出，这可能导致数据泄露。为什么会这样？'
- en: '**Hint**: You might want to clarify what oversampling here means. Oversampling
    can be as simple as dupplicating samples from the rare class.'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：你可能需要澄清这里的过采样是什么意思。过采样可能只是简单地复制稀有类别的样本。'
- en: '[M] How does data sparsity affect your models?'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 数据稀疏性如何影响你的模型？'
- en: '**Hint**: Sparse data is different from missing data.'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：稀疏数据与缺失数据不同。'
- en: Feature leakage
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征泄露
- en: '[E] What are some causes of feature leakage?'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E] 特征泄露的某些原因是什么？'
- en: '[E] Why does normalization help prevent feature leakage?'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E] 正则化如何帮助防止特征泄露？'
- en: '[M] How do you detect feature leakage?'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 你如何检测特征泄露？'
- en: '[M] Suppose you want to build a model to classify whether a tweet spreads misinformation.
    You have 100K labeled tweets over the last 24 months. You decide to randomly shuffle
    on your data and pick 80% to be the train split, 10% to be the valid split, and
    10% to be the test split. What might be the problem with this way of partitioning?'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 假设你想构建一个模型来分类推文是否传播了错误信息。在过去24个月内，你有10万个标记的推文。你决定随机打乱你的数据，并选择80%作为训练集，10%作为验证集，10%作为测试集。这种划分方式可能存在什么问题？'
- en: '[M] You’re building a neural network and you want to use both numerical and
    textual features. How would you process those different features?'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[M] 你正在构建一个神经网络，并且希望使用数值和文本特征。你将如何处理这些不同的特征？'
- en: '[H] Your model has been performing fairly well using just a subset of features
    available in your data. Your boss decided that you should use all the features
    available instead. What might happen to the training error? What might happen
    to the test error?'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[H] 你的模型仅使用你数据中可用特征的一个子集表现相当好。你的老板决定你应该使用所有可用的特征。训练错误可能会发生什么？测试错误可能会发生什么？'
- en: '**Hint**: Think about the curse of dimensionality: as we use more dimensions
    to describe our data, the more sparse space becomes, and the further are data
    points from each other.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：考虑维度诅咒：当我们使用更多维度来描述我们的数据时，空间变得更加稀疏，数据点彼此之间的距离也越远。'
- en: '* * *'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '*This book was created by [Chip Huyen](https://huyenchip.com) with the help
    of wonderful friends. For feedback, errata, and suggestions, the author can be
    reached [here](https://huyenchip.com/communication/). Copyright ©2021 Chip Huyen.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*本书由[Chip Huyen](https://huyenchip.com)在众多朋友的帮助下创作。对于反馈、勘误和建议，作者可以通过[这里](https://huyenchip.com/communication/)联系。版权©2021
    Chip Huyen.*'
