["```py\nimport geostatspy.GSLIB as GSLIB                              # GSLIB utilities, visualization and wrapper\nimport geostatspy.geostats as geostats                        # GSLIB methods convert to Python \nimport geostatspy\nprint('GeostatsPy version: ' + str(geostatspy.__version__)) \n```", "```py\nGeostatsPy version: 0.0.71 \n```", "```py\nignore_warnings = True                                        # ignore warnings?\nimport numpy as np                                            # ndarrays for gridded data\nimport pandas as pd                                           # DataFrames for tabular data\nimport os                                                     # set working directory, run executables\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.lines import Line2D                           # custom legend\nfrom matplotlib.patches import Patch                          # add shapes to plots \nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nimport matplotlib.patheffects as pe                           # advanced plotting of lines / curves\nfrom scipy import stats                                       # summary statistics\nfrom scipy.stats import norm                                  # Gaussian parametric distribution\nimport math                                                   # trigonometry etc.\nimport scipy.signal as signal                                 # kernel for moving window calculation\nimport random                                                 # for random numbers\nimport seaborn as sns                                         # for matrix scatter plots\nfrom scipy import linalg                                      # for linear regression\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Normalizer                  # L1/L2 normalizer\nfrom sklearn.preprocessing import StandardScaler              # standardization\nfrom sklearn.preprocessing import Binarizer                   # indicator transform\nfrom sklearn.preprocessing import KBinsDiscretizer            # k-bins discretization\nfrom sklearn.preprocessing import QuantileTransformer         # quantile\nfrom sklearn.preprocessing import FunctionTransformer         # custom transformations\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map \n```", "```py\ndef weighted_percentile(data, weights, perc):                 # calculate weighted percentile \n    ix = np.argsort(data)\n    data = data[ix] \n    weights = weights[ix] \n    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) \n    return np.interp(perc, cdf, data)\n# function from iambr on StackOverflow @ https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049 \n\ndef histogram_bounds(values,weights,color):                   # add uncertainty bounds to a histogram \n    p10 = weighted_percentile(values,weights,0.1); avg = np.average(values,weights=weights); p90 = weighted_percentile(values,weights,0.9)\n    plt.plot([p10,p10],[0.0,45],color = color,linestyle='dashed')\n    plt.plot([avg,avg],[0.0,45],color = color)\n    plt.plot([p90,p90],[0.0,45],color = color,linestyle='dashed')\n\ndef add_grid():                                               # add major and minor gridlines\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"c:/PGE383\")                                        # set the working directory \n```", "```py\n#df = pd.read_csv('unconv_MV_v4.csv')                         # load our data table\ndf = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \ndf = df.iloc[:,1:]                                            # remove the well index\n\nresponse = 'Prod'                                             # specify the response feature\nx = df.copy(deep = True); x = x.drop([response],axis='columns') # make predictor and response DataFrames\nY = df.loc[:,response]\n\nfeatures = x.columns.values.tolist() + [Y.name]               # store the names of the features\npred = x.columns.values.tolist()\nresp = Y.name\n\nxmin = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minumum and maximum values for plotting\nYmin = 500.0; Ymax = 9000.0\n\npredlabel = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\nresplabel = 'Initial Production (MCFPD)'\n\npredtitle = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\nresptitle = 'Initial Production'\n\nfeaturelabel = predlabel + [resplabel]                        # make feature labels and titles for concise code\nfeaturetitle = predtitle + [resptitle]\n\nm = len(pred) + 1\nmpred = len(pred) \n```", "```py\ndf.head(n=13)                                                 # we could also use this command for a table preview \n```", "```py\ndf.describe().transpose() \n```", "```py\nnbins = 20                                                    # number of histogram bins\nfor i, feature in enumerate(features):                        # plot histograms with central tendency and P10 and P90 labeled\n    plt.subplot(3,3,i+1)\n    y,_,_ = plt.hist(x=df[feature],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\n    histogram_bounds(values=df[feature].values,weights=np.ones(len(df)),color='red')\n    plt.xlabel(feature); plt.ylabel('Frequency'); plt.ylim([0.0,y.max()*1.10]); plt.title(featuretitle[i]); add_grid() \n    if feature == resp:   \n        plt.xlim([Ymin,Ymax])    \n    else:\n        plt.xlim([xmin[i],xmax[i]]) \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2., top=2.1, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nnum = df._get_numeric_data() \nnum[num < data_min] = data_min\nnum[num > data_max] = data_max \n```", "```py\nplt.subplot(121)\nplt.hist(df['TOC'].values,color='darkorange',alpha=0.8,edgecolor='black',bins=np.linspace(-0.2,1.0,25))\nplt.xlabel('TOC (fraction)'); plt.ylabel('Frequency'); plt.title('Original Histogram'); plt.ylim([0,14]); plt.xlim([-0.2,1.0])\nplt.gca().grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\nplt.gca().grid(which='major', color='#DDDDDD', linewidth=0.8); plt.gca().minorticks_on()\n\nold_TOC = df['TOC'].values.copy()\nnum = df._get_numeric_data()                                  # get the numerical values\nnum[num < 0] = 0                                              # truncate negative values to 0.0\ndf.describe().transpose()                                     # get the summary statistics of all features\n\nplt.subplot(122)\nplt.hist(df['TOC'].values,color='red',alpha=0.8,edgecolor='black',bins=np.linspace(-0.2,1.0,25),zorder=10)\nplt.hist(old_TOC,color='darkorange',alpha=0.8,edgecolor='black',bins=np.linspace(-0.2,1.0,25),zorder=20)\nplt.xlabel('TOC (fraction)'); plt.ylabel('Frequency'); plt.title('Truncated (>0.0) Histogram'); plt.ylim([0,14]); plt.xlim([-0.2,1.0])\nplt.fill_between([-0.2,0.0],[14,14],[0,0],color='grey',alpha=1.0,zorder=30); plt.plot([0.0,0.0],[0,14],color='black',ls='--',zorder=30)\nplt.gca().grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\nplt.gca().grid(which='major', color='#DDDDDD', linewidth=0.8); plt.gca().minorticks_on()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndf.describe().transpose() \n```", "```py\ndf['aPor'] = GSLIB.affine(df['Por'].values,tmean = 22.0,tstdev = 1.5) # affine correction\n\nplt.subplot(121)\nplt.hist(df['Por'].values,color='yellow',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,30.0,30),label='Original')\nplt.hist(df['aPor'].values,color='red',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,30.0,30),label='Transformed')\nplt.hist(df['aPor'].values,fill=False,alpha=1.0,edgecolor='black',lw=2.0,bins=np.linspace(0.0,30.0,30))\nplt.legend(loc='upper left'); plt.grid(True)\nplt.xlabel('Porosity (%)'); plt.ylabel('Frequency'); plt.title('Original and Affine Transformed Histograms'); plt.ylim([0,60]); plt.xlim([0.0,30.0])\nadd_grid()\n\nplt.subplot(122)\nplt.plot(np.sort(df['Por']),np.linspace(0,1,len(df)),color='yellow',alpha=0.8,lw=3,zorder=10,label='Original', path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.plot(np.sort(df['aPor']),np.linspace(0,1,len(df)),color='red',alpha=0.8,lw=3,zorder=10,label='Transformed', path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.xlim([0,30]); plt.ylim(0,1); plt.xlabel('Porosity (%)'); plt.ylabel('Cumulative Probability'); \nplt.title('Original and Affine Transformed CDFs'); plt.legend(loc='upper left'); plt.grid(True)\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndf['aPor'].describe().transpose() \n```", "```py\ncount    200.000000\nmean      22.000000\nstd        1.503764\nmin       17.727787\n25%       20.947959\n50%       22.039907\n75%       23.220426\nmax       26.331783\nName: aPor, dtype: float64 \n```", "```py\ndf = df.drop(columns = ['aPor']) \n```", "```py\nscaler = StandardScaler() \n```", "```py\nsfeatures = scaler.fit_transform(df_mv.values) \n```", "```py\ndf_nmv = pd.DataFrame() \n```", "```py\ndf_nmv = pd.DataFrame(sfeatures, index=df_mv.index, columns=df_mv.columns) \n```", "```py\nscaler = StandardScaler()                                     # instantiate the scaler \nsfeatures = scaler.fit_transform(df.values)                   # standardize all the values extracted from the DataFrame \ndf_st = pd.DataFrame()                                        # instantiate a new DataFrame\ndf_st = pd.DataFrame(sfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\n\nplt.subplot(121)\nplt.hist(df['Por'].values,color='yellow',alpha=0.4,edgecolor='black',bins=np.linspace(-5.0,30.0,36),label='Original')\nplt.hist(df_st['Por'].values,color='red',alpha=0.4,edgecolor='black',bins=np.linspace(-5.0,30.0,36),label='Standardized')\nplt.hist(df_st['Por'].values,fill=False,alpha=1.0,edgecolor='black',lw=2.0,bins=np.linspace(-5.0,30.0,36))\nplt.legend(loc='upper left')\nplt.xlabel('Porosity (%)'); plt.ylabel('Frequency'); plt.title('Original and Standardized Histograms'); plt.ylim([0,80]); plt.xlim([-5.0,25.0])\nadd_grid()\n\nplt.subplot(122)\nplt.plot(np.sort(df['Por']),np.linspace(0,1,len(df)),color='yellow',alpha=0.8,lw=3,zorder=10,label='Original',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.plot(np.sort(df_st['Por']),np.linspace(0,1,len(df)),color='red',alpha=0.8,lw=3,zorder=10,label='Standardized',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.xlim([-5,25]); plt.ylim(0,1); plt.xlabel('Porosity (%)'); plt.ylabel('Cumulative Probability'); \nplt.title('Original and Standardized CDFs'); plt.legend(loc='lower right'); plt.grid(True)\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nrfeatures = scaler.inverse_transform(df_st.values) \n```", "```py\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) \n```", "```py\nrfeatures = scaler.inverse_transform(df_st.values)\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_reverse.head() \n\nplt.subplot(131)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(132)\nGSLIB.hist_st(df_st['Por'].values,-3,3,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Standardized',title='Standardized Porosity')\nadd_grid()\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Reverse Standardization (%)',\n              title='Porosity Reverse Standardization')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\ndel df_reverse \n```", "```py\ndel df_reverse \n```", "```py\nmin_max_scaler = preprocessing.MinMaxScaler()\nscaled_array = min_max_scaler.fit_transform(float_array) \n```", "```py\nnorm_scaler = preprocessing.MinMaxScaler()                 # instantiate the scaler \nnfeatures = norm_scaler.fit_transform(df.values)           # standardize all the values extracted from the DataFrame \ndf_n = pd.DataFrame(nfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_n.head() \n\nplt.subplot(121)\nplt.hist(df['Por'].values,color='yellow',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,25.0,26),label='Original')\nplt.hist(df_n['Por'].values,color='red',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,25.0,26),label='Standardized')\nplt.hist(df_n['Por'].values,fill=False,alpha=1.0,edgecolor='black',lw=2.0,bins=np.linspace(0.0,25.0,26))\nplt.legend(loc='upper left')\nplt.xlabel('Porosity (%)'); plt.ylabel('Frequency'); plt.title('Original and Standardized Histograms'); plt.ylim([0,80]); plt.xlim([0.0,25.0])\nadd_grid()\n\nplt.subplot(122)\nplt.plot(np.sort(df['Por']),np.linspace(0,1,len(df)),color='yellow',alpha=0.8,lw=3,zorder=10,label='Original',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.plot(np.sort(df_n['Por']),np.linspace(0,1,len(df)),color='red',alpha=0.8,lw=3,zorder=10,label='Standardized',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.xlim([0,25]); plt.ylim(0,1); plt.xlabel('Porosity (%)'); plt.ylabel('Cumulative Probability'); \nplt.title('Original and Standardized CDFs'); plt.legend(loc='lower right'); plt.grid(True)\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndf_n.describe().transpose() \n```", "```py\nrfeatures = norm_scaler.inverse_transform(df_n.values)\ndf_reverse = pd.DataFrame()                                     # instantiate a new DataFrame\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_reverse.head() \n\nplt.subplot(131)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2)\n\nplt.subplot(132)\nGSLIB.hist_st(df_n['Por'].values,0,1,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Normalized',title='Normalization Porosity')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2)\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Reverse Normalization (%)',\n              title='Porosity Reverse Normalization')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndel df_reverse \n```", "```py\nl2normalizer = Normalizer(norm = 'l2') \nl2features = l2normalizer.fit_transform(df_n) \n\ncolors =  ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2','#7f7f7f', '#bcbd22', '#17becf']\nnames = ['Porosity','Permeability','Acoustic Impedance','Brittleness','Total Organic Carbon','Vitrinite Reflectance','Production']\n\nplt.subplot(121)\nn_cumul_sum =np.cumsum(np.power(df_n.values,2),axis=1)\nfor i in range(0,l2features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l2features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],n_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,5])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative Square'); plt.title('Original')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\nadd_grid()\n\nplt.subplot(122)\nl2_cumul_sum =np.cumsum(np.power(l2features,2),axis=1)\nfor i in range(0,l2features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),l2_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),l2_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l2features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),l2_cumul_sum[:,i],l2_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,1])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative Square'); plt.title('L2 Normalized')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nl1normalizer = Normalizer(norm = 'l1') \nl1features = l1normalizer.fit_transform(df_n)                # standardize all the values extracted from the DataFrame \ndf_nL1 = pd.DataFrame()                                      # instantiate a new DataFrame\ndf_nL1 = pd.DataFrame(l1features, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_nL1.head() \n\ncolors =  ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2','#7f7f7f', '#bcbd22', '#17becf']\nnames = ['Porosity','Permeability','Acoustic Impedance','Brittleness','Total Organic Carbon','Vitrinite Reflectance','Production']\n\nplt.subplot(121)\nn_cumul_sum =np.cumsum(df_n.values,axis=1)\nfor i in range(0,l1features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l1features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],n_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,5])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative'); plt.title('Original')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\n\nplt.subplot(122)\nl1_cumul_sum =np.cumsum(l1features,axis=1)\nfor i in range(0,l1features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),l1_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),l1_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l1features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),l1_cumul_sum[:,i],l1_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,1])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative'); plt.title('L1 Normalized')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nthreshold = 13.0\nbinarizer = Binarizer(threshold = threshold) \nbPor = binarizer.fit_transform(df['Por'].values.reshape(-1, 1)) # standardize all the values extracted from the DataFrame \n\nplt.subplot(121)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(bPor,0,1,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Indicator Transform',\n              title='Porosity Indicator Transform, Threshold = ' + str(threshold))\nadd_grid()\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nnbins = 5\nkbins = KBinsDiscretizer(n_bins=nbins, strategy='uniform',encode='onehot') \nkbins_por = kbins.fit_transform(df['Por'].values.reshape(-1, 1)) # standardize all the values extracted from the DataFrame \nkbins_values = np.concatenate((df['Por'].values.reshape(-1, 1),kbins_por.toarray()),axis=1)\nkbins_values \n```", "```py\narray([[12.08,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ,  0\\.  ],\n       [12.38,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ,  0\\.  ],\n       [14.02,  0\\.  ,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ],\n       ...,\n       [12.12,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ,  0\\.  ],\n       [15.55,  0\\.  ,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ],\n       [20.89,  0\\.  ,  0\\.  ,  0\\.  ,  0\\.  ,  1\\.  ]]) \n```", "```py\nkbins_edges = kbins.bin_edges_[0]\nkbins_centers = (kbins_edges[1:] + kbins_edges[:-1]) / 2\nbsiz = (np.max(kbins_edges) - np.min(kbins_edges))/nbins\nfig = plt.figure(figsize=(6, 6))\ngs = fig.add_gridspec(2,2 ,width_ratios=(1.0, 1.0))\n\nplt_scatter = fig.add_subplot(gs[0, 1])\nplt_x = fig.add_subplot(gs[0, 0],sharey=plt_scatter) \nplt_y = fig.add_subplot(gs[1, 1],sharex=plt_scatter) \n\nfor i in range(0,len(df)):\n    ones = kbins_centers[kbins_values[i][1:] == 1.0]\n    plt_scatter.scatter(ones,np.full(len(ones),kbins_values[i][0]),marker = 'o',s=10,color='red')\n    zeros = kbins_centers[kbins_values[i][1:] == 0.0]\n    plt_scatter.scatter(zeros,np.full(len(zeros),kbins_values[i][0]),color='black',s=5,marker='x',lw=0.4)\n    #print(zeros,np.full(len(zeros),kbins_values[i][0]))\n\nfor edge in kbins_edges:\n    plt_scatter.plot([edge,edge],[0,30],color='black',lw=1,ls='--',alpha=0.5)\n    #plt.plot([5,25],[edge,edge],color='black',lw=1,ls='--',alpha=0.5)\n\nfor icenter,center in enumerate(kbins_centers):\n    plt_scatter.annotate('Bin ' + str(icenter),[center-bsiz*0.1,5.2])\n\nplt_scatter.set_ylabel(r'Original Feature, $X$'); plt_scatter.set_xlabel(r'Transformed Features, $X^{\\prime}$')\nplt_scatter.set_xlim([5,25]); plt_scatter.set_ylim([5,25])\n\nplt_scatter.scatter(-9999.9,99999,marker = 'o',s=10,color='red',label='1')\nplt_scatter.scatter(-9999.9,99999,color='black',s=5,marker='x',lw=0.4,label='0')\nplt_scatter.set_xticks(kbins_edges)\nplt_scatter.legend(loc='upper left')\nplt_scatter.set_title('K Bins Discretization, One Hot Encoding of Continuous Feature')\n\nplt_x.hist(df['Por'].values,orientation='horizontal',density = False,weights = np.ones(len(df))/len(df),\n           color='red',alpha=0.8,edgecolor='black',bins=np.linspace(5.0,25.0,30))\n\nplt_x.set_xlim([0.13,0.0])\nplt_x.set_ylabel(r'Original Feature, $X$'); plt_x.set_xlabel(r'Probability') \nplt_x.set_title('Original Feature')\n\nz_values = np.zeros(int(np.sum(kbins_values[:,1:])))\ncount = np.sum(kbins_values[:,1:],axis=0)\nii = 0\nfor i in range(0,kbins_values[:,1:].shape[1]):\n    for j in range(0,int(count[i])):\n        z_values[ii] = kbins_centers[i]  \n        ii = ii + 1\n\nplt_y.hist(z_values,orientation='vertical',density = False,weights = np.ones(len(df))/len(df),\n           color='red',alpha=0.8,edgecolor='black',bins=np.linspace(5.0,25.0,30),zorder=10)\nplt_y.hist(df['Por'].values,orientation='vertical',density = False,weights = np.ones(len(df))/len(df),\n           color='red',alpha=0.2,edgecolor='black',bins=np.linspace(5.0,25.0,30),zorder=5)\n\nfor edge in kbins_edges:\n    plt_y.plot([edge,edge],[0,0.6],color='black',lw=1,ls='--',alpha=0.5)\n\nfor icenter,center in enumerate(kbins_centers):\n    plt_y.annotate('Bin ' + str(icenter),[center-bsiz*0.21,0.58])\n    plt_y.plot([center,center],[0,0.6],color='grey',lw=1,alpha=0.5,zorder=1)\n    plt_y.annotate(str(np.round(center,1)),[center+bsiz*0.01,0.5],rotation=270.0,color='grey')\n\nplt_y.set_ylim([0.0,0.6])\nplt_y.set_xlabel(r'Transformed Features, $X^{\\prime}$'); plt_y.set_ylabel(r'Probability') \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.6, top=1.6, wspace=0.2, hspace=0.2) \n```", "```py\npor = df['Por'].copy(deep = True).values                 # make a deepcopy of the feature from the DataFrame\n\npor = np.sort(por)                                            # sort the data in ascending order\nn = por.shape[0]                                              # get the number of data samples\n\ncprob = np.zeros(n)\nfor i in range(0,n):\n    index = i + 1\n    cprob[i] = index / n                                      # known upper tail\n    # cprob[i] = (index - 1)/n                                # known lower tail\n    # cprob[i] = (index - 1)/(n - 1)                          # known upper and lower tails\n    # cprob[i] = index/(n+1)                                  # unknown tails \n\ny = np.zeros(n)\n\nfor i in range(0,n):\n    y[i] = norm.ppf(cprob[i],loc=0.0,scale=1.0)\n\nplt.subplot(121)\nplt.plot(por,cprob, alpha = 0.2, c = 'black') # plot piecewise linear interpolation\nplt.scatter(por,cprob,s = 10, alpha = 1.0, c = 'red', edgecolor = 'black') # plot the CDF points\nplt.grid(); plt.xlim([5,25]); plt.ylim([0.0,1.0])\nplt.xlabel(\"Porosity (fraction)\"); plt.ylabel(\"Cumulative Probability\"); plt.title(\"Non-parametric Porosity Cumulative Distribution Function\")\n\nplt.subplot(122)\nplt.plot(y,cprob, alpha = 0.2, c = 'black') # plot piecewise linear interpolation\nplt.scatter(y,cprob,s = 10, alpha = 1.0, c = 'red', edgecolor = 'black') # plot the CDF points\nplt.grid(); plt.xlim([-3.0,3.0]); plt.ylim([0.0,1.0])\nplt.xlabel(\"Porosity (fraction)\"); plt.ylabel(\"Cumulative Probability\"); plt.title(\"After Distribution Transformation to Gaussian\")\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nfrom sklearn.preprocessing import QuantileTransformer\nnscore = QuantileTransformer(n_quantiles=100, random_state=73, output_distribution = 'normal') \nnsfeatures = nscore.fit_transform(df)                       # standardize all the values extracted from the DataFrame \ndf_ns = pd.DataFrame()                                      # instantiate a new DataFrame\ndf_ns = pd.DataFrame(nsfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_ns.head() \n\nplt.subplot(121)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(df_ns['Por'].values,-3,3,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Normal Score',title='Standard Normal Porosity')\nadd_grid()\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nnbins = 30                                                    # number of histogram bins\nfor i, feature in enumerate(features):                        # plot histograms with central tendency and P10 and P90 labeled\n    plt.subplot(3,3,i+1)\n    y,_,_ = plt.hist(x=df_ns[feature],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\n    histogram_bounds(values=df_ns[feature].values,weights=np.ones(len(df)),color='red')\n    plt.xlabel(feature); plt.ylabel('Frequency'); plt.ylim([0.0,y.max()*1.10]); plt.title(featuretitle[i]); add_grid() \n    plt.xlim([-3.0,3.0]) \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2., top=2.1, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nrfeatures = nscore.inverse_transform(df_ns.values)\ndf_reverse = pd.DataFrame()                                     # instantiate a new DataFrame\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\n\nplt.subplot(131)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(132)\nGSLIB.hist_st(df_ns['Por'].values,-3,3,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Normal Score',title='Standard Normal Porosity')\nadd_grid()\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Reverse Normal Score (%)',\n              title='Porosity Reverse Gaussian Transform')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nuniform = QuantileTransformer(n_quantiles=100, random_state=73, output_distribution = 'uniform') \nunifeatures = uniform.fit_transform(df)                      # standardize all the values extracted from the DataFrame \ndf_uni = pd.DataFrame()                                      # instantiate a new DataFrame\ndf_uni = pd.DataFrame(unifeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\n\nplt.subplot(121)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(df_uni['Por'].values,0,1,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Uniform Transform',\n              title='Uniform Transform Porosity')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nnbins = 30                                                    # number of histogram bins\nfor i, feature in enumerate(features):                        # plot histograms with central tendency and P10 and P90 labeled\n    plt.subplot(3,3,i+1)\n    y,_,_ = plt.hist(x=df_uni[feature],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\n    histogram_bounds(values=df_uni[feature].values,weights=np.ones(len(df)),color='red')\n    plt.xlabel(feature); plt.ylabel('Frequency'); plt.ylim([0.0,y.max()*1.10]); plt.title(featuretitle[i]); add_grid() \n    plt.xlim([0.0,1.0]) \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2., top=2.1, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\ncustom_transformer = FunctionTransformer(func = np.log, inverse_func = np.exp) \n```", "```py\ncustom_transformer = FunctionTransformer(func = np.log, inverse_func = np.exp, check_inverse = True, validate=True)\ncustom_features = custom_transformer.fit_transform(df['Perm'].values.reshape(-1, 1)) # standardize all the values extracted from the DataFrame \ndf_custom = pd.DataFrame(custom_features, columns = ['LogPerm'])                 # instantiate a new DataFrame\ndf_custom.head() \n\nplt.subplot(121)\nGSLIB.hist_st(df['Perm'].values,0,15,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability (mD)',title='Original Permeability')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(df_custom['LogPerm'].values,0,3,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability Log Transform',\n              title='Custom Transform - Log Transformed Permeability')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nrfeatures = custom_transformer.inverse_transform(df_custom.values)\ndf_reverse = pd.DataFrame(rfeatures, index=df_custom.index, columns=['Perm']) # copy the standardized values into the new DataFrame\n\nplt.subplot(131)\nGSLIB.hist_st(df['Perm'].values,0,15,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability (mD)',title='Original Permeability')\nadd_grid()\n\nplt.subplot(132)\nGSLIB.hist_st(df_custom['LogPerm'].values,0,3,log=False,cumul = False,bins=40,weights = None,xlabel='Pemeability Log Transform',\n              title='Custom Transform - Log Transformed Permeability')\nadd_grid()\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Perm'].values,0,15,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability (mD)',title='Original Permeability')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nimport geostatspy.GSLIB as GSLIB                              # GSLIB utilities, visualization and wrapper\nimport geostatspy.geostats as geostats                        # GSLIB methods convert to Python \nimport geostatspy\nprint('GeostatsPy version: ' + str(geostatspy.__version__)) \n```", "```py\nGeostatsPy version: 0.0.71 \n```", "```py\nignore_warnings = True                                        # ignore warnings?\nimport numpy as np                                            # ndarrays for gridded data\nimport pandas as pd                                           # DataFrames for tabular data\nimport os                                                     # set working directory, run executables\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.lines import Line2D                           # custom legend\nfrom matplotlib.patches import Patch                          # add shapes to plots \nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nimport matplotlib.patheffects as pe                           # advanced plotting of lines / curves\nfrom scipy import stats                                       # summary statistics\nfrom scipy.stats import norm                                  # Gaussian parametric distribution\nimport math                                                   # trigonometry etc.\nimport scipy.signal as signal                                 # kernel for moving window calculation\nimport random                                                 # for random numbers\nimport seaborn as sns                                         # for matrix scatter plots\nfrom scipy import linalg                                      # for linear regression\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Normalizer                  # L1/L2 normalizer\nfrom sklearn.preprocessing import StandardScaler              # standardization\nfrom sklearn.preprocessing import Binarizer                   # indicator transform\nfrom sklearn.preprocessing import KBinsDiscretizer            # k-bins discretization\nfrom sklearn.preprocessing import QuantileTransformer         # quantile\nfrom sklearn.preprocessing import FunctionTransformer         # custom transformations\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map \n```", "```py\ndef weighted_percentile(data, weights, perc):                 # calculate weighted percentile \n    ix = np.argsort(data)\n    data = data[ix] \n    weights = weights[ix] \n    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) \n    return np.interp(perc, cdf, data)\n# function from iambr on StackOverflow @ https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049 \n\ndef histogram_bounds(values,weights,color):                   # add uncertainty bounds to a histogram \n    p10 = weighted_percentile(values,weights,0.1); avg = np.average(values,weights=weights); p90 = weighted_percentile(values,weights,0.9)\n    plt.plot([p10,p10],[0.0,45],color = color,linestyle='dashed')\n    plt.plot([avg,avg],[0.0,45],color = color)\n    plt.plot([p90,p90],[0.0,45],color = color,linestyle='dashed')\n\ndef add_grid():                                               # add major and minor gridlines\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"c:/PGE383\")                                        # set the working directory \n```", "```py\n#df = pd.read_csv('unconv_MV_v4.csv')                         # load our data table\ndf = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \ndf = df.iloc[:,1:]                                            # remove the well index\n\nresponse = 'Prod'                                             # specify the response feature\nx = df.copy(deep = True); x = x.drop([response],axis='columns') # make predictor and response DataFrames\nY = df.loc[:,response]\n\nfeatures = x.columns.values.tolist() + [Y.name]               # store the names of the features\npred = x.columns.values.tolist()\nresp = Y.name\n\nxmin = [6.0,0.0,1.0,10.0,0.0,0.9]; xmax = [24.0,10.0,5.0,85.0,2.2,2.9] # set the minumum and maximum values for plotting\nYmin = 500.0; Ymax = 9000.0\n\npredlabel = ['Porosity (%)','Permeability (mD)','Acoustic Impedance (kg/m2s*10^6)','Brittleness Ratio (%)', # set the names for plotting\n             'Total Organic Carbon (%)','Vitrinite Reflectance (%)']\nresplabel = 'Initial Production (MCFPD)'\n\npredtitle = ['Porosity','Permeability','Acoustic Impedance','Brittleness Ratio', # set the units for plotting\n             'Total Organic Carbon','Vitrinite Reflectance']\nresptitle = 'Initial Production'\n\nfeaturelabel = predlabel + [resplabel]                        # make feature labels and titles for concise code\nfeaturetitle = predtitle + [resptitle]\n\nm = len(pred) + 1\nmpred = len(pred) \n```", "```py\ndf.head(n=13)                                                 # we could also use this command for a table preview \n```", "```py\ndf.describe().transpose() \n```", "```py\nnbins = 20                                                    # number of histogram bins\nfor i, feature in enumerate(features):                        # plot histograms with central tendency and P10 and P90 labeled\n    plt.subplot(3,3,i+1)\n    y,_,_ = plt.hist(x=df[feature],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\n    histogram_bounds(values=df[feature].values,weights=np.ones(len(df)),color='red')\n    plt.xlabel(feature); plt.ylabel('Frequency'); plt.ylim([0.0,y.max()*1.10]); plt.title(featuretitle[i]); add_grid() \n    if feature == resp:   \n        plt.xlim([Ymin,Ymax])    \n    else:\n        plt.xlim([xmin[i],xmax[i]]) \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2., top=2.1, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nnum = df._get_numeric_data() \nnum[num < data_min] = data_min\nnum[num > data_max] = data_max \n```", "```py\nplt.subplot(121)\nplt.hist(df['TOC'].values,color='darkorange',alpha=0.8,edgecolor='black',bins=np.linspace(-0.2,1.0,25))\nplt.xlabel('TOC (fraction)'); plt.ylabel('Frequency'); plt.title('Original Histogram'); plt.ylim([0,14]); plt.xlim([-0.2,1.0])\nplt.gca().grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\nplt.gca().grid(which='major', color='#DDDDDD', linewidth=0.8); plt.gca().minorticks_on()\n\nold_TOC = df['TOC'].values.copy()\nnum = df._get_numeric_data()                                  # get the numerical values\nnum[num < 0] = 0                                              # truncate negative values to 0.0\ndf.describe().transpose()                                     # get the summary statistics of all features\n\nplt.subplot(122)\nplt.hist(df['TOC'].values,color='red',alpha=0.8,edgecolor='black',bins=np.linspace(-0.2,1.0,25),zorder=10)\nplt.hist(old_TOC,color='darkorange',alpha=0.8,edgecolor='black',bins=np.linspace(-0.2,1.0,25),zorder=20)\nplt.xlabel('TOC (fraction)'); plt.ylabel('Frequency'); plt.title('Truncated (>0.0) Histogram'); plt.ylim([0,14]); plt.xlim([-0.2,1.0])\nplt.fill_between([-0.2,0.0],[14,14],[0,0],color='grey',alpha=1.0,zorder=30); plt.plot([0.0,0.0],[0,14],color='black',ls='--',zorder=30)\nplt.gca().grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\nplt.gca().grid(which='major', color='#DDDDDD', linewidth=0.8); plt.gca().minorticks_on()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndf.describe().transpose() \n```", "```py\ndf['aPor'] = GSLIB.affine(df['Por'].values,tmean = 22.0,tstdev = 1.5) # affine correction\n\nplt.subplot(121)\nplt.hist(df['Por'].values,color='yellow',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,30.0,30),label='Original')\nplt.hist(df['aPor'].values,color='red',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,30.0,30),label='Transformed')\nplt.hist(df['aPor'].values,fill=False,alpha=1.0,edgecolor='black',lw=2.0,bins=np.linspace(0.0,30.0,30))\nplt.legend(loc='upper left'); plt.grid(True)\nplt.xlabel('Porosity (%)'); plt.ylabel('Frequency'); plt.title('Original and Affine Transformed Histograms'); plt.ylim([0,60]); plt.xlim([0.0,30.0])\nadd_grid()\n\nplt.subplot(122)\nplt.plot(np.sort(df['Por']),np.linspace(0,1,len(df)),color='yellow',alpha=0.8,lw=3,zorder=10,label='Original', path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.plot(np.sort(df['aPor']),np.linspace(0,1,len(df)),color='red',alpha=0.8,lw=3,zorder=10,label='Transformed', path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.xlim([0,30]); plt.ylim(0,1); plt.xlabel('Porosity (%)'); plt.ylabel('Cumulative Probability'); \nplt.title('Original and Affine Transformed CDFs'); plt.legend(loc='upper left'); plt.grid(True)\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndf['aPor'].describe().transpose() \n```", "```py\ncount    200.000000\nmean      22.000000\nstd        1.503764\nmin       17.727787\n25%       20.947959\n50%       22.039907\n75%       23.220426\nmax       26.331783\nName: aPor, dtype: float64 \n```", "```py\ndf = df.drop(columns = ['aPor']) \n```", "```py\nscaler = StandardScaler() \n```", "```py\nsfeatures = scaler.fit_transform(df_mv.values) \n```", "```py\ndf_nmv = pd.DataFrame() \n```", "```py\ndf_nmv = pd.DataFrame(sfeatures, index=df_mv.index, columns=df_mv.columns) \n```", "```py\nscaler = StandardScaler()                                     # instantiate the scaler \nsfeatures = scaler.fit_transform(df.values)                   # standardize all the values extracted from the DataFrame \ndf_st = pd.DataFrame()                                        # instantiate a new DataFrame\ndf_st = pd.DataFrame(sfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\n\nplt.subplot(121)\nplt.hist(df['Por'].values,color='yellow',alpha=0.4,edgecolor='black',bins=np.linspace(-5.0,30.0,36),label='Original')\nplt.hist(df_st['Por'].values,color='red',alpha=0.4,edgecolor='black',bins=np.linspace(-5.0,30.0,36),label='Standardized')\nplt.hist(df_st['Por'].values,fill=False,alpha=1.0,edgecolor='black',lw=2.0,bins=np.linspace(-5.0,30.0,36))\nplt.legend(loc='upper left')\nplt.xlabel('Porosity (%)'); plt.ylabel('Frequency'); plt.title('Original and Standardized Histograms'); plt.ylim([0,80]); plt.xlim([-5.0,25.0])\nadd_grid()\n\nplt.subplot(122)\nplt.plot(np.sort(df['Por']),np.linspace(0,1,len(df)),color='yellow',alpha=0.8,lw=3,zorder=10,label='Original',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.plot(np.sort(df_st['Por']),np.linspace(0,1,len(df)),color='red',alpha=0.8,lw=3,zorder=10,label='Standardized',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.xlim([-5,25]); plt.ylim(0,1); plt.xlabel('Porosity (%)'); plt.ylabel('Cumulative Probability'); \nplt.title('Original and Standardized CDFs'); plt.legend(loc='lower right'); plt.grid(True)\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nrfeatures = scaler.inverse_transform(df_st.values) \n```", "```py\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) \n```", "```py\nrfeatures = scaler.inverse_transform(df_st.values)\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_reverse.head() \n\nplt.subplot(131)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(132)\nGSLIB.hist_st(df_st['Por'].values,-3,3,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Standardized',title='Standardized Porosity')\nadd_grid()\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Reverse Standardization (%)',\n              title='Porosity Reverse Standardization')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\ndel df_reverse \n```", "```py\ndel df_reverse \n```", "```py\nmin_max_scaler = preprocessing.MinMaxScaler()\nscaled_array = min_max_scaler.fit_transform(float_array) \n```", "```py\nnorm_scaler = preprocessing.MinMaxScaler()                 # instantiate the scaler \nnfeatures = norm_scaler.fit_transform(df.values)           # standardize all the values extracted from the DataFrame \ndf_n = pd.DataFrame(nfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_n.head() \n\nplt.subplot(121)\nplt.hist(df['Por'].values,color='yellow',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,25.0,26),label='Original')\nplt.hist(df_n['Por'].values,color='red',alpha=0.4,edgecolor='black',bins=np.linspace(0.0,25.0,26),label='Standardized')\nplt.hist(df_n['Por'].values,fill=False,alpha=1.0,edgecolor='black',lw=2.0,bins=np.linspace(0.0,25.0,26))\nplt.legend(loc='upper left')\nplt.xlabel('Porosity (%)'); plt.ylabel('Frequency'); plt.title('Original and Standardized Histograms'); plt.ylim([0,80]); plt.xlim([0.0,25.0])\nadd_grid()\n\nplt.subplot(122)\nplt.plot(np.sort(df['Por']),np.linspace(0,1,len(df)),color='yellow',alpha=0.8,lw=3,zorder=10,label='Original',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.plot(np.sort(df_n['Por']),np.linspace(0,1,len(df)),color='red',alpha=0.8,lw=3,zorder=10,label='Standardized',\n         path_effects=[pe.Stroke(linewidth=7, foreground='black'), pe.Normal()])\nplt.xlim([0,25]); plt.ylim(0,1); plt.xlabel('Porosity (%)'); plt.ylabel('Cumulative Probability'); \nplt.title('Original and Standardized CDFs'); plt.legend(loc='lower right'); plt.grid(True)\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndf_n.describe().transpose() \n```", "```py\nrfeatures = norm_scaler.inverse_transform(df_n.values)\ndf_reverse = pd.DataFrame()                                     # instantiate a new DataFrame\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_reverse.head() \n\nplt.subplot(131)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2)\n\nplt.subplot(132)\nGSLIB.hist_st(df_n['Por'].values,0,1,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Normalized',title='Normalization Porosity')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2)\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Reverse Normalization (%)',\n              title='Porosity Reverse Normalization')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\ndel df_reverse \n```", "```py\nl2normalizer = Normalizer(norm = 'l2') \nl2features = l2normalizer.fit_transform(df_n) \n\ncolors =  ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2','#7f7f7f', '#bcbd22', '#17becf']\nnames = ['Porosity','Permeability','Acoustic Impedance','Brittleness','Total Organic Carbon','Vitrinite Reflectance','Production']\n\nplt.subplot(121)\nn_cumul_sum =np.cumsum(np.power(df_n.values,2),axis=1)\nfor i in range(0,l2features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l2features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],n_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,5])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative Square'); plt.title('Original')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\nadd_grid()\n\nplt.subplot(122)\nl2_cumul_sum =np.cumsum(np.power(l2features,2),axis=1)\nfor i in range(0,l2features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),l2_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),l2_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l2features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),l2_cumul_sum[:,i],l2_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,1])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative Square'); plt.title('L2 Normalized')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nl1normalizer = Normalizer(norm = 'l1') \nl1features = l1normalizer.fit_transform(df_n)                # standardize all the values extracted from the DataFrame \ndf_nL1 = pd.DataFrame()                                      # instantiate a new DataFrame\ndf_nL1 = pd.DataFrame(l1features, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_nL1.head() \n\ncolors =  ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2','#7f7f7f', '#bcbd22', '#17becf']\nnames = ['Porosity','Permeability','Acoustic Impedance','Brittleness','Total Organic Carbon','Vitrinite Reflectance','Production']\n\nplt.subplot(121)\nn_cumul_sum =np.cumsum(df_n.values,axis=1)\nfor i in range(0,l1features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l1features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),n_cumul_sum[:,i],n_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,5])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative'); plt.title('Original')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\n\nplt.subplot(122)\nl1_cumul_sum =np.cumsum(l1features,axis=1)\nfor i in range(0,l1features.shape[1]):\n    plt.plot(np.linspace(0,len(df)-1,len(df)),l1_cumul_sum[:,i])\n\nplt.fill_between(np.linspace(0,len(df)-1,len(df)),l1_cumul_sum[:,i],np.zeros(len(df)))\nfor i in range(1,l1features.shape[1]):\n    plt.fill_between(np.linspace(0,len(df)-1,len(df)),l1_cumul_sum[:,i],l1_cumul_sum[:,i-1])\n\nplt.xlim([0,len(df)-1]); plt.ylim([0,1])\nplt.xlabel('Sample (index)'); plt.ylabel('Features Cumulative'); plt.title('L1 Normalized')\n\nlegend_elements = []\nfor i in range(len(names)):\n    legend_elements.append(Patch(facecolor=colors[i], edgecolor='black',label=names[i]))\nplt.gca().legend(handles=legend_elements, loc='upper right')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nthreshold = 13.0\nbinarizer = Binarizer(threshold = threshold) \nbPor = binarizer.fit_transform(df['Por'].values.reshape(-1, 1)) # standardize all the values extracted from the DataFrame \n\nplt.subplot(121)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(bPor,0,1,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Indicator Transform',\n              title='Porosity Indicator Transform, Threshold = ' + str(threshold))\nadd_grid()\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nnbins = 5\nkbins = KBinsDiscretizer(n_bins=nbins, strategy='uniform',encode='onehot') \nkbins_por = kbins.fit_transform(df['Por'].values.reshape(-1, 1)) # standardize all the values extracted from the DataFrame \nkbins_values = np.concatenate((df['Por'].values.reshape(-1, 1),kbins_por.toarray()),axis=1)\nkbins_values \n```", "```py\narray([[12.08,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ,  0\\.  ],\n       [12.38,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ,  0\\.  ],\n       [14.02,  0\\.  ,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ],\n       ...,\n       [12.12,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ,  0\\.  ],\n       [15.55,  0\\.  ,  0\\.  ,  1\\.  ,  0\\.  ,  0\\.  ],\n       [20.89,  0\\.  ,  0\\.  ,  0\\.  ,  0\\.  ,  1\\.  ]]) \n```", "```py\nkbins_edges = kbins.bin_edges_[0]\nkbins_centers = (kbins_edges[1:] + kbins_edges[:-1]) / 2\nbsiz = (np.max(kbins_edges) - np.min(kbins_edges))/nbins\nfig = plt.figure(figsize=(6, 6))\ngs = fig.add_gridspec(2,2 ,width_ratios=(1.0, 1.0))\n\nplt_scatter = fig.add_subplot(gs[0, 1])\nplt_x = fig.add_subplot(gs[0, 0],sharey=plt_scatter) \nplt_y = fig.add_subplot(gs[1, 1],sharex=plt_scatter) \n\nfor i in range(0,len(df)):\n    ones = kbins_centers[kbins_values[i][1:] == 1.0]\n    plt_scatter.scatter(ones,np.full(len(ones),kbins_values[i][0]),marker = 'o',s=10,color='red')\n    zeros = kbins_centers[kbins_values[i][1:] == 0.0]\n    plt_scatter.scatter(zeros,np.full(len(zeros),kbins_values[i][0]),color='black',s=5,marker='x',lw=0.4)\n    #print(zeros,np.full(len(zeros),kbins_values[i][0]))\n\nfor edge in kbins_edges:\n    plt_scatter.plot([edge,edge],[0,30],color='black',lw=1,ls='--',alpha=0.5)\n    #plt.plot([5,25],[edge,edge],color='black',lw=1,ls='--',alpha=0.5)\n\nfor icenter,center in enumerate(kbins_centers):\n    plt_scatter.annotate('Bin ' + str(icenter),[center-bsiz*0.1,5.2])\n\nplt_scatter.set_ylabel(r'Original Feature, $X$'); plt_scatter.set_xlabel(r'Transformed Features, $X^{\\prime}$')\nplt_scatter.set_xlim([5,25]); plt_scatter.set_ylim([5,25])\n\nplt_scatter.scatter(-9999.9,99999,marker = 'o',s=10,color='red',label='1')\nplt_scatter.scatter(-9999.9,99999,color='black',s=5,marker='x',lw=0.4,label='0')\nplt_scatter.set_xticks(kbins_edges)\nplt_scatter.legend(loc='upper left')\nplt_scatter.set_title('K Bins Discretization, One Hot Encoding of Continuous Feature')\n\nplt_x.hist(df['Por'].values,orientation='horizontal',density = False,weights = np.ones(len(df))/len(df),\n           color='red',alpha=0.8,edgecolor='black',bins=np.linspace(5.0,25.0,30))\n\nplt_x.set_xlim([0.13,0.0])\nplt_x.set_ylabel(r'Original Feature, $X$'); plt_x.set_xlabel(r'Probability') \nplt_x.set_title('Original Feature')\n\nz_values = np.zeros(int(np.sum(kbins_values[:,1:])))\ncount = np.sum(kbins_values[:,1:],axis=0)\nii = 0\nfor i in range(0,kbins_values[:,1:].shape[1]):\n    for j in range(0,int(count[i])):\n        z_values[ii] = kbins_centers[i]  \n        ii = ii + 1\n\nplt_y.hist(z_values,orientation='vertical',density = False,weights = np.ones(len(df))/len(df),\n           color='red',alpha=0.8,edgecolor='black',bins=np.linspace(5.0,25.0,30),zorder=10)\nplt_y.hist(df['Por'].values,orientation='vertical',density = False,weights = np.ones(len(df))/len(df),\n           color='red',alpha=0.2,edgecolor='black',bins=np.linspace(5.0,25.0,30),zorder=5)\n\nfor edge in kbins_edges:\n    plt_y.plot([edge,edge],[0,0.6],color='black',lw=1,ls='--',alpha=0.5)\n\nfor icenter,center in enumerate(kbins_centers):\n    plt_y.annotate('Bin ' + str(icenter),[center-bsiz*0.21,0.58])\n    plt_y.plot([center,center],[0,0.6],color='grey',lw=1,alpha=0.5,zorder=1)\n    plt_y.annotate(str(np.round(center,1)),[center+bsiz*0.01,0.5],rotation=270.0,color='grey')\n\nplt_y.set_ylim([0.0,0.6])\nplt_y.set_xlabel(r'Transformed Features, $X^{\\prime}$'); plt_y.set_ylabel(r'Probability') \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.6, top=1.6, wspace=0.2, hspace=0.2) \n```", "```py\npor = df['Por'].copy(deep = True).values                 # make a deepcopy of the feature from the DataFrame\n\npor = np.sort(por)                                            # sort the data in ascending order\nn = por.shape[0]                                              # get the number of data samples\n\ncprob = np.zeros(n)\nfor i in range(0,n):\n    index = i + 1\n    cprob[i] = index / n                                      # known upper tail\n    # cprob[i] = (index - 1)/n                                # known lower tail\n    # cprob[i] = (index - 1)/(n - 1)                          # known upper and lower tails\n    # cprob[i] = index/(n+1)                                  # unknown tails \n\ny = np.zeros(n)\n\nfor i in range(0,n):\n    y[i] = norm.ppf(cprob[i],loc=0.0,scale=1.0)\n\nplt.subplot(121)\nplt.plot(por,cprob, alpha = 0.2, c = 'black') # plot piecewise linear interpolation\nplt.scatter(por,cprob,s = 10, alpha = 1.0, c = 'red', edgecolor = 'black') # plot the CDF points\nplt.grid(); plt.xlim([5,25]); plt.ylim([0.0,1.0])\nplt.xlabel(\"Porosity (fraction)\"); plt.ylabel(\"Cumulative Probability\"); plt.title(\"Non-parametric Porosity Cumulative Distribution Function\")\n\nplt.subplot(122)\nplt.plot(y,cprob, alpha = 0.2, c = 'black') # plot piecewise linear interpolation\nplt.scatter(y,cprob,s = 10, alpha = 1.0, c = 'red', edgecolor = 'black') # plot the CDF points\nplt.grid(); plt.xlim([-3.0,3.0]); plt.ylim([0.0,1.0])\nplt.xlabel(\"Porosity (fraction)\"); plt.ylabel(\"Cumulative Probability\"); plt.title(\"After Distribution Transformation to Gaussian\")\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nfrom sklearn.preprocessing import QuantileTransformer\nnscore = QuantileTransformer(n_quantiles=100, random_state=73, output_distribution = 'normal') \nnsfeatures = nscore.fit_transform(df)                       # standardize all the values extracted from the DataFrame \ndf_ns = pd.DataFrame()                                      # instantiate a new DataFrame\ndf_ns = pd.DataFrame(nsfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\ndf_ns.head() \n\nplt.subplot(121)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(df_ns['Por'].values,-3,3,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Normal Score',title='Standard Normal Porosity')\nadd_grid()\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nnbins = 30                                                    # number of histogram bins\nfor i, feature in enumerate(features):                        # plot histograms with central tendency and P10 and P90 labeled\n    plt.subplot(3,3,i+1)\n    y,_,_ = plt.hist(x=df_ns[feature],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\n    histogram_bounds(values=df_ns[feature].values,weights=np.ones(len(df)),color='red')\n    plt.xlabel(feature); plt.ylabel('Frequency'); plt.ylim([0.0,y.max()*1.10]); plt.title(featuretitle[i]); add_grid() \n    plt.xlim([-3.0,3.0]) \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2., top=2.1, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nrfeatures = nscore.inverse_transform(df_ns.values)\ndf_reverse = pd.DataFrame()                                     # instantiate a new DataFrame\ndf_reverse = pd.DataFrame(rfeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\n\nplt.subplot(131)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(132)\nGSLIB.hist_st(df_ns['Por'].values,-3,3,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Normal Score',title='Standard Normal Porosity')\nadd_grid()\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Reverse Normal Score (%)',\n              title='Porosity Reverse Gaussian Transform')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=3.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nuniform = QuantileTransformer(n_quantiles=100, random_state=73, output_distribution = 'uniform') \nunifeatures = uniform.fit_transform(df)                      # standardize all the values extracted from the DataFrame \ndf_uni = pd.DataFrame()                                      # instantiate a new DataFrame\ndf_uni = pd.DataFrame(unifeatures, index=df.index, columns=df.columns) # copy the standardized values into the new DataFrame\n\nplt.subplot(121)\nGSLIB.hist_st(df['Por'].values,0,30,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity (%)',title='Original Porosity')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(df_uni['Por'].values,0,1,log=False,cumul = False,bins=40,weights = None,xlabel='Porosity Uniform Transform',\n              title='Uniform Transform Porosity')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nnbins = 30                                                    # number of histogram bins\nfor i, feature in enumerate(features):                        # plot histograms with central tendency and P10 and P90 labeled\n    plt.subplot(3,3,i+1)\n    y,_,_ = plt.hist(x=df_uni[feature],weights=None,bins=nbins,alpha = 0.8,edgecolor='black',color='darkorange',density=True)\n    histogram_bounds(values=df_uni[feature].values,weights=np.ones(len(df)),color='red')\n    plt.xlabel(feature); plt.ylabel('Frequency'); plt.ylim([0.0,y.max()*1.10]); plt.title(featuretitle[i]); add_grid() \n    plt.xlim([0.0,1.0]) \n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2., top=2.1, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\ncustom_transformer = FunctionTransformer(func = np.log, inverse_func = np.exp) \n```", "```py\ncustom_transformer = FunctionTransformer(func = np.log, inverse_func = np.exp, check_inverse = True, validate=True)\ncustom_features = custom_transformer.fit_transform(df['Perm'].values.reshape(-1, 1)) # standardize all the values extracted from the DataFrame \ndf_custom = pd.DataFrame(custom_features, columns = ['LogPerm'])                 # instantiate a new DataFrame\ndf_custom.head() \n\nplt.subplot(121)\nGSLIB.hist_st(df['Perm'].values,0,15,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability (mD)',title='Original Permeability')\nadd_grid()\n\nplt.subplot(122)\nGSLIB.hist_st(df_custom['LogPerm'].values,0,3,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability Log Transform',\n              title='Custom Transform - Log Transformed Permeability')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2) \n```", "```py\nrfeatures = custom_transformer.inverse_transform(df_custom.values)\ndf_reverse = pd.DataFrame(rfeatures, index=df_custom.index, columns=['Perm']) # copy the standardized values into the new DataFrame\n\nplt.subplot(131)\nGSLIB.hist_st(df['Perm'].values,0,15,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability (mD)',title='Original Permeability')\nadd_grid()\n\nplt.subplot(132)\nGSLIB.hist_st(df_custom['LogPerm'].values,0,3,log=False,cumul = False,bins=40,weights = None,xlabel='Pemeability Log Transform',\n              title='Custom Transform - Log Transformed Permeability')\nadd_grid()\n\nplt.subplot(133)\nGSLIB.hist_st(df_reverse['Perm'].values,0,15,log=False,cumul = False,bins=40,weights = None,xlabel='Permeability (mD)',title='Original Permeability')\nadd_grid()\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.1, wspace=0.2, hspace=0.2); plt.show() \n```"]