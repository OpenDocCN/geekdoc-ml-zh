- en: Setup and No-Code Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置和无代码应用
- en: '![](../media/file699.jpg)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file699.jpg)'
- en: In this Lab, we will explore computer vision (CV) applications using the Seeed
    Studio [*Grove Vision AI Module V2*](https://wiki.seeedstudio.com/grove_vision_ai_v2/),
    a powerful yet compact device specifically designed for embedded machine learning
    applications. Based on the **Himax WiseEye2** chip, this module is designed to
    enable AI capabilities on edge devices, making it an ideal tool for Edge Machine
    Learning (ML) applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验室中，我们将探索使用 Seeed Studio [*Grove Vision AI 模块 V2*](https://wiki.seeedstudio.com/grove_vision_ai_v2/)
    的计算机视觉 (CV) 应用，这是一个专为嵌入式机器学习应用设计的强大而紧凑的设备。基于 **Himax WiseEye2** 芯片，该模块旨在使边缘设备具备
    AI 功能，使其成为边缘机器学习 (ML) 应用的理想工具。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: Grove Vision AI Module (V2) Overview
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Grove Vision AI 模块 (V2) 概述
- en: '![](../media/file700.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file700.jpg)'
- en: The Grove Vision AI (V2) is an MCU-based vision AI module that utilizes a [Himax
    WiseEye2 HX6538](https://www.himax.com.tw/products/intelligent-sensing/always-on-smart-sensing/wiseeye2-ai-processor/)
    processor featuring a **dual-core Arm Cortex-M55 and an integrated ARM Ethos-U55
    neural network unit**. The [Arm Ethos-U55](https://www.arm.com/products/silicon-ip-cpu/ethos/ethos-u55)
    is a machine learning (ML) processor class, specifically designed as a microNPU,
    to accelerate ML inference in area-constrained embedded and IoT devices. The Ethos-U55,
    combined with the AI-capable Cortex-M55 processor, provides a 480x uplift in ML
    performance over existing Cortex-M-based systems. Its clock frequency is 400 MHz,
    and its internal system memory (SRAM) is configurable, with a maximum capacity
    of 2.4 MB.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Grove Vision AI (V2) 是一个基于 MCU 的视觉 AI 模块，它使用一个 [Himax WiseEye2 HX6538](https://www.himax.com.tw/products/intelligent-sensing/always-on-smart-sensing/wiseeye2-ai-processor/)
    处理器，该处理器具有**双核 Arm Cortex-M55 和一个集成的 ARM Ethos-U55 神经网络单元**。[Arm Ethos-U55](https://www.arm.com/products/silicon-ip-cpu/ethos/ethos-u55)
    是一个机器学习 (ML) 处理器类别，特别设计为微 NPU，以加速在区域受限的嵌入式和物联网设备中的 ML 推理。Ethos-U55 与 AI 兼容的 Cortex-M55
    处理器结合，在基于 Cortex-M 的现有系统中提供了 480 倍的 ML 性能提升。其时钟频率为 400 MHz，其内部系统内存（SRAM）可配置，最大容量为
    2.4 MB。
- en: '![](../media/file701.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file701.jpg)'
- en: 'Note: Based on Seeed Studio documentation, besides the Himax internal memory
    of 2.5MB (2.4MB SRAM + 64KB ROM), the Grove Vision AI (V2) is also equipped with
    a 16MB/133 MHz external flash.'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：根据 Seeed Studio 文档，除了 Himax 内部内存 2.5MB（2.4MB SRAM + 64KB ROM）外，Grove Vision
    AI (V2) 还配备了一个 16MB/133 MHz 的外部闪存。
- en: '![](../media/file702.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file702.jpg)'
- en: Below is a block Diagram of the Grove Vision AI (V2) system, including a camera
    and a master controller.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 Grove Vision AI (V2) 系统的框图，包括一个摄像头和一个主控制器。
- en: '![](../media/file703.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file703.png)'
- en: With interfaces like **IIC, UART, SPI, and Type-C,** the Grove Vision AI (V2)
    can be easily connected to devices such as **XIAO, Raspberry Pi, BeagleBoard**,
    **and ESP-based products** for further development. For instance, integrating
    Grove Vision AI V2 with one of the devices from the XIAO family makes it easy
    to access the data resulting from inference on the device through the Arduino
    IDE or MicroPython, and conveniently connect to the cloud or dedicated servers,
    such as Home Assistance.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过**IIC、UART、SPI 和 Type-C**等接口，Grove Vision AI (V2) 可以轻松连接到 XIAO、Raspberry Pi、BeagleBoard
    和基于 ESP 的产品等设备，以进行进一步开发。例如，将 Grove Vision AI V2 与 XIAO 系列设备之一集成，可以通过 Arduino IDE
    或 MicroPython 容易地访问设备推理的结果数据，并方便地连接到云端或专用服务器，如家庭助手。
- en: Using the **I2C Grove connector**, the Grove Vision AI V2 can be easily connected
    with any Master Device.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用**I2C Grove 连接器**，Grove Vision AI V2 可以轻松连接到任何主设备。
- en: '![](../media/file704.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file704.png)'
- en: Besides performance, another area to comment on is **Power Consumption**. For
    example, in a comparative test against the XIAO ESP32S3 Sense, running Swift-YOLO
    Tiny 96x96, despite achieving higher performance (30 FPS vs. 5.5 FPS), the Grove
    Vision AI V2 exhibited lower power consumption (0.35 W vs. 0.45 W) when compared
    with the XIAO ESP32S3 Sense.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 除了性能之外，另一个值得评论的领域是**功耗**。例如，在与 XIAO ESP32S3 Sense 的比较测试中，运行 Swift-YOLO Tiny
    96x96，尽管实现了更高的性能（30 FPS 对 5.5 FPS），但与 XIAO ESP32S3 Sense 相比，Grove Vision AI V2
    表现出更低的功耗（0.35 W 对 0.45 W）。
- en: '![](../media/file705.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file705.png)'
- en: 'The above comparison (and with other devices) can be found in the article [2024
    MCU AI Vision Boards: Performance Comparison](https://www.hackster.io/limengdu0117/2024-mcu-ai-vision-boards-performance-comparison-998505),
    which confirms the power of Grove Vision AI (V2).'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 上述比较（以及与其他设备的比较）可以在文章 [2024 MCU AI 视觉板：性能比较](https://www.hackster.io/limengdu0117/2024-mcu-ai-vision-boards-performance-comparison-998505)
    中找到，该文章证实了 Grove Vision AI (V2) 的强大功能。
- en: Camera Installation
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摄像头安装
- en: Having the Grove Vision AI (V2) and camera ready, you can connect, for example,
    a **Raspberry Pi OV5647 Camera Module** via the CSI cable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好 Grove Vision AI (V2) 和摄像头后，您可以通过 CSI 线连接，例如 **Raspberry Pi OV5647 摄像头模块**。
- en: When connecting, please pay attention to the direction of the row of pins and
    ensure they are plugged in correctly, not in the opposite direction.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 连接时，请注意引脚排的方向，并确保它们正确插入，而不是反方向。
- en: '![](../media/file706.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file706.jpg)'
- en: The SenseCraft AI Studio
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SenseCraft AI Studio
- en: The [SenseCraft AI](https://sensecraft.seeed.cc/ai/home) Studio is a robust
    platform that offers a wide range of AI models compatible with various devices,
    including the XIAO ESP32S3 Sense and the **Grove Vision AI V2**. In this lab,
    we will walk through the process of using an AI model with the Grove Vision AI
    V2 and preview the model’s output. We will also explore some key concepts, settings,
    and how to optimize the model’s performance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[SenseCraft AI](https://sensecraft.seeed.cc/ai/home) Studio 是一个强大的平台，提供各种与各种设备兼容的
    AI 模型，包括 XIAO ESP32S3 Sense 和 **Grove Vision AI V2**。在本实验中，我们将介绍如何使用 Grove Vision
    AI V2 的 AI 模型，并预览模型的输出。我们还将探讨一些关键概念、设置以及如何优化模型性能。'
- en: '![](../media/file707.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file707.png)'
- en: Models can also be deployed using the [**SenseCraft Web Toolkit**](https://seeed-studio.github.io/SenseCraft-Web-Toolkit/#/setup/process),
    a simplified version of the SenseCraft AI Studio.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 模型也可以使用 [**SenseCraft Web Toolkit**](https://seeed-studio.github.io/SenseCraft-Web-Toolkit/#/setup/process)
    部署，这是 SenseCraft AI Studio 的简化版本。
- en: We can start using the SenseCraft Web Toolkit for simplicity, or go directly
    to the [SenseCraft AI Studio](https://sensecraft.seeed.cc/ai/model), which has
    more resources.
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了简单起见，我们可以开始使用 SenseCraft Web Toolkit，或者直接进入 [SenseCraft AI Studio](https://sensecraft.seeed.cc/ai/model)，那里有更多资源。
- en: The SenseCraft Web-Toolkit
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SenseCraft Web-Toolkit
- en: The SenseCraft Web Toolkit is a visual model deployment tool included in the
    [SSCMA](https://sensecraftma.seeed.cc/)(Seeed SenseCraft Model Assistant). This
    tool enables us to deploy models to various platforms with ease through simple
    operations. The tool offers a user-friendly interface and does not require any
    coding.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: SenseCraft Web Toolkit 是 [SSCMA](https://sensecraftma.seeed.cc/)(Seeed SenseCraft
    Model Assistant) 中包含的可视化模型部署工具。此工具使我们能够通过简单的操作轻松地将模型部署到各种平台。该工具提供用户友好的界面，无需任何编码。
- en: The SenseCraft Web Toolkit is based on the Himax AI Web Toolkit, which can (**optionally**)
    be downloaded from [here](https://github.com/HimaxWiseEyePlus/Seeed_Grove_Vision_AI_Module_V2/releases/download/v1.1/Himax_AI_web_toolkit.zip).
    Once downloaded and unzipped to the local PC, double-click `index.html` to run
    it locally.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: SenseCraft Web Toolkit 是基于 Himax AI Web Toolkit 的，它可以从 [这里](https://github.com/HimaxWiseEyePlus/Seeed_Grove_Vision_AI_Module_V2/releases/download/v1.1/Himax_AI_web_toolkit.zip)
    （**可选**）下载。下载后解压到本地 PC，双击 `index.html` 以本地运行。
- en: '![](../media/file708.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file708.png)'
- en: 'But in our case, let’s follow the steps below to start the **SenseCraft-Web-Toolkit**:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们的情况下，让我们按照以下步骤开始 **SenseCraft-Web-Toolkit**：
- en: Open the [SenseCraft-Web-Toolkit website](https://seeed-studio.github.io/SenseCraft-Web-Toolkit/#/setup/process)
    on a web browser as **Chrome**.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 **Chrome** 浏览器中打开 [SenseCraft-Web-Toolkit 网站](https://seeed-studio.github.io/SenseCraft-Web-Toolkit/#/setup/process)。
- en: Connect Grove Vision AI (V2) to your computer using a Type-C cable.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Type-C 线将 Grove Vision AI (V2) 连接到您的计算机。
- en: 'Having the XIAO connected, select it as below:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接 XIAO 后，选择如下：
- en: '![](../media/file709.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file709.png)'
- en: 'Select the device/Port and press `[Connect]`:'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择设备/端口，然后按 `[连接]`：
- en: '![](../media/file710.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file710.png)'
- en: 'Note: The **WebUSB tool** may not function correctly in certain browsers, such
    as Safari. Use Chrome instead.'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：**WebUSB 工具**可能在某些浏览器中无法正常工作，例如 Safari。请使用 Chrome。
- en: We can try several Basic Computer Vision models previously uploaded by Seeed
    Studio. Passing the cursor over the AI models, we can have some information about
    them, such as name, description, **category** (Image Classification, Object Detection,
    or Pose/Keypoint Detection), the **algorithm** (like YOLO V5 or V8, FOMO, MobileNet
    V2, etc.) and **metrics** (Accuracy or mAP).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试Seeed Studio之前上传的几个基本计算机视觉模型。将光标移过AI模型，我们可以了解一些关于它们的信息，例如名称、描述、**类别**（图像分类、目标检测或姿态/关键点检测）、**算法**（如YOLO
    V5或V8、FOMO、MobileNet V2等）和**指标**（准确度或mAP）。
- en: '![](../media/file711.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file711.png)'
- en: We can choose one of those ready-to-use AI models by clicking on it and pressing
    the `[Send]` button, or upload our model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过点击它并按 `[发送]` 按钮选择那些现成的AI模型之一，或者上传我们的模型。
- en: For the **SenseCraft AI** platform, follow the instructions [here](https://wiki.seeedstudio.com/sensecraft_ai_pretrained_models_for_grove_visionai_v2/).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**SenseCraft AI**平台，请按照[这里](https://wiki.seeedstudio.com/sensecraft_ai_pretrained_models_for_grove_visionai_v2/)的说明操作。
- en: Exploring CV AI models
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索CV AI模型
- en: Object Detection
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标检测
- en: Object detection is a pivotal technology in computer vision that focuses on
    identifying and locating objects within digital images or video frames. Unlike
    image classification, which categorizes an entire image into a single label, object
    detection recognizes multiple objects within the image and determines their precise
    locations, typically represented by bounding boxes. This capability is crucial
    for a wide range of applications, including autonomous vehicles, security, surveillance
    systems, and augmented reality, where understanding the context and content of
    the visual environment is essential.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测是计算机视觉中的一个关键技术，它专注于在数字图像或视频帧中识别和定位对象。与将整个图像分类为单个标签的图像分类不同，目标检测识别图像中的多个对象并确定它们的精确位置，通常由边界框表示。这种能力对于广泛的用途至关重要，包括自动驾驶汽车、安全、监控系统以及增强现实，在这些应用中，理解视觉环境中的上下文和内容是至关重要的。
- en: Common architectures that have set the benchmark in object detection include
    the YOLO (You Only Look Once), SSD (Single Shot MultiBox Detector), FOMO (Faster
    Objects, More Objects), and Faster R-CNN (Region-based Convolutional Neural Networks)
    models.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标检测中设定基准的常见架构包括YOLO（You Only Look Once）、SSD（Single Shot MultiBox Detector）、FOMO（Faster
    Objects, More Objects）和Faster R-CNN（基于区域的卷积神经网络）模型。
- en: Let’s choose one of the ready-to-use AI models, such as **Person Detection**,
    which was trained using the Swift-YOLO algorithm.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们选择一个现成的AI模型，例如**人员检测**，它使用Swift-YOLO算法进行训练。
- en: '![](../media/file712.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file712.png)'
- en: Once the model is uploaded successfully, you can see the live feed from the
    Grove Vision AI (V2) camera in the Preview area on the right. Also, the inference
    details can be shown on the Serial Monitor by clicking on the `[Device Log`] button
    at the top.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型成功上传，你可以在右侧预览区域看到Grove Vision AI (V2)摄像头的实时流。此外，通过点击顶部的 `[设备日志]` 按钮可以在串行监视器上显示推理详情。
- en: '![](../media/file713.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file713.png)'
- en: In the SenseCraft AI Studio, the Device Logger is always on the screen.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在SenseCraft AI Studio中，设备日志始终在屏幕上。
- en: 'Pointing the camera at me, only one person was detected, so that the model
    output will be a single “box”. Looking in detail, the module sends continuously
    two lines of information:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 将摄像头对准我，只检测到一个人，因此模型输出将是一个单独的“框”。仔细观察，模块会连续发送两行信息：
- en: '![](../media/file714.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file714.png)'
- en: '**perf** (Performance), displays latency in milliseconds.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**perf**（性能），显示毫秒级的延迟。'
- en: 'Preprocess time (image capture and Crop): **7ms**;'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理时间（图像捕获和裁剪）：**7ms**；
- en: 'Inference time (model latency): **76ms (13 fps)**'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理时间（模型延迟）：**76ms (13 fps)**
- en: 'Postprocess time (display of the image and inclusion of data): less than 0ms.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后处理时间（显示图像和数据包含）：小于0ms。
- en: '**boxes**: Show the objects detected in the image. In this case, only one.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**boxes**: 显示图像中检测到的对象。在这种情况下，只有一个。'
- en: The box has the x, y, w, and h coordinates of (**245**, **292**,**449**,**392**),
    and the object (person, label **0**) was captured with a value of .**89**.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 框的坐标为 x, y, w, h （**245**, **292**，**449**，**392**），并且对象（人，标签 **0**）的捕获值为 .**89**。
- en: 'If we point the camera at an image with several people, we will get one box
    for each person (object):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用摄像头指向有几个人的图像，我们将为每个人（对象）得到一个框：
- en: '![](../media/file715.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file715.png)'
- en: On the SenseCraft AI Studio, the inference latency (48ms) is lower than on the
    SenseCraft ToolKit (76ms), due to a distinct deployment implementation.
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在SenseCraft AI Studio上，推理延迟（48ms）低于SenseCraft ToolKit（76ms），这是由于独特的部署实现。
- en: '![](../media/file716.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file716.png)'
- en: '**Power Consumption**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**功耗**'
- en: The peak power consumption running this Swift-YOLO model was 410 milliwatts.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个Swift-YOLO模型时的峰值功耗为410毫瓦。
- en: '**Preview Settings**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**预览设置**'
- en: We can see that in the Settings, two settings options can be adjusted to optimize
    the model’s recognition accuracy.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在设置中，有两个设置选项可以调整以优化模型的识别精度。
- en: '**Confidence:** Refers to the level of certainty or probability assigned to
    its predictions by a model. This value determines the minimum confidence level
    required for the model to consider a detection as valid. A higher confidence threshold
    will result in fewer detections but with higher certainty, while a lower threshold
    will allow more detections but may include some false positives.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：指模型对其预测赋予的确定性或概率水平。此值确定模型认为检测有效所需的最小置信度水平。较高的置信度阈值将导致检测数量减少但确定性更高，而较低的阈值将允许更多检测，但可能包括一些误报。'
- en: '**IoU:** Used to assess the accuracy of predicted bounding boxes compared to
    truth bounding boxes. IoU is a metric that measures the overlap between the predicted
    bounding box and the ground truth bounding box. It is used to determine the accuracy
    of the object detection. The IoU threshold sets the minimum IoU value required
    for a detection to be considered a true positive. Adjusting this threshold can
    help in fine-tuning the model’s precision and recall.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IoU**：用于评估预测边界框与真实边界框的准确性。IoU是一个度量指标，用于衡量预测边界框与真实边界框之间的重叠。它用于确定目标检测的准确性。IoU阈值设置了对检测被认为是真正阳性的最小IoU值。调整此阈值可以帮助微调模型的精确度和召回率。'
- en: '![](../media/file717.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file717.png)'
- en: Experiment with different values for the Confidence Threshold and IoU Threshold
    to find the optimal balance between detecting persons accurately and minimizing
    false positives. The best settings may vary depending on our specific application
    and the characteristics of the images or video feed.
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尝试调整置信度阈值和IoU阈值的不同值，以找到在准确检测人员的同时最小化误报的最佳平衡。最佳设置可能因我们的具体应用和图像或视频流的特点而异。
- en: Pose/Keypoint Detection
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**姿态/关键点检测**'
- en: Pose or keypoint detection is a sophisticated area within computer vision that
    focuses on identifying specific points of interest within an image or video frame,
    often related to human bodies, faces, or other objects of interest. This technology
    can detect and map out the various keypoints of a subject, such as the **joints
    on a human body** or the features of a face, enabling the analysis of postures,
    movements, and gestures. This has profound implications for various applications,
    including augmented reality, human-computer interaction, sports analytics, and
    healthcare monitoring, where understanding human motion and activity is crucial.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 姿态或关键点检测是计算机视觉中的一个复杂领域，它专注于在图像或视频帧中识别特定的兴趣点，通常与人体、面部或其他感兴趣的对象相关。这项技术可以检测并绘制出主题的各种关键点，如人体上的**关节**或面部的特征，从而实现姿态、运动和手势的分析。这对于各种应用具有深远的影响，包括增强现实、人机交互、运动分析和医疗监测，在这些应用中，理解人体运动和活动至关重要。
- en: Unlike general object detection, which identifies and locates objects, pose
    detection drills down to a finer level of detail, capturing the nuanced positions
    and orientations of specific parts. Leading architectures in this field include
    OpenPose, AlphaPose, and PoseNet, each designed to tackle the challenges of pose
    estimation with varying degrees of complexity and precision. Through advancements
    in deep learning and neural networks, pose detection has become increasingly accurate
    and efficient, offering real-time insights into the intricate dynamics of subjects
    captured in visual data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与一般目标检测不同，目标检测识别并定位对象，姿态检测则深入到更细致的细节，捕捉特定部分的细微位置和方向。该领域的领先架构包括OpenPose、AlphaPose和PoseNet，每个架构都旨在以不同复杂度和精度解决姿态估计的挑战。通过深度学习和神经网络的发展，姿态检测变得越来越准确和高效，为视觉数据中捕获的主题的复杂动态提供实时洞察。
- en: So, let’s explore this popular CV application, *Pose/Keypoint Detection*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们探索这个流行的计算机视觉应用，*姿态/关键点检测*。
- en: '![](../media/file718.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file718.png)'
- en: Stop the current model inference by pressing `[Stop]` in the Preview area. Select
    the model and press `[Send]`. Once the model is uploaded successfully, you can
    view the live feed from the Grove Vision AI (V2) camera in the Preview area on
    the right, along with the inference details displayed in the Serial Monitor (accessible
    by clicking the `[Device Log]` button at the top).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在预览区域按 `[停止]` 来停止当前模型的推理。选择模型并按 `[发送]`。一旦模型成功上传，您可以在右侧预览区域的预览区域中查看Grove Vision
    AI（V2）摄像头的实时流，以及通过点击顶部 `[设备日志]` 按钮可访问的串行监视器中显示的推理细节。
- en: '![](../media/file719.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file719.png)'
- en: The YOLOV8 Pose model was trained using the [COCO-Pose Dataset](https://docs.ultralytics.com/datasets/pose/coco/),
    which contains 200K images labeled with **17** keypoints for pose estimation tasks.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOV8姿态模型使用[COCO-Pose数据集](https://docs.ultralytics.com/datasets/pose/coco/)进行训练，该数据集包含200K张带有**17**个关键点的图像，用于姿态估计任务。
- en: 'Let’s look at a single screenshot of the inference (to simplify, let’s analyse
    an image with a single person in it). We can note that we have two lines, one
    with the inference **performance** in milliseconds (121 ms) and a second line
    with the **keypoints** as below:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看单个推理截图（为了简化，让我们分析包含一个人的图像）。我们可以注意到我们有两行，一行是推理**性能**（121毫秒），另一行是以下**关键点**：
- en: 1 box of info, the same as we got with the object detection example (box coordinates
    (113, 119, 67, 208), inference result (90), label (0).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1个信息框，与目标检测示例中得到的相同（框坐标（113，119，67，208），推理结果（90），标签（0）。
- en: 17 groups of 4 numbers represent the 17 “joints” of the body, where ‘0’ is the
    nose, ‘1’ and ‘2’ are the eyes, ‘15’ and’ 16’ are the feet, and so on.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 17组4个数字代表身体的17个“关节”，其中‘0’是鼻子，‘1’和‘2’是眼睛，‘15’和‘16’是脚，等等。
- en: '![](../media/file720.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file720.png)'
- en: 'To understand a pose estimation project more deeply, please refer to the tutorial:
    [Exploring AI at the Edge! - Pose Estimation](https://www.hackster.io/mjrobot/exploring-ai-at-the-edge-97588d#toc-pose-estimation-10).'
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要更深入地了解姿态估计项目，请参阅教程：[探索边缘AI！- 姿态估计](https://www.hackster.io/mjrobot/exploring-ai-at-the-edge-97588d#toc-pose-estimation-10)。
- en: Image Classification
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像分类
- en: Image classification is a foundational task within computer vision aimed at
    categorizing **entire images** into one of several predefined classes. This process
    involves analyzing the visual content of an image and assigning it a label from
    a fixed set of categories based on the predominant object or scene it contains.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是计算机视觉中的一个基础任务，旨在将**整个图像**分类到预定义的几个类别之一。这个过程涉及分析图像的视觉内容，并根据它包含的主要物体或场景，从固定的类别集中分配一个标签。
- en: Image classification is crucial in various applications, ranging from organizing
    and searching through large databases of images in digital libraries and social
    media platforms to enabling autonomous systems to comprehend their surroundings.
    Common architectures that have significantly advanced the field of image classification
    include Convolutional Neural Networks (CNNs), such as AlexNet, VGGNet, and ResNet.
    These models have demonstrated remarkable accuracy on challenging datasets, such
    as **ImageNet,** by learning hierarchical representations of visual data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类在各种应用中至关重要，从组织并搜索数字图书馆和社交媒体平台中的大型图像数据库，到使自主系统能够理解其周围环境。显著推进图像分类领域的常见架构包括卷积神经网络（CNNs），如AlexNet、VGGNet和ResNet。这些模型通过学习视觉数据的高级表示，在具有挑战性的数据集（如**ImageNet**）上展示了显著的准确性。
- en: As the cornerstone of many computer vision systems, image classification drives
    innovation, laying the groundwork for more complex tasks like object detection
    and image segmentation, and facilitating a deeper understanding of visual data
    across various industries. So, let’s also explore this computer vision application.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 作为许多计算机视觉系统的基石，图像分类推动了创新，为更复杂任务如目标检测和图像分割奠定了基础，并促进了各行业对视觉数据的更深入理解。因此，让我们也来探索这个计算机视觉应用。
- en: '![](../media/file721.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file721.png)'
- en: This example is available on the SenseCraft ToolKit, but not in the SenseCraft
    AI Studio. In the last one, it is possible to find other examples of Image Classification.
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此示例可在SenseCraft ToolKit中找到，但不在SenseCraft AI Studio中。在最后一个示例中，可以找到其他图像分类的示例。
- en: After the model is uploaded successfully, we can view the live feed from the
    Grove Vision AI (V2) camera in the Preview area on the right, along with the inference
    details displayed in the Serial Monitor (by clicking the `[Device Log]` button
    at the top).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 模型成功上传后，我们可以在右侧的预览区域查看Grove Vision AI (V2)摄像头的实时流，同时显示在串行监视器（通过点击顶部的 `[设备日志]`
    按钮）中的推理细节。
- en: '![](../media/file722.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file722.png)'
- en: As a result, we will receive a score and the class as output.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将收到一个分数和类别作为输出。
- en: '![](../media/file723.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file723.png)'
- en: 'For example, **[99, 1]** means class: 1 (Person) with a score of 0.99\. Once
    this model is a binary classification, class 0 will be “No Person” (or Background).
    The Inference latency is **15ms** or around 70fps.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**[99, 1]** 表示类别：1（人物）得分为0.99。一旦这个模型是二元分类，类别0将是“无人”（或背景）。推理延迟为**15ms**或大约70fps。
- en: Power Consumption
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 功耗
- en: To run the Mobilenet V2 0.35, the Grove Vision AI V2 had a peak current of 80mA
    at 5.24V, resulting in a **power consumption of 420mW**.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行Mobilenet V2 0.35，Grove Vision AI V2在5.24V时的峰值电流为80mA，导致**功耗为420mW**。
- en: Running the same model on XIAO ESP32S3 Sense, the **power consumption was 523mW**
    with a latency of 291ms.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在XIAO ESP32S3 Sense上运行相同的模型，**功耗为523mW**，延迟为291ms。
- en: '![](../media/file724.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file724.png)'
- en: Exploring Other Models on SenseCraft AI Studio
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在SenseCraft AI Studio上探索其他模型
- en: 'Several public AI models can also be downloaded from the [SenseCraft AI WebPage](https://sensecraft.seeed.cc/ai/model).
    For example, you can run a Swift-YOLO model, [detecting traffic lights](https://sensecraft.seeed.cc/ai/view-model/60281-traffic-light-detection?tab=public)
    as shown here:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以从 [SenseCraft AI 网页](https://sensecraft.seeed.cc/ai/model) 下载几个公共AI模型。例如，你可以运行一个Swift-YOLO模型，[检测交通灯](https://sensecraft.seeed.cc/ai/view-model/60281-traffic-light-detection?tab=public)
    如此所示：
- en: '![](../media/file725.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file725.png)'
- en: The latency of this model is approximately 86 ms, with an average power consumption
    of 420 mW.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型的延迟大约为86ms，平均功耗为420mW。
- en: An Image Classification Project
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个图像分类项目
- en: Let’s create a complete Image Classification project, using the SenseCraft AI
    Studio.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个完整的图像分类项目，使用SenseCraft AI Studio。
- en: '![](../media/file726.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file726.png)'
- en: 'On SenseCraft AI Studio: Let’s open the tab [Training](https://sensecraft.seeed.cc/ai/training):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在SenseCraft AI Studio上：让我们打开标签页 [训练](https://sensecraft.seeed.cc/ai/training)：
- en: '![](../media/file727.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file727.png)'
- en: The default is to train a `Classification` model with a WebCam if it is available.
    Let’s select the Grove Vision AI V2 instead. Pressing the green button`[Connect]`,
    a Pop-Up window will appear. Select the corresponding Port and press the blue
    button `[Connect]`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有WebCam，默认情况下训练一个`分类`模型。让我们选择Grove Vision AI V2。按下绿色按钮`[连接]`，将出现一个弹出窗口。选择相应的端口，然后按蓝色按钮
    `[连接]`。
- en: '![](../media/file728.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file728.png)'
- en: The image streamed from the Grove Vision AI V2 will be displayed.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从Grove Vision AI V2流出的图像将被显示。
- en: The Goal
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标
- en: The first step is always to define a goal. Let’s classify, for example, two
    simple objects—for instance, a toy `box` and a toy `wheel`. We should also include
    a 3rd class of images, `background`, where no object is in the scene.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步始终是定义一个目标。例如，让我们分类两个简单的物体——例如，一个玩具`盒子`和一个玩具`轮子`。我们还应该包括一个图像类别，`背景`，其中场景中没有物体。
- en: '![](../media/file729.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file729.png)'
- en: Data Collection
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集
- en: 'Let’s create the classes, following, for example, an alphabetical order:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建类，例如按照字母顺序：
- en: 'Class1: background'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类1：背景
- en: 'Class 2: box'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类2：盒子
- en: 'Class 3: wheel'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类3：轮子
- en: '![](../media/file730.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file730.png)'
- en: Select one of the classes and keep pressing the green button under the preview
    area. The collected images will appear on the Image Samples Screen.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个类别，并持续按预览区域下的绿色按钮。收集的图像将出现在图像样本屏幕上。
- en: '![](../media/file731.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file731.png)'
- en: After collecting the images, review them and delete any incorrect ones.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 收集图像后，检查它们并删除任何错误的图像。
- en: '![](../media/file732.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file732.png)'
- en: 'Collect around 50 images from each class and go to Training Step:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个类别收集大约50张图像，然后转到训练步骤：
- en: Training
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: Confirm if the correct device is selected (`Grove Vision AI V2`) and press `[Start
    Training]`
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 确认是否选择了正确的设备（`Grove Vision AI V2`），然后按 `[开始训练]`
- en: '![](../media/file733.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file733.png)'
- en: Test
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试
- en: After training, the inference result can be previewed.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后，可以预览推理结果。
- en: Note that the model is not running on the device. We are, in fact, only capturing
    the images with the device and performing a live preview using the training model,
    which is running in the Studio.
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意，模型当前并未在设备上运行。实际上，我们只是在用设备捕捉图像，并使用在Studio中运行的训练模型进行实时预览。
- en: '![](../media/file734.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file734.png)'
- en: 'Now is time to really deploy the model in the device:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是真正在设备上部署模型的时候了：
- en: Deployment
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署
- en: 'Select the trained model on `[Deploy to device]`, select the Grove Vision AI
    V2:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在`部署到设备`上选择训练好的模型，选择Grove Vision AI V2：
- en: '![](../media/file735.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file735.png)'
- en: 'The Studio will redirect us to the `Vision Workplace` tab. Confirm the deployment,
    select the appropriate Port, and connect it:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Studio将带我们转到`视觉工作空间`标签。确认部署，选择合适的端口，并连接：
- en: '![](../media/file736.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file736.png)'
- en: The model will be flashed into the device. After an automatic reset, the model
    will start running on the device. On the Device Logger, we can see that the inference
    has a **latency of approximately 8 ms**, corresponding to a **frame rate of 125
    frames per second (FPS)**.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 模型将被烧录到设备中。自动重置后，模型将在设备上开始运行。在设备日志中，我们可以看到推理的**延迟约为8 ms**，对应**每秒125帧（FPS）**。
- en: Also, note that it is possible to adjust the model’s confidence.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，可以调整模型的置信度。
- en: '![](../media/file737.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file737.png)'
- en: To run the Image Classification Model, the Grove Vision AI V2 had a peak current
    of 80mA at 5.24V, resulting in a **power consumption of 420mW**.
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要运行图像分类模型，Grove Vision AI V2在5.24V下的峰值电流为80mA，导致**功耗为420mW**。
- en: Saving the Model
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保存模型
- en: 'It is possible to save the model in the SenseCraft AI Studio. The Studio will
    keep all our models, which can be deployed later. For that, return to the `Training`
    tab and select the button `[Save to SenseCraft`]:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '在SenseCraft AI Studio中可以保存模型。Studio将保留所有我们的模型，这些模型可以在以后部署。为此，返回到`训练`标签并选择按钮`[保存到SenseCraft`]:'
- en: '![](../media/file738.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../media/file738.png)'
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this lab, we explored several computer vision (CV) applications using the
    [Seeed Studio Grove Vision AI Module V2](https://wiki.seeedstudio.com/grove_vision_ai_v2/),
    demonstrating its exceptional capabilities as a powerful yet compact device specifically
    designed for embedded machine learning applications.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验室中，我们使用[Seeed Studio Grove Vision AI模块V2](https://wiki.seeedstudio.com/grove_vision_ai_v2/)探索了几个计算机视觉（CV）应用，展示了它作为一款专为嵌入式机器学习应用设计的强大而紧凑设备的卓越能力。
- en: '**Performance Excellence**: The Grove Vision AI V2 demonstrated remarkable
    performance across multiple computer vision tasks. With its **Himax WiseEye2 chip**
    featuring a **dual-core Arm Cortex-M55 and integrated ARM Ethos-U55 neural network
    unit**, the device delivered:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能卓越**：Grove Vision AI V2在多个计算机视觉任务中表现出色。凭借其**Himax WiseEye2芯片**，该芯片具有**双核Arm
    Cortex-M55和集成的ARM Ethos-U55神经网络单元**，设备提供了：'
- en: '**Image Classification**: **15 ms** inference time (67 FPS)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分类**：**15 ms**推理时间（67 FPS）'
- en: '**Object Detection (Person)**: **48 ms to 76 ms** inference time (21 FPS to
    13 FPS)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物体检测（人物）**：**48 ms到76 ms**推理时间（21 FPS到13 FPS）'
- en: '**Pose Detection**: **121 ms** real-time keypoint detection with 17-joint tracking
    (8 FPS)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**姿态检测**：**121 ms**实时关键点检测，17关节跟踪（8 FPS）'
- en: '**Power Efficiency Leadership**: One of the most compelling advantages of the
    Grove Vision AI V2 is its superior power efficiency. Comparative testing revealed
    significant improvements over traditional embedded platforms:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**能效领先**：Grove Vision AI V2最引人注目的优势之一是其卓越的能效。比较测试显示，与传统嵌入式平台相比有显著改进：'
- en: '**Grove Vision AI V2**: 80 mA (**410 mW**) peak consumption (60+ FPS)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grove Vision AI V2**：峰值功耗80 mA（**410 mW**），（60+ FPS）'
- en: '**XIAO ESP32S3**: Performing similar CV tasks (Image Classification) **523
    mW** (3+ FPS)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XIAO ESP32S3**：执行类似的CV任务（图像分类）**523 mW**（3+ FPS）'
- en: '**Practical Implementation**: The device’s versatility was demonstrated through
    a comprehensive end-to-end project, encompassing dataset creation, model training,
    deployment, and offline inference.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**实际应用**：通过一个全面的端到端项目展示了设备的通用性，包括数据集创建、模型训练、部署和离线推理。'
- en: '**Developer-Friendly Ecosystem**: The SenseCraft AI Studio, with its no-code
    deployment and integration capabilities for custom applications, makes the Grove
    Vision AI V2 accessible to both beginners and advanced developers. The extensive
    library of pre-trained models and support for custom model deployment provide
    flexibility for diverse applications.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**开发者友好生态系统**：SenseCraft AI Studio凭借其无代码部署和集成能力，为定制应用程序提供了对Grove Vision AI
    V2的访问，使得初学者和高级开发者都能使用。丰富的预训练模型库和自定义模型部署支持为各种应用提供了灵活性。'
- en: The Grove Vision AI V2 represents a significant advancement in edge AI hardware,
    offering professional-grade computer vision capabilities in a compact, energy-efficient
    package that democratizes AI deployment for embedded applications across industrial,
    IoT, and educational domains.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Grove Vision AI V2代表了边缘AI硬件的重大进步，它以紧凑、节能的包装形式提供了专业级的计算机视觉能力，使嵌入式应用在工业、物联网和教育领域的AI部署民主化。
- en: '**Key Takeaways**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键要点**'
- en: This Lab demonstrates that sophisticated computer vision applications are not
    limited to cloud-based solutions or power-hungry hardware, as the Raspberry Pi
    or Jetson Nanos – they can now be deployed effectively at the edge with remarkable
    efficiency and performance.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验室证明，复杂的计算机视觉应用不仅限于基于云的解决方案或能耗高的硬件，如Raspberry Pi或Jetson Nanos——它们现在可以以出色的效率和性能在边缘有效部署。
- en: 'Optionally, we can have the [XIAO Vision AI Camera](https://www.seeedstudio.com/XIAO-Vision-AI-Camera-p-6450.html).
    This innovative vision solution seamlessly combines the Grove Vision AI V2 module,
    XIAO ESP32-C3 controller, and an OV5647 camera, all housed in a custom 3D-printed
    enclosure:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 可选，我们可以使用[XIAO 视觉AI相机](https://www.seeedstudio.com/XIAO-Vision-AI-Camera-p-6450.html)。这个创新的视觉解决方案无缝结合了Grove
    Vision AI V2模块、XIAO ESP32-C3控制器和OV5647相机，所有这些都被封装在一个定制的3D打印外壳中：
- en: '![](../media/file739.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../media/file739.png)'
- en: Resources
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[SenseCraft AI Studio Instructions](https://wiki.seeedstudio.com/sensecraft_ai_pretrained_models_for_grove_visionai_v2/).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[SenseCraft AI Studio 指令](https://wiki.seeedstudio.com/sensecraft_ai_pretrained_models_for_grove_visionai_v2/).'
- en: '[SenseCraft-Web-Toolkit website.](https://seeed-studio.github.io/SenseCraft-Web-Toolkit/#/setup/process)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[SenseCraft-Web-Toolkit 网站](https://seeed-studio.github.io/SenseCraft-Web-Toolkit/#/setup/process)'
- en: '[SenseCraft AI Studio](https://sensecraft.seeed.cc/ai/model)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[SenseCraft AI Studio](https://sensecraft.seeed.cc/ai/model)'
- en: '[Himax AI Web Toolkit](https://github.com/HimaxWiseEyePlus/Seeed_Grove_Vision_AI_Module_V2/releases/download/v1.1/Himax_AI_web_toolkit.zip)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[Himax AI Web Toolkit](https://github.com/HimaxWiseEyePlus/Seeed_Grove_Vision_AI_Module_V2/releases/download/v1.1/Himax_AI_web_toolkit.zip)'
- en: '[Himax examples](https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/Grove/Grove_Sensors/AI-powered/Grove-vision-ai-v2/Development/grove-vision-ai-v2-himax-sdk.md)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[Himax 示例](https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/Grove/Grove_Sensors/AI-powered/Grove-vision-ai-v2/Development/grove-vision-ai-v2-himax-sdk.md)'
