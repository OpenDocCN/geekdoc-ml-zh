- en: Construction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://dafriedman97.github.io/mlbook/content/c1/construction.html](https://dafriedman97.github.io/mlbook/content/c1/construction.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '\[ \newcommand{\sumN}{\sum_{n = 1}^N} \newcommand{\sumn}{\sum_n} \newcommand{\bx}{\mathbf{x}}
    \newcommand{\bbeta}{\boldsymbol{\beta}} \newcommand{\btheta}{\boldsymbol{\theta}}
    \newcommand{\bbetahat}{\boldsymbol{\hat{\beta}}} \newcommand{\bthetahat}{\boldsymbol{\hat{\theta}}}
    \newcommand{\dadb}[2]{\frac{\partial #1}{\partial #2}} \newcommand{\by}{\mathbf{y}}
    \newcommand{\bX}{\mathbf{X}} \]'
  prefs: []
  type: TYPE_NORMAL
- en: This section demonstrates how to construct a linear regression model using only
    `numpy`. To do this, we generate a class named `LinearRegression`. We use this
    class to train the model and make future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: The first method in the `LinearRegression` class is `fit()`, which takes care
    of estimating the \(\bbeta\) parameters. This simply consists of calculating
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bbetahat = \left(\bX^\top \bX\right)^{-1}\bX^\top \by \]
  prefs: []
  type: TYPE_NORMAL
- en: The `fit` method also makes in-sample predictions with \(\hat{\by} = \bX \bbetahat\)
    and calculates the training loss with
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathcal{L}(\bbetahat) = \frac{1}{2}\sumN \left(y_n - \hat{y}_n \right)^2.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: The second method is `predict()`, which forms out-of-sample predictions. Given
    a test set of predictors \(\bX'\), we can form fitted values with \(\hat{\by}'
    = \bX' \bbetahat\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let’s try out our `LinearRegression` class with some data. Here we use the [Boston
    housing](../appendix/data.html) dataset from `sklearn.datasets`. The target variable
    in this dataset is median neighborhood home value. The predictors are all continuous
    and represent factors possibly related to the median home value, such as average
    rooms per house. Hit “Click to show” to see the code that loads this data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: With the class built and the data loaded, we are ready to run our regression
    model. This is as simple as instantiating the model and applying `fit()`, as shown
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Let’s then see how well our fitted values model the true target values. The
    closer the points lie to the 45-degree line, the more accurate the fit. The model
    seems to do reasonably well; our predictions definitely follow the true values
    quite well, although we would like the fit to be a bit tighter.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note the handful of observations with \(y = 50\) exactly. This is due to censorship
    in the data collection process. It appears neighborhoods with average home values
    above $50,000 were assigned a value of 50 even.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/construction_10_0.png](../Images/da7ad87ad14998b49f5c2665f1e949d7.png)'
  prefs: []
  type: TYPE_IMG
