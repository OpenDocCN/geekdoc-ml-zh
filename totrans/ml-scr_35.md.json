["```py\nimport numpy as np\n\ndef OLS_GD(X, y, eta = 1e-3, n_iter = 1e4, add_intercept = True):\n\n  ## Add Intercept\n  if add_intercept:\n    ones = np.ones(X.shape[0]).reshape(-1, 1)\n    X = np.concatenate((ones, X), 1)\n\n  ## Instantiate\n  beta_hat = np.random.randn(X.shape[1])\n\n  ## Iterate\n  for i in range(int(n_iter)):\n\n    ## Calculate Derivative\n    yhat = X @ beta_hat\n    delta = -X.T @ (y - yhat)\n    beta_hat -= delta*eta \n```", "```py\n## Import packages \nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.datasets import load_boston\n\n## Import data\nboston = load_boston()\nX = boston['data']\ny = boston['target']\nN = X.shape[0]\n\n## Choose alphas to consider\npotential_alphas = [0, 1, 10]\nerror_by_alpha = np.zeros(len(potential_alphas))\n\n## Choose the folds \nK = 5\nindices = np.arange(N)\nnp.random.shuffle(indices)\nfolds = np.array_split(indices, K)\n\n## Iterate through folds\nfor k in range(K):\n\n  ## Split Train and Validation\n    X_train = np.delete(X, folds[k], 0)\n    y_train = np.delete(y, folds[k], 0)\n    X_val = X[folds[k]]\n    y_val = y[folds[k]]\n\n  ## Iterate through Alphas\n    for i in range(len(potential_alphas)):\n\n        ## Train on Training Set\n        model = Ridge(alpha = potential_alphas[i])\n        model.fit(X_train, y_train)\n\n        ## Calculate and Append Error\n        error = np.sum( (y_val - model.predict(X_val))**2 )\n        error_by_alpha[i] += error\n\nerror_by_alpha /= N \n```", "```py\nimport numpy as np\n\ndef OLS_GD(X, y, eta = 1e-3, n_iter = 1e4, add_intercept = True):\n\n  ## Add Intercept\n  if add_intercept:\n    ones = np.ones(X.shape[0]).reshape(-1, 1)\n    X = np.concatenate((ones, X), 1)\n\n  ## Instantiate\n  beta_hat = np.random.randn(X.shape[1])\n\n  ## Iterate\n  for i in range(int(n_iter)):\n\n    ## Calculate Derivative\n    yhat = X @ beta_hat\n    delta = -X.T @ (y - yhat)\n    beta_hat -= delta*eta \n```", "```py\nimport numpy as np\n\ndef OLS_GD(X, y, eta = 1e-3, n_iter = 1e4, add_intercept = True):\n\n  ## Add Intercept\n  if add_intercept:\n    ones = np.ones(X.shape[0]).reshape(-1, 1)\n    X = np.concatenate((ones, X), 1)\n\n  ## Instantiate\n  beta_hat = np.random.randn(X.shape[1])\n\n  ## Iterate\n  for i in range(int(n_iter)):\n\n    ## Calculate Derivative\n    yhat = X @ beta_hat\n    delta = -X.T @ (y - yhat)\n    beta_hat -= delta*eta \n```", "```py\n## Import packages \nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.datasets import load_boston\n\n## Import data\nboston = load_boston()\nX = boston['data']\ny = boston['target']\nN = X.shape[0]\n\n## Choose alphas to consider\npotential_alphas = [0, 1, 10]\nerror_by_alpha = np.zeros(len(potential_alphas))\n\n## Choose the folds \nK = 5\nindices = np.arange(N)\nnp.random.shuffle(indices)\nfolds = np.array_split(indices, K)\n\n## Iterate through folds\nfor k in range(K):\n\n  ## Split Train and Validation\n    X_train = np.delete(X, folds[k], 0)\n    y_train = np.delete(y, folds[k], 0)\n    X_val = X[folds[k]]\n    y_val = y[folds[k]]\n\n  ## Iterate through Alphas\n    for i in range(len(potential_alphas)):\n\n        ## Train on Training Set\n        model = Ridge(alpha = potential_alphas[i])\n        model.fit(X_train, y_train)\n\n        ## Calculate and Append Error\n        error = np.sum( (y_val - model.predict(X_val))**2 )\n        error_by_alpha[i] += error\n\nerror_by_alpha /= N \n```"]