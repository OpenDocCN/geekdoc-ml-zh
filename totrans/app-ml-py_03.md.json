["```py\nignore_warnings = True\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nfrom sklearn.model_selection import cross_val_score           # multi-processor K-fold crossvalidation\nfrom sklearn.model_selection import train_test_split          # train and test split\nfrom sklearn.model_selection import KFold                     # K-fold cross validation\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map\nseed = 42                                                     # random number seed \n```", "```py\ndef add_grid():\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\ndf = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n\nresponse = 'Prod'                                             # specify the response feature\nX = df.iloc[:,[1,3]]                                          # make predictor and response DataFrames\ny = df.loc[:,response]\n\nXname = X.columns.values.tolist()                             # store the names of the features\nyname = y.name\n\nXmin = [6.0,1.0]; Xmax = [24.0,5.0]                           # set the minimum and maximum values for plotting\nymin = 500.0; ymax = 9000.0\n\nXlabel = ['Porosity','Acoustic Impedance']\nylabel = 'Normalized Initial Production (MCFPD)'\n\nXtitle = ['Porosity','Acoustic Impedance']\nytitle = 'Normalized Initial Production'\n\nXunit = ['%',r'$kg/m^3 x m/s x 10^3$']; yunit = 'MCFPD'\nXlabelunit = [Xlabel[0] + ' (' + Xunit[0] + ')',Xlabel[1] + ' (' + Xunit[1] + ')']\nylabelunit = ylabel + ' (' + yunit + ')'\n\nm = len(pred) + 1\nmpred = len(pred) \n```", "```py\n---------------------------------------------------------------------------\nNameError  Traceback (most recent call last)\nCell In[3], line 23\n  20 Xlabelunit = [Xlabel[0] + ' (' + Xunit[0] + ')',Xlabel[1] + ' (' + Xunit[1] + ')']\n  21 ylabelunit = ylabel + ' (' + yunit + ')'\n---> 23 m = len(pred) + 1\n  24 mpred = len(pred)\n\nNameError: name 'pred' is not defined \n```", "```py\ntest_prop = 0.15                                              # set the proportion of test data to withhold\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_prop,random_state=73073) # train and test split\ndf_train = pd.concat([X_train,y_train],axis=1)                # make one train DataFrame with both X and y (remove all other features)\ndf_test = pd.concat([X_test,y_test],axis=1)                   # make one testin DataFrame with both X and y (remove all other features)\n\nnbins = 20                                                    # number of histogram bins\n\nplt.subplot(221)                                              # predictor feature #1 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_test[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10)\nplt.xlabel(Xlabelunit[0]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[0]); add_grid()  \nplt.xlim([Xmin[0],Xmax[0]]); plt.legend(loc='upper right')   \n\nplt.subplot(222)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_test[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10)\nplt.xlabel(Xlabelunit[1]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[1]); add_grid()  \nplt.xlim([Xmin[1],Xmax[1]]); plt.legend(loc='upper right')   \n\nplt.subplot(223)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_test[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10)\nplt.xlabel(ylabelunit); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(ytitle); add_grid()  \nplt.xlim([ymin,ymax]); plt.legend(loc='upper right')   \n\nplt.subplot(224)                                              # predictor features #1 and #2 scatter plot\nplt.scatter(df_train[Xname[0]],df_train[Xname[1]],s=40,marker='o',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10,label='Train')\nplt.scatter(df_test[Xname[0]],df_test[Xname[1]],s=40,marker='o',color = 'red',alpha = 0.8,edgecolor = 'black',zorder=10,label='Test')\nplt.title(Xlabel[0] + ' vs ' +  Xlabel[1])\nplt.xlabel(Xlabelunit[0]); plt.ylabel(Xlabelunit[1])\nplt.legend(); add_grid(); plt.xlim([Xmin[0],Xmax[0]]); plt.ylim([Xmin[1],Xmax[1]])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)\n#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') \nplt.show() \n```", "```py\nval_prop = 0.15; test_prop = 0.15                             # set the proportion of test data to withhold\nnbins = 20                                                    # number of histogram bins\n\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=val_prop + test_prop, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_prop/(val_prop + test_prop), random_state=42)\n\ndf_train = pd.concat([X_train,y_train],axis=1); df_val = pd.concat([X_val,y_val],axis=1); df_test = pd.concat([X_test,y_test],axis=1) \n\nplt.subplot(221)                                              # predictor feature #1 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_val[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Validate')\nfreq3,_,_ = plt.hist(x=df_test[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='blue',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10,freq3.max()*1.10)\nplt.xlabel(Xlabelunit[0]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[0]); add_grid()  \nplt.xlim([Xmin[0],Xmax[0]]); plt.legend(loc='upper right')   \n\nplt.subplot(222)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_val[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Validate')\nfreq3,_,_ = plt.hist(x=df_test[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='blue',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10,freq3.max()*1.10)\nplt.xlabel(Xlabelunit[1]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[1]); add_grid()  \nplt.xlim([Xmin[1],Xmax[1]]); plt.legend(loc='upper right')   \n\nplt.subplot(223)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_val[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Validate')\nfreq2,_,_ = plt.hist(x=df_test[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='blue',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10,freq3.max()*1.10)\nplt.xlabel(ylabelunit); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(ytitle); add_grid()  \nplt.xlim([ymin,ymax]); plt.legend(loc='upper right')   \n\nplt.subplot(224)                                              # predictor features #1 and #2 scatter plot\nplt.scatter(df_train[Xname[0]],df_train[Xname[1]],s=40,marker='o',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10,label='Train')\nplt.scatter(df_val[Xname[0]],df_val[Xname[1]],s=40,marker='o',color = 'blue',alpha = 0.8,edgecolor = 'black',zorder=10,label='Test')\nplt.scatter(df_test[Xname[0]],df_test[Xname[1]],s=40,marker='o',color = 'red',alpha = 0.8,edgecolor = 'black',zorder=10,label='Test')\nplt.title(Xlabel[0] + ' vs ' +  Xlabel[1])\nplt.xlabel(Xlabelunit[0]); plt.ylabel(Xlabelunit[1])\nplt.legend(); add_grid(); plt.xlim([Xmin[0],Xmax[0]]); plt.ylim([Xmin[1],Xmax[1]])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)\n#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') \nplt.show() \n```", "```py\nK = 4\nkf = KFold(n_splits=K, shuffle=True, random_state=seed)\n\ndf['Fold'] = -1\nfor fold_number, (train_index, test_index) in enumerate(kf.split(df)):\n    df.loc[test_index, 'Fold'] = fold_number  # Assign fold number to test set\n\nfor k in range(0,K):\n    df_in = df[df['Fold'] == k]; df_out = df[df['Fold'] != k]\n    plt.subplot(2,2,k+1)\n    plt.scatter(df_in[Xname[0]],df_in[Xname[1]],color='red',edgecolor='black',label='Test')\n    plt.scatter(df_out[Xname[0]],df_out[Xname[1]],color='white',edgecolor='black',label='Train'); add_grid()\n    plt.title('K-fold #' + str(k) + ', ' + Xlabel[0] + ' vs ' +  Xlabel[1])\n    plt.xlabel(Xlabelunit[0]); plt.ylabel(Xlabelunit[1])\n    plt.legend(); add_grid(); plt.xlim([Xmin[0],Xmax[0]]); plt.ylim([Xmin[1],Xmax[1]])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nignore_warnings = True\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\nfrom sklearn.model_selection import cross_val_score           # multi-processor K-fold crossvalidation\nfrom sklearn.model_selection import train_test_split          # train and test split\nfrom sklearn.model_selection import KFold                     # K-fold cross validation\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map\nseed = 42                                                     # random number seed \n```", "```py\ndef add_grid():\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\ndf = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv') # load data from Dr. Pyrcz's GitHub repository \n\nresponse = 'Prod'                                             # specify the response feature\nX = df.iloc[:,[1,3]]                                          # make predictor and response DataFrames\ny = df.loc[:,response]\n\nXname = X.columns.values.tolist()                             # store the names of the features\nyname = y.name\n\nXmin = [6.0,1.0]; Xmax = [24.0,5.0]                           # set the minimum and maximum values for plotting\nymin = 500.0; ymax = 9000.0\n\nXlabel = ['Porosity','Acoustic Impedance']\nylabel = 'Normalized Initial Production (MCFPD)'\n\nXtitle = ['Porosity','Acoustic Impedance']\nytitle = 'Normalized Initial Production'\n\nXunit = ['%',r'$kg/m^3 x m/s x 10^3$']; yunit = 'MCFPD'\nXlabelunit = [Xlabel[0] + ' (' + Xunit[0] + ')',Xlabel[1] + ' (' + Xunit[1] + ')']\nylabelunit = ylabel + ' (' + yunit + ')'\n\nm = len(pred) + 1\nmpred = len(pred) \n```", "```py\n---------------------------------------------------------------------------\nNameError  Traceback (most recent call last)\nCell In[3], line 23\n  20 Xlabelunit = [Xlabel[0] + ' (' + Xunit[0] + ')',Xlabel[1] + ' (' + Xunit[1] + ')']\n  21 ylabelunit = ylabel + ' (' + yunit + ')'\n---> 23 m = len(pred) + 1\n  24 mpred = len(pred)\n\nNameError: name 'pred' is not defined \n```", "```py\ntest_prop = 0.15                                              # set the proportion of test data to withhold\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_prop,random_state=73073) # train and test split\ndf_train = pd.concat([X_train,y_train],axis=1)                # make one train DataFrame with both X and y (remove all other features)\ndf_test = pd.concat([X_test,y_test],axis=1)                   # make one testin DataFrame with both X and y (remove all other features)\n\nnbins = 20                                                    # number of histogram bins\n\nplt.subplot(221)                                              # predictor feature #1 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_test[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10)\nplt.xlabel(Xlabelunit[0]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[0]); add_grid()  \nplt.xlim([Xmin[0],Xmax[0]]); plt.legend(loc='upper right')   \n\nplt.subplot(222)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_test[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10)\nplt.xlabel(Xlabelunit[1]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[1]); add_grid()  \nplt.xlim([Xmin[1],Xmax[1]]); plt.legend(loc='upper right')   \n\nplt.subplot(223)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_test[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10)\nplt.xlabel(ylabelunit); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(ytitle); add_grid()  \nplt.xlim([ymin,ymax]); plt.legend(loc='upper right')   \n\nplt.subplot(224)                                              # predictor features #1 and #2 scatter plot\nplt.scatter(df_train[Xname[0]],df_train[Xname[1]],s=40,marker='o',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10,label='Train')\nplt.scatter(df_test[Xname[0]],df_test[Xname[1]],s=40,marker='o',color = 'red',alpha = 0.8,edgecolor = 'black',zorder=10,label='Test')\nplt.title(Xlabel[0] + ' vs ' +  Xlabel[1])\nplt.xlabel(Xlabelunit[0]); plt.ylabel(Xlabelunit[1])\nplt.legend(); add_grid(); plt.xlim([Xmin[0],Xmax[0]]); plt.ylim([Xmin[1],Xmax[1]])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)\n#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') \nplt.show() \n```", "```py\nval_prop = 0.15; test_prop = 0.15                             # set the proportion of test data to withhold\nnbins = 20                                                    # number of histogram bins\n\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=val_prop + test_prop, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_prop/(val_prop + test_prop), random_state=42)\n\ndf_train = pd.concat([X_train,y_train],axis=1); df_val = pd.concat([X_val,y_val],axis=1); df_test = pd.concat([X_test,y_test],axis=1) \n\nplt.subplot(221)                                              # predictor feature #1 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_val[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Validate')\nfreq3,_,_ = plt.hist(x=df_test[Xname[0]],weights=None,bins=np.linspace(Xmin[0],Xmax[0],nbins),alpha = 0.6,\n                     edgecolor='black',color='blue',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10,freq3.max()*1.10)\nplt.xlabel(Xlabelunit[0]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[0]); add_grid()  \nplt.xlim([Xmin[0],Xmax[0]]); plt.legend(loc='upper right')   \n\nplt.subplot(222)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_val[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Validate')\nfreq3,_,_ = plt.hist(x=df_test[Xname[1]],weights=None,bins=np.linspace(Xmin[1],Xmax[1],nbins),alpha = 0.6,\n                     edgecolor='black',color='blue',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10,freq3.max()*1.10)\nplt.xlabel(Xlabelunit[1]); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(Xtitle[1]); add_grid()  \nplt.xlim([Xmin[1],Xmax[1]]); plt.legend(loc='upper right')   \n\nplt.subplot(223)                                              # predictor feature #2 histogram\nfreq1,_,_ = plt.hist(x=df_train[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='darkorange',density=False,label='Train')\nfreq2,_,_ = plt.hist(x=df_val[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='red',density=False,label='Validate')\nfreq2,_,_ = plt.hist(x=df_test[yname],weights=None,bins=np.linspace(ymin,ymax,nbins),alpha = 0.6,\n                     edgecolor='black',color='blue',density=False,label='Test')\nmax_freq = max(freq1.max()*1.10,freq2.max()*1.10,freq3.max()*1.10)\nplt.xlabel(ylabelunit); plt.ylabel('Frequency'); plt.ylim([0.0,max_freq]); plt.title(ytitle); add_grid()  \nplt.xlim([ymin,ymax]); plt.legend(loc='upper right')   \n\nplt.subplot(224)                                              # predictor features #1 and #2 scatter plot\nplt.scatter(df_train[Xname[0]],df_train[Xname[1]],s=40,marker='o',color = 'darkorange',alpha = 0.8,edgecolor = 'black',zorder=10,label='Train')\nplt.scatter(df_val[Xname[0]],df_val[Xname[1]],s=40,marker='o',color = 'blue',alpha = 0.8,edgecolor = 'black',zorder=10,label='Test')\nplt.scatter(df_test[Xname[0]],df_test[Xname[1]],s=40,marker='o',color = 'red',alpha = 0.8,edgecolor = 'black',zorder=10,label='Test')\nplt.title(Xlabel[0] + ' vs ' +  Xlabel[1])\nplt.xlabel(Xlabelunit[0]); plt.ylabel(Xlabelunit[1])\nplt.legend(); add_grid(); plt.xlim([Xmin[0],Xmax[0]]); plt.ylim([Xmin[1],Xmax[1]])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.3, hspace=0.2)\n#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf') \nplt.show() \n```", "```py\nK = 4\nkf = KFold(n_splits=K, shuffle=True, random_state=seed)\n\ndf['Fold'] = -1\nfor fold_number, (train_index, test_index) in enumerate(kf.split(df)):\n    df.loc[test_index, 'Fold'] = fold_number  # Assign fold number to test set\n\nfor k in range(0,K):\n    df_in = df[df['Fold'] == k]; df_out = df[df['Fold'] != k]\n    plt.subplot(2,2,k+1)\n    plt.scatter(df_in[Xname[0]],df_in[Xname[1]],color='red',edgecolor='black',label='Test')\n    plt.scatter(df_out[Xname[0]],df_out[Xname[1]],color='white',edgecolor='black',label='Train'); add_grid()\n    plt.title('K-fold #' + str(k) + ', ' + Xlabel[0] + ' vs ' +  Xlabel[1])\n    plt.xlabel(Xlabelunit[0]); plt.ylabel(Xlabelunit[1])\n    plt.legend(); add_grid(); plt.xlim([Xmin[0],Xmax[0]]); plt.ylim([Xmin[1],Xmax[1]])\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.2, hspace=0.2); plt.show() \n```"]