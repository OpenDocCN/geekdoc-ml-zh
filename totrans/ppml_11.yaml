- en: Chapter 5 Designing and Structuring Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章 设计和构建管道
- en: 原文：[https://ppml.dev/design-code.html](https://ppml.dev/design-code.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ppml.dev/design-code.html](https://ppml.dev/design-code.html)
- en: When we start writing a new piece of software, one of our first challenges is
    to identify its logical components and how they interact with each other. We can
    then *structure* our software into a series of modules, be they classes, libraries
    or completely separate programs, that implement those logical components in such
    a way as to make reasoning about the software as easy as possible. In other words,
    we *design* software to divide and conquer complexity into manageable chunks so
    that we only need to face a small fraction of it at any given time (Ousterhout
    [2018](#ref-philo)). Failure to do so quickly leads to software that is impossible
    to understand and to work on (Chapter [6](writing-code.html#writing-code)), which
    in turn makes it difficult to deploy (Chapter [7](deploying-code.html#deploying-code)),
    document (Chapter [8](documenting-code.html#documenting-code)), test or troubleshoot
    (Chapter [9](troubleshooting-code.html#troubleshooting-code)), and in general
    to keep running.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始编写新的软件时，我们面临的第一大挑战之一是确定其逻辑组件以及它们之间的交互方式。然后我们可以将我们的软件*结构化*为一系列模块，无论是类、库还是完全独立的程序，以便以尽可能简单的方式实现这些逻辑组件。换句话说，我们*设计*软件是为了将复杂性分解成可管理的块，这样我们只需在任何给定时间面对其中的一小部分（Ousterhout
    [2018](#ref-philo))。未能做到这一点会迅速导致软件难以理解和修改（第 [6](writing-code.html#writing-code)
    章），进而使得部署（第 [7](deploying-code.html#deploying-code) 章）、文档（第 [8](documenting-code.html#documenting-code)
    章）、测试或故障排除（第 [9](troubleshooting-code.html#troubleshooting-code) 章）变得困难，总的来说，难以保持运行。
- en: 'In this chapter we discuss the unique challenges that define machine learning
    software design: the role of data (Section [5.1](design-code.html#data-as-code)),
    the nature of technical debt (Section [5.2](design-code.html#technical-debt))
    and the anatomy of a machine learning pipeline (Section [5.3](design-code.html#processing-pipeline)).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论定义机器学习软件设计的独特挑战：数据的作用（第 [5.1](design-code.html#data-as-code) 节）、技术债务的本质（第
    [5.2](design-code.html#technical-debt) 节）以及机器学习管道的解剖结构（第 [5.3](design-code.html#processing-pipeline)
    节）。
- en: 5.1 Data as Code
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 数据作为代码
- en: '![The inversion of roles in machine learning software (right) compared to other
    software (left).](../Images/6221efc35fbad3a0e8b2a6aca4f3ff9d.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习软件中角色反转（右）与其他软件（左）的比较](../Images/6221efc35fbad3a0e8b2a6aca4f3ff9d.png)'
- en: 'Figure 5.1: The inversion of roles in machine learning software (right) compared
    to other software (left).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：机器学习软件中角色反转（右）与其他软件（左）的比较。
- en: 'Machine learning software is fundamentally different from most other software
    in one important respect: *it is tightly linked with data* (Arpteg et al. [2018](#ref-sweng-challenges)).
    The structure and the behaviour of a piece of traditional software[^(11)](#fn11)
    arise from some combination of processes gleaned from experts in the field, a
    specification of the desired output, and the set of technologies we can use to
    support its operations (Figure [5.1](design-code.html#fig:role-of-data), left).
    We are in charge of designing a software architecture that produces the desired
    behaviour. For instance, we structure web services to direct user navigation patterns
    through established procedures for different tasks, taking information retrieved
    from some database or from various vendor APIs and producing outputs to be consumed
    through some dashboard (by humans) or API (from other computer systems). Desktop
    applications do the same through windows and dialogs. Obviously, our freedom in
    designing software architectures is limited for good reasons (performance requirements,
    good practices and maintainability among them) as well as bad reasons (like less-than-ideal
    requirements, limitations in the chosen technological stack and unclear requirements)
    but this still leaves us a substantial amount of control.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习软件在一点上与其他大多数软件有根本的不同：*它与数据紧密相连*（Arpteg 等人 [2018](#ref-sweng-challenges)）。一块传统软件的结构和行为[^(11)](#fn11)源于从该领域专家那里获取的一些过程的组合，对期望输出的规范，以及我们可以用来支持其操作的技术集合（图
    [5.1](design-code.html#fig:role-of-data)，左侧）。我们负责设计产生所需行为的软件架构。例如，我们通过为不同任务建立程序来结构化网络服务，以指导用户导航模式，从某些数据库或各种供应商的
    API 中检索信息，并生成通过某些仪表板（由人类）或 API（来自其他计算机系统）消费的输出。桌面应用程序通过窗口和对话框做同样的事情。显然，出于良好的原因（如性能要求、良好实践和可维护性）以及不良的原因（如不理想的要求、所选技术栈的限制和模糊的要求），我们在设计软件架构方面的自由度是有限的，但这仍然给我们留下了相当大的控制权。
- en: 'On the other hand, the behaviour of machine learning software is dictated as
    much by the data we train our models on as it is by our design choices. We may
    decide how to measure model performance but the best performer will then be determined
    by the data: the distribution of the variables in the data and their probabilistic
    structure will be better captured by some models than others. So we may choose
    to try, say, random forests, deep neural networks and some hierarchical Bayesian
    model but, in the end, we will end up using the model that the data say is best
    regardless of our personal preferences. *The information in the data is compiled
    into the software* through the models, which program the software automatically:
    developers do not completely encode its behaviour in the code (Figure [5.1](design-code.html#fig:role-of-data),
    right).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，机器学习软件的行为既受我们训练模型所使用的数据的影响，也受我们的设计选择的影响。我们可能决定如何衡量模型性能，但最佳性能将由数据决定：数据中变量的分布及其概率结构将被某些模型比其他模型更好地捕捉。因此，我们可能会选择尝试，例如，随机森林、深度神经网络和一些层次贝叶斯模型，但最终，我们将使用数据表明最佳的那个模型，而不考虑我们的个人偏好。*数据中的信息通过模型编译到软件中*，这些模型自动编程软件：开发者并不完全在代码中编码其行为（图
    [5.1](design-code.html#fig:role-of-data)，右侧）。
- en: 'This realisation leads to a paradigm shift: *we should treat data as code*
    because data functionally replaces parts of our source code and because changes
    in the data may change the behaviour of the software. Hence we should *test the
    data* to ensure that their characteristics do not change over time (Section [5.2.1](design-code.html#data-debt)).
    After all, if the data change, our models may no longer be fit for purpose and
    we may have to retrain them to retain suitable levels of performance. In the case
    of offline data, this means that *data should be versioned along with the code*
    and that changes in either of them should trigger testing by continuous integration
    tools. In the case of online data, we should also implement a *real-time monitoring
    and logging* of the characteristics of new data and of the performance of the
    deployed models (Section [5.3.6](design-code.html#monitoring-pipeline)). Once
    we are confident that the data are as we expect them to be, we can use them to
    test that our software (the implementation) is behaving correctly and ensure that
    the models themselves are correctly specified (in their mathematical and probabilistic
    formulation). We will discuss the troubleshooting and testing of both data and
    machine learning models in more detail in the next section and in Chapter [9](troubleshooting-code.html#troubleshooting-code).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这一认识导致了一个范式转变：**我们应该将数据视为代码**，因为数据在功能上取代了我们源代码的一部分，并且数据的变化可能会改变软件的行为。因此，我们应该**测试数据**以确保其特征不会随时间改变（第[5.2.1](design-code.html#data-debt)节）。毕竟，如果数据发生变化，我们的模型可能不再适合使用，我们可能需要重新训练它们以保持适当的性能水平。在离线数据的情况下，这意味着**数据应该与代码一起进行版本控制**，并且它们中的任何变化都应触发持续集成工具的测试。在在线数据的情况下，我们还应该实施**实时监控和日志记录**新数据的特征和部署模型的性能（第[5.3.6](design-code.html#monitoring-pipeline)节）。一旦我们确信数据正如我们所期望的那样，我们就可以使用它们来测试我们的软件（实现）是否表现正确，并确保模型本身被正确指定（在其数学和概率公式中）。我们将在下一节和第[9](troubleshooting-code.html#troubleshooting-code)章中更详细地讨论数据和机器学习模型的故障排除和测试。
- en: Ideally, we should have a configuration management platform (often called an
    “experiment tracking” or “experiment management” platform in this context) using
    version control (Section [6.5](writing-code.html#versioning)) to track the hardware,
    the source code, the environment configurations, the parameters, the hyperparameters,
    the model characteristics, the input data and the outputs of all instances of
    model training and inference. (Including those we use to explore the data.) We
    can then tag the exact version of all the components used in each development
    and production environment, as we would do in a traditional software engineering
    setting. In turn, this means that we can (re)create any of those environments
    as needed, which makes automated deployments possible (Chapter [7](deploying-code.html#deploying-code))
    and greatly facilitates troubleshooting. Given the limited interpretability and
    explainability of most machine learning models, which are essentially black boxes,
    only a solution approaching a reproducible build setup (Humble and Farley [2011](#ref-devops))
    can hope to make in-depth debugging and root cause analyses possible.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们应该有一个配置管理平台（在这种情况下通常被称为“实验跟踪”或“实验管理”平台），使用版本控制（第[6.5](writing-code.html#versioning)节）来跟踪硬件、源代码、环境配置、参数、超参数、模型特征、输入数据和所有模型训练和推理实例的输出。（包括我们用来探索数据的那些。）然后我们可以为每个开发和生产环境中的所有组件标记确切的版本，就像在传统的软件工程环境中做的那样。反过来，这意味着我们可以（重新）创建任何这些环境，如需要，这使得自动化部署成为可能（第[7](deploying-code.html#deploying-code)章），并极大地简化了故障排除。鉴于大多数机器学习模型（本质上都是黑盒）的可解释性和可解释性有限，只有接近可重复构建设置（Humble
    and Farley [2011](#ref-devops)）的解决方案才能希望实现深入的调试和根本原因分析。
- en: 5.2 Technical Debt
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 技术债务
- en: 'Treating data as code means we should *consider data a potential source of
    technical debt*. Models can also be sources of technical debt because of their
    dependence on data and in their own right. In practice, the data and the models
    are dependencies of our machine learning code: like all dependencies, they are
    a potential liability and should be handled as such.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据视为代码意味着我们应该**考虑数据是潜在的技术债务来源**。由于模型依赖于数据，并且本身也是技术债务的来源，因此模型也可以是技术债务的来源。在实践中，数据和模型都是我们机器学习代码的依赖项：像所有依赖项一样，它们是潜在的负债，应该这样处理。
- en: 'The term “technical debt” has commonly had a negative connotation since it
    was first introduced (Cunningham [1992](#ref-debt92), [2011](#ref-debt11)): it
    highlights how hasty design choices can lead to unexpected costs, not only in
    purely economic terms, but by introducing latent complexity that makes the software
    more difficult to evolve over time. Technical debt allows us to produce results
    faster by trading quality for speed but, as with borrowed money, we must eventually
    pay it off with (compound) interest. It is unavoidable when tight deadlines reduce
    the time spent on analysis and design (Evans [2003](#ref-domain-driven)), leading
    to solutions that are suboptimal in terms of functionality, code quality or technical
    implementation. Establishing and following the practices we advocate in Part [**2**](design-code.html#)
    of this book is a good way of keeping it in check and of paying it off quickly
    enough to reduce it over time.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: “技术债务”这个术语自从首次被提出以来（Cunningham [1992](#ref-debt92), [2011](#ref-debt11)）通常带有负面含义：它强调了匆忙的设计选择如何导致意外的成本，这不仅从纯粹的经济角度出发，还通过引入潜在的复杂性，使得软件在随时间演进时更加困难。技术债务允许我们通过牺牲质量换取速度来更快地产生结果，但就像借来的钱一样，我们最终必须以（复利）利息的形式偿还它。当紧迫的截止日期减少了分析和设计所花费的时间（Evans
    [2003](#ref-domain-driven)），导致的功能、代码质量或技术实现方面的次优解决方案时，这是不可避免的。在本书的第二部分[**2**](design-code.html#)中建立并遵循我们倡导的实践是控制它并快速偿还以减少其时间的好方法。
- en: 'Machine learning models and the underlying training, testing and serving software
    infrastructure, which we will introduce in Section [5.3](design-code.html#processing-pipeline)
    as a *machine learning pipeline*, combine all the complexities of traditional
    software development with the issues arising from the experimental nature of data
    analysis. (More about this in Chapter [6](writing-code.html#writing-code).) Therefore,
    we find it useful to rethink the nature of technical debt in machine learning
    software in a unified, comprehensive way. We classify it into four broad areas:
    *data*, *model*, *architecture* (*design*) and *code* debt. These areas span issues
    both in various parts of the machine learning practice, such as data collection,
    data validation, feature extraction, data visualisation and observability; and
    in the software that we use to interact with machine learning models, such as
    monitoring, configurations, training and serving infrastructure. The libraries
    that power the models themselves, like PyTorch (Paszke et al. [2019](#ref-pytorch))
    or Scikit-learn (Scikit-learn Developers [2022](#ref-sklearn)), are typically
    very stable and we rarely find them to be a source of technical debt.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型及其底层的训练、测试和服务软件基础设施，我们将在第[5.3](design-code.html#processing-pipeline)节中将其称为*机器学习流水线*，结合了传统软件开发的所有复杂性以及数据分析实验性质产生的问题。（更多内容请见第[6](writing-code.html#writing-code)章。）因此，我们认为以统一、全面的方式重新思考机器学习软件中的技术债务性质是有用的。我们将它分为四个广泛的领域：*数据*、*模型*、*架构*（设计）和*代码*债务。这些领域涵盖了机器学习实践中各个部分的议题，例如数据收集、数据验证、特征提取、数据可视化和可观察性；以及我们用来与机器学习模型交互的软件，例如监控、配置、训练和服务基础设施。驱动模型的库，如PyTorch（Paszke等[2019](#ref-pytorch)）或Scikit-learn（Scikit-learn开发者[2022](#ref-sklearn)），通常非常稳定，我们很少发现它们是技术债务的来源。
- en: 5.2.1 At the Data Level
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 在数据层面
- en: 'Section [5.1](design-code.html#data-as-code) suggests that data can be a liability
    for three reasons. Firstly, they may originate from *untrusted sources*, either
    from in-house or from third-party systems. Data sources that are outside of our
    control or that do not have strict quality standards should be treated as an unknown
    quantity: data may unexpectedly change over time in shape (raw data structure
    or type change), in general quality (data duplication, missing data, null data
    or incorrectly normalised data) or in relevance and statistical properties (*data*
    or *concept drift*). This is particularly the case for online data that come in
    the form of event streams or that are generated by aggregating data from multiple
    sources. (More on that in Sections [9.1](troubleshooting-code.html#data-problems)
    and [9.4.3](troubleshooting-code.html#offline-vs-online).) In order to prevent
    such anomalies from affecting both the training of models and their subsequent
    use, we should only allow data that have been versioned and validated by our suite
    of software tests (Section [9.4](troubleshooting-code.html#testing)) to enter
    the machine learning pipeline. Systematic testing acts as a *quality gate* that
    the data must pass before entering later processing stages. Data drift will make
    models become *stale*: their accuracy will decrease as the data they will perform
    inference on become increasingly different from those that were used to train
    them (Gama et al. [2014](#ref-gama) is an extensive review of this topic). The
    same may happen if the general quality of the data degrades over time. Unless
    such changes are sudden enough and sharp enough, their effects will be difficult
    to detect without a test suite. This is what appears to have happened to Zillow
    (Sherman [2022](#ref-zillow)), the online real-estate company: the machine learning
    model they used to price properties to buy was trained on self-reported data,
    which were untrusted and difficult to validate, and it was left to overestimate
    prices for too long as the market cooled down. By the time the model was retired
    in 2021, Zillow had to sell between 60% and 85% of the properties it bought at
    a loss and fire 25% of its staff just to remain afloat.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第5.1节[设计代码](design-code.html#data-as-code)建议，数据可能因为三个原因成为负担。首先，它们可能来自*不受信任的来源*，无论是来自内部还是第三方系统。那些超出我们控制范围或没有严格质量标准的数据源应被视为未知量：数据可能会在形状（原始数据结构或类型变化）、总体质量（数据重复、缺失数据、空数据或错误归一化的数据）或相关性和统计属性（*数据*或*概念漂移*）上意外地随时间变化。这种情况对于以事件流形式出现或由聚合多个来源的数据生成的在线数据尤其如此。（更多内容请参阅第9.1节[代码故障排除](troubleshooting-code.html#data-problems)和第9.4.3节[离线与在线](troubleshooting-code.html#offline-vs-online)。）为了防止此类异常影响模型的训练及其后续使用，我们应仅允许经过我们的软件测试套件（第9.4节[代码故障排除](troubleshooting-code.html#testing)）版本化和验证的数据进入机器学习流程。系统测试充当数据必须通过的质量门，才能进入后续处理阶段。数据漂移会使模型变得*过时*：随着它们将要执行推理的数据与用于训练的数据越来越不同，其准确性将降低（Gama等人[2014](#ref-gama)对该主题进行了广泛的回顾）。如果数据的一般质量随时间下降，也可能发生同样的事情。除非这种变化足够突然且足够明显，否则没有测试套件很难检测到其影响。这似乎是Zillow（Sherman
    [2022](#ref-zillow)）在线房地产公司所发生的情况：他们用来为购买房产定价的机器学习模型是在自我报告的数据上训练的，这些数据不受信任且难以验证，随着市场冷却，它被用来过高估计价格的时间过长。到2021年模型退役时，Zillow不得不以亏损60%至85%的价格出售其购买的房产，并解雇25%的员工以维持运营。
- en: 'Secondly, data may originate from *untracked sources*: we should always take
    into account that third-party sources can be volatile and can also suddenly become
    unavailable. If that happens to a data source we are not aware we depend on, troubleshooting
    the resulting issues may be challenging. Furthermore, untracked sources are often
    untrusted as well, but unlike tracked sources they are not systematically versioned
    and validated: any issue they may have can potentially go unnoticed for long periods
    of time. In this context, where a piece of data comes from and how it was produced
    is called *data provenance* or *data lineage* (Cheney, Chiticariu, and Tan [209AD](#ref-provenance)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，数据可能来自*未追踪的来源*：我们应始终考虑到第三方来源可能是不稳定的，也可能突然变得不可用。如果这种情况发生在我们不知道我们依赖的数据源上，解决由此产生的问题可能具有挑战性。此外，未追踪的来源通常也不受信任，但与追踪来源不同，它们没有系统地版本化和验证：它们可能存在的问题可能长时间未被察觉。在这种情况下，数据来自何处以及它是如何产生的被称为*数据来源*或*数据血缘*（Cheney，Chiticariu和Tan
    [209AD](#ref-provenance)）。
- en: 'Finally, we may introduce in the data when we prepare them for use in the pipeline.
    In many applications, we can only collect *unlabelled data* that we have to annotate
    manually: this is an expensive, time-consuming and error-prone process that requires
    a team of domain experts. Automated labelling using machine learning models is
    a poor substitute as it is known to have 0.15–0.20 lower accuracy for both natural
    language processing and computer vision tasks (Wu et al. [2022](#ref-xiao)). The
    lack of ground truth labels makes it very difficult to spot these errors, which
    in turn impacts both other data quality controls and model training. Furthermore,
    manual labelling is too slow to allow us to monitor the outputs of the pipeline
    in real time, limiting our ability to detect data drift and model staleness. Hence
    this issue can produce technical debt at different levels in ways that are difficult
    to detect.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在准备数据以用于管道时可能会引入数据。在许多应用中，我们只能收集 *未标记数据*，我们必须手动进行标注：这是一个昂贵、耗时且易出错的流程，需要一支领域专家团队。使用机器学习模型进行自动标注是一个较差的替代方案，因为它已知在自然语言处理和计算机视觉任务中的准确性比已知低
    0.15–0.20（Wu 等人 [2022](#ref-xiao)）。缺乏真实标签使得很难发现这些错误，这反过来又影响了其他数据质量控制和模型训练。此外，手动标注速度太慢，使我们无法实时监控管道的输出，限制了检测数据漂移和模型过时的能力。因此，这个问题可能会在不同层面上产生难以检测的技术债务。
- en: 5.2.2 At the Model Level
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 在模型层面
- en: 'Issues with model performance, caused by data or otherwise, are unlikely to
    be limited to a single model. Consider data drift again: if any output of machine
    learning model `A` is used as an input to another machine learning model `B`,
    any degradation in accuracy in model `A` will propagate to model `B` and possibly
    be amplified in the process. As was the case with the data, we can detect such
    issues by using integration tests as quality gates to ensure that the inputs and
    the outputs of each model behave as expected. This is only possible if we track
    the dependencies between the models, for instance, by recording them as-code in
    the orchestrator configuration (Section [7.1.4](deploying-code.html#container-packaging))
    or by putting in place authentication and authorisation mechanisms to access models
    (say, with OAuth2 (ETF OAuth Working Group [2022](#ref-oauth2))).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由数据或其他原因引起的模型性能问题不太可能仅限于单个模型。再次考虑数据漂移：如果机器学习模型 `A` 的任何输出被用作另一个机器学习模型 `B` 的输入，模型
    `A` 的准确性下降将传播到模型 `B`，并且在过程中可能被放大。正如数据的情况一样，我们可以通过使用集成测试作为质量门来检测此类问题，以确保每个模型的输入和输出行为符合预期。这只有在我们跟踪模型之间的依赖关系时才可能实现，例如，通过在编排器配置中将它们记录为代码（第
    [7.1.4](deploying-code.html#container-packaging) 节）或通过实施认证和授权机制来访问模型（例如，使用 OAuth2（ETF
    OAuth 工作组 [2022](#ref-oauth2)））。
- en: 'Therefore, we can say that technical debt at the model level arises mainly
    from *feature and model entanglement*: any issue that impacts one model’s inference
    capabilities will propagate to all the downstream models that depend on it, directly
    or indirectly, in what is called a *correction cascade* (Section [9.1.2](troubleshooting-code.html#troubleshooting-heterogeneous-data)).
    Entanglement between features, between models, and between features and models
    is unavoidable in practical applications: “changing anything changes everything”
    (Sculley et al. [2014](#ref-high-interest)). Features are rarely completely independent
    of each other, and black-box models (Section [9.2.2](troubleshooting-code.html#troubleshooting-black-boxes))
    like deep neural networks deliberately “entangle them” in ways that are difficult
    to understand. Models are also entangled with each other because they consume
    each other’s outputs (Section [9.1.2](troubleshooting-code.html#troubleshooting-heterogeneous-data)).
    This complex interplay unfortunately means that it can be difficult to find the
    root causes of the issues we are troubleshooting even when we observe tell-tale
    signs that something is wrong (Section [9.3](troubleshooting-code.html#signs-of-trouble)).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以这样说，模型层面的技术债务主要源于*特征和模型纠缠*：任何影响一个模型推理能力的问题都会传播到所有依赖它的下游模型，无论是直接还是间接的，这被称为*纠正级联*（章节
    [9.1.2](troubleshooting-code.html#troubleshooting-heterogeneous-data)）。在实际应用中，特征之间、模型之间以及特征和模型之间的纠缠是不可避免的：“改变任何东西都会改变一切”（Sculley
    et al. [2014](#ref-high-interest)）。特征很少完全独立于彼此，而像深度神经网络这样的黑盒模型（章节 [9.2.2](troubleshooting-code.html#troubleshooting-black-boxes)）故意以难以理解的方式“纠缠”它们。模型之间也相互纠缠，因为它们消费彼此的输出（章节
    [9.1.2](troubleshooting-code.html#troubleshooting-heterogeneous-data)）。这种复杂的相互作用不幸地意味着，即使我们观察到一些明显的迹象表明有问题（章节
    [9.3](troubleshooting-code.html#signs-of-trouble)），我们可能也很难找到我们正在调试的问题的根本原因。
- en: 'On top of that, models are entangled with the real world: for instance, if
    the suggestions made by the model that drives a recommender system change, the
    behaviour of the system’s users will change in response. This creates a *feedback
    loop* because the users consume the model’s outputs and at the same time provide
    the data the model is trained on. Whether this is desirable or not depends on
    the specific application and on whether this feedback loop has a positive or negative
    effect: uncontrolled *direct feedback loops* can lead to an amplification of bias
    while artificially improving the model’s accuracy. Microsoft’s Tay chatbot (Hunt
    [2016](#ref-tay)) is a good case in point. Launched on Twitter in 2016 to “engage
    and entertain people through casual and playful conversation” while self-training
    from those conversations, it was shut down a few days later because every tweet
    it posted contained conspiracy theories or racist, inflammatory statements. (Maybe
    it maximised some abstract engagement metric in doing so?) *Hidden feedback loops*
    where machine learning models directly affect each other through exogenous events
    are also possible and harder to spot. Techniques such as reject inference (Crook
    and Banasik [2004](#ref-reject)) and contextual bandits (Dimakopoulou et al. [2018](#ref-bandits1),
    [2019](#ref-bandits2)), collecting feedback from users and domain experts (Sections
    [5.3.4](design-code.html#model-pipeline) and [5.3.5](design-code.html#production-pipeline))
    and including additional features can help to break such loops by exploring new
    models and by suggesting whether the current ones should be retrained.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型与现实世界相互纠缠：例如，如果驱动推荐系统的模型提出的建议发生变化，系统用户的反应也会随之改变。这形成了一个*反馈循环*，因为用户消费模型的输出，同时为模型提供训练数据。这是否可取取决于具体的应用以及这个反馈循环是否有积极或消极的影响：不受控制的*直接反馈循环*可能导致偏差的放大，同时人为地提高模型的准确性。微软的Tay聊天机器人（Hunt
    [2016](#ref-tay)）就是一个很好的例子。2016年在Twitter上推出，旨在“通过轻松愉快的对话参与和娱乐人们”的同时，从这些对话中自我训练，但几天后就被关闭，因为它发布的每条推文都包含阴谋论或种族主义、煽动性的言论。（也许它在这样做的同时最大化了一些抽象的参与度指标？）通过外生事件直接相互影响的*隐藏反馈循环*也是可能的，并且更难被发现。诸如拒绝推理（Crook
    and Banasik [2004](#ref-reject)）和上下文投币机（Dimakopoulou et al. [2018](#ref-bandits1)，[2019](#ref-bandits2)）等技术，从用户和领域专家那里收集反馈（章节
    [5.3.4](design-code.html#model-pipeline) 和 [5.3.5](design-code.html#production-pipeline)），以及包括额外的特征，可以通过探索新的模型并建议是否应该重新训练当前的模型来帮助打破这样的循环。
- en: 'Finally, models may be entangled with each other when we take a pre-trained
    model and we fine-tune it for different tasks. This practice reduces computational
    requirements and speeds up model development: we buy a pre-trained model `A` for
    a general task (say, object detection) and then use tightly-focused data sets
    to specialise it into models `B`, `C`, etc. for specific tasks (say, detecting
    impurities in the semi-finished products of an industrial process). However, models
    `B`, `C`, etc. are likely to inherit similar failure modes from `A`, thus introducing
    coupling between models with no tracked dependencies and producing unexpected
    correction cascades in the machine learning pipeline. Furthermore, models `B`,
    `C`, etc. become more difficult to evolve independently because any bug we fix
    in model `B` should also be fixed in models `A`, `C`, etc. (or confirmed not to
    affect them) and the software tests for all models should be updated at the same
    time. Similarly, any enhancement that is meaningful for model `B` is likely to
    be meaningful for models `A`, `C`, etc. as well. We can manage these issues by
    using a configuration management platform, as we pointed out in Section [5.1](design-code.html#data-as-code),
    to track dependencies between models and between models and data, to version them
    and to enable systematic testing (Section [9.4.2](troubleshooting-code.html#testing-what)).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们对一个预训练模型进行微调以适应不同的任务时，模型之间可能会相互纠缠。这种做法减少了计算需求并加快了模型开发速度：我们购买一个用于一般任务（例如，目标检测）的预训练模型
    `A`，然后使用高度专注的数据集将其专门化为针对特定任务（例如，检测工业过程半成品中的杂质）的模型 `B`、`C` 等。然而，模型 `B`、`C` 等很可能会从
    `A` 继承类似的故障模式，从而在无跟踪依赖关系的模型之间引入耦合，并在机器学习管道中产生意外的修正级联。此外，模型 `B`、`C` 等变得更加难以独立演进，因为我们在模型
    `B` 中修复的任何错误也应该在模型 `A`、`C` 等中修复（或确认不会影响它们），并且所有模型的软件测试应同时更新。同样，对模型 `B` 有意义的任何增强可能对模型
    `A`、`C` 等也有意义。我们可以通过使用配置管理平台来管理这些问题，正如我们在第 [5.1](design-code.html#data-as-code)
    节中指出的，以跟踪模型之间的依赖关系以及模型与数据之间的依赖关系，对它们进行版本控制，并启用系统测试（第 [9.4.2](troubleshooting-code.html#testing-what)
    节）。
- en: 5.2.3 At the Architecture (Design) Level
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 在架构（设计）层面
- en: 'The architecture of a machine learning pipeline directs how data and models
    interact to achieve its goals: it is implemented as an *orchestration system*
    that schedules and coordinates various tasks such as data ingestion, data validation,
    feature engineering, model training and validation, model deployment on production
    systems, and serving. We will discuss them in detail in Section [5.3](design-code.html#processing-pipeline).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道的架构指导数据与模型如何交互以实现其目标：它被实现为一个 *编排系统*，该系统安排和协调各种任务，如数据摄取、数据验证、特征工程、模型训练和验证、在生产系统上部署模型以及服务。我们将在第
    [5.3](design-code.html#processing-pipeline) 节中详细讨论这些内容。
- en: 'Machine learning pipelines are inherently complex systems with many moving
    parts, and they can easily hide *architecture* (*design*) *debt*. The key to keeping
    this type of technical debt in check is to *give visibility into all aspects of
    their configuration as code* using files in a human-readable data serialisation
    language like XML, YAML or JSON.[^(12)](#fn12) These files should be under version
    control in a configuration management solution along with the data (Section [5.1](design-code.html#data-as-code))
    and the models (Section [5.2.2](design-code.html#model-debt)), and for similar
    reasons. Each change in design can then be expressed in those configuration files
    or using environment variables. Configuration files should be used for parameters,
    options and settings for which we need complete versioning across iterations,
    such as data set locations, training hyperparameters and model parameters. These
    files can also be linked to and supplement architecture documentation, which describes
    the pipeline using the more accessible ubiquitous language (Section [8.3](documenting-code.html#designdocs)).
    Environment variables should be used to store runtime configurations such as log-levels
    (Section [5.3.6](design-code.html#monitoring-pipeline)), feature flags (Section
    [6.5](writing-code.html#versioning)) and the labels of target testing or production
    environments. Environment variables are also commonly used for secrets management,
    that is, to store credentials, certificates and other sensitive information. All
    modern software solutions to build machine learning pipelines provide mechanisms
    for configuring, overriding and exposing environment variables, including secrets.
    Only with a comprehensive formal description of the pipeline and of all its components
    we may be able to evolve and extend both over time without accidentally accruing
    architecture debt. Tracking and versioning the architecture along with the data
    and the models reduces the time spent on troubleshooting and debugging, and makes
    it possible to implement efficient deployment strategies (Section [7.2](deploying-code.html#deployment-strategies))
    and to roll back problematic models (Section [7.6](deploying-code.html#rollback)).
    The alternative is to perform these operations manually, which is time-consuming
    and error prone: Knight Capital (.Seven [2014](#ref-knights-capital)) proved that
    clearly to the world by burning $460 million in 45 minutes due to a botched manual
    deployment of their algorithmic trading software.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道本质上是具有许多动态部分的复杂系统，并且它们很容易隐藏*架构*（*设计*）*债务*。控制这种类型技术债务的关键是使用人类可读的数据序列化语言，如XML、YAML或JSON文件，*使所有配置方面都可见*。[^(12)](#fn12)
    这些文件应该在配置管理解决方案中与数据（第[5.1节](design-code.html#data-as-code)）和模型（第[5.2.2节](design-code.html#model-debt)）一起进行版本控制，以及出于类似原因。设计中的每个变化都可以在这些配置文件或使用环境变量中表达。配置文件应用于需要跨迭代完整版本控制的参数、选项和设置，例如数据集位置、训练超参数和模型参数。这些文件还可以链接到并补充架构文档，该文档使用更易于访问的通用语言描述管道（第[8.3节](documenting-code.html#designdocs)）。环境变量应用于存储运行时配置，如日志级别（第[5.3.6节](design-code.html#monitoring-pipeline)）、功能标志（第[6.5节](writing-code.html#versioning)）和目标测试或生产环境的标签。环境变量也常用于秘密管理，即存储凭证、证书和其他敏感信息。所有现代构建机器学习管道的软件解决方案都提供配置、覆盖和公开环境变量（包括秘密）的机制。只有通过全面的形式化描述管道及其所有组件，我们才可能在时间上不断发展和扩展，而不会意外地积累架构债务。跟踪和版本控制架构以及数据和模型可以减少在故障排除和调试上花费的时间，并使得实施高效的部署策略（第[7.2节](deploying-code.html#deployment-strategies)）和回滚有问题的模型（第[7.6节](deploying-code.html#rollback)）成为可能。另一种选择是手动执行这些操作，这既耗时又容易出错：Knight
    Capital（Seven [2014](#ref-knights-capital)）通过在45分钟内烧毁4.6亿美元，证明了这一点，这是由于他们算法交易软件的手动部署失败。
- en: Unfortunately, we cannot control and version models from third-party libraries
    or remote systems as easily as those we train ourselves. Hence we are left to
    integrate them by wrapping their APIs with *glue code* to interface them with
    the rest of the machine learning pipeline. Glue code is a piece of ad hoc code,
    often in the form of a one-off script, that has no function other than to adapt
    software that would otherwise be incompatible. It is a common source of technical
    debt both at the model level (if shipped in the model) and at the architecture
    level (if used to bind together different modules in non-standard ways) where
    it creates what is known as the “pipeline jungle” anti-pattern (Bogner, Verdecchia,
    and Gerostathopoulos [2021](#ref-technical-debt-mapping)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们无法像控制自己训练的模型那样轻松地控制和版本化第三方库或远程系统。因此，我们只能通过用 *粘合代码* 包装它们的API来将它们集成到机器学习管道的其余部分。粘合代码是一段临时代码，通常以一次性脚本的形式出现，其唯一功能就是使原本不兼容的软件兼容。它既是模型级别（如果包含在模型中）也是架构级别（如果以非标准方式将不同的模块绑定在一起）的技术债务的常见来源，它创造了所谓的“管道丛林”反模式（Bogner,
    Verdecchia, and Gerostathopoulos [2021](#ref-technical-debt-mapping))。
- en: 'Glue code is also commonly used to wrap libraries and remote APIs because it
    allows us to quickly expose them with new domain-specific names, interfaces and
    data structures (Section [8.2](documenting-code.html#apidocs)). While this practice
    may seem expedient, it can couple glue code tightly with what it is wrapping,
    causing it to break when the library or the remote API changes its public interface.
    We should only use glue code wrappers when we strictly need them, for example:
    to instrument a function for debugging purposes; to expose different versions
    or different features of the same library to different modules in the pipeline;
    or to integrate a legacy library or API that we would be otherwise unable to use.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 粘合代码也常用于包装库和远程API，因为它允许我们快速以新的领域特定名称、接口和数据结构公开它们（第[8.2](documenting-code.html#apidocs)节）。虽然这种做法可能看起来很方便，但它可能会将粘合代码与其包装的内容紧密耦合，导致当库或远程API更改其公共接口时，粘合代码会崩溃。我们只有在严格需要时才应使用粘合代码包装器，例如：为了调试目的对函数进行仪器化；为了向管道中的不同模块公开同一库的不同版本或不同功能；或者为了集成我们否则无法使用的遗留库或API。
- en: 5.2.4 At the Code Level
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 代码级别
- en: 'As for *code debt*, we should avoid mixing different versions of interpreters,
    programming languages and frameworks in the same machine learning pipeline. Unfortunately,
    this is a common issue for two reasons. Firstly, machine learning experts and
    data scientists often work in isolation, without a shared development environment.
    Secondly, microservices and similar architectures favour the use of multiple programming
    languages inside the same application in what they call *polyglot programming*.
    While it is often the case that different programming languages are better suited
    to different parts of a pipeline (Section [6.1](writing-code.html#programming-language)),
    having too much variety can lead to *organisational anti-patterns* like an unbalanced
    distribution of skills and skill levels (say, there is only one developer with
    expertise in a key framework) and inadequate knowledge transfer (because there
    are too many technologies to keep track of). From a practical standpoint, a good
    compromise is to build any new machine learning pipeline from a small, up-to-date
    set of technologies and to involve all developers when incorporating new ones.
    The latter should be done sparingly: resume-driven development rarely ends well.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 至于 *代码债务*，我们应该避免在同一个机器学习管道中混合不同的解释器、编程语言和框架的版本。不幸的是，这通常有两个原因。首先，机器学习专家和数据科学家通常独立工作，没有共享的开发环境。其次，微服务和类似架构倾向于在同一个应用程序中使用多种编程语言，这被称为
    *多语言编程*。虽然不同编程语言通常更适合管道的不同部分（第[6.1](writing-code.html#programming-language)节），但过多的多样性可能导致
    *组织反模式*，如技能和技能水平的不平衡分布（例如，只有一个开发者精通关键框架）以及知识转移不足（因为技术太多难以跟踪）。从实际的角度来看，一个好的折衷方案是从一个小型、最新的技术集构建任何新的机器学习管道，并在引入新技术时让所有开发者参与。后者应谨慎进行：简历驱动的开发很少会有好结果。
- en: A related problem is that of *vendoring software libraries*, that is, including
    the source code of a specific version of a third-party software in our codebase
    instead of managing it as an external library through a package manager. Vendored
    libraries become untracked dependencies (Section [6.3](writing-code.html#coding-standards)),
    are often integrated using glue code, and are problematic to update because package
    managers and other automated tooling are unaware of their existence.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 相关问题之一是**软件库的 vendoring**，即在我们的代码库中包含第三方软件特定版本的源代码，而不是通过包管理器将其作为外部库来管理。Vendored
    库成为未跟踪的依赖项（见第 [6.3](writing-code.html#coding-standards) 节），通常使用粘合代码进行集成，并且由于包管理器和其它自动化工具不知道它们的存在，更新起来很麻烦。
- en: Another source of code debt is the amount of exploration and experimentation
    involved in creating machine learning models. It can easily produce dead experimental
    code paths, which are usually badly documented by comments (Section [8.1](documenting-code.html#comments))
    and can lead to wasted effort as we try to achieve code coverage (Section [9.4.6](troubleshooting-code.html#test-coverage)).
    It can also limit the time we can spend on improving the quality of the code we
    produce from prototype to production level. Practices such as code review (Section
    [6.6](writing-code.html#code-review)) and constant refactoring (Section [6.7](writing-code.html#refactoring))
    can address both these issues, as we will discuss in the next chapter. They will
    also help in tackling low-quality code which, as a source of technical debt, significantly
    increases the number of bugs and the time required to fix them, slowing down development
    (Tornhill and Borg [2022](#ref-tornhill)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个导致代码债务的来源是在创建机器学习模型过程中涉及的大量探索和实验。它很容易产生无效的实验代码路径，这些路径通常通过注释（见第 [8.1](documenting-code.html#comments)
    节）进行糟糕的文档记录，并且在我们试图实现代码覆盖率（见第 [9.4.6](troubleshooting-code.html#test-coverage)
    节）时可能导致浪费精力。它还可能限制我们从原型到生产级别改进代码质量的时间。代码审查（见第 [6.6](writing-code.html#code-review)
    节）和持续重构（见第 [6.7](writing-code.html#refactoring) 节）等实践可以解决这两个问题，我们将在下一章中讨论。它们还将帮助解决低质量代码，作为技术债务的来源，显著增加了错误数量和修复它们所需的时间，从而减慢了开发速度（Tornhill
    和 Borg [2022](#ref-tornhill)）。
- en: 5.3 Machine Learning Pipeline
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 机器学习管道
- en: Modern software development schools like Agile (Beck et al. [2001](#ref-agile))
    and DevOps (Humble and Farley [2011](#ref-devops)) have pushed for the automation
    of testing, release management and deployment processes since the early 2000s,
    leading to the adoption of *continuous integration* / *continuous delivery* and
    *deployment* (CI/CD) solutions (Duvall, Matyas, and Glover [2007](#ref-cicd))
    to manage the software development life cycle. Continuous integration is the practice
    of developing code by committing small changes frequently to a version control
    repository. Each change is validated by an automated software testing solution,
    manually reviewed, and then integrated into the mainline branch the production
    builds are created from. As a result, the mainline branch is always in a working
    state and changes to the code are immediately visible to all developers. (More
    on that in Chapter [6](writing-code.html#writing-code).) Continuous delivery and
    continuous deployment focus on being able to release a working version of the
    software at any time and to deploy it on production systems. (More on that in
    Chapter [7](deploying-code.html#deploying-code).) In both cases, the emphasis
    is on using automated processes, versioning, configuration management, software
    testing and code review to enable an effortless, fast and reliable software development
    life cycle.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2000 年代初以来，像敏捷（Beck 等人 [2001](#ref-agile)）和 DevOps（Humble 和 Farley [2011](#ref-devops)）这样的现代软件开发学派一直在推动测试、发布管理和部署过程的自动化，这导致了**持续集成**/**持续交付**和**部署**（CI/CD）解决方案（Duvall,
    Matyas, 和 Glover [2007](#ref-cicd)）的采用，以管理软件开发生命周期。持续集成是通过频繁提交小更改到版本控制仓库来开发代码的实践。每个更改都通过自动软件测试解决方案进行验证，手动审查，然后集成到主线分支，生产构建就是从这个分支创建的。因此，主线分支始终处于工作状态，代码更改对所有开发者都是立即可见的。（更多内容请见第
    [6](writing-code.html#writing-code) 章。）持续交付和持续部署侧重于能够在任何时间发布软件的工作版本，并将其部署到生产系统上。（更多内容请见第
    [7](deploying-code.html#deploying-code) 章。）在这两种情况下，重点都是使用自动化流程、版本控制、配置管理、软件测试和代码审查来实现轻松、快速和可靠的软件开发生命周期。
- en: '![Life cycle of a machine learning pipeline.](../Images/49327be097cb9b8e87d715419cc5dac1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习管道的生命周期](../Images/49327be097cb9b8e87d715419cc5dac1.png)'
- en: 'Figure 5.2: Life cycle of a machine learning pipeline.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：机器学习管道的生命周期。
- en: 'Nowadays, we have many integrated CI/CD solutions to build machine learning
    pipelines (called “MLOps”). However, a complete understanding of how a pipeline
    works becomes crucial when its development evolves from a simple proof of concept
    running on some developer’s local environment into a larger piece of software
    managed by a team and running on multiple systems. (Most real-world pipelines
    are complex enough to require a team to manage them.) At first, we explore some
    sample data and we try different models to gauge their performance, spending little
    to no time on software tests. Developing a pipeline then becomes the iterative
    and increasingly complex process shown in Figure [5.2](design-code.html#fig:pipeline-lifecycle):
    feeding new data from the ingestion phase to existing models for validating, monitoring
    and troubleshooting them; generating new models as the data change; deploying
    models and serving them continuously to downstream models or to the application
    or service that users will access. This is what we call a *machine learning pipeline*:
    the codification of these steps into independent, reusable, modular parts that
    can be pipelined together to orchestrate the flow of data into, and outputs from,
    machine learning models.[^(13)](#fn13) MLOps practices standardise and automate
    how a pipeline is developed, giving us all the advantages that CI/CD brought to
    traditional software engineering, and builds on the same foundations: effective
    use of versioning, configuration management, automated testing, code review and
    automated deployments. Continuous integration, in addition to the testing and
    validation of code, now covers the testing and validation of the data and the
    models. Continuous delivery and continuous deployment expand to the production
    and deployment of the entire machine learning pipeline, again including the models.
    This extended definition of CI/CD allows us to focus on the development, testing
    and validation of the machine learning models, replacing homegrown solutions based
    on glue code with systematic solutions based on industry standards.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有许多集成的CI/CD解决方案来构建机器学习管道（称为“MLOps”）。然而，当管道的开发从运行在某个开发者本地环境中的简单概念验证演变为由团队管理的大型软件并在多个系统上运行时，对其工作方式的完整理解变得至关重要。（大多数实际管道都足够复杂，需要团队来管理。）起初，我们探索一些样本数据，并尝试不同的模型来评估它们的性能，在软件测试上花费很少或没有时间。然后，开发管道变成图[5.2](design-code.html#fig:pipeline-lifecycle)中所示的迭代和越来越复杂的过程：从摄取阶段向现有模型提供新数据以验证、监控和故障排除；随着数据的变化生成新模型；部署模型并持续将其提供给下游模型或用户将访问的应用程序或服务。这就是我们所说的*机器学习管道*：将这些步骤编码成独立的、可重用的、模块化的部分，可以将它们组合在一起以协调数据流入和流出机器学习模型的数据流。[^(13)](#fn13)
    MLOps实践标准化并自动化了管道的开发方式，为我们带来了CI/CD带给传统软件工程的全部优势，并建立在相同的基础上：有效使用版本控制、配置管理、自动化测试、代码审查和自动化部署。持续集成除了测试和验证代码外，现在还包括测试和验证数据和模型。持续交付和持续部署扩展到整个机器学习管道的生产和部署，再次包括模型。这种扩展的CI/CD定义使我们能够专注于机器学习模型的开发、测试和验证，用基于行业标准的系统解决方案取代基于粘合代码的自建解决方案。
- en: 'Figure [5.2](design-code.html#fig:pipeline-lifecycle) takes the software development
    life-cycle representation from Figure [1.2](intro.html#fig:software-life-cycle)
    and puts it into context. It shows the key logical steps of reproducible machine
    learning: what we should take care of to build a solid and maintainable pipeline.
    Some boxes represent development stages, some are actual pieces of software that
    will become modules in our pipeline, others are both. Broadly speaking, we can
    group the modules in a pipeline into four stages: *data ingestion* and *preparation*;
    *model training*, *evaluation* and *validation*; *model deployment* and *serving*;
    and *monitoring*, *logging* and *reporting*. How the functionality provided by
    each stage is split into modules is something that we can decide when we define
    the scope of the pipeline; we can then produce a baseline implementation to develop
    an understanding of its size and structure. However, well-established design principles
    from software engineering apply (Ousterhout [2018](#ref-philo); Thomas and Hunt
    [2019](#ref-pragpro)). Each module should do one thing and do it completely (the
    “Single Responsibility Principle”), encapsulating as much complexity as possible
    and abstracting it behind a simple interface (a “deep module”). Thus, we can keep
    the complexity of the pipeline in check by avoiding *change amplification* (making
    a simple change requires modifying code many different locations) and by reducing
    *cognitive load* (how much does a developer need to know in order to successfully
    make the change) as well as *unknown unknowns* (which parts of the code should
    be touched is not obvious). Simple interfaces are less likely to change: they
    also reduce coupling between the modules if we limit the number of dependencies
    and avoid common anti-patterns such as implicit constraints (say, functions should
    be called in a specific order) and pass-through variables containing all kinds
    of unrelated information (say, the whole global state in a context object). Simple
    interfaces should also reflect domain knowledge by exposing methods and data structures
    with domain meaning, with names taken from the ubiquitous language (Chapter [8](documenting-code.html#documenting-code))
    and with default settings that make common cases simple to implement. This approach
    is likely to result in a pipeline architecture patterned after the workflow of
    domain experts, which allows them to help validate models and inference outputs
    in a “human-in-the-loop” setup (Wu et al. [2022](#ref-xiao); Xin et al. [2018](#ref-xin)).
    Furthermore, a modular pipeline can be easily managed by an *orchestrator* which
    can deploy the modules (Chapter [7](deploying-code.html#deploying-code)), allocate
    them to systems with the appropriate hardware resources (Chapter [2](hardware.html#hardware))
    and control their execution.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [5.2](design-code.html#fig:pipeline-lifecycle) 从图 [1.2](intro.html#fig:software-life-cycle)
    中提取了软件开发生命周期的表示，并将其置于上下文中。它展示了可重复机器学习的关键逻辑步骤：我们应该注意哪些方面来构建一个稳固且可维护的流水线。一些方框代表开发阶段，一些是将成为我们流水线模块的实际软件组件，还有一些两者兼具。从广义上讲，我们可以将流水线中的模块分为四个阶段：*数据摄取*和*准备*；*模型训练*、*评估*和*验证*；*模型部署*和*服务*；以及*监控*、*日志记录*和*报告*。每个阶段提供的功能如何拆分为模块，是我们定义流水线范围时可以决定的事情；然后我们可以生成一个基线实现，以了解其规模和结构。然而，软件工程中确立的设计原则同样适用（Ousterhout
    [2018](#ref-philo)；Thomas and Hunt [2019](#ref-pragpro)）。每个模块应该只做一件事，并且做到完全（“单一职责原则”），封装尽可能多的复杂性，并通过一个简单的接口（“深度模块”）进行抽象。因此，我们可以通过避免*变更放大*（简单的更改需要修改代码的多个不同位置）和减少*认知负荷*（开发者需要知道多少才能成功进行更改）以及*未知未知*（哪些代码部分需要修改并不明显）来控制流水线的复杂性。简单的接口不太可能改变：如果我们限制依赖项的数量并避免常见的反模式，如隐式约束（例如，函数应按特定顺序调用）和包含各种无关信息的传递变量（例如，上下文对象中的整个全局状态），它们还可以减少模块之间的耦合。简单的接口还应通过暴露具有领域意义的方法和数据结构来反映领域知识，这些名称来自通用语言（第
    [8](documenting-code.html#documenting-code) 章）和具有使常见情况易于实现的默认设置。这种方法可能产生一个模仿领域专家工作流程的流水线架构，这允许他们在“人机交互”设置中帮助验证模型和推理输出（Wu
    et al. [2022](#ref-xiao)；Xin et al. [2018](#ref-xin)）。此外，模块化流水线可以很容易地由一个*编排器*管理，该编排器可以部署模块（第
    [7](deploying-code.html#deploying-code) 章）、将它们分配到具有适当硬件资源的系统（第 [2](hardware.html#hardware)
    章）并控制它们的执行。
- en: 5.3.1 Project Scoping
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 项目范围定义
- en: 'Starting from the top of Figure [5.2](design-code.html#fig:pipeline-lifecycle),
    the first step in building a machine learning pipeline is to understand the problem
    it should solve, what data it can use to do so, what outputs it should produce,
    and who its end users will be. To clarify these points, we should first identify
    who will be involved in developing the pipeline or will interact with it (the
    “stakeholders”): a combination of software developers, machine learning experts,
    domain experts and users. Together they will have all the information necessary
    to define the scope of the pipeline.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从图[5.2](design-code.html#fig:pipeline-lifecycle)的顶部开始，构建机器学习管道的第一步是理解它应该解决的问题、它可以使用哪些数据来完成这项任务、它应该产生什么输出，以及它的最终用户是谁。为了阐明这些点，我们首先应确定谁将参与开发管道或与之互动（即“利益相关者”）：软件开发者、机器学习专家、领域专家和用户。他们共同将拥有定义管道范围所需的所有信息。
- en: 'The process of scoping a machine learning pipeline and the underlying systems
    (Chapter [2](hardware.html#hardware)) involves the following steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 确定机器学习管道及其底层系统（第[2](hardware.html#hardware)章）的范围涉及以下步骤：
- en: '*Identifying the problem we want to solve:* the stakeholders should work together
    to explicitly define the problem that the pipeline should solve and to evaluate
    its impact. Domain experts should have a concrete business or academic need to
    address and, together with the other stakeholders, they should decide whether
    the problem is worth solving and whether solving it will be valuable to enough
    people. This process is much smoother if the domain experts have some familiarity
    with the classes of problems that can be effectively tackled with machine learning.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*确定我们想要解决的问题：*利益相关者应共同努力明确管道应解决的问题及其影响。领域专家应有一个具体的商业或学术需求需要解决，并且与其他利益相关者一起，他们应决定这个问题是否值得解决，以及解决它是否对足够多的人有价值。如果领域专家对可以使用机器学习有效解决的各类问题有所了解，这个过程会更加顺畅。'
- en: '*Identifying the targets we want to optimise for:* the stakeholders should
    decide what it means to have solved the problem successfully. To this end, the
    domain experts should set measurable domain metrics with achievable threshold
    values to define “success”. These metrics should be:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*确定我们想要优化的目标：*利益相关者应决定成功解决问题的含义。为此，领域专家应设定可衡量的领域指标和可实现的阈值值来定义“成功”。这些指标应包括：'
- en: comparable across different data, models and technical solutions to make it
    possible to contrast different pipeline implementations;
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同的数据、模型和技术解决方案之间具有可比性，以便对比不同的管道实现。
- en: easy to understand and to interpret;
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易理解和解释；
- en: simple enough that they can be collected in real-time for logging and monitoring
    (Section [5.3.6](design-code.html#monitoring-pipeline));
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 足够简单，可以实时收集以进行日志记录和监控（第[5.3.6](design-code.html#monitoring-pipeline)节）；
- en: actionable.
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可执行的。
- en: '*Identifying what data we need*: data are a critical component of a machine
    learning pipeline because they determine its performance (Section [5.1](design-code.html#data-as-code)).
    Therefore, it is essential to identify all the data sources we want to use, who
    owns them, and the technical details of how the data are stored (files, databases
    or data lakes) and structured (data schema). This allows us to track data provenance
    and reduce technical debt (Section [5.2.1](design-code.html#data-debt)). In particular,
    we should be wary about data sources that provide overlapping information because
    they introduce hidden dependencies in the pipeline. They can easily be inconsistent
    because of differences in their schemas (say, the same variable is scaled or discretised
    in different ways) and, even if they are consistent, they can diverge over time
    (say, one data source changes schema and the others do not). A common case is
    that of partially pre-processed data, which should always be reconciled with the
    raw data they originate from and stored in the same versioned repository. In addition,
    we should collect data following the best practices accumulated in decades of
    survey sampling (Lohr [2021](#ref-lohr); Groves et al. [2009](#ref-groves)) and
    experimental design (Montgomery [20AD](#ref-montgomery)) to make sure that the
    data we collect to train the machine learning models (Section [5.3.4](design-code.html#model-pipeline))
    are representative of the data the models will perform inference on (Section [5.3.5](design-code.html#production-pipeline)).
    Sampling bias can have unpredictable effects on the performance of the pipeline.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*确定我们需要的数据*：数据是机器学习流程的一个关键组成部分，因为它们决定了其性能（第[5.1节](design-code.html#data-as-code)）。因此，确定我们想要使用的所有数据源、它们的所有者以及数据存储（文件、数据库或数据湖）和结构（数据模式）的技术细节至关重要。这使我们能够跟踪数据来源并减少技术债务（第[5.2.1节](design-code.html#data-debt)）。特别是，我们应该警惕提供重叠信息的数据源，因为它们在流程中引入了隐藏的依赖关系。由于它们模式的不同（例如，相同的变量以不同的方式缩放或离散化），它们很容易不一致，即使它们是一致的，随着时间的推移也可能发生分歧（例如，一个数据源更改了模式，而其他没有）。一个常见的例子是部分预处理的
    数据，它们应该始终与它们起源的原始数据保持一致，并存储在同一个版本化的存储库中。此外，我们应该遵循几十年来在调查抽样（Lohr [2021](#ref-lohr)；Groves
    等人 [2009](#ref-groves)）和实验设计（Montgomery [20AD](#ref-montgomery)）中积累的最佳实践来收集数据，以确保我们收集的数据（第[5.3.4节](design-code.html#model-pipeline)）用于训练机器学习模型，能够代表模型将执行推理的数据（第[5.3.5节](design-code.html#production-pipeline)）。抽样偏差可能会对流程的性能产生不可预测的影响。'
- en: '*Analysis:* we should assess how much data we can collect and what variable
    types they will contain. With this information, we can start evaluating different
    models based on their sample size requirements, their probabilistic assumptions
    and the inference types they support (prediction, classification, etc.). As a
    general rule, it is always preferable to start with simpler models because they
    enable a fast feedback loop: if simple models cannot achieve our targets, we can
    move to more complex models and use the simpler ones as baselines. In addition,
    we should take into consideration:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分析*：我们应该评估我们可以收集多少数据以及它们将包含哪些变量类型。有了这些信息，我们可以开始评估不同的模型，基于它们的样本大小要求、它们的概率假设以及它们支持的推理类型（预测、分类等）。作为一个一般规则，始终从更简单的模型开始总是更可取，因为它们允许快速反馈循环：如果简单的模型无法达到我们的目标，我们可以转向更复杂的模型，并将简单的模型用作基线。此外，我们还应考虑以下因素：'
- en: The *robustness* of the model against the noise in the data, against model misspecification
    and adversarial attacks.
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型对数据噪声、模型误指定和对抗性攻击的*鲁棒性*。
- en: '*Interpretability* and *explainability*, that is, how well we can understand
    the behaviour and the outputs of the models. Some models are inherently interpretable
    either because of their simple structure (say, regression models) or because of
    their construction (say, Bayesian networks (Scutari and Denis [2021](#ref-scutari))).
    For others (say, deep neural networks), we can introduce auxiliary models to provide
    post hoc explanations: some of them are application-agnostic (Linardatos, Papastefanopoulos,
    and Kotsiantis [2021](#ref-explainability)) while others are specific to natural
    language processing (Li et al. [2016](#ref-nlp-viz)) or computer vision (Simonyan,
    Vedaldi, and Zisserman [2014](#ref-cv-viz)).'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**和**可解释性**，即我们理解模型行为和输出的程度。一些模型由于其简单的结构（例如，回归模型）或构建方式（例如，贝叶斯网络（Scutari和Denis
    [2021](#ref-scutari)））而内在可解释。对于其他模型（例如，深度神经网络），我们可以引入辅助模型来提供事后解释：其中一些是应用无关的（Linardatos，Papastefanopoulos和Kotsiantis
    [2021](#ref-explainability)），而另一些则专门针对自然语言处理（Li等人[2016](#ref-nlp-viz)）或计算机视觉（Simonyan，Vedaldi和Zisserman
    [2014](#ref-cv-viz)）。'
- en: 'The *fairness* of model outputs, which should not induce the machine learning
    pipeline to discriminate against individuals or groups based on sensitive attributes
    such as gender, race or age. While there is much literature on this topic (Mehrabi
    et al. [2021](#ref-fairness)), there is no consensus on how fairness should be
    measured. What there is consensus on is that machine learning models can easily
    incorporate the biases present in the data they are trained from. Therefore, we
    should consider carefully how the data are collected and we should constrain models
    to limit or disregard the discriminating effect of known sensitive attributes.
    Failures to do so have often ended in the news: Amazon’s sexist recruitment tool
    (BBC [2018](#ref-sexist-hr)), Facebook image recognition labelling black men as
    primates (BBC [2021](#ref-primates)[a](#ref-primates)) and Twitter’s racist preview
    cropping (BBC [2021](#ref-racist-preview)[b](#ref-racist-preview)) are just a
    few examples.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型输出的**公平性**，这不应该导致机器学习流程基于性别、种族或年龄等敏感属性歧视个人或群体。虽然关于这个主题的文献很多（Mehrabi等人[2021](#ref-fairness)），但对于如何衡量公平性并没有共识。大家普遍认同的是，机器学习模型可以轻易地吸收它们训练数据中存在的偏见。因此，我们应该仔细考虑数据的收集方式，并限制模型以限制或忽略已知敏感属性的歧视效应。未能做到这一点往往会导致新闻曝光：亚马逊的性别歧视招聘工具（BBC
    [2018](#ref-sexist-hr)）、Facebook图像识别实验室将黑人男子标记为灵长类动物（BBC [2021](#ref-primates)[a](#ref-primates)）和Twitter的种族主义预览裁剪（BBC
    [2021](#ref-racist-preview)[b](#ref-racist-preview)）只是其中几个例子。
- en: '*Privacy* and *security* concerns for sensitive data (Papernot et al. [2018](#ref-papernot)).
    Machine learning models excel at extracting useful information from data, but
    at the same time, they should protect privacy by not disclosing personally identifiable
    information. How to achieve that is an open problem, with research investigating
    approaches like differential privacy (Gong et al. [2020](#ref-differential-privacy)),
    defences against adversarial attacks and data re-identification (Narayanan and
    Shmatikov [2008](#ref-reid)), and distributed learning implementations such as
    federated learning (Li et al. [2021](#ref-federated)) and edge computing (Khan
    et al. [2019](#ref-edge)) (Section [2.3](hardware.html#hardware-cloud)).'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对敏感数据的**隐私**和**安全**问题（Papernot等人[2018](#ref-papernot)）。机器学习模型擅长从数据中提取有用信息，但与此同时，它们应该通过不披露个人信息来保护隐私。如何实现这一点是一个开放性问题，研究正在调查诸如差分隐私（Gong等人[2020](#ref-differential-privacy)）、对抗攻击防御和数据再识别（Narayanan和Shmatikov
    [2008](#ref-reid)）以及联邦学习（Li等人[2021](#ref-federated)）和边缘计算（Khan等人[2019](#ref-edge)）等分布式学习实现方法（第[2.3](hardware.html#hardware-cloud)节）。
- en: 'A machine learning pipeline typically spans several data sources and several
    models: as a result, we will iterate over these steps a few times depending on
    the nature of the project and of the organisation undertaking it. In the end,
    we will have the information we need to compile a mission statement document (Section
    [8.4](documenting-code.html#domaindocs)) and to sketch the layout of the architecture
    (Section [8.3](documenting-code.html#designdocs)) and of our software test suite
    (Section [9.4.1](troubleshooting-code.html#testing-goals)). The architecture is
    typically represented with a directed acyclic graph (DAG): see Figure [8.2](documenting-code.html#fig:uber-design)
    for an illustrative example. Each node will correspond to one of the modules in
    the pipeline, with incoming and outgoing arcs showing its inputs and outputs,
    respectively. The DAG therefore maps the paths of execution of the pipeline and
    the flow of data and information from data ingestion to training, inference and
    reporting. The DAG may be quite large for particularly complex pipelines: splitting
    it into smaller DAGs corresponding to different sections of the pipeline and working
    with them independently may be more convenient.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道通常跨越多个数据源和多个模型：因此，我们将根据项目的性质和执行该项目的组织的性质多次迭代这些步骤。最终，我们将拥有编制任务说明文档（第[8.4](documenting-code.html#domaindocs)节）和绘制架构布局（第[8.3](documenting-code.html#designdocs)节）以及我们的软件测试套件（第[9.4.1](troubleshooting-code.html#testing-goals)节）所需的信息。架构通常用有向无环图（DAG）表示：请参阅图[8.2](documenting-code.html#fig:uber-design)以了解一个说明性的例子。每个节点将对应于管道中的一个模块，输入和输出弧分别表示其输入和输出。因此，DAG映射了管道的执行路径以及从数据摄取到训练、推理和报告的数据和信息流。对于特别复杂的管道，DAG可能相当大：将其拆分为对应于管道不同部分的较小DAG，并独立地处理它们可能更方便。
- en: 5.3.2 Producing a Baseline Implementation
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 生成基线实现
- en: Data validation, model development, tuning, training and validation are initially
    explored by individual developers and machine learning experts on local hardware,
    if suitable hardware is available. After experimentation, they will eventually
    produce a minimal, working prototype of some part of the pipeline. This is often
    called a *baseline implementation* or *proof of concept*, and it will only involve
    the smallest amount of code that allows us to check whether we can achieve our
    targets.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有合适的硬件，数据验证、模型开发、调整、训练和验证最初由个别开发人员和机器学习专家在本地硬件上进行探索。经过实验后，他们最终将产生管道某一部分的最小、可工作的原型。这通常被称为*基线实现*或*概念验证*，它将只涉及允许我们检查是否能够实现目标的最小代码量。
- en: 'This initial exploration of the problem does not typically involve all the
    CI/CD development workflows discussed above and in Chapter [6](writing-code.html#writing-code):
    at this stage, the code and the models are too volatile. However, developers and
    machine learning experts should at least agree on a common, unified development
    environment (software dependencies management, build processes and configurations).
    This environment should be buildable in a reproducible and reliable way, which
    requires configuration management, and it should be as close as possible to our
    target production environment. For convenience, the development environment should
    be modular in the same way as the pipeline, so that we can run only the modules
    we are working on: it is typically impossible to run the whole pipeline on a developer
    workstation.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对问题的初步探索通常不涉及上述以及第[6](writing-code.html#writing-code)章中讨论的所有CI/CD开发工作流程：在这个阶段，代码和模型太不稳定。然而，开发人员和机器学习专家至少应该就一个共同、统一的开发环境（软件依赖关系管理、构建过程和配置）达成一致。这个环境应该以可重复和可靠的方式进行构建，这需要配置管理，并且它应该尽可能接近我们的目标生产环境。为了方便起见，开发环境应该像管道一样模块化，这样我们就可以只运行我们正在工作的模块：通常不可能在开发工作站的整个管道上运行。
- en: 'After checking that our proof of concept achieves all its targets, we then:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在确认我们的概念验证实现了所有目标之后，我们接下来：
- en: Construct a suite of software tests (Section [9.4.2](troubleshooting-code.html#testing-what))
    and push both to our version control repository to start taking advantage of continuous
    integration. We can then transform the proof of concept into production-quality
    code by gradually refactoring (Section [6.7](writing-code.html#refactoring)) and
    documenting it (Chapter [8](documenting-code.html#documenting-code)) with the
    help of code review (Section [6.6](writing-code.html#code-review)).
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一套软件测试（第[9.4.2节](troubleshooting-code.html#testing-what)）并将其推送到我们的版本控制仓库，以开始利用持续集成。然后，我们可以通过逐步重构（第[6.7节](writing-code.html#refactoring)）和编写文档（第[8章](documenting-code.html#documenting-code)）来帮助代码审查（第[6.6节](writing-code.html#code-review)），将概念验证逐步转化为生产质量的代码。
- en: Improve scalability. A proof of concept is typically built using a small fraction
    of the available data, so we must ensure that its computational complexity (Chapter
    [4](algorithms.html#algorithms)) is small enough to make learning and inference
    feasible in production when all data are used. Time complexity is important to
    allow for timely model retraining and for inference under latency constraints;
    space complexity must fit the machine learning systems (Chapter [2](hardware.html#hardware))
    we have available. If our development system is similar to the production systems,
    we can expect computational complexity to translate into practical performance
    in similar ways and predict the latter reliably.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提高可扩展性。通常，一个概念验证是通过使用可用数据的一小部分来构建的，因此我们必须确保其计算复杂度（第[4章](algorithms.html#algorithms)）足够小，以便在所有数据都用于生产时，学习和推理仍然是可行的。时间复杂度很重要，它允许及时重新训练模型以及在延迟约束下的推理；空间复杂度必须适合我们可用的机器学习系统（第[2章](hardware.html#hardware)）。如果我们的开发系统与生产系统相似，我们可以预期计算复杂度将以类似的方式转化为实际性能，并可靠地预测后者。
- en: 5.3.3 Data Ingestion and Preparation
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 数据摄取和准备
- en: 'After scoping the pipeline and producing a baseline implementation of its parts,
    we can start designing and implementing its modules in a more structured way.
    A machine learning pipeline is the formalisation of a data processing workflow.
    Therefore, the first part of the pipeline will comprise one or more *data ingestion*
    modules where we collect data from various sources such as relational databases,
    legacy OLTP/OLAP systems and modern in-house or cloud data lakes. These modules
    vary in nature depending on the machine learning systems the pipeline will run
    on: their design will be heavily influenced by factors such as data locality (Sections
    [2.2](hardware.html#hardware-using) and [2.3](hardware.html#hardware-cloud)),
    data provenance (Section [5.2.1](design-code.html#data-debt)), the availability
    of different types of storage (Section [2.1.2](hardware.html#hardware-memory))
    and compliance with privacy frameworks like HIPAA and FCRA in the United Stated
    or GDPR in Europe (Section [5.3.1](design-code.html#scoping-pipeline)).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定了管道的范围并实现了其部分的基础实现之后，我们可以以更结构化的方式开始设计和实现其模块。机器学习管道是数据处理工作流程的形式化。因此，管道的第一部分将包括一个或多个*数据摄取*模块，我们从各种来源收集数据，例如关系数据库、遗留的OLTP/OLAP系统以及现代内部或云数据湖。这些模块的性质取决于管道将运行的机器学习系统：它们的设计将受到诸如数据本地性（第[2.2节](hardware.html#hardware-using)和[2.3节](hardware.html#hardware-cloud)）、数据来源（第[5.2.1节](design-code.html#data-debt)）、不同类型存储的可用性（第[2.1.2节](hardware.html#hardware-memory)）以及符合美国HIPAA和FCRA或欧洲GDPR等隐私框架（第[5.3.1节](design-code.html#scoping-pipeline)）等因素的严重影响。
- en: Data ingestion is followed by *data preparation*. Preparing and cleaning the
    data is a hard but crucial step involving data scientists, domain experts and
    machine learning experts (Kenett and Redman [2019](#ref-kenett)). Modules for
    data preparation build on the exploratory analysis of the data used to produce
    the baseline implementation of the models, which is often limited to a high-level
    analysis of summary statistics, graphical visualisations and some basic feature
    selection. Their purpose is to clean and improve the quality of the data in the
    most automatic and reproducible way possible, making subsequent stages of the
    pipeline more reliable. In addition to validating the types, the acceptable values
    and the statistical distribution of each feature, data preparation modules should
    address the issues discussed in Section [9.1](troubleshooting-code.html#data-problems).
    They can also automate both feature selection and *feature engineering* (that
    is, the transformation of existing features into new ones that are better suited
    to model training or that are more meaningful in domain terms). Current software
    solutions for data and machine learning pipelines handle these tasks in a flexible
    way by taking as configuration arguments a processing function and a validation
    function that checks the properties of the now-clean data. The former may, for
    example, remove outliers, impute missing data and sort labels and features; the
    latter serves as a quality gate (Section [5.2.1](design-code.html#data-debt))
    and as the kernel of a property-based software test (Section [9.4.2](troubleshooting-code.html#testing-what)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 数据采集之后是*数据准备*。准备和清洗数据是一个艰难但至关重要的步骤，涉及数据科学家、领域专家和机器学习专家（Kenett和Redman [2019](#ref-kenett)）。数据准备模块建立在用于生成模型基线实现的探索性数据分析之上，这通常限于对汇总统计、图形可视化和一些基本特征选择的概述分析。它们的目的是以尽可能自动和可重复的方式清洗和提升数据质量，使管道的后续阶段更加可靠。除了验证每个特征的类型、可接受的值和统计分布之外，数据准备模块还应解决第[9.1](troubleshooting-code.html#data-problems)节中讨论的问题。它们还可以自动化特征选择和*特征工程*（即，将现有特征转换为更适合模型训练或从领域角度更有意义的新的特征）。当前的数据和机器学习管道的软件解决方案通过将处理函数和验证函数作为配置参数来灵活处理这些任务，这些函数检查现在已清洗的数据的性质。例如，前者可能移除异常值、填补缺失数据并对标签和特征进行排序；后者作为质量门（第[5.2.1](design-code.html#data-debt)节）和基于属性的软件测试的核心（第[9.4.2](troubleshooting-code.html#testing-what)节）。
- en: Finally, the data are split into multiple sets for later use as training, validation
    and test sets. (Making sure to avoid data leakage, see Section [9.3](troubleshooting-code.html#signs-of-trouble).)
    Each data set is tagged with information about its origin and with the version
    of the code that was used to extract and clean it, to track data provenance. These
    tags become part of our configuration management, and the data is stored as an
    artefact under versioning for later use.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，数据被分成多个集合，用于后续作为训练集、验证集和测试集。确保避免数据泄露，见第[9.3](troubleshooting-code.html#signs-of-trouble)节。）每个数据集都附有关于其来源的信息以及用于提取和清洗它的代码版本，以跟踪数据来源。这些标签成为我们配置管理的一部分，数据作为版本控制下的工件存储，以供后续使用。
- en: 5.3.4 Model Training, Evaluation and Validation
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.4 模型训练、评估和验证
- en: After ingestion and preparation, a machine learning pipeline passes the data
    either to *model training* modules or to *inference* modules (which we will discuss
    in Section [5.3.5](design-code.html#production-pipeline)). The trained models
    are then *evaluated* (on their statistical performance) and *validated* (in domain
    terms) using software tests and human expert judgement to ensure they are efficient,
    reproducible and scalable. Only models that perform sufficiently well in both
    statistical and domain terms will be considered suitable for deployment and serving.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在采集和准备之后，机器学习管道将数据传递给*模型训练*模块或*推理*模块（我们将在第[5.3.5](design-code.html#production-pipeline)节中讨论）。然后，使用软件测试和人类专家判断对训练好的模型进行*评估*（在统计性能方面）和*验证*（在领域术语中），以确保它们是高效、可重复和可扩展的。只有统计和领域方面都表现良好的模型才会被认为适合部署和服务。
- en: '*Training* a machine learning model consists in identifying an optimal instance
    in some model class (neural networks, random forests, etc.) by iteratively applying
    a combination of feature engineering, hyperparameter tuning and parameter optimisation.
    This is what the “learning” in “machine learning” refers to: a computer system
    is trained to learn a working model of some piece of the real world from the information
    contained in the data. The probabilistic techniques used for this purpose are
    specific to each model class and are beyond the scope of this book: see Kuhn and
    Johnson (M. Kuhn and Johnson [2013](#ref-kuhn)) for an approachable treatment
    of this topic. Training is a computationally demanding task, especially in the
    case of deep learning. The role of the pipeline is to schedule the training workload
    on compute systems with the appropriate hardware capabilities (as discussed in
    Section [2.4](hardware.html#hardware-choice)) and to monitor its progress. It
    should also simplify the parallel training of models with predefined, regular
    patterns of hyperparameters; and it should automate software tests implementing
    property-based testing of the model’s probabilistic properties (Section [9.4.2](troubleshooting-code.html#testing-what)).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练*一个机器学习模型包括通过迭代应用特征工程、超参数调整和参数优化组合，在某个模型类（神经网络、随机森林等）中识别一个最优实例。这正是“机器学习”中的“学习”所指：计算机系统被训练从数据中包含的信息学习现实世界某个部分的运行模型。为此目的所使用的概率技术针对每个模型类都是特定的，并且超出了本书的范围：有关此主题的易于理解的讨论，请参阅Kuhn和Johnson（M.
    Kuhn和Johnson [2013](#ref-kuhn)）。训练是一个计算密集型任务，尤其是在深度学习的情况下。管道的作用是在具有适当硬件能力的计算系统上安排训练工作负载（如第[2.4](hardware.html#hardware-choice)节所述），并监控其进度。它还应简化具有预定义、常规超参数模式的模型的并行训练；并且它应该自动化实现基于属性的模型概率属性测试的软件测试（第[9.4.2](troubleshooting-code.html#testing-what)节）。'
- en: Training can take quite different forms depending on the nature of the data
    (Section [9.4.3](troubleshooting-code.html#offline-vs-online)). In *static learning*,
    the model is trained from scratch on *cold* (offline) data selected to be representative
    of the data currently observed in production. Its statistical performance is then
    evaluated against either a separate set of cold data or a small stream of production
    data. In either case, the data should be labelled or validated by domain experts
    to address the issues discussed in Section [5.2.1](design-code.html#data-debt)
    and to maximise model quality. In *dynamic learning*, the model is continuously
    trained and evaluated on a live *stream* of (online) production data collected
    in real time. This requires fine-grained monitoring to be in place (Section [5.3.6](design-code.html#monitoring-pipeline)).
    If data drift is gradual, we may prevent the model from going stale by fine-tuning
    it (Gama et al. [2014](#ref-gama)). If, on the other hand, data drift is sudden,
    it may be preferable to retrain the model from scratch with a batch of recent
    data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据的性质，训练可以采取相当不同的形式（第[9.4.3](troubleshooting-code.html#offline-vs-online)节）。在*静态学习*中，模型从零开始在对当前生产中观察到的数据进行代表性选择的基础上，在*冷*（离线）数据上进行训练。然后，其统计性能与一组单独的冷数据或一小部分生产数据进行比较。在两种情况下，数据都应由领域专家进行标记或验证，以解决第[5.2.1](design-code.html#data-debt)节中讨论的问题，并最大化模型质量。在*动态学习*中，模型在实时收集的实时*流*生产数据上进行持续训练和评估。这需要实施细粒度监控（第[5.3.6](design-code.html#monitoring-pipeline)节）。如果数据漂移是渐进的，我们可能通过微调来防止模型过时（Gama等人[2014](#ref-gama)）。另一方面，如果数据漂移是突然的，可能更倾向于使用最近的数据批次从头开始重新训练模型。
- en: '*Model evaluation* modules check whether the predictive accuracy of the model
    the pipeline just trained is better in statistical terms than that of the corresponding
    model currently in production. To assess both simultaneously, we can perform a
    *canary deployment*: running the current and the new model in parallel on the
    same data to compare them directly. (More on this in Chapter [7](deploying-code.html#deploying-code).)
    In the case of streaming data, it is standard practice to use A/B testing (Amazon
    [2021](#ref-amazon-ab-testing); Zheng [2015](#ref-evaluatingml)) for this purpose,
    assigning new data points at random to either model. At the same time, we can
    check whether the new model is preferable to the current one in domain terms using
    the metrics we decided to optimise for (Section [5.3.1](design-code.html#scoping-pipeline)).
    We call this *model validation*, in contrast with the evaluation of the model
    in purely statistical terms. The two may be related because models with poor statistical
    properties will typically not encode the domain well enough for practical use.
    However, models with good statistical properties are not always of practical use
    either: in particular when the loss function the model is trained to minimise
    is too different from that implied by how costly prediction errors are in business
    or domain terms. In general, it is better to choose well-matched domain metrics
    and statistical accuracy measures for consistency. Unlike model evaluation, which
    can be automated to a large extent using software tests and continuous integration,
    model validation should involve domain experts. Even if we practise domain-driven
    development (Evans [2003](#ref-domain-driven)) and involve them in the design
    of the pipeline, in implementing it (Chapter [6](writing-code.html#writing-code))
    and in documenting it (Chapter [8](documenting-code.html#documenting-code)), there
    will always be some domain knowledge or intuition that they were not able to convey
    to developers and machine learning experts. As unscientific as it may sound, there
    is knowledge that is essentially impossible to put into numbers. Therefore, there
    will be issues we cannot write tests for, but that experts can “eyeball” and flag
    in model outputs because “they look wrong” and “do not quite make sense.” This
    approach is known as “human-in-the-loop” in the literature, and it is known to
    improve the quality of machine learning across tasks and application fields (Wu
    et al. [2022](#ref-xiao); Xin et al. [2018](#ref-xin)).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型评估*模块检查刚刚训练的模型的预测准确性在统计意义上是否优于当前生产中相应模型的准确性。为了同时评估这两个方面，我们可以执行一个*金丝雀部署*：在相同的数据上并行运行当前模型和新模型，以直接比较它们。（关于这一点，请参阅第[7章](deploying-code.html#deploying-code)。）在流数据的案例中，使用A/B测试（Amazon
    [2021](#ref-amazon-ab-testing)；Zheng [2015](#ref-evaluatingml)）是标准做法，随机将新数据点分配给任一模型。同时，我们可以使用我们决定优化的指标来检查新模型在领域方面是否优于当前模型（第[5.3.1节](design-code.html#scoping-pipeline)）。我们称之为*模型验证*，与仅从统计意义上评估模型相对。这两个方面可能相关，因为统计性能较差的模型通常不足以在实际应用中很好地编码领域知识。然而，统计性能良好的模型也不一定具有实际应用价值：特别是当模型训练以最小化的损失函数与业务或领域术语中预测错误成本所隐含的损失函数差异太大时。一般来说，选择匹配良好的领域指标和统计准确性度量以保持一致性更好。与可以通过软件测试和持续集成在很大程度上自动化的模型评估不同，模型验证应涉及领域专家。即使我们实践领域驱动开发（Evans
    [2003](#ref-domain-driven)）并将他们纳入管道的设计（第[6章](writing-code.html#writing-code)）、实施（第[6章](writing-code.html#writing-code)）和文档化（第[8章](documenting-code.html#documenting-code)），他们仍会存在一些领域知识或直觉，无法传达给开发人员和机器学习专家。尽管听起来不太科学，但有些知识基本上无法用数字表示。因此，将会有一些我们无法编写测试的问题，但专家可以通过“直观判断”并在模型输出中标记出来，因为“它们看起来不正确”和“不太合理。”这种做法在文献中被称为“人机交互”，并且已知它可以提高跨任务和应用领域的机器学习质量（Wu
    et al. [2022](#ref-xiao)；Xin et al. [2018](#ref-xin))。'
- en: 'When a model is finally found to perform well in both statistical and domain
    terms, the pipeline should trigger a CI/CD process to generate an *artefact* containing
    the model and all the relevant information from the training process. An artefact
    can be, from simple to complex:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型最终在统计和领域方面都表现出良好的性能时，管道应触发CI/CD过程，生成包含模型和训练过程中所有相关信息的*工件*。工件可以是简单的，也可以是复杂的：
- en: A (usually binary) file in a standardised format that will be stored and versioned
    in a general-purpose *artefact registry*. The format can be either model-independent,
    like ONNX (ONNX [2021](#ref-onnx)), or specific to the machine learning framework
    used for training.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个（通常是二进制）文件，以标准化格式存储并在通用**工件注册库**中版本化。该格式可以是模型无关的，如ONNX（ONNX [2021](#ref-onnx)），或者特定于用于训练的机器学习框架。
- en: A (usually Docker (Docker [2022](#ref-docker)[a](#ref-docker))) container that
    embeds the model and wraps it with application code that provides APIs for inference,
    health checking and monitoring. The container is then stored and versioned in
    a *container registry*.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个（通常是Docker（Docker [2022](#ref-docker)[a](#ref-docker)））容器，它嵌入模型并使用提供推理、健康检查和监控API的应用代码将其封装。然后，该容器被存储并版本化在**容器注册库**中。
- en: An annotated file uploaded to a *model registry* that provides experiment tracking,
    model serving, monitoring and comparison between models in addition to versioning.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个上传到**模型注册库**的带注释文件，它提供实验跟踪、模型服务、监控以及模型之间的版本比较。
- en: Platforms like GitHub and GitLab integrate both a general-purpose artefact registry
    (GitHub [2022](#ref-github-artefact)[b](#ref-github-artefact); GitLab [2022](#ref-gitlab-artefact)[a](#ref-gitlab-artefact))
    and a container registry (GitHub [2022](#ref-github-registry)[c](#ref-github-registry);
    GitLab [2022](#ref-gitlab-registry)[b](#ref-gitlab-registry)), as does Nexus (Sonatype
    [2022](#ref-nexus)). MLOps platforms like TensorFlow Extended (TFX) (TensorFlow
    [2021](#ref-tensorflow-extended)[b](#ref-tensorflow-extended)) implement experiment
    tracking and other machine-learning-specific features. We will return to this
    topic in Section [7.1](deploying-code.html#deployment-prep).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于GitHub和GitLab这样的平台集成了通用工件注册库（GitHub [2022](#ref-github-artefact)[b](#ref-github-artefact)；GitLab
    [2022](#ref-gitlab-artefact)[a](#ref-gitlab-artefact)）和容器注册库（GitHub [2022](#ref-github-registry)[c](#ref-github-registry)；GitLab
    [2022](#ref-gitlab-registry)[b](#ref-gitlab-registry)），Nexus（Sonatype [2022](#ref-nexus)）也是如此。像TensorFlow
    Extended (TFX)（TensorFlow [2021](#ref-tensorflow-extended)[b](#ref-tensorflow-extended)）这样的MLOps平台实现了实验跟踪和其他机器学习特定功能。我们将在第[7.1](deploying-code.html#deployment-prep)节中回到这个话题。
- en: 'Regardless of their form, artefacts should be *immutable*: they cannot be altered
    once generated so they can be used as the single source of truth for the model.
    Data artefacts (Section [5.3.3](design-code.html#data-pipeline)), code (Section
    [6.5](writing-code.html#versioning)) and often other software artefacts are also
    stored as immutable artefacts and versioned. When their versions are linked, we
    have a complete configuration management solution that allows for reproducible
    builds of any development, testing or production environment that has ever been
    used in the pipeline.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 不论其形式如何，工件应该是**不可变的**：一旦生成后就不能更改，这样它们就可以作为模型的唯一真相来源。数据工件（第[5.3.3](design-code.html#data-pipeline)节）、代码（第[6.5](writing-code.html#versioning)节）以及通常其他软件工件也作为不可变工件存储并版本化。当它们的版本被链接时，我们就有一个完整的配置管理解决方案，允许对管道中曾经使用过的任何开发、测试或生产环境进行可重复构建。
- en: 5.3.5 Deployment, Serving and Inference
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.5 部署、服务与推理
- en: 'Not all the artefacts we produce will be *deployed* immediately, or at all:
    continuous delivery only ensures that we are always ready to deploy our latest
    models. In academia, we cannot make any change to a pipeline halfway through a
    set of experiments without potentially introducing confounding in the results.
    In business, we may have service-level agreements with our customers that make
    it risky to deploy new models without a compelling reason to do so. Artefacts
    may also be found to be unsuitable for deployment for security reasons: for instance,
    we may find out that a container contains vulnerable dependencies or is misconfigured
    (Section [7.1.4](deploying-code.html#container-packaging)).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生产的并非所有工件都会立即**部署**，或者根本不会部署：持续交付只能确保我们始终准备好部署最新的模型。在学术界，我们无法在一系列实验中途对管道进行任何更改，否则可能会引入结果中的混淆。在商业领域，我们可能与客户签订了服务级别协议，这使得在没有充分理由的情况下部署新模型变得风险很高。工件也可能因安全原因被发现不适合部署：例如，我们可能会发现一个容器包含易受攻击的依赖项或配置错误（第[7.1.4](deploying-code.html#container-packaging)节）。
- en: 'Model deployment is not implemented as a module: rather, it is the part of
    the pipeline orchestration that enables models to be deployed to a target environment.
    Models deployed in production will be *served* so that users, applications or
    other models can access their inference capabilities. Models deployed to test
    environments will be evaluated by software tests and expert judgement, and those
    deployed to development environments can be used for troubleshooting bugs or further
    investigation of the data.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署不是作为一个模块实现的：相反，它是管道编排的一部分，使得模型能够部署到目标环境。在生产环境中部署的模型将被 *提供* 服务，以便用户、应用程序或其他模型可以访问其推理能力。部署到测试环境的模型将通过软件测试和专家判断进行评估，而部署到开发环境的模型可以用于调试错误或进一步调查数据。
- en: How a machine learning model is deployed depends on how it has been packaged
    into an artefact and on how it will be used. File artefacts can be either embedded
    in a software library that exposes inference methods locally or served “as-a-service”
    from a model registry using suitable remote APIs and protocols (such as RESTful
    or, when we need low latency, gRPC (Ganiev et al. [2021](#ref-ganiev))). Container
    artefacts can be deployed by all orchestration platforms in common use, which
    provide built-in monitoring and logging of hardware and software metrics (load,
    memory and I/O use) as well as troubleshooting facilities. Despite being intrinsically
    more complex, container artefacts are easier to deploy because they are ephemeral
    and highly portable, and because we can manage as-a-code both their runtime dependencies
    and configuration. We will develop this topic in detail in Sections [7.1.4](deploying-code.html#container-packaging)
    and [7.2](deploying-code.html#deployment-strategies) using Dockerfiles as a reference.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的部署方式取决于它如何被打包成工件以及如何使用。文件工件可以是嵌入到暴露本地推理方法的软件库中，或者通过合适的远程API和协议（如RESTful或，当我们需要低延迟时，gRPC（Ganiev等
    [2021](#ref-ganiev)）从模型注册表中提供“作为服务”。容器工件可以通过所有通用编排平台部署，这些平台提供内置的硬件和软件指标（负载、内存和I/O使用）监控以及故障排除设施。尽管容器工件本质上更复杂，但它们更容易部署，因为它们是短暂的且高度可移植的，并且我们可以以代码的方式管理它们的运行时依赖和配置。我们将在第
    [7.1.4](deploying-code.html#container-packaging) 节和 [7.2](deploying-code.html#deployment-strategies)
    节中详细讨论这一主题，以Dockerfile作为参考。
- en: 5.3.6 Monitoring, Logging and Reporting
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.6 监控、日志记录和报告
- en: '*Monitoring* modules collect the metrics we identified in the scoping phase
    (Section [5.3.1](design-code.html#scoping-pipeline)) to track at all times whether
    the pipeline achieves the required statistical and domain performance levels.
    The metrics should describe both the pipeline as a whole and individual modules
    to allow us to pinpoint the source of any issue we may have to troubleshoot. In
    particular:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*监控* 模块收集我们在范围阶段（第 [5.3.1](design-code.html#scoping-pipeline) 节）中确定的指标，以跟踪管道是否始终达到所需的统计和领域性能水平。这些指标应描述整个管道以及各个模块，以便我们能够确定任何可能需要解决的任何问题的来源。特别是：'
- en: 'Data ingestion and preparation modules (Section [5.3.3](design-code.html#data-pipeline)):
    we should monitor the same data metrics we check with property-based software
    tests to guard against data drift and data degradation.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据摄取和准备模块（第 [5.3.3](design-code.html#data-pipeline) 节）：我们应该监控与基于属性的软件测试中检查的相同数据指标，以防止数据漂移和数据退化。
- en: 'Training modules (Section [5.3.4](design-code.html#model-pipeline)): we should
    monitor the same metrics we use for model validation and evaluation consistently
    across all models in the pipeline to separate issues with individual models from
    issues arising from the data. Especially when using online data.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模块（第 [5.3.4](design-code.html#model-pipeline) 节）：我们应该一致地监控所有模型在管道中使用的相同指标，以区分单个模型的问题和数据引起的问题。特别是当使用在线数据时。
- en: 'Serving and inference modules (Section [5.3.5](design-code.html#production-pipeline)):
    we should monitor the same metrics we monitor during training to ensure that performance
    has not degraded over time (the so-called “training-serving skew”). And we should
    do that for all inference requests (possibly in small batches) so that we can
    guarantee that outputs are always in line with our targets. This is crucial to
    enable human-in-the-loop validation by domain experts for black-box models whose
    failure modes are mostly unknown and difficult to test.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务和推理模块（第 [5.3.5](design-code.html#production-pipeline) 节）：我们应该监控与训练期间相同的指标，以确保性能没有随时间退化（所谓的“训练-服务偏差”）。并且我们应该对所有推理请求（可能是在小批量中进行）进行监控，以确保输出始终与我们的目标保持一致。这对于通过领域专家进行人工验证黑盒模型至关重要，这些模型的故障模式大多未知且难以测试。
- en: 'The coverage of monitoring facilities is important for the same reason why
    test coverage is important: both are tasked to identify a broad range of issues
    with the data (Section [9.1](troubleshooting-code.html#data-problems)), with the
    models (Section [9.2](troubleshooting-code.html#model-problems)) and with the
    pipeline (Section [9.2.4](troubleshooting-code.html#troubleshooting-pipelines))
    with enough precision to allow for root-cause analyses. Software tests perform
    this function at development and deployment time; monitoring does it at runtime.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 监控设施的覆盖范围之所以重要，与测试覆盖范围之所以重要的原因相同：两者都负责识别数据（第 [9.1](troubleshooting-code.html#data-problems)
    节）、模型（第 [9.2](troubleshooting-code.html#model-problems) 节）和管道（第 [9.2.4](troubleshooting-code.html#troubleshooting-pipelines)
    节）的广泛问题，以足够的精确度进行根本原因分析。软件测试在开发和部署时执行此功能；监控在运行时执行此功能。
- en: In practice, we can implement monitoring with a client-server software such
    as Prometheus (Prometheus Authors and The Linux Foundation [2022](#ref-prometheus)).
    Each module in the pipeline produces all relevant metrics internally, tags them
    to track provenance (which module, and which instance of the module if we have
    multiple copies running in parallel) and makes them available in a structured
    format through the client interface. Monitoring modules then provide the corresponding
    server that pulls the metrics from all clients and saves them into an *event store*
    database. They will also filter the metrics, sanitise them, and run frequent checks
    for anomalies. If any is found, the monitoring modules can then trigger alerts
    and send failure reports to the appropriate people using, for instance, Alertmanager
    (which is part of Prometheus) or PagerDuty (PagerDuty [2022](#ref-pagerduty)).
    If our pipeline is sufficiently automated, we may also trigger model retraining
    automatically at the same time. This is the only way to address anomalies in a
    timely manner and to provide guarantees on the quality of the outputs of the pipeline.
    Cross-referencing the information in the event store to that in our configuration
    management system is invaluable in comparing the performance of our current production
    environment against that of past (now unavailable) environments. The same metrics
    may also be useful for troubleshooting infrastructure issues, like excessive consumption
    of computing resources, memory and I/O, as well service issues that impact downstream
    services and models, like readiness (whether a specific API is ready to accept
    requests) and excessive inference latency (how long it takes for the API to respond).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们可以使用Prometheus（Prometheus Authors and The Linux Foundation [2022](#ref-prometheus)）等客户端-服务器软件来实现监控。管道中的每个模块都会内部生成所有相关指标，将它们标记以跟踪来源（哪个模块，以及如果有多个副本并行运行，哪个模块的实例）并通过客户端接口以结构化格式提供。监控模块随后提供相应的服务器，从所有客户端拉取指标并将它们保存到*事件存储*数据库中。它们还将过滤指标，净化它们，并频繁检查异常。如果发现任何异常，监控模块可以触发警报并将故障报告发送给相关人员，例如使用Alertmanager（它是Prometheus的一部分）或PagerDuty（PagerDuty
    [2022](#ref-pagerduty)）。如果我们的管道足够自动化，我们还可以同时自动触发模型重新训练。这是及时处理异常并保证管道输出质量保证的唯一方法。将事件存储中的信息与我们的配置管理系统中的信息进行交叉引用，对于比较我们当前生产环境与过去（现在不可用）环境的性能非常有价值。相同的指标也可能有助于解决基础设施问题，如计算资源、内存和I/O的过度消耗，以及影响下游服务和模型的服务问题，如就绪状态（是否特定的API准备好接受请求）和过度的推理延迟（API响应所需的时间）。
- en: '*Logging* modules complement monitoring by recording relevant information about
    events that occur inside individual modules or within the pipeline orchestration,
    capturing exceptions and errors. Typically, at least part of a machine learning
    pipeline runs on remote systems: since we cannot access them directly, especially
    in the case of cloud instances (Section [2.3](hardware.html#hardware-cloud)),
    we are limited in our ability to debug and troubleshoot issues. Logging makes
    this problem less severe by recording what each module is doing in a sequence
    of timestamped *log messages*, ranging from simple plain-text messages (as we
    may produce ourselves) to more structured JSON or binary objects (from frameworks
    or language interpreters). Each log message has a “level” that determines its
    severity and that allows us to control how much we want to log for each module:
    for instance, a set of labels like `DEBUG`, `INFO`, `WARNING`, `ERROR`, and `CRITICAL`.
    Each log message is also tagged with its provenance, which allows us to distinguish
    between:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*日志*模块通过记录单个模块或管道编排中发生的事件的相关信息来补充监控，捕获异常和错误。通常，至少部分机器学习管道是在远程系统上运行的：由于我们无法直接访问它们，尤其是在云实例的情况下（第[2.3](hardware.html#hardware-cloud)节），我们在调试和解决问题方面的能力受到限制。通过记录每个模块在一系列带有时戳的*日志消息*中执行的操作，日志记录使这个问题不那么严重，这些消息从简单的纯文本消息（我们可能自己生成）到更结构化的JSON或二进制对象（来自框架或语言解释器）。每个日志消息都有一个“级别”，它决定了其严重性，并允许我们控制每个模块想要记录多少：例如，一组标签如`DEBUG`、`INFO`、`WARNING`、`ERROR`和`CRITICAL`。每个日志消息还带有其来源的标签，这允许我们区分：'
- en: system logs, which provide information on the load of the machine learning systems,
    the runtime environment and the versions of relevant dependencies;
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统日志，提供了有关机器学习系统负载、运行时环境和相关依赖项版本的信息。
- en: training logs, which describe the model structure, how well it fits the data
    and the values of its parameters and hyperparameters for each training iteration;
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练日志，描述了模型结构、其与数据的拟合程度以及每个训练迭代的参数和超参数的值；
- en: inference logs, which describe inputs, outputs, accuracy and latency for each
    request and each API.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理日志，描述了每个请求和每个API的输入、输出、准确率和延迟。
- en: 'Therefore, logs provide a measure of observability when we otherwise would
    have none: all modules should implement logging as much as monitoring. However,
    the more messages we generate, the more resources logging requires: which poses
    practical limits on how much we can afford to log, especially on production systems.
    In development environments, we may just append log messages to a file. In production
    environments, we should aggregate log messages from the whole pipeline to a remote
    log collector instead of locally. Log collectors can normalise log messages, make
    them easy to browse and make it possible to correlate events happening in different
    modules.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，日志在通常情况下提供了可观察性的度量：所有模块都应该尽可能多地实现日志记录，就像监控一样。然而，我们生成的消息越多，日志记录所需的资源就越多：这给我们可以负担的日志记录量设置了实际限制，尤其是在生产系统中。在开发环境中，我们可能只是将日志消息追加到文件中。在生产环境中，我们应该将整个管道的日志消息聚合到一个远程日志收集器，而不是本地。日志收集器可以标准化日志消息，使它们易于浏览，并使关联不同模块中发生的事件成为可能。
- en: 'Similar to monitoring modules, logging modules are implemented with a client-server
    software such as Fluentd (The Fluentd Project [2022](#ref-fluentd)) complemented
    by a search engine like Elasticsearch and a web frontend like Kibana (Elasticsearch
    [2022](#ref-elastic)). The two software stacks have some apparent similarities:
    both have a remote server aggregating information from clients inside the modules.
    The underlying reason for this architecture is that we should locate the server
    on a system that is completely separate from those the machine learning pipeline
    runs on: when the latter crashes and burns, we need to be able to access the information
    stored by monitoring and logging servers to investigate what its last known status
    was and decide how to best restore it.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 与监控模块类似，日志模块使用客户端-服务器软件（如Fluentd[Fluentd项目[2022](#ref-fluentd)]）实现，辅以搜索引擎（如Elasticsearch[2022](#ref-elastic)）和Web前端（如Kibana[2022](#ref-elastic)）。这两个软件堆栈有一些明显的相似之处：两者都有一个远程服务器从模块内部的客户端聚合信息。这种架构的潜在原因是，我们应该将服务器放置在一个完全独立于机器学习管道运行的系统上：当后者崩溃时，我们需要能够访问监控和日志服务器存储的信息，以调查其最后已知的状态并决定如何最佳地恢复它。
- en: 'However, monitoring and logging have two key technical differences. Firstly,
    logging should support unstructured data, whereas monitoring only handles data
    in the form of `{key, type, value}` triplets. Logging gives observability from
    outside the code we wrote to implement a module, reporting information that we
    do not produce directly and whose format we cannot necessarily control. Monitoring
    gives observability from the inside: we incorporate the client component into
    our code and we give it access to its internal state. Hence the information we
    expose to the monitoring server is necessarily structured in various data types
    and data structures (Chapter [3](types-structures.html#types-structures)). Secondly,
    logs are pushed from the clients to the servers as they are generated, whereas
    monitoring servers pull the metrics from the clients in the modules at regular
    intervals. Therefore, the databases used by the logging servers are general-purpose
    event stores, whereas those used for monitoring are optimised for time series
    data. The ability to access the internal state of all modules at regular intervals
    makes monitoring servers ideal for observing any gradual degradation in the machine
    learning pipeline.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，监控和日志记录有两个关键的技术差异。首先，日志记录应支持非结构化数据，而监控仅处理 `{key, type, value}` 三元组形式的数据。日志记录为我们编写的代码实现模块之外的观察性提供了信息，报告的信息是我们没有直接产生且其格式我们可能无法控制的信息。监控从内部提供观察性：我们将客户端组件集成到我们的代码中，并给它访问其内部状态的能力。因此，我们向监控服务器公开的信息必然以各种数据类型和数据结构进行结构化（第
    [3](types-structures.html#types-structures) 章）。其次，日志是随着生成而推送到服务器的，而监控服务器定期从模块的客户端拉取指标。因此，日志服务器使用的数据库是通用的事件存储，而用于监控的数据库是针对时间序列数据进行优化的。定期访问所有模块的内部状态的能力使监控服务器非常适合观察机器学习管道中的任何逐渐退化。
- en: '*Reporting* modules implement graphical interfaces that display the information
    collected by the monitoring and logging modules. Building on best practices from
    data science (Kenett and Redman [2019](#ref-kenett)), they provide web interfaces
    with intuitive, interactive *dashboards* that can be used by developers, machine
    learning experts and domain experts alike. Graphical displays in common use are:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*报告* 模块实现了图形界面，显示监控和日志记录模块收集的信息。基于数据科学领域的最佳实践（Kenett 和 Redman [2019](#ref-kenett)），它们提供了具有直观、交互式
    *仪表板* 的网络界面，这些界面可供开发者、机器学习专家和领域专家使用。常用的图形显示包括：'
- en: 'Data ingestion and preparation modules (Section [5.3.3](design-code.html#data-pipeline)):'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据摄取和准备模块（第 [5.3.3](design-code.html#data-pipeline) 节）：
- en: Plots of the empirical distribution both of individual features and of pairs
    of features against each other such as histograms, boxplots, heatmaps and pairwise
    scatterplots (for continuous features) or barplots and tileplots (for discrete
    features).
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验分布图，包括单个特征和特征对的分布，如直方图、箱线图、热图和成对散点图（对于连续特征）或条形图和镶嵌图（对于离散特征）。
- en: Plots of key summaries from minimal statistical models such as simple linear
    regressions to assess the magnitude and the sign of the relationships between
    features and to explore potential fairness issues.
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从简单的线性回归等最小统计模型中提取的关键摘要图，以评估特征之间关系的大小和符号，并探索潜在的公平性问题。
- en: 'Training modules (Section [5.3.4](design-code.html#model-pipeline)):'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模块（第 [5.3.4](design-code.html#model-pipeline) 节）：
- en: Plots of model performance over the course and at the end of the training process,
    like profile plots of the loss function against epochs for deep neural networks
    and heatmaps for confusion matrices produced by classification models.
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型性能在训练过程期间和结束时的情况图，例如深度神经网络损失函数随时间步长的轮廓图以及由分类模型生成的混淆矩阵的热图。
- en: Plots that help interpret the model behaviour, showing either its parameters
    or the outputs of explainability approaches like LIME (Ribeiro, Singh, and Guestrin
    [2016](#ref-lime)) and SHAP (Lundberg and Lee [2017](#ref-shap)).
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助解释模型行为的图，显示其参数或解释性方法（如 LIME（Ribeiro, Singh, 和 Guestrin [2016](#ref-lime)）和
    SHAP（Lundberg 和 Lee [2017](#ref-shap)））的输出。
- en: For less computationally-intensive models, interactive dashboards that can trigger
    model training, with sliders to pick hyperparameters on the fly.
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于计算密集度较低的模式，可以触发模型训练的交互式仪表板，带有滑块以动态选择超参数。
- en: 'Serving and inference modules (Section [5.3.5](design-code.html#production-pipeline)):'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务和推理模块（第 [5.3.5](design-code.html#production-pipeline) 节）：
- en: Plots of the empirical distribution of input data against historical data, to
    detect data drift.
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据的经验分布与历史数据的对比图，以检测数据漂移。
- en: Time series plots of the accuracy measures used in model validation and the
    metrics used for model evaluation, to detect when models become stale.
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于模型验证的准确度度量指标和用于模型评估的指标的时间序列图，以检测模型何时变得过时。
- en: Time series plots of latency and readiness.
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滞后和就绪状态的时间序列图。
- en: All plots should also include confidence intervals to convey the likely range
    of values for each of the quantities they display, wherever it makes sense.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图表也应包括置信区间，以传达它们显示的每个数量的可能值范围，只要合理。
- en: 'Domains like natural language processing and computer vision may require specialised
    graphical interfaces in addition to the above: for instance, visualising word
    relevance in natural language processing (Li et al. [2016](#ref-nlp-viz)) and
    pixel relevance in computer vision (Simonyan, Vedaldi, and Zisserman [2014](#ref-cv-viz))
    or splitting images into layers with semantic meaning (Ribeiro, Singh, and Guestrin
    [2016](#ref-lime)). Such interfaces can be very useful to involve domain experts
    in validating model training and the outputs from the inference modules. Instances
    that were not classified or predicted correctly can then be visually inspected,
    labelled and used to retrain the machine learning models.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 像自然语言处理和计算机视觉这样的领域可能除了上述内容外还需要专门的图形界面：例如，在自然语言处理中可视化词语的相关性（Li 等人 [2016](#ref-nlp-viz)）和在计算机视觉中可视化像素的相关性（Simonyan，Vedaldi
    和 Zisserman [2014](#ref-cv-viz)）或根据语义意义将图像分割成层（Ribeiro，Singh 和 Guestrin [2016](#ref-lime)）。这样的界面对于让领域专家参与验证模型训练和推理模块的输出非常有用。然后可以对未正确分类或预测的实例进行视觉检查、标记并用于重新训练机器学习模型。
- en: References
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: Amazon. 2021\. *Dynamic A/B Testing for Machine Learning Models with Amazon
    SageMaker MLOps Projects*. [https://aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/](https://aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon. 2021\. *Dynamic A/B Testing for Machine Learning Models with Amazon
    SageMaker MLOps Projects*. [https://aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/](https://aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/).
- en: Arpteg, A., B. Brinne, L. Crnkovic-Friis, and J. Bosch. 2018\. “Software Engineering
    Challenges of Deep Learning.” In *Euromicro Conference on Software Engineering
    and Advanced Applications*, 50–59\. IEEE.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Arpteg, A., B. Brinne, L. Crnkovic-Friis, and J. Bosch. 2018\. “Software Engineering
    Challenges of Deep Learning.” In *Euromicro Conference on Software Engineering
    and Advanced Applications*, 50–59\. IEEE.
- en: BBC. 2018\. *Amazon Scrapped “Sexist AI” Tool*. [https://www.bbc.com/news/technology-45809919](https://www.bbc.com/news/technology-45809919).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: BBC. 2018\. *Amazon Scrapped “Sexist AI” Tool*. [https://www.bbc.com/news/technology-45809919](https://www.bbc.com/news/technology-45809919).
- en: BBC. 2021a. *Facebook Apology as AI Labels Black Men “Primates”*. [https://www.bbc.com/news/technology-58462511](https://www.bbc.com/news/technology-58462511).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: BBC. 2021a. *Facebook Apology as AI Labels Black Men “Primates”*. [https://www.bbc.com/news/technology-58462511](https://www.bbc.com/news/technology-58462511).
- en: BBC. 2021b. *Twitter Finds Racial Bias in Image-Cropping AI*. [https://www.bbc.com/news/technology-57192898](https://www.bbc.com/news/technology-57192898).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: BBC. 2021b. *Twitter Finds Racial Bias in Image-Cropping AI*. [https://www.bbc.com/news/technology-57192898](https://www.bbc.com/news/technology-57192898).
- en: Beck, K., M. Beedle, A. Van Bennekum, A. Cockburn, W. Cunningham, M. Fowler,
    J. Grenning, et al. 2001\. *The Agile Manifesto*. [https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf](https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Beck, K., M. Beedle, A. Van Bennekum, A. Cockburn, W. Cunningham, M. Fowler,
    J. Grenning, et al. 2001\. *The Agile Manifesto*. [https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf](https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf).
- en: 'Bogner, J., R. Verdecchia, and I. Gerostathopoulos. 2021\. “Characterizing
    Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study.”
    In *2021 IEEE/ACM International Conference on Technical Debt (TechDebt)*, 64–73.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 'Bogner, J., R. Verdecchia, and I. Gerostathopoulos. 2021\. “Characterizing
    Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study.”
    In *2021 IEEE/ACM International Conference on Technical Debt (TechDebt)*, 64–73.'
- en: 'Cheney, J., L. Chiticariu, and W.-C. Tan. 209AD. “Provenance in Databases:
    Why, How and Where.” *Foundations and Trends in Databases* 1 (4): 379–474.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 'Cheney, J., L. Chiticariu, and W.-C. Tan. 209AD. “Provenance in Databases:
    Why, How and Where.” *Foundations and Trends in Databases* 1 (4): 379–474.'
- en: 'Crook, J., and J. Banasik. 2004\. “Does Reject Inference Really Improve the
    Performance of Application Scoring Models?” *Journal of Banking and Finance* 28:
    857–74.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 'Crook, J., 和 J. Banasik. 2004\. “拒绝推断是否真的提高了应用评分模型的性能？” *银行与金融杂志* 28: 857–74.'
- en: Cunningham, W. 1992\. “The WyCash Portfolio Management System.” In *Addendum
    to the Proceedings of ACM Object-Oriented Programming, Systems, Languages & Applications
    Conference*, 29–30.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Cunningham, W. 1992\. “WyCash投资组合管理系统补充。” 在 *ACM面向对象编程、系统、语言与应用会议补充程序* 中，第29-30页。
- en: Cunningham, W. 2011\. *Ward Explains the Debt Metaphor*. [https://wiki.c2.com/?WardExplainsDebtMetaphor](https://wiki.c2.com/?WardExplainsDebtMetaphor).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Cunningham, W. 2011\. *沃德解释债务隐喻*. [https://wiki.c2.com/?WardExplainsDebtMetaphor](https://wiki.c2.com/?WardExplainsDebtMetaphor).
- en: Dimakopoulou, M., Z. Zhou, S. Athey, and G. Imbens. 2018\. *Estimation Considerations
    in Contextual Bandits*. [https://arxiv.org/abs/1711.07077](https://arxiv.org/abs/1711.07077).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Dimakopoulou, M., Z. Zhou, S. Athey, 和 G. Imbens. 2018\. *情境性赌博中的估计考虑*. [https://arxiv.org/abs/1711.07077](https://arxiv.org/abs/1711.07077).
- en: Dimakopoulou, M., Z. Zhou, S. Athey, and G. Imbens. 2018\. *Estimation Considerations
    in Contextual Bandits*. [https://arxiv.org/abs/1711.07077](https://arxiv.org/abs/1711.07077).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Dimakopoulou, M., Z. Zhou, S. Athey, 和 G. Imbens. 2018\. *情境性赌博中的估计考虑*. [https://arxiv.org/abs/1711.07077](https://arxiv.org/abs/1711.07077).
- en: 2019\. “Balanced Linear Contextual Bandits.” In *Proceedings of the AAAI Conference
    on Artificial Intelligence*, 3445–53.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 2019\. “平衡线性情境性赌博。” 在 *AAAI人工智能会议论文集* 中，第3445–53页。
- en: Docker. 2022a. *Docker*. [https://www.docker.com/](https://www.docker.com/).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Docker. 2022a. *Docker*. [https://www.docker.com/](https://www.docker.com/).
- en: 'Duvall, P. M., S. Matyas, and A. Glover. 2007\. *Continuous Integration: Improving
    Software Quality and Reducing Risk*. Addison-Wesley.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Duvall, P. M., S. Matyas, 和 A. Glover. 2007\. *持续集成：提高软件质量和降低风险*. Addison-Wesley.
- en: 'Elasticsearch. 2022\. *Free and Open Search: The Creators of Elasticsearch,
    ELK & Kibana*. [https://www.elastic.co/](https://www.elastic.co/).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch. 2022\. *免费和开源搜索：Elasticsearch、ELK和Kibana的创造者*. [https://www.elastic.co/](https://www.elastic.co/).
- en: ETF OAuth Working Group. 2022\. *OAuth 2.0*. [https://oauth.net/2/](https://oauth.net/2/).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ETF OAuth工作组. 2022\. *OAuth 2.0*. [https://oauth.net/2/](https://oauth.net/2/).
- en: 'Evans, E. 2003\. *Domain-Driven Design: Tackling Complexity in the Heart of
    Software*. Addison-Wesley.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Evans, E. 2003\. *领域驱动设计：软件核心的复杂性处理*. Addison-Wesley.
- en: 'Gama, J., I. Žliobaitè, A. Bifet, M. Pechenizkiy, and A. Bouchachia. 2014\.
    “A Survey on Concept Drift Adaptation.” *ACM Computing Surveys* 46 (4): 44.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 'Gama, J., I. Žliobaitè, A. Bifet, M. Pechenizkiy, 和 A. Bouchachia. 2014\. “关于概念漂移适应的综述。”
    *ACM计算调查* 46 (4): 44.'
- en: Ganiev, A., C. Chapin, A. Andrade, and C. Liu. 2021\. “An Architecture for Accelerated
    Large-Scale Inference of Transformer-Based Language Models.” In *Proceedings of
    the 2021 Conference of the North American Chapter of the Association for Computational
    Linguistics*, 163–69.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Ganiev, A., C. Chapin, A. Andrade, 和 C. Liu. 2021\. “用于加速基于Transformer的语言模型大规模推理的架构。”
    在 *北美计算语言学协会2021年会议论文集* 中，第163–69页。
- en: GitHub. 2022b. *Storing Workflow Data as Artifacts*. [https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts](https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub. 2022b. *将工作流程数据存储为工件*. [https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts](https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts).
- en: GitHub. 2022c. *Working with the Container Registry*. [https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub. 2022c. *与容器注册库一起工作*. [https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry).
- en: GitLab. 2022a. *GitLab Artifacts*.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: GitLab. 2022a. *GitLab工件*.
- en: GitLab. 2022b. *GitLab Container Registry*. [https://docs.gitlab.com/ee/user/packages/container_registry/](https://docs.gitlab.com/ee/user/packages/container_registry/).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: GitLab. 2022b. *GitLab容器注册库*. [https://docs.gitlab.com/ee/user/packages/container_registry/](https://docs.gitlab.com/ee/user/packages/container_registry/).
- en: 'Gong, M., Y. Xie, K. Pan, and K. Feng. 2020\. “A Survey on Differentially Private
    Machine Learning.” *IEEE Computational Intelligence Magazine* 15 (2): 49–64.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 'Gong, M., Y. Xie, K. Pan, 和 K. Feng. 2020\. “关于差分隐私机器学习的综述。” *IEEE计算智能杂志* 15
    (2): 49–64.'
- en: Groves, R. M., F. J. Fowler, M. P. Couper, J. M. Lepkowski, E. Singer, and R.
    Tourangeau. 2009\. *Survey Methodology*. Wiley.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Groves, R. M., F. J. Fowler, M. P. Couper, J. M. Lepkowski, E. Singer, 和 R.
    Tourangeau. 2009\. *调查方法*. Wiley.
- en: Humble, J., and D. Farley. 2011\. *Continuous Delivery*. Addison Wesley.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Humble, J., and D. Farley. 2011\. *持续交付*. Addison Wesley.
- en: Hunt, E. 2016\. *Tay, Microsoft’s AI Chatbot, Gets a Crash Course in Racism
    from Twitter*. [https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter](https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Hunt, E. 2016\. *泰，微软的AI聊天机器人，从推特上接受了种族主义的速成课程*. [https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter](https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter).
- en: Kenett, R. S., and T. C. Redman. 2019\. *The Real Work of Data Science*. Wiley.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Kenett, R. S., and T. C. Redman. 2019\. *数据科学的真实工作*. Wiley.
- en: 'Khan, W. Z., E. Ahmed, S. Hakak, I. Yaqoob, and A. Ahmed. 2019\. “Edge Computing:
    A Survey.” *Future Generation Computer Systems* 97: 219–35.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 'Khan, W. Z., E. Ahmed, S. Hakak, I. Yaqoob, and A. Ahmed. 2019\. “边缘计算：综述.”
    *未来计算机系统* 97: 219–35.'
- en: Kuhn, M., and K. Johnson. 2013\. *Applied Predictive Modeling*. Springer.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Kuhn, M., and K. Johnson. 2013\. *应用预测建模*. Springer.
- en: 'Li, J., X. Chen, E. Hovy, and D. Jurafsky. 2016\. “Visualizing and Understanding
    Neural Models in NLP.” In *Proceedings of the 2016 Conference of the North American
    Chapter of the Association for Computational Linguistics: Human Language Technologies*,
    681–91\. Association for Computational Linguistics.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Li, J., X. Chen, E. Hovy, and D. Jurafsky. 2016\. “在自然语言处理中可视化和理解神经网络模型.” 在
    *2016年北美计算语言学协会分会会议：人机语言技术* 论文中, 681–91\. 计算语言学协会.
- en: 'Li, Q., Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He. 2021\. “A
    Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy
    and Protection.” *IEEE Transactions on Knowledge and Data Engineering* Advance
    publication.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Li, Q., Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He. 2021\. “联邦学习系统综述：数据隐私和保护愿景、炒作和现实.”
    *IEEE 知识和数据工程 Transactions* 早期发布.
- en: 'Linardatos, P., V. Papastefanopoulos, and S. Kotsiantis. 2021\. “Explainable
    AI: A Review of Machine Learning Interpretability Methods.” *Entropy* 23 (1):
    18.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 'Linardatos, P., V. Papastefanopoulos, and S. Kotsiantis. 2021\. “可解释人工智能：机器学习可解释性方法的综述.”
    *熵* 23 (1): 18.'
- en: 'Lohr, S. L. 2021\. *Sampling: Design and Analysis*. 3rd ed. CRC Press.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Lohr, S. L. 2021\. *抽样：设计和分析*. 第3版. CRC Press.
- en: Lundberg, S. M., and S.-I. Lee. 2017\. “A Unified Approach to Interpreting Model
    Predictions.” In *Advances in Neural Information Processing Systems (NIPS)*, 4765–74.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Lundberg, S. M., and S.-I. Lee. 2017\. “一种统一的方法来解释模型预测.” 在 *神经信息处理系统（NIPS）的进展*
    中, 4765–74.
- en: 'Mehrabi, N., F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan. 2021\. “A
    Survey on Bias and Fairness in Machine Learning.” *ACM Computing Surveys* 54 (6):
    115.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 'Mehrabi, N., F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan. 2021\. “机器学习中的偏差和公平性综述.”
    *ACM 计算机调查* 54 (6): 115.'
- en: Montgomery, D. C. 20AD. *Design and Analysis of Experiments*. 10th ed. Wiley.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Montgomery, D. C. 20AD. *实验设计和分析*. 第10版. Wiley.
- en: Narayanan, A., and V. Shmatikov. 2008\. “Robust De-Anonymization of Large Sparse
    Datasets.” In *Proceedings of the IEEE Symposium on Security and Privacy*, 111–25.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Narayanan, A., and V. Shmatikov. 2008\. “大型稀疏数据集的鲁棒去匿名化.” 在 *IEEE 安全与隐私研讨会论文集*
    中, 111–25.
- en: ONNX. 2021\. *Open Neural Network Exchange*. [https://github.com/onnx/onnx](https://github.com/onnx/onnx).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX. 2021\. *开放神经网络交换*. [https://github.com/onnx/onnx](https://github.com/onnx/onnx).
- en: Ousterhout, J. 2018\. *A Philosophy of Software Design*. Yaknyam Press.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Ousterhout, J. 2018\. *软件设计的哲学*. Yaknyam Press.
- en: 'PagerDuty. 2022\. *PagerDuty: Uptime Is Money*. [https://www.pagerduty.com/](https://www.pagerduty.com/).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: PagerDuty. 2022\. *PagerDuty：上线即金钱*. [https://www.pagerduty.com/](https://www.pagerduty.com/).
- en: 'Papernot, N., P. McDaniel, A. Sinha, and M. P. Wellman. 2018\. “SoK: Security
    and Privacy in Machine Learning.” In *Proceedings of the IEEE European Symposium
    on Security and Privacy*, 399–414.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Papernot, N., P. McDaniel, A. Sinha, and M. P. Wellman. 2018\. “SoK：机器学习中的安全和隐私.”
    在 *IEEE 欧洲安全与隐私研讨会论文集* 中, 399–414.
- en: 'Paszke, A., S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
    et al. 2019\. “PyTorch: An Imperative Style, High-Performance Deep Learning Library.”
    In *Advances in Neural Information Processing Systems (Nips)*, 32:8026–37.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Paszke, A., S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
    et al. 2019\. “PyTorch：一种命令式风格、高性能深度学习库.” 在 *神经信息处理系统（NIPS）的进展* 中, 32:8026–37.
- en: 'Prometheus Authors, and The Linux Foundation. 2022\. *Prometheus: Monitoring
    System and Time Series Databases*. [https://prometheus.io/](https://prometheus.io/).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 作者，以及 Linux 基金会. 2022\. *Prometheus：监控系统和时间序列数据库*. [https://prometheus.io/](https://prometheus.io/).
- en: Ribeiro, M. T., S. Singh, and C. Guestrin. 2016\. “Why Should I Trust You? Explaining
    the Predictions of Any Classifier.” In *Proceedings of the 22nd ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining*, 1135–44\. ACM.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Ribeiro, M. T., S. Singh, 和 C. Guestrin. 2016. “为什么我应该相信你？解释任何分类器的预测.” 在 *第
    22 届 ACM SIGKDD 国际知识发现和数据挖掘会议论文集*，第 1135–44 页. ACM.
- en: 'Scikit-learn Developers. 2022\. *Scikit-learn: Machine Learning in Python*.
    [https://scikit-learn.org/](https://scikit-learn.org/).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'Scikit-learn 开发者. 2022. *Scikit-learn: Python 中的机器学习*. [https://scikit-learn.org/](https://scikit-learn.org/).'
- en: 'Sculley, D., G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary,
    and M. Young. 2014\. “Machine Learning: The High Interest Credit Card of Technical
    Debt.” In *SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)*.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 'Sculley, D., G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary,
    和 M. Young. 2014. “机器学习：技术债务的高息信用卡.” 在 *SE4ML: 机器学习的软件工程 (NIPS 2014 工作坊)* 中.'
- en: Scutari, M., and J.-B. Denis. 2021\. *Bayesian Networks with Examples in R*.
    2nd ed. Chapman & Hall.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Scutari, M. 和 J.-B. Denis. 2021. *带有 R 示例的贝叶斯网络*. 第 2 版. Chapman & Hall.
- en: '.Seven, D. 2014\. *Knightmare: A DevOps Cautionary Tale*. [https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/](https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: .Seven, D. 2014. *《骑士噩梦：DevOps 警示故事》*. [https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/](https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/).
- en: Sherman, E. 2022\. *What Zillow’s Failed Algorithm Means for the Future of Data
    Science*. [https://fortune.com/education/business/articles/2022/02/01/what-zillows-failed-algorithm-means-for-the-future-of-data-science/](https://fortune.com/education/business/articles/2022/02/01/what-zillows-failed-algorithm-means-for-the-future-of-data-science/).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Sherman, E. 2022. *Zillow 失败算法对数据科学未来的影响*. [https://fortune.com/education/business/articles/2022/02/01/what-zillows-failed-algorithm-means-for-the-future-of-data-science/](https://fortune.com/education/business/articles/2022/02/01/what-zillows-failed-algorithm-means-for-the-future-of-data-science/).
- en: 'Simonyan, K., A. Vedaldi, and A. Zisserman. 2014\. “Deep Inside Convolutional
    Networks: Visualising Image Classification Models and Saliency Maps.” In *Proceedings
    of the 2nd International Conference on Learning Representations (ICLR), Workshop
    Track*.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Simonyan, K., A. Vedaldi, 和 A. Zisserman. 2014. “卷积网络的内部：可视化图像分类模型和显著性图.” 在
    *第 2 届国际学习表示会议 (ICLR) 工作坊轨道* 中.
- en: Sonatype. 2022\. *Nexus Repository Manager*. [https://www.sonatype.com/products/nexus-repository](https://www.sonatype.com/products/nexus-repository).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Sonatype. 2022. *Nexus 仓库管理器*. [https://www.sonatype.com/products/nexus-repository](https://www.sonatype.com/products/nexus-repository).
- en: TensorFlow. 2021b. *TensorFlow Extended (TFX)*. [https://www.tensorflow.org/tfx/](https://www.tensorflow.org/tfx/).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow. 2021b. *TensorFlow Extended (TFX)*. [https://www.tensorflow.org/tfx/](https://www.tensorflow.org/tfx/).
- en: 'The Fluentd Project. 2022\. *Fluentd: Open Source Data Collector*. [https://www.fluentd.org/](https://www.fluentd.org/).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 'The Fluentd Project. 2022. *Fluentd: 开源数据收集器*. [https://www.fluentd.org/](https://www.fluentd.org/).'
- en: 'Thomas, D., and A. Hunt. 2019\. *The Pragmatic Programmer: Your Journey to
    Mastery*. Anniversary. Addison-Wesley.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Thomas, D. 和 A. Hunt. 2019. *《实用程序员：你的精通之旅》*. 周年纪念版. Addison-Wesley.
- en: 'Tornhill, A., and M. Borg. 2022\. “Code Red: The Business Impact of Code Quality:
    A Quantitative Study of 39 Proprietary Production Codebases.” In *Proceedings
    of International Conference on Technical Debt*, 1–10.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Tornhill, A. 和 M. Borg. 2022. “代码红色：代码质量对业务的影响：对 39 个专有生产代码库的定量研究.” 在 *国际技术债务会议论文集*，第
    1–10 页.
- en: 'Wu, X., L. Xiao, Y. Sun, J. Zhang, T. Ma, and L. He. 2022\. “A Survey of Human-in-the-Loop
    for Machine Learning.” *Future Generation Computer Systems* 135: 364–81.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 'Wu, X., L. Xiao, Y. Sun, J. Zhang, T. Ma, 和 L. He. 2022. “机器学习中的闭环：综述.” *未来计算机系统*
    135: 364–81.'
- en: 'Xin, D., L. Ma, J. Liu, S. Song, and A. Parameswaran. 2018\. “Accelerating
    Human-in-the-Loop Machine Learning: Challenges and Opportunities.” In *Proceedings
    of the Second Workshop on Data Management for End-to-End Machine Learning*, 1–4.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Xin, D., L. Ma, J. Liu, S. Song, 和 A. Parameswaran. 2018. “加速闭环机器学习：挑战与机遇.”
    在 *端到端机器学习数据管理第二次研讨会论文集*，第 1–4 页.
- en: Zheng, A. 2015\. *Evaluating Machine Learning Models*. O’Reilly.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng, A. 2015. *评估机器学习模型*. O’Reilly.
- en: '* * *'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: By “traditional software”, we mean any software that is not related to analytics,
    data science or machine learning.[↩︎](design-code.html#fnref11)
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过“传统软件”，我们指的是任何与分析、数据科学或机器学习无关的软件。[↩︎](design-code.html#fnref11)
- en: The choice of the language is often dictated by the orchestration software.
    However, YAML is becoming a de facto standard because of its readability, portability
    and maturity.[↩︎](design-code.html#fnref12)
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语言的选择通常由编排软件决定。然而，由于其可读性、可移植性和成熟度，YAML正成为事实上的标准。[↩︎](design-code.html#fnref12)
- en: 'In software engineering, “pipeline” is used to mean the process of developing
    and delivering software: CI/CD is a pipeline. In this book, we use it to mean
    the software infrastructure to develop and put to use the machine learning models
    and, by extension, the process of building and operating it.[↩︎](design-code.html#fnref13)'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在软件工程中，“pipeline”一词用来指代开发和交付软件的过程：CI/CD 就是一个 pipeline。在这本书中，我们用它来指代开发和部署机器学习模型的软件基础设施，以及扩展到构建和运营该过程。[↩︎](design-code.html#fnref13)
