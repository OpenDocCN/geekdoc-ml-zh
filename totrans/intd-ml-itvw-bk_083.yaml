- en: 6.2 Complexity and numerical analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://huyenchip.com/ml-interviews-book/contents/6.2-complexity-and-numerical-analysis.html](https://huyenchip.com/ml-interviews-book/contents/6.2-complexity-and-numerical-analysis.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*If some characters seem to be missing, it''s because MathJax is not loaded
    correctly. Refreshing the page should fix it.*'
  prefs: []
  type: TYPE_NORMAL
- en: Given that most of the recent breakthroughs in machine learning come from bigger
    models that require massive memory and computational power, it’s important to
    not only know how to implement a model but also how to scale it. To scale a model,
    we’d need to be able to estimate memory requirement and computational cost, as
    well as mitigate numerical instability when training and serving machine learning
    models. Here are some of the questions that can be asked to evaluate your understanding
    of numerical stability and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix multiplication
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] You have three matrices:  and you need to calculate the product . In what
    order would you perform your multiplication and why?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] Now you need to calculate the product of  matrices . How would you determine
    the order in which to perform the multiplication?'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] What are some of the causes for numerical instability in deep learning?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] In many machine learning techniques (e.g. batch norm), we often see a small
    term  added to the calculation. What’s the purpose of that term?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E] What made GPUs popular for deep learning? How are they compared to TPUs?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] What does it mean when we say a problem is intractable?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] What are the time and space complexity for doing backpropagation on a recurrent
    neural network?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] Is knowing a model’s architecture and its hyperparameters enough to calculate
    the memory requirements for that model?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] Your model works fine on a single GPU but gives poor results when you train
    it on 8 GPUs. What might be the cause of this? What would you do to address it?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] What benefits do we get from reducing the precision of our model? What
    problems might we run into? How to solve these problems?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] How to calculate the average of 1M floating-point numbers with minimal
    loss of precision?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[H] How should we implement batch normalization if a batch is spread out over
    multiple GPUs?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[M] Given the following code snippet. What might be a problem with it? How
    would you improve it? **Hint**: this is an actual question asked on [StackOverflow](https://stackoverflow.com/questions/39667089/python-vectorizing-nested-for-loops/39667342).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
