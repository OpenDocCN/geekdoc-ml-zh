<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Support Vector Machines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Support Vector Machines</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_support_vector_machines.html">https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_support_vector_machines.html</a></blockquote>

<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book ‚ÄúApplied Machine Learning in Python: a Hands-on Guide with Code‚Äù.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M. J., 2024, Applied Machine Learning in Python: A Hands-on Guide with Code. GitHub repository. Zenodo. DOI: 10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="../Images/7e4ea662f44af1eae87e87ecbb962ff4.png" data-original-src="https://zenodo.org/badge/863274676.svg"/></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository (0.0.1). Zenodo. DOI: 10.5281/zenodo.13835312  <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="../Images/4e3a59c17d684b06a170c4af84e0f631.png" data-original-src="https://zenodo.org/badge/862519860.svg"/></a></p>
</div>
<p>By Michael J. Pyrcz <br/>
¬© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>Support Vector Machines</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/z19Hs2HfO88?si=U2eAMJcMXRMwHG0C">Polynomial Regression</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/UpN6TLMJiGg?si=-aevKAWNqk_sXxYO">Support Vector Machines</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael‚Äôs Story</a>.</p>
<section id="motivations-for-support-vector-machines">
<h2>Motivations for Support Vector Machines</h2>
<p>A binary classification machine learning method that is a good classification method when there is poor separation of groups.</p>
<ul class="simple">
<li><p>projects the original predictor features to higher dimensional space and then applies a linear, plane or hyperplane,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
ùëì(ùë•) = ùë•^ùëá \beta +\beta_0
\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta\)</span> is a vector and together with <span class="math notranslate nohighlight">\(\beta\)</span> are the hyperplane model parameters, while <span class="math notranslate nohighlight">\(x\)</span> is the matrix of predictor features, all are in the high dimensional space.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ùëì(ùë•)\)</span> is proportional to the signed distance from the decision boundary, and <span class="math notranslate nohighlight">\(ùê∫(ùë•)\)</span> is the side of the decision boundary, <span class="math notranslate nohighlight">\(‚àí\)</span> one side and <span class="math notranslate nohighlight">\(+\)</span> the other, <span class="math notranslate nohighlight">\(f(x) = 0\)</span> is on the decision boundary,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
ùê∫(ùë•)=\text{ùë†ùëñùëîùëõ}\left( ùëì(ùë•) \right)
\]</div>
<p>We represent the constraint, all data of each category must be on the correct side of the boundary, by,</p>
<div class="math notranslate nohighlight">
\[
y_i \left( x_i^T \beta + \beta_0 \right) \geq 0
\]</div>
<p>where this holds if the categories, <span class="math notranslate nohighlight">\(y_i\)</span>, are -1 or 1. We need a model that allows for some misclassification,</p>
<div class="math notranslate nohighlight">
\[
y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i
\]</div>
<p>We introduce the concept of a margin, <span class="math notranslate nohighlight">\(ùëÄ\)</span>, and a distance from the margin, the error as <span class="math notranslate nohighlight">\(\xi_i\)</span>. Now we can pose our loss function as,</p>
<div class="math notranslate nohighlight">
\[
\underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N \xi_i \right)
\]</div>
<p>subject to, <span class="math notranslate nohighlight">\(\xi_i \geq 0, \quad y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i\)</span>.</p>
<p>This is the support vector machine loss function in the higher dimensional space, where ùõΩ,ùõΩ_0 are the multilinear model parameters.</p>
<p>Training the support vector machine, by finding the model parameters of the plane to maximize the margin, <span class="math notranslate nohighlight">\(M\)</span>, while minimizing the error, <span class="math notranslate nohighlight">\(\sum_{i=1}^N \xi_i\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ùë™\)</span> hyperparameter weights the sum of errors, <span class="math notranslate nohighlight">\(xi_ùëñ\)</span>, higher <span class="math notranslate nohighlight">\(ùê∂\)</span>, will result in reduced margin, <span class="math notranslate nohighlight">\(M\)</span>, and lead to overfit</p></li>
<li><p>smaller margin, fewer data used to constrain the boundary, known as support vectors</p></li>
<li><p>training data well within the correct side of the boundary have no influence</p></li>
</ul>
<p>Here are some key aspects of support vector machines,</p>
<ul class="simple">
<li><p>known as support vector machines, and not machine, because with a new kernel you get a new machine</p></li>
<li><p>there are many kernels available including polynomial and radial basis functions</p></li>
</ul>
<p>The primary hyperparameter is <span class="math notranslate nohighlight">\(C\)</span>, the cost of</p>
<p>Hyperparameters are related to the choice of kernel, for example,</p>
<ul class="simple">
<li><p><em>polynomial</em> - polynomial order</p></li>
<li><p><em>radial basis function</em> - <span class="math notranslate nohighlight">\(\gamma\)</span> inversely proportional to the distance influence of the training data</p></li>
</ul>
</section>
<section id="kernel-trick">
<h2><strong>Kernel Trick</strong></h2>
<p>We can incorporate our basis expansion in our method without ever needing to transform the training data to this higher dimensional space,</p>
<div class="math notranslate nohighlight">
\[
h(x)
\]</div>
<p>We only need the inner product over the predictor features,</p>
<div class="math notranslate nohighlight">
\[
h(x) \left( h(x') \right)^T = \langle h(x), h(x') \rangle
\]</div>
<p>Instead of the actual values in the transformed space, we just need the ‚Äòsimilarity‚Äô between all available training data in that transformed space!</p>
<ul class="simple">
<li><p>we training our support vector machines with only a similarity matrix between training data that will be projected to the higher dimensional space</p></li>
<li><p>we never actually need to calculate the training data values in the higher dimensional space</p></li>
</ul>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">,</span><span class="n">NullLocator</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>                                   <span class="c1"># support vector machine methods</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>                  <span class="c1"># for summarizing model performance</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">StratifiedShuffleSplit</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>           <span class="c1"># multi-processor K-fold crossvalidation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>          <span class="c1"># train and test split</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias</span>
<span class="n">binary_cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">'grey'</span><span class="p">,</span> <span class="s1">'gold'</span><span class="p">])</span>                <span class="c1"># custom binary categorical colormap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># suppress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions</h2>
<p>Let‚Äôs define a couple of functions to streamline plotting correlation matrices and visualization of a decision tree regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span>

<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks  </span>

<span class="k">def</span> <span class="nf">plot_CDF</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">):</span>
    <span class="n">cumprob</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">visualize_SVM</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xfeature</span><span class="p">,</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">,</span><span class="n">response</span><span class="p">,</span><span class="n">z_min</span><span class="p">,</span><span class="n">z_max</span><span class="p">,</span><span class="n">xlabel</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">cat</span><span class="p">,</span><span class="n">label</span><span class="p">,</span><span class="n">cmap</span><span class="p">,</span><span class="n">plot_support</span><span class="p">):</span> 
    <span class="n">xplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">/</span><span class="mf">300.0</span><span class="p">;</span> <span class="n">yplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span><span class="o">/</span><span class="mf">300.0</span> <span class="c1"># resolution of the model visualization</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">xplot_step</span><span class="p">),</span> <span class="c1"># set up the mesh</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">yplot_step</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>          <span class="c1"># predict with our trained model over the mesh</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span><span class="n">Z</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span><span class="n">levels</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span> <span class="c1"># plot the predictions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cat</span><span class="p">)):</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">[</span><span class="n">response</span><span class="o">==</span><span class="n">cat</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">yfeature</span><span class="p">[</span><span class="n">response</span><span class="o">==</span><span class="n">cat</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">response</span><span class="p">[</span><span class="n">response</span><span class="o">==</span><span class="n">cat</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> 
                    <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">cat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">)</span> <span class="c1"># custom legend</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">cat</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">999</span><span class="p">,</span><span class="o">-</span><span class="mi">999</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'white'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plot_support</span><span class="p">:</span>                                          <span class="c1"># modified from Jake VanderPlas's Python Data Science Handbook </span>
        <span class="n">sv</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">support_vectors_</span>                           <span class="c1"># retrieve the support vectors</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sv</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span><span class="n">sv</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span><span class="n">facecolors</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Support Vector'</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>                    
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>                       <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">'&lt;div style="display: flex;"&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the working directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="loading-data">
<h2>Loading Data</h2>
<p>Let‚Äôs load the provided multivariate, spatial dataset ‚Äò12_sample_data.csv‚Äô.  It is a comma delimited file with:</p>
<ul class="simple">
<li><p>X and Y coordinates (<span class="math notranslate nohighlight">\(m\)</span>)</p></li>
<li><p>facies 0 and 1</p></li>
<li><p>porosity (fraction)</p></li>
<li><p>permeability (<span class="math notranslate nohighlight">\(mD\)</span>)</p></li>
<li><p>acoustic impedance (<span class="math notranslate nohighlight">\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^3\)</span>).</p></li>
</ul>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a data frame we called ‚Äòdf‚Äô and then preview it to make sure it loaded correctly.</p>
<p><strong>Python Tip: using functions from a package</strong> just type the label for the package that we declared at the beginning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<p>so we can access the pandas function ‚Äòread_csv‚Äô with the command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">()</span>
</pre></div>
</div>
<p>but read csv has required input parameters. The essential one is the name of the file. For our circumstance all the other default parameters are fine. If you want to see all the possible parameters for this function, just go to the docs <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html">here</a>.</p>
<ul class="simple">
<li><p>The docs are always helpful</p></li>
<li><p>There is often a lot of flexibility for Python functions, possible through using various inputs parameters</p></li>
</ul>
<p>also, the program has an output, a pandas DataFrame loaded from the data.  So we have to specficy the name / variable representing that new object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"12_sample_data.csv"</span><span class="p">)</span>  
</pre></div>
</div>
</section>
<section id="standardize-predictor-features">
<h2>Standardize Predictor Features</h2>
<p>The support vector machines minimize the error, the distance of training data from the margin. Therefore, this method is sensitivity to the relative ranges of the predictor features.</p>
<ul class="simple">
<li><p>if one predictor feature has a much larger range then it will dominate the model, the model will only separate on that feature! The result is a model orthogonal to that one feature, i.e., splitting only on that feature.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv"</span><span class="p">)</span>

<span class="n">yname</span> <span class="o">=</span> <span class="s1">'Facies'</span><span class="p">;</span> <span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'AI'</span><span class="p">]</span>                   <span class="c1"># specify the predictor features (x2) and response feature (x1)</span>
<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1500.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">6500.0</span><span class="p">]</span>                      <span class="c1"># set minimums and maximums for visualization </span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">Xlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">];</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'Facies'</span> <span class="c1"># specify the feature labels for plotting</span>
<span class="n">Xunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Fraction'</span><span class="p">,</span><span class="sa">r</span><span class="s1">'$\frac</span><span class="si">{kg}</span><span class="s1">{m^3} \cdot \frac</span><span class="si">{m}{s}</span><span class="s1"> \cdot 10^3$'</span><span class="p">];</span> <span class="n">yunit</span> <span class="o">=</span> <span class="s1">'MCFPD'</span>
<span class="n">Xlabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>
<span class="n">ylabelunit</span> <span class="o">=</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span> <span class="o">+</span> <span class="s1">')'</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                                   <span class="c1"># extract selected features as X and y DataFrames</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">]</span>

<span class="n">ysname</span> <span class="o">=</span> <span class="s1">'s'</span> <span class="o">+</span> <span class="n">yname</span><span class="p">;</span> <span class="n">Xsname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'s'</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">Xname</span><span class="p">]</span> <span class="c1"># standardized predictor names</span>
<span class="n">Xsmin</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="o">-</span><span class="mf">3.0</span><span class="p">];</span> <span class="n">Xsmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]</span>                        <span class="c1"># set minimums and maximums for standardized features</span>
<span class="n">Xslabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Standardized '</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">Xlabel</span><span class="p">]</span>   <span class="c1"># standardized predictor names</span>
<span class="n">Xsunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'S['</span> <span class="o">+</span> <span class="n">element</span> <span class="o">+</span> <span class="s1">']'</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">Xunit</span><span class="p">]</span>          <span class="c1"># standardized predictor names</span>
<span class="n">Xslabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xsunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xsunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>                                 <span class="c1"># instantiate feature standardization method</span>
<span class="n">Xs</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                               <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>
<span class="n">X</span><span class="p">[</span><span class="n">Xsname</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xs</span>                                                <span class="c1"># add standardized features to the predictor feature DataFrame</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-and-test-split">
<h2>Train and Test Split</h2>
<p>For convenience and simplicity we use scikit-learn‚Äôs random train and test split.</p>
<ul class="simple">
<li><p>we use the same random_state parameter so the train and test splits on original and standardized features are the same.</p></li>
<li><p>I could have just backtransformed the standardize latter (spoiler alert, I‚Äôm going to show the impact of not standardizing on the model).</p></li>
<li><p>typically we don‚Äôt have to back transform the predictor features, for our prediction workflows it is a one way trip for the predictor features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span> <span class="c1"># train and test split</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train and test DataFrame with both X and y</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame</h2>
<p>Visualizing the train and test DataFrame is useful check before we build our models.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'       Training DataFrame          Testing DataFrame'</span><span class="p">)</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span><span class="n">df_test</span><span class="p">)</span>                          <span class="c1"># custom function for side-by-side DataFrame display</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>       Training DataFrame          Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>340</th>
      <td>0.204313</td>
      <td>4373.187870</td>
      <td>0.469659</td>
      <td>0.788406</td>
      <td>1</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.167316</td>
      <td>3088.482947</td>
      <td>-0.698603</td>
      <td>-0.860390</td>
      <td>0</td>
    </tr>
    <tr>
      <th>315</th>
      <td>0.219801</td>
      <td>2983.326185</td>
      <td>0.958720</td>
      <td>-0.995349</td>
      <td>1</td>
    </tr>
    <tr>
      <th>365</th>
      <td>0.216819</td>
      <td>2543.772663</td>
      <td>0.864542</td>
      <td>-1.559474</td>
      <td>1</td>
    </tr>
    <tr>
      <th>385</th>
      <td>0.191565</td>
      <td>3670.457907</td>
      <td>0.067120</td>
      <td>-0.113481</td>
      <td>1</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>72</th>
      <td>0.139637</td>
      <td>4747.274043</td>
      <td>-1.572630</td>
      <td>1.268510</td>
      <td>0</td>
    </tr>
    <tr>
      <th>153</th>
      <td>0.170732</td>
      <td>4535.625583</td>
      <td>-0.590742</td>
      <td>0.996879</td>
      <td>0</td>
    </tr>
    <tr>
      <th>258</th>
      <td>0.244345</td>
      <td>2696.102930</td>
      <td>1.733756</td>
      <td>-1.363972</td>
      <td>1</td>
    </tr>
    <tr>
      <th>56</th>
      <td>0.167125</td>
      <td>5500.997419</td>
      <td>-0.704644</td>
      <td>2.235841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>303</th>
      <td>0.216253</td>
      <td>3959.934912</td>
      <td>0.846677</td>
      <td>0.258035</td>
      <td>1</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
</section>
<section id="summary-statistics-for-tabular-data">
<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames.</p>
<ul class="simple">
<li><p>The describe command provides count, mean, minimum, maximum in a nice data table.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'            Training DataFrame                      Testing DataFrame'</span><span class="p">)</span> <span class="c1"># custom function for side-by-side summary statistics</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]],</span><span class="n">df_test</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>            Training DataFrame                      Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>360.000000</td>
      <td>360.000000</td>
      <td>360.000000</td>
      <td>360.000000</td>
      <td>360.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.189150</td>
      <td>3767.451286</td>
      <td>-0.009167</td>
      <td>0.011001</td>
      <td>0.602778</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.031636</td>
      <td>786.394126</td>
      <td>0.998983</td>
      <td>1.009262</td>
      <td>0.490004</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.117562</td>
      <td>1746.387548</td>
      <td>-2.269691</td>
      <td>-2.582841</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.261091</td>
      <td>5957.162150</td>
      <td>2.262519</td>
      <td>2.821285</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>120.000000</td>
      <td>120.000000</td>
      <td>120.000000</td>
      <td>120.000000</td>
      <td>120.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.190311</td>
      <td>3733.164755</td>
      <td>0.027500</td>
      <td>-0.033003</td>
      <td>0.658333</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.032014</td>
      <td>763.117871</td>
      <td>1.010903</td>
      <td>0.979389</td>
      <td>0.476257</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.131230</td>
      <td>1961.600397</td>
      <td>-1.838105</td>
      <td>-2.306636</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.256172</td>
      <td>6194.573653</td>
      <td>2.107198</td>
      <td>3.125980</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
</section>
<section id="visualize-the-train-and-test-splits">
<h2>Visualize the Train and Test Splits</h2>
<p>Let‚Äôs check the consistency and coverage of training and testing with histograms and scatter plots.</p>
<ul class="simple">
<li><p>check to make sure the training and testing cover the range of possible feature combinations</p></li>
<li><p>ensure we are not extrapolating beyond the training data with the testing cases</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">232</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">233</span><span class="p">)</span>                                              <span class="c1"># predictor features #1 and #2 scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs '</span> <span class="o">+</span>  <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">235</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">236</span><span class="p">)</span>                                              <span class="c1"># predictor features #1 and #2 scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs '</span> <span class="o">+</span>  <span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c96849d9ac15251e0c63378a9f425aa0f734d87c0a250b8ce44f189349db09c5.png" src="../Images/acefe3d0111ef4c4aadff2177c5a7676.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/c96849d9ac15251e0c63378a9f425aa0f734d87c0a250b8ce44f189349db09c5.png"/>
</div>
</div>
<p>Sometimes I find it more convenient to compare distributions by looking at CDF‚Äôs instead of histograms.</p>
<ul class="simple">
<li><p>we avoid the arbitrary choice of histogram bin size, because CDF‚Äôs are at the data resolution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>                                              <span class="c1"># categorical response feature grouped histogram</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="o">-</span><span class="mf">0.125</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'darkorange'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">0.125</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'red'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">0.875</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'darkorange'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">1.125</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'red'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">x_ticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">];</span> <span class="n">x_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Shale'</span><span class="p">,</span> <span class="s1">'Sand'</span><span class="p">];</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span><span class="n">x_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span><span class="mf">250.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">();</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">NullLocator</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' Train and Test Categorical Response Frequencies'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Facies'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7f4199220c2686c54fc8e8ceea1351ff88ab7bba2333e7441c6d268c034adbed.png" src="../Images/2bbf0a8662041cb7a556a37197370bc0.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/7f4199220c2686c54fc8e8ceea1351ff88ab7bba2333e7441c6d268c034adbed.png"/>
</div>
</div>
<p>This looks good,</p>
<ul class="simple">
<li><p>the distributions are well behaved, we cannot observe obvious gaps, outliers nor truncations</p></li>
<li><p>the test and train cases have similar coverage</p></li>
<li><p>the relative frequencies of the categorical response are similar over train and test datasets, i.e., a good train and test balance.</p></li>
</ul>
</section>
<section id="visualize-the-predictor-feature-space">
<h2>Visualize the Predictor Feature Space</h2>
<p>Let‚Äôs build a simplified plot to visualize the 2D predictor feature space with the train and test data.</p>
<ul class="simple">
<li><p>we ask the question, will we be able to model the classification boundary? Is there a lot of data overlap? Is the boundary simple (i.e., linear) or more complicated?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot train and test data in predictor feature space</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'gold'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Sand'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkgrey'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Shale'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'gold'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkgrey'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="o">-</span><span class="mi">999</span><span class="p">],[</span><span class="o">-</span><span class="mi">999</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'white'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="o">-</span><span class="mi">999</span><span class="p">],[</span><span class="o">-</span><span class="mi">999</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'white'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training and Testing '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b3c308d6eca35509ace9645fe2c47910d318c23c40b049222f1c1f89bfeeea5b.png" src="../Images/56dc165df133e2ddbce54c0beda4915c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b3c308d6eca35509ace9645fe2c47910d318c23c40b049222f1c1f89bfeeea5b.png"/>
</div>
</div>
<p>This will be a difficult classification,</p>
<ul class="simple">
<li><p>there is certainly a lot of overlap</p></li>
<li><p>the boundary may be nonlinear.</p></li>
</ul>
<p>But, there is good news,</p>
<ul class="simple">
<li><p>the train and test coverage looks good in general, note there are a few testing cases that will test model extrapolation.</p></li>
<li><p>support vector machines are designed to work with this overlap!</p></li>
</ul>
</section>
<section id="support-vector-machine-model-with-linear-kernel">
<h2>Support Vector Machine Model with Linear Kernel</h2>
<p>Let‚Äôs start simple, train and visualize linear support vector machine models over our feature space.</p>
<ul class="simple">
<li><p>This will provide a linear spatial classification model for facies 0 and 1 as a function of AI and porosity.</p></li>
</ul>
<p>We use the scikit-learn function <span class="math notranslate nohighlight">\(SVC\)</span> substantiate the support vector machine:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">svm_linear</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
</pre></div>
</div>
<p>The parameters include:</p>
<ul class="simple">
<li><p><strong>kernel</strong> the kernel type that is applied to project the data to a potentially higher dimensional space</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(C\)</span></strong> penalty for misclassification</p></li>
<li><p><strong>random_state</strong> random number see for random shuffling data for probability estimates</p></li>
</ul>
<p>We then use the command,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">svm_linear</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>to train the model with the training dataset.</p>
<p>The inputs to the fit function include:</p>
<ul class="simple">
<li><p><strong>X</strong> - the <span class="math notranslate nohighlight">\(n \times m\)</span> array with the predictor features for the training dataset</p></li>
<li><p><strong>y</strong> - the <span class="math notranslate nohighlight">\(n \times 1\)</span> array with the response feature for the training dataset</p></li>
</ul>
<p>Let‚Äôs try out 2 different <span class="math notranslate nohighlight">\(C\)</span> penalty hyperparameters to visualize the impact of the penalty for misclassification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C1_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>                                          <span class="c1"># set hyperparameters</span>
<span class="n">SVM1_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">C1_list</span><span class="p">:</span>                                             <span class="c1"># train the models</span>
    <span class="n">SVM1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">'linear'</span><span class="p">,</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y_train</span><span class="p">))</span> <span class="c1"># instantiate and train</span>
</pre></div>
</div>
</div>
</div>
<p>Looks like it ran ok!  Let‚Äôs visualize the results using the convenient visualization functions that we previously defined.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">for</span> <span class="n">iC</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C1_list</span><span class="p">):</span>                              <span class="c1"># visualize the training data and model</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">iC</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">SVM1_list</span><span class="p">[</span><span class="n">iC</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'Training Data and Linear Support Vector Machine, $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span>
                <span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0dec98b51eac972aa8541bbcf4d2742f7a09bcb6b1b19ee80196793e988428ba.png" src="../Images/f9599d00749b4f00b75cb1eeb40f7f47.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/0dec98b51eac972aa8541bbcf4d2742f7a09bcb6b1b19ee80196793e988428ba.png"/>
</div>
</div>
<p>The above plot shows the linear kernel support vector machine classification model, the training dataset and the resulting support vectors with bold circles.</p>
<ul class="simple">
<li><p>Linear kernel only provide a straight decision boundary.</p></li>
<li><p>It is hard to tune the model to fit more complicated situation.</p></li>
</ul>
<p>Note that with higher C, weighting of the sum of errors, we get a smaller margin. The linear model is fit with fewer support vectors (training data in the margin. Let‚Äôs summarize the end members of this hyperparameter with respect to simple and complicated models, potential under and overfit and the model bias and variance trade-off.</p>
<ul class="simple">
<li><p><strong>simple model \ underfit model</strong> - when C is smaller, the classifier is more tolerant with misclassified data points (higher model bias, lower model variance).</p></li>
<li><p><strong>complex model \ overfit model</strong> - when C is larger, the classifier is more sensitive to misclassified data points (lower model bias, higher model variance).</p></li>
</ul>
<p>In other words, <span class="math notranslate nohighlight">\(C\)</span> is a regularization term, just like the shrinkage term for ridge regression. Let‚Äôs try some more flexible classifiers with a different kernel so we can better see this.</p>
</section>
<section id="support-vector-machine-model-with-polynomial-kernel">
<h2>Support Vector Machine Model with Polynomial Kernel</h2>
<p>The polynomial kernel is defined as</p>
<p>\begin{equation}
K(x,x‚Äô) = (x^Tx)^d,
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(d\)</span> is the degree of polynomials.</p>
<p>The hyperparameter <span class="math notranslate nohighlight">\(degree\)</span> is the order of the polynomial kernel function.</p>
<p>As previously mentioned, let‚Äôs try out different <span class="math notranslate nohighlight">\(C\)</span>, penalty for error, with a single polynomial order observe the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C2_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span>                                     <span class="c1"># set hyperparameters</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">C2_list</span><span class="p">)),</span><span class="mi">3</span><span class="p">)</span>       
<span class="n">SVM2_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">iC</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C2_list</span><span class="p">):</span>                              <span class="c1"># train the model and visualize the training data and model</span>
    <span class="n">SVM2_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">'poly'</span><span class="p">,</span><span class="n">degree</span><span class="o">=</span><span class="n">order</span><span class="p">[</span><span class="n">iC</span><span class="p">],</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y_train</span><span class="p">))</span> <span class="c1"># instantiate and train</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">iC</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">SVM2_list</span><span class="p">[</span><span class="n">iC</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s1">'Polynomial Support Vector Machine, Order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">order</span><span class="p">[</span><span class="n">iC</span><span class="p">])</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/db044f313815811c58d2c4c54acfdaba7a6e69a6ce29d65cc9a535b7ec667c76.png" src="../Images/00a2d3685850074a3a660b3f3a1259f2.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/db044f313815811c58d2c4c54acfdaba7a6e69a6ce29d65cc9a535b7ec667c76.png"/>
</div>
</div>
<p>As we increase the <span class="math notranslate nohighlight">\(C\)</span> hyperparameter, the margin shrinks, the number of support vectors reduces and the model complexity increases.</p>
</section>
<section id="support-vector-machine-model-with-radial-basis-function-kernel">
<h2>Support Vector Machine Model with Radial Basis Function Kernel</h2>
<p>Radial Basis Function (RBF) is another commonly used kernel in SVC:</p>
<p>\begin{equation}
K(x,x‚Äô) = e^{- \gamma ||x-x‚Äô||^2},
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(||x-x'||^2\)</span> is the squared Euclidean distance between two data points x and x‚Äô.</p>
<p>Gaussian kernel is a special case of RBF, where:</p>
<p>\begin{equation}
K(x,x‚Äô) = e^{- \frac {||x-x‚Äô||^2} {2 \sigma^2}}.
\end{equation}</p>
<p>By changing the value of <span class="math notranslate nohighlight">\(\gamma\)</span> and C, the classifier with an RBF kernel can be tuned.</p>
<p><span class="math notranslate nohighlight">\(\gamma\)</span> can be thought of as the spread of the kernel.</p>
<ul class="simple">
<li><p>when <span class="math notranslate nohighlight">\(\gamma\)</span> is low, the curvature of the decision boundary is low, leading to a broad decision region (low variance, high bias), low complexity</p></li>
<li><p>The <span class="math notranslate nohighlight">\(\gamma\)</span> parameter can be interpreted as the inverse of the radius of influence of samples selected by the model as support vectors, i.e., low gamma integrates more data for a smoother model</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C3_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">]</span>                                      <span class="c1"># set hyperparameters</span>
<span class="n">gamma1_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">]</span>

<span class="n">index</span><span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">C3_list</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">gamma1_list</span><span class="p">:</span>                                 <span class="c1"># train the models, visualize the training data and models</span>
        <span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'rbf'</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span> <span class="c1"># instantiate and train</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">index</span><span class="p">)</span>
        <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'RBF Support Vector Machine, $\gamma$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.4</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/82ff1c768a726890aad3ac7762874583b4c7c13de8c4a2eb9150851584e58eb1.png" src="../Images/6f78098f6348e837aa484bf3c227abf8.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/82ff1c768a726890aad3ac7762874583b4c7c13de8c4a2eb9150851584e58eb1.png"/>
</div>
</div>
<p>The impact of regularization with the C hyperparameter is very clear in this case,</p>
<ul class="simple">
<li><p>higher C, smaller margin, fewer support vectors, tends to overfit</p></li>
<li><p>lower C, larger margin, more support vectors, tends to underfit</p></li>
</ul>
<p>The impact of gamma is also very clear in this case,</p>
<ul class="simple">
<li><p>higher gamma results in more complicated, high curvature decision boundaries</p></li>
<li><p>lower gamma results in more simple, low curvature, smooth decision boundaries</p></li>
</ul>
<p>Although two facies seem to be classified properly in some cases above, there is a risk of overfitting, specifically for the high gamma and high C example.</p>
</section>
<section id="support-vector-machines-without-standardizing-the-predictor-features">
<h2>Support Vector Machines without Standardizing the Predictor Features</h2>
<p>As promised, let‚Äôs try a model without standardizing the predictor features.</p>
<ul class="simple">
<li><p>this will be illustrative as the original predictor features have very different ranges!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">order</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">0.01</span>                                           <span class="c1"># set the hyperparameters</span>
<span class="n">svc_test1</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'poly'</span><span class="p">,</span><span class="n">degree</span><span class="o">=</span><span class="n">order</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span> <span class="c1"># fit with original features, not standardized</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>                                          <span class="c1"># set the hyperparameters</span>
<span class="n">svc_test2</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'rbf'</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span> <span class="c1"># fit with original features, not standardized</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize the training data and models</span>
<span class="n">visualize_SVM</span><span class="p">(</span><span class="n">svc_test1</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s1">'Polynomial Support Vector Machine, Order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">visualize_SVM</span><span class="p">(</span><span class="n">svc_test2</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'RBF Support Vector Machine, $\gamma$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/214f9d02bb8c207b3c3bbefb825c5bd28482dca26856c9f37b16b8d18e527260.png" src="../Images/6284d1148a1bd492bb2d8429f0b4cd96.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/214f9d02bb8c207b3c3bbefb825c5bd28482dca26856c9f37b16b8d18e527260.png"/>
</div>
</div>
<p>What happened?</p>
<ul class="simple">
<li><p>The support vector machine with the polynomial kernel splits on the feature with the largest range, acoustic impedance. The differences in the feature with the very small range, porosity here, do not significantly influence to the model.</p></li>
<li><p>The radial basis function support vector machine has thin shale and sand layers over the acoustic impedance.</p></li>
</ul>
<p>We must standardize our predictor features to apply support vector machines.</p>
</section>
<section id="hyperparameter-tuning">
<h2>Hyperparameter Tuning</h2>
<p>Let‚Äôs use the brute force grid search with stratified shuffle splits to iterate over multiple hyperparameters and find the optimum model complexity.</p>
<ul class="simple">
<li><p><strong>Grid Search Cross Validation</strong> - models are constructed for the full combinatorial of hyperparameters</p></li>
<li><p><strong>Stratified Shuffle Splits</strong> - ensures that the balance of categorical cases is preserved in the splits and randomizes the split to ensure the model does use the same data in the same order each time</p></li>
<li><p>warning this will take about 2 minutes to run on a regular PC</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>                              <span class="c1"># set hyperparameter cases</span>
<span class="n">gamma_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma_range</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C_range</span><span class="p">)</span>               <span class="c1"># store hyperparameter cases in a dictionary</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span> <span class="c1"># instantiate the cross validation method</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y</span><span class="p">)</span> <span class="c1"># brute force, full combinatorial search with cross validation </span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'mean_test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">C_range</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">gamma_range</span><span class="p">))</span> <span class="c1"># retrieve average accuracy and shape as a 2D array for plot</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can visualize the cross validation accuracy for all of the hyperparameter combinations.</p>
<ul class="simple">
<li><p>note, the output is average accuracy over all of the stratified shuffle splits, where accuracy is,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
Accuracy = \frac{n_{\text{correctly classified}}}{n}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot results of hyperparameter tuning                               </span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$\gamma$ Hyperparameter'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$C$ Hyperparameter'</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">'Average Classification Accuracy Over Splits'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gamma_range</span><span class="p">)),</span> <span class="n">gamma_range</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">C_range</span><span class="p">)),</span> <span class="n">C_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'SVC Hyperparameter Tuning, Cross Validation Accuracy'</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c27ee9a9f09064a90ce366edd51e5c5e6693ed7e75b913239500a89b85839743.png" src="../Images/a7a596942f23b8c59494c817735ad48e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/c27ee9a9f09064a90ce366edd51e5c5e6693ed7e75b913239500a89b85839743.png"/>
</div>
</div>
<p>We can observe a region around <span class="math notranslate nohighlight">\(C\)</span> of 100 and <span class="math notranslate nohighlight">\(\gamma\)</span> of 0.1 with the best model cross validation accuracy.</p>
</section>
<section id="visualizing-high-mid-and-low-performing-models">
<h2>Visualizing High, Mid and Low Performing Models</h2>
<p>Now we show examples of high, mid and low performing model based on validation accuracy from the demonstration above.</p>
<ul class="simple">
<li><p>we will use parameter combinations, <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(\gamma\)</span>, from the plot above to select and rerun the cases.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">cases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Poor'</span><span class="p">,</span><span class="s1">'OK'</span><span class="p">,</span><span class="s1">'Good'</span><span class="p">]</span>                                  <span class="c1"># selected hyperparameter cases for visualization</span>
<span class="n">C_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mf">1e6</span><span class="p">]</span>
<span class="n">gamma_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.01</span><span class="p">]</span>
<span class="n">model_cases</span> <span class="o">=</span> <span class="p">[]</span>
 
<span class="k">for</span> <span class="n">icase</span><span class="p">,</span> <span class="n">case</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cases</span><span class="p">):</span>                          <span class="c1"># visualize the training data and model</span>
    <span class="n">model_cases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'rbf'</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C_list</span><span class="p">[</span><span class="n">icase</span><span class="p">],</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma_list</span><span class="p">[</span><span class="n">icase</span><span class="p">])</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y</span><span class="p">))</span> <span class="c1"># train on all the data</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">icase</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># visualize model cases and all data</span>
    <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">model_cases</span><span class="p">[</span><span class="n">icase</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'RBF Support Vector Machine, '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cases</span><span class="p">[</span><span class="n">icase</span><span class="p">])</span> <span class="o">+</span> <span class="s1">' Model'</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/72e5e586c8cb2a4e90eea81cd6276fdc2175a66c300652b076105e3cc3ba6079.png" src="../Images/e3b9d37c4cafc9bc078800f977947926.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/72e5e586c8cb2a4e90eea81cd6276fdc2175a66c300652b076105e3cc3ba6079.png"/>
</div>
</div>
<p>By selecting low, mid and high accuracy hyperparameter cases from our hyperparameter tuning cross validation accuracy we obtain a good illustration example of overfit to well-fit models.</p>
</section>
<section id="comments">
<h2>Comments</h2>
<p>I hope you found this chapter helpful. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a>,</p>
<p><em>Michael</em></p>
</section>
<section id="the-author">
<h2>The Author:</h2>
<p>Michael Pyrcz, Professor, The University of Texas at Austin
<em>Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions</em></p>
<p>With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers‚Äô and geoscientists‚Äô impact in subsurface resource development.</p>
<p>For more about Michael check out these links:</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
</section>
<section id="more-resources-available-at-twitter-github-website-googlescholar-geostatistics-book-youtube-applied-geostats-in-python-e-book-applied-machine-learning-in-python-e-book-linkedin">
<h2>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></h2>
</section>
&#13;

<h2>Motivations for Support Vector Machines</h2>
<p>A binary classification machine learning method that is a good classification method when there is poor separation of groups.</p>
<ul class="simple">
<li><p>projects the original predictor features to higher dimensional space and then applies a linear, plane or hyperplane,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
ùëì(ùë•) = ùë•^ùëá \beta +\beta_0
\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta\)</span> is a vector and together with <span class="math notranslate nohighlight">\(\beta\)</span> are the hyperplane model parameters, while <span class="math notranslate nohighlight">\(x\)</span> is the matrix of predictor features, all are in the high dimensional space.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ùëì(ùë•)\)</span> is proportional to the signed distance from the decision boundary, and <span class="math notranslate nohighlight">\(ùê∫(ùë•)\)</span> is the side of the decision boundary, <span class="math notranslate nohighlight">\(‚àí\)</span> one side and <span class="math notranslate nohighlight">\(+\)</span> the other, <span class="math notranslate nohighlight">\(f(x) = 0\)</span> is on the decision boundary,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
ùê∫(ùë•)=\text{ùë†ùëñùëîùëõ}\left( ùëì(ùë•) \right)
\]</div>
<p>We represent the constraint, all data of each category must be on the correct side of the boundary, by,</p>
<div class="math notranslate nohighlight">
\[
y_i \left( x_i^T \beta + \beta_0 \right) \geq 0
\]</div>
<p>where this holds if the categories, <span class="math notranslate nohighlight">\(y_i\)</span>, are -1 or 1. We need a model that allows for some misclassification,</p>
<div class="math notranslate nohighlight">
\[
y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i
\]</div>
<p>We introduce the concept of a margin, <span class="math notranslate nohighlight">\(ùëÄ\)</span>, and a distance from the margin, the error as <span class="math notranslate nohighlight">\(\xi_i\)</span>. Now we can pose our loss function as,</p>
<div class="math notranslate nohighlight">
\[
\underset{\beta, \beta_0}{\text{min}} \left( \frac{1}{2M^2} + C \sum_{i=1}^N \xi_i \right)
\]</div>
<p>subject to, <span class="math notranslate nohighlight">\(\xi_i \geq 0, \quad y_i \left( x_i^T \beta + \beta_0 \right) \geq M - \xi_i\)</span>.</p>
<p>This is the support vector machine loss function in the higher dimensional space, where ùõΩ,ùõΩ_0 are the multilinear model parameters.</p>
<p>Training the support vector machine, by finding the model parameters of the plane to maximize the margin, <span class="math notranslate nohighlight">\(M\)</span>, while minimizing the error, <span class="math notranslate nohighlight">\(\sum_{i=1}^N \xi_i\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ùë™\)</span> hyperparameter weights the sum of errors, <span class="math notranslate nohighlight">\(xi_ùëñ\)</span>, higher <span class="math notranslate nohighlight">\(ùê∂\)</span>, will result in reduced margin, <span class="math notranslate nohighlight">\(M\)</span>, and lead to overfit</p></li>
<li><p>smaller margin, fewer data used to constrain the boundary, known as support vectors</p></li>
<li><p>training data well within the correct side of the boundary have no influence</p></li>
</ul>
<p>Here are some key aspects of support vector machines,</p>
<ul class="simple">
<li><p>known as support vector machines, and not machine, because with a new kernel you get a new machine</p></li>
<li><p>there are many kernels available including polynomial and radial basis functions</p></li>
</ul>
<p>The primary hyperparameter is <span class="math notranslate nohighlight">\(C\)</span>, the cost of</p>
<p>Hyperparameters are related to the choice of kernel, for example,</p>
<ul class="simple">
<li><p><em>polynomial</em> - polynomial order</p></li>
<li><p><em>radial basis function</em> - <span class="math notranslate nohighlight">\(\gamma\)</span> inversely proportional to the distance influence of the training data</p></li>
</ul>
&#13;

<h2><strong>Kernel Trick</strong></h2>
<p>We can incorporate our basis expansion in our method without ever needing to transform the training data to this higher dimensional space,</p>
<div class="math notranslate nohighlight">
\[
h(x)
\]</div>
<p>We only need the inner product over the predictor features,</p>
<div class="math notranslate nohighlight">
\[
h(x) \left( h(x') \right)^T = \langle h(x), h(x') \rangle
\]</div>
<p>Instead of the actual values in the transformed space, we just need the ‚Äòsimilarity‚Äô between all available training data in that transformed space!</p>
<ul class="simple">
<li><p>we training our support vector machines with only a similarity matrix between training data that will be projected to the higher dimensional space</p></li>
<li><p>we never actually need to calculate the training data values in the higher dimensional space</p></li>
</ul>
&#13;

<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">,</span><span class="n">NullLocator</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>                                   <span class="c1"># support vector machine methods</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>                  <span class="c1"># for summarizing model performance</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">StratifiedShuffleSplit</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>           <span class="c1"># multi-processor K-fold crossvalidation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>          <span class="c1"># train and test split</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias</span>
<span class="n">binary_cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">'grey'</span><span class="p">,</span> <span class="s1">'gold'</span><span class="p">])</span>                <span class="c1"># custom binary categorical colormap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># suppress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
&#13;

<h2>Declare Functions</h2>
<p>Let‚Äôs define a couple of functions to streamline plotting correlation matrices and visualization of a decision tree regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span>

<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks  </span>

<span class="k">def</span> <span class="nf">plot_CDF</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">):</span>
    <span class="n">cumprob</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">visualize_SVM</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xfeature</span><span class="p">,</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">,</span><span class="n">response</span><span class="p">,</span><span class="n">z_min</span><span class="p">,</span><span class="n">z_max</span><span class="p">,</span><span class="n">xlabel</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">cat</span><span class="p">,</span><span class="n">label</span><span class="p">,</span><span class="n">cmap</span><span class="p">,</span><span class="n">plot_support</span><span class="p">):</span> 
    <span class="n">xplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">/</span><span class="mf">300.0</span><span class="p">;</span> <span class="n">yplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span><span class="o">/</span><span class="mf">300.0</span> <span class="c1"># resolution of the model visualization</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">xplot_step</span><span class="p">),</span> <span class="c1"># set up the mesh</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">yplot_step</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>          <span class="c1"># predict with our trained model over the mesh</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span><span class="n">Z</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span><span class="n">levels</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span> <span class="c1"># plot the predictions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cat</span><span class="p">)):</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">[</span><span class="n">response</span><span class="o">==</span><span class="n">cat</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">yfeature</span><span class="p">[</span><span class="n">response</span><span class="o">==</span><span class="n">cat</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">response</span><span class="p">[</span><span class="n">response</span><span class="o">==</span><span class="n">cat</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> 
                    <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">cat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">)</span> <span class="c1"># custom legend</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">cat</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">999</span><span class="p">,</span><span class="o">-</span><span class="mi">999</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'white'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plot_support</span><span class="p">:</span>                                          <span class="c1"># modified from Jake VanderPlas's Python Data Science Handbook </span>
        <span class="n">sv</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">support_vectors_</span>                           <span class="c1"># retrieve the support vectors</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sv</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span><span class="n">sv</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span><span class="n">facecolors</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Support Vector'</span><span class="p">);</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>                    
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>                       <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">'&lt;div style="display: flex;"&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Set the working directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Loading Data</h2>
<p>Let‚Äôs load the provided multivariate, spatial dataset ‚Äò12_sample_data.csv‚Äô.  It is a comma delimited file with:</p>
<ul class="simple">
<li><p>X and Y coordinates (<span class="math notranslate nohighlight">\(m\)</span>)</p></li>
<li><p>facies 0 and 1</p></li>
<li><p>porosity (fraction)</p></li>
<li><p>permeability (<span class="math notranslate nohighlight">\(mD\)</span>)</p></li>
<li><p>acoustic impedance (<span class="math notranslate nohighlight">\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^3\)</span>).</p></li>
</ul>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a data frame we called ‚Äòdf‚Äô and then preview it to make sure it loaded correctly.</p>
<p><strong>Python Tip: using functions from a package</strong> just type the label for the package that we declared at the beginning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<p>so we can access the pandas function ‚Äòread_csv‚Äô with the command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">()</span>
</pre></div>
</div>
<p>but read csv has required input parameters. The essential one is the name of the file. For our circumstance all the other default parameters are fine. If you want to see all the possible parameters for this function, just go to the docs <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html">here</a>.</p>
<ul class="simple">
<li><p>The docs are always helpful</p></li>
<li><p>There is often a lot of flexibility for Python functions, possible through using various inputs parameters</p></li>
</ul>
<p>also, the program has an output, a pandas DataFrame loaded from the data.  So we have to specficy the name / variable representing that new object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"12_sample_data.csv"</span><span class="p">)</span>  
</pre></div>
</div>
&#13;

<h2>Standardize Predictor Features</h2>
<p>The support vector machines minimize the error, the distance of training data from the margin. Therefore, this method is sensitivity to the relative ranges of the predictor features.</p>
<ul class="simple">
<li><p>if one predictor feature has a much larger range then it will dominate the model, the model will only separate on that feature! The result is a model orthogonal to that one feature, i.e., splitting only on that feature.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv"</span><span class="p">)</span>

<span class="n">yname</span> <span class="o">=</span> <span class="s1">'Facies'</span><span class="p">;</span> <span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'AI'</span><span class="p">]</span>                   <span class="c1"># specify the predictor features (x2) and response feature (x1)</span>
<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1500.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">6500.0</span><span class="p">]</span>                      <span class="c1"># set minimums and maximums for visualization </span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">Xlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">];</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'Facies'</span> <span class="c1"># specify the feature labels for plotting</span>
<span class="n">Xunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Fraction'</span><span class="p">,</span><span class="sa">r</span><span class="s1">'$\frac</span><span class="si">{kg}</span><span class="s1">{m^3} \cdot \frac</span><span class="si">{m}{s}</span><span class="s1"> \cdot 10^3$'</span><span class="p">];</span> <span class="n">yunit</span> <span class="o">=</span> <span class="s1">'MCFPD'</span>
<span class="n">Xlabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>
<span class="n">ylabelunit</span> <span class="o">=</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span> <span class="o">+</span> <span class="s1">')'</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                                   <span class="c1"># extract selected features as X and y DataFrames</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">]</span>

<span class="n">ysname</span> <span class="o">=</span> <span class="s1">'s'</span> <span class="o">+</span> <span class="n">yname</span><span class="p">;</span> <span class="n">Xsname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'s'</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">Xname</span><span class="p">]</span> <span class="c1"># standardized predictor names</span>
<span class="n">Xsmin</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="o">-</span><span class="mf">3.0</span><span class="p">];</span> <span class="n">Xsmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]</span>                        <span class="c1"># set minimums and maximums for standardized features</span>
<span class="n">Xslabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Standardized '</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">Xlabel</span><span class="p">]</span>   <span class="c1"># standardized predictor names</span>
<span class="n">Xsunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'S['</span> <span class="o">+</span> <span class="n">element</span> <span class="o">+</span> <span class="s1">']'</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">Xunit</span><span class="p">]</span>          <span class="c1"># standardized predictor names</span>
<span class="n">Xslabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xsunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xsunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>                                 <span class="c1"># instantiate feature standardization method</span>
<span class="n">Xs</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                               <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>
<span class="n">X</span><span class="p">[</span><span class="n">Xsname</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xs</span>                                                <span class="c1"># add standardized features to the predictor feature DataFrame</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Train and Test Split</h2>
<p>For convenience and simplicity we use scikit-learn‚Äôs random train and test split.</p>
<ul class="simple">
<li><p>we use the same random_state parameter so the train and test splits on original and standardized features are the same.</p></li>
<li><p>I could have just backtransformed the standardize latter (spoiler alert, I‚Äôm going to show the impact of not standardizing on the model).</p></li>
<li><p>typically we don‚Äôt have to back transform the predictor features, for our prediction workflows it is a one way trip for the predictor features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span> <span class="c1"># train and test split</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train and test DataFrame with both X and y</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Visualize the DataFrame</h2>
<p>Visualizing the train and test DataFrame is useful check before we build our models.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'       Training DataFrame          Testing DataFrame'</span><span class="p">)</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span><span class="n">df_test</span><span class="p">)</span>                          <span class="c1"># custom function for side-by-side DataFrame display</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>       Training DataFrame          Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>340</th>
      <td>0.204313</td>
      <td>4373.187870</td>
      <td>0.469659</td>
      <td>0.788406</td>
      <td>1</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.167316</td>
      <td>3088.482947</td>
      <td>-0.698603</td>
      <td>-0.860390</td>
      <td>0</td>
    </tr>
    <tr>
      <th>315</th>
      <td>0.219801</td>
      <td>2983.326185</td>
      <td>0.958720</td>
      <td>-0.995349</td>
      <td>1</td>
    </tr>
    <tr>
      <th>365</th>
      <td>0.216819</td>
      <td>2543.772663</td>
      <td>0.864542</td>
      <td>-1.559474</td>
      <td>1</td>
    </tr>
    <tr>
      <th>385</th>
      <td>0.191565</td>
      <td>3670.457907</td>
      <td>0.067120</td>
      <td>-0.113481</td>
      <td>1</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>72</th>
      <td>0.139637</td>
      <td>4747.274043</td>
      <td>-1.572630</td>
      <td>1.268510</td>
      <td>0</td>
    </tr>
    <tr>
      <th>153</th>
      <td>0.170732</td>
      <td>4535.625583</td>
      <td>-0.590742</td>
      <td>0.996879</td>
      <td>0</td>
    </tr>
    <tr>
      <th>258</th>
      <td>0.244345</td>
      <td>2696.102930</td>
      <td>1.733756</td>
      <td>-1.363972</td>
      <td>1</td>
    </tr>
    <tr>
      <th>56</th>
      <td>0.167125</td>
      <td>5500.997419</td>
      <td>-0.704644</td>
      <td>2.235841</td>
      <td>0</td>
    </tr>
    <tr>
      <th>303</th>
      <td>0.216253</td>
      <td>3959.934912</td>
      <td>0.846677</td>
      <td>0.258035</td>
      <td>1</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
&#13;

<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames.</p>
<ul class="simple">
<li><p>The describe command provides count, mean, minimum, maximum in a nice data table.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'            Training DataFrame                      Testing DataFrame'</span><span class="p">)</span> <span class="c1"># custom function for side-by-side summary statistics</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]],</span><span class="n">df_test</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>            Training DataFrame                      Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>360.000000</td>
      <td>360.000000</td>
      <td>360.000000</td>
      <td>360.000000</td>
      <td>360.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.189150</td>
      <td>3767.451286</td>
      <td>-0.009167</td>
      <td>0.011001</td>
      <td>0.602778</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.031636</td>
      <td>786.394126</td>
      <td>0.998983</td>
      <td>1.009262</td>
      <td>0.490004</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.117562</td>
      <td>1746.387548</td>
      <td>-2.269691</td>
      <td>-2.582841</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.261091</td>
      <td>5957.162150</td>
      <td>2.262519</td>
      <td>2.821285</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Porosity</th>
      <th>AI</th>
      <th>sPorosity</th>
      <th>sAI</th>
      <th>Facies</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>120.000000</td>
      <td>120.000000</td>
      <td>120.000000</td>
      <td>120.000000</td>
      <td>120.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.190311</td>
      <td>3733.164755</td>
      <td>0.027500</td>
      <td>-0.033003</td>
      <td>0.658333</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.032014</td>
      <td>763.117871</td>
      <td>1.010903</td>
      <td>0.979389</td>
      <td>0.476257</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.131230</td>
      <td>1961.600397</td>
      <td>-1.838105</td>
      <td>-2.306636</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.256172</td>
      <td>6194.573653</td>
      <td>2.107198</td>
      <td>3.125980</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
&#13;

<h2>Visualize the Train and Test Splits</h2>
<p>Let‚Äôs check the consistency and coverage of training and testing with histograms and scatter plots.</p>
<ul class="simple">
<li><p>check to make sure the training and testing cover the range of possible feature combinations</p></li>
<li><p>ensure we are not extrapolating beyond the training data with the testing cases</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">232</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">233</span><span class="p">)</span>                                              <span class="c1"># predictor features #1 and #2 scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs '</span> <span class="o">+</span>  <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">235</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">236</span><span class="p">)</span>                                              <span class="c1"># predictor features #1 and #2 scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs '</span> <span class="o">+</span>  <span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c96849d9ac15251e0c63378a9f425aa0f734d87c0a250b8ce44f189349db09c5.png" src="../Images/acefe3d0111ef4c4aadff2177c5a7676.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/c96849d9ac15251e0c63378a9f425aa0f734d87c0a250b8ce44f189349db09c5.png"/>
</div>
</div>
<p>Sometimes I find it more convenient to compare distributions by looking at CDF‚Äôs instead of histograms.</p>
<ul class="simple">
<li><p>we avoid the arbitrary choice of histogram bin size, because CDF‚Äôs are at the data resolution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>                                              <span class="c1"># categorical response feature grouped histogram</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="o">-</span><span class="mf">0.125</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'darkorange'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">0.125</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'red'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">0.875</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'darkorange'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mf">1.125</span><span class="p">],</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]),</span><span class="n">width</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'red'</span><span class="p">],</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
<span class="n">x_ticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">];</span> <span class="n">x_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Shale'</span><span class="p">,</span> <span class="s1">'Sand'</span><span class="p">];</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span><span class="n">x_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span><span class="mf">250.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">();</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">NullLocator</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' Train and Test Categorical Response Frequencies'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Facies'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7f4199220c2686c54fc8e8ceea1351ff88ab7bba2333e7441c6d268c034adbed.png" src="../Images/2bbf0a8662041cb7a556a37197370bc0.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/7f4199220c2686c54fc8e8ceea1351ff88ab7bba2333e7441c6d268c034adbed.png"/>
</div>
</div>
<p>This looks good,</p>
<ul class="simple">
<li><p>the distributions are well behaved, we cannot observe obvious gaps, outliers nor truncations</p></li>
<li><p>the test and train cases have similar coverage</p></li>
<li><p>the relative frequencies of the categorical response are similar over train and test datasets, i.e., a good train and test balance.</p></li>
</ul>
&#13;

<h2>Visualize the Predictor Feature Space</h2>
<p>Let‚Äôs build a simplified plot to visualize the 2D predictor feature space with the train and test data.</p>
<ul class="simple">
<li><p>we ask the question, will we be able to model the classification boundary? Is there a lot of data overlap? Is the boundary simple (i.e., linear) or more complicated?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot train and test data in predictor feature space</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'gold'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Sand'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkgrey'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Shale'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'gold'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkgrey'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="o">-</span><span class="mi">999</span><span class="p">],[</span><span class="o">-</span><span class="mi">999</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'white'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="o">-</span><span class="mi">999</span><span class="p">],[</span><span class="o">-</span><span class="mi">999</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'white'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training and Testing '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">Xslabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b3c308d6eca35509ace9645fe2c47910d318c23c40b049222f1c1f89bfeeea5b.png" src="../Images/56dc165df133e2ddbce54c0beda4915c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b3c308d6eca35509ace9645fe2c47910d318c23c40b049222f1c1f89bfeeea5b.png"/>
</div>
</div>
<p>This will be a difficult classification,</p>
<ul class="simple">
<li><p>there is certainly a lot of overlap</p></li>
<li><p>the boundary may be nonlinear.</p></li>
</ul>
<p>But, there is good news,</p>
<ul class="simple">
<li><p>the train and test coverage looks good in general, note there are a few testing cases that will test model extrapolation.</p></li>
<li><p>support vector machines are designed to work with this overlap!</p></li>
</ul>
&#13;

<h2>Support Vector Machine Model with Linear Kernel</h2>
<p>Let‚Äôs start simple, train and visualize linear support vector machine models over our feature space.</p>
<ul class="simple">
<li><p>This will provide a linear spatial classification model for facies 0 and 1 as a function of AI and porosity.</p></li>
</ul>
<p>We use the scikit-learn function <span class="math notranslate nohighlight">\(SVC\)</span> substantiate the support vector machine:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">svm_linear</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
</pre></div>
</div>
<p>The parameters include:</p>
<ul class="simple">
<li><p><strong>kernel</strong> the kernel type that is applied to project the data to a potentially higher dimensional space</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(C\)</span></strong> penalty for misclassification</p></li>
<li><p><strong>random_state</strong> random number see for random shuffling data for probability estimates</p></li>
</ul>
<p>We then use the command,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">svm_linear</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>to train the model with the training dataset.</p>
<p>The inputs to the fit function include:</p>
<ul class="simple">
<li><p><strong>X</strong> - the <span class="math notranslate nohighlight">\(n \times m\)</span> array with the predictor features for the training dataset</p></li>
<li><p><strong>y</strong> - the <span class="math notranslate nohighlight">\(n \times 1\)</span> array with the response feature for the training dataset</p></li>
</ul>
<p>Let‚Äôs try out 2 different <span class="math notranslate nohighlight">\(C\)</span> penalty hyperparameters to visualize the impact of the penalty for misclassification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C1_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>                                          <span class="c1"># set hyperparameters</span>
<span class="n">SVM1_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">C1_list</span><span class="p">:</span>                                             <span class="c1"># train the models</span>
    <span class="n">SVM1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">'linear'</span><span class="p">,</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y_train</span><span class="p">))</span> <span class="c1"># instantiate and train</span>
</pre></div>
</div>
</div>
</div>
<p>Looks like it ran ok!  Let‚Äôs visualize the results using the convenient visualization functions that we previously defined.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">for</span> <span class="n">iC</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C1_list</span><span class="p">):</span>                              <span class="c1"># visualize the training data and model</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">iC</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">SVM1_list</span><span class="p">[</span><span class="n">iC</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'Training Data and Linear Support Vector Machine, $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span>
                <span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0dec98b51eac972aa8541bbcf4d2742f7a09bcb6b1b19ee80196793e988428ba.png" src="../Images/f9599d00749b4f00b75cb1eeb40f7f47.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/0dec98b51eac972aa8541bbcf4d2742f7a09bcb6b1b19ee80196793e988428ba.png"/>
</div>
</div>
<p>The above plot shows the linear kernel support vector machine classification model, the training dataset and the resulting support vectors with bold circles.</p>
<ul class="simple">
<li><p>Linear kernel only provide a straight decision boundary.</p></li>
<li><p>It is hard to tune the model to fit more complicated situation.</p></li>
</ul>
<p>Note that with higher C, weighting of the sum of errors, we get a smaller margin. The linear model is fit with fewer support vectors (training data in the margin. Let‚Äôs summarize the end members of this hyperparameter with respect to simple and complicated models, potential under and overfit and the model bias and variance trade-off.</p>
<ul class="simple">
<li><p><strong>simple model \ underfit model</strong> - when C is smaller, the classifier is more tolerant with misclassified data points (higher model bias, lower model variance).</p></li>
<li><p><strong>complex model \ overfit model</strong> - when C is larger, the classifier is more sensitive to misclassified data points (lower model bias, higher model variance).</p></li>
</ul>
<p>In other words, <span class="math notranslate nohighlight">\(C\)</span> is a regularization term, just like the shrinkage term for ridge regression. Let‚Äôs try some more flexible classifiers with a different kernel so we can better see this.</p>
&#13;

<h2>Support Vector Machine Model with Polynomial Kernel</h2>
<p>The polynomial kernel is defined as</p>
<p>\begin{equation}
K(x,x‚Äô) = (x^Tx)^d,
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(d\)</span> is the degree of polynomials.</p>
<p>The hyperparameter <span class="math notranslate nohighlight">\(degree\)</span> is the order of the polynomial kernel function.</p>
<p>As previously mentioned, let‚Äôs try out different <span class="math notranslate nohighlight">\(C\)</span>, penalty for error, with a single polynomial order observe the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C2_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span>                                     <span class="c1"># set hyperparameters</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">C2_list</span><span class="p">)),</span><span class="mi">3</span><span class="p">)</span>       
<span class="n">SVM2_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">iC</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C2_list</span><span class="p">):</span>                              <span class="c1"># train the model and visualize the training data and model</span>
    <span class="n">SVM2_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">'poly'</span><span class="p">,</span><span class="n">degree</span><span class="o">=</span><span class="n">order</span><span class="p">[</span><span class="n">iC</span><span class="p">],</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y_train</span><span class="p">))</span> <span class="c1"># instantiate and train</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">iC</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">SVM2_list</span><span class="p">[</span><span class="n">iC</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s1">'Polynomial Support Vector Machine, Order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">order</span><span class="p">[</span><span class="n">iC</span><span class="p">])</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/db044f313815811c58d2c4c54acfdaba7a6e69a6ce29d65cc9a535b7ec667c76.png" src="../Images/00a2d3685850074a3a660b3f3a1259f2.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/db044f313815811c58d2c4c54acfdaba7a6e69a6ce29d65cc9a535b7ec667c76.png"/>
</div>
</div>
<p>As we increase the <span class="math notranslate nohighlight">\(C\)</span> hyperparameter, the margin shrinks, the number of support vectors reduces and the model complexity increases.</p>
&#13;

<h2>Support Vector Machine Model with Radial Basis Function Kernel</h2>
<p>Radial Basis Function (RBF) is another commonly used kernel in SVC:</p>
<p>\begin{equation}
K(x,x‚Äô) = e^{- \gamma ||x-x‚Äô||^2},
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(||x-x'||^2\)</span> is the squared Euclidean distance between two data points x and x‚Äô.</p>
<p>Gaussian kernel is a special case of RBF, where:</p>
<p>\begin{equation}
K(x,x‚Äô) = e^{- \frac {||x-x‚Äô||^2} {2 \sigma^2}}.
\end{equation}</p>
<p>By changing the value of <span class="math notranslate nohighlight">\(\gamma\)</span> and C, the classifier with an RBF kernel can be tuned.</p>
<p><span class="math notranslate nohighlight">\(\gamma\)</span> can be thought of as the spread of the kernel.</p>
<ul class="simple">
<li><p>when <span class="math notranslate nohighlight">\(\gamma\)</span> is low, the curvature of the decision boundary is low, leading to a broad decision region (low variance, high bias), low complexity</p></li>
<li><p>The <span class="math notranslate nohighlight">\(\gamma\)</span> parameter can be interpreted as the inverse of the radius of influence of samples selected by the model as support vectors, i.e., low gamma integrates more data for a smoother model</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C3_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">]</span>                                      <span class="c1"># set hyperparameters</span>
<span class="n">gamma1_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">]</span>

<span class="n">index</span><span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">C3_list</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">gamma1_list</span><span class="p">:</span>                                 <span class="c1"># train the models, visualize the training data and models</span>
        <span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'rbf'</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span> <span class="c1"># instantiate and train</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">index</span><span class="p">)</span>
        <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'RBF Support Vector Machine, $\gamma$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.4</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/82ff1c768a726890aad3ac7762874583b4c7c13de8c4a2eb9150851584e58eb1.png" src="../Images/6f78098f6348e837aa484bf3c227abf8.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/82ff1c768a726890aad3ac7762874583b4c7c13de8c4a2eb9150851584e58eb1.png"/>
</div>
</div>
<p>The impact of regularization with the C hyperparameter is very clear in this case,</p>
<ul class="simple">
<li><p>higher C, smaller margin, fewer support vectors, tends to overfit</p></li>
<li><p>lower C, larger margin, more support vectors, tends to underfit</p></li>
</ul>
<p>The impact of gamma is also very clear in this case,</p>
<ul class="simple">
<li><p>higher gamma results in more complicated, high curvature decision boundaries</p></li>
<li><p>lower gamma results in more simple, low curvature, smooth decision boundaries</p></li>
</ul>
<p>Although two facies seem to be classified properly in some cases above, there is a risk of overfitting, specifically for the high gamma and high C example.</p>
&#13;

<h2>Support Vector Machines without Standardizing the Predictor Features</h2>
<p>As promised, let‚Äôs try a model without standardizing the predictor features.</p>
<ul class="simple">
<li><p>this will be illustrative as the original predictor features have very different ranges!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">order</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">0.01</span>                                           <span class="c1"># set the hyperparameters</span>
<span class="n">svc_test1</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'poly'</span><span class="p">,</span><span class="n">degree</span><span class="o">=</span><span class="n">order</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span> <span class="c1"># fit with original features, not standardized</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>                                          <span class="c1"># set the hyperparameters</span>
<span class="n">svc_test2</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'rbf'</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span> <span class="c1"># fit with original features, not standardized</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize the training data and models</span>
<span class="n">visualize_SVM</span><span class="p">(</span><span class="n">svc_test1</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s1">'Polynomial Support Vector Machine, Order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">visualize_SVM</span><span class="p">(</span><span class="n">svc_test2</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'RBF Support Vector Machine, $\gamma$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gamma</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">', $C$ = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">C</span><span class="p">),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/214f9d02bb8c207b3c3bbefb825c5bd28482dca26856c9f37b16b8d18e527260.png" src="../Images/6284d1148a1bd492bb2d8429f0b4cd96.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/214f9d02bb8c207b3c3bbefb825c5bd28482dca26856c9f37b16b8d18e527260.png"/>
</div>
</div>
<p>What happened?</p>
<ul class="simple">
<li><p>The support vector machine with the polynomial kernel splits on the feature with the largest range, acoustic impedance. The differences in the feature with the very small range, porosity here, do not significantly influence to the model.</p></li>
<li><p>The radial basis function support vector machine has thin shale and sand layers over the acoustic impedance.</p></li>
</ul>
<p>We must standardize our predictor features to apply support vector machines.</p>
&#13;

<h2>Hyperparameter Tuning</h2>
<p>Let‚Äôs use the brute force grid search with stratified shuffle splits to iterate over multiple hyperparameters and find the optimum model complexity.</p>
<ul class="simple">
<li><p><strong>Grid Search Cross Validation</strong> - models are constructed for the full combinatorial of hyperparameters</p></li>
<li><p><strong>Stratified Shuffle Splits</strong> - ensures that the balance of categorical cases is preserved in the splits and randomizes the split to ensure the model does use the same data in the same order each time</p></li>
<li><p>warning this will take about 2 minutes to run on a regular PC</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">C_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>                              <span class="c1"># set hyperparameter cases</span>
<span class="n">gamma_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma_range</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C_range</span><span class="p">)</span>               <span class="c1"># store hyperparameter cases in a dictionary</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span> <span class="c1"># instantiate the cross validation method</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y</span><span class="p">)</span> <span class="c1"># brute force, full combinatorial search with cross validation </span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'mean_test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">C_range</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">gamma_range</span><span class="p">))</span> <span class="c1"># retrieve average accuracy and shape as a 2D array for plot</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can visualize the cross validation accuracy for all of the hyperparameter combinations.</p>
<ul class="simple">
<li><p>note, the output is average accuracy over all of the stratified shuffle splits, where accuracy is,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
Accuracy = \frac{n_{\text{correctly classified}}}{n}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot results of hyperparameter tuning                               </span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$\gamma$ Hyperparameter'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$C$ Hyperparameter'</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">'Average Classification Accuracy Over Splits'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gamma_range</span><span class="p">)),</span> <span class="n">gamma_range</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">C_range</span><span class="p">)),</span> <span class="n">C_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'SVC Hyperparameter Tuning, Cross Validation Accuracy'</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c27ee9a9f09064a90ce366edd51e5c5e6693ed7e75b913239500a89b85839743.png" src="../Images/a7a596942f23b8c59494c817735ad48e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/c27ee9a9f09064a90ce366edd51e5c5e6693ed7e75b913239500a89b85839743.png"/>
</div>
</div>
<p>We can observe a region around <span class="math notranslate nohighlight">\(C\)</span> of 100 and <span class="math notranslate nohighlight">\(\gamma\)</span> of 0.1 with the best model cross validation accuracy.</p>
&#13;

<h2>Visualizing High, Mid and Low Performing Models</h2>
<p>Now we show examples of high, mid and low performing model based on validation accuracy from the demonstration above.</p>
<ul class="simple">
<li><p>we will use parameter combinations, <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(\gamma\)</span>, from the plot above to select and rerun the cases.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">cases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Poor'</span><span class="p">,</span><span class="s1">'OK'</span><span class="p">,</span><span class="s1">'Good'</span><span class="p">]</span>                                  <span class="c1"># selected hyperparameter cases for visualization</span>
<span class="n">C_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mf">1e6</span><span class="p">]</span>
<span class="n">gamma_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.01</span><span class="p">]</span>
<span class="n">model_cases</span> <span class="o">=</span> <span class="p">[]</span>
 
<span class="k">for</span> <span class="n">icase</span><span class="p">,</span> <span class="n">case</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cases</span><span class="p">):</span>                          <span class="c1"># visualize the training data and model</span>
    <span class="n">model_cases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'rbf'</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="n">C_list</span><span class="p">[</span><span class="n">icase</span><span class="p">],</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma_list</span><span class="p">[</span><span class="n">icase</span><span class="p">])</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">Xsname</span><span class="p">],</span><span class="n">y</span><span class="p">))</span> <span class="c1"># train on all the data</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">icase</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># visualize model cases and all data</span>
    <span class="n">visualize_SVM</span><span class="p">(</span><span class="n">model_cases</span><span class="p">[</span><span class="n">icase</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xsname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xsmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xsmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xslabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="sa">r</span><span class="s1">'RBF Support Vector Machine, '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cases</span><span class="p">[</span><span class="n">icase</span><span class="p">])</span> <span class="o">+</span> <span class="s1">' Model'</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="s1">'Shale'</span><span class="p">,</span><span class="s1">'Sand'</span><span class="p">],</span><span class="n">binary_cmap</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/72e5e586c8cb2a4e90eea81cd6276fdc2175a66c300652b076105e3cc3ba6079.png" src="../Images/e3b9d37c4cafc9bc078800f977947926.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/72e5e586c8cb2a4e90eea81cd6276fdc2175a66c300652b076105e3cc3ba6079.png"/>
</div>
</div>
<p>By selecting low, mid and high accuracy hyperparameter cases from our hyperparameter tuning cross validation accuracy we obtain a good illustration example of overfit to well-fit models.</p>
&#13;

<h2>Comments</h2>
<p>I hope you found this chapter helpful. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a>,</p>
<p><em>Michael</em></p>
&#13;

<h2>The Author:</h2>
<p>Michael Pyrcz, Professor, The University of Texas at Austin
<em>Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions</em></p>
<p>With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers‚Äô and geoscientists‚Äô impact in subsurface resource development.</p>
<p>For more about Michael check out these links:</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
&#13;

<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
&#13;

<h2>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></h2>
    
</body>
</html>