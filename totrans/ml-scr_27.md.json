["```py\n## Import packages\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd \n```", "```py\n## Load penguins data\npenguins = sns.load_dataset('penguins')\npenguins = penguins.dropna().reset_index(drop = True)\nX = penguins.drop(columns = 'species')\ny = penguins['species']\n\n## Train-test split\nnp.random.seed(1)\ntest_frac = 0.25\ntest_size = int(len(y)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y)), test_size, replace = False)\nX_train = X.drop(test_idxs)\ny_train = y.drop(test_idxs)\nX_test = X.loc[test_idxs]\ny_test = y.loc[test_idxs]\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True) \n```", "```py\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n## Decision Tree bagger\nbagger1 = BaggingClassifier(n_estimators = 50, random_state = 123)\nbagger1.fit(X_train, y_train)\n\n## Naive Bayes bagger\nbagger2 = BaggingClassifier(base_estimator = GaussianNB(), random_state = 123)\nbagger2.fit(X_train, y_train)\n\n## Evaluate\nprint(np.mean(bagger1.predict(X_test) == y_test))\nprint(np.mean(bagger2.predict(X_test) == y_test)) \n```", "```py\n0.963855421686747\n0.9156626506024096 \n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100, max_features = int(np.sqrt(X_test.shape[1])), random_state = 123)\nrf.fit(X_train, y_train)\nprint(np.mean(rf.predict(X_test) == y_test)) \n```", "```py\n0.9879518072289156 \n```", "```py\n## Make binary\ny_train = (y_train == 'Adelie')\ny_test = (y_test == 'Adelie') \n```", "```py\nfrom sklearn.ensemble import AdaBoostClassifier\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True)\n\n## Build model\nabc = AdaBoostClassifier(n_estimators = 50)\nabc.fit(X_train, y_train)\ny_test_hat = abc.predict(X_test)\n\n## Evaluate \nnp.mean(y_test_hat == y_test) \n```", "```py\n0.9759036144578314 \n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nabc = AdaBoostClassifier(base_estimator = LogisticRegression(max_iter = 1000))\nabc.fit(X_train, y_train); \n```", "```py\n## Load penguins data\ntips = sns.load_dataset('tips')\ntips = tips.dropna().reset_index(drop = True)\nX = tips.drop(columns = 'tip')\ny = tips['tip']\n\n## Train-test split\nnp.random.seed(1)\ntest_frac = 0.25\ntest_size = int(len(y)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y)), test_size, replace = False)\nX_train = X.drop(test_idxs)\ny_train = y.drop(test_idxs)\nX_test = X.loc[test_idxs]\ny_test = y.loc[test_idxs] \n```", "```py\nfrom sklearn.ensemble import AdaBoostRegressor\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True)\n\n## Build model\nabr = AdaBoostRegressor(n_estimators = 50)\nabr.fit(X_train, y_train)\ny_test_hat = abr.predict(X_test)\n\n## Visualize predictions\nfig, ax = plt.subplots(figsize = (7, 5))\nsns.scatterplot(y_test, y_test_hat)\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'Test Sample $y$ vs. $\\hat{y}$')\nsns.despine() \n```", "```py\n## Load penguins data\npenguins = sns.load_dataset('penguins')\npenguins = penguins.dropna().reset_index(drop = True)\nX = penguins.drop(columns = 'species')\ny = penguins['species']\n\n## Train-test split\nnp.random.seed(1)\ntest_frac = 0.25\ntest_size = int(len(y)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y)), test_size, replace = False)\nX_train = X.drop(test_idxs)\ny_train = y.drop(test_idxs)\nX_test = X.loc[test_idxs]\ny_test = y.loc[test_idxs]\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True) \n```", "```py\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n## Decision Tree bagger\nbagger1 = BaggingClassifier(n_estimators = 50, random_state = 123)\nbagger1.fit(X_train, y_train)\n\n## Naive Bayes bagger\nbagger2 = BaggingClassifier(base_estimator = GaussianNB(), random_state = 123)\nbagger2.fit(X_train, y_train)\n\n## Evaluate\nprint(np.mean(bagger1.predict(X_test) == y_test))\nprint(np.mean(bagger2.predict(X_test) == y_test)) \n```", "```py\n0.963855421686747\n0.9156626506024096 \n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100, max_features = int(np.sqrt(X_test.shape[1])), random_state = 123)\nrf.fit(X_train, y_train)\nprint(np.mean(rf.predict(X_test) == y_test)) \n```", "```py\n0.9879518072289156 \n```", "```py\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n## Decision Tree bagger\nbagger1 = BaggingClassifier(n_estimators = 50, random_state = 123)\nbagger1.fit(X_train, y_train)\n\n## Naive Bayes bagger\nbagger2 = BaggingClassifier(base_estimator = GaussianNB(), random_state = 123)\nbagger2.fit(X_train, y_train)\n\n## Evaluate\nprint(np.mean(bagger1.predict(X_test) == y_test))\nprint(np.mean(bagger2.predict(X_test) == y_test)) \n```", "```py\n0.963855421686747\n0.9156626506024096 \n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100, max_features = int(np.sqrt(X_test.shape[1])), random_state = 123)\nrf.fit(X_train, y_train)\nprint(np.mean(rf.predict(X_test) == y_test)) \n```", "```py\n0.9879518072289156 \n```", "```py\n## Make binary\ny_train = (y_train == 'Adelie')\ny_test = (y_test == 'Adelie') \n```", "```py\nfrom sklearn.ensemble import AdaBoostClassifier\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True)\n\n## Build model\nabc = AdaBoostClassifier(n_estimators = 50)\nabc.fit(X_train, y_train)\ny_test_hat = abc.predict(X_test)\n\n## Evaluate \nnp.mean(y_test_hat == y_test) \n```", "```py\n0.9759036144578314 \n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nabc = AdaBoostClassifier(base_estimator = LogisticRegression(max_iter = 1000))\nabc.fit(X_train, y_train); \n```", "```py\n## Load penguins data\ntips = sns.load_dataset('tips')\ntips = tips.dropna().reset_index(drop = True)\nX = tips.drop(columns = 'tip')\ny = tips['tip']\n\n## Train-test split\nnp.random.seed(1)\ntest_frac = 0.25\ntest_size = int(len(y)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y)), test_size, replace = False)\nX_train = X.drop(test_idxs)\ny_train = y.drop(test_idxs)\nX_test = X.loc[test_idxs]\ny_test = y.loc[test_idxs] \n```", "```py\nfrom sklearn.ensemble import AdaBoostRegressor\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True)\n\n## Build model\nabr = AdaBoostRegressor(n_estimators = 50)\nabr.fit(X_train, y_train)\ny_test_hat = abr.predict(X_test)\n\n## Visualize predictions\nfig, ax = plt.subplots(figsize = (7, 5))\nsns.scatterplot(y_test, y_test_hat)\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'Test Sample $y$ vs. $\\hat{y}$')\nsns.despine() \n```", "```py\n## Make binary\ny_train = (y_train == 'Adelie')\ny_test = (y_test == 'Adelie') \n```", "```py\nfrom sklearn.ensemble import AdaBoostClassifier\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True)\n\n## Build model\nabc = AdaBoostClassifier(n_estimators = 50)\nabc.fit(X_train, y_train)\ny_test_hat = abc.predict(X_test)\n\n## Evaluate \nnp.mean(y_test_hat == y_test) \n```", "```py\n0.9759036144578314 \n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nabc = AdaBoostClassifier(base_estimator = LogisticRegression(max_iter = 1000))\nabc.fit(X_train, y_train); \n```", "```py\n## Load penguins data\ntips = sns.load_dataset('tips')\ntips = tips.dropna().reset_index(drop = True)\nX = tips.drop(columns = 'tip')\ny = tips['tip']\n\n## Train-test split\nnp.random.seed(1)\ntest_frac = 0.25\ntest_size = int(len(y)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y)), test_size, replace = False)\nX_train = X.drop(test_idxs)\ny_train = y.drop(test_idxs)\nX_test = X.loc[test_idxs]\ny_test = y.loc[test_idxs] \n```", "```py\nfrom sklearn.ensemble import AdaBoostRegressor\n\n## Get dummies\nX_train = pd.get_dummies(X_train, drop_first = True)\nX_test = pd.get_dummies(X_test, drop_first = True)\n\n## Build model\nabr = AdaBoostRegressor(n_estimators = 50)\nabr.fit(X_train, y_train)\ny_test_hat = abr.predict(X_test)\n\n## Visualize predictions\nfig, ax = plt.subplots(figsize = (7, 5))\nsns.scatterplot(y_test, y_test_hat)\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'Test Sample $y$ vs. $\\hat{y}$')\nsns.despine() \n```"]