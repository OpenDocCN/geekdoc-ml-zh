<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Decision Tree</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Decision Tree</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_decision_tree.html">https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_decision_tree.html</a></blockquote>

<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book ‚ÄúApplied Machine Learning in Python: a Hands-on Guide with Code‚Äù.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, <em>Applied Machine Learning in Python: A Hands-on Guide with Code</em> [e-book]. Zenodo. doi:10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="../Images/7e4ea662f44af1eae87e87ecbb962ff4.png" data-original-src="https://zenodo.org/badge/863274676.svg"/></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, <em>MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository</em> (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312. GitHub repository: <a class="github reference external" href="https://github.com/GeostatsGuy/MachineLearningDemos">GeostatsGuy/MachineLearningDemos</a> <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="../Images/4e3a59c17d684b06a170c4af84e0f631.png" data-original-src="https://zenodo.org/badge/862519860.svg"/></a></p>
</div>
<p>By Michael J. Pyrcz <br/>
¬© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>Decision Tree</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/JUGo1Pu3QT4?si=ebQXv6Yglar0mYWp">Decision Tree</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/m5_wk310fho?si=up-mzVPHvniXsYE6">Random Forest</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/___T8_ixIwc?si=ozHR_eIuMF3SPTxJ">Gradient Boosting</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael‚Äôs Story</a>.</p>
<section id="motivation">
<h2>Motivation</h2>
<p>Decision trees are not the most powerful, cutting edge method in machine learning, so why cover decision trees?</p>
<ul class="simple">
<li><p>one of the most understandable, interpretable predictive machine learning models</p></li>
<li><p>decision trees are enhanced with random forests, bagging and boosting to be one of the best machine learning predictive models in many cases</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/90b8611f2db53bd1e441fa8eb6dce0d1.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/blackspruce.png"/>
  <figcaption style="text-align: center;"> A single proud black spruce tree within the Boreal Forest in Alaska, similar to the northern region of my home province of Alberta. Crop of photo from https://www.britannica.com/plant/spruce#/media/1/561445/8933, access date May 1, 2025. 
</figcaption>
</figure>
<p>Let‚Äôs cover some key aspects of decision trees.</p>
</section>
<section id="model-formulation">
<h2>Model Formulation</h2>
<p>The prediction feature space is partitioned into <span class="math notranslate nohighlight">\(J\)</span> exhaustive, mutually exclusive regions <span class="math notranslate nohighlight">\(R_1, R_2, \ldots, R_J\)</span>. For a given prediction case <span class="math notranslate nohighlight">\(x_1,\ldots,x_m \in R_j\)</span>, the prediction is:</p>
<p><strong>Regression</strong> - the average of the training data in the region, <span class="math notranslate nohighlight">\(R_j\)</span></p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} y_i
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the predicted value for input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, <span class="math notranslate nohighlight">\(R_j\)</span> is the region (leaf node) that <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> falls into, <span class="math notranslate nohighlight">\(|R_j|\)</span> is the number of training samples in region <span class="math notranslate nohighlight">\(R_j\)</span>, and <span class="math notranslate nohighlight">\(y_i\)</span> is the actual target values of those training samples in <span class="math notranslate nohighlight">\(R_j\)</span>.</p>
<p><strong>Classification</strong> - category with the plurality of training cases (most common case) in region <span class="math notranslate nohighlight">\(R_j\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \arg\max_{c \in C} \left( \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} \mathbb{1}(y_i = c) \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> is the set of all possible categories, <span class="math notranslate nohighlight">\(\mathbb{1}(y_i = c)\)</span> is indicator transform, 1 if <span class="math notranslate nohighlight">\(y_i = c\)</span>, 0 otherwise, <span class="math notranslate nohighlight">\(|R_j|\)</span> is the number of training samples in region <span class="math notranslate nohighlight">\(R_j\)</span>, and <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the predicted class label.</p>
<p>The predictor space, <span class="math notranslate nohighlight">\(ùëã_1,\ldots,ùëã_ùëö\)</span>, is segmented into <span class="math notranslate nohighlight">\(J\)</span> mutually exclusive, exhaustive regions, <span class="math notranslate nohighlight">\(R_j, j = 1,\ldots,J\)</span>, where the regions are,</p>
<ul class="simple">
<li><p><strong>mutually exclusive</strong> ‚Äì any combination of predictor features, <span class="math notranslate nohighlight">\(x_1,\ldots,x_ùëö\)</span>, only belongs to a single region, <span class="math notranslate nohighlight">\(R_j\)</span></p></li>
<li><p><strong>exhaustive</strong> ‚Äì all combinations of predictor feature values belong a region, <span class="math notranslate nohighlight">\(R_j\)</span>, i.e., all the regions, <span class="math notranslate nohighlight">\(R_j, j = 1,\ldots,J\)</span>, cover entire predictor  feature space</p></li>
</ul>
<p>All prediction cases, <span class="math notranslate nohighlight">\(x_1,\ldots,x_m\)</span> that fall in the same region, <span class="math notranslate nohighlight">\(R_j\)</span>, are estimated with the same value.</p>
<ul class="simple">
<li><p>the prediction model inherently discontinuous at the region boundaries</p></li>
</ul>
<p>For example, consider this decision tree prediction model for the production response feature, <span class="math notranslate nohighlight">\(\hat{Y}\)</span>¬†ÃÇfrom porosity, <span class="math notranslate nohighlight">\(X_1\)</span>, predictor feature,</p>
<figure style="text-align: center;">
  <img src="../Images/98d8fb73fe41299a6a9b443163b47c96.png" style="display: block; margin: 0 auto; width: 80%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/regions.png"/>
  <figcaption style="text-align: center;"> Four region decision tree with data and predictions, \(\hat{Y}(R_j) = \overline{Y}(R_j)\) by region, \(R_j, j=1,‚Ä¶,4\). For example, given a predictor feature value of 13% porosity, the model predicts about 2,000 MCFPD for production.
</figcaption>
</figure>
<p>How do we segment the predictor feature space?</p>
<p>Look at this example with predictor features porosity and brittleness to predict the production response feature.</p>
<figure style="text-align: center;">
  <img src="../Images/31b00c9edfa4f39d2ae71626df2cd687.png" style="display: block; margin: 0 auto; width: 80%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/complexboundaries.png"/>
  <figcaption style="text-align: center;"> A very complicated segmentation of the predictor feature space with 3 regions.
</figcaption>
</figure>
<ul class="simple">
<li><p>these are very efficient boundaries that would capture low, mid and high production</p></li>
</ul>
<p>But, this model would be quite complicated,</p>
<ul class="simple">
<li><p>requiring a large number of model parameters</p></li>
<li><p>difficult to train for a large number of prediction features, i.e., high dimensionality</p></li>
</ul>
<p>If I can convince you to accept these regions instead, then you would have a model that,</p>
<ul class="simple">
<li><p>is very easy to train</p></li>
<li><p>has very few parameters</p></li>
<li><p>very compact and interpretable</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/13cf7080472834d100f0e7812be6d2d3.png" style="display: block; margin: 0 auto; width: 80%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/simpleboundaries.png"/>
  <figcaption style="text-align: center;"> A simpler segmentation of the predictor feature space with 9 regions, but much fewer parameters and easy to train for any dimensionality.
</figcaption>
</figure>
<p>This is a set of regions based on hierarchical, binary segmentation. Let‚Äôs clarify the concept of predictor feature space and then explain this form of predictor feature segmentation.</p>
</section>
<section id="predictor-feature-space">
<h2>Predictor Feature Space</h2>
<p>Let‚Äôs step back and establish the concept of predictor feature space. We define it as,</p>
<ul class="simple">
<li><p>the space that includes all possible estimation problems, i.e., the combination of all possible predictor feature values, <span class="math notranslate nohighlight">\(x_1, x_2,\ldots,x_m\)</span>.</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/2328290a847e59dd59f76c37a18c6df3.png" style="display: block; margin: 0 auto; width: 60%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/predictorspace.png"/>
  <figcaption style="text-align: center;"> Illustration of predictor feature space for the case of 3 predictor features with specified minimum and maximum values per feature resulting in a rectangular cuboid of possible predictions, $x_1, x_2, x_3$.
</figcaption>
</figure>
<p>Typically this is defined by the range of possible values, <span class="math notranslate nohighlight">\(x_{\alpha} \in \left[X_{\alpha,\text{ùëöùëñùëõ}},ùëã_{\alpha,\text{max}} \right]\)</span>‚Äã, resulting in,</p>
<ul class="simple">
<li><p>1 predictor feature <span class="math notranslate nohighlight">\(\rightarrow\)</span> line segment</p></li>
<li><p>2 predictor features <span class="math notranslate nohighlight">\(\rightarrow\)</span> rectangle</p></li>
<li><p>3 predictor features <span class="math notranslate nohighlight">\(\rightarrow\)</span> rectangular cuboid</p></li>
<li><p><span class="math notranslate nohighlight">\(&gt;\)</span>3 predictor features <span class="math notranslate nohighlight">\(\rightarrow\)</span> hyperrectangle</p></li>
</ul>
<p>While we define the predictor feature space with the ranges of the predictor features, I should provide a cautionary note.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Decision Trees have an Implicit Extrapolation Model</p>
<p>As you will see below, the regions along the exterior extend to infinity, effectively assuming a constant extrapolation model.</p>
</div>
</section>
<section id="tree-loss-functions">
<h2>Tree Loss Functions</h2>
<p>For regression trees we minimize the residual sum of squares and for classification trees we minimize the weighted average Gini impurity.</p>
<p>The Residual Sum of Squares (RSS) measures the total squared difference between the actual values and predicted values in a regression tree,</p>
<div class="math notranslate nohighlight">
\[
\text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(J\)</span> is the total number of regions in the tree, <span class="math notranslate nohighlight">\(R_j\)</span> is the <span class="math notranslate nohighlight">\(j\)</span> region, <span class="math notranslate nohighlight">\(y_i\)</span> is the truth value of the response feature at observation the <span class="math notranslate nohighlight">\(i\)</span> training data, and <span class="math notranslate nohighlight">\(\hat{y}_{R_j}\)</span> is the predicted value for region <span class="math notranslate nohighlight">\(R_j\)</span>, the mean of <span class="math notranslate nohighlight">\(y_i \; \forall \; i \in R_j\)</span>.</p>
<p>When a parent node splits into two child nodes ( t_L ) and ( t_R ), the weighted Gini impurity is:</p>
<div class="math notranslate nohighlight">
\[
\text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
\]</div>
<p>where <span class="math notranslate nohighlight">\(J\)</span> is the total number of regions in the tree, <span class="math notranslate nohighlight">\(N\)</span> is the total number of samples in the dataset,   <span class="math notranslate nohighlight">\(N_j\)</span> is the number of samples in leaf node <span class="math notranslate nohighlight">\(j\)</span>, and <span class="math notranslate nohighlight">\(\text{Gini}(j)\)</span> is the Gini impurity of leaf node <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>The Gini impurity for a single decision tree node is calculated as,</p>
<div class="math notranslate nohighlight">
\[
\text{Gini}(j) = 1 - \sum_{c=1}^{C} p_{j,c}^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{j,c}\)</span> is the proportion of class <span class="math notranslate nohighlight">\(c\)</span> samples in node <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>For classification our loss function does not compare the predictions to the truth values like our regression loss!</p>
<ul class="simple">
<li><p>the Gini impurity penalizes mixtures of training data categories! A region of all one category of training data will have a Gini impurity of 0 to contribute to the over all loss.</p></li>
</ul>
<p>Note that the by-region Gini impurity is,</p>
<ul class="simple">
<li><p><strong>weighted</strong> - by the number of training data in each regions, regions with more training data have greater impact on the overall loss</p></li>
<li><p><strong>averaged</strong> - over all the regions to calculate the total Gini impurity of the decision tree</p></li>
</ul>
<p>These losses are calculated during,</p>
<ul class="simple">
<li><p><strong>tree model training</strong> - with respect to training data to grow the tree</p></li>
<li><p><strong>tree model tuning</strong> - with respect to withheld testing data to select the optimum tree complexity.</p></li>
</ul>
<p>Let‚Äôs talk about tree model training first and then tree model tuning.</p>
</section>
<section id="training-the-tree-model">
<h2>Training the Tree Model</h2>
<p>How do we calculate these mutually exclusive, exhaustive regions? This is accomplished through hierarchical binary segmentation of the predictor feature space.</p>
<p>Training a decision tree model is both,</p>
<ol class="arabic simple">
<li><p>assigning the mutual exclusive, exhaustive regions</p></li>
<li><p>building a decision tree, each region is a terminal node, also known as a leaf node</p></li>
</ol>
<p>These are the same thing! Let‚Äôs list the steps and then walk through a training a tree to demonstrate this.</p>
<ol class="arabic simple" start="0">
<li><p><strong>Assign All Data to a Single Region</strong> - this region covers the entire predictor feature space</p></li>
<li><p><strong>Scan All Possible Splits</strong> - over all regions and over all features</p></li>
<li><p><strong>Select the Best Split</strong> - this is greedy optimization, i.e., the best split minimizes the residual sum of squares of errors over all the training data <span class="math notranslate nohighlight">\(y_i\)</span> over all of the regions <span class="math notranslate nohighlight">\(j = 1,\ldots,J\)</span>.</p></li>
<li><p><strong>Iterate Until Very Overfit</strong> - return to step 1 for the next split until the tree is very overfit.</p></li>
</ol>
<p>Note, this method for training a decision tree is a solution heuristic,</p>
<ul class="simple">
<li><p>there is no effort to jointly optimize all splits at once, for example, to select a suboptimal split to maximize training error reduction with a subsequent split</p></li>
</ul>
<p>Also, the decision tree is constructed from the top down.</p>
<ul class="simple">
<li><p>we begin with a single region that covers the entire predictor feature space and then proceed with a sequence of region splits / tree branches.</p></li>
</ul>
<p>Now let‚Äôs illustrate this with an example, predicting natural gas production response feature with 2 predictor features,</p>
<ul class="simple">
<li><p>porosity - impacting pore volume and flow</p></li>
<li><p>brittleness - impacting the ability to induce and hold open fractures</p></li>
</ul>
<p>We start with all our predictor feature space in a single region with the single possible prediction as the average of all the training data.</p>
<figure style="text-align: center;">
  <img src="../Images/4a6be7714eba68f580cfee8421d15f61.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_1nodes.png"/>
  <figcaption style="text-align: center;"> Initial data all in 1 region, i.e., hyperparameter number of leaf nodes of 1, predict with the global mean of the response feature.
</figcaption>
</figure>
<p>Next, we scan all features to find the first best split, porosity of 16.7%. This very simple decision tree with a single decision node and 2 regions or leaf nodes is known as a stump tree, i.e., the simplest possible decision tree model.</p>
<figure style="text-align: center;">
  <img src="../Images/c418139a6f37dbda3462cd0ab2d519d6.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_2nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 2,  first best split resulting in a stump tree.
</figcaption>
</figure>
<p>Now we scan over both regions and over all predictor features to find the best next split, brittleness of 36.1 in the greater than or equal to porosity of 16.7% region.</p>
<figure style="text-align: center;">
  <img src="../Images/5786413cc0e329c72793e1d2adf2a54b.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_3nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 3.
</figcaption>
</figure>
<p>Continuing, we find our next split of porosity of 18.5% in the upper right region. We now have 4 regions. Our decision tree is starting to capture the increasing production with increasing porosity along with lower production for low brittleness.</p>
<figure style="text-align: center;">
  <img src="../Images/9931df51305b719f93fc51eecf44641d.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_4nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 4.
</figcaption>
</figure>
<p>Now the next best split is in the original lower porosity region from the stump tree with porosity of 13.2%.</p>
<figure style="text-align: center;">
  <img src="../Images/597e4adea071f8f67d71e82f4c1015f2.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_5nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 5.
</figcaption>
</figure>
<p>The next best split divides the region in the middle of porosity, capturing the trend of low production for low brittleness, even with high porosity.</p>
<figure style="text-align: center;">
  <img src="../Images/b1024ff1d9be25d7b007a5ee890b6d8f.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_6nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 6.
</figcaption>
</figure>
<p>The next split is capturing the reduction in production with high brittleness, even with high porosity,</p>
<figure style="text-align: center;">
  <img src="../Images/782938df9c411d347bdc8e6e031a6d66.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_7nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 7.
</figcaption>
</figure>
<p>and this split continues to capture this same pattern in the data.</p>
<figure style="text-align: center;">
  <img src="../Images/c3401dcf9ca381bf65d39fada64ecde2.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_8nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 8.
</figcaption>
</figure>
<p>For brevity we stop here, and make these observations,</p>
<ul class="simple">
<li><p>hierarchical, binary segmentation is the same as sequentially building a decision tree, each split adds a new decision node and increases the number of leaf nodes by one.</p></li>
<li><p>the simple decision trees are in the complicated decision tree, i.e., if we build an <span class="math notranslate nohighlight">\(8\)</span> leaf node model, we have the <span class="math notranslate nohighlight">\(8, 7, \ldots, 2\)</span> leaf node model by sequentially removing the decision nodes, in the order of last one is the first one to remove.</p></li>
<li><p>the ultimate overfit model is number of leaf nodes equal to the number of training data. In this case, the training error is 0.0 as have one region for each training data a we estimate with the training data response feature values for all the at the training data cases.</p></li>
</ul>
</section>
<section id="updating-the-loss-function-with-a-new-split">
<h2>Updating the Loss Function with a New Split</h2>
<p>To find the next best split, we must scan over all regions, and over all features with the regions. This may sound like a lot of computation, but it is quite efficient.</p>
<ul class="simple">
<li><p>we only need to check the midpoints between sorted training data for each feature in each region, because any split that does not change the region assignment of a training data will not change the training loss.</p></li>
</ul>
<p>For a region <span class="math notranslate nohighlight">\(R\)</span> split into candidate regions <span class="math notranslate nohighlight">\(R_L\)</span> and <span class="math notranslate nohighlight">\(R_R\)</span>, the RSS after the split is:</p>
<div class="math notranslate nohighlight">
\[
\text{RSS}_{\text{split}} = \sum_{i \in R_L} (y_i - \hat{y}_{R_L})^2 + \sum_{i \in R_R} (y_i - \hat{y}_{R_R})^2
\]</div>
<p>where, <span class="math notranslate nohighlight">\(y_i\)</span> is the actual response feature for training data observation <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(\hat{y}_{R_L}\)</span>, <span class="math notranslate nohighlight">\(\hat{y}_{R_R}\)</span> is the mean of training data response feature in candidate regions <span class="math notranslate nohighlight">\(R_L\)</span> and <span class="math notranslate nohighlight">\(R_R\)</span>.</p>
<p>Note, we add in the RSS components from all the other regions to get the total model RSS to find the best split over all the regions,</p>
<ul class="simple">
<li><p>the split with the lowest <span class="math notranslate nohighlight">\(\text{RSS}_{\text{split}}\)</span> is selected for the region and compared to all other best splits in the other regions to find the next best split, greedy solution.</p></li>
</ul>
<p>Now we are prepared for tuning a decision tree model.</p>
</section>
<section id="tuning-the-tree-model">
<h2>Tuning the Tree Model</h2>
<p>To tune the decision tree we take the very overfit trained tree model,</p>
<ul class="simple">
<li><p>sequentially cut the last decision node</p></li>
<li><p>i.e., prune the last branch of the decision tree</p></li>
</ul>
<p>Since the simpler trees are inside the complicated tree!</p>
<p>We can calculate test error as we prune and select tree with minimum test error</p>
<p>We overfit the decision tree model, with a large number of leaf nodes and then we reduce the number of leaf nodes while tracking the test error.</p>
<ul class="simple">
<li><p>we select the number of leaf nodes that minimize the testing error.</p></li>
<li><p>since we are sequentially removing the last branch to simplify the tree, we call model tuning <strong>pruning</strong> for decision trees</p></li>
</ul>
<p>Here is an overfit decision tree with many, <span class="math notranslate nohighlight">\(100\)</span>, leaf nodes.</p>
<figure style="text-align: center;">
  <img src="../Images/3383a81c81cdb9ed5c96432a485e7194.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/veryoverfit.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, hyperparameter number of leaf nodes of 100 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes (right).
</figcaption>
</figure>
<p>Since this tree is calculated with my interactive Python dashboard, I am able to easily reduce the number of regions from <span class="math notranslate nohighlight">\(100, 99, 98, 96, 95, \ldots\)</span> and visualize the tree to explore complicated to simple trees.</p>
<ul class="simple">
<li><p>by doing this we can demonstrate that the simple trees are in the complicated tree.</p></li>
</ul>
<p>For example, here‚Äôs the 5 region decision tree in the overfit 100 region decision tree,</p>
<figure style="text-align: center;">
  <img src="../Images/566f12da178143a07d17de9adc100684.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/5nodetree.png"/>
  <figcaption style="text-align: center;"> The 5 leaf node tree in the very overfit 100 leaf node tree model.
</figcaption>
</figure>
<p>and here is the 10 region decision tree in the overfit 100 region decision tree,</p>
<figure style="text-align: center;">
  <img src="../Images/96e18c15cb01e9558e4b2512a6b1ef20.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/10nodetree.png"/>
  <figcaption style="text-align: center;"> The 10 leaf node tree in the very overfit 100 leaf node tree model.
</figcaption>
</figure>
<p>and finally, here is the 20 region decision tree in the overfit 100 region decision tree,</p>
<figure style="text-align: center;">
  <img src="../Images/19d39b48f3c129dc12099bd52c3bb546.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/20nodetree.png"/>
  <figcaption style="text-align: center;"> The 20 leaf node tree in the very overfit 100 leaf node tree model.
</figcaption>
</figure>
<p>You might wonder, why I didn‚Äôt just update the decision tree plot? scikit-learn‚Äôs decision tree plotting function recales the plot and the geometry changes so much it is not easy to visualize the simple trees within the complicated tree.</p>
<ul class="simple">
<li><p>I think this approach of visualizing the simple trees and drafting the polylines works well for educational purposes!</p></li>
</ul>
<p>Now let‚Äôs return to our very overfit tree and demonstrate the hyperparameter tuning by tree pruning approach,</p>
<figure style="text-align: center;">
  <img src="../Images/24f9e4745fc35d0cf9c039aec32684f0.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune100.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>Now, we identify the last added branch and remove it to calculate the 99 region decision tree, a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/2c6ffbcc9634d3d3f7350cb0564380d1.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune99.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 98 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/efae49220a4ea118479dcc21d333e37a.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune98.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 97 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/f4af3bd7dce90621152ff68c398bd578.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune97.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 96 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/eeea92714bf8b2f878a05ce7f50e9eae.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune96.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 95 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/90180132c5183f3342f2051c501aee4a.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune95.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 94 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/53f087807a31ef6a8e1be0e1ec170292.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune94.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>Now let‚Äôs return and look at the very overfit model and add some more information over different levels of complexity.</p>
<figure style="text-align: center;">
  <img src="../Images/ab38e613fbf8ad17fdab5bd4f89adaa6.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/overfit.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, hyperparameter number of leaf nodes of 100 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes (right).
</figcaption>
</figure>
<p>I include the,</p>
<ul class="simple">
<li><p>train and test cross validation plot with nearly perfect training prediction and very poor testing prediction for the 100 leaf node overfit decision tree</p></li>
<li><p>train and test error versus number of leaf nodes.</p></li>
</ul>
<p>This demonstrates that the decision tree model is indeed very overfit, for example, see the falling training error and rising testing error.</p>
<p>Now we prune the decision nodes until we obtain the model with the minimum testing error at about 19 leaf nodes.</p>
<figure style="text-align: center;">
  <img src="../Images/064eac7331174101230aee9c413623f3.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tuned.png"/>
  <figcaption style="text-align: center;"> Tuned decision tree, hyperparameter number of leaf nodes of 20 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes indicating that testing error is minimized (right).
</figcaption>
</figure>
<p>For completeness, I have included an underfit model, i.e., if we prune our decision tree too much, with only 8 leaf nodes.</p>
<figure style="text-align: center;">
  <img src="../Images/9d7b773b0de829f858763876c59a1c04.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/underfit.png"/>
  <figcaption style="text-align: center;"> Underfit decision tree, hyperparameter number of leaf nodes of 8 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes indicating that testing error is minimized (right).
</figcaption>
</figure>
<p>Note, that the train and test error are both very high with the underfit decision tree.</p>
<p>I prefer number of leaf nodes as my decision tree hyperparameter because it provides,</p>
<ul class="simple">
<li><p><strong>continuous, uniform increase in complexity</strong> -  equal steps in increased complexity without jumps</p></li>
<li><p><strong>intuitive control on complexity</strong> - we can understand and relate the <span class="math notranslate nohighlight">\(2, 3, \ldots, 100\)</span> leaf node decision trees</p></li>
<li><p><strong>flexible complexity</strong> - the tree is free to grow in any manner to reduce training error, including highly asymmetric decision trees</p></li>
</ul>
<p>There are other common decision tree hyperparameters including,</p>
<ul class="simple">
<li><p><strong>Minimum reduction in RSS</strong> ‚Äì related to the idea that incremental increase in complexity must be offset by sufficient reduction in training error. This could stop the model early, for example, a split with low reduction in training error could lead to a subsequent split with a much larger reduction in training error</p></li>
<li><p><strong>Minimum number of training data in each region</strong> ‚Äì related to the concept of accuracy of the by-region estimates, i.e., we need at least <span class="math notranslate nohighlight">\(n\)</span> data for a reliable mean and most common category</p></li>
<li><p><strong>Maximum number of levels</strong> ‚Äì forces symmetric trees, similar number of splits to get to each leaf node. There is a large change in model complexity with change in the hyperparameter.</p></li>
</ul>
</section>
<section id="the-prediction-model">
<h2>The Prediction Model</h2>
<p>The decision tree prediction model is represented as <strong>set of nested if statements</strong>, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="k">if</span> <span class="n">porosity</span> <span class="o">&gt;</span> <span class="mf">0.15</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">brittleness</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">7000</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">brittleness</span> <span class="o">&lt;</span> <span class="mi">40</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">3000</span>
</pre></div>
</div>
<p>and the predictions as stated above are either the,</p>
<ul class="simple">
<li><p>regression - average of the training data in the region</p></li>
<li><p>classification - the plurality, most common category, of the training data in the region</p></li>
</ul>
</section>
<section id="shapley-values-from-decision-trees">
<h2>Shapley Values from Decision Trees</h2>
<p>Recall, we need to take a single model, for example, <span class="math notranslate nohighlight">\(f(x_1,x_2,x_3,x_4)\)</span>, and make an estimate for all possible combinations of feature subsets, for example,</p>
<div class="math notranslate nohighlight">
\[
f(x_1) \quad f(x_2,x_4) \quad f(x_1,x_2,x_3)
\]</div>
<ul class="simple">
<li><p>note, the na√Øve approach to calculate Shapley values is to train the full combinatorial of models with different predictor features, but we don‚Äôt want to make new models if our goal is feature importance to diagnose our specific model, <span class="math notranslate nohighlight">\(f\)</span>, to support model explainability.</p></li>
</ul>
<p>One solution is to apply a variety of approaches, similar to imputation methods, including,</p>
<ul class="simple">
<li><p>replace the excluded feature(s) with the expected value, global mean,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(x_1,x_2,x_3) = f(x_1,x_2,x_3,x_4=E[x_4])
\]</div>
<ul class="simple">
<li><p>replace the excluded feature(s) with the median value, the 50th percentile,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(x_1,x_2,x_3) = f(x_1,x_2,x_3,x_4=P50_{x_4})
\]</div>
<p>There is a more accurate, unique method with tree-based models, we can actually remove the influence of any of the features from the decision tree after the model is trained, for example,</p>
<ul class="simple">
<li><p>remove all <span class="math notranslate nohighlight">\(x_4\)</span> branches, and then the model does not use <span class="math notranslate nohighlight">\(x_4\)</span> to make the prediction</p></li>
</ul>
<p>Of course, we cannot just remove branches and ‚Äòwood glue‚Äô the tree back together!</p>
<ul class="simple">
<li><p>we must make new predictions that don‚Äôt introduce bias.</p></li>
</ul>
<p>Let‚Äôs demonstrate the procedure for removing a feature from a decision tree, with a couple of prediction cases,</p>
<ol class="arabic simple">
<li><p>Here is a prediction case that does not encounter the removed feature, <span class="math notranslate nohighlight">\(x_2\)</span> is removed and,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x_1=25
\]</div>
<ul class="simple">
<li><p>the prediction is made as usual.</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/a9783a200ab476bb3a92cb2cfec12d63.png" style="display: block; margin: 0 auto; width: 60%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/shaptree1.png"/>
  <figcaption style="text-align: center;"> Prediction case that does not encounter the removed feature is made as usual.
</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[
f(x_1=25) = 20
\]</div>
<ol class="arabic simple" start="2">
<li><p>A prediction case that does encounter the removed feature, <span class="math notranslate nohighlight">\(x_1\)</span> is removed and,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x_2 = 60
\]</div>
<ul class="simple">
<li><p>we effectively go down both paths, by weighting, by number of training data, the solution over both paths!</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/8152951b8a3c920f03825528d98c5ae7.png" style="display: block; margin: 0 auto; width: 60%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/shaptree2.png"/>
  <figcaption style="text-align: center;"> Prediction case that does encounter the removed feature is made by weighting both paths by the number of training data.
</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[
f(x_2=60) = \frac{60}{100} \left[ \frac{15}{60} \times 20 + \frac{45}{60} \times 70 \right] + \frac{40}{100} \left[130\right] = 86.5
\]</div>
<div class="math notranslate nohighlight">
\[
f(x_2=60) = 86.5
\]</div>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>                                      <span class="c1"># toggle to supress warnings</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>                                      <span class="c1"># tree program from scikit learn (package for machine learning)</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">_tree</span>                                <span class="c1"># for accessing tree information</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>                      <span class="c1"># graphical visualization of trees</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>           <span class="c1"># multi-processor K-fold crossvalidation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>          <span class="c1"># train and test split</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># supress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions</h2>
<p>Let‚Äôs define a couple of functions to streamline plotting correlation matrices and visualization of a decision tree regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span>

<span class="k">def</span> <span class="nf">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">,</span><span class="n">nominal</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span> <span class="c1"># feature ranking plot</span>
    <span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">);</span> <span class="n">mask_low</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">-</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">nominal</span><span class="o">-</span><span class="n">mmin</span><span class="p">);</span> <span class="n">mask_high</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">mmax</span><span class="o">-</span><span class="n">nominal</span><span class="p">);</span> <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span><span class="s1">'r--'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'dodgerblue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'lightcoral'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_low</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">mask_low</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_high</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">mask_high</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predictor Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'RdBu_r'</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
    
<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks   </span>

<span class="k">def</span> <span class="nf">plot_CDF</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">):</span>
    <span class="n">cumprob</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">extract_rules</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>                 <span class="c1"># recursive method to extract rules, from paulkernfeld Stack Overflow (?)</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">def</span> <span class="nf">traverse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">prev_rule</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>        <span class="c1"># Leaf node</span>
            <span class="n">class_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">node</span><span class="p">])</span>
            <span class="n">rule</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prev_rule</span><span class="si">}</span><span class="s2"> =&gt; Class </span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2">"</span>
            <span class="n">rules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Split node</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="n">node</span><span class="p">]]</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">left_child</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">right_child</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">traverse</span><span class="p">(</span><span class="n">left_child</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prev_rule</span><span class="si">}</span><span class="s2"> &amp; </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> &lt;= </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> <span class="c1"># Recursively traverse left and right subtrees</span>
            <span class="n">traverse</span><span class="p">(</span><span class="n">right_child</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prev_rule</span><span class="si">}</span><span class="s2"> &amp; </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> &gt; </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">traverse</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"Root"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rules</span>

<span class="k">def</span> <span class="nf">plot_decision_tree_regions</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span><span class="n">X_min</span><span class="p">,</span><span class="n">X_max</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="n">extract_rules</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">irule</span><span class="p">,</span> <span class="n">____</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rules</span><span class="p">):</span>
        <span class="n">rule</span> <span class="o">=</span> <span class="n">rules</span><span class="p">[</span><span class="n">irule</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">X_min</span> <span class="o">=</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">X_max</span> <span class="o">=</span> <span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">Y_min</span> <span class="o">=</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span> <span class="n">Y_max</span> <span class="o">=</span> <span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
        <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span> <span class="k">if</span> <span class="n">val</span><span class="o">==</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'&lt;='</span><span class="p">:</span>
                <span class="n">X_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">X_max</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">X_min</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span> <span class="k">if</span> <span class="n">val</span><span class="o">==</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'&lt;='</span><span class="p">:</span>
                <span class="n">Y_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">Y_max</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Y_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">Y_min</span><span class="p">)</span> 
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="n">X_min</span><span class="p">,</span><span class="n">Y_min</span><span class="p">),</span><span class="n">X_max</span><span class="o">-</span><span class="n">X_min</span><span class="p">,</span><span class="n">Y_max</span><span class="o">-</span><span class="n">Y_min</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">ec</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">fc</span><span class="o">=</span><span class="s2">"none"</span><span class="p">))</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_min</span> <span class="o">+</span> <span class="n">X_max</span><span class="p">)</span><span class="o">*</span><span class="mf">0.5</span><span class="p">;</span> <span class="n">cy</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_min</span> <span class="o">+</span> <span class="n">Y_max</span><span class="p">)</span><span class="o">*</span><span class="mf">0.5</span><span class="p">;</span> <span class="n">loc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">cx</span><span class="p">,</span><span class="n">cy</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">annotate</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">loc</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">,.0f</span><span class="si">}</span><span class="s1">'</span><span class="p">),</span><span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">cx</span><span class="p">,</span><span class="n">cy</span><span class="p">),</span><span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
                         <span class="n">weight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">'white'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">visualize_tree_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span>
                         <span class="n">ymax</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabel</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span><span class="c1"># plots the data points and the decision tree prediction </span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>
    <span class="n">X1plot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mf">300.0</span><span class="p">;</span> <span class="n">X2plot_step</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mf">300.0</span> <span class="c1"># resolution of the model visualization</span>
    <span class="n">XX1</span><span class="p">,</span> <span class="n">XX2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X1plot_step</span><span class="p">),</span> <span class="c1"># set up the mesh</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X2plot_step</span><span class="p">))</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">XX1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">XX2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>    <span class="c1"># predict with our trained model over the mesh</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">interpolation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> 
        <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sp</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Train'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Test'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">plot_decision_tree_regions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">annotate</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sp</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>         <span class="c1"># add the color bar</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_hat</span>

<span class="k">def</span> <span class="nf">check_tree_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">title</span><span class="p">):</span> <span class="c1"># plots the estimated vs. the actual  </span>
    <span class="n">y_hat_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X2_train</span><span class="p">]);</span> <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_test</span><span class="p">])</span>

    <span class="n">df_cross</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'y_test'</span><span class="p">,</span><span class="s1">'y_hat_test'</span><span class="p">])</span>
    <span class="n">df_cross_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'y_train'</span><span class="p">,</span><span class="s1">'y_hat_train'</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">unique_y_hat_all</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_hat_test</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="n">unique_y_hat_all</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">],[</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y_hat</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="n">unique_y_hat_test</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">y_hat_test</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="n">unique_y_hat_test</span><span class="p">:</span>
        <span class="c1">#plt.plot([ymin,ymax],[y_hat,y_hat],c='black',alpha=0.3,ls='--',zorder=1)</span>
        <span class="n">cond_mean_y_hat</span> <span class="o">=</span> <span class="n">df_cross</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross</span><span class="p">[</span><span class="s1">'y_hat_test'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_test'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">cond_P75_y_hat</span> <span class="o">=</span> <span class="n">df_cross</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross</span><span class="p">[</span><span class="s1">'y_hat_test'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_test'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
        <span class="n">cond_P25_y_hat</span> <span class="o">=</span> <span class="n">df_cross</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross</span><span class="p">[</span><span class="s1">'y_hat_test'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_test'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cond_mean_y_hat</span><span class="p">,</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.02</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'^'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P25_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P75_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        
    <span class="n">unique_y_hat_train</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">y_hat_train</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="n">unique_y_hat_train</span><span class="p">:</span>
        <span class="c1">#plt.plot([ymin,ymax],[y_hat,y_hat],c='black',alpha=0.3,ls='--',zorder=1)</span>
        <span class="n">cond_mean_y_hat</span> <span class="o">=</span> <span class="n">df_cross_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross_train</span><span class="p">[</span><span class="s1">'y_hat_train'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_train'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">cond_P75_y_hat</span> <span class="o">=</span> <span class="n">df_cross_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross_train</span><span class="p">[</span><span class="s1">'y_hat_train'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_train'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
        <span class="n">cond_P25_y_hat</span> <span class="o">=</span> <span class="n">df_cross_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross_train</span><span class="p">[</span><span class="s1">'y_hat_train'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_train'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cond_mean_y_hat</span><span class="p">,</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.02</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'v'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P25_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P75_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Actual Production (MCFPD)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimated Production (MCFPD)'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">head_length</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">head_width</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">MSE_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">);</span> <span class="n">MSE_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.6</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.1</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)),</span><span class="mf">0.40</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="mf">0.12</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span>
        <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">ec</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">fc</span><span class="o">=</span><span class="s2">"white"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'MSE Testing:  '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">,.0f</span><span class="si">}</span><span class="s1">'</span><span class="p">),(</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.62</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.18</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)),</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'MSE Training: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_train</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">,.0f</span><span class="si">}</span><span class="s1">'</span><span class="p">),(</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.62</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.12</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)),</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">tree_tuning</span><span class="p">(</span><span class="n">node_max</span><span class="p">,</span><span class="n">cnode</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">MSE_test_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">node_max</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span> <span class="n">MSE_train_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">node_max</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
    
    <span class="k">for</span> <span class="n">imax_leaf_node</span><span class="p">,</span> <span class="n">max_leaf_node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">node_max</span><span class="o">+</span><span class="mi">1</span><span class="p">)):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">tree_temp</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_node</span><span class="p">)</span>
        <span class="n">tree_temp</span> <span class="o">=</span> <span class="n">tree_temp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">y_hat_train</span> <span class="o">=</span> <span class="n">tree_temp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X2_train</span><span class="p">]);</span> <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">tree_temp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_test</span><span class="p">])</span>  
        <span class="n">MSE_train_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">)</span>
        <span class="n">MSE_test_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_leaf_node</span> <span class="o">==</span> <span class="n">cnode</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cnode</span><span class="p">,</span><span class="n">MSE_train_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cnode</span><span class="p">,</span><span class="n">MSE_test_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">maxcheck</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_train_mat</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_test_mat</span><span class="p">))</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">cnode</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">maxcheck</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">node_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">MSE_train_mat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">node_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">MSE_test_mat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Maximum Number of Leaf Nodes'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Means Square Error'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">node_max</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">maxcheck</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks   </span>

<span class="k">def</span> <span class="nf">tree_to_code</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>                        <span class="c1"># code from StackOverFlow by paulkernfeld</span>
    <span class="n">tree_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span>                                        <span class="c1"># convert tree object to portable code to use anywhere</span>
    <span class="n">feature_name</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span> <span class="k">else</span> <span class="s2">"undefined!"</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tree_</span><span class="o">.</span><span class="n">feature</span>
    <span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"def tree(</span><span class="si">{}</span><span class="s2">):"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">", "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">recurse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
        <span class="n">indent</span> <span class="o">=</span> <span class="s2">"  "</span> <span class="o">*</span> <span class="n">depth</span>
        <span class="k">if</span> <span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">feature_name</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2">if </span><span class="si">{}</span><span class="s2"> &lt;= </span><span class="si">{}</span><span class="s2">:"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indent</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">threshold</span><span class="p">))</span>
            <span class="n">recurse</span><span class="p">(</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2">elif </span><span class="si">{}</span><span class="s2"> &gt; </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indent</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">threshold</span><span class="p">))</span>
            <span class="n">recurse</span><span class="p">(</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2">return </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indent</span><span class="p">,</span> <span class="n">tree_</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">node</span><span class="p">]))</span>
    <span class="n">recurse</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 

<span class="k">def</span> <span class="nf">get_lineage</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>                         <span class="c1"># code from StackOverFlow by Zelanzny7</span>
    <span class="n">left</span>      <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span>                      <span class="c1"># track the decision path for any set of inputs</span>
    <span class="n">right</span>     <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span>
    <span class="n">features</span>  <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">]</span>
    <span class="c1"># get ids of child nodes</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">left</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span>     
    <span class="k">def</span> <span class="nf">recurse</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">child</span><span class="p">,</span> <span class="n">lineage</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>          
        <span class="k">if</span> <span class="n">lineage</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lineage</span> <span class="o">=</span> <span class="p">[</span><span class="n">child</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">left</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">left</span> <span class="o">==</span> <span class="n">child</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">split</span> <span class="o">=</span> <span class="s1">'l'</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">right</span> <span class="o">==</span> <span class="n">child</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">split</span> <span class="o">=</span> <span class="s1">'r'</span>
        <span class="n">lineage</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">parent</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">threshold</span><span class="p">[</span><span class="n">parent</span><span class="p">],</span> <span class="n">features</span><span class="p">[</span><span class="n">parent</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">lineage</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">lineage</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">recurse</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">parent</span><span class="p">,</span> <span class="n">lineage</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">recurse</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> 

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>  <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">'&lt;div style="display: flex;"&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the Working Directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
</section>
<section id="loading-data">
<h2>Loading Data</h2>
<p>Let‚Äôs load the provided multivariate, spatial dataset <a class="reference external" href="https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv">unconv_MV.csv</a> available in my GeoDataSet repo. It is a comma delimited file with:</p>
<ul class="simple">
<li><p>well index (integer)</p></li>
<li><p>porosity (%)</p></li>
<li><p>permeability (<span class="math notranslate nohighlight">\(mD\)</span>)</p></li>
<li><p>acoustic impedance (<span class="math notranslate nohighlight">\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^6\)</span>).</p></li>
<li><p>brittleness (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial gas production (90 day average) (MCFPD)</p></li>
</ul>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a data frame we called ‚Äòdf‚Äô and then preview it to make sure it loaded correctly.</p>
<p><strong>Python Tip: using functions from a package</strong> just type the label for the package that we declared at the beginning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<p>so we can access the pandas function ‚Äòread_csv‚Äô with the command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">()</span>
</pre></div>
</div>
<p>but read csv has required input parameters. The essential one is the name of the file. For our circumstance all the other default parameters are fine. If you want to see all the possible parameters for this function, just go to the docs <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html">here</a>.</p>
<ul class="simple">
<li><p>The docs are always helpful</p></li>
<li><p>There is often a lot of flexibility for Python functions, possible through using various inputs parameters</p></li>
</ul>
<p>also, the program has an output, a pandas DataFrame loaded from the data.  So we have to specify the name / variable representing that new object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"unconv_MV.csv"</span><span class="p">)</span>  
</pre></div>
</div>
<p>Let‚Äôs run this command to load the data and then this command to extract a random subset of the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">.30</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">73073</span><span class="p">);</span> 
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="feature-engineering">
<h2>Feature Engineering</h2>
<p>Let‚Äôs make some changes to the data to improve the workflow:</p>
<ul class="simple">
<li><p><strong>Select the predictor features (x2) and the response feature (x1)</strong>, make sure the metadata is also consistent.</p></li>
<li><p><strong>Metadata</strong> encoding such as the units, labels and display ranges for each feature.</p></li>
<li><p><strong>Reduce the number of data</strong> for ease of visualization (hard to see if too many points on our plots).</p></li>
<li><p><strong>Train and test data split</strong> to demonstrate and visualize simple hyperparameter tuning.</p></li>
<li><p><strong>Add random noise to the data</strong> to demonstrate model overfit. The original data is error free and does not readily demonstrate overfit.</p></li>
</ul>
<p>Given this is properly set, one should be able to use any dataset and features for this demonstration.</p>
<ul class="simple">
<li><p>for brevity we don‚Äôt show any feature selection here. Previous chapter, e.g., k-nearest neighbours include some feature selection methods, but see the feature selection chapter for many possible methods with codes for feature selection.</p></li>
</ul>
</section>
<section id="optional-add-random-noise-to-the-response-feature">
<h2>Optional: Add Random Noise to the Response Feature</h2>
<p>We can do this to observe the impact of data noise on overfit and hyperparameter tuning.</p>
<ul class="simple">
<li><p>This is for experiential learning, of course we wouldn‚Äôt add random noise to our data</p></li>
<li><p>We set the random number seed for reproducibility</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">add_error</span> <span class="o">=</span> <span class="kc">True</span>                                              <span class="c1"># add random error to the response feature</span>
<span class="n">std_error</span> <span class="o">=</span> <span class="mi">500</span>                                               <span class="c1"># standard deviation of random error, for demonstration only</span>
<span class="n">idata</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv"</span><span class="p">)</span> <span class="c1"># load the data from my github repo</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">.30</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">);</span> <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> <span class="c1"># extract 30% random to reduce the number of data</span>
    
<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v5.csv"</span><span class="p">)</span> <span class="c1"># load the data </span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">.70</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">);</span> <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> <span class="c1"># extract 30% random to reduce the number of data</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"Prod"</span><span class="p">:</span> <span class="s2">"Production"</span><span class="p">})</span>
    
<span class="n">yname</span> <span class="o">=</span> <span class="s1">'Production'</span><span class="p">;</span> <span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Por'</span><span class="p">,</span><span class="s1">'Brittle'</span><span class="p">]</span>               <span class="c1"># specify the predictor features (x2) and response feature (x1)</span>
<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">]</span>                         <span class="c1"># set minimums and maximums for visualization </span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">9000.0</span>
<span class="n">Xlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Brittleness'</span><span class="p">];</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'Production'</span>    <span class="c1"># specify the feature labels for plotting</span>
<span class="n">Xunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'%'</span><span class="p">,</span><span class="s1">'%'</span><span class="p">];</span> <span class="n">yunit</span> <span class="o">=</span> <span class="s1">'MCFPD'</span>
<span class="n">Xlabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>
<span class="n">ylabelunit</span> <span class="o">=</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span> <span class="o">+</span> <span class="s1">')'</span>

<span class="k">if</span> <span class="n">add_error</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>                                         <span class="c1"># method to add error</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>                                 <span class="c1"># set random number seed</span>
    <span class="n">df_load</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">std_error</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_load</span><span class="p">))</span> <span class="c1"># add noise</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">_get_numeric_data</span><span class="p">();</span> <span class="n">values</span><span class="p">[</span><span class="n">values</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>   <span class="c1"># set negative to 0 in a shallow copy ndarray</span>
    
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_load</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">Xname</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># make one DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs make sure that we have selected reasonable features to build a model</p>
<ul class="simple">
<li><p>the 2 predictor features are not collinear, as this would result in an unstable prediction model</p></li>
<li><p>each of the features are related to the response feature, the predictor features inform the response</p></li>
</ul>
</section>
<section id="calculate-the-correlation-matrix-and-correlation-with-response-ranking">
<h2>Calculate the Correlation Matrix and Correlation with Response Ranking</h2>
<p>Let‚Äôs start with correlation analysis. We can calculate and view the correlation matrix and correlation to the response features with these previously declared functions.</p>
<ul class="simple">
<li><p>correlation analysis is based on the assumption of linear relationships, but it is a good start</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">correlation</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>           <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">feature_rank_plot</span><span class="p">(</span><span class="n">Xname</span><span class="p">,</span><span class="n">correlation</span><span class="p">,</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">'Feature Ranking, Correlation with '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">,</span><span class="s1">'Correlation'</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png" src="../Images/fe078f42023f81da1972474b1d3bbf26.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png"/>
</div>
</div>
<p>Note the 1.0 diagonal resulting from the correlation of each variable with themselves.</p>
<p>This looks good.  There is a mix of correlation magnitudes. Of course, correlation coefficients are limited to degree of linear correlations.</p>
<ul class="simple">
<li><p>Let‚Äôs look at the matrix scatter plot to see the pairwise relationship between the features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pairgrid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="nb">vars</span><span class="o">=</span><span class="n">Xname</span><span class="o">+</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                <span class="c1"># matrix scatter plots</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_upper</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'k'</span><span class="p">)</span><span class="c1"># Map a density plot to the lower triangle</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span><span class="p">,</span> 
                              <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_levels</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png" src="../Images/515a70a53d49c49c9ecf98249cd67b5d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png"/>
</div>
</div>
</section>
<section id="train-and-test-split">
<h2>Train and Test Split</h2>
<p>For convenience and simplicity we use scikit-learn‚Äôs random train and test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span> <span class="c1"># train and test split</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train DataFrame with both X and y (remove all other features)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># make one testin DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame</h2>
<p>Visualizing the train and test DataFrame is useful check before we build our models.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'       Training DataFrame          Testing DataFrame'</span><span class="p">)</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span><span class="n">df_test</span><span class="p">)</span>                          <span class="c1"># custom function for side-by-side DataFrame display</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>       Training DataFrame          Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>86</th>
      <td>12.83</td>
      <td>29.87</td>
      <td>2089.258307</td>
    </tr>
    <tr>
      <th>35</th>
      <td>17.39</td>
      <td>56.43</td>
      <td>5803.596379</td>
    </tr>
    <tr>
      <th>75</th>
      <td>12.23</td>
      <td>40.67</td>
      <td>3511.348151</td>
    </tr>
    <tr>
      <th>36</th>
      <td>13.72</td>
      <td>40.24</td>
      <td>4004.849870</td>
    </tr>
    <tr>
      <th>126</th>
      <td>12.83</td>
      <td>17.20</td>
      <td>2712.836372</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>15.55</td>
      <td>58.25</td>
      <td>5353.761093</td>
    </tr>
    <tr>
      <th>46</th>
      <td>20.21</td>
      <td>23.78</td>
      <td>4387.577571</td>
    </tr>
    <tr>
      <th>96</th>
      <td>15.07</td>
      <td>39.39</td>
      <td>4412.135054</td>
    </tr>
    <tr>
      <th>45</th>
      <td>12.10</td>
      <td>63.24</td>
      <td>3654.779704</td>
    </tr>
    <tr>
      <th>105</th>
      <td>19.54</td>
      <td>37.40</td>
      <td>5251.551624</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
</section>
<section id="summary-statistics-for-tabular-data">
<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames.</p>
<ul class="simple">
<li><p>The describe command provides count, mean, minimum, maximum in a nice data table.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'            Training DataFrame                      Testing DataFrame'</span><span class="p">)</span>    <span class="c1"># custom function for side-by-side summary statistics</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]],</span><span class="n">df_test</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>            Training DataFrame                      Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>105.000000</td>
      <td>105.000000</td>
      <td>105.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>14.859238</td>
      <td>48.861143</td>
      <td>4238.554591</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.057228</td>
      <td>14.432050</td>
      <td>1087.707113</td>
    </tr>
    <tr>
      <th>min</th>
      <td>7.220000</td>
      <td>10.940000</td>
      <td>1517.373571</td>
    </tr>
    <tr>
      <th>max</th>
      <td>23.550000</td>
      <td>84.330000</td>
      <td>6907.632261</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>35.000000</td>
      <td>35.000000</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>15.011714</td>
      <td>46.798286</td>
      <td>4378.913131</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.574467</td>
      <td>13.380910</td>
      <td>1290.216113</td>
    </tr>
    <tr>
      <th>min</th>
      <td>6.550000</td>
      <td>20.120000</td>
      <td>1846.027145</td>
    </tr>
    <tr>
      <th>max</th>
      <td>20.860000</td>
      <td>68.760000</td>
      <td>6593.447893</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
</section>
<section id="visualize-the-train-and-test-splits">
<h2>Visualize the Train and Test Splits</h2>
<p>Let‚Äôs check the consistency and coverage of training and testing with histograms and scatter plots.</p>
<ul class="simple">
<li><p>check to make sure the training and testing cover the range of possible feature combinations</p></li>
<li><p>ensure we are not extrapolating beyond the training data with the testing cases</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Density'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Porosity'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># predictor features #1 and #2 scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs '</span> <span class="o">+</span>  <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7f95232f4bccd970cd69b500c8930cfffaf4ffd9a243b7aea1e184337ba9175d.png" src="../Images/3e84676c9f7f37dcabed4194a238047f.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/7f95232f4bccd970cd69b500c8930cfffaf4ffd9a243b7aea1e184337ba9175d.png"/>
</div>
</div>
<p>Sometimes I find it more convenient to compare distributions by looking at CDF‚Äôs instead of histograms.</p>
<ul class="simple">
<li><p>we avoid the arbitrary choice of histogram bin size, because CDF‚Äôs are at the data resolution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># response feature CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">ylabelunit</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/846daf6f4bcdece7bb39d2b1b9c385e351fbcf923d9599f41f5c7a4c3639c3dc.png" src="../Images/89d70d18d70c546bb0ac8c55112e894e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/846daf6f4bcdece7bb39d2b1b9c385e351fbcf923d9599f41f5c7a4c3639c3dc.png"/>
</div>
</div>
<p>Once again, the distributions are well behaved,</p>
<ul class="simple">
<li><p>we cannot observe obvious gaps nor truncations.</p></li>
<li><p>check coverage of the train and test data</p></li>
</ul>
<p>Let‚Äôs look at a scatter plot of Porosity vs. Brittleness with points colored by Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># visualize the train and test data in predictor feature space</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
    <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
    <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s1">'upper right'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a0a42ff41b36629afd1b47ee725006868db8d0038504ccf72d1f966ac5e69281.png" src="../Images/3ec3d66453c69d41e8b4c7a2508530a0.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/a0a42ff41b36629afd1b47ee725006868db8d0038504ccf72d1f966ac5e69281.png"/>
</div>
</div>
<p>This problem looks complicated and could not be modeled with simple linear regression. It appears that there are non-linearities. Let‚Äôs use a simple nonparametric model, decision tree.</p>
</section>
<section id="instantiate-fit-and-predict-with-scikit-learn">
<h2>Instantiate, Fit and Predict with scikit-learn</h2>
<p>Let‚Äôs build our predictive machine learning model, by instantiate, fit and predict with scikit-learn.</p>
<ul class="simple">
<li><p><strong>instantiate</strong> the model object with the hyperparameters, k-nearest neighbours</p></li>
<li><p><strong>fit</strong> by training the model with the training data, we use the member function fit</p></li>
<li><p><strong>predict</strong> with the trained model. After fit is run, predict is available to make predictions</p></li>
</ul>
</section>
<section id="training-a-decision-tree-regression-tree">
<h2>Training a Decision Tree (Regression Tree)</h2>
<p>Now we are ready to run the DecisionTreeRegressor command to build our regression tree to predict our response feature given our 2 predictor features (recall we limit ourselves here to 2 predictor features for ease of visualization).</p>
<ul class="simple">
<li><p>We will use our two functions defined above to visualize the decision tree prediction over the feature space and the cross plot of actual and estimated production for the training data along with three model metrics from the sklearn.metric module.</p></li>
</ul>
<p><strong>Hyper Parameters</strong> - we constrain our tree complexity with:</p>
<ul class="simple">
<li><p><em>max_leaf_nodes</em> - maximum number of regions, also called terminal or lead nodes in the decision tree</p></li>
<li><p><em>max_depth</em> - maximum number of levels, e.g., max_depth = 1 is a stump tree with only 1 decision and two regions</p></li>
<li><p><em>min_samples_leaf</em> - minimum number of data in a new region, good constraint to ensure each region has enough data to make a reasonable estimate</p></li>
</ul>
<p>For now lets just try out some hyperparameters.</p>
<section id="underfit-decision-tree-model">
<h3>Underfit Decision Tree Model</h3>
<p>Let‚Äôs use too few regions, set max_leaf_nodes too small and see the resulting decision tree model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">max_depth</span> <span class="o">=</span><span class="mi">99</span><span class="p">;</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>      <span class="c1"># hyperparameters</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">)</span>
<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model'</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> 
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot'</span><span class="p">,)</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/de9bb85033f26085feea46a1ec5a5786ccbe3d092bb940c53d319584063a39c7.png" src="../Images/be259c4cb62524490823c4f4d2d09c0c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/de9bb85033f26085feea46a1ec5a5786ccbe3d092bb940c53d319584063a39c7.png"/>
</div>
</div>
<p>This model is very much underfit, it is too simple to fit the shape of the prediction problem. Here‚Äôs some more information on the plot.</p>
<p>See the horizontal lines on the plot of estimated vs. actual production (plot on the bottom)?</p>
<ul class="simple">
<li><p>That is expected as the regression tree estimates with the average of the data in each region of the feature space (terminal node).</p></li>
<li><p>To further assess the model performance, I have included the actual response P10, mean and P90 for each leaf node, region for both training and testing.</p></li>
<li><p>underfit predictive machine learning models have poor accuracy and training and testing.</p></li>
</ul>
<p>If we have a more complicated tree with more terminal nodes then there would be more lines.</p>
</section>
<section id="overfit-decision-tree-model">
<h3>Overfit Decision Tree Model</h3>
<p>Let‚Äôs use too many regions, set max_leaf_nodes too large and see the resulting decision tree model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>     <span class="c1"># hyperparameters</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">)</span>
<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model'</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> 
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot'</span><span class="p">,)</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b64f9666026f63544dd4662412c50db7132cd58f19c828937a4e3bbfa9366dc6.png" src="../Images/c28519e97623d45a6f72540a6b408c6d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b64f9666026f63544dd4662412c50db7132cd58f19c828937a4e3bbfa9366dc6.png"/>
</div>
</div>
<p>Now we have an overfit predictive machine learning model.</p>
<ul class="simple">
<li><p>too much complexity and flexibility</p></li>
<li><p>we are fitting the noise in the data</p></li>
<li><p>good accuracy in training, but poor accuracy in testing</p></li>
</ul>
<p>It is instructive to observe the decision tree model over the feature space as we incrementally add terminal nodes. We can graphically observe the hierarchical binary splitting quite clearly.</p>
<ul class="simple">
<li><p>Let‚Äôs visualize from simple complicated models.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">leaf_nodes_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>

<span class="k">for</span> <span class="n">inode</span><span class="p">,</span><span class="n">leaf_nodes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">leaf_nodes_list</span><span class="p">):</span>

    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">leaf_nodes</span><span class="p">)</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">inode</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>                                         <span class="c1"># visualize, data, and decision tree regions and predictions</span>
    <span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mi">1000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="s1">'Decision Tree Model, Number of Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">leaf_nodes</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">3.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b066c86d94043d639bf7b5305f612745b8a64d2920e129e3f924e8deaac2ab67.png" src="../Images/43008585fa66e722cde17f42284274b4.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b066c86d94043d639bf7b5305f612745b8a64d2920e129e3f924e8deaac2ab67.png"/>
</div>
</div>
<p>It may be useful to look at a decision tree model and the associated decision tree, side-by-side.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">leaf_nodes_viz</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">tree_model_viz</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">leaf_nodes_viz</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_gridspec</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># 1 row, 3 columns with 1:2 width ratio</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>                         <span class="c1"># visualize, data, and decision tree regions and predictions                                      </span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model_viz</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mi">1000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="s1">'Decision Tree Model, Number of Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">leaf_nodes</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span>
        <span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   

<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>                                  <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">tree_model_viz</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">,</span><span class="n">feature_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">),</span><span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">yname</span><span class="p">),</span><span class="n">filled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">,</span><span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">precision</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                  <span class="n">proportion</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fbf5427fe1d098a17a235d28fdd24ff7b7b442c21b958df2b2855e4ffeb66011.png" src="../Images/de575bff5cbcf3e18e0bc1c385400e3e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/fbf5427fe1d098a17a235d28fdd24ff7b7b442c21b958df2b2855e4ffeb66011.png"/>
</div>
</div>
<p>How do we find the best hyperparameters, for the best complexity for optimum prediction accuracy for testing? That is hyperparameter tuning.</p>
</section>
</section>
<section id="tuning-a-decision-tree-regression-tree">
<h2>Tuning a Decision Tree (Regression Tree)</h2>
<p>Let‚Äôs perform hyperparameter tuning. To do this we,</p>
<ol class="arabic simple">
<li><p>See the range of possible hyperparameter values.</p></li>
<li><p>Loop over the range of possible hyperparameter values.</p>
<ul class="simple">
<li><p>Train on the training data with the current hyperparameter values.</p></li>
<li><p>Predict at the testing data</p></li>
<li><p>Summarize the error over all the testing data</p></li>
</ul>
</li>
<li><p>Select the hyperparameters that minimize the error at for the testing data</p></li>
</ol>
<p>When I teach this to my students, I suggest that this is a model dress rehearsal. We add value by making predictions for cases not used to train the model. We want the model that performs best for cases not in the training, so we are simulating real world use of the model!</p>
<p>Now let‚Äôs do hyperparameter tuning ‚Äòby-hand‚Äô, by varying the decision tree complexity and find the complexity that minimizes MSE in testing</p>
<ul class="simple">
<li><p>for simplicity the code below loops only over the maximum leaf nodes hyperparameter</p></li>
<li><p>we set minimum number of samples to 1, and maximum depth to 9 to ensure that these hyperparameters will not have any impact (we set them to very complicated so they don‚Äôt limit the model complexity)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">trees</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">MSE_CV</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_CV</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>                                   <span class="c1"># loop over the hyperparameter, train with training and test with testing</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">trees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tree_model</span><span class="p">)</span>
    <span class="n">predict_train</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]]])</span> 
    <span class="n">MSE_CV</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">predict_train</span><span class="p">))</span>   
    <span class="n">all_nodes</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span>             
    <span class="n">decision_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">]);</span> <span class="n">terminal_nodes</span> <span class="o">=</span> <span class="n">all_nodes</span> <span class="o">-</span> <span class="n">decision_nodes</span>
    <span class="n">node_CV</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">terminal_nodes</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_CV</span><span class="p">,</span><span class="n">MSE_CV</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">tuned_node</span> <span class="o">=</span> <span class="n">node_CV</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_CV</span><span class="p">)];</span> <span class="n">max_MSE_CV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_CV</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_CV</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node</span><span class="p">),(</span><span class="n">tuned_node</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree Cross Validation Testing Error vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_CV</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/27a521f2cbd01b3caec37b95530d68674a6785fa6c061acdac71ea6326a9fe6b.png" src="../Images/f43c9ad2b759692c2b199e397c735352.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/27a521f2cbd01b3caec37b95530d68674a6785fa6c061acdac71ea6326a9fe6b.png"/>
</div>
</div>
<p>It is useful to evaluate the performance of our tree by observing the accuracy vs. complexity, with a minimum due to the model variance and model bias trade-off.</p>
<p>For a more robust result, let‚Äôs try k-fold cross validation. sklearn has a built in cross validation method called cross_val_score that we can use to:</p>
<ol class="arabic simple">
<li><p>Apply k-fold approach with iterative separation of training and testing data</p></li>
<li><p>With k=5, we have 20% withheld for testing for each fold</p></li>
<li><p>Automate the model construction, looping over folds and averaging the metric of interest</p></li>
</ol>
<p>Let‚Äôs try it out on our trees with variable number of terminal nodes.  Note the cross validation is set to use 4 processors, but still will likely take a couple of minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">MSE_kF</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_kF</span> <span class="o">=</span> <span class="p">[]</span>                                     <span class="c1"># k-fold iteration code modified from StackOverFlow by Dimosthenis</span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span>                   <span class="c1"># perform 4-fold cross validation</span>
    <span class="n">MSE_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">all_nodes</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span>   
    <span class="n">decision_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">]);</span> <span class="n">terminal_nodes</span> <span class="o">=</span> <span class="n">all_nodes</span> <span class="o">-</span> <span class="n">decision_nodes</span>
    <span class="n">node_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">terminal_nodes</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">tuned_node_kF</span> <span class="o">=</span> <span class="n">node_kF</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)];</span> <span class="n">max_MSE_kF</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),(</span><span class="n">tuned_node_kF</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_kF</span><span class="p">,</span><span class="n">MSE_kF</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'k-Fold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_CV</span><span class="p">,</span><span class="n">MSE_CV</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Cross Validation'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree k-Fold Cross Validation Error (MSE) vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/35821438b0adbe9ae455b2e6731dab92e05cf7dfb2dcbaaa8d296ac1c9a18b39.png" src="../Images/2df3cfa16f6fb36c7bd2a52fe7d20a6d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/35821438b0adbe9ae455b2e6731dab92e05cf7dfb2dcbaaa8d296ac1c9a18b39.png"/>
</div>
</div>
<p>The k-fold cross validation provides a smoother plot of MSE vs. the hyperparameter.</p>
<ul class="simple">
<li><p>this is accomplished by averaging the MSE over all the folds to reduce sensitivity of the metric to specific assignment of training and testing data</p></li>
<li><p>all our train and test cross validation or k-fold cross validation was to get this one value, the model <strong>hyperparameter</strong></p></li>
</ul>
</section>
<section id="build-the-final-model">
<h2>Build the Final Model</h2>
<p>Now let‚Äôs take that hyperparameter and train on all the data, this is our <strong>final model</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pruned_tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">tuned_node_kF</span><span class="p">)</span>
<span class="n">pruned_tree_model</span> <span class="o">=</span> <span class="n">pruned_tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>               <span class="c1"># re-train</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model, Tuned Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span>
                    <span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> <span class="c1"># plots the data points and the decision tree prediction </span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot, Tuned Leaf Nodes: '</span> <span class="o">+</span> 
                    <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),)</span>
       
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e85bbd71cc280b9a057d106524b0d1dfca28c6500e32ece594637cde5b8b1dba.png" src="../Images/608907e2a0d015a0d611204bfa6c41e5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/e85bbd71cc280b9a057d106524b0d1dfca28c6500e32ece594637cde5b8b1dba.png"/>
</div>
</div>
<p>We have completed our predictive machine learning model. Now let‚Äôs cover a couple more decision tree diagnostics.</p>
</section>
<section id="interrogating-decision-trees">
<h2>Interrogating Decision Trees</h2>
<p>It may be useful to evaluate for any possible feature combination, the order of decision nodes that resulted in the specific prediction.  The following function provides the list of nodes that the prediction cases passes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">x1</span> <span class="o">=</span> <span class="mf">7.0</span><span class="p">;</span> <span class="n">x2</span> <span class="o">=</span> <span class="mf">10.0</span>                                          <span class="c1"># the predictor feature values for the decision path</span>

<span class="n">decision_path</span> <span class="o">=</span> <span class="n">pruned_tree_model</span><span class="o">.</span><span class="n">decision_path</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decision_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>  (0, 0)	1
  (0, 1)	1
  (0, 3)	1
  (0, 13)	1
</pre></div>
</div>
</div>
</div>
</section>
<section id="extracting-the-decision-tree-prediction-model-as-a-function">
<h2>Extracting the Decision Tree Prediction Model as a Function</h2>
<p>Furthermore it may be useful to convert the decision tree to code, a nested set of ‚Äòif‚Äô statements.</p>
<ul class="simple">
<li><p>This creates a portable model that could be copied and applied as a standalone function.</p></li>
</ul>
<p>Also, one could conveniently interrogate the code version of the tree.</p>
<ul class="simple">
<li><p>We use the previously defined function to do this with our pruned tree.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">tree_to_code</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">))</span>                  <span class="c1"># convert a decision tree to Python code, nested if statements</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>def tree(Por, Brittle):
  if Por &lt;= 14.789999961853027:
    if Por &lt;= 12.425000190734863:
      if Por &lt;= 8.335000038146973:
        return [[1879.19091537]]
      elif Por &gt; 8.335000038146973
        if Brittle &lt;= 39.125:
          return [[2551.00021508]]
        elif Brittle &gt; 39.125
          return [[3369.12903299]]
    elif Por &gt; 12.425000190734863
      if Brittle &lt;= 39.26500129699707:
        return [[3160.11022857]]
      elif Brittle &gt; 39.26500129699707
        return [[4154.18334527]]
  elif Por &gt; 14.789999961853027
    if Por &lt;= 18.015000343322754:
      if Brittle &lt;= 33.25:
        return [[3883.19381758]]
      elif Brittle &gt; 33.25
        if Por &lt;= 16.434999465942383:
          return [[4544.69777089]]
        elif Por &gt; 16.434999465942383
          return [[5240.84146117]]
    elif Por &gt; 18.015000343322754
      if Brittle &lt;= 31.5600004196167:
        return [[4353.11874206]]
      elif Brittle &gt; 31.5600004196167
        return [[5868.56369869]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="decision-tree-based-feature-importance">
<h2>Decision Tree-based Feature Importance</h2>
<p>Feature importance is calculated from a decision trees by summarizing the reduction in mean square error through inclusion of each feature and is summarized as:</p>
<div class="math notranslate nohighlight">
\[
FI(x) = \sum_{t \in T_f} \frac{N_t}{N} \Delta_{MSE_t}
\]</div>
<p>where <span class="math notranslate nohighlight">\(T_f\)</span> are all nodes with feature <span class="math notranslate nohighlight">\(x\)</span> as the split, <span class="math notranslate nohighlight">\(N_t\)</span> is the number of training samples reaching node <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(N\)</span> is the total number of samples in the dataset and <span class="math notranslate nohighlight">\(\Delta_{MSE_t}\)</span> is the reduction in MSE with the <span class="math notranslate nohighlight">\(t\)</span> split.</p>
<p>Note, feature importance can be calculated in a similar manner to MSE above for the case of classification trees with <strong>Gini Impurity</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the feature importance </span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Decision Tree Feature Importance"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">,</span> <span class="n">pruned_tree_model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span>
       <span class="n">color</span><span class="o">=</span><span class="s2">"darkorange"</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">Xname</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predictor Feature'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Feature Importance'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8fcae780c3b59534e28863b5aa7a46545ac1a9e556ab9950e41495b87e7bee49.png" src="../Images/e7672512b746dfc82482f39bc8c78ddc.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8fcae780c3b59534e28863b5aa7a46545ac1a9e556ab9950e41495b87e7bee49.png"/>
</div>
</div>
</section>
<section id="visualize-the-model">
<h2>Visualize the Model</h2>
<p>Let‚Äôs take a last look at the graphical representation of our pruned tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span>                         <span class="c1"># plot the decision tree for model visualization</span>
                   <span class="n">feature_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">),</span>  
                   <span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">yname</span><span class="p">),</span>
                   <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/67fb9697896ebccb3d2ba5fce562153c671634fd57bdc8739c47227f04785578.png" src="../Images/dceac0eb1f800b2c21d5e490c1248210.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/67fb9697896ebccb3d2ba5fce562153c671634fd57bdc8739c47227f04785578.png"/>
</div>
</div>
</section>
<section id="simple-code-to-make-a-decision-tree-machine-and-calculate-a-prediction">
<h2>Simple Code to Make a Decision Tree Machine and Calculate a Prediction</h2>
<p>To support those just getting started, here‚Äôs a minimal amount of code to:</p>
<ul class="simple">
<li><p>load the scikit-learn package for decision trees</p></li>
<li><p>load data</p></li>
<li><p>instantiate a decision tree with hyperparameters (no tuning is shown)</p></li>
<li><p>train the decision tree with the training data</p></li>
<li><p>make a prediction with the decision tree</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>                                      <span class="c1"># import decision tree from scikit-learn</span>
<span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Por'</span><span class="p">,</span><span class="s1">'Brittle'</span><span class="p">];</span> <span class="n">yname</span><span class="o">=</span><span class="s1">'Production'</span>                 <span class="c1"># predictor features and response feature</span>
<span class="n">x1</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">;</span> <span class="n">x2</span> <span class="o">=</span> <span class="mf">0.3</span>                                           <span class="c1"># predictor values for the prediction</span>
<span class="n">my_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv"</span><span class="p">)</span> <span class="c1"># load subsurface data table</span>
<span class="n">my_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>       <span class="c1"># instantiate tree with hyperparameters</span>
<span class="n">my_tree</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>                      <span class="c1"># train tree with training data</span>
<span class="n">estimate</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">]])[</span><span class="mi">0</span><span class="p">]</span>                      <span class="c1"># make a prediction (no tuning shown)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Estimated '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' for '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>  <span class="o">+</span> <span class="s1">' is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">estimate</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">)</span> <span class="c1"># print results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Estimated Production for Porosity = 0.25 and Brittleness = 0.3 is 1879.2 MCFPD
</pre></div>
</div>
</div>
</div>
</section>
<section id="machine-learning-pipelines-for-clean-compact-machine-learning-code">
<h2>Machine Learning Pipelines for Clean, Compact Machine Learning Code</h2>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>build complete workflows with very few lines of readable code</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to find the best model (AutoML)</p>
<p>For more information see my recorded lecture on <a class="reference external" href="https://www.youtube.com/watch?v=tYrPs8s1l9U&amp;list=PLG19vXLQHvSAufDFgZEFAYQEwMJXklnQV&amp;index=5">Machine Learning Pipelines</a> and a well-documented demonstration <a class="reference external" href="http://localhost:8892/notebooks/OneDrive%20-%20The%20University%20of%20Texas%20at%20Austin/Courses/Workflows/PythonDataBasics_Pipelines.ipynb">Machine Learning Pipeline Workflow</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pipe_tree</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>                                        <span class="c1"># the machine learning workflow as a pipeline object</span>

    <span class="p">(</span><span class="s1">'tree'</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>                                                    <span class="c1"># the machine learning workflow method's parameters to search</span>
    <span class="s1">'tree__max_leaf_nodes'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">),</span>
<span class="p">}</span>

<span class="n">KF_tuned_tree</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe_tree</span><span class="p">,</span><span class="n">params</span><span class="p">,</span><span class="n">scoring</span> <span class="o">=</span> <span class="s1">'neg_mean_squared_error'</span><span class="p">,</span> <span class="c1"># hyperparameter tuning w. grid search k-fold cross validation </span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span><span class="n">refit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">KF_tuned_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>                                        <span class="c1"># tune and train the model</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Tuned hyperparameter: max_leaf_nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">KF_tuned_tree</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>

<span class="n">estimate</span> <span class="o">=</span> <span class="n">KF_tuned_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">]])[</span><span class="mi">0</span><span class="p">]</span>                <span class="c1"># make a prediction (no tuning shown)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Estimated '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' for '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>  <span class="o">+</span> <span class="s1">' is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">estimate</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">)</span> <span class="c1"># print results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Tuned hyperparameter: max_leaf_nodes = {'tree__max_leaf_nodes': 10}
Estimated Production for Porosity = 0.25 and Brittleness = 0.3 is 1879.2 MCFPD
</pre></div>
</div>
</div>
</div>
</section>
<section id="practice-on-a-new-dataset">
<h2>Practice on a New Dataset</h2>
<p>Ok, time to get to work. Let‚Äôs load up a dataset and build a decision tree prediction model with,</p>
<ul class="simple">
<li><p>compact code</p></li>
<li><p>basic visaulizations</p></li>
<li><p>save the output</p></li>
</ul>
<p>You can select any of these datasets or modify the code and add your own to do this.</p>
<section id="dataset-0-unconventional-multivariate-v4">
<h3>Dataset 0, Unconventional Multivariate v4</h3>
<p>Let‚Äôs load the provided multivariate, dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv">unconv_MV.csv</a>. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
</section>
<section id="dataset-2-reservoir-21">
<h3>Dataset 2, Reservoir 21</h3>
<p>Let‚Äôs load the provided multivariate, 3D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv">res21_wells.csv</a>. This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50 m reservoir unit:</p>
<ul class="simple">
<li><p>well (ID)</p></li>
<li><p>X (m), Y (m), Depth (m) location coordinates</p></li>
<li><p>Porosity (%) after units conversion</p></li>
<li><p>Permeability (mD)</p></li>
<li><p>Acoustic Impedance (kg/m2s*10^6) after units conversion</p></li>
<li><p>Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley Sand, to Sandstone.</p></li>
<li><p>Density (g/cm^3)</p></li>
<li><p>Compressible velocity (m/s)</p></li>
<li><p>Youngs modulus (GPa)</p></li>
<li><p>Shear velocity (m/s)</p></li>
<li><p>Shear modulus (GPa)</p></li>
<li><p>3 year cumulative oil production (Mbbl)</p></li>
</ul>
<p>We load the tabular data with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
<ul class="simple">
<li><p>we also populate lists with data ranges and labels for ease of plotting</p></li>
</ul>
<p>Load and format the data,</p>
<ul class="simple">
<li><p>drop the response feature</p></li>
<li><p>reformate the features as needed</p></li>
<li><p>also, I like to store the metadata in lists</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">idata</span> <span class="o">=</span> <span class="mi">2</span>                                                    <span class="c1"># select the dataset</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Well'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                 <span class="c1"># remove well index and response feature</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
       
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">10000.0</span>
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Production (MCFPD)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Production'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Porosity'</span><span class="p">:</span><span class="s1">'Por'</span><span class="p">}</span>
    
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Unnamed: 0'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>   <span class="c1"># remove response feature</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="n">df_new</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">;</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1000.0</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">1.60</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">6.20</span>
    
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Well_ID'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># remove Well Index, X and Y coordinates, and response feature</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
     
    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">1600.0</span>
    
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Production (Mbbl)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Production'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="n">df_new</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Density</th>
      <th>PVel</th>
      <th>Youngs</th>
      <th>SVel</th>
      <th>Shear</th>
      <th>CumulativeOil</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>12.907730</td>
      <td>133.910637</td>
      <td>7.308846</td>
      <td>2.146360</td>
      <td>3563.549461</td>
      <td>25.688560</td>
      <td>1673.770439</td>
      <td>6.429229</td>
      <td>1201.20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>12.647965</td>
      <td>114.359667</td>
      <td>7.343836</td>
      <td>2.188597</td>
      <td>3570.094553</td>
      <td>25.444064</td>
      <td>1670.043495</td>
      <td>6.100984</td>
      <td>683.92</td>
    </tr>
    <tr>
      <th>10</th>
      <td>12.998469</td>
      <td>129.332122</td>
      <td>7.282051</td>
      <td>2.131121</td>
      <td>3524.448615</td>
      <td>25.985734</td>
      <td>1681.960101</td>
      <td>6.203527</td>
      <td>978.14</td>
    </tr>
    <tr>
      <th>15</th>
      <td>12.426141</td>
      <td>123.227677</td>
      <td>7.351795</td>
      <td>2.203026</td>
      <td>3417.596818</td>
      <td>25.976462</td>
      <td>1675.355860</td>
      <td>6.288040</td>
      <td>608.09</td>
    </tr>
    <tr>
      <th>16</th>
      <td>13.507371</td>
      <td>147.562087</td>
      <td>7.300360</td>
      <td>2.210916</td>
      <td>3476.167397</td>
      <td>24.817767</td>
      <td>1656.890690</td>
      <td>6.222528</td>
      <td>1062.10</td>
    </tr>
    <tr>
      <th>36</th>
      <td>13.309477</td>
      <td>122.818961</td>
      <td>7.345220</td>
      <td>2.178749</td>
      <td>3346.347661</td>
      <td>25.436579</td>
      <td>1651.679529</td>
      <td>6.334308</td>
      <td>539.98</td>
    </tr>
    <tr>
      <th>49</th>
      <td>11.822910</td>
      <td>98.168307</td>
      <td>7.386212</td>
      <td>2.301552</td>
      <td>3250.020705</td>
      <td>24.340656</td>
      <td>1662.438742</td>
      <td>6.617267</td>
      <td>1095.30</td>
    </tr>
    <tr>
      <th>51</th>
      <td>13.986616</td>
      <td>132.575456</td>
      <td>7.194749</td>
      <td>2.108986</td>
      <td>3415.255945</td>
      <td>26.253236</td>
      <td>1712.017629</td>
      <td>5.583251</td>
      <td>805.49</td>
    </tr>
    <tr>
      <th>61</th>
      <td>14.735895</td>
      <td>128.201000</td>
      <td>7.172693</td>
      <td>1.841786</td>
      <td>3886.950307</td>
      <td>28.289950</td>
      <td>1672.370150</td>
      <td>5.044439</td>
      <td>1146.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="build-and-check-model">
<h3>Build and Check Model</h3>
<p>We apply the follow steps,</p>
<ol class="arabic simple">
<li><p>specify the K-fold method</p></li>
<li><p>loop over number of leaf nodes, instantiate, fit and record the error</p></li>
<li><p>plot the test error vs. number of leaf nodes, select the hyperparameter that minimizes test error</p></li>
<li><p>retrain the model with the tuned hyperparameter and all of the data</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">MSE_kF</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_kF</span> <span class="o">=</span> <span class="p">[]</span>                                     
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>       <span class="c1"># k-fold specification     </span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span> <span class="c1"># perform 5-fold cross validation</span>
    <span class="n">MSE_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">node_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inode</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">tuned_node_kF</span> <span class="o">=</span> <span class="n">node_kF</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)]</span>
<span class="n">tuned_tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">tuned_node_kF</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="c1"># retrain on all the data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),(</span><span class="n">tuned_node_kF</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_kF</span><span class="p">,</span><span class="n">MSE_kF</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'k-Fold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree k-Fold Cross Validation Error (MSE) vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">tuned_tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span> <span class="c1"># cross validation plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">],[</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Truth: '</span> <span class="o">+</span> <span class="n">ylabel_new</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimate: '</span> <span class="o">+</span> <span class="n">ylabel_new</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Tuned Decision Tree, Cross Validation'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/800e93156a21d23fb27ec3b349cbd0c234a2789e27a8582567a80abbbf0e08b0.png" src="../Images/a3d66d6b8f851c5edb5b770a5393116c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/800e93156a21d23fb27ec3b349cbd0c234a2789e27a8582567a80abbbf0e08b0.png"/>
</div>
</div>
</section>
</section>
<section id="comments">
<h2>Comments</h2>
<p>This was a basic treatment of decision tree. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
&#13;

<h2>Motivation</h2>
<p>Decision trees are not the most powerful, cutting edge method in machine learning, so why cover decision trees?</p>
<ul class="simple">
<li><p>one of the most understandable, interpretable predictive machine learning models</p></li>
<li><p>decision trees are enhanced with random forests, bagging and boosting to be one of the best machine learning predictive models in many cases</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/90b8611f2db53bd1e441fa8eb6dce0d1.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/blackspruce.png"/>
  <figcaption style="text-align: center;"> A single proud black spruce tree within the Boreal Forest in Alaska, similar to the northern region of my home province of Alberta. Crop of photo from https://www.britannica.com/plant/spruce#/media/1/561445/8933, access date May 1, 2025. 
</figcaption>
</figure>
<p>Let‚Äôs cover some key aspects of decision trees.</p>
&#13;

<h2>Model Formulation</h2>
<p>The prediction feature space is partitioned into <span class="math notranslate nohighlight">\(J\)</span> exhaustive, mutually exclusive regions <span class="math notranslate nohighlight">\(R_1, R_2, \ldots, R_J\)</span>. For a given prediction case <span class="math notranslate nohighlight">\(x_1,\ldots,x_m \in R_j\)</span>, the prediction is:</p>
<p><strong>Regression</strong> - the average of the training data in the region, <span class="math notranslate nohighlight">\(R_j\)</span></p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} y_i
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the predicted value for input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, <span class="math notranslate nohighlight">\(R_j\)</span> is the region (leaf node) that <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> falls into, <span class="math notranslate nohighlight">\(|R_j|\)</span> is the number of training samples in region <span class="math notranslate nohighlight">\(R_j\)</span>, and <span class="math notranslate nohighlight">\(y_i\)</span> is the actual target values of those training samples in <span class="math notranslate nohighlight">\(R_j\)</span>.</p>
<p><strong>Classification</strong> - category with the plurality of training cases (most common case) in region <span class="math notranslate nohighlight">\(R_j\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \arg\max_{c \in C} \left( \frac{1}{|R_j|} \sum_{\mathbf{x}_i \in R_j} \mathbb{1}(y_i = c) \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> is the set of all possible categories, <span class="math notranslate nohighlight">\(\mathbb{1}(y_i = c)\)</span> is indicator transform, 1 if <span class="math notranslate nohighlight">\(y_i = c\)</span>, 0 otherwise, <span class="math notranslate nohighlight">\(|R_j|\)</span> is the number of training samples in region <span class="math notranslate nohighlight">\(R_j\)</span>, and <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the predicted class label.</p>
<p>The predictor space, <span class="math notranslate nohighlight">\(ùëã_1,\ldots,ùëã_ùëö\)</span>, is segmented into <span class="math notranslate nohighlight">\(J\)</span> mutually exclusive, exhaustive regions, <span class="math notranslate nohighlight">\(R_j, j = 1,\ldots,J\)</span>, where the regions are,</p>
<ul class="simple">
<li><p><strong>mutually exclusive</strong> ‚Äì any combination of predictor features, <span class="math notranslate nohighlight">\(x_1,\ldots,x_ùëö\)</span>, only belongs to a single region, <span class="math notranslate nohighlight">\(R_j\)</span></p></li>
<li><p><strong>exhaustive</strong> ‚Äì all combinations of predictor feature values belong a region, <span class="math notranslate nohighlight">\(R_j\)</span>, i.e., all the regions, <span class="math notranslate nohighlight">\(R_j, j = 1,\ldots,J\)</span>, cover entire predictor  feature space</p></li>
</ul>
<p>All prediction cases, <span class="math notranslate nohighlight">\(x_1,\ldots,x_m\)</span> that fall in the same region, <span class="math notranslate nohighlight">\(R_j\)</span>, are estimated with the same value.</p>
<ul class="simple">
<li><p>the prediction model inherently discontinuous at the region boundaries</p></li>
</ul>
<p>For example, consider this decision tree prediction model for the production response feature, <span class="math notranslate nohighlight">\(\hat{Y}\)</span>¬†ÃÇfrom porosity, <span class="math notranslate nohighlight">\(X_1\)</span>, predictor feature,</p>
<figure style="text-align: center;">
  <img src="../Images/98d8fb73fe41299a6a9b443163b47c96.png" style="display: block; margin: 0 auto; width: 80%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/regions.png"/>
  <figcaption style="text-align: center;"> Four region decision tree with data and predictions, \(\hat{Y}(R_j) = \overline{Y}(R_j)\) by region, \(R_j, j=1,‚Ä¶,4\). For example, given a predictor feature value of 13% porosity, the model predicts about 2,000 MCFPD for production.
</figcaption>
</figure>
<p>How do we segment the predictor feature space?</p>
<p>Look at this example with predictor features porosity and brittleness to predict the production response feature.</p>
<figure style="text-align: center;">
  <img src="../Images/31b00c9edfa4f39d2ae71626df2cd687.png" style="display: block; margin: 0 auto; width: 80%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/complexboundaries.png"/>
  <figcaption style="text-align: center;"> A very complicated segmentation of the predictor feature space with 3 regions.
</figcaption>
</figure>
<ul class="simple">
<li><p>these are very efficient boundaries that would capture low, mid and high production</p></li>
</ul>
<p>But, this model would be quite complicated,</p>
<ul class="simple">
<li><p>requiring a large number of model parameters</p></li>
<li><p>difficult to train for a large number of prediction features, i.e., high dimensionality</p></li>
</ul>
<p>If I can convince you to accept these regions instead, then you would have a model that,</p>
<ul class="simple">
<li><p>is very easy to train</p></li>
<li><p>has very few parameters</p></li>
<li><p>very compact and interpretable</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/13cf7080472834d100f0e7812be6d2d3.png" style="display: block; margin: 0 auto; width: 80%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/simpleboundaries.png"/>
  <figcaption style="text-align: center;"> A simpler segmentation of the predictor feature space with 9 regions, but much fewer parameters and easy to train for any dimensionality.
</figcaption>
</figure>
<p>This is a set of regions based on hierarchical, binary segmentation. Let‚Äôs clarify the concept of predictor feature space and then explain this form of predictor feature segmentation.</p>
&#13;

<h2>Predictor Feature Space</h2>
<p>Let‚Äôs step back and establish the concept of predictor feature space. We define it as,</p>
<ul class="simple">
<li><p>the space that includes all possible estimation problems, i.e., the combination of all possible predictor feature values, <span class="math notranslate nohighlight">\(x_1, x_2,\ldots,x_m\)</span>.</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/2328290a847e59dd59f76c37a18c6df3.png" style="display: block; margin: 0 auto; width: 60%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/predictorspace.png"/>
  <figcaption style="text-align: center;"> Illustration of predictor feature space for the case of 3 predictor features with specified minimum and maximum values per feature resulting in a rectangular cuboid of possible predictions, $x_1, x_2, x_3$.
</figcaption>
</figure>
<p>Typically this is defined by the range of possible values, <span class="math notranslate nohighlight">\(x_{\alpha} \in \left[X_{\alpha,\text{ùëöùëñùëõ}},ùëã_{\alpha,\text{max}} \right]\)</span>‚Äã, resulting in,</p>
<ul class="simple">
<li><p>1 predictor feature <span class="math notranslate nohighlight">\(\rightarrow\)</span> line segment</p></li>
<li><p>2 predictor features <span class="math notranslate nohighlight">\(\rightarrow\)</span> rectangle</p></li>
<li><p>3 predictor features <span class="math notranslate nohighlight">\(\rightarrow\)</span> rectangular cuboid</p></li>
<li><p><span class="math notranslate nohighlight">\(&gt;\)</span>3 predictor features <span class="math notranslate nohighlight">\(\rightarrow\)</span> hyperrectangle</p></li>
</ul>
<p>While we define the predictor feature space with the ranges of the predictor features, I should provide a cautionary note.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Decision Trees have an Implicit Extrapolation Model</p>
<p>As you will see below, the regions along the exterior extend to infinity, effectively assuming a constant extrapolation model.</p>
</div>
&#13;

<h2>Tree Loss Functions</h2>
<p>For regression trees we minimize the residual sum of squares and for classification trees we minimize the weighted average Gini impurity.</p>
<p>The Residual Sum of Squares (RSS) measures the total squared difference between the actual values and predicted values in a regression tree,</p>
<div class="math notranslate nohighlight">
\[
\text{RSS} = \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(J\)</span> is the total number of regions in the tree, <span class="math notranslate nohighlight">\(R_j\)</span> is the <span class="math notranslate nohighlight">\(j\)</span> region, <span class="math notranslate nohighlight">\(y_i\)</span> is the truth value of the response feature at observation the <span class="math notranslate nohighlight">\(i\)</span> training data, and <span class="math notranslate nohighlight">\(\hat{y}_{R_j}\)</span> is the predicted value for region <span class="math notranslate nohighlight">\(R_j\)</span>, the mean of <span class="math notranslate nohighlight">\(y_i \; \forall \; i \in R_j\)</span>.</p>
<p>When a parent node splits into two child nodes ( t_L ) and ( t_R ), the weighted Gini impurity is:</p>
<div class="math notranslate nohighlight">
\[
\text{Gini}_{\text{total}} = \sum_{j=1}^{J} \frac{N_j}{N} \cdot \text{Gini}(j)
\]</div>
<p>where <span class="math notranslate nohighlight">\(J\)</span> is the total number of regions in the tree, <span class="math notranslate nohighlight">\(N\)</span> is the total number of samples in the dataset,   <span class="math notranslate nohighlight">\(N_j\)</span> is the number of samples in leaf node <span class="math notranslate nohighlight">\(j\)</span>, and <span class="math notranslate nohighlight">\(\text{Gini}(j)\)</span> is the Gini impurity of leaf node <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>The Gini impurity for a single decision tree node is calculated as,</p>
<div class="math notranslate nohighlight">
\[
\text{Gini}(j) = 1 - \sum_{c=1}^{C} p_{j,c}^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{j,c}\)</span> is the proportion of class <span class="math notranslate nohighlight">\(c\)</span> samples in node <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>For classification our loss function does not compare the predictions to the truth values like our regression loss!</p>
<ul class="simple">
<li><p>the Gini impurity penalizes mixtures of training data categories! A region of all one category of training data will have a Gini impurity of 0 to contribute to the over all loss.</p></li>
</ul>
<p>Note that the by-region Gini impurity is,</p>
<ul class="simple">
<li><p><strong>weighted</strong> - by the number of training data in each regions, regions with more training data have greater impact on the overall loss</p></li>
<li><p><strong>averaged</strong> - over all the regions to calculate the total Gini impurity of the decision tree</p></li>
</ul>
<p>These losses are calculated during,</p>
<ul class="simple">
<li><p><strong>tree model training</strong> - with respect to training data to grow the tree</p></li>
<li><p><strong>tree model tuning</strong> - with respect to withheld testing data to select the optimum tree complexity.</p></li>
</ul>
<p>Let‚Äôs talk about tree model training first and then tree model tuning.</p>
&#13;

<h2>Training the Tree Model</h2>
<p>How do we calculate these mutually exclusive, exhaustive regions? This is accomplished through hierarchical binary segmentation of the predictor feature space.</p>
<p>Training a decision tree model is both,</p>
<ol class="arabic simple">
<li><p>assigning the mutual exclusive, exhaustive regions</p></li>
<li><p>building a decision tree, each region is a terminal node, also known as a leaf node</p></li>
</ol>
<p>These are the same thing! Let‚Äôs list the steps and then walk through a training a tree to demonstrate this.</p>
<ol class="arabic simple" start="0">
<li><p><strong>Assign All Data to a Single Region</strong> - this region covers the entire predictor feature space</p></li>
<li><p><strong>Scan All Possible Splits</strong> - over all regions and over all features</p></li>
<li><p><strong>Select the Best Split</strong> - this is greedy optimization, i.e., the best split minimizes the residual sum of squares of errors over all the training data <span class="math notranslate nohighlight">\(y_i\)</span> over all of the regions <span class="math notranslate nohighlight">\(j = 1,\ldots,J\)</span>.</p></li>
<li><p><strong>Iterate Until Very Overfit</strong> - return to step 1 for the next split until the tree is very overfit.</p></li>
</ol>
<p>Note, this method for training a decision tree is a solution heuristic,</p>
<ul class="simple">
<li><p>there is no effort to jointly optimize all splits at once, for example, to select a suboptimal split to maximize training error reduction with a subsequent split</p></li>
</ul>
<p>Also, the decision tree is constructed from the top down.</p>
<ul class="simple">
<li><p>we begin with a single region that covers the entire predictor feature space and then proceed with a sequence of region splits / tree branches.</p></li>
</ul>
<p>Now let‚Äôs illustrate this with an example, predicting natural gas production response feature with 2 predictor features,</p>
<ul class="simple">
<li><p>porosity - impacting pore volume and flow</p></li>
<li><p>brittleness - impacting the ability to induce and hold open fractures</p></li>
</ul>
<p>We start with all our predictor feature space in a single region with the single possible prediction as the average of all the training data.</p>
<figure style="text-align: center;">
  <img src="../Images/4a6be7714eba68f580cfee8421d15f61.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_1nodes.png"/>
  <figcaption style="text-align: center;"> Initial data all in 1 region, i.e., hyperparameter number of leaf nodes of 1, predict with the global mean of the response feature.
</figcaption>
</figure>
<p>Next, we scan all features to find the first best split, porosity of 16.7%. This very simple decision tree with a single decision node and 2 regions or leaf nodes is known as a stump tree, i.e., the simplest possible decision tree model.</p>
<figure style="text-align: center;">
  <img src="../Images/c418139a6f37dbda3462cd0ab2d519d6.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_2nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 2,  first best split resulting in a stump tree.
</figcaption>
</figure>
<p>Now we scan over both regions and over all predictor features to find the best next split, brittleness of 36.1 in the greater than or equal to porosity of 16.7% region.</p>
<figure style="text-align: center;">
  <img src="../Images/5786413cc0e329c72793e1d2adf2a54b.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_3nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 3.
</figcaption>
</figure>
<p>Continuing, we find our next split of porosity of 18.5% in the upper right region. We now have 4 regions. Our decision tree is starting to capture the increasing production with increasing porosity along with lower production for low brittleness.</p>
<figure style="text-align: center;">
  <img src="../Images/9931df51305b719f93fc51eecf44641d.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_4nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 4.
</figcaption>
</figure>
<p>Now the next best split is in the original lower porosity region from the stump tree with porosity of 13.2%.</p>
<figure style="text-align: center;">
  <img src="../Images/597e4adea071f8f67d71e82f4c1015f2.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_5nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 5.
</figcaption>
</figure>
<p>The next best split divides the region in the middle of porosity, capturing the trend of low production for low brittleness, even with high porosity.</p>
<figure style="text-align: center;">
  <img src="../Images/b1024ff1d9be25d7b007a5ee890b6d8f.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_6nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 6.
</figcaption>
</figure>
<p>The next split is capturing the reduction in production with high brittleness, even with high porosity,</p>
<figure style="text-align: center;">
  <img src="../Images/782938df9c411d347bdc8e6e031a6d66.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_7nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 7.
</figcaption>
</figure>
<p>and this split continues to capture this same pattern in the data.</p>
<figure style="text-align: center;">
  <img src="../Images/c3401dcf9ca381bf65d39fada64ecde2.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tree_8nodes.png"/>
  <figcaption style="text-align: center;"> Hyperparameter number of leaf nodes of 8.
</figcaption>
</figure>
<p>For brevity we stop here, and make these observations,</p>
<ul class="simple">
<li><p>hierarchical, binary segmentation is the same as sequentially building a decision tree, each split adds a new decision node and increases the number of leaf nodes by one.</p></li>
<li><p>the simple decision trees are in the complicated decision tree, i.e., if we build an <span class="math notranslate nohighlight">\(8\)</span> leaf node model, we have the <span class="math notranslate nohighlight">\(8, 7, \ldots, 2\)</span> leaf node model by sequentially removing the decision nodes, in the order of last one is the first one to remove.</p></li>
<li><p>the ultimate overfit model is number of leaf nodes equal to the number of training data. In this case, the training error is 0.0 as have one region for each training data a we estimate with the training data response feature values for all the at the training data cases.</p></li>
</ul>
&#13;

<h2>Updating the Loss Function with a New Split</h2>
<p>To find the next best split, we must scan over all regions, and over all features with the regions. This may sound like a lot of computation, but it is quite efficient.</p>
<ul class="simple">
<li><p>we only need to check the midpoints between sorted training data for each feature in each region, because any split that does not change the region assignment of a training data will not change the training loss.</p></li>
</ul>
<p>For a region <span class="math notranslate nohighlight">\(R\)</span> split into candidate regions <span class="math notranslate nohighlight">\(R_L\)</span> and <span class="math notranslate nohighlight">\(R_R\)</span>, the RSS after the split is:</p>
<div class="math notranslate nohighlight">
\[
\text{RSS}_{\text{split}} = \sum_{i \in R_L} (y_i - \hat{y}_{R_L})^2 + \sum_{i \in R_R} (y_i - \hat{y}_{R_R})^2
\]</div>
<p>where, <span class="math notranslate nohighlight">\(y_i\)</span> is the actual response feature for training data observation <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(\hat{y}_{R_L}\)</span>, <span class="math notranslate nohighlight">\(\hat{y}_{R_R}\)</span> is the mean of training data response feature in candidate regions <span class="math notranslate nohighlight">\(R_L\)</span> and <span class="math notranslate nohighlight">\(R_R\)</span>.</p>
<p>Note, we add in the RSS components from all the other regions to get the total model RSS to find the best split over all the regions,</p>
<ul class="simple">
<li><p>the split with the lowest <span class="math notranslate nohighlight">\(\text{RSS}_{\text{split}}\)</span> is selected for the region and compared to all other best splits in the other regions to find the next best split, greedy solution.</p></li>
</ul>
<p>Now we are prepared for tuning a decision tree model.</p>
&#13;

<h2>Tuning the Tree Model</h2>
<p>To tune the decision tree we take the very overfit trained tree model,</p>
<ul class="simple">
<li><p>sequentially cut the last decision node</p></li>
<li><p>i.e., prune the last branch of the decision tree</p></li>
</ul>
<p>Since the simpler trees are inside the complicated tree!</p>
<p>We can calculate test error as we prune and select tree with minimum test error</p>
<p>We overfit the decision tree model, with a large number of leaf nodes and then we reduce the number of leaf nodes while tracking the test error.</p>
<ul class="simple">
<li><p>we select the number of leaf nodes that minimize the testing error.</p></li>
<li><p>since we are sequentially removing the last branch to simplify the tree, we call model tuning <strong>pruning</strong> for decision trees</p></li>
</ul>
<p>Here is an overfit decision tree with many, <span class="math notranslate nohighlight">\(100\)</span>, leaf nodes.</p>
<figure style="text-align: center;">
  <img src="../Images/3383a81c81cdb9ed5c96432a485e7194.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/veryoverfit.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, hyperparameter number of leaf nodes of 100 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes (right).
</figcaption>
</figure>
<p>Since this tree is calculated with my interactive Python dashboard, I am able to easily reduce the number of regions from <span class="math notranslate nohighlight">\(100, 99, 98, 96, 95, \ldots\)</span> and visualize the tree to explore complicated to simple trees.</p>
<ul class="simple">
<li><p>by doing this we can demonstrate that the simple trees are in the complicated tree.</p></li>
</ul>
<p>For example, here‚Äôs the 5 region decision tree in the overfit 100 region decision tree,</p>
<figure style="text-align: center;">
  <img src="../Images/566f12da178143a07d17de9adc100684.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/5nodetree.png"/>
  <figcaption style="text-align: center;"> The 5 leaf node tree in the very overfit 100 leaf node tree model.
</figcaption>
</figure>
<p>and here is the 10 region decision tree in the overfit 100 region decision tree,</p>
<figure style="text-align: center;">
  <img src="../Images/96e18c15cb01e9558e4b2512a6b1ef20.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/10nodetree.png"/>
  <figcaption style="text-align: center;"> The 10 leaf node tree in the very overfit 100 leaf node tree model.
</figcaption>
</figure>
<p>and finally, here is the 20 region decision tree in the overfit 100 region decision tree,</p>
<figure style="text-align: center;">
  <img src="../Images/19d39b48f3c129dc12099bd52c3bb546.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/20nodetree.png"/>
  <figcaption style="text-align: center;"> The 20 leaf node tree in the very overfit 100 leaf node tree model.
</figcaption>
</figure>
<p>You might wonder, why I didn‚Äôt just update the decision tree plot? scikit-learn‚Äôs decision tree plotting function recales the plot and the geometry changes so much it is not easy to visualize the simple trees within the complicated tree.</p>
<ul class="simple">
<li><p>I think this approach of visualizing the simple trees and drafting the polylines works well for educational purposes!</p></li>
</ul>
<p>Now let‚Äôs return to our very overfit tree and demonstrate the hyperparameter tuning by tree pruning approach,</p>
<figure style="text-align: center;">
  <img src="../Images/24f9e4745fc35d0cf9c039aec32684f0.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune100.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>Now, we identify the last added branch and remove it to calculate the 99 region decision tree, a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/2c6ffbcc9634d3d3f7350cb0564380d1.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune99.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 98 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/efae49220a4ea118479dcc21d333e37a.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune98.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 97 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/f4af3bd7dce90621152ff68c398bd578.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune97.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 96 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/eeea92714bf8b2f878a05ce7f50e9eae.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune96.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 95 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/90180132c5183f3342f2051c501aee4a.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune95.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>And we identify the last added branch again and remove it to calculate the 94 region decision tree, once again a slightly simpler decision tree, and we calculate the test error.</p>
<figure style="text-align: center;">
  <img src="../Images/53f087807a31ef6a8e1be0e1ec170292.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tune94.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, train and test error vs. model complexity (left) and decision tree (right).
</figcaption>
</figure>
<p>Now let‚Äôs return and look at the very overfit model and add some more information over different levels of complexity.</p>
<figure style="text-align: center;">
  <img src="../Images/ab38e613fbf8ad17fdab5bd4f89adaa6.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/overfit.png"/>
  <figcaption style="text-align: center;"> Very overfit decision tree, hyperparameter number of leaf nodes of 100 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes (right).
</figcaption>
</figure>
<p>I include the,</p>
<ul class="simple">
<li><p>train and test cross validation plot with nearly perfect training prediction and very poor testing prediction for the 100 leaf node overfit decision tree</p></li>
<li><p>train and test error versus number of leaf nodes.</p></li>
</ul>
<p>This demonstrates that the decision tree model is indeed very overfit, for example, see the falling training error and rising testing error.</p>
<p>Now we prune the decision nodes until we obtain the model with the minimum testing error at about 19 leaf nodes.</p>
<figure style="text-align: center;">
  <img src="../Images/064eac7331174101230aee9c413623f3.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/tuned.png"/>
  <figcaption style="text-align: center;"> Tuned decision tree, hyperparameter number of leaf nodes of 20 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes indicating that testing error is minimized (right).
</figcaption>
</figure>
<p>For completeness, I have included an underfit model, i.e., if we prune our decision tree too much, with only 8 leaf nodes.</p>
<figure style="text-align: center;">
  <img src="../Images/9d7b773b0de829f858763876c59a1c04.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/underfit.png"/>
  <figcaption style="text-align: center;"> Underfit decision tree, hyperparameter number of leaf nodes of 8 (left), train and test cross validation plot (center) and train and test error over number of leaf nodes indicating that testing error is minimized (right).
</figcaption>
</figure>
<p>Note, that the train and test error are both very high with the underfit decision tree.</p>
<p>I prefer number of leaf nodes as my decision tree hyperparameter because it provides,</p>
<ul class="simple">
<li><p><strong>continuous, uniform increase in complexity</strong> -  equal steps in increased complexity without jumps</p></li>
<li><p><strong>intuitive control on complexity</strong> - we can understand and relate the <span class="math notranslate nohighlight">\(2, 3, \ldots, 100\)</span> leaf node decision trees</p></li>
<li><p><strong>flexible complexity</strong> - the tree is free to grow in any manner to reduce training error, including highly asymmetric decision trees</p></li>
</ul>
<p>There are other common decision tree hyperparameters including,</p>
<ul class="simple">
<li><p><strong>Minimum reduction in RSS</strong> ‚Äì related to the idea that incremental increase in complexity must be offset by sufficient reduction in training error. This could stop the model early, for example, a split with low reduction in training error could lead to a subsequent split with a much larger reduction in training error</p></li>
<li><p><strong>Minimum number of training data in each region</strong> ‚Äì related to the concept of accuracy of the by-region estimates, i.e., we need at least <span class="math notranslate nohighlight">\(n\)</span> data for a reliable mean and most common category</p></li>
<li><p><strong>Maximum number of levels</strong> ‚Äì forces symmetric trees, similar number of splits to get to each leaf node. There is a large change in model complexity with change in the hyperparameter.</p></li>
</ul>
&#13;

<h2>The Prediction Model</h2>
<p>The decision tree prediction model is represented as <strong>set of nested if statements</strong>, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="k">if</span> <span class="n">porosity</span> <span class="o">&gt;</span> <span class="mf">0.15</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">brittleness</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">7000</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">brittleness</span> <span class="o">&lt;</span> <span class="mi">40</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">initial_production</span> <span class="o">=</span> <span class="mi">3000</span>
</pre></div>
</div>
<p>and the predictions as stated above are either the,</p>
<ul class="simple">
<li><p>regression - average of the training data in the region</p></li>
<li><p>classification - the plurality, most common category, of the training data in the region</p></li>
</ul>
&#13;

<h2>Shapley Values from Decision Trees</h2>
<p>Recall, we need to take a single model, for example, <span class="math notranslate nohighlight">\(f(x_1,x_2,x_3,x_4)\)</span>, and make an estimate for all possible combinations of feature subsets, for example,</p>
<div class="math notranslate nohighlight">
\[
f(x_1) \quad f(x_2,x_4) \quad f(x_1,x_2,x_3)
\]</div>
<ul class="simple">
<li><p>note, the na√Øve approach to calculate Shapley values is to train the full combinatorial of models with different predictor features, but we don‚Äôt want to make new models if our goal is feature importance to diagnose our specific model, <span class="math notranslate nohighlight">\(f\)</span>, to support model explainability.</p></li>
</ul>
<p>One solution is to apply a variety of approaches, similar to imputation methods, including,</p>
<ul class="simple">
<li><p>replace the excluded feature(s) with the expected value, global mean,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(x_1,x_2,x_3) = f(x_1,x_2,x_3,x_4=E[x_4])
\]</div>
<ul class="simple">
<li><p>replace the excluded feature(s) with the median value, the 50th percentile,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(x_1,x_2,x_3) = f(x_1,x_2,x_3,x_4=P50_{x_4})
\]</div>
<p>There is a more accurate, unique method with tree-based models, we can actually remove the influence of any of the features from the decision tree after the model is trained, for example,</p>
<ul class="simple">
<li><p>remove all <span class="math notranslate nohighlight">\(x_4\)</span> branches, and then the model does not use <span class="math notranslate nohighlight">\(x_4\)</span> to make the prediction</p></li>
</ul>
<p>Of course, we cannot just remove branches and ‚Äòwood glue‚Äô the tree back together!</p>
<ul class="simple">
<li><p>we must make new predictions that don‚Äôt introduce bias.</p></li>
</ul>
<p>Let‚Äôs demonstrate the procedure for removing a feature from a decision tree, with a couple of prediction cases,</p>
<ol class="arabic simple">
<li><p>Here is a prediction case that does not encounter the removed feature, <span class="math notranslate nohighlight">\(x_2\)</span> is removed and,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x_1=25
\]</div>
<ul class="simple">
<li><p>the prediction is made as usual.</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/a9783a200ab476bb3a92cb2cfec12d63.png" style="display: block; margin: 0 auto; width: 60%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/shaptree1.png"/>
  <figcaption style="text-align: center;"> Prediction case that does not encounter the removed feature is made as usual.
</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[
f(x_1=25) = 20
\]</div>
<ol class="arabic simple" start="2">
<li><p>A prediction case that does encounter the removed feature, <span class="math notranslate nohighlight">\(x_1\)</span> is removed and,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x_2 = 60
\]</div>
<ul class="simple">
<li><p>we effectively go down both paths, by weighting, by number of training data, the solution over both paths!</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/8152951b8a3c920f03825528d98c5ae7.png" style="display: block; margin: 0 auto; width: 60%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/decision_tree/shaptree2.png"/>
  <figcaption style="text-align: center;"> Prediction case that does encounter the removed feature is made by weighting both paths by the number of training data.
</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[
f(x_2=60) = \frac{60}{100} \left[ \frac{15}{60} \times 20 + \frac{45}{60} \times 70 \right] + \frac{40}{100} \left[130\right] = 86.5
\]</div>
<div class="math notranslate nohighlight">
\[
f(x_2=60) = 86.5
\]</div>
&#13;

<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>                                      <span class="c1"># toggle to supress warnings</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>                                      <span class="c1"># tree program from scikit learn (package for machine learning)</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">_tree</span>                                <span class="c1"># for accessing tree information</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>                      <span class="c1"># graphical visualization of trees</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>           <span class="c1"># multi-processor K-fold crossvalidation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>          <span class="c1"># train and test split</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># supress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
&#13;

<h2>Declare Functions</h2>
<p>Let‚Äôs define a couple of functions to streamline plotting correlation matrices and visualization of a decision tree regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span>

<span class="k">def</span> <span class="nf">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">,</span><span class="n">nominal</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span> <span class="c1"># feature ranking plot</span>
    <span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">);</span> <span class="n">mask_low</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">-</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">nominal</span><span class="o">-</span><span class="n">mmin</span><span class="p">);</span> <span class="n">mask_high</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">mmax</span><span class="o">-</span><span class="n">nominal</span><span class="p">);</span> <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span><span class="s1">'r--'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'dodgerblue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'lightcoral'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_low</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">mask_low</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_high</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">mask_high</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predictor Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'RdBu_r'</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
    
<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks   </span>

<span class="k">def</span> <span class="nf">plot_CDF</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">):</span>
    <span class="n">cumprob</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="n">cumprob</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">extract_rules</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>                 <span class="c1"># recursive method to extract rules, from paulkernfeld Stack Overflow (?)</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">def</span> <span class="nf">traverse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">prev_rule</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>        <span class="c1"># Leaf node</span>
            <span class="n">class_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">node</span><span class="p">])</span>
            <span class="n">rule</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prev_rule</span><span class="si">}</span><span class="s2"> =&gt; Class </span><span class="si">{</span><span class="n">class_label</span><span class="si">}</span><span class="s2">"</span>
            <span class="n">rules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Split node</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="n">node</span><span class="p">]]</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">left_child</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">right_child</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">traverse</span><span class="p">(</span><span class="n">left_child</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prev_rule</span><span class="si">}</span><span class="s2"> &amp; </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> &lt;= </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> <span class="c1"># Recursively traverse left and right subtrees</span>
            <span class="n">traverse</span><span class="p">(</span><span class="n">right_child</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prev_rule</span><span class="si">}</span><span class="s2"> &amp; </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> &gt; </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">traverse</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"Root"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rules</span>

<span class="k">def</span> <span class="nf">plot_decision_tree_regions</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span><span class="n">X_min</span><span class="p">,</span><span class="n">X_max</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="n">extract_rules</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">irule</span><span class="p">,</span> <span class="n">____</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rules</span><span class="p">):</span>
        <span class="n">rule</span> <span class="o">=</span> <span class="n">rules</span><span class="p">[</span><span class="n">irule</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">X_min</span> <span class="o">=</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">X_max</span> <span class="o">=</span> <span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">Y_min</span> <span class="o">=</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span> <span class="n">Y_max</span> <span class="o">=</span> <span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
        <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span> <span class="k">if</span> <span class="n">val</span><span class="o">==</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'&lt;='</span><span class="p">:</span>
                <span class="n">X_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">X_max</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">X_min</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span> <span class="k">if</span> <span class="n">val</span><span class="o">==</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'&lt;='</span><span class="p">:</span>
                <span class="n">Y_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">Y_max</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Y_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">rule</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]),</span><span class="n">Y_min</span><span class="p">)</span> 
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="n">X_min</span><span class="p">,</span><span class="n">Y_min</span><span class="p">),</span><span class="n">X_max</span><span class="o">-</span><span class="n">X_min</span><span class="p">,</span><span class="n">Y_max</span><span class="o">-</span><span class="n">Y_min</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">ec</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">fc</span><span class="o">=</span><span class="s2">"none"</span><span class="p">))</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_min</span> <span class="o">+</span> <span class="n">X_max</span><span class="p">)</span><span class="o">*</span><span class="mf">0.5</span><span class="p">;</span> <span class="n">cy</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_min</span> <span class="o">+</span> <span class="n">Y_max</span><span class="p">)</span><span class="o">*</span><span class="mf">0.5</span><span class="p">;</span> <span class="n">loc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">cx</span><span class="p">,</span><span class="n">cy</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">annotate</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">loc</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">,.0f</span><span class="si">}</span><span class="s1">'</span><span class="p">),</span><span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">cx</span><span class="p">,</span><span class="n">cy</span><span class="p">),</span><span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
                         <span class="n">weight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">'white'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">visualize_tree_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span>
                         <span class="n">ymax</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabel</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span><span class="c1"># plots the data points and the decision tree prediction </span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>
    <span class="n">X1plot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mf">300.0</span><span class="p">;</span> <span class="n">X2plot_step</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mf">300.0</span> <span class="c1"># resolution of the model visualization</span>
    <span class="n">XX1</span><span class="p">,</span> <span class="n">XX2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X1plot_step</span><span class="p">),</span> <span class="c1"># set up the mesh</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X2plot_step</span><span class="p">))</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">XX1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">XX2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>    <span class="c1"># predict with our trained model over the mesh</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">interpolation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> 
        <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sp</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Train'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Test'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">plot_decision_tree_regions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">annotate</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sp</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>         <span class="c1"># add the color bar</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_hat</span>

<span class="k">def</span> <span class="nf">check_tree_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">title</span><span class="p">):</span> <span class="c1"># plots the estimated vs. the actual  </span>
    <span class="n">y_hat_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X2_train</span><span class="p">]);</span> <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_test</span><span class="p">])</span>

    <span class="n">df_cross</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'y_test'</span><span class="p">,</span><span class="s1">'y_hat_test'</span><span class="p">])</span>
    <span class="n">df_cross_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'y_train'</span><span class="p">,</span><span class="s1">'y_hat_train'</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">unique_y_hat_all</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_hat_test</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="n">unique_y_hat_all</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">],[</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y_hat</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="n">unique_y_hat_test</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">y_hat_test</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="n">unique_y_hat_test</span><span class="p">:</span>
        <span class="c1">#plt.plot([ymin,ymax],[y_hat,y_hat],c='black',alpha=0.3,ls='--',zorder=1)</span>
        <span class="n">cond_mean_y_hat</span> <span class="o">=</span> <span class="n">df_cross</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross</span><span class="p">[</span><span class="s1">'y_hat_test'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_test'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">cond_P75_y_hat</span> <span class="o">=</span> <span class="n">df_cross</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross</span><span class="p">[</span><span class="s1">'y_hat_test'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_test'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
        <span class="n">cond_P25_y_hat</span> <span class="o">=</span> <span class="n">df_cross</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross</span><span class="p">[</span><span class="s1">'y_hat_test'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_test'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cond_mean_y_hat</span><span class="p">,</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.02</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'^'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P25_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P75_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">-</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        
    <span class="n">unique_y_hat_train</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">y_hat_train</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y_hat</span> <span class="ow">in</span> <span class="n">unique_y_hat_train</span><span class="p">:</span>
        <span class="c1">#plt.plot([ymin,ymax],[y_hat,y_hat],c='black',alpha=0.3,ls='--',zorder=1)</span>
        <span class="n">cond_mean_y_hat</span> <span class="o">=</span> <span class="n">df_cross_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross_train</span><span class="p">[</span><span class="s1">'y_hat_train'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_train'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">cond_P75_y_hat</span> <span class="o">=</span> <span class="n">df_cross_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross_train</span><span class="p">[</span><span class="s1">'y_hat_train'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_train'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
        <span class="n">cond_P25_y_hat</span> <span class="o">=</span> <span class="n">df_cross_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cross_train</span><span class="p">[</span><span class="s1">'y_hat_train'</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">,</span> <span class="s1">'y_train'</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cond_mean_y_hat</span><span class="p">,</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.02</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'v'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.025</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P25_y_hat</span><span class="p">,</span><span class="n">cond_P25_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">cond_P75_y_hat</span><span class="p">,</span><span class="n">cond_P75_y_hat</span><span class="p">],[</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.032</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">y_hat</span><span class="o">+</span><span class="mf">0.018</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)],</span><span class="n">c</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Actual Production (MCFPD)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimated Production (MCFPD)'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">head_length</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">head_width</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">MSE_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">);</span> <span class="n">MSE_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.6</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.1</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)),</span><span class="mf">0.40</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="mf">0.12</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span>
        <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">ec</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">fc</span><span class="o">=</span><span class="s2">"white"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'MSE Testing:  '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">,.0f</span><span class="si">}</span><span class="s1">'</span><span class="p">),(</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.62</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.18</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)),</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'MSE Training: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_train</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">,.0f</span><span class="si">}</span><span class="s1">'</span><span class="p">),(</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.62</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">),</span><span class="n">ymin</span><span class="o">+</span><span class="mf">0.12</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)),</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">tree_tuning</span><span class="p">(</span><span class="n">node_max</span><span class="p">,</span><span class="n">cnode</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_train</span><span class="p">,</span><span class="n">X2_test</span><span class="p">,</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">MSE_test_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">node_max</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span> <span class="n">MSE_train_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">node_max</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
    
    <span class="k">for</span> <span class="n">imax_leaf_node</span><span class="p">,</span> <span class="n">max_leaf_node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">node_max</span><span class="o">+</span><span class="mi">1</span><span class="p">)):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">tree_temp</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_node</span><span class="p">)</span>
        <span class="n">tree_temp</span> <span class="o">=</span> <span class="n">tree_temp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">y_hat_train</span> <span class="o">=</span> <span class="n">tree_temp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_train</span><span class="p">,</span><span class="n">X2_train</span><span class="p">]);</span> <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">tree_temp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X1_test</span><span class="p">,</span><span class="n">X2_test</span><span class="p">])</span>  
        <span class="n">MSE_train_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_hat_train</span><span class="p">)</span>
        <span class="n">MSE_test_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_hat_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_leaf_node</span> <span class="o">==</span> <span class="n">cnode</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cnode</span><span class="p">,</span><span class="n">MSE_train_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cnode</span><span class="p">,</span><span class="n">MSE_test_mat</span><span class="p">[</span><span class="n">imax_leaf_node</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">maxcheck</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_train_mat</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_test_mat</span><span class="p">))</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">cnode</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">maxcheck</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">node_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">MSE_train_mat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">node_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">MSE_test_mat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Maximum Number of Leaf Nodes'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Means Square Error'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">node_max</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">maxcheck</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks   </span>

<span class="k">def</span> <span class="nf">tree_to_code</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>                        <span class="c1"># code from StackOverFlow by paulkernfeld</span>
    <span class="n">tree_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span>                                        <span class="c1"># convert tree object to portable code to use anywhere</span>
    <span class="n">feature_name</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span> <span class="k">else</span> <span class="s2">"undefined!"</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tree_</span><span class="o">.</span><span class="n">feature</span>
    <span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"def tree(</span><span class="si">{}</span><span class="s2">):"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">", "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">recurse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
        <span class="n">indent</span> <span class="o">=</span> <span class="s2">"  "</span> <span class="o">*</span> <span class="n">depth</span>
        <span class="k">if</span> <span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">feature_name</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2">if </span><span class="si">{}</span><span class="s2"> &lt;= </span><span class="si">{}</span><span class="s2">:"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indent</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">threshold</span><span class="p">))</span>
            <span class="n">recurse</span><span class="p">(</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2">elif </span><span class="si">{}</span><span class="s2"> &gt; </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indent</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">threshold</span><span class="p">))</span>
            <span class="n">recurse</span><span class="p">(</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2">return </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indent</span><span class="p">,</span> <span class="n">tree_</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">node</span><span class="p">]))</span>
    <span class="n">recurse</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 

<span class="k">def</span> <span class="nf">get_lineage</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>                         <span class="c1"># code from StackOverFlow by Zelanzny7</span>
    <span class="n">left</span>      <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span>                      <span class="c1"># track the decision path for any set of inputs</span>
    <span class="n">right</span>     <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span>
    <span class="n">features</span>  <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">]</span>
    <span class="c1"># get ids of child nodes</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">left</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span>     
    <span class="k">def</span> <span class="nf">recurse</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">child</span><span class="p">,</span> <span class="n">lineage</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>          
        <span class="k">if</span> <span class="n">lineage</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lineage</span> <span class="o">=</span> <span class="p">[</span><span class="n">child</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">left</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">left</span> <span class="o">==</span> <span class="n">child</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">split</span> <span class="o">=</span> <span class="s1">'l'</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">right</span> <span class="o">==</span> <span class="n">child</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">split</span> <span class="o">=</span> <span class="s1">'r'</span>
        <span class="n">lineage</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">parent</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">threshold</span><span class="p">[</span><span class="n">parent</span><span class="p">],</span> <span class="n">features</span><span class="p">[</span><span class="n">parent</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">parent</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">lineage</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">lineage</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">recurse</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">parent</span><span class="p">,</span> <span class="n">lineage</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">recurse</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> 

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>  <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">'&lt;div style="display: flex;"&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Set the Working Directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
&#13;

<h2>Loading Data</h2>
<p>Let‚Äôs load the provided multivariate, spatial dataset <a class="reference external" href="https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv">unconv_MV.csv</a> available in my GeoDataSet repo. It is a comma delimited file with:</p>
<ul class="simple">
<li><p>well index (integer)</p></li>
<li><p>porosity (%)</p></li>
<li><p>permeability (<span class="math notranslate nohighlight">\(mD\)</span>)</p></li>
<li><p>acoustic impedance (<span class="math notranslate nohighlight">\(\frac{kg}{m^3} \cdot \frac{m}{s} \cdot 10^6\)</span>).</p></li>
<li><p>brittleness (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial gas production (90 day average) (MCFPD)</p></li>
</ul>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a data frame we called ‚Äòdf‚Äô and then preview it to make sure it loaded correctly.</p>
<p><strong>Python Tip: using functions from a package</strong> just type the label for the package that we declared at the beginning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<p>so we can access the pandas function ‚Äòread_csv‚Äô with the command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">()</span>
</pre></div>
</div>
<p>but read csv has required input parameters. The essential one is the name of the file. For our circumstance all the other default parameters are fine. If you want to see all the possible parameters for this function, just go to the docs <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html">here</a>.</p>
<ul class="simple">
<li><p>The docs are always helpful</p></li>
<li><p>There is often a lot of flexibility for Python functions, possible through using various inputs parameters</p></li>
</ul>
<p>also, the program has an output, a pandas DataFrame loaded from the data.  So we have to specify the name / variable representing that new object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"unconv_MV.csv"</span><span class="p">)</span>  
</pre></div>
</div>
<p>Let‚Äôs run this command to load the data and then this command to extract a random subset of the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">.30</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">73073</span><span class="p">);</span> 
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
&#13;

<h2>Feature Engineering</h2>
<p>Let‚Äôs make some changes to the data to improve the workflow:</p>
<ul class="simple">
<li><p><strong>Select the predictor features (x2) and the response feature (x1)</strong>, make sure the metadata is also consistent.</p></li>
<li><p><strong>Metadata</strong> encoding such as the units, labels and display ranges for each feature.</p></li>
<li><p><strong>Reduce the number of data</strong> for ease of visualization (hard to see if too many points on our plots).</p></li>
<li><p><strong>Train and test data split</strong> to demonstrate and visualize simple hyperparameter tuning.</p></li>
<li><p><strong>Add random noise to the data</strong> to demonstrate model overfit. The original data is error free and does not readily demonstrate overfit.</p></li>
</ul>
<p>Given this is properly set, one should be able to use any dataset and features for this demonstration.</p>
<ul class="simple">
<li><p>for brevity we don‚Äôt show any feature selection here. Previous chapter, e.g., k-nearest neighbours include some feature selection methods, but see the feature selection chapter for many possible methods with codes for feature selection.</p></li>
</ul>
&#13;

<h2>Optional: Add Random Noise to the Response Feature</h2>
<p>We can do this to observe the impact of data noise on overfit and hyperparameter tuning.</p>
<ul class="simple">
<li><p>This is for experiential learning, of course we wouldn‚Äôt add random noise to our data</p></li>
<li><p>We set the random number seed for reproducibility</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">add_error</span> <span class="o">=</span> <span class="kc">True</span>                                              <span class="c1"># add random error to the response feature</span>
<span class="n">std_error</span> <span class="o">=</span> <span class="mi">500</span>                                               <span class="c1"># standard deviation of random error, for demonstration only</span>
<span class="n">idata</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv"</span><span class="p">)</span> <span class="c1"># load the data from my github repo</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">.30</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">);</span> <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> <span class="c1"># extract 30% random to reduce the number of data</span>
    
<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v5.csv"</span><span class="p">)</span> <span class="c1"># load the data </span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">.70</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">);</span> <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> <span class="c1"># extract 30% random to reduce the number of data</span>
    <span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"Prod"</span><span class="p">:</span> <span class="s2">"Production"</span><span class="p">})</span>
    
<span class="n">yname</span> <span class="o">=</span> <span class="s1">'Production'</span><span class="p">;</span> <span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Por'</span><span class="p">,</span><span class="s1">'Brittle'</span><span class="p">]</span>               <span class="c1"># specify the predictor features (x2) and response feature (x1)</span>
<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">]</span>                         <span class="c1"># set minimums and maximums for visualization </span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">9000.0</span>
<span class="n">Xlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Brittleness'</span><span class="p">];</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'Production'</span>    <span class="c1"># specify the feature labels for plotting</span>
<span class="n">Xunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'%'</span><span class="p">,</span><span class="s1">'%'</span><span class="p">];</span> <span class="n">yunit</span> <span class="o">=</span> <span class="s1">'MCFPD'</span>
<span class="n">Xlabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>
<span class="n">ylabelunit</span> <span class="o">=</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span> <span class="o">+</span> <span class="s1">')'</span>

<span class="k">if</span> <span class="n">add_error</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>                                         <span class="c1"># method to add error</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>                                 <span class="c1"># set random number seed</span>
    <span class="n">df_load</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">yname</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">std_error</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_load</span><span class="p">))</span> <span class="c1"># add noise</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">_get_numeric_data</span><span class="p">();</span> <span class="n">values</span><span class="p">[</span><span class="n">values</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>   <span class="c1"># set negative to 0 in a shallow copy ndarray</span>
    
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_load</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">Xname</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># make one DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs make sure that we have selected reasonable features to build a model</p>
<ul class="simple">
<li><p>the 2 predictor features are not collinear, as this would result in an unstable prediction model</p></li>
<li><p>each of the features are related to the response feature, the predictor features inform the response</p></li>
</ul>
&#13;

<h2>Calculate the Correlation Matrix and Correlation with Response Ranking</h2>
<p>Let‚Äôs start with correlation analysis. We can calculate and view the correlation matrix and correlation to the response features with these previously declared functions.</p>
<ul class="simple">
<li><p>correlation analysis is based on the assumption of linear relationships, but it is a good start</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">correlation</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>           <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">feature_rank_plot</span><span class="p">(</span><span class="n">Xname</span><span class="p">,</span><span class="n">correlation</span><span class="p">,</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">'Feature Ranking, Correlation with '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">,</span><span class="s1">'Correlation'</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png" src="../Images/fe078f42023f81da1972474b1d3bbf26.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/152d837d72f43ba9a48527a444d81b3bbc73a2ba553d2760d27f5c20206ea0b2.png"/>
</div>
</div>
<p>Note the 1.0 diagonal resulting from the correlation of each variable with themselves.</p>
<p>This looks good.  There is a mix of correlation magnitudes. Of course, correlation coefficients are limited to degree of linear correlations.</p>
<ul class="simple">
<li><p>Let‚Äôs look at the matrix scatter plot to see the pairwise relationship between the features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pairgrid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="nb">vars</span><span class="o">=</span><span class="n">Xname</span><span class="o">+</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                <span class="c1"># matrix scatter plots</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_upper</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'k'</span><span class="p">)</span><span class="c1"># Map a density plot to the lower triangle</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span><span class="p">,</span> 
                              <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_levels</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png" src="../Images/515a70a53d49c49c9ecf98249cd67b5d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8d03fa748bcc76aea92c8e57b5fb8071473e84b910d1402f5fd62dd21b102145.png"/>
</div>
</div>
&#13;

<h2>Train and Test Split</h2>
<p>For convenience and simplicity we use scikit-learn‚Äôs random train and test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span> <span class="c1"># train and test split</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train DataFrame with both X and y (remove all other features)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># make one testin DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Visualize the DataFrame</h2>
<p>Visualizing the train and test DataFrame is useful check before we build our models.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'       Training DataFrame          Testing DataFrame'</span><span class="p">)</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span><span class="n">df_test</span><span class="p">)</span>                          <span class="c1"># custom function for side-by-side DataFrame display</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>       Training DataFrame          Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>86</th>
      <td>12.83</td>
      <td>29.87</td>
      <td>2089.258307</td>
    </tr>
    <tr>
      <th>35</th>
      <td>17.39</td>
      <td>56.43</td>
      <td>5803.596379</td>
    </tr>
    <tr>
      <th>75</th>
      <td>12.23</td>
      <td>40.67</td>
      <td>3511.348151</td>
    </tr>
    <tr>
      <th>36</th>
      <td>13.72</td>
      <td>40.24</td>
      <td>4004.849870</td>
    </tr>
    <tr>
      <th>126</th>
      <td>12.83</td>
      <td>17.20</td>
      <td>2712.836372</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>15.55</td>
      <td>58.25</td>
      <td>5353.761093</td>
    </tr>
    <tr>
      <th>46</th>
      <td>20.21</td>
      <td>23.78</td>
      <td>4387.577571</td>
    </tr>
    <tr>
      <th>96</th>
      <td>15.07</td>
      <td>39.39</td>
      <td>4412.135054</td>
    </tr>
    <tr>
      <th>45</th>
      <td>12.10</td>
      <td>63.24</td>
      <td>3654.779704</td>
    </tr>
    <tr>
      <th>105</th>
      <td>19.54</td>
      <td>37.40</td>
      <td>5251.551624</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
&#13;

<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames.</p>
<ul class="simple">
<li><p>The describe command provides count, mean, minimum, maximum in a nice data table.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'            Training DataFrame                      Testing DataFrame'</span><span class="p">)</span>    <span class="c1"># custom function for side-by-side summary statistics</span>
<span class="n">display_sidebyside</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]],</span><span class="n">df_test</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">'count'</span><span class="p">,</span> <span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'std'</span><span class="p">,</span> <span class="s1">'min'</span><span class="p">,</span> <span class="s1">'max'</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>            Training DataFrame                      Testing DataFrame
</pre></div>
</div>
<div class="output text_html"><div style="display: flex;"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>105.000000</td>
      <td>105.000000</td>
      <td>105.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>14.859238</td>
      <td>48.861143</td>
      <td>4238.554591</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.057228</td>
      <td>14.432050</td>
      <td>1087.707113</td>
    </tr>
    <tr>
      <th>min</th>
      <td>7.220000</td>
      <td>10.940000</td>
      <td>1517.373571</td>
    </tr>
    <tr>
      <th>max</th>
      <td>23.550000</td>
      <td>84.330000</td>
      <td>6907.632261</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Brittle</th>
      <th>Production</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>35.000000</td>
      <td>35.000000</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>15.011714</td>
      <td>46.798286</td>
      <td>4378.913131</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.574467</td>
      <td>13.380910</td>
      <td>1290.216113</td>
    </tr>
    <tr>
      <th>min</th>
      <td>6.550000</td>
      <td>20.120000</td>
      <td>1846.027145</td>
    </tr>
    <tr>
      <th>max</th>
      <td>20.860000</td>
      <td>68.760000</td>
      <td>6593.447893</td>
    </tr>
  </tbody>
</table></div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
&#13;

<h2>Visualize the Train and Test Splits</h2>
<p>Let‚Äôs check the consistency and coverage of training and testing with histograms and scatter plots.</p>
<ul class="simple">
<li><p>check to make sure the training and testing cover the range of possible feature combinations</p></li>
<li><p>ensure we are not extrapolating beyond the training data with the testing cases</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Density'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 histogram</span>
<span class="n">freq1</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">freq2</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nbins</span><span class="p">),</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">freq1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">,</span><span class="n">freq2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">*</span><span class="mf">1.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="n">max_freq</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Porosity'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># predictor features #1 and #2 scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">df_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">df_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs '</span> <span class="o">+</span>  <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7f95232f4bccd970cd69b500c8930cfffaf4ffd9a243b7aea1e184337ba9175d.png" src="../Images/3e84676c9f7f37dcabed4194a238047f.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/7f95232f4bccd970cd69b500c8930cfffaf4ffd9a243b7aea1e184337ba9175d.png"/>
</div>
</div>
<p>Sometimes I find it more convenient to compare distributions by looking at CDF‚Äôs instead of histograms.</p>
<ul class="simple">
<li><p>we avoid the arbitrary choice of histogram bin size, because CDF‚Äôs are at the data resolution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># predictor feature #1 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># predictor feature #2 CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabelunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># response feature CDF</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plot_CDF</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'solid'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">ylabelunit</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' Train and Test CDFs'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">#plt.savefig('Test.pdf', dpi=600, bbox_inches = 'tight',format='pdf')   </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/846daf6f4bcdece7bb39d2b1b9c385e351fbcf923d9599f41f5c7a4c3639c3dc.png" src="../Images/89d70d18d70c546bb0ac8c55112e894e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/846daf6f4bcdece7bb39d2b1b9c385e351fbcf923d9599f41f5c7a4c3639c3dc.png"/>
</div>
</div>
<p>Once again, the distributions are well behaved,</p>
<ul class="simple">
<li><p>we cannot observe obvious gaps nor truncations.</p></li>
<li><p>check coverage of the train and test data</p></li>
</ul>
<p>Let‚Äôs look at a scatter plot of Porosity vs. Brittleness with points colored by Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># visualize the train and test data in predictor feature space</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
    <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> 
    <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s1">'upper right'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a0a42ff41b36629afd1b47ee725006868db8d0038504ccf72d1f966ac5e69281.png" src="../Images/3ec3d66453c69d41e8b4c7a2508530a0.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/a0a42ff41b36629afd1b47ee725006868db8d0038504ccf72d1f966ac5e69281.png"/>
</div>
</div>
<p>This problem looks complicated and could not be modeled with simple linear regression. It appears that there are non-linearities. Let‚Äôs use a simple nonparametric model, decision tree.</p>
&#13;

<h2>Instantiate, Fit and Predict with scikit-learn</h2>
<p>Let‚Äôs build our predictive machine learning model, by instantiate, fit and predict with scikit-learn.</p>
<ul class="simple">
<li><p><strong>instantiate</strong> the model object with the hyperparameters, k-nearest neighbours</p></li>
<li><p><strong>fit</strong> by training the model with the training data, we use the member function fit</p></li>
<li><p><strong>predict</strong> with the trained model. After fit is run, predict is available to make predictions</p></li>
</ul>
&#13;

<h2>Training a Decision Tree (Regression Tree)</h2>
<p>Now we are ready to run the DecisionTreeRegressor command to build our regression tree to predict our response feature given our 2 predictor features (recall we limit ourselves here to 2 predictor features for ease of visualization).</p>
<ul class="simple">
<li><p>We will use our two functions defined above to visualize the decision tree prediction over the feature space and the cross plot of actual and estimated production for the training data along with three model metrics from the sklearn.metric module.</p></li>
</ul>
<p><strong>Hyper Parameters</strong> - we constrain our tree complexity with:</p>
<ul class="simple">
<li><p><em>max_leaf_nodes</em> - maximum number of regions, also called terminal or lead nodes in the decision tree</p></li>
<li><p><em>max_depth</em> - maximum number of levels, e.g., max_depth = 1 is a stump tree with only 1 decision and two regions</p></li>
<li><p><em>min_samples_leaf</em> - minimum number of data in a new region, good constraint to ensure each region has enough data to make a reasonable estimate</p></li>
</ul>
<p>For now lets just try out some hyperparameters.</p>
<section id="underfit-decision-tree-model">
<h3>Underfit Decision Tree Model</h3>
<p>Let‚Äôs use too few regions, set max_leaf_nodes too small and see the resulting decision tree model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">max_depth</span> <span class="o">=</span><span class="mi">99</span><span class="p">;</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>      <span class="c1"># hyperparameters</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">)</span>
<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model'</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> 
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot'</span><span class="p">,)</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/de9bb85033f26085feea46a1ec5a5786ccbe3d092bb940c53d319584063a39c7.png" src="../Images/be259c4cb62524490823c4f4d2d09c0c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/de9bb85033f26085feea46a1ec5a5786ccbe3d092bb940c53d319584063a39c7.png"/>
</div>
</div>
<p>This model is very much underfit, it is too simple to fit the shape of the prediction problem. Here‚Äôs some more information on the plot.</p>
<p>See the horizontal lines on the plot of estimated vs. actual production (plot on the bottom)?</p>
<ul class="simple">
<li><p>That is expected as the regression tree estimates with the average of the data in each region of the feature space (terminal node).</p></li>
<li><p>To further assess the model performance, I have included the actual response P10, mean and P90 for each leaf node, region for both training and testing.</p></li>
<li><p>underfit predictive machine learning models have poor accuracy and training and testing.</p></li>
</ul>
<p>If we have a more complicated tree with more terminal nodes then there would be more lines.</p>
</section>
<section id="overfit-decision-tree-model">
<h3>Overfit Decision Tree Model</h3>
<p>Let‚Äôs use too many regions, set max_leaf_nodes too large and see the resulting decision tree model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>     <span class="c1"># hyperparameters</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">)</span>
<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model'</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> 
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot'</span><span class="p">,)</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b64f9666026f63544dd4662412c50db7132cd58f19c828937a4e3bbfa9366dc6.png" src="../Images/c28519e97623d45a6f72540a6b408c6d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b64f9666026f63544dd4662412c50db7132cd58f19c828937a4e3bbfa9366dc6.png"/>
</div>
</div>
<p>Now we have an overfit predictive machine learning model.</p>
<ul class="simple">
<li><p>too much complexity and flexibility</p></li>
<li><p>we are fitting the noise in the data</p></li>
<li><p>good accuracy in training, but poor accuracy in testing</p></li>
</ul>
<p>It is instructive to observe the decision tree model over the feature space as we incrementally add terminal nodes. We can graphically observe the hierarchical binary splitting quite clearly.</p>
<ul class="simple">
<li><p>Let‚Äôs visualize from simple complicated models.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">leaf_nodes_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>

<span class="k">for</span> <span class="n">inode</span><span class="p">,</span><span class="n">leaf_nodes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">leaf_nodes_list</span><span class="p">):</span>

    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">leaf_nodes</span><span class="p">)</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">inode</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>                                         <span class="c1"># visualize, data, and decision tree regions and predictions</span>
    <span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mi">1000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="s1">'Decision Tree Model, Number of Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">leaf_nodes</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">3.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b066c86d94043d639bf7b5305f612745b8a64d2920e129e3f924e8deaac2ab67.png" src="../Images/43008585fa66e722cde17f42284274b4.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b066c86d94043d639bf7b5305f612745b8a64d2920e129e3f924e8deaac2ab67.png"/>
</div>
</div>
<p>It may be useful to look at a decision tree model and the associated decision tree, side-by-side.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">leaf_nodes_viz</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">tree_model_viz</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">leaf_nodes_viz</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_gridspec</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># 1 row, 3 columns with 1:2 width ratio</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>                         <span class="c1"># visualize, data, and decision tree regions and predictions                                      </span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model_viz</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mi">1000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="s1">'Decision Tree Model, Number of Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">leaf_nodes</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span>
        <span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   

<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>                                  <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">tree_model_viz</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">,</span><span class="n">feature_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">),</span><span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">yname</span><span class="p">),</span><span class="n">filled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">,</span><span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">precision</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                  <span class="n">proportion</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fbf5427fe1d098a17a235d28fdd24ff7b7b442c21b958df2b2855e4ffeb66011.png" src="../Images/de575bff5cbcf3e18e0bc1c385400e3e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/fbf5427fe1d098a17a235d28fdd24ff7b7b442c21b958df2b2855e4ffeb66011.png"/>
</div>
</div>
<p>How do we find the best hyperparameters, for the best complexity for optimum prediction accuracy for testing? That is hyperparameter tuning.</p>
</section>
&#13;

<h3>Underfit Decision Tree Model</h3>
<p>Let‚Äôs use too few regions, set max_leaf_nodes too small and see the resulting decision tree model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">max_depth</span> <span class="o">=</span><span class="mi">99</span><span class="p">;</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>      <span class="c1"># hyperparameters</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">)</span>
<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model'</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> 
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot'</span><span class="p">,)</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/de9bb85033f26085feea46a1ec5a5786ccbe3d092bb940c53d319584063a39c7.png" src="../Images/be259c4cb62524490823c4f4d2d09c0c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/de9bb85033f26085feea46a1ec5a5786ccbe3d092bb940c53d319584063a39c7.png"/>
</div>
</div>
<p>This model is very much underfit, it is too simple to fit the shape of the prediction problem. Here‚Äôs some more information on the plot.</p>
<p>See the horizontal lines on the plot of estimated vs. actual production (plot on the bottom)?</p>
<ul class="simple">
<li><p>That is expected as the regression tree estimates with the average of the data in each region of the feature space (terminal node).</p></li>
<li><p>To further assess the model performance, I have included the actual response P10, mean and P90 for each leaf node, region for both training and testing.</p></li>
<li><p>underfit predictive machine learning models have poor accuracy and training and testing.</p></li>
</ul>
<p>If we have a more complicated tree with more terminal nodes then there would be more lines.</p>
&#13;

<h3>Overfit Decision Tree Model</h3>
<p>Let‚Äôs use too many regions, set max_leaf_nodes too large and see the resulting decision tree model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">9</span><span class="p">;</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>     <span class="c1"># hyperparameters</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">max_leaf_nodes</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">)</span>
<span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model'</span><span class="p">,</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> 
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot'</span><span class="p">,)</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b64f9666026f63544dd4662412c50db7132cd58f19c828937a4e3bbfa9366dc6.png" src="../Images/c28519e97623d45a6f72540a6b408c6d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b64f9666026f63544dd4662412c50db7132cd58f19c828937a4e3bbfa9366dc6.png"/>
</div>
</div>
<p>Now we have an overfit predictive machine learning model.</p>
<ul class="simple">
<li><p>too much complexity and flexibility</p></li>
<li><p>we are fitting the noise in the data</p></li>
<li><p>good accuracy in training, but poor accuracy in testing</p></li>
</ul>
<p>It is instructive to observe the decision tree model over the feature space as we incrementally add terminal nodes. We can graphically observe the hierarchical binary splitting quite clearly.</p>
<ul class="simple">
<li><p>Let‚Äôs visualize from simple complicated models.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">leaf_nodes_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>

<span class="k">for</span> <span class="n">inode</span><span class="p">,</span><span class="n">leaf_nodes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">leaf_nodes_list</span><span class="p">):</span>

    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">leaf_nodes</span><span class="p">)</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">inode</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>                                         <span class="c1"># visualize, data, and decision tree regions and predictions</span>
    <span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mi">1000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="s1">'Decision Tree Model, Number of Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">leaf_nodes</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span><span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">3.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b066c86d94043d639bf7b5305f612745b8a64d2920e129e3f924e8deaac2ab67.png" src="../Images/43008585fa66e722cde17f42284274b4.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b066c86d94043d639bf7b5305f612745b8a64d2920e129e3f924e8deaac2ab67.png"/>
</div>
</div>
<p>It may be useful to look at a decision tree model and the associated decision tree, side-by-side.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">leaf_nodes_viz</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">tree_model_viz</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">leaf_nodes_viz</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_gridspec</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># 1 row, 3 columns with 1:2 width ratio</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>                         <span class="c1"># visualize, data, and decision tree regions and predictions                                      </span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">tree_model_viz</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="mi">1000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="s1">'Decision Tree Model, Number of Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">leaf_nodes</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span>
        <span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">,</span><span class="n">annotate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   

<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>                                  <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">tree_model_viz</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">,</span><span class="n">feature_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">),</span><span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">yname</span><span class="p">),</span><span class="n">filled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'none'</span><span class="p">,</span><span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">precision</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                  <span class="n">proportion</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fbf5427fe1d098a17a235d28fdd24ff7b7b442c21b958df2b2855e4ffeb66011.png" src="../Images/de575bff5cbcf3e18e0bc1c385400e3e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/fbf5427fe1d098a17a235d28fdd24ff7b7b442c21b958df2b2855e4ffeb66011.png"/>
</div>
</div>
<p>How do we find the best hyperparameters, for the best complexity for optimum prediction accuracy for testing? That is hyperparameter tuning.</p>
&#13;

<h2>Tuning a Decision Tree (Regression Tree)</h2>
<p>Let‚Äôs perform hyperparameter tuning. To do this we,</p>
<ol class="arabic simple">
<li><p>See the range of possible hyperparameter values.</p></li>
<li><p>Loop over the range of possible hyperparameter values.</p>
<ul class="simple">
<li><p>Train on the training data with the current hyperparameter values.</p></li>
<li><p>Predict at the testing data</p></li>
<li><p>Summarize the error over all the testing data</p></li>
</ul>
</li>
<li><p>Select the hyperparameters that minimize the error at for the testing data</p></li>
</ol>
<p>When I teach this to my students, I suggest that this is a model dress rehearsal. We add value by making predictions for cases not used to train the model. We want the model that performs best for cases not in the training, so we are simulating real world use of the model!</p>
<p>Now let‚Äôs do hyperparameter tuning ‚Äòby-hand‚Äô, by varying the decision tree complexity and find the complexity that minimizes MSE in testing</p>
<ul class="simple">
<li><p>for simplicity the code below loops only over the maximum leaf nodes hyperparameter</p></li>
<li><p>we set minimum number of samples to 1, and maximum depth to 9 to ensure that these hyperparameters will not have any impact (we set them to very complicated so they don‚Äôt limit the model complexity)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">trees</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">MSE_CV</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_CV</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>                                   <span class="c1"># loop over the hyperparameter, train with training and test with testing</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">trees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tree_model</span><span class="p">)</span>
    <span class="n">predict_train</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]]])</span> 
    <span class="n">MSE_CV</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">predict_train</span><span class="p">))</span>   
    <span class="n">all_nodes</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span>             
    <span class="n">decision_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">]);</span> <span class="n">terminal_nodes</span> <span class="o">=</span> <span class="n">all_nodes</span> <span class="o">-</span> <span class="n">decision_nodes</span>
    <span class="n">node_CV</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">terminal_nodes</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_CV</span><span class="p">,</span><span class="n">MSE_CV</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">tuned_node</span> <span class="o">=</span> <span class="n">node_CV</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_CV</span><span class="p">)];</span> <span class="n">max_MSE_CV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_CV</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_CV</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node</span><span class="p">),(</span><span class="n">tuned_node</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree Cross Validation Testing Error vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_CV</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/27a521f2cbd01b3caec37b95530d68674a6785fa6c061acdac71ea6326a9fe6b.png" src="../Images/f43c9ad2b759692c2b199e397c735352.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/27a521f2cbd01b3caec37b95530d68674a6785fa6c061acdac71ea6326a9fe6b.png"/>
</div>
</div>
<p>It is useful to evaluate the performance of our tree by observing the accuracy vs. complexity, with a minimum due to the model variance and model bias trade-off.</p>
<p>For a more robust result, let‚Äôs try k-fold cross validation. sklearn has a built in cross validation method called cross_val_score that we can use to:</p>
<ol class="arabic simple">
<li><p>Apply k-fold approach with iterative separation of training and testing data</p></li>
<li><p>With k=5, we have 20% withheld for testing for each fold</p></li>
<li><p>Automate the model construction, looping over folds and averaging the metric of interest</p></li>
</ol>
<p>Let‚Äôs try it out on our trees with variable number of terminal nodes.  Note the cross validation is set to use 4 processors, but still will likely take a couple of minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">MSE_kF</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_kF</span> <span class="o">=</span> <span class="p">[]</span>                                     <span class="c1"># k-fold iteration code modified from StackOverFlow by Dimosthenis</span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span>                   <span class="c1"># perform 4-fold cross validation</span>
    <span class="n">MSE_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">all_nodes</span> <span class="o">=</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span>   
    <span class="n">decision_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tree_model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">]);</span> <span class="n">terminal_nodes</span> <span class="o">=</span> <span class="n">all_nodes</span> <span class="o">-</span> <span class="n">decision_nodes</span>
    <span class="n">node_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">terminal_nodes</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">tuned_node_kF</span> <span class="o">=</span> <span class="n">node_kF</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)];</span> <span class="n">max_MSE_kF</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),(</span><span class="n">tuned_node_kF</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_kF</span><span class="p">,</span><span class="n">MSE_kF</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'k-Fold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_CV</span><span class="p">,</span><span class="n">MSE_CV</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Cross Validation'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree k-Fold Cross Validation Error (MSE) vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/35821438b0adbe9ae455b2e6731dab92e05cf7dfb2dcbaaa8d296ac1c9a18b39.png" src="../Images/2df3cfa16f6fb36c7bd2a52fe7d20a6d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/35821438b0adbe9ae455b2e6731dab92e05cf7dfb2dcbaaa8d296ac1c9a18b39.png"/>
</div>
</div>
<p>The k-fold cross validation provides a smoother plot of MSE vs. the hyperparameter.</p>
<ul class="simple">
<li><p>this is accomplished by averaging the MSE over all the folds to reduce sensitivity of the metric to specific assignment of training and testing data</p></li>
<li><p>all our train and test cross validation or k-fold cross validation was to get this one value, the model <strong>hyperparameter</strong></p></li>
</ul>
&#13;

<h2>Build the Final Model</h2>
<p>Now let‚Äôs take that hyperparameter and train on all the data, this is our <strong>final model</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pruned_tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">tuned_node_kF</span><span class="p">)</span>
<span class="n">pruned_tree_model</span> <span class="o">=</span> <span class="n">pruned_tree_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>               <span class="c1"># re-train</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># visualize, data, and decision tree regions and predictions</span>
<span class="n">visualize_tree_model</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model, Tuned Leaf Nodes: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),</span><span class="n">Xname</span><span class="p">,</span><span class="n">yname</span><span class="p">,</span>
                    <span class="n">Xlabelunit</span><span class="p">,</span><span class="n">ylabelunit</span><span class="p">)</span> <span class="c1"># plots the data points and the decision tree prediction </span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># cross validation with conditional statistics plot</span>
<span class="n">check_tree_model</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">yname</span><span class="p">],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="s1">'Decision Tree Model Cross Validation Plot, Tuned Leaf Nodes: '</span> <span class="o">+</span> 
                    <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),)</span>
       
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e85bbd71cc280b9a057d106524b0d1dfca28c6500e32ece594637cde5b8b1dba.png" src="../Images/608907e2a0d015a0d611204bfa6c41e5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/e85bbd71cc280b9a057d106524b0d1dfca28c6500e32ece594637cde5b8b1dba.png"/>
</div>
</div>
<p>We have completed our predictive machine learning model. Now let‚Äôs cover a couple more decision tree diagnostics.</p>
&#13;

<h2>Interrogating Decision Trees</h2>
<p>It may be useful to evaluate for any possible feature combination, the order of decision nodes that resulted in the specific prediction.  The following function provides the list of nodes that the prediction cases passes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">x1</span> <span class="o">=</span> <span class="mf">7.0</span><span class="p">;</span> <span class="n">x2</span> <span class="o">=</span> <span class="mf">10.0</span>                                          <span class="c1"># the predictor feature values for the decision path</span>

<span class="n">decision_path</span> <span class="o">=</span> <span class="n">pruned_tree_model</span><span class="o">.</span><span class="n">decision_path</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decision_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>  (0, 0)	1
  (0, 1)	1
  (0, 3)	1
  (0, 13)	1
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Extracting the Decision Tree Prediction Model as a Function</h2>
<p>Furthermore it may be useful to convert the decision tree to code, a nested set of ‚Äòif‚Äô statements.</p>
<ul class="simple">
<li><p>This creates a portable model that could be copied and applied as a standalone function.</p></li>
</ul>
<p>Also, one could conveniently interrogate the code version of the tree.</p>
<ul class="simple">
<li><p>We use the previously defined function to do this with our pruned tree.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">tree_to_code</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">))</span>                  <span class="c1"># convert a decision tree to Python code, nested if statements</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>def tree(Por, Brittle):
  if Por &lt;= 14.789999961853027:
    if Por &lt;= 12.425000190734863:
      if Por &lt;= 8.335000038146973:
        return [[1879.19091537]]
      elif Por &gt; 8.335000038146973
        if Brittle &lt;= 39.125:
          return [[2551.00021508]]
        elif Brittle &gt; 39.125
          return [[3369.12903299]]
    elif Por &gt; 12.425000190734863
      if Brittle &lt;= 39.26500129699707:
        return [[3160.11022857]]
      elif Brittle &gt; 39.26500129699707
        return [[4154.18334527]]
  elif Por &gt; 14.789999961853027
    if Por &lt;= 18.015000343322754:
      if Brittle &lt;= 33.25:
        return [[3883.19381758]]
      elif Brittle &gt; 33.25
        if Por &lt;= 16.434999465942383:
          return [[4544.69777089]]
        elif Por &gt; 16.434999465942383
          return [[5240.84146117]]
    elif Por &gt; 18.015000343322754
      if Brittle &lt;= 31.5600004196167:
        return [[4353.11874206]]
      elif Brittle &gt; 31.5600004196167
        return [[5868.56369869]]
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Decision Tree-based Feature Importance</h2>
<p>Feature importance is calculated from a decision trees by summarizing the reduction in mean square error through inclusion of each feature and is summarized as:</p>
<div class="math notranslate nohighlight">
\[
FI(x) = \sum_{t \in T_f} \frac{N_t}{N} \Delta_{MSE_t}
\]</div>
<p>where <span class="math notranslate nohighlight">\(T_f\)</span> are all nodes with feature <span class="math notranslate nohighlight">\(x\)</span> as the split, <span class="math notranslate nohighlight">\(N_t\)</span> is the number of training samples reaching node <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(N\)</span> is the total number of samples in the dataset and <span class="math notranslate nohighlight">\(\Delta_{MSE_t}\)</span> is the reduction in MSE with the <span class="math notranslate nohighlight">\(t\)</span> split.</p>
<p>Note, feature importance can be calculated in a similar manner to MSE above for the case of classification trees with <strong>Gini Impurity</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the feature importance </span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Decision Tree Feature Importance"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Xlabel</span><span class="p">,</span> <span class="n">pruned_tree_model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span>
       <span class="n">color</span><span class="o">=</span><span class="s2">"darkorange"</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">Xname</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predictor Feature'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Feature Importance'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8fcae780c3b59534e28863b5aa7a46545ac1a9e556ab9950e41495b87e7bee49.png" src="../Images/e7672512b746dfc82482f39bc8c78ddc.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8fcae780c3b59534e28863b5aa7a46545ac1a9e556ab9950e41495b87e7bee49.png"/>
</div>
</div>
&#13;

<h2>Visualize the Model</h2>
<p>Let‚Äôs take a last look at the graphical representation of our pruned tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">pruned_tree_model</span><span class="p">,</span>                         <span class="c1"># plot the decision tree for model visualization</span>
                   <span class="n">feature_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">Xname</span><span class="p">),</span>  
                   <span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">yname</span><span class="p">),</span>
                   <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/67fb9697896ebccb3d2ba5fce562153c671634fd57bdc8739c47227f04785578.png" src="../Images/dceac0eb1f800b2c21d5e490c1248210.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/67fb9697896ebccb3d2ba5fce562153c671634fd57bdc8739c47227f04785578.png"/>
</div>
</div>
&#13;

<h2>Simple Code to Make a Decision Tree Machine and Calculate a Prediction</h2>
<p>To support those just getting started, here‚Äôs a minimal amount of code to:</p>
<ul class="simple">
<li><p>load the scikit-learn package for decision trees</p></li>
<li><p>load data</p></li>
<li><p>instantiate a decision tree with hyperparameters (no tuning is shown)</p></li>
<li><p>train the decision tree with the training data</p></li>
<li><p>make a prediction with the decision tree</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>                                      <span class="c1"># import decision tree from scikit-learn</span>
<span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Por'</span><span class="p">,</span><span class="s1">'Brittle'</span><span class="p">];</span> <span class="n">yname</span><span class="o">=</span><span class="s1">'Production'</span>                 <span class="c1"># predictor features and response feature</span>
<span class="n">x1</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">;</span> <span class="n">x2</span> <span class="o">=</span> <span class="mf">0.3</span>                                           <span class="c1"># predictor values for the prediction</span>
<span class="n">my_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV.csv"</span><span class="p">)</span> <span class="c1"># load subsurface data table</span>
<span class="n">my_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>       <span class="c1"># instantiate tree with hyperparameters</span>
<span class="n">my_tree</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>                      <span class="c1"># train tree with training data</span>
<span class="n">estimate</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">]])[</span><span class="mi">0</span><span class="p">]</span>                      <span class="c1"># make a prediction (no tuning shown)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Estimated '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' for '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>  <span class="o">+</span> <span class="s1">' is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">estimate</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">)</span> <span class="c1"># print results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Estimated Production for Porosity = 0.25 and Brittleness = 0.3 is 1879.2 MCFPD
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Machine Learning Pipelines for Clean, Compact Machine Learning Code</h2>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>build complete workflows with very few lines of readable code</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to find the best model (AutoML)</p>
<p>For more information see my recorded lecture on <a class="reference external" href="https://www.youtube.com/watch?v=tYrPs8s1l9U&amp;list=PLG19vXLQHvSAufDFgZEFAYQEwMJXklnQV&amp;index=5">Machine Learning Pipelines</a> and a well-documented demonstration <a class="reference external" href="http://localhost:8892/notebooks/OneDrive%20-%20The%20University%20of%20Texas%20at%20Austin/Courses/Workflows/PythonDataBasics_Pipelines.ipynb">Machine Learning Pipeline Workflow</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pipe_tree</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>                                        <span class="c1"># the machine learning workflow as a pipeline object</span>

    <span class="p">(</span><span class="s1">'tree'</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>                                                    <span class="c1"># the machine learning workflow method's parameters to search</span>
    <span class="s1">'tree__max_leaf_nodes'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">),</span>
<span class="p">}</span>

<span class="n">KF_tuned_tree</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe_tree</span><span class="p">,</span><span class="n">params</span><span class="p">,</span><span class="n">scoring</span> <span class="o">=</span> <span class="s1">'neg_mean_squared_error'</span><span class="p">,</span> <span class="c1"># hyperparameter tuning w. grid search k-fold cross validation </span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span><span class="n">refit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">KF_tuned_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>                                        <span class="c1"># tune and train the model</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Tuned hyperparameter: max_leaf_nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">KF_tuned_tree</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>

<span class="n">estimate</span> <span class="o">=</span> <span class="n">KF_tuned_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">]])[</span><span class="mi">0</span><span class="p">]</span>                <span class="c1"># make a prediction (no tuning shown)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Estimated '</span> <span class="o">+</span> <span class="n">ylabel</span> <span class="o">+</span> <span class="s1">' for '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">Xlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>  <span class="o">+</span> <span class="s1">' is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">estimate</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">)</span> <span class="c1"># print results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Tuned hyperparameter: max_leaf_nodes = {'tree__max_leaf_nodes': 10}
Estimated Production for Porosity = 0.25 and Brittleness = 0.3 is 1879.2 MCFPD
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Practice on a New Dataset</h2>
<p>Ok, time to get to work. Let‚Äôs load up a dataset and build a decision tree prediction model with,</p>
<ul class="simple">
<li><p>compact code</p></li>
<li><p>basic visaulizations</p></li>
<li><p>save the output</p></li>
</ul>
<p>You can select any of these datasets or modify the code and add your own to do this.</p>
<section id="dataset-0-unconventional-multivariate-v4">
<h3>Dataset 0, Unconventional Multivariate v4</h3>
<p>Let‚Äôs load the provided multivariate, dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv">unconv_MV.csv</a>. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
</section>
<section id="dataset-2-reservoir-21">
<h3>Dataset 2, Reservoir 21</h3>
<p>Let‚Äôs load the provided multivariate, 3D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv">res21_wells.csv</a>. This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50 m reservoir unit:</p>
<ul class="simple">
<li><p>well (ID)</p></li>
<li><p>X (m), Y (m), Depth (m) location coordinates</p></li>
<li><p>Porosity (%) after units conversion</p></li>
<li><p>Permeability (mD)</p></li>
<li><p>Acoustic Impedance (kg/m2s*10^6) after units conversion</p></li>
<li><p>Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley Sand, to Sandstone.</p></li>
<li><p>Density (g/cm^3)</p></li>
<li><p>Compressible velocity (m/s)</p></li>
<li><p>Youngs modulus (GPa)</p></li>
<li><p>Shear velocity (m/s)</p></li>
<li><p>Shear modulus (GPa)</p></li>
<li><p>3 year cumulative oil production (Mbbl)</p></li>
</ul>
<p>We load the tabular data with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
<ul class="simple">
<li><p>we also populate lists with data ranges and labels for ease of plotting</p></li>
</ul>
<p>Load and format the data,</p>
<ul class="simple">
<li><p>drop the response feature</p></li>
<li><p>reformate the features as needed</p></li>
<li><p>also, I like to store the metadata in lists</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">idata</span> <span class="o">=</span> <span class="mi">2</span>                                                    <span class="c1"># select the dataset</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Well'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                 <span class="c1"># remove well index and response feature</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
       
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">10000.0</span>
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Production (MCFPD)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Production'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Porosity'</span><span class="p">:</span><span class="s1">'Por'</span><span class="p">}</span>
    
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Unnamed: 0'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>   <span class="c1"># remove response feature</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="n">df_new</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">;</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1000.0</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">1.60</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">6.20</span>
    
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Well_ID'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># remove Well Index, X and Y coordinates, and response feature</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
     
    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">1600.0</span>
    
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Production (Mbbl)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Production'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="n">df_new</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Density</th>
      <th>PVel</th>
      <th>Youngs</th>
      <th>SVel</th>
      <th>Shear</th>
      <th>CumulativeOil</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>12.907730</td>
      <td>133.910637</td>
      <td>7.308846</td>
      <td>2.146360</td>
      <td>3563.549461</td>
      <td>25.688560</td>
      <td>1673.770439</td>
      <td>6.429229</td>
      <td>1201.20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>12.647965</td>
      <td>114.359667</td>
      <td>7.343836</td>
      <td>2.188597</td>
      <td>3570.094553</td>
      <td>25.444064</td>
      <td>1670.043495</td>
      <td>6.100984</td>
      <td>683.92</td>
    </tr>
    <tr>
      <th>10</th>
      <td>12.998469</td>
      <td>129.332122</td>
      <td>7.282051</td>
      <td>2.131121</td>
      <td>3524.448615</td>
      <td>25.985734</td>
      <td>1681.960101</td>
      <td>6.203527</td>
      <td>978.14</td>
    </tr>
    <tr>
      <th>15</th>
      <td>12.426141</td>
      <td>123.227677</td>
      <td>7.351795</td>
      <td>2.203026</td>
      <td>3417.596818</td>
      <td>25.976462</td>
      <td>1675.355860</td>
      <td>6.288040</td>
      <td>608.09</td>
    </tr>
    <tr>
      <th>16</th>
      <td>13.507371</td>
      <td>147.562087</td>
      <td>7.300360</td>
      <td>2.210916</td>
      <td>3476.167397</td>
      <td>24.817767</td>
      <td>1656.890690</td>
      <td>6.222528</td>
      <td>1062.10</td>
    </tr>
    <tr>
      <th>36</th>
      <td>13.309477</td>
      <td>122.818961</td>
      <td>7.345220</td>
      <td>2.178749</td>
      <td>3346.347661</td>
      <td>25.436579</td>
      <td>1651.679529</td>
      <td>6.334308</td>
      <td>539.98</td>
    </tr>
    <tr>
      <th>49</th>
      <td>11.822910</td>
      <td>98.168307</td>
      <td>7.386212</td>
      <td>2.301552</td>
      <td>3250.020705</td>
      <td>24.340656</td>
      <td>1662.438742</td>
      <td>6.617267</td>
      <td>1095.30</td>
    </tr>
    <tr>
      <th>51</th>
      <td>13.986616</td>
      <td>132.575456</td>
      <td>7.194749</td>
      <td>2.108986</td>
      <td>3415.255945</td>
      <td>26.253236</td>
      <td>1712.017629</td>
      <td>5.583251</td>
      <td>805.49</td>
    </tr>
    <tr>
      <th>61</th>
      <td>14.735895</td>
      <td>128.201000</td>
      <td>7.172693</td>
      <td>1.841786</td>
      <td>3886.950307</td>
      <td>28.289950</td>
      <td>1672.370150</td>
      <td>5.044439</td>
      <td>1146.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="build-and-check-model">
<h3>Build and Check Model</h3>
<p>We apply the follow steps,</p>
<ol class="arabic simple">
<li><p>specify the K-fold method</p></li>
<li><p>loop over number of leaf nodes, instantiate, fit and record the error</p></li>
<li><p>plot the test error vs. number of leaf nodes, select the hyperparameter that minimizes test error</p></li>
<li><p>retrain the model with the tuned hyperparameter and all of the data</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">MSE_kF</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_kF</span> <span class="o">=</span> <span class="p">[]</span>                                     
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>       <span class="c1"># k-fold specification     </span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span> <span class="c1"># perform 5-fold cross validation</span>
    <span class="n">MSE_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">node_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inode</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">tuned_node_kF</span> <span class="o">=</span> <span class="n">node_kF</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)]</span>
<span class="n">tuned_tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">tuned_node_kF</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="c1"># retrain on all the data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),(</span><span class="n">tuned_node_kF</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_kF</span><span class="p">,</span><span class="n">MSE_kF</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'k-Fold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree k-Fold Cross Validation Error (MSE) vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">tuned_tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span> <span class="c1"># cross validation plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">],[</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Truth: '</span> <span class="o">+</span> <span class="n">ylabel_new</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimate: '</span> <span class="o">+</span> <span class="n">ylabel_new</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Tuned Decision Tree, Cross Validation'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/800e93156a21d23fb27ec3b349cbd0c234a2789e27a8582567a80abbbf0e08b0.png" src="../Images/a3d66d6b8f851c5edb5b770a5393116c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/800e93156a21d23fb27ec3b349cbd0c234a2789e27a8582567a80abbbf0e08b0.png"/>
</div>
</div>
</section>
&#13;

<h3>Dataset 0, Unconventional Multivariate v4</h3>
<p>Let‚Äôs load the provided multivariate, dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/unconv_MV_v4.csv">unconv_MV.csv</a>. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
&#13;

<h3>Dataset 2, Reservoir 21</h3>
<p>Let‚Äôs load the provided multivariate, 3D spatial dataset <a class="reference external" href="https://github.com/GeostatsGuy/GeoDataSets/blob/master/res21_wells.csv">res21_wells.csv</a>. This dataset has variables from 73 vertical wells over a 10,000m x 10,000m x 50 m reservoir unit:</p>
<ul class="simple">
<li><p>well (ID)</p></li>
<li><p>X (m), Y (m), Depth (m) location coordinates</p></li>
<li><p>Porosity (%) after units conversion</p></li>
<li><p>Permeability (mD)</p></li>
<li><p>Acoustic Impedance (kg/m2s*10^6) after units conversion</p></li>
<li><p>Facies (categorical) - ordinal with ordering from Shale, Sandy Shale, Shaley Sand, to Sandstone.</p></li>
<li><p>Density (g/cm^3)</p></li>
<li><p>Compressible velocity (m/s)</p></li>
<li><p>Youngs modulus (GPa)</p></li>
<li><p>Shear velocity (m/s)</p></li>
<li><p>Shear modulus (GPa)</p></li>
<li><p>3 year cumulative oil production (Mbbl)</p></li>
</ul>
<p>We load the tabular data with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
<ul class="simple">
<li><p>we also populate lists with data ranges and labels for ease of plotting</p></li>
</ul>
<p>Load and format the data,</p>
<ul class="simple">
<li><p>drop the response feature</p></li>
<li><p>reformate the features as needed</p></li>
<li><p>also, I like to store the metadata in lists</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">idata</span> <span class="o">=</span> <span class="mi">2</span>                                                    <span class="c1"># select the dataset</span>

<span class="k">if</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Well'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                 <span class="c1"># remove well index and response feature</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
       
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>
    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">10000.0</span>
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Production (MCFPD)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Production'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Porosity'</span><span class="p">:</span><span class="s1">'Por'</span><span class="p">}</span>
    
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Unnamed: 0'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>   <span class="c1"># remove response feature</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
    <span class="n">df_new</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">;</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s1">'AI'</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1000.0</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">1.60</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">6.20</span>
    
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="k">elif</span> <span class="n">idata</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/res21_2D_wells.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub repository  </span>
    <span class="n">df_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Well_ID'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># remove Well Index, X and Y coordinates, and response feature</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s1">'any'</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
     
    <span class="n">features</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>                 <span class="c1"># store the names of the features</span>

    <span class="n">xname</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    
    <span class="n">xmin_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">6.5</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">1600.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">1300.0</span><span class="p">,</span><span class="mf">1.6</span><span class="p">];</span> <span class="n">xmax_new</span> <span class="o">=</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">10000.0</span><span class="p">,</span><span class="mf">19.0</span><span class="p">,</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">8.3</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">6200.0</span><span class="p">,</span><span class="mf">50.0</span><span class="p">,</span><span class="mf">2000.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">]</span> <span class="c1"># set the minimum and maximum values for plotting</span>

    <span class="n">ymin_new</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">ymax_new</span> <span class="o">=</span> <span class="mf">1600.0</span>
    
    <span class="n">xlabel_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well (ID)'</span><span class="p">,</span><span class="s1">'X (m)'</span><span class="p">,</span><span class="s1">'Y (m)'</span><span class="p">,</span><span class="s1">'Depth (m)'</span><span class="p">,</span><span class="s1">'Porosity (fraction)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Facies (categorical)'</span><span class="p">,</span>
              <span class="s1">'Density (g/cm^3)'</span><span class="p">,</span><span class="s1">'Compressible velocity (m/s)'</span><span class="p">,</span><span class="s1">'Youngs modulus (GPa)'</span><span class="p">,</span> <span class="s1">'Shear velocity (m/s)'</span><span class="p">,</span> <span class="s1">'Shear modulus (GPa)'</span><span class="p">]</span> <span class="c1"># set the names for plotting</span>

    <span class="n">ylabel_new</span> <span class="o">=</span> <span class="s1">'Production (Mbbl)'</span>
    
    <span class="n">xtitle_new</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Well'</span><span class="p">,</span><span class="s1">'X'</span><span class="p">,</span><span class="s1">'Y'</span><span class="p">,</span><span class="s1">'Depth'</span><span class="p">,</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Facies'</span><span class="p">,</span>
              <span class="s1">'Density'</span><span class="p">,</span><span class="s1">'Compressible velocity'</span><span class="p">,</span><span class="s1">'Youngs modulus'</span><span class="p">,</span> <span class="s1">'Shear velocity'</span><span class="p">,</span> <span class="s1">'Shear modulus'</span><span class="p">]</span>

    <span class="n">ytitle_new</span> <span class="o">=</span> <span class="s1">'Production'</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df_new</span><span class="p">[</span><span class="n">yname</span><span class="p">])</span>                              <span class="c1"># extract selected features as X and y DataFrames  </span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="n">xname</span><span class="p">]</span>

<span class="n">df_new</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Density</th>
      <th>PVel</th>
      <th>Youngs</th>
      <th>SVel</th>
      <th>Shear</th>
      <th>CumulativeOil</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>12.907730</td>
      <td>133.910637</td>
      <td>7.308846</td>
      <td>2.146360</td>
      <td>3563.549461</td>
      <td>25.688560</td>
      <td>1673.770439</td>
      <td>6.429229</td>
      <td>1201.20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>12.647965</td>
      <td>114.359667</td>
      <td>7.343836</td>
      <td>2.188597</td>
      <td>3570.094553</td>
      <td>25.444064</td>
      <td>1670.043495</td>
      <td>6.100984</td>
      <td>683.92</td>
    </tr>
    <tr>
      <th>10</th>
      <td>12.998469</td>
      <td>129.332122</td>
      <td>7.282051</td>
      <td>2.131121</td>
      <td>3524.448615</td>
      <td>25.985734</td>
      <td>1681.960101</td>
      <td>6.203527</td>
      <td>978.14</td>
    </tr>
    <tr>
      <th>15</th>
      <td>12.426141</td>
      <td>123.227677</td>
      <td>7.351795</td>
      <td>2.203026</td>
      <td>3417.596818</td>
      <td>25.976462</td>
      <td>1675.355860</td>
      <td>6.288040</td>
      <td>608.09</td>
    </tr>
    <tr>
      <th>16</th>
      <td>13.507371</td>
      <td>147.562087</td>
      <td>7.300360</td>
      <td>2.210916</td>
      <td>3476.167397</td>
      <td>24.817767</td>
      <td>1656.890690</td>
      <td>6.222528</td>
      <td>1062.10</td>
    </tr>
    <tr>
      <th>36</th>
      <td>13.309477</td>
      <td>122.818961</td>
      <td>7.345220</td>
      <td>2.178749</td>
      <td>3346.347661</td>
      <td>25.436579</td>
      <td>1651.679529</td>
      <td>6.334308</td>
      <td>539.98</td>
    </tr>
    <tr>
      <th>49</th>
      <td>11.822910</td>
      <td>98.168307</td>
      <td>7.386212</td>
      <td>2.301552</td>
      <td>3250.020705</td>
      <td>24.340656</td>
      <td>1662.438742</td>
      <td>6.617267</td>
      <td>1095.30</td>
    </tr>
    <tr>
      <th>51</th>
      <td>13.986616</td>
      <td>132.575456</td>
      <td>7.194749</td>
      <td>2.108986</td>
      <td>3415.255945</td>
      <td>26.253236</td>
      <td>1712.017629</td>
      <td>5.583251</td>
      <td>805.49</td>
    </tr>
    <tr>
      <th>61</th>
      <td>14.735895</td>
      <td>128.201000</td>
      <td>7.172693</td>
      <td>1.841786</td>
      <td>3886.950307</td>
      <td>28.289950</td>
      <td>1672.370150</td>
      <td>5.044439</td>
      <td>1146.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
&#13;

<h3>Build and Check Model</h3>
<p>We apply the follow steps,</p>
<ol class="arabic simple">
<li><p>specify the K-fold method</p></li>
<li><p>loop over number of leaf nodes, instantiate, fit and record the error</p></li>
<li><p>plot the test error vs. number of leaf nodes, select the hyperparameter that minimizes test error</p></li>
<li><p>retrain the model with the tuned hyperparameter and all of the data</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">MSE_kF</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">node_kF</span> <span class="o">=</span> <span class="p">[]</span>                                     
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>       <span class="c1"># k-fold specification     </span>

<span class="n">inode</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">while</span> <span class="n">inode</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">inode</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span> <span class="c1"># perform 5-fold cross validation</span>
    <span class="n">MSE_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">node_kF</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inode</span><span class="p">);</span> <span class="n">inode</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">tuned_node_kF</span> <span class="o">=</span> <span class="n">node_kF</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">MSE_kF</span><span class="p">)]</span>
<span class="n">tuned_tree_model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">tuned_node_kF</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="c1"># retrain on all the data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Tuned Max Nodes = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tuned_node_kF</span><span class="p">),(</span><span class="n">tuned_node_kF</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.5e5</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">node_kF</span><span class="p">,</span><span class="n">MSE_kF</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'k-Fold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree k-Fold Cross Validation Error (MSE) vs. Complexity'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Terminal Nodes'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="o">*</span><span class="n">max_MSE_kF</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">tuned_tree_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span> <span class="c1"># cross validation plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">],[</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin_new</span><span class="p">,</span><span class="n">ymax_new</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Truth: '</span> <span class="o">+</span> <span class="n">ylabel_new</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimate: '</span> <span class="o">+</span> <span class="n">ylabel_new</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Tuned Decision Tree, Cross Validation'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/800e93156a21d23fb27ec3b349cbd0c234a2789e27a8582567a80abbbf0e08b0.png" src="../Images/a3d66d6b8f851c5edb5b770a5393116c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/800e93156a21d23fb27ec3b349cbd0c234a2789e27a8582567a80abbbf0e08b0.png"/>
</div>
</div>
&#13;

<h2>Comments</h2>
<p>This was a basic treatment of decision tree. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
&#13;

<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
&#13;

<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
    
</body>
</html>