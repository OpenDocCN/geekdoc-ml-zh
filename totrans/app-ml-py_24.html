<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Polynomial Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Polynomial Regression</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_polynomial_regression.html">https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_polynomial_regression.html</a></blockquote>

<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book ‚ÄúApplied Machine Learning in Python: a Hands-on Guide with Code‚Äù.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, <em>Applied Machine Learning in Python: A Hands-on Guide with Code</em> [e-book]. Zenodo. doi:10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="../Images/7e4ea662f44af1eae87e87ecbb962ff4.png" data-original-src="https://zenodo.org/badge/863274676.svg"/></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, <em>MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository</em> (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312. GitHub repository: <a class="github reference external" href="https://github.com/GeostatsGuy/MachineLearningDemos">GeostatsGuy/MachineLearningDemos</a> <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="../Images/4e3a59c17d684b06a170c4af84e0f631.png" data-original-src="https://zenodo.org/badge/862519860.svg"/></a></p>
</div>
<p>By Michael J. Pyrcz <br/>
¬© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>Polynomial Regression</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/0fzbyhWiP84?si=uRdmHOTzdnUvDPA9">Linear Regression</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/z19Hs2HfO88?si=etUIb3LegiTigEio">Polynomial Regression</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/4nYz5j0sAQs?si=n_553YQdh5grTquV">Numerical Optimization</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael‚Äôs Story</a>.</p>
<section id="motivations-for-polynomial-regression">
<h2>Motivations for Polynomial Regression</h2>
<p>By moving from linear regression to polynomial regression we,</p>
<ul class="simple">
<li><p>add prediction flexibility by modeling non-linearity in our data</p></li>
<li><p>build on the feature engineering concept of feature expansion</p></li>
</ul>
<p>while benefiting from the analytical solutions for training model parameters like linear regression.</p>
<p>We accomplish all of this with basis expansion,</p>
<ul class="simple">
<li><p>we transform and expand the features <span class="math notranslate nohighlight">\(\rightarrow\)</span> introduce basis expansion!</p></li>
<li><p>we can increase our predictive model complexity and flexibility <span class="math notranslate nohighlight">\(\rightarrow\)</span> nonlinear basis!</p></li>
<li><p>we can improve the model robustness by removing multicollinearity <span class="math notranslate nohighlight">\(\rightarrow\)</span> orthogonal basis!</p></li>
</ul>
<p>Let‚Äôs start with linear regression and then build to polynomial regression.</p>
</section>
<section id="linear-regression">
<h2>Linear Regression</h2>
<p>Linear regression for prediction, let‚Äôs start by looking at a linear model fit to a set of data.</p>
<figure style="text-align: center;">
  <img src="../Images/806bf5f702f9bb5a63e30d6e1f7969d9.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/linear/linear_example.png"/>
  <figcaption style="text-align: center;">Example linear regression model.</figcaption>
</figure>
<p>Let‚Äôs start by defining some terms,</p>
<ul class="simple">
<li><p><strong>predictor feature</strong> - an input feature for the prediction model, given we are only discussing linear regression and not multilinear regression we have only one predictor feature, <span class="math notranslate nohighlight">\(x\)</span>. On out plots (including above) the predictor feature is on the x-axis.</p></li>
<li><p><strong>response feature</strong> - the output feature for the prediction model, in this case, <span class="math notranslate nohighlight">\(y\)</span>. On our plots (including above) the response feature is on the y-axis.</p></li>
</ul>
<p>Now, here are some key aspects of linear regression:</p>
<p><strong>Parametric Model</strong></p>
<p>This is a parametric predictive machine learning model, we accept an a prior assumption of linearity and then gain a very low parametric representation that is easy to train without a onerous amount of data.</p>
<ul class="simple">
<li><p>the fit model is a simple weighted linear additive model based on all the available features, <span class="math notranslate nohighlight">\(x_1,\ldots,x_m\)</span>.</p></li>
<li><p>the parametric model takes the form of:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0
\]</div>
<p>Here‚Äôs the visualization of the linear model parameters,</p>
<figure style="text-align: center;">
  <img src="../Images/ada2fcc2740c48478e79404563c91061.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/linear/linear_model.png"/>
  <figcaption style="text-align: center;">The linear model parameters.</figcaption>
</figure>
<p><strong>Least Squares</strong></p>
<p>The analytical solution for the model parameters, <span class="math notranslate nohighlight">\(b_1,\ldots,b_m,b_0\)</span>, is available for the L2 norm loss function, the errors are summed and squared known a least squares.</p>
<ul class="simple">
<li><p>we minimize the error, residual sum of squares (RSS) over the training data:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0) \right)^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the actual response feature values and <span class="math notranslate nohighlight">\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\)</span> are the model predictions, over the <span class="math notranslate nohighlight">\(\alpha = 1,\ldots,n\)</span> training data.</p>
<p>Here‚Äôs a visualization of the L2 norm loss function, MSE,</p>
<figure style="text-align: center;">
  <img src="../Images/835541b16e1038a4606f7d97b628c4f9.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/linear/linear_MSE.png"/>
  <figcaption style="text-align: center;">The linear model loss function, mean square error.</figcaption>
</figure>
<ul class="simple">
<li><p>this may be simplified as the sum of square error over the training data,</p></li>
</ul>
<p>\begin{equation}
\sum_{i=1}^n (\Delta y_i)^2
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(\Delta y_i\)</span> is actual response feature observation <span class="math notranslate nohighlight">\(y_i\)</span> minus the model prediction <span class="math notranslate nohighlight">\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\)</span>, over the <span class="math notranslate nohighlight">\(i = 1,\ldots,n\)</span> training data.</p>
<p><strong>Assumptions</strong></p>
<p>There are important assumption with our linear regression model,</p>
<ul class="simple">
<li><p><strong>Error-free</strong> - predictor variables are error free, not random variables</p></li>
<li><p><strong>Linearity</strong> - response is linear combination of feature(s)</p></li>
<li><p><strong>Constant Variance</strong> - error in response is constant over predictor(s) value</p></li>
<li><p><strong>Independence of Error</strong> - error in response are uncorrelated with each other</p></li>
<li><p><strong>No multicollinearity</strong> - none of the features are redundant with other features</p></li>
</ul>
</section>
<section id="predictor-feature-basis-expansion">
<h2>Predictor Feature / Basis Expansion</h2>
<p>We can improve model flexibility and complexity by applying basis expansion with basis functions applied to our predictor features. The fundamental idea is to utilize a suite of basis functions, <span class="math notranslate nohighlight">\(h_1, h_2, \ldots, h_k\)</span>, that provide new predictor features.</p>
<div class="math notranslate nohighlight">
\[
h(x_i) = (h_1(x_i),h_1(x_i),\ldots,h_k(x_i))
\]</div>
<p>where we from one feature <span class="math notranslate nohighlight">\(X\)</span> to an expanded basis of <span class="math notranslate nohighlight">\(k\)</span> features, <span class="math notranslate nohighlight">\(X_1, X_2,\ldots, X_k\)</span>.</p>
<ul class="simple">
<li><p>if we had <span class="math notranslate nohighlight">\(m\)</span> features in our data table, we now have <span class="math notranslate nohighlight">\(k \times m\)</span> features</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/3cf75cc4ca509f9dd86ecfb64061b7cf.png" style="display: block; margin: 0 auto; width: 90%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/basis_expansion.png"/>
  <figcaption style="text-align: center;">Basis expansion of predictor $m$ features with $k$ basis functions to $m \times k$ expanded features.</figcaption>
</figure>
</section>
<section id="id1">
<h2>Polynomial Regression</h2>
<p>It can be shown that polynomial regression is just linear regression applied to a polynomial expansion of the predictor features.</p>
<div class="math notranslate nohighlight">
\[
X_{j} \rightarrow X_{j}, X_{j}^2, X_{j}^3, \ldots X_{j}^k 
\]</div>
<p>where we have <span class="math notranslate nohighlight">\(j = 1, \ldots, m\)</span> original features.</p>
<p>We now have a expanded set of predictor features.</p>
<div class="math notranslate nohighlight">
\[
h_{j,k}(X_j) = X_j^k 
\]</div>
<p>were we have <span class="math notranslate nohighlight">\(j = 1, \ldots, m\)</span> original features and <span class="math notranslate nohighlight">\(k = 1, \ldots, K\)</span> polynomial orders.</p>
<p>We can now state our model as a linear regression of the transformed features.</p>
<div class="math notranslate nohighlight">
\[
y = f(x) = \sum_{j=1}^{m} \sum_{k = 1}^{K} \beta_{j,k} h_{j,m}(X_j) + \beta_0
\]</div>
<p>after the <span class="math notranslate nohighlight">\(h_l, l=1,\ldots,k\)</span> transforms, over the <span class="math notranslate nohighlight">\(j=1,\ldots,m\)</span> predictor features we have the same linear equation and the ability to utilize the previously discussed analytical solution, see the chapter on linear regression.</p>
<p>We are assuming linearity after application of our basis transforms.</p>
<ul class="simple">
<li><p>now the model coefficients, <span class="math notranslate nohighlight">\(\beta_{l,i}\)</span>, relate to a transformed version of the initial predictor feature, <span class="math notranslate nohighlight">\(h_l(X_i)\)</span>.</p></li>
<li><p>but we lose the ability to interpret the coefficients, e.g., what is <span class="math notranslate nohighlight">\(\phi^4\)</span> where <span class="math notranslate nohighlight">\(\phi\)</span> is porosity?</p></li>
</ul>
<p>For example, with a single predictor feature, <span class="math notranslate nohighlight">\(m = 1\)</span>, and up to a <span class="math notranslate nohighlight">\(4^{th}\)</span> order the model is,</p>
<div class="math notranslate nohighlight">
\[
y = \beta_{1,1}X_1 + \beta_{1,1}X_1^2 + \beta_{1,3}X_1^3 + \beta_{1,4}X_1^4 + \beta_0
\]</div>
<p>where the model parameter notation is <span class="math notranslate nohighlight">\(\beta_{m,k}\)</span>, were <span class="math notranslate nohighlight">\(m\)</span> is the feature and <span class="math notranslate nohighlight">\(k\)</span> is the order. To clarify here is the case for <span class="math notranslate nohighlight">\(m = 2\)</span>,</p>
<div class="math notranslate nohighlight">
\[
y = \beta_{1,1}X_1 + \beta_{1,2}X_1^2 + \beta_{1,3}X_1^3 + \beta_{1,4}X_1^4 + \beta_{2,1}X_2 + \beta_{2,2}X_2^2 + \beta_{2,3}X_2^3 + \beta_{2,4}X_2^4 + \beta_0
\]</div>
<p>So our predictive modeling workflow is:</p>
<ul class="simple">
<li><p>apply polynomial basis expansion</p></li>
<li><p>perform linear regression on the polynomial basis expansion</p></li>
</ul>
</section>
<section id="advantage-and-disadvantages-of-polynomial-regression">
<h2>Advantage and Disadvantages of Polynomial Regression</h2>
<p>The advantages of polynomial regression vs. linear regression, include,</p>
<ul class="simple">
<li><p>improved flexibility to fit nonlinear phenomenon, with linear analysis and an analytical solution to train the model parameters.</p></li>
</ul>
<p>Disadvantages</p>
<p>Generally, significantly higher model variance! May have unstable interpolation and especially extrapolation.</p>
<p>sensitivity to outliers, especially with <span class="math notranslate nohighlight">\(‚Ñé_ùëò \left(ùë•_{ùëñ,ùëó}\right)=ùë•_{ùëñ,ùëó}^ùëò\)</span> where <span class="math notranslate nohighlight">\(ùëò\)</span> is large</p>
<p>we lose model parameter interpretability, <span class="math notranslate nohighlight">\(ùõΩ_{ùëó,ùëò}\)</span> is related to <span class="math notranslate nohighlight">\(‚Ñé_ùëò \left(ùëã_j \right)\)</span>.</p>
</section>
<section id="adding-elementary-functions">
<h2>Adding Elementary Functions</h2>
<p>An alternative interpretation of polynomial regression is the construction of a regression model by adding elementary functions, i.e., the basis functions.</p>
<p>Let‚Äôs work with a single predictor feature and <span class="math notranslate nohighlight">\(K\)</span> basis expansion.</p>
<div class="math notranslate nohighlight">
\[ y = \sum_{l=1}^{k} \beta_{1,k} h_k (X_j) \]</div>
<p>For our simple, single predictor feature, <span class="math notranslate nohighlight">\(X\)</span>, polynomial problem this is,</p>
<div class="math notranslate nohighlight">
\[ y = \beta_{1,K} X^K + \beta_{1,K-1} X^{K-1} + \dots + \beta_{1,2} X^2 + \beta_{1,1} X + \beta_0 \]</div>
<p>Let‚Äôs work with a 4th order polynomial expansion, <span class="math notranslate nohighlight">\(K=4\)</span>, of standardized depth.</p>
<figure style="text-align: center;">
  <img src="../Images/ea64332d4805861caa74b4d26e6bd3f0.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/basis.png"/>
  <figcaption style="text-align: center;">Polynomial basis for up to \(K=4\).</figcaption>
</figure>
<p>To build our function we are moving, scaling and adding these elementary functions. Let‚Äôs review how we perform moving and scaling of an elementary function with the example of the <span class="math notranslate nohighlight">\(k=2\)</span> basis function, i.e., a parabola, <span class="math notranslate nohighlight">\(h_2: ùë¶=ùë•^2\)</span>. Consider the following changes:</p>
<ul class="simple">
<li><p>shifting on the X-axis</p></li>
<li><p>shifting on the Y-axis</p></li>
<li><p>flipping on the X-axis</p></li>
<li><p>changing the slope</p></li>
</ul>
<p>For each, I show a visualization of the change and then the impact on the polynomial equation.</p>
<ul class="simple">
<li><p>Shifting the function on the X-axis,</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/87df4ff1a6183394b90b31dfe989e9f7.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/shiftx.png"/>
  <figcaption style="text-align: center;">Shifting $2^{nd}$ order elementary function on the X-axis.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = (x - \Delta_x)^2 = x^2 - 2\Delta_x x + \Delta_x^2 \]</div>
<ul class="simple">
<li><p>Shifting the function on the Y-axis,</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/87df4ff1a6183394b90b31dfe989e9f7.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/shiftx.png"/>
  <figcaption style="text-align: center;">Shifting $2^{nd}$ order elementary function on the Y-axis.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = x^2 - \Delta_y \]</div>
<ul class="simple">
<li><p>flipping the function on the X-axis:</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/2e93ae27cb57ce4b016c4823c8e50642.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/flip.png"/>
  <figcaption style="text-align: center;">Flipping the $2^{nd}$ order elmentary function on the X-axis.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = \pm \beta_2 x^2 \]</div>
<ul class="simple">
<li><p>changing the slope:</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/63aa39b205aca7c3c08dd272484377e3.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/scale.png"/>
  <figcaption style="text-align: center;">Changing the slope of the $2^{nd}$ order elmentary function.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = \downarrow \beta_2 x^2, \text{wider / shallower} \]</div>
<div class="math notranslate nohighlight">
\[ y = \uparrow \beta_2 x^2, \text{narrower / deeper} \]</div>
<p>Let‚Äôs make some observations from above,</p>
<ul class="simple">
<li><p>shifting on the Y-axis only requires modification of the contant term of the model parameters in the polynomial equation</p></li>
<li><p>shifting on the X-axis requires modification of the lower order model parameters in the polynomial equation</p></li>
<li><p>flipping on the X-axis requires change in sign of the current order model parameter in the polynomial equation</p></li>
<li><p>increasing the slope requires increasing the current order model parameter in the polynomial equation</p></li>
</ul>
</section>
<section id="assumptions-of-polynomial-regression">
<h2>Assumptions of Polynomial Regression</h2>
<p>There are important assumption with our polynomial regression model, extended from the assumptions of linear regression above,</p>
<ul class="simple">
<li><p><strong>Error-free</strong> - predictor features basis expansions are error free, not random variables</p></li>
<li><p><strong>Constant Variance</strong> - error in response is constant over predictor(s) value</p></li>
<li><p><strong>Linearity</strong> - response is linear combination of basis features</p></li>
<li><p><strong>Polynomial</strong> - relationships between ùëã and Y is polynomial</p></li>
<li><p><strong>Independence of Error</strong> - error in response are uncorrelated with each other</p></li>
<li><p><strong>No Multicollinearity</strong> - none of the basis feature expansions are linearly redundant with other features</p></li>
</ul>
<p>Consider the polynomial basis expansion above, are the colinearities between our basis. To check, I calculated the correlation matrix for the basis expansion used in the demonstration below.</p>
<figure style="text-align: center;">
  <img src="../Images/08d2443894d5916687f1cf4785734bec.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/corr_matrix.png"/>
  <figcaption style="text-align: center;">Correlation matrix from a polynomial basis expansion with $K=4$.</figcaption>
</figure>
<p>There is strong collinearity between the <span class="math notranslate nohighlight">\(K=1\)</span> and <span class="math notranslate nohighlight">\(K=3\)</span> bases and the <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(k=4\)</span> bases.</p>
<ul class="simple">
<li><p>recall, collinearity and multicolinearity may increase model variance</p></li>
</ul>
<p>To remove this collinearity we can apply Hermite polynomials.</p>
</section>
<section id="hermite-polynomials">
<h2><strong>Hermite Polynomials</strong></h2>
<p>Is a family of orthogonal polynomials on the real number line.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Order</p></th>
<th class="head text-center"><p>Hermite Polynomial <span class="math notranslate nohighlight">\(H_e(x)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>0th Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_0}(x) = 1\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>1st Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_1}(x) = x\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>2nd Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_2}(x) = x^2 - 1\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>3rd Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_3}(x) = x^3 - 3x\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>4th Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_4}(x) = x^4 - 6x^2 + 3\)</span></p></td>
</tr>
</tbody>
</table>
<p>These polynomials are orthogonal with respect to a weighting function,</p>
<div class="math notranslate nohighlight">
\[
ùë§(ùë•)=ùëí^{‚àí\frac{ùë•^2}{2}}
\]</div>
<p>this is the standard Gaussian probability density function without the scaler, <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{2\pi}}\)</span>. The definition of orthogonality is stated as,</p>
<div class="math notranslate nohighlight">
\[ 
\int_{-\infty}^{\infty} H_m(x) H_n(x) w(x) \, dx = 0 
\]</div>
<p>The Hermite polynomials are orthogonal over the interval <span class="math notranslate nohighlight">\([‚àí\infty,\infty]\)</span> for the standard normal probability distribution.</p>
<p>By applying hermite polynomials instead of regular polynomials for polynomial basis expandion in polynomial regression were remove the multicolinearity between the predictor features,</p>
<ul class="simple">
<li><p>recall, independence of the predictor features is an assumption of the linear system applied in polynomial regression with the polynomial basis expansion</p></li>
</ul>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy</span>                                                  <span class="c1"># Hermite polynomials</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>                                       <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">pandas.plotting</span> <span class="k">as</span> <span class="nn">pd_plot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>             <span class="c1"># linear regression with scikit learn</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>          <span class="c1"># polynomial basis expansion</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="p">(</span><span class="n">StandardScaler</span><span class="p">,</span><span class="n">PolynomialFeatures</span><span class="p">)</span> <span class="c1"># standardize the features, polynomial basis expansion</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>           <span class="c1"># multi-processor K-fold crossvalidation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>          <span class="c1"># train and test split</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># supress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions</h2>
<p>Let‚Äôs define a convenience function to add gridlines to our plots and to plot correlation matrices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'RdBu_r'</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the Working Directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
</section>
<section id="loading-data">
<h2>Loading Data</h2>
<p>Let‚Äôs load the provided bivariate, spatial dataset <a class="reference external" href="https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/Density_Por_data.csv">Density_Por_data.csv</a> available in my GeoDataSet repo. It is a comma delimited file with:</p>
<ul class="simple">
<li><p>depth (m)</p></li>
<li><p>Gaussian transformed porosity (%)</p></li>
</ul>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a data frame we called ‚Äòdf‚Äô.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/1D_Porosity.csv"</span><span class="p">)</span> <span class="c1"># data from Dr. Pyrcz's github repository</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame</h2>
<p>Visualizing the train and test DataFrame is useful check before we build our models.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>                                                 <span class="c1"># preview the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Depth</th>
      <th>Nporosity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.25</td>
      <td>-1.37</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.50</td>
      <td>-2.08</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.75</td>
      <td>-1.67</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.00</td>
      <td>-1.16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.25</td>
      <td>-0.24</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.50</td>
      <td>-0.36</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.75</td>
      <td>0.44</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2.00</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2.25</td>
      <td>-0.02</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2.50</td>
      <td>-0.63</td>
    </tr>
    <tr>
      <th>10</th>
      <td>2.75</td>
      <td>-1.26</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3.00</td>
      <td>-1.03</td>
    </tr>
    <tr>
      <th>12</th>
      <td>3.25</td>
      <td>0.88</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="summary-statistics-for-tabular-data">
<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames.</p>
<ul class="simple">
<li><p>The describe command provides count, mean, standard deviation, percentiles, minimum, maximum in a nice data table.</p></li>
<li><p>I like to specify the percentiles, otherwise P25, P50 and P75 quartiles are the default</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                <span class="c1"># summary statistics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>10%</th>
      <th>50%</th>
      <th>90%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Depth</th>
      <td>40.0</td>
      <td>5.12500</td>
      <td>2.922613</td>
      <td>0.25</td>
      <td>1.225</td>
      <td>5.125</td>
      <td>9.025</td>
      <td>10.00</td>
    </tr>
    <tr>
      <th>Nporosity</th>
      <td>40.0</td>
      <td>0.02225</td>
      <td>0.992111</td>
      <td>-2.08</td>
      <td>-1.271</td>
      <td>0.140</td>
      <td>1.220</td>
      <td>2.35</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here we extract the Depth and Gaussian transformed porosity, Nporosity, from the DataFrame into separate 1D arrays called ‚Äòdepth‚Äô and ‚ÄòNPor‚Äô for readable code.</p>
<ul class="simple">
<li><p>warning, this is a shallow copy, if we change these 1D arrays, the change will be reflected back in the original DataFrame</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Depth'</span><span class="p">];</span> <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Nporosity'</span><span class="p">]</span>                      <span class="c1"># select the predictor and response feature</span>

<span class="n">Xlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Depth'</span><span class="p">];</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Gaussian Transformed Porosity'</span><span class="p">]</span> <span class="c1"># specify the feature labels for plotting</span>
<span class="n">Xunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'m'</span><span class="p">];</span> <span class="n">yunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'N[%]'</span><span class="p">]</span>
<span class="n">Xlabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>
<span class="n">ylabelunit</span> <span class="o">=</span> <span class="n">ylabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>                                              <span class="c1"># extract the 1D ndarrays from the DataFrame</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

<span class="n">Xmin</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="mf">10.0</span>                                       <span class="c1"># limits for plotting</span>
<span class="n">ymin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">3.0</span>

<span class="n">X_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>                         <span class="c1"># X intervals to visualize the model </span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="linear-regression-model">
<h2>Linear Regression Model</h2>
<p>Let‚Äôs first calculate the linear regression model with the LinearRegression class from scikit-learn. The steps include,</p>
<ol class="arabic simple">
<li><p><strong>instantiate</strong> - the linear regression object, note there are no hyperparameters to specify.</p></li>
<li><p><strong>fit</strong> - train the instantiated linear regression object with the training data</p></li>
<li><p><strong>predict</strong> - with the trained linear regression object</p></li>
</ol>
<p>Here‚Äôs the instantiation and fit steps for our linear regression model.</p>
<ul class="simple">
<li><p>note, we add the reshape to our predictor feature because scikit-learn assumes more than one predictor feature and expects a 2D array. We reshape our 1D ndarray to a 2D array with only 1 column.</p></li>
</ul>
<p>After we train the model we plot it with the data for visual model checking.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                      <span class="c1"># instantiate linear regression object, note no hyperparameters </span>
<span class="n">lin</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>                           <span class="c1"># train linear regression model</span>

<span class="n">slope</span> <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                                          <span class="c1"># get the model parameters</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the data and the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_values</span><span class="p">,</span><span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span><span class="o">*</span><span class="n">X_values</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Linear Regression Model, Regression of '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Linear Regression Model'</span><span class="p">,[</span><span class="mf">4.5</span><span class="p">,</span><span class="o">-</span><span class="mf">1.8</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">6.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">6.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_1 \times z + \beta_0$'</span><span class="p">,[</span><span class="mf">4.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times$ $z$ + ('</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,[</span><span class="mf">4.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/64b4519fff29b4b1c8eef0c0d94e3ceba809f3543abba1333ea33b4f4120ac4a.png" src="../Images/ba77774bef128a461422095cb22a2827.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/64b4519fff29b4b1c8eef0c0d94e3ceba809f3543abba1333ea33b4f4120ac4a.png"/>
</div>
</div>
</section>
<section id="comparison-to-a-nonparametric-predictive-machine-learning-model">
<h2>Comparison to a Nonparametric Predictive Machine Learning Model</h2>
<p>Let‚Äôs run a couple nonparametric predictive machine learning models to contrast with the linear and polynomial parametric models. First we train a quick decision tree model and then a random forest model.</p>
<ul class="simple">
<li><p>we gain significant flexibility to fit any patterns from the data</p></li>
<li><p>requires more inference as nonparametric is actually parameter rich!</p></li>
</ul>
<p>For more details, see the chapter on decision trees and random forest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>                                      <span class="c1"># tree program from scikit learn </span>

<span class="n">my_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="c1"># instantiate the decision tree model with hyperparameters</span>
<span class="n">my_tree</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="n">y</span><span class="p">)</span>              <span class="c1"># fit the decision tree to the training data (all the data in this case)</span>
<span class="n">DT_y</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                <span class="c1"># predict at high resolution over the range of depths</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the model and data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_values</span><span class="p">,</span> <span class="n">DT_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree Model, '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' as a Function of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b5e3bfa9d8d83005e43dd6add7fb70f36813fa375d987065f62bbdf04957cddb.png" src="../Images/8e31233c62876ecb3c64296751df5ef5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b5e3bfa9d8d83005e43dd6add7fb70f36813fa375d987065f62bbdf04957cddb.png"/>
</div>
</div>
<p>and here is a random forest model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>            <span class="c1"># random forest method</span>

<span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span>                                                 <span class="c1"># set the random forest hyperparameters</span>
<span class="n">num_tree</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">max_features</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">my_forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">num_tree</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="n">max_features</span><span class="p">)</span>
<span class="n">my_forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>  
<span class="n">RF_y</span> <span class="o">=</span> <span class="n">my_forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_values</span><span class="p">,</span> <span class="n">RF_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Random Forest Tree Model, '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' as a Function of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d5ecd12edcb40da8fada767537df53155d9f68f2ab79546bb129a6d93f2cc28e.png" src="../Images/704a35303eabbbf03215f2c0a311653d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/d5ecd12edcb40da8fada767537df53155d9f68f2ab79546bb129a6d93f2cc28e.png"/>
</div>
</div>
<p>Note, no effort was made to tune the hyperparameters for these models. I just wanted to demonstrate the great flexibility of a nonparametric model to learn the shape of the system from the data.</p>
<p>Now, we return to our parametric polynomial model.</p>
<ul class="simple">
<li><p>Let‚Äôs first transform our data to be standard normal, Gaussian.</p></li>
<li><p>We do this to improve the model fit (handle outliers) and to comply with theory for the Hermite polynomials that will be introduced shortly.</p></li>
</ul>
</section>
<section id="gaussian-anamorphosis-gaussian-transform">
<h2>Gaussian Anamorphosis \ Gaussian Transform</h2>
<p>Let‚Äôs transform the features to standard normal,</p>
<ul class="simple">
<li><p>Gaussian distribution</p></li>
<li><p>mean of 0.0</p></li>
<li><p>standard deviation of 1.0</p></li>
</ul>
<p>The porosity feature was ‚Äòtransformed‚Äô to Gaussian previously, but there is an opportunity to clean it up.</p>
<ul class="simple">
<li><p>compare the original and transformed below</p></li>
<li><p>note, I use my GeostatsPy Gaussian transform ported from the original GSLIB (Deutsch and Journel, 1997) because the scikit-learn Gaussian transform creates truncation spikes / outliers.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">geostatspy.geostats</span> <span class="k">as</span> <span class="nn">geostats</span>                        <span class="c1"># for Gaussian transform from GSLIB</span>

<span class="n">df_ns</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>   
<span class="n">df_ns</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">tvPor</span><span class="p">,</span> <span class="n">tnsPor</span> <span class="o">=</span> <span class="n">geostats</span><span class="o">.</span><span class="n">nscore</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># nscore transform for all facies porosity </span>
<span class="n">df_ns</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">tvdepth</span><span class="p">,</span> <span class="n">tnsdepth</span> <span class="o">=</span> <span class="n">geostats</span><span class="o">.</span><span class="n">nscore</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># nscore transform for all facies permeability</span>
<span class="n">X_ns</span> <span class="o">=</span> <span class="n">df_ns</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]];</span> <span class="n">y_ns</span> <span class="o">=</span> <span class="n">df_ns</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">X_ns_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>                      <span class="c1"># values to predict at in standard normal space               </span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs make some good cumulative distribution function plots to check the original and transformed variables.</p>
<ul class="simple">
<li><p>the results look very good</p></li>
</ul>
<p>We are doing this because we will need a Gaussian distribution for the predictor feature for orthogonality.  More later!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># plot original sand and shale porosity histograms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Original'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Original Depth'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_ns</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'NS'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Nscore '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                        <span class="c1"># plot nscore transformed sand and shale histograms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Original'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Original Porosity'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>                                        <span class="c1"># plot nscore transformed sand and shale histograms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_ns</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'NS'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Nscore '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/502106ad20a71cc9f6a412707dabe69539c7d2e42d6c72fa8b141c5695c13588.png" src="../Images/7b0e4b346e5f29d5e18e8d52b82145f1.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/502106ad20a71cc9f6a412707dabe69539c7d2e42d6c72fa8b141c5695c13588.png"/>
</div>
</div>
</section>
<section id="linear-regression-model-with-standardized-features">
<h2>Linear Regression Model with Standardized Features</h2>
<p>Let‚Äôs repeat the linear regression model, now with the standardized features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_ns</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                   <span class="c1"># instantiate linear regression object, note no hyperparameters </span>
<span class="n">lin_ns</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_ns</span><span class="p">)</span>                  <span class="c1"># train linear regression model</span>
<span class="n">slope_ns</span> <span class="o">=</span> <span class="n">lin_ns</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                                    <span class="c1"># get the model parameters</span>
<span class="n">intercept_ns</span> <span class="o">=</span> <span class="n">lin_ns</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the data and the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">intercept_ns</span> <span class="o">+</span> <span class="n">slope_ns</span><span class="o">*</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Linear Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Linear Regression Model'</span><span class="p">,[</span><span class="mf">0.8</span><span class="p">,</span><span class="o">-</span><span class="mf">1.8</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">1.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">1.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_1 \times z + \beta_0$'</span><span class="p">,[</span><span class="mf">0.5</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times$ $z$ + ('</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,[</span><span class="mf">0.5</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1966b7337c4a5b38596f989a8211aa0c1e8cfbab292369ed714bb5b7ebefb550.png" src="../Images/4c865fd8f2805646d61c8babce9fdbbd.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/1966b7337c4a5b38596f989a8211aa0c1e8cfbab292369ed714bb5b7ebefb550.png"/>
</div>
</div>
<p>Once again, not a good fit. Let‚Äôs use a more complex, flexible predictive machine learning model.</p>
</section>
<section id="id2">
<h2>Polynomial Regression</h2>
<p>We will do polynomial regression by hand:</p>
<ul class="simple">
<li><p>create the polynomial basis expansion of the original predictor feature</p></li>
<li><p>perform linear regression on the polynomial basis expansion</p></li>
</ul>
<section id="polynomial-basis-expansion">
<h3>Polynomial Basis Expansion</h3>
<p>Let‚Äôs start with calculating the polynomial basis expansion for the 1 predictor feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">poly4</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>                        <span class="c1"># instantiate polynomial expansion </span>
<span class="n">X_ns_poly4</span> <span class="o">=</span> <span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># calculate the basis expansion for our dataset</span>
<span class="n">df_X_ns_poly4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Values'</span><span class="p">:</span><span class="n">X_ns</span><span class="p">,</span><span class="s1">'0th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> 
                              <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_poly4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Values'</span><span class="p">:</span><span class="n">X_ns</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> 
                              <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>                                          <span class="c1"># preview the polynomial basis expansion with the original predictor feature</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Values</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-2.026808</td>
      <td>4.107951</td>
      <td>-8.326029</td>
      <td>16.875264</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-1.780464</td>
      <td>3.170053</td>
      <td>-5.644167</td>
      <td>10.049238</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-1.534121</td>
      <td>2.353526</td>
      <td>-3.610592</td>
      <td>5.539084</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-1.356312</td>
      <td>1.839582</td>
      <td>-2.495046</td>
      <td>3.384060</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-1.213340</td>
      <td>1.472193</td>
      <td>-1.786270</td>
      <td>2.167352</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let‚Äôs check the correlation between the polynomial basis expansion of the original predictor features data.</p>
<ul class="simple">
<li><p>Recall that a high degree of correlation between predictor features increases model variance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>                 <span class="c1"># calculate the correlation matrix</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Polynomial Expansion Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2f3f18b5d2988d034a420125ea0efceca61840db5af413c92d054ca206d52af6.png" src="../Images/9b9eee94daf8d4510c17a21728efa520.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/2f3f18b5d2988d034a420125ea0efceca61840db5af413c92d054ca206d52af6.png"/>
</div>
</div>
<p>We have high correlations between order 1 and 3 and order 2 and 4.</p>
<ul class="simple">
<li><p>Let‚Äôs check this with matrix scatter plot of the polynomial basis.</p></li>
</ul>
</section>
</section>
<section id="visualize-the-polynomial-expansion-features-pairwise-relationship">
<h2>Visualize the Polynomial Expansion Features‚Äô Pairwise Relationship</h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'1st'</span><span class="p">,</span><span class="s1">'2nd'</span><span class="p">,</span><span class="s1">'3rd'</span><span class="p">,</span><span class="s1">'4th'</span><span class="p">],</span><span class="n">markers</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">'reg'</span><span class="p">,</span><span class="n">diag_kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9f46b45339b77aeca8a91c3df0f6006093ccd5e8e509c9feb5231794e4797834.png" src="../Images/3ea96d491efa1ce020f1f121c4e5fc5c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/9f46b45339b77aeca8a91c3df0f6006093ccd5e8e509c9feb5231794e4797834.png"/>
</div>
</div>
<p>Let‚Äôs visualize the polynomial expansion over the Gaussian transformed depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the polynomial basis expansion</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'0th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'1th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'2th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">3</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'3th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">4</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'4th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'orange'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Polynomial Basis Expansion of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'h[ NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">') ]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/918e255b4a95601966627b5b6f5cd42f0edf824785db2cd3669e31d5f4519ed5.png" src="../Images/3f62f7e21b741e2cd86be2687d0f5fdb.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/918e255b4a95601966627b5b6f5cd42f0edf824785db2cd3669e31d5f4519ed5.png"/>
</div>
</div>
<p>We can also check the arithmetic average of each polynomial basis expansion.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'The averages of each basis expansion, 0 - 4th order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">X_ns_poly4</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>The averages of each basis expansion, 0 - 4th order = [1.         0.00536486 0.9458762  0.07336308 2.31077802].
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs fit the linear regression model to the polynomial basis expansion.</p>
<ul class="simple">
<li><p>note the model is quite flexible to fit this complicated / nonlinear data</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_poly4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                <span class="c1"># instantiate new linear model </span>
<span class="n">lin_poly4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_ns</span><span class="p">)</span>                 <span class="c1"># train linear model with polynomial expansion, polynomial regression</span>
<span class="n">b1</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span><span class="n">b3</span><span class="p">,</span><span class="n">b4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">lin_poly4</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>                     <span class="c1"># retrieve the model parameters</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">lin_poly4</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">lin_poly4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">:]),</span><span class="n">label</span><span class="o">=</span><span class="s1">'polynomial'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Polynomial Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">b4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">b3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8e8a2889184278abe92b133ef03f98039f95b3558223864483cc2bfb0461e2d1.png" src="../Images/8544dd539b8a7b35cc6999a54d0fecb5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8e8a2889184278abe92b133ef03f98039f95b3558223864483cc2bfb0461e2d1.png"/>
</div>
</div>
</section>
<section id="regression-with-hermite-basis-expansion">
<h2>Regression with Hermite Basis Expansion</h2>
<p>We can use Hermite polynomials to reduce the correlation between the basis predictor features.</p>
<ul class="simple">
<li><p>We transform the predictor feature, depth, to standard normal since the Hermite polynomial expansion approach independence over the range of negative infinity to positive infinity under the assumption of standard normal probability density function.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">orders4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>                                           <span class="c1"># specify the orders for Hermite basis expansion</span>
<span class="n">X_ns_hermite4</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermitenorm</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># Hermite polynomials for X </span>
<span class="n">df_X_ns_hermite4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'value'</span><span class="p">:</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> 
                                     <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>value</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-2.026808</td>
      <td>3.107951</td>
      <td>-2.245605</td>
      <td>-4.772444</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-1.780464</td>
      <td>2.170053</td>
      <td>-0.302774</td>
      <td>-5.971082</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-1.534121</td>
      <td>1.353526</td>
      <td>0.991769</td>
      <td>-5.582071</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-1.356312</td>
      <td>0.839582</td>
      <td>1.573889</td>
      <td>-4.653429</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-1.213340</td>
      <td>0.472193</td>
      <td>1.853749</td>
      <td>-3.665806</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note: I have omitted orders that had a higher degree of correlation for our dataset.</p>
<p>Let‚Äôs check the correlation between the Hermite predictor features. There is improvement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">hermite_corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>      <span class="c1"># calculate correlation matrix of Hermite basis expansion of X</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">hermite_corr_matrix</span><span class="p">,</span><span class="s1">'Hermite Polynomial Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/767654dc38789e23879b6040b9c52283c5c21eb95f0671e3d0470ab4b3b8c71f.png" src="../Images/f1b9e3f1eac053a1460fbb16b9d3ab5e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/767654dc38789e23879b6040b9c52283c5c21eb95f0671e3d0470ab4b3b8c71f.png"/>
</div>
</div>
<p>The pairwise linear correlation is quite low compared to the polynomial basis.</p>
<p>Let‚Äôs visualize the bivariate relationships between our Hermite basis orders.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'1st'</span><span class="p">,</span><span class="s1">'2nd'</span><span class="p">,</span><span class="s1">'3rd'</span><span class="p">,</span><span class="s1">'4th'</span><span class="p">],</span><span class="n">markers</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">'reg'</span><span class="p">,</span><span class="n">diag_kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/695a6474c0e6f88800c5be51a4e1437b374986904af57e9dfff07a1184f65977.png" src="../Images/9fd622d54d360b533c8ba76f2bd6a2b6.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/695a6474c0e6f88800c5be51a4e1437b374986904af57e9dfff07a1184f65977.png"/>
</div>
</div>
<p>We can check the arithmetic averages of all the Hermite basis expansions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'The means of each basis expansion, 1 - 4th order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">X_ns_hermite4</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>The means of each basis expansion, 1 - 4th order = [ 0.00536486 -0.0541238   0.05726848 -0.36447919].
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs visualize Hermite polynomials over the range of the standardized depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot Hermite polynomials</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'1st'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'2nd'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'3rd'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">3</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'4th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'orange'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Hermite Polynomial Basis Expansion of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'h[ NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">') ]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f32be19da954ac4bb5bdc7d502a565b9c8e6c3c007728bd33276d37d1eaf6259.png" src="../Images/4014172673585ba0353f9f413f88bd94.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/f32be19da954ac4bb5bdc7d502a565b9c8e6c3c007728bd33276d37d1eaf6259.png"/>
</div>
</div>
<p>Now let‚Äôs fit our Hermite basis regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_herm4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                <span class="c1"># instantiate model</span>
<span class="n">lin_herm4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_ns</span><span class="p">)</span>              <span class="c1"># fit Hermite polynomials </span>
<span class="n">hb1</span><span class="p">,</span><span class="n">hb2</span><span class="p">,</span><span class="n">hb3</span><span class="p">,</span><span class="n">hb4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">lin_herm4</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>                 <span class="c1"># retrieve the model parameters</span>
<span class="n">hb0</span> <span class="o">=</span> <span class="n">lin_herm4</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot data and model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">lin_herm4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermitenorm</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)),</span> 
         <span class="n">label</span><span class="o">=</span><span class="s1">'4th order'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Hermite Polynomial Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hermite Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hb4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hb3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hb2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">hb1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5b4926cdbd311bf1b5374a042995789082def9fd00376dc30620f948c00f669d.png" src="../Images/f42cc4ffefcd978188c7348b3d653b8b.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/5b4926cdbd311bf1b5374a042995789082def9fd00376dc30620f948c00f669d.png"/>
</div>
</div>
<p>Since we have less correlation between the expanded basis features we can check out the model coefficients and interpret the unique importance of each order.</p>
</section>
<section id="orthogonal-polynomials">
<h2>Orthogonal Polynomials</h2>
<p>Let‚Äôs try the orthogonal polynomial basis expansion reimplemented in Python by Dave Moore from the poly() function in R.</p>
<ul class="simple">
<li><p>the functions below for fit and predict are directly from Dave‚Äôs <a class="reference external" href="http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly">blog</a></p></li>
<li><p>note during the fit to the training data the norm2 and alpha model parameters are calcluated</p></li>
<li><p>these parameters must be passed to each subsequent predict to ensure the results are consistent</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1"># functions taken (without modification) from http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly</span>
<span class="c1"># appreciation to Dave Moore for the great blog post on titled 'Orthogonal polynomial regression in Python'</span>
<span class="c1"># functions are Dave's reimplementation of poly() from R</span>

<span class="k">def</span> <span class="nf">ortho_poly_fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span><span class="p">(</span><span class="n">degree</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">))):</span>
            <span class="n">stop</span><span class="p">(</span><span class="s2">"'degree' must be less than number of unique points"</span><span class="p">)</span>
    <span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">xbar</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">q</span><span class="p">,</span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

    <span class="n">norm2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">raw</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">raw</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="n">norm2</span> <span class="o">+</span> <span class="n">xbar</span><span class="p">)[:</span><span class="n">degree</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">raw</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">alpha</span>

<span class="k">def</span> <span class="nf">ortho_poly_predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">Z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">Z</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">degree</span><span class="p">):</span>
             <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">norm2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">norm2</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Z</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs give it a try and perform orthogonal polynomial expansion of our standard normal transformed depth</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_ns_ortho4</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">ortho_poly_fit</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># orthogonal polynomial expansion</span>
<span class="n">df_X_ns_ortho4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'value'</span><span class="p">:</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span>
                               <span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span>       <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>value</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-0.330385</td>
      <td>0.440404</td>
      <td>-0.460160</td>
      <td>0.420374</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-0.290335</td>
      <td>0.313201</td>
      <td>-0.207862</td>
      <td>0.021278</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-0.250285</td>
      <td>0.202153</td>
      <td>-0.029761</td>
      <td>-0.172968</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-0.221377</td>
      <td>0.132038</td>
      <td>0.058235</td>
      <td>-0.220834</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-0.198133</td>
      <td>0.081765</td>
      <td>0.107183</td>
      <td>-0.219084</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let‚Äôs check the correlation between the orthogonal polynomial predictor features. I‚Äôm impressed! The between basis feature order correlations are all zero!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">ortho_corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>          <span class="c1"># calculate the correlation matrix</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">ortho_corr_matrix</span><span class="p">,</span><span class="s1">'Orthogonal Polynomial Expansion Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/51874452bf180e62d5f0824897a2b248a5e40bd802ff4ba4fefefda0c75d9c65.png" src="../Images/5c444109d15f6a2e24d2be84d8941629.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/51874452bf180e62d5f0824897a2b248a5e40bd802ff4ba4fefefda0c75d9c65.png"/>
</div>
</div>
<p>Let‚Äôs visualize the bivariate relationships between our orthogonal polynomial basis orders.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'1st'</span><span class="p">,</span><span class="s1">'2nd'</span><span class="p">,</span><span class="s1">'3rd'</span><span class="p">,</span><span class="s1">'4th'</span><span class="p">],</span><span class="n">markers</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">kind</span><span class="o">=</span><span class="s1">'reg'</span><span class="p">,</span><span class="n">diag_kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>&lt;seaborn.axisgrid.PairGrid at 0x1ed608d8370&gt;
</pre></div>
</div>
<img alt="_images/ad56938294bca2fddf0cb90bd5afb4aa9c16bdec043fae497f76527072c2698b.png" src="../Images/5a2f9488237446e128cc99a668c78ad7.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/ad56938294bca2fddf0cb90bd5afb4aa9c16bdec043fae497f76527072c2698b.png"/>
</div>
</div>
<p>Let‚Äôs visualize orthogonal polynomial basis orders over the range of the standardized depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">ortho_poly_ns_values</span> <span class="o">=</span> <span class="n">ortho_poly_predict</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'0th'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'1st'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'2nd'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'3rd'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'4th'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'orange'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Basis Expansion of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'h[ NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">') ]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fb2ab3f98848b762f738beb5133cf2b9963dbab254ba2882a5a5265e218ba8ce.png" src="../Images/74a68b06994a2941d62a1c4da558780c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/fb2ab3f98848b762f738beb5133cf2b9963dbab254ba2882a5a5265e218ba8ce.png"/>
</div>
</div>
<p>Finally let‚Äôs fit our orthogonal polynomial basis expansion regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_ortho4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                               <span class="c1"># instantiate model</span>
<span class="n">lin_ortho4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_ns</span><span class="p">)</span>               <span class="c1"># fit Hermite polynomials </span>
<span class="n">ob1</span><span class="p">,</span><span class="n">ob2</span><span class="p">,</span><span class="n">ob3</span><span class="p">,</span><span class="n">ob4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">lin_ortho4</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>                <span class="c1"># retrieve the model parameters</span>
<span class="n">ob0</span> <span class="o">=</span> <span class="n">lin_ortho4</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">lin_ortho4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]),</span><span class="n">label</span><span class="o">=</span><span class="s1">'orthogonal polynomial'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ob4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ob3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ob2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">ob1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b9adcfb2f480cc56becaad7a7b7d097564da38381dbf860303502572e5eab039.png" src="../Images/2a189618f9055efc6488a7eb46c5c41d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b9adcfb2f480cc56becaad7a7b7d097564da38381dbf860303502572e5eab039.png"/>
</div>
</div>
</section>
<section id="polynomial-regression-in-scikit-learn-with-pipelines">
<h2>Polynomial Regression in scikit-learn with Pipelines</h2>
<p>The need to first perform basis expansion and then train the resulting (after basis transformations) linear model may seem a bit complicated.</p>
<ul class="simple">
<li><p>one solution is to use the Pipeline object from scikit-learn. Here are some highlights on Pipelines.</p></li>
</ul>
<p>Machine learning workflows can be complicated, with various steps:</p>
<ul class="simple">
<li><p>data preparation, feature engineering transformations</p></li>
<li><p>model parameter fitting</p></li>
<li><p>model hyperparameter tuning</p></li>
<li><p>modeling method selection</p></li>
<li><p>searching over a large combinatorial of hyperparameters</p></li>
<li><p>training and testing model runs</p></li>
</ul>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to find the best model (AutoML)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">order</span><span class="o">=</span><span class="mi">4</span>                                                       <span class="c1"># set the polynomial order</span>

<span class="n">polyreg_pipe</span><span class="o">=</span><span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">order</span><span class="p">),</span><span class="n">LinearRegression</span><span class="p">())</span> <span class="c1"># make the modeling pipeline</span>
<span class="n">polyreg_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_ns</span><span class="p">)</span>            <span class="c1"># fit the model to the data</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">polyreg_pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>      <span class="c1"># predict with the modeling pipeline</span>
<span class="n">poly_reg_model</span> <span class="o">=</span> <span class="n">polyreg_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">'linearregression'</span><span class="p">]</span> <span class="c1"># retrieve the model from the pipeline</span>
<span class="n">pb0a</span><span class="p">,</span><span class="n">pb1</span><span class="p">,</span><span class="n">pb2</span><span class="p">,</span><span class="n">pb3</span><span class="p">,</span><span class="n">pb4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">poly_reg_model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>       <span class="c1"># retrieve the model parameters</span>
<span class="n">pb0b</span> <span class="o">=</span> <span class="n">poly_reg_model</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">pb0</span> <span class="o">=</span> <span class="n">pb0a</span> <span class="o">+</span> <span class="n">pb0b</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the data and model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'4th order'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">'$^</span><span class="si">{th}</span><span class="s1">$ Polynomial Regression Model with Pipelines, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pb4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pb3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pb2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">pb1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c8e565b643fa879eb74f2d3c49419386b5073f8c2dce53cd9dd9142465f16ee.png" src="../Images/e0ba7ea47dd6042f5976cb230740cb93.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4c8e565b643fa879eb74f2d3c49419386b5073f8c2dce53cd9dd9142465f16ee.png"/>
</div>
</div>
</section>
<section id="comments">
<h2>Comments</h2>
<p>This was a basic treatment of polynomial regression. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
</section>
&#13;

<h2>Motivations for Polynomial Regression</h2>
<p>By moving from linear regression to polynomial regression we,</p>
<ul class="simple">
<li><p>add prediction flexibility by modeling non-linearity in our data</p></li>
<li><p>build on the feature engineering concept of feature expansion</p></li>
</ul>
<p>while benefiting from the analytical solutions for training model parameters like linear regression.</p>
<p>We accomplish all of this with basis expansion,</p>
<ul class="simple">
<li><p>we transform and expand the features <span class="math notranslate nohighlight">\(\rightarrow\)</span> introduce basis expansion!</p></li>
<li><p>we can increase our predictive model complexity and flexibility <span class="math notranslate nohighlight">\(\rightarrow\)</span> nonlinear basis!</p></li>
<li><p>we can improve the model robustness by removing multicollinearity <span class="math notranslate nohighlight">\(\rightarrow\)</span> orthogonal basis!</p></li>
</ul>
<p>Let‚Äôs start with linear regression and then build to polynomial regression.</p>
&#13;

<h2>Linear Regression</h2>
<p>Linear regression for prediction, let‚Äôs start by looking at a linear model fit to a set of data.</p>
<figure style="text-align: center;">
  <img src="../Images/806bf5f702f9bb5a63e30d6e1f7969d9.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/linear/linear_example.png"/>
  <figcaption style="text-align: center;">Example linear regression model.</figcaption>
</figure>
<p>Let‚Äôs start by defining some terms,</p>
<ul class="simple">
<li><p><strong>predictor feature</strong> - an input feature for the prediction model, given we are only discussing linear regression and not multilinear regression we have only one predictor feature, <span class="math notranslate nohighlight">\(x\)</span>. On out plots (including above) the predictor feature is on the x-axis.</p></li>
<li><p><strong>response feature</strong> - the output feature for the prediction model, in this case, <span class="math notranslate nohighlight">\(y\)</span>. On our plots (including above) the response feature is on the y-axis.</p></li>
</ul>
<p>Now, here are some key aspects of linear regression:</p>
<p><strong>Parametric Model</strong></p>
<p>This is a parametric predictive machine learning model, we accept an a prior assumption of linearity and then gain a very low parametric representation that is easy to train without a onerous amount of data.</p>
<ul class="simple">
<li><p>the fit model is a simple weighted linear additive model based on all the available features, <span class="math notranslate nohighlight">\(x_1,\ldots,x_m\)</span>.</p></li>
<li><p>the parametric model takes the form of:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
y = \sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0
\]</div>
<p>Here‚Äôs the visualization of the linear model parameters,</p>
<figure style="text-align: center;">
  <img src="../Images/ada2fcc2740c48478e79404563c91061.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/linear/linear_model.png"/>
  <figcaption style="text-align: center;">The linear model parameters.</figcaption>
</figure>
<p><strong>Least Squares</strong></p>
<p>The analytical solution for the model parameters, <span class="math notranslate nohighlight">\(b_1,\ldots,b_m,b_0\)</span>, is available for the L2 norm loss function, the errors are summed and squared known a least squares.</p>
<ul class="simple">
<li><p>we minimize the error, residual sum of squares (RSS) over the training data:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
RSS = \sum_{i=1}^n \left(y_i - (\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha,i} + b_0) \right)^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the actual response feature values and <span class="math notranslate nohighlight">\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\)</span> are the model predictions, over the <span class="math notranslate nohighlight">\(\alpha = 1,\ldots,n\)</span> training data.</p>
<p>Here‚Äôs a visualization of the L2 norm loss function, MSE,</p>
<figure style="text-align: center;">
  <img src="../Images/835541b16e1038a4606f7d97b628c4f9.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/linear/linear_MSE.png"/>
  <figcaption style="text-align: center;">The linear model loss function, mean square error.</figcaption>
</figure>
<ul class="simple">
<li><p>this may be simplified as the sum of square error over the training data,</p></li>
</ul>
<p>\begin{equation}
\sum_{i=1}^n (\Delta y_i)^2
\end{equation}</p>
<p>where <span class="math notranslate nohighlight">\(\Delta y_i\)</span> is actual response feature observation <span class="math notranslate nohighlight">\(y_i\)</span> minus the model prediction <span class="math notranslate nohighlight">\(\sum_{\alpha = 1}^m b_{\alpha} x_{\alpha} + b_0\)</span>, over the <span class="math notranslate nohighlight">\(i = 1,\ldots,n\)</span> training data.</p>
<p><strong>Assumptions</strong></p>
<p>There are important assumption with our linear regression model,</p>
<ul class="simple">
<li><p><strong>Error-free</strong> - predictor variables are error free, not random variables</p></li>
<li><p><strong>Linearity</strong> - response is linear combination of feature(s)</p></li>
<li><p><strong>Constant Variance</strong> - error in response is constant over predictor(s) value</p></li>
<li><p><strong>Independence of Error</strong> - error in response are uncorrelated with each other</p></li>
<li><p><strong>No multicollinearity</strong> - none of the features are redundant with other features</p></li>
</ul>
&#13;

<h2>Predictor Feature / Basis Expansion</h2>
<p>We can improve model flexibility and complexity by applying basis expansion with basis functions applied to our predictor features. The fundamental idea is to utilize a suite of basis functions, <span class="math notranslate nohighlight">\(h_1, h_2, \ldots, h_k\)</span>, that provide new predictor features.</p>
<div class="math notranslate nohighlight">
\[
h(x_i) = (h_1(x_i),h_1(x_i),\ldots,h_k(x_i))
\]</div>
<p>where we from one feature <span class="math notranslate nohighlight">\(X\)</span> to an expanded basis of <span class="math notranslate nohighlight">\(k\)</span> features, <span class="math notranslate nohighlight">\(X_1, X_2,\ldots, X_k\)</span>.</p>
<ul class="simple">
<li><p>if we had <span class="math notranslate nohighlight">\(m\)</span> features in our data table, we now have <span class="math notranslate nohighlight">\(k \times m\)</span> features</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/3cf75cc4ca509f9dd86ecfb64061b7cf.png" style="display: block; margin: 0 auto; width: 90%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/basis_expansion.png"/>
  <figcaption style="text-align: center;">Basis expansion of predictor $m$ features with $k$ basis functions to $m \times k$ expanded features.</figcaption>
</figure>
&#13;

<h2>Polynomial Regression</h2>
<p>It can be shown that polynomial regression is just linear regression applied to a polynomial expansion of the predictor features.</p>
<div class="math notranslate nohighlight">
\[
X_{j} \rightarrow X_{j}, X_{j}^2, X_{j}^3, \ldots X_{j}^k 
\]</div>
<p>where we have <span class="math notranslate nohighlight">\(j = 1, \ldots, m\)</span> original features.</p>
<p>We now have a expanded set of predictor features.</p>
<div class="math notranslate nohighlight">
\[
h_{j,k}(X_j) = X_j^k 
\]</div>
<p>were we have <span class="math notranslate nohighlight">\(j = 1, \ldots, m\)</span> original features and <span class="math notranslate nohighlight">\(k = 1, \ldots, K\)</span> polynomial orders.</p>
<p>We can now state our model as a linear regression of the transformed features.</p>
<div class="math notranslate nohighlight">
\[
y = f(x) = \sum_{j=1}^{m} \sum_{k = 1}^{K} \beta_{j,k} h_{j,m}(X_j) + \beta_0
\]</div>
<p>after the <span class="math notranslate nohighlight">\(h_l, l=1,\ldots,k\)</span> transforms, over the <span class="math notranslate nohighlight">\(j=1,\ldots,m\)</span> predictor features we have the same linear equation and the ability to utilize the previously discussed analytical solution, see the chapter on linear regression.</p>
<p>We are assuming linearity after application of our basis transforms.</p>
<ul class="simple">
<li><p>now the model coefficients, <span class="math notranslate nohighlight">\(\beta_{l,i}\)</span>, relate to a transformed version of the initial predictor feature, <span class="math notranslate nohighlight">\(h_l(X_i)\)</span>.</p></li>
<li><p>but we lose the ability to interpret the coefficients, e.g., what is <span class="math notranslate nohighlight">\(\phi^4\)</span> where <span class="math notranslate nohighlight">\(\phi\)</span> is porosity?</p></li>
</ul>
<p>For example, with a single predictor feature, <span class="math notranslate nohighlight">\(m = 1\)</span>, and up to a <span class="math notranslate nohighlight">\(4^{th}\)</span> order the model is,</p>
<div class="math notranslate nohighlight">
\[
y = \beta_{1,1}X_1 + \beta_{1,1}X_1^2 + \beta_{1,3}X_1^3 + \beta_{1,4}X_1^4 + \beta_0
\]</div>
<p>where the model parameter notation is <span class="math notranslate nohighlight">\(\beta_{m,k}\)</span>, were <span class="math notranslate nohighlight">\(m\)</span> is the feature and <span class="math notranslate nohighlight">\(k\)</span> is the order. To clarify here is the case for <span class="math notranslate nohighlight">\(m = 2\)</span>,</p>
<div class="math notranslate nohighlight">
\[
y = \beta_{1,1}X_1 + \beta_{1,2}X_1^2 + \beta_{1,3}X_1^3 + \beta_{1,4}X_1^4 + \beta_{2,1}X_2 + \beta_{2,2}X_2^2 + \beta_{2,3}X_2^3 + \beta_{2,4}X_2^4 + \beta_0
\]</div>
<p>So our predictive modeling workflow is:</p>
<ul class="simple">
<li><p>apply polynomial basis expansion</p></li>
<li><p>perform linear regression on the polynomial basis expansion</p></li>
</ul>
&#13;

<h2>Advantage and Disadvantages of Polynomial Regression</h2>
<p>The advantages of polynomial regression vs. linear regression, include,</p>
<ul class="simple">
<li><p>improved flexibility to fit nonlinear phenomenon, with linear analysis and an analytical solution to train the model parameters.</p></li>
</ul>
<p>Disadvantages</p>
<p>Generally, significantly higher model variance! May have unstable interpolation and especially extrapolation.</p>
<p>sensitivity to outliers, especially with <span class="math notranslate nohighlight">\(‚Ñé_ùëò \left(ùë•_{ùëñ,ùëó}\right)=ùë•_{ùëñ,ùëó}^ùëò\)</span> where <span class="math notranslate nohighlight">\(ùëò\)</span> is large</p>
<p>we lose model parameter interpretability, <span class="math notranslate nohighlight">\(ùõΩ_{ùëó,ùëò}\)</span> is related to <span class="math notranslate nohighlight">\(‚Ñé_ùëò \left(ùëã_j \right)\)</span>.</p>
&#13;

<h2>Adding Elementary Functions</h2>
<p>An alternative interpretation of polynomial regression is the construction of a regression model by adding elementary functions, i.e., the basis functions.</p>
<p>Let‚Äôs work with a single predictor feature and <span class="math notranslate nohighlight">\(K\)</span> basis expansion.</p>
<div class="math notranslate nohighlight">
\[ y = \sum_{l=1}^{k} \beta_{1,k} h_k (X_j) \]</div>
<p>For our simple, single predictor feature, <span class="math notranslate nohighlight">\(X\)</span>, polynomial problem this is,</p>
<div class="math notranslate nohighlight">
\[ y = \beta_{1,K} X^K + \beta_{1,K-1} X^{K-1} + \dots + \beta_{1,2} X^2 + \beta_{1,1} X + \beta_0 \]</div>
<p>Let‚Äôs work with a 4th order polynomial expansion, <span class="math notranslate nohighlight">\(K=4\)</span>, of standardized depth.</p>
<figure style="text-align: center;">
  <img src="../Images/ea64332d4805861caa74b4d26e6bd3f0.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/basis.png"/>
  <figcaption style="text-align: center;">Polynomial basis for up to \(K=4\).</figcaption>
</figure>
<p>To build our function we are moving, scaling and adding these elementary functions. Let‚Äôs review how we perform moving and scaling of an elementary function with the example of the <span class="math notranslate nohighlight">\(k=2\)</span> basis function, i.e., a parabola, <span class="math notranslate nohighlight">\(h_2: ùë¶=ùë•^2\)</span>. Consider the following changes:</p>
<ul class="simple">
<li><p>shifting on the X-axis</p></li>
<li><p>shifting on the Y-axis</p></li>
<li><p>flipping on the X-axis</p></li>
<li><p>changing the slope</p></li>
</ul>
<p>For each, I show a visualization of the change and then the impact on the polynomial equation.</p>
<ul class="simple">
<li><p>Shifting the function on the X-axis,</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/87df4ff1a6183394b90b31dfe989e9f7.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/shiftx.png"/>
  <figcaption style="text-align: center;">Shifting $2^{nd}$ order elementary function on the X-axis.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = (x - \Delta_x)^2 = x^2 - 2\Delta_x x + \Delta_x^2 \]</div>
<ul class="simple">
<li><p>Shifting the function on the Y-axis,</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/87df4ff1a6183394b90b31dfe989e9f7.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/shiftx.png"/>
  <figcaption style="text-align: center;">Shifting $2^{nd}$ order elementary function on the Y-axis.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = x^2 - \Delta_y \]</div>
<ul class="simple">
<li><p>flipping the function on the X-axis:</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/2e93ae27cb57ce4b016c4823c8e50642.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/flip.png"/>
  <figcaption style="text-align: center;">Flipping the $2^{nd}$ order elmentary function on the X-axis.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = \pm \beta_2 x^2 \]</div>
<ul class="simple">
<li><p>changing the slope:</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/63aa39b205aca7c3c08dd272484377e3.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/scale.png"/>
  <figcaption style="text-align: center;">Changing the slope of the $2^{nd}$ order elmentary function.</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[ y = \downarrow \beta_2 x^2, \text{wider / shallower} \]</div>
<div class="math notranslate nohighlight">
\[ y = \uparrow \beta_2 x^2, \text{narrower / deeper} \]</div>
<p>Let‚Äôs make some observations from above,</p>
<ul class="simple">
<li><p>shifting on the Y-axis only requires modification of the contant term of the model parameters in the polynomial equation</p></li>
<li><p>shifting on the X-axis requires modification of the lower order model parameters in the polynomial equation</p></li>
<li><p>flipping on the X-axis requires change in sign of the current order model parameter in the polynomial equation</p></li>
<li><p>increasing the slope requires increasing the current order model parameter in the polynomial equation</p></li>
</ul>
&#13;

<h2>Assumptions of Polynomial Regression</h2>
<p>There are important assumption with our polynomial regression model, extended from the assumptions of linear regression above,</p>
<ul class="simple">
<li><p><strong>Error-free</strong> - predictor features basis expansions are error free, not random variables</p></li>
<li><p><strong>Constant Variance</strong> - error in response is constant over predictor(s) value</p></li>
<li><p><strong>Linearity</strong> - response is linear combination of basis features</p></li>
<li><p><strong>Polynomial</strong> - relationships between ùëã and Y is polynomial</p></li>
<li><p><strong>Independence of Error</strong> - error in response are uncorrelated with each other</p></li>
<li><p><strong>No Multicollinearity</strong> - none of the basis feature expansions are linearly redundant with other features</p></li>
</ul>
<p>Consider the polynomial basis expansion above, are the colinearities between our basis. To check, I calculated the correlation matrix for the basis expansion used in the demonstration below.</p>
<figure style="text-align: center;">
  <img src="../Images/08d2443894d5916687f1cf4785734bec.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/polynomial/corr_matrix.png"/>
  <figcaption style="text-align: center;">Correlation matrix from a polynomial basis expansion with $K=4$.</figcaption>
</figure>
<p>There is strong collinearity between the <span class="math notranslate nohighlight">\(K=1\)</span> and <span class="math notranslate nohighlight">\(K=3\)</span> bases and the <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(k=4\)</span> bases.</p>
<ul class="simple">
<li><p>recall, collinearity and multicolinearity may increase model variance</p></li>
</ul>
<p>To remove this collinearity we can apply Hermite polynomials.</p>
&#13;

<h2><strong>Hermite Polynomials</strong></h2>
<p>Is a family of orthogonal polynomials on the real number line.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Order</p></th>
<th class="head text-center"><p>Hermite Polynomial <span class="math notranslate nohighlight">\(H_e(x)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>0th Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_0}(x) = 1\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>1st Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_1}(x) = x\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>2nd Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_2}(x) = x^2 - 1\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>3rd Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_3}(x) = x^3 - 3x\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>4th Order</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(H_{e_4}(x) = x^4 - 6x^2 + 3\)</span></p></td>
</tr>
</tbody>
</table>
<p>These polynomials are orthogonal with respect to a weighting function,</p>
<div class="math notranslate nohighlight">
\[
ùë§(ùë•)=ùëí^{‚àí\frac{ùë•^2}{2}}
\]</div>
<p>this is the standard Gaussian probability density function without the scaler, <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{2\pi}}\)</span>. The definition of orthogonality is stated as,</p>
<div class="math notranslate nohighlight">
\[ 
\int_{-\infty}^{\infty} H_m(x) H_n(x) w(x) \, dx = 0 
\]</div>
<p>The Hermite polynomials are orthogonal over the interval <span class="math notranslate nohighlight">\([‚àí\infty,\infty]\)</span> for the standard normal probability distribution.</p>
<p>By applying hermite polynomials instead of regular polynomials for polynomial basis expandion in polynomial regression were remove the multicolinearity between the predictor features,</p>
<ul class="simple">
<li><p>recall, independence of the predictor features is an assumption of the linear system applied in polynomial regression with the polynomial basis expansion</p></li>
</ul>
&#13;

<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy</span>                                                  <span class="c1"># Hermite polynomials</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>                                       <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">pandas.plotting</span> <span class="k">as</span> <span class="nn">pd_plot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>             <span class="c1"># linear regression with scikit learn</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>          <span class="c1"># polynomial basis expansion</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="p">(</span><span class="n">StandardScaler</span><span class="p">,</span><span class="n">PolynomialFeatures</span><span class="p">)</span> <span class="c1"># standardize the features, polynomial basis expansion</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>           <span class="c1"># multi-processor K-fold crossvalidation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>          <span class="c1"># train and test split</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># supress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
&#13;

<h2>Declare Functions</h2>
<p>Let‚Äôs define a convenience function to add gridlines to our plots and to plot correlation matrices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'RdBu_r'</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Set the Working Directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
&#13;

<h2>Loading Data</h2>
<p>Let‚Äôs load the provided bivariate, spatial dataset <a class="reference external" href="https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/Density_Por_data.csv">Density_Por_data.csv</a> available in my GeoDataSet repo. It is a comma delimited file with:</p>
<ul class="simple">
<li><p>depth (m)</p></li>
<li><p>Gaussian transformed porosity (%)</p></li>
</ul>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a data frame we called ‚Äòdf‚Äô.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">r</span><span class="s2">"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/1D_Porosity.csv"</span><span class="p">)</span> <span class="c1"># data from Dr. Pyrcz's github repository</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Visualize the DataFrame</h2>
<p>Visualizing the train and test DataFrame is useful check before we build our models.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>                                                 <span class="c1"># preview the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Depth</th>
      <th>Nporosity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.25</td>
      <td>-1.37</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.50</td>
      <td>-2.08</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.75</td>
      <td>-1.67</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.00</td>
      <td>-1.16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.25</td>
      <td>-0.24</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.50</td>
      <td>-0.36</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.75</td>
      <td>0.44</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2.00</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2.25</td>
      <td>-0.02</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2.50</td>
      <td>-0.63</td>
    </tr>
    <tr>
      <th>10</th>
      <td>2.75</td>
      <td>-1.26</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3.00</td>
      <td>-1.03</td>
    </tr>
    <tr>
      <th>12</th>
      <td>3.25</td>
      <td>0.88</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
&#13;

<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames.</p>
<ul class="simple">
<li><p>The describe command provides count, mean, standard deviation, percentiles, minimum, maximum in a nice data table.</p></li>
<li><p>I like to specify the percentiles, otherwise P25, P50 and P75 quartiles are the default</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                <span class="c1"># summary statistics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>10%</th>
      <th>50%</th>
      <th>90%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Depth</th>
      <td>40.0</td>
      <td>5.12500</td>
      <td>2.922613</td>
      <td>0.25</td>
      <td>1.225</td>
      <td>5.125</td>
      <td>9.025</td>
      <td>10.00</td>
    </tr>
    <tr>
      <th>Nporosity</th>
      <td>40.0</td>
      <td>0.02225</td>
      <td>0.992111</td>
      <td>-2.08</td>
      <td>-1.271</td>
      <td>0.140</td>
      <td>1.220</td>
      <td>2.35</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here we extract the Depth and Gaussian transformed porosity, Nporosity, from the DataFrame into separate 1D arrays called ‚Äòdepth‚Äô and ‚ÄòNPor‚Äô for readable code.</p>
<ul class="simple">
<li><p>warning, this is a shallow copy, if we change these 1D arrays, the change will be reflected back in the original DataFrame</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">Xname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Depth'</span><span class="p">];</span> <span class="n">yname</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Nporosity'</span><span class="p">]</span>                      <span class="c1"># select the predictor and response feature</span>

<span class="n">Xlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Depth'</span><span class="p">];</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Gaussian Transformed Porosity'</span><span class="p">]</span> <span class="c1"># specify the feature labels for plotting</span>
<span class="n">Xunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'m'</span><span class="p">];</span> <span class="n">yunit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'N[%]'</span><span class="p">]</span>
<span class="n">Xlabelunit</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">]</span>
<span class="n">ylabelunit</span> <span class="o">=</span> <span class="n">ylabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>                                              <span class="c1"># extract the 1D ndarrays from the DataFrame</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

<span class="n">Xmin</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="mf">10.0</span>                                       <span class="c1"># limits for plotting</span>
<span class="n">ymin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">3.0</span>

<span class="n">X_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>                         <span class="c1"># X intervals to visualize the model </span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Linear Regression Model</h2>
<p>Let‚Äôs first calculate the linear regression model with the LinearRegression class from scikit-learn. The steps include,</p>
<ol class="arabic simple">
<li><p><strong>instantiate</strong> - the linear regression object, note there are no hyperparameters to specify.</p></li>
<li><p><strong>fit</strong> - train the instantiated linear regression object with the training data</p></li>
<li><p><strong>predict</strong> - with the trained linear regression object</p></li>
</ol>
<p>Here‚Äôs the instantiation and fit steps for our linear regression model.</p>
<ul class="simple">
<li><p>note, we add the reshape to our predictor feature because scikit-learn assumes more than one predictor feature and expects a 2D array. We reshape our 1D ndarray to a 2D array with only 1 column.</p></li>
</ul>
<p>After we train the model we plot it with the data for visual model checking.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                      <span class="c1"># instantiate linear regression object, note no hyperparameters </span>
<span class="n">lin</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>                           <span class="c1"># train linear regression model</span>

<span class="n">slope</span> <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                                          <span class="c1"># get the model parameters</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the data and the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_values</span><span class="p">,</span><span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span><span class="o">*</span><span class="n">X_values</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Linear Regression Model, Regression of '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Linear Regression Model'</span><span class="p">,[</span><span class="mf">4.5</span><span class="p">,</span><span class="o">-</span><span class="mf">1.8</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">6.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">6.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_1 \times z + \beta_0$'</span><span class="p">,[</span><span class="mf">4.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times$ $z$ + ('</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,[</span><span class="mf">4.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/64b4519fff29b4b1c8eef0c0d94e3ceba809f3543abba1333ea33b4f4120ac4a.png" src="../Images/ba77774bef128a461422095cb22a2827.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/64b4519fff29b4b1c8eef0c0d94e3ceba809f3543abba1333ea33b4f4120ac4a.png"/>
</div>
</div>
&#13;

<h2>Comparison to a Nonparametric Predictive Machine Learning Model</h2>
<p>Let‚Äôs run a couple nonparametric predictive machine learning models to contrast with the linear and polynomial parametric models. First we train a quick decision tree model and then a random forest model.</p>
<ul class="simple">
<li><p>we gain significant flexibility to fit any patterns from the data</p></li>
<li><p>requires more inference as nonparametric is actually parameter rich!</p></li>
</ul>
<p>For more details, see the chapter on decision trees and random forest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>                                      <span class="c1"># tree program from scikit learn </span>

<span class="n">my_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="c1"># instantiate the decision tree model with hyperparameters</span>
<span class="n">my_tree</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="n">y</span><span class="p">)</span>              <span class="c1"># fit the decision tree to the training data (all the data in this case)</span>
<span class="n">DT_y</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                <span class="c1"># predict at high resolution over the range of depths</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the model and data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_values</span><span class="p">,</span> <span class="n">DT_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decision Tree Model, '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' as a Function of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b5e3bfa9d8d83005e43dd6add7fb70f36813fa375d987065f62bbdf04957cddb.png" src="../Images/8e31233c62876ecb3c64296751df5ef5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b5e3bfa9d8d83005e43dd6add7fb70f36813fa375d987065f62bbdf04957cddb.png"/>
</div>
</div>
<p>and here is a random forest model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>            <span class="c1"># random forest method</span>

<span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span>                                                 <span class="c1"># set the random forest hyperparameters</span>
<span class="n">num_tree</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">max_features</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">my_forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">num_tree</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="n">max_features</span><span class="p">)</span>
<span class="n">my_forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>  
<span class="n">RF_y</span> <span class="o">=</span> <span class="n">my_forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_values</span><span class="p">,</span> <span class="n">RF_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Random Forest Tree Model, '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' as a Function of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d5ecd12edcb40da8fada767537df53155d9f68f2ab79546bb129a6d93f2cc28e.png" src="../Images/704a35303eabbbf03215f2c0a311653d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/d5ecd12edcb40da8fada767537df53155d9f68f2ab79546bb129a6d93f2cc28e.png"/>
</div>
</div>
<p>Note, no effort was made to tune the hyperparameters for these models. I just wanted to demonstrate the great flexibility of a nonparametric model to learn the shape of the system from the data.</p>
<p>Now, we return to our parametric polynomial model.</p>
<ul class="simple">
<li><p>Let‚Äôs first transform our data to be standard normal, Gaussian.</p></li>
<li><p>We do this to improve the model fit (handle outliers) and to comply with theory for the Hermite polynomials that will be introduced shortly.</p></li>
</ul>
&#13;

<h2>Gaussian Anamorphosis \ Gaussian Transform</h2>
<p>Let‚Äôs transform the features to standard normal,</p>
<ul class="simple">
<li><p>Gaussian distribution</p></li>
<li><p>mean of 0.0</p></li>
<li><p>standard deviation of 1.0</p></li>
</ul>
<p>The porosity feature was ‚Äòtransformed‚Äô to Gaussian previously, but there is an opportunity to clean it up.</p>
<ul class="simple">
<li><p>compare the original and transformed below</p></li>
<li><p>note, I use my GeostatsPy Gaussian transform ported from the original GSLIB (Deutsch and Journel, 1997) because the scikit-learn Gaussian transform creates truncation spikes / outliers.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">geostatspy.geostats</span> <span class="k">as</span> <span class="nn">geostats</span>                        <span class="c1"># for Gaussian transform from GSLIB</span>

<span class="n">df_ns</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>   
<span class="n">df_ns</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">tvPor</span><span class="p">,</span> <span class="n">tnsPor</span> <span class="o">=</span> <span class="n">geostats</span><span class="o">.</span><span class="n">nscore</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># nscore transform for all facies porosity </span>
<span class="n">df_ns</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">tvdepth</span><span class="p">,</span> <span class="n">tnsdepth</span> <span class="o">=</span> <span class="n">geostats</span><span class="o">.</span><span class="n">nscore</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># nscore transform for all facies permeability</span>
<span class="n">X_ns</span> <span class="o">=</span> <span class="n">df_ns</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]];</span> <span class="n">y_ns</span> <span class="o">=</span> <span class="n">df_ns</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">X_ns_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>                      <span class="c1"># values to predict at in standard normal space               </span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs make some good cumulative distribution function plots to check the original and transformed variables.</p>
<ul class="simple">
<li><p>the results look very good</p></li>
</ul>
<p>We are doing this because we will need a Gaussian distribution for the predictor feature for orthogonality.  More later!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># plot original sand and shale porosity histograms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Xmin</span><span class="p">,</span><span class="n">Xmax</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Original'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Original Depth'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_ns</span><span class="p">[</span><span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'NS'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Nscore '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                        <span class="c1"># plot nscore transformed sand and shale histograms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Original'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Original Porosity'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>                                        <span class="c1"># plot nscore transformed sand and shale histograms</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_ns</span><span class="p">[</span><span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">),</span><span class="n">histtype</span><span class="o">=</span><span class="s2">"stepfilled"</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'NS'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Nscore '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/502106ad20a71cc9f6a412707dabe69539c7d2e42d6c72fa8b141c5695c13588.png" src="../Images/7b0e4b346e5f29d5e18e8d52b82145f1.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/502106ad20a71cc9f6a412707dabe69539c7d2e42d6c72fa8b141c5695c13588.png"/>
</div>
</div>
&#13;

<h2>Linear Regression Model with Standardized Features</h2>
<p>Let‚Äôs repeat the linear regression model, now with the standardized features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_ns</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                   <span class="c1"># instantiate linear regression object, note no hyperparameters </span>
<span class="n">lin_ns</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_ns</span><span class="p">)</span>                  <span class="c1"># train linear regression model</span>
<span class="n">slope_ns</span> <span class="o">=</span> <span class="n">lin_ns</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                                    <span class="c1"># get the model parameters</span>
<span class="n">intercept_ns</span> <span class="o">=</span> <span class="n">lin_ns</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the data and the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">intercept_ns</span> <span class="o">+</span> <span class="n">slope_ns</span><span class="o">*</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'model'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Linear Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Linear Regression Model'</span><span class="p">,[</span><span class="mf">0.8</span><span class="p">,</span><span class="o">-</span><span class="mf">1.8</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">1.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="mf">1.8</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_1 \times z + \beta_0$'</span><span class="p">,[</span><span class="mf">0.5</span><span class="p">,</span><span class="o">-</span><span class="mf">2.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">slope_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times$ $z$ + ('</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept_ns</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">,[</span><span class="mf">0.5</span><span class="p">,</span><span class="o">-</span><span class="mf">2.7</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1966b7337c4a5b38596f989a8211aa0c1e8cfbab292369ed714bb5b7ebefb550.png" src="../Images/4c865fd8f2805646d61c8babce9fdbbd.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/1966b7337c4a5b38596f989a8211aa0c1e8cfbab292369ed714bb5b7ebefb550.png"/>
</div>
</div>
<p>Once again, not a good fit. Let‚Äôs use a more complex, flexible predictive machine learning model.</p>
&#13;

<h2>Polynomial Regression</h2>
<p>We will do polynomial regression by hand:</p>
<ul class="simple">
<li><p>create the polynomial basis expansion of the original predictor feature</p></li>
<li><p>perform linear regression on the polynomial basis expansion</p></li>
</ul>
<section id="polynomial-basis-expansion">
<h3>Polynomial Basis Expansion</h3>
<p>Let‚Äôs start with calculating the polynomial basis expansion for the 1 predictor feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">poly4</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>                        <span class="c1"># instantiate polynomial expansion </span>
<span class="n">X_ns_poly4</span> <span class="o">=</span> <span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># calculate the basis expansion for our dataset</span>
<span class="n">df_X_ns_poly4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Values'</span><span class="p">:</span><span class="n">X_ns</span><span class="p">,</span><span class="s1">'0th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> 
                              <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_poly4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Values'</span><span class="p">:</span><span class="n">X_ns</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> 
                              <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>                                          <span class="c1"># preview the polynomial basis expansion with the original predictor feature</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Values</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-2.026808</td>
      <td>4.107951</td>
      <td>-8.326029</td>
      <td>16.875264</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-1.780464</td>
      <td>3.170053</td>
      <td>-5.644167</td>
      <td>10.049238</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-1.534121</td>
      <td>2.353526</td>
      <td>-3.610592</td>
      <td>5.539084</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-1.356312</td>
      <td>1.839582</td>
      <td>-2.495046</td>
      <td>3.384060</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-1.213340</td>
      <td>1.472193</td>
      <td>-1.786270</td>
      <td>2.167352</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let‚Äôs check the correlation between the polynomial basis expansion of the original predictor features data.</p>
<ul class="simple">
<li><p>Recall that a high degree of correlation between predictor features increases model variance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>                 <span class="c1"># calculate the correlation matrix</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Polynomial Expansion Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2f3f18b5d2988d034a420125ea0efceca61840db5af413c92d054ca206d52af6.png" src="../Images/9b9eee94daf8d4510c17a21728efa520.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/2f3f18b5d2988d034a420125ea0efceca61840db5af413c92d054ca206d52af6.png"/>
</div>
</div>
<p>We have high correlations between order 1 and 3 and order 2 and 4.</p>
<ul class="simple">
<li><p>Let‚Äôs check this with matrix scatter plot of the polynomial basis.</p></li>
</ul>
</section>
&#13;

<h3>Polynomial Basis Expansion</h3>
<p>Let‚Äôs start with calculating the polynomial basis expansion for the 1 predictor feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">poly4</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>                        <span class="c1"># instantiate polynomial expansion </span>
<span class="n">X_ns_poly4</span> <span class="o">=</span> <span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># calculate the basis expansion for our dataset</span>
<span class="n">df_X_ns_poly4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Values'</span><span class="p">:</span><span class="n">X_ns</span><span class="p">,</span><span class="s1">'0th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> 
                              <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_poly4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Values'</span><span class="p">:</span><span class="n">X_ns</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> 
                              <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_poly4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>                                          <span class="c1"># preview the polynomial basis expansion with the original predictor feature</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Values</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-2.026808</td>
      <td>4.107951</td>
      <td>-8.326029</td>
      <td>16.875264</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-1.780464</td>
      <td>3.170053</td>
      <td>-5.644167</td>
      <td>10.049238</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-1.534121</td>
      <td>2.353526</td>
      <td>-3.610592</td>
      <td>5.539084</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-1.356312</td>
      <td>1.839582</td>
      <td>-2.495046</td>
      <td>3.384060</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-1.213340</td>
      <td>1.472193</td>
      <td>-1.786270</td>
      <td>2.167352</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let‚Äôs check the correlation between the polynomial basis expansion of the original predictor features data.</p>
<ul class="simple">
<li><p>Recall that a high degree of correlation between predictor features increases model variance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>                 <span class="c1"># calculate the correlation matrix</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Polynomial Expansion Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2f3f18b5d2988d034a420125ea0efceca61840db5af413c92d054ca206d52af6.png" src="../Images/9b9eee94daf8d4510c17a21728efa520.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/2f3f18b5d2988d034a420125ea0efceca61840db5af413c92d054ca206d52af6.png"/>
</div>
</div>
<p>We have high correlations between order 1 and 3 and order 2 and 4.</p>
<ul class="simple">
<li><p>Let‚Äôs check this with matrix scatter plot of the polynomial basis.</p></li>
</ul>
&#13;

<h2>Visualize the Polynomial Expansion Features‚Äô Pairwise Relationship</h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'1st'</span><span class="p">,</span><span class="s1">'2nd'</span><span class="p">,</span><span class="s1">'3rd'</span><span class="p">,</span><span class="s1">'4th'</span><span class="p">],</span><span class="n">markers</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">'reg'</span><span class="p">,</span><span class="n">diag_kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9f46b45339b77aeca8a91c3df0f6006093ccd5e8e509c9feb5231794e4797834.png" src="../Images/3ea96d491efa1ce020f1f121c4e5fc5c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/9f46b45339b77aeca8a91c3df0f6006093ccd5e8e509c9feb5231794e4797834.png"/>
</div>
</div>
<p>Let‚Äôs visualize the polynomial expansion over the Gaussian transformed depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the polynomial basis expansion</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'0th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'1th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'2th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">3</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'3th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">4</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'4th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'orange'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Polynomial Basis Expansion of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'h[ NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">') ]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/918e255b4a95601966627b5b6f5cd42f0edf824785db2cd3669e31d5f4519ed5.png" src="../Images/3f62f7e21b741e2cd86be2687d0f5fdb.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/918e255b4a95601966627b5b6f5cd42f0edf824785db2cd3669e31d5f4519ed5.png"/>
</div>
</div>
<p>We can also check the arithmetic average of each polynomial basis expansion.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'The averages of each basis expansion, 0 - 4th order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">X_ns_poly4</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>The averages of each basis expansion, 0 - 4th order = [1.         0.00536486 0.9458762  0.07336308 2.31077802].
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs fit the linear regression model to the polynomial basis expansion.</p>
<ul class="simple">
<li><p>note the model is quite flexible to fit this complicated / nonlinear data</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_poly4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                <span class="c1"># instantiate new linear model </span>
<span class="n">lin_poly4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X_ns_poly4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_ns</span><span class="p">)</span>                 <span class="c1"># train linear model with polynomial expansion, polynomial regression</span>
<span class="n">b1</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span><span class="n">b3</span><span class="p">,</span><span class="n">b4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">lin_poly4</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>                     <span class="c1"># retrieve the model parameters</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">lin_poly4</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">lin_poly4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">poly4</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">:]),</span><span class="n">label</span><span class="o">=</span><span class="s1">'polynomial'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Polynomial Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">b4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">b3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8e8a2889184278abe92b133ef03f98039f95b3558223864483cc2bfb0461e2d1.png" src="../Images/8544dd539b8a7b35cc6999a54d0fecb5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8e8a2889184278abe92b133ef03f98039f95b3558223864483cc2bfb0461e2d1.png"/>
</div>
</div>
&#13;

<h2>Regression with Hermite Basis Expansion</h2>
<p>We can use Hermite polynomials to reduce the correlation between the basis predictor features.</p>
<ul class="simple">
<li><p>We transform the predictor feature, depth, to standard normal since the Hermite polynomial expansion approach independence over the range of negative infinity to positive infinity under the assumption of standard normal probability density function.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">orders4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>                                           <span class="c1"># specify the orders for Hermite basis expansion</span>
<span class="n">X_ns_hermite4</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermitenorm</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># Hermite polynomials for X </span>
<span class="n">df_X_ns_hermite4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'value'</span><span class="p">:</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> 
                                     <span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_hermite4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]})</span> <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>value</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-2.026808</td>
      <td>3.107951</td>
      <td>-2.245605</td>
      <td>-4.772444</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-1.780464</td>
      <td>2.170053</td>
      <td>-0.302774</td>
      <td>-5.971082</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-1.534121</td>
      <td>1.353526</td>
      <td>0.991769</td>
      <td>-5.582071</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-1.356312</td>
      <td>0.839582</td>
      <td>1.573889</td>
      <td>-4.653429</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-1.213340</td>
      <td>0.472193</td>
      <td>1.853749</td>
      <td>-3.665806</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note: I have omitted orders that had a higher degree of correlation for our dataset.</p>
<p>Let‚Äôs check the correlation between the Hermite predictor features. There is improvement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">hermite_corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>      <span class="c1"># calculate correlation matrix of Hermite basis expansion of X</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">hermite_corr_matrix</span><span class="p">,</span><span class="s1">'Hermite Polynomial Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/767654dc38789e23879b6040b9c52283c5c21eb95f0671e3d0470ab4b3b8c71f.png" src="../Images/f1b9e3f1eac053a1460fbb16b9d3ab5e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/767654dc38789e23879b6040b9c52283c5c21eb95f0671e3d0470ab4b3b8c71f.png"/>
</div>
</div>
<p>The pairwise linear correlation is quite low compared to the polynomial basis.</p>
<p>Let‚Äôs visualize the bivariate relationships between our Hermite basis orders.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'1st'</span><span class="p">,</span><span class="s1">'2nd'</span><span class="p">,</span><span class="s1">'3rd'</span><span class="p">,</span><span class="s1">'4th'</span><span class="p">],</span><span class="n">markers</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">'reg'</span><span class="p">,</span><span class="n">diag_kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/695a6474c0e6f88800c5be51a4e1437b374986904af57e9dfff07a1184f65977.png" src="../Images/9fd622d54d360b533c8ba76f2bd6a2b6.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/695a6474c0e6f88800c5be51a4e1437b374986904af57e9dfff07a1184f65977.png"/>
</div>
</div>
<p>We can check the arithmetic averages of all the Hermite basis expansions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'The means of each basis expansion, 1 - 4th order = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">X_ns_hermite4</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="s1">'.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>The means of each basis expansion, 1 - 4th order = [ 0.00536486 -0.0541238   0.05726848 -0.36447919].
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs visualize Hermite polynomials over the range of the standardized depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot Hermite polynomials</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'1st'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'2nd'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'3rd'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermite</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[:,</span><span class="mi">3</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'4th'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'orange'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Hermite Polynomial Basis Expansion of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'h[ NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">') ]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f32be19da954ac4bb5bdc7d502a565b9c8e6c3c007728bd33276d37d1eaf6259.png" src="../Images/4014172673585ba0353f9f413f88bd94.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/f32be19da954ac4bb5bdc7d502a565b9c8e6c3c007728bd33276d37d1eaf6259.png"/>
</div>
</div>
<p>Now let‚Äôs fit our Hermite basis regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_herm4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                                <span class="c1"># instantiate model</span>
<span class="n">lin_herm4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X_ns_hermite4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_ns</span><span class="p">)</span>              <span class="c1"># fit Hermite polynomials </span>
<span class="n">hb1</span><span class="p">,</span><span class="n">hb2</span><span class="p">,</span><span class="n">hb3</span><span class="p">,</span><span class="n">hb4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">lin_herm4</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>                 <span class="c1"># retrieve the model parameters</span>
<span class="n">hb0</span> <span class="o">=</span> <span class="n">lin_herm4</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot data and model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">lin_herm4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">eval_hermitenorm</span><span class="p">(</span><span class="n">orders4</span><span class="p">,</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)),</span> 
         <span class="n">label</span><span class="o">=</span><span class="s1">'4th order'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Hermite Polynomial Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hermite Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hb4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hb3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">hb2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">hb1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">hb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5b4926cdbd311bf1b5374a042995789082def9fd00376dc30620f948c00f669d.png" src="../Images/f42cc4ffefcd978188c7348b3d653b8b.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/5b4926cdbd311bf1b5374a042995789082def9fd00376dc30620f948c00f669d.png"/>
</div>
</div>
<p>Since we have less correlation between the expanded basis features we can check out the model coefficients and interpret the unique importance of each order.</p>
&#13;

<h2>Orthogonal Polynomials</h2>
<p>Let‚Äôs try the orthogonal polynomial basis expansion reimplemented in Python by Dave Moore from the poly() function in R.</p>
<ul class="simple">
<li><p>the functions below for fit and predict are directly from Dave‚Äôs <a class="reference external" href="http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly">blog</a></p></li>
<li><p>note during the fit to the training data the norm2 and alpha model parameters are calcluated</p></li>
<li><p>these parameters must be passed to each subsequent predict to ensure the results are consistent</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1"># functions taken (without modification) from http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly</span>
<span class="c1"># appreciation to Dave Moore for the great blog post on titled 'Orthogonal polynomial regression in Python'</span>
<span class="c1"># functions are Dave's reimplementation of poly() from R</span>

<span class="k">def</span> <span class="nf">ortho_poly_fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span><span class="p">(</span><span class="n">degree</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">))):</span>
            <span class="n">stop</span><span class="p">(</span><span class="s2">"'degree' must be less than number of unique points"</span><span class="p">)</span>
    <span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">xbar</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">q</span><span class="p">,</span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

    <span class="n">norm2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">raw</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">raw</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="n">norm2</span> <span class="o">+</span> <span class="n">xbar</span><span class="p">)[:</span><span class="n">degree</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">raw</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">alpha</span>

<span class="k">def</span> <span class="nf">ortho_poly_predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">Z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">Z</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">degree</span><span class="p">):</span>
             <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">norm2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">norm2</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Z</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs give it a try and perform orthogonal polynomial expansion of our standard normal transformed depth</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_ns_ortho4</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">ortho_poly_fit</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># orthogonal polynomial expansion</span>
<span class="n">df_X_ns_ortho4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'value'</span><span class="p">:</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="s1">'1st'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">'2nd'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">'3rd'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span>
                               <span class="s1">'4th'</span><span class="p">:</span><span class="n">X_ns_ortho4</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]})</span>       <span class="c1"># make a new DataFrame from the vectors</span>
<span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>value</th>
      <th>1st</th>
      <th>2nd</th>
      <th>3rd</th>
      <th>4th</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.026808</td>
      <td>-0.330385</td>
      <td>0.440404</td>
      <td>-0.460160</td>
      <td>0.420374</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.780464</td>
      <td>-0.290335</td>
      <td>0.313201</td>
      <td>-0.207862</td>
      <td>0.021278</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.534121</td>
      <td>-0.250285</td>
      <td>0.202153</td>
      <td>-0.029761</td>
      <td>-0.172968</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.356312</td>
      <td>-0.221377</td>
      <td>0.132038</td>
      <td>0.058235</td>
      <td>-0.220834</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.213340</td>
      <td>-0.198133</td>
      <td>0.081765</td>
      <td>0.107183</td>
      <td>-0.219084</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let‚Äôs check the correlation between the orthogonal polynomial predictor features. I‚Äôm impressed! The between basis feature order correlations are all zero!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">ortho_corr_matrix</span> <span class="o">=</span> <span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>          <span class="c1"># calculate the correlation matrix</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">ortho_corr_matrix</span><span class="p">,</span><span class="s1">'Orthogonal Polynomial Expansion Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/51874452bf180e62d5f0824897a2b248a5e40bd802ff4ba4fefefda0c75d9c65.png" src="../Images/5c444109d15f6a2e24d2be84d8941629.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/51874452bf180e62d5f0824897a2b248a5e40bd802ff4ba4fefefda0c75d9c65.png"/>
</div>
</div>
<p>Let‚Äôs visualize the bivariate relationships between our orthogonal polynomial basis orders.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'1st'</span><span class="p">,</span><span class="s1">'2nd'</span><span class="p">,</span><span class="s1">'3rd'</span><span class="p">,</span><span class="s1">'4th'</span><span class="p">],</span><span class="n">markers</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">kind</span><span class="o">=</span><span class="s1">'reg'</span><span class="p">,</span><span class="n">diag_kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>&lt;seaborn.axisgrid.PairGrid at 0x1ed608d8370&gt;
</pre></div>
</div>
<img alt="_images/ad56938294bca2fddf0cb90bd5afb4aa9c16bdec043fae497f76527072c2698b.png" src="../Images/5a2f9488237446e128cc99a668c78ad7.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/ad56938294bca2fddf0cb90bd5afb4aa9c16bdec043fae497f76527072c2698b.png"/>
</div>
</div>
<p>Let‚Äôs visualize orthogonal polynomial basis orders over the range of the standardized depth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">ortho_poly_ns_values</span> <span class="o">=</span> <span class="n">ortho_poly_predict</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">norm2</span><span class="p">,</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'0th'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'1st'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'2nd'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'green'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'3rd'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span> <span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'4th'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'orange'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Basis Expansion of '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'h[ NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">') ]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fb2ab3f98848b762f738beb5133cf2b9963dbab254ba2882a5a5265e218ba8ce.png" src="../Images/74a68b06994a2941d62a1c4da558780c.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/fb2ab3f98848b762f738beb5133cf2b9963dbab254ba2882a5a5265e218ba8ce.png"/>
</div>
</div>
<p>Finally let‚Äôs fit our orthogonal polynomial basis expansion regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">lin_ortho4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>                               <span class="c1"># instantiate model</span>
<span class="n">lin_ortho4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X_ns_ortho4</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:],</span> <span class="n">y_ns</span><span class="p">)</span>               <span class="c1"># fit Hermite polynomials </span>
<span class="n">ob1</span><span class="p">,</span><span class="n">ob2</span><span class="p">,</span><span class="n">ob3</span><span class="p">,</span><span class="n">ob4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">lin_ortho4</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>                <span class="c1"># retrieve the model parameters</span>
<span class="n">ob0</span> <span class="o">=</span> <span class="n">lin_ortho4</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">lin_ortho4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ortho_poly_ns_values</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]),</span><span class="n">label</span><span class="o">=</span><span class="s1">'orthogonal polynomial'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Regression Model, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ob4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ob3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ob2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">ob1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ob0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b9adcfb2f480cc56becaad7a7b7d097564da38381dbf860303502572e5eab039.png" src="../Images/2a189618f9055efc6488a7eb46c5c41d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/b9adcfb2f480cc56becaad7a7b7d097564da38381dbf860303502572e5eab039.png"/>
</div>
</div>
&#13;

<h2>Polynomial Regression in scikit-learn with Pipelines</h2>
<p>The need to first perform basis expansion and then train the resulting (after basis transformations) linear model may seem a bit complicated.</p>
<ul class="simple">
<li><p>one solution is to use the Pipeline object from scikit-learn. Here are some highlights on Pipelines.</p></li>
</ul>
<p>Machine learning workflows can be complicated, with various steps:</p>
<ul class="simple">
<li><p>data preparation, feature engineering transformations</p></li>
<li><p>model parameter fitting</p></li>
<li><p>model hyperparameter tuning</p></li>
<li><p>modeling method selection</p></li>
<li><p>searching over a large combinatorial of hyperparameters</p></li>
<li><p>training and testing model runs</p></li>
</ul>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to find the best model (AutoML)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">order</span><span class="o">=</span><span class="mi">4</span>                                                       <span class="c1"># set the polynomial order</span>

<span class="n">polyreg_pipe</span><span class="o">=</span><span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">order</span><span class="p">),</span><span class="n">LinearRegression</span><span class="p">())</span> <span class="c1"># make the modeling pipeline</span>
<span class="n">polyreg_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_ns</span><span class="p">)</span>            <span class="c1"># fit the model to the data</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">polyreg_pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_ns_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>      <span class="c1"># predict with the modeling pipeline</span>
<span class="n">poly_reg_model</span> <span class="o">=</span> <span class="n">polyreg_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">'linearregression'</span><span class="p">]</span> <span class="c1"># retrieve the model from the pipeline</span>
<span class="n">pb0a</span><span class="p">,</span><span class="n">pb1</span><span class="p">,</span><span class="n">pb2</span><span class="p">,</span><span class="n">pb3</span><span class="p">,</span><span class="n">pb4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">poly_reg_model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>       <span class="c1"># retrieve the model parameters</span>
<span class="n">pb0b</span> <span class="o">=</span> <span class="n">poly_reg_model</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">pb0</span> <span class="o">=</span> <span class="n">pb0a</span> <span class="o">+</span> <span class="n">pb0b</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>                                              <span class="c1"># plot the data and model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_ns_values</span><span class="p">,</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'4th order'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ns</span><span class="p">,</span><span class="n">y_ns</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">'$^</span><span class="si">{th}</span><span class="s1">$ Polynomial Regression Model with Pipelines, Regression of NS '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' on NS '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">Xname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">Xunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'NS: '</span> <span class="o">+</span> <span class="n">yname</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' ('</span> <span class="o">+</span> <span class="n">yunit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">')'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Orthogonal Polynomial Regression Model'</span><span class="p">,[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.6</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_4$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb4</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">2.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_3$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb3</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_2$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_1$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb1</span><span class="p">,</span><span class="mi">3</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'    $\beta_0$ :'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">2.8</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = \beta_4 \times N[z]^4 + \beta_3 \times N[z]^3 + \beta_2 \times N[z]^2 + \beta_1 \times N[z] + \beta_0$'</span><span class="p">,[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$N[\phi] = $'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pb4</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^4 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pb3</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^3 +$ '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pb2</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]^2 +$ '</span> <span class="o">+</span> 
             <span class="nb">str</span><span class="p">(</span><span class="n">pb1</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">' $\times N[z]$ + '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pb0</span><span class="p">,</span><span class="mi">2</span><span class="p">)),[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="o">-</span><span class="mf">2.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c8e565b643fa879eb74f2d3c49419386b5073f8c2dce53cd9dd9142465f16ee.png" src="../Images/e0ba7ea47dd6042f5976cb230740cb93.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4c8e565b643fa879eb74f2d3c49419386b5073f8c2dce53cd9dd9142465f16ee.png"/>
</div>
</div>
&#13;

<h2>Comments</h2>
<p>This was a basic treatment of polynomial regression. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
&#13;

<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
&#13;

<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
<p>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
    
</body>
</html>