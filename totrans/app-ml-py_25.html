<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>k-nearest Neighbours</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>k-nearest Neighbours</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_knearest_neighbours.html">https://geostatsguy.github.io/MachineLearningDemos_Book/MachineLearning_knearest_neighbours.html</a></blockquote>

<p>Michael J. Pyrcz, Professor, The University of Texas at Austin</p>
<p><a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistics Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/">Applied Machine Learning in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></p>
<p>Chapter of e-book ‚ÄúApplied Machine Learning in Python: a Hands-on Guide with Code‚Äù.</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite this e-Book as:</p>
<p>Pyrcz, M.J., 2024, <em>Applied Machine Learning in Python: A Hands-on Guide with Code</em> [e-book]. Zenodo. doi:10.5281/zenodo.15169138 <a class="reference external" href="https://doi.org/10.5281/zenodo.15169138"><img alt="DOI" src="../Images/7e4ea662f44af1eae87e87ecbb962ff4.png" data-original-src="https://zenodo.org/badge/863274676.svg"/></a></p>
</div>
<p>The workflows in this book and more are available here:</p>
<div class="remove-from-content-only admonition">
<p class="admonition-title">Cite the MachineLearningDemos GitHub Repository as:</p>
<p>Pyrcz, M.J., 2024, <em>MachineLearningDemos: Python Machine Learning Demonstration Workflows Repository</em> (0.0.3) [Software]. Zenodo. DOI: 10.5281/zenodo.13835312. GitHub repository: <a class="github reference external" href="https://github.com/GeostatsGuy/MachineLearningDemos">GeostatsGuy/MachineLearningDemos</a> <a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.13835312"><img alt="DOI" src="../Images/4e3a59c17d684b06a170c4af84e0f631.png" data-original-src="https://zenodo.org/badge/862519860.svg"/></a></p>
</div>
<p>By Michael J. Pyrcz <br/>
¬© Copyright 2024.</p>
<p>This chapter is a tutorial for / demonstration of <strong>k-nearest Neighbours</strong>.</p>
<p><strong>YouTube Lecture</strong>: check out my lectures on:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/zOUM_AnI1DQ?si=wzWdJ35qJ9n8O6Bl">Introduction to Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://youtu.be/lzmeChSYvv8?si=nfcvGtkIAQ7rFkjo">k-nearest Neighbours Regression</a></p></li>
</ul>
<p>These lectures are all part of my <a class="reference external" href="https://youtube.com/playlist?list=PLG19vXLQHvSC2ZKFIkgVpI9fCjkN38kwf&amp;si=XonjO2wHdXffMpeI">Machine Learning Course</a> on YouTube with linked well-documented Python workflows and interactive dashboards. My goal is to share accessible, actionable, and repeatable educational content. If you want to know about my motivation, check out <a class="reference external" href="https://michaelpyrcz.com/my-story">Michael‚Äôs Story</a>.</p>
<section id="motivations-for-k-nearest-neighbours-regression">
<h2>Motivations for k-nearest Neighbours Regression</h2>
<p>There are many good reasons to cover k-nearest neighbours regression. In addition to being a simple, interpretable and flexible predictive machine learning model, it also demonstrates important concepts,</p>
<ul class="simple">
<li><p><strong>non-parametric predictive model</strong> - that learns the form of the relationships from the data, i.e., no prior assumption about the form of the relationship</p></li>
<li><p><strong>instance-based, lazy learning</strong> - model training is postponed until prediction is required, no precalculation of the model. i.e., prediction requires access to the data</p></li>
<li><p><strong>hyperparameter tuning</strong> - with a understandable hyperparameters that control model fit</p></li>
<li><p><strong>very flexible, versatile predictive model</strong> - performs well in many situations</p></li>
</ul>
</section>
<section id="convolution">
<h2>Convolution</h2>
<p>In fact, k-nearest neighbours is analogous to spatial estimation through weighted averaging within a local neighbourhood.</p>
<figure style="text-align: center;">
  <img src="../Images/0cfb5694654b0332a568b81d0ae25755.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/knearest/spatial_interpolation.png"/>
  <figcaption style="text-align: center;">Prediction modeling a spatial interpolation in predictor feature space.</figcaption>
</figure>
<p>The k-nearest neighbours approach is similar to a convolution approach for spatial interpolation. Convolution is the integral product of two functions, after one is reversed and shifted by <span class="math notranslate nohighlight">\(\tau\)</span>.</p>
<ul class="simple">
<li><p>one interpretation is smoothing a function with weighting function, <span class="math notranslate nohighlight">\(ùëì(\Delta)\)</span>, is applied to calculate the weighted average of function, <span class="math notranslate nohighlight">\(ùëî(x)\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ 
(f * g)(x) = \int_{-\infty}^{\infty} f(\tau) g(x - \tau) \, d\tau 
\]</div>
<p>this easily extends into multidimensional</p>
<div class="math notranslate nohighlight">
\[
(f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(\tau_x, \tau_y, \tau_z) g(x - \tau_x, y - \tau_y, z - \tau_z) \, d\tau_x \, d\tau_y \, d\tau_z
\]</div>
<p>The choice of which function is shifted before integration does not change the result, the convolution operator has commutativity,</p>
<div class="math notranslate nohighlight">
\[ 
(f * g)(x) = \int_{-\infty}^{\infty} f(\tau) g(x - \tau) \, d\tau 
\]</div>
<div class="math notranslate nohighlight">
\[
(f * g)(x) = \int_{-\infty}^{\infty} f(x - \tau) g(\tau) \, d\tau 
\]</div>
<ul class="simple">
<li><p>if either function is reflected then convolution is equivalent to cross-correlation, measure of similarity between 2 signals as a function of displacement.</p></li>
</ul>
<p>To demonstrate convolution with an exhaustive <span class="math notranslate nohighlight">\(g(x)\)</span> and sparsely sampled <span class="math notranslate nohighlight">\(g(x)\)</span> I built out an <a class="reference external" href="https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Convolution_kNearest.ipynb">interactive Python convolution dashboard</a>,</p>
<figure style="text-align: center;">
  <img src="../Images/f55c37e0f7da98a233affd5fbd5ba38c.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/knearest/interactive_convolution.png"/>
  <figcaption style="text-align: center;">Interactive Python dashboard to demonstrate convolution.</figcaption>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">scipy.ndimage</span> <span class="kn">import</span> <span class="n">convolve1d</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">73073</span>                                                  <span class="c1"># random number seed</span>

<span class="n">kr</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">kloc</span> <span class="o">=</span> <span class="mi">45</span>                                             <span class="c1"># kernel radius, kernel location for example point</span>

<span class="n">df_denpor</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/1D_por_perm_smooth.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub </span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                    
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">],</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'f(x)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Exhaustive Case: Original and Convolved Function'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kr</span> <span class="o">+</span> <span class="mi">1</span>                                             <span class="c1"># make uniform kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span>                                 <span class="c1"># normalize kernel to sum to one for unbiasedness</span>

<span class="n">convolved</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'same'</span><span class="p">)</span> <span class="c1"># convolution</span>

<span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">trim</span> <span class="o">=</span> <span class="n">k</span> <span class="o">//</span> <span class="mi">2</span>  <span class="c1"># how many values to trim from each edge</span>
<span class="n">convolved_valid</span> <span class="o">=</span> <span class="n">convolved</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">convolved</span>
<span class="n">depth_valid</span> <span class="o">=</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">convolved_pt</span> <span class="o">=</span> <span class="n">convolved_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()];</span> <span class="n">depth_pt</span> <span class="o">=</span> <span class="n">depth_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">convolved_valid</span><span class="p">,</span><span class="n">depth_valid</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$(f * g)(x)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">convolved_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$g(\tau)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Kernel'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Weight (unitless)'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/58f0d6ec82ae506386975d87b4fbaa3fa88f321e3ef516e9f956402a156d2751.png" src="../Images/83364c0e2e061f041cd64b882996eb7e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/58f0d6ec82ae506386975d87b4fbaa3fa88f321e3ef516e9f956402a156d2751.png"/>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">astropy.convolution.convolve</span> <span class="k">as</span> <span class="nn">convolve</span>               <span class="c1"># sparse data convolution</span>
<span class="n">frac</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por_Sparse'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
<span class="n">nan_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">frac</span><span class="p">)),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df_denpor</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">nan_indices</span><span class="p">,</span> <span class="s1">'Por_Sparse'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                    
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por_Sparse'</span><span class="p">],</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'f(x) Sparse'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">],</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'f(x) Exhaustive'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">26</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Sparse Case: Original and Convolved Function'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kr</span> <span class="o">+</span> <span class="mi">1</span>                                             <span class="c1"># make uniform kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span>                                 <span class="c1"># normalize kernel to sum to one for unbiasedness</span>

<span class="n">convolved</span> <span class="o">=</span> <span class="n">convolve</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por_Sparse'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">boundary</span><span class="o">=</span><span class="s1">'extend'</span><span class="p">,</span><span class="n">nan_treatment</span><span class="o">=</span><span class="s1">'interpolate'</span><span class="p">,</span><span class="n">normalize_kernel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># convolve</span>

<span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">trim</span> <span class="o">=</span> <span class="n">k</span> <span class="o">//</span> <span class="mi">2</span>  <span class="c1"># how many values to trim from each edge</span>
<span class="n">convolved_valid</span> <span class="o">=</span> <span class="n">convolved</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">convolved</span>
<span class="n">depth_valid</span> <span class="o">=</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">convolved_pt</span> <span class="o">=</span> <span class="n">convolved_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()];</span> <span class="n">depth_pt</span> <span class="o">=</span> <span class="n">depth_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">convolved_valid</span><span class="p">,</span><span class="n">depth_valid</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$(f * g)(x)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">convolved_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$g(\tau)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Kernel'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Weight (unitless)'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>WARNING: nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this. [astropy.convolution.convolve]
</pre></div>
</div>
<img alt="_images/ae797e2e907bd48f0c7b524dd697136f6a863602289a91dc8e372c930f4a72c1.png" src="../Images/2eab3ef179c50a4d663c4b21d6e38124.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/ae797e2e907bd48f0c7b524dd697136f6a863602289a91dc8e372c930f4a72c1.png"/>
</div>
</div>
<p>While it is useful to review and discuss convolution, k-nearest neighbours departs from convolution with the specification of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours to include in the weighted average,</p>
<ul class="simple">
<li><p>specifying <span class="math notranslate nohighlight">\(k\)</span> results in a locally adaptive window size, the local neighbourhood extends far enough to find <span class="math notranslate nohighlight">\(k\)</span> training data</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/2ffab60ca866a945ae26ac4aab566a02.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/knearest/adaptive_window.png"/>
  <figcaption style="text-align: center;">For a given $k$ number of nearest neighbours data are collected from farther away in sparse data regions of the predictor feature space.</figcaption>
</figure>
</section>
<section id="k-nearest-neighbours-hyperparameters">
<h2>k-nearest Neighbours Hyperparameters</h2>
<p>Now let‚Äôs discuss the k-nearest neighbours hyperparameters.</p>
<ol class="arabic simple">
<li><p><strong>k number of nearest data</strong> - to utilize for prediction</p></li>
<li><p><strong>data weighting</strong> - for example uniform weighting (use local training data average), inverse distance weighting</p></li>
</ol>
<p>Note, for the case of inverse distance weighting, the method is analogous to inverse distance weighted interpolation with a maximum number of local data constraint commonly applied for spatial interpolation. Inverse distance is available in GeostatsPy for spatial mapping.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Distance Metric</strong> - training data within the predictor feature space are ranked by distance, closest to farthest, a variety of distance metrics may be applied, including:</p></li>
</ol>
<ul class="simple">
<li><p>Euclidian distance</p></li>
</ul>
<p>\begin{equation}<br/>
d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
\end{equation}</p>
<ul class="simple">
<li><p>Minkowski Distance - a generalized form of distance with well-known Manhattan and Euclidean distances are special cases,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p \right)^{\frac{1}{p}}
\]</div>
<ul class="simple">
<li><p>when <span class="math notranslate nohighlight">\(p=2\)</span>, this becomes the Euclidean distance</p></li>
<li><p>when <span class="math notranslate nohighlight">\(p=1\)</span> it becomes the Manhattan distance</p></li>
</ul>
</section>
<section id="load-the-required-libraries">
<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">pandas.plotting</span> <span class="k">as</span> <span class="nn">pd_plot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>             <span class="c1"># for nearest k neighbours</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># suppress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
</section>
<section id="declare-functions">
<h2>Declare Functions</h2>
<p>Let‚Äôs define a couple of functions to streamline plotting correlation matrices, visualization of a decision tree regression model, and the addition specified percentiles and major and minor gridlines to our plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span>

<span class="k">def</span> <span class="nf">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">,</span><span class="n">nominal</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span> <span class="c1"># feature ranking plot</span>
    <span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">);</span> <span class="n">mask_low</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">-</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">nominal</span><span class="o">-</span><span class="n">mmin</span><span class="p">);</span> <span class="n">mask_high</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">mmax</span><span class="o">-</span><span class="n">nominal</span><span class="p">);</span> <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span><span class="s1">'r--'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'dodgerblue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'lightcoral'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_low</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">mask_low</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_high</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">mask_high</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predictor Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'RdBu_r'</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
    
<span class="k">def</span> <span class="nf">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xfeature</span><span class="p">,</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">,</span><span class="n">response</span><span class="p">,</span><span class="n">z_min</span><span class="p">,</span><span class="n">z_max</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">axes_commas</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span> <span class="c1"># plots the data points and the decision tree prediction </span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">cmap_temp</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>
    <span class="n">xplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span><span class="o">-</span><span class="n">x_min</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">;</span> <span class="n">yplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_max</span><span class="o">-</span><span class="n">y_min</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">xplot_step</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">yplot_step</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">z_min</span><span class="p">,</span> <span class="n">z_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> 
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'white'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> 
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xfeature</span><span class="o">.</span><span class="n">name</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yfeature</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">);</span> <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">axes_commas</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Z</span>
    
<span class="k">def</span> <span class="nf">visualize_tuned_model</span><span class="p">(</span><span class="n">k_tuned</span><span class="p">,</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score_mat</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score_mat</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">k_tuned</span><span class="p">,</span><span class="n">k_tuned</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000000</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),</span><span class="n">label</span><span class="o">=</span><span class="s1">'tuned'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'k-fold Cross Validation Error (MSE) vs. k Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Nearest Neighbours'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">score_mat</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">check_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">rtrain</span><span class="p">,</span><span class="n">rtest</span><span class="p">,</span><span class="n">title</span><span class="p">):</span> <span class="c1"># plots the estimated vs. the actual  </span>
    <span class="n">predict_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">])</span>
    <span class="n">predict_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rtest</span><span class="p">,</span><span class="n">predict_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Actual Production (MCFPD)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimated Production (MCFPD)'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">head_length</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">head_width</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">MSE_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">)</span>
    <span class="n">Var_Explained_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">)</span>
    <span class="n">cor_train</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">))</span>
    <span class="n">MSE_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rtest</span><span class="p">,</span><span class="n">predict_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Train MSE: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_train</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span><span class="p">),[</span><span class="mf">0.05</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">,</span><span class="mf">0.95</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">])</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Test MSE:  '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_test</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span><span class="p">),[</span><span class="mf">0.05</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">,</span><span class="mf">0.90</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">])</span>
    <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
    <span class="c1"># print('Mean Squared Error on Training = ', round(MSE_test,2),', Variance Explained =', round(Var_Explained,2),'Cor =', round(cor,2))</span>

<span class="k">def</span> <span class="nf">weighted_percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">perc</span><span class="p">):</span>                 <span class="c1"># calculate weighted percentile (iambr on StackOverflow @ https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049) </span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> 
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> 
    <span class="n">cdf</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">perc</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">histogram_bounds</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">color</span><span class="p">):</span>                   <span class="c1"># add uncertainty bounds to a histogram          </span>
    <span class="n">p10</span> <span class="o">=</span> <span class="n">weighted_percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="mf">0.1</span><span class="p">);</span> <span class="n">avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">);</span> <span class="n">p90</span> <span class="o">=</span> <span class="n">weighted_percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p10</span><span class="p">,</span><span class="n">p10</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">avg</span><span class="p">,</span><span class="n">avg</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p90</span><span class="p">,</span><span class="n">p90</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks </span>

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>  <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">'&lt;div style="display: flex;"&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-the-working-directory">
<h2>Set the Working Directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
</section>
<section id="loading-tabular-data">
<h2>Loading Tabular Data</h2>
<p>Here‚Äôs the command to load our comma delimited data file in to a Pandas‚Äô DataFrame object.</p>
<p>Let‚Äôs load the provided multivariate, spatial dataset ‚Äòunconv_MV.csv‚Äô. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
<p>Note, the dataset is synthetic.</p>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
</section>
<section id="optional-add-random-noise-to-the-response-feature">
<h2>Optional: Add Random Noise to the Response Feature</h2>
<p>We can do this to observe the impact of data noise on overfit and hyperparameter tuning.</p>
<ul class="simple">
<li><p>This is for experiential learning, of course we wouldn‚Äôt add random noise to our data</p></li>
<li><p>We set the random number seed for reproducibility</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub  </span>
<span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>                                 <span class="c1"># copy all rows and columns 1 through 8, note 0 column is removed</span>

<span class="n">response</span> <span class="o">=</span> <span class="s1">'Prod'</span>                                             <span class="c1"># specify the response feature</span>
<span class="n">add_noise</span> <span class="o">=</span> <span class="kc">True</span>                                              <span class="c1"># set True to add noise to response feature to demonstrate overfit</span>
<span class="n">noise_stdev</span> <span class="o">=</span> <span class="mi">500</span>                                             <span class="c1"># amount of noise to add to response feature to demonstrate overfit</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>                                   <span class="c1"># set the random number seed</span>
<span class="k">if</span> <span class="n">add_noise</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">df_load</span><span class="p">[</span><span class="n">response</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">response</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">noise_stdev</span><span class="p">,</span><span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_load</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">response</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="s1">'columns'</span><span class="p">)</span>                         <span class="c1"># make predictor and response DataFrames</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">response</span><span class="p">]</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>               <span class="c1"># store the names of the features</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">resp</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minumum and maximum values for plotting</span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">9000.0</span>

<span class="n">predlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>
<span class="n">resplabel</span> <span class="o">=</span> <span class="s1">'Normalized Initial Production (MCFPD)'</span>

<span class="n">predtitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>
<span class="n">resptitle</span> <span class="o">=</span> <span class="s1">'Initial Production'</span>

<span class="n">featurelabel</span> <span class="o">=</span> <span class="n">predlabel</span> <span class="o">+</span> <span class="p">[</span><span class="n">resplabel</span><span class="p">]</span>                        <span class="c1"># make feature labels and titles for concise code</span>
<span class="n">featuretitle</span> <span class="o">=</span> <span class="n">predtitle</span> <span class="o">+</span> <span class="p">[</span><span class="n">resptitle</span><span class="p">]</span>

<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># make one DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-dataframe">
<h2>Visualize the DataFrame</h2>
<p>Visualizing the DataFrame is useful first check of the data.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<ul class="simple">
<li><p>add parameter ‚Äòn=13‚Äô to see the first 13 rows of the dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Prod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>1339.165488</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>3383.979252</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>2509.686720</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>5514.421023</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>3532.020478</td>
    </tr>
    <tr>
      <th>5</th>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
      <td>4283.543382</td>
    </tr>
    <tr>
      <th>6</th>
      <td>13.49</td>
      <td>3.60</td>
      <td>2.93</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
      <td>3627.906723</td>
    </tr>
    <tr>
      <th>7</th>
      <td>11.58</td>
      <td>3.03</td>
      <td>3.25</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
      <td>3101.539533</td>
    </tr>
    <tr>
      <th>8</th>
      <td>12.52</td>
      <td>2.72</td>
      <td>2.43</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
      <td>3213.391047</td>
    </tr>
    <tr>
      <th>9</th>
      <td>13.25</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
      <td>2200.204701</td>
    </tr>
    <tr>
      <th>10</th>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>61.11</td>
      <td>1.08</td>
      <td>1.77</td>
      <td>3433.752662</td>
    </tr>
    <tr>
      <th>11</th>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
      <td>4465.007131</td>
    </tr>
    <tr>
      <th>12</th>
      <td>16.82</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
      <td>4373.060709</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="summary-statistics-for-tabular-data">
<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames. The describe command provides count, mean, minimum, maximum in a nice data table.</p>
<ul class="simple">
<li><p>we have some negative TOC values! Let‚Äôs check the distribution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                     <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>200.0</td>
      <td>14.991150</td>
      <td>2.971176</td>
      <td>6.550000</td>
      <td>12.912500</td>
      <td>15.070000</td>
      <td>17.40250</td>
      <td>23.550000</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>200.0</td>
      <td>4.330750</td>
      <td>1.731014</td>
      <td>1.130000</td>
      <td>3.122500</td>
      <td>4.035000</td>
      <td>5.28750</td>
      <td>9.870000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>200.0</td>
      <td>2.968850</td>
      <td>0.566885</td>
      <td>1.280000</td>
      <td>2.547500</td>
      <td>2.955000</td>
      <td>3.34500</td>
      <td>4.630000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>200.0</td>
      <td>48.161950</td>
      <td>14.129455</td>
      <td>10.940000</td>
      <td>37.755000</td>
      <td>49.510000</td>
      <td>58.26250</td>
      <td>84.330000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>200.0</td>
      <td>0.990450</td>
      <td>0.481588</td>
      <td>-0.190000</td>
      <td>0.617500</td>
      <td>1.030000</td>
      <td>1.35000</td>
      <td>2.180000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>200.0</td>
      <td>1.964300</td>
      <td>0.300827</td>
      <td>0.930000</td>
      <td>1.770000</td>
      <td>1.960000</td>
      <td>2.14250</td>
      <td>2.870000</td>
    </tr>
    <tr>
      <th>Prod</th>
      <td>200.0</td>
      <td>3842.630027</td>
      <td>1594.301295</td>
      <td>803.640483</td>
      <td>2551.414599</td>
      <td>3626.229052</td>
      <td>4739.73408</td>
      <td>9021.792491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>There are just a couple slightly negative values, let‚Äôs just truncate them at zero. We   can use this command below to set all TOC values in the DataFrame that are less than 0.0 as 0.0, otherwise we keep the original TOC value.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">_get_numeric_data</span><span class="p">()</span>                                  <span class="c1"># get the numerical values</span>
<span class="n">num</span><span class="p">[</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                                              <span class="c1"># truncate negative values to 0.0</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                     <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>200.0</td>
      <td>14.991150</td>
      <td>2.971176</td>
      <td>6.550000</td>
      <td>12.912500</td>
      <td>15.070000</td>
      <td>17.40250</td>
      <td>23.550000</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>200.0</td>
      <td>4.330750</td>
      <td>1.731014</td>
      <td>1.130000</td>
      <td>3.122500</td>
      <td>4.035000</td>
      <td>5.28750</td>
      <td>9.870000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>200.0</td>
      <td>2.968850</td>
      <td>0.566885</td>
      <td>1.280000</td>
      <td>2.547500</td>
      <td>2.955000</td>
      <td>3.34500</td>
      <td>4.630000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>200.0</td>
      <td>48.161950</td>
      <td>14.129455</td>
      <td>10.940000</td>
      <td>37.755000</td>
      <td>49.510000</td>
      <td>58.26250</td>
      <td>84.330000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>200.0</td>
      <td>0.991950</td>
      <td>0.478264</td>
      <td>0.000000</td>
      <td>0.617500</td>
      <td>1.030000</td>
      <td>1.35000</td>
      <td>2.180000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>200.0</td>
      <td>1.964300</td>
      <td>0.300827</td>
      <td>0.930000</td>
      <td>1.770000</td>
      <td>1.960000</td>
      <td>2.14250</td>
      <td>2.870000</td>
    </tr>
    <tr>
      <th>Prod</th>
      <td>200.0</td>
      <td>3842.630027</td>
      <td>1594.301295</td>
      <td>803.640483</td>
      <td>2551.414599</td>
      <td>3626.229052</td>
      <td>4739.73408</td>
      <td>9021.792491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
</section>
<section id="calculate-the-correlation-matrix-and-correlation-with-response-ranking">
<h2>Calculate the Correlation Matrix and Correlation with Response Ranking</h2>
<p>Let‚Äôs perform with correlation analysis. We can calculate and view the correlation matrix and correlation to the response features with these previously declared functions.</p>
<ul class="simple">
<li><p>correlation analysis is based on the assumption of linear relationships, but it is a good start</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">correlation</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>           <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">correlation</span><span class="p">,</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">'Feature Ranking, Correlation with '</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">'Correlation'</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9ccb60421ffa42bec24f02270e0cb19e4ab0827d13308e827a76a7a86b2c0dc6.png" src="../Images/6194a66796a23a77575acb7c89abb176.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/9ccb60421ffa42bec24f02270e0cb19e4ab0827d13308e827a76a7a86b2c0dc6.png"/>
</div>
</div>
<p>Note the 1.0 diagonal resulting from the correlation of each variable with themselves.</p>
<p>This looks good.  There is a mix of correlation magnitudes. Of course, correlation coefficients are limited to degree of linear correlations.</p>
<ul class="simple">
<li><p>Let‚Äôs look at the matrix scatter plot to see the pairwise relationship between the features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pairgrid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">,</span><span class="s1">'Perm'</span><span class="p">,</span><span class="s1">'AI'</span><span class="p">,</span><span class="s1">'Brittle'</span><span class="p">,</span><span class="s1">'TOC'</span><span class="p">,</span><span class="s1">'Prod'</span><span class="p">])</span> <span class="c1"># matrix scatter plots</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_upper</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'k'</span><span class="p">)</span><span class="c1"># Map a density plot to the lower triangle</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span><span class="p">,</span> 
                              <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_levels</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c23ae18eda1e533de50c2330dba444a3862043169ebd7569532055f40e72e5f.png" src="../Images/18798d69cb2a69a3c10006380bba6873.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4c23ae18eda1e533de50c2330dba444a3862043169ebd7569532055f40e72e5f.png"/>
</div>
</div>
</section>
<section id="working-with-only-two-predictor-features">
<h2>Working with Only Two Predictor Features</h2>
<p>Let‚Äôs simplify the problem to 2 predictor features, Porosity and Brittleness to predict Production rate.  By working with only 2 features, it is very easy to visualize the segmentation of the feature space (it is only 2D and can be shown completely on a single plot).</p>
</section>
<section id="standardizing-predictor-features">
<h2>Standardizing Predictor Features</h2>
<p>The k-nearest neighbour method uses a nearest training sample search in feature space (like k-means clustering). To remove the impact feature range from the approach we standardize the features.</p>
<ul class="simple">
<li><p>we will standardize our predictor features to have a mean of zero and a variance of one.</p></li>
<li><p>we use the scikit-learn preprocessing module to simplify this step and provide a convenient and safe reverse transform.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">if1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">if2</span> <span class="o">=</span> <span class="mi">3</span>                                              <span class="c1"># selected predictor features</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>                                 <span class="c1"># instantiate feature standardization method</span>

<span class="n">sel_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">pred</span><span class="p">[</span><span class="n">if1</span><span class="p">],</span><span class="n">pred</span><span class="p">[</span><span class="n">if2</span><span class="p">]]</span>
<span class="n">sel_features</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">+</span> <span class="p">[</span><span class="n">resp</span><span class="p">]</span>

<span class="n">spredlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Standardized '</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">predlabel</span><span class="p">]</span> <span class="c1"># standardized predictors list</span>

<span class="n">sel_spredlabel</span> <span class="o">=</span> <span class="p">[</span><span class="n">spredlabel</span><span class="p">[</span><span class="n">if1</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">spredlabel</span><span class="p">[</span><span class="n">if2</span><span class="p">]]</span> 

<span class="n">sel_spred</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'s'</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">sel_pred</span><span class="p">]</span>           <span class="c1"># standardized predictors list</span>

<span class="n">df</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>
<span class="n">df</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Selected Predictor Features: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sel_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Standardized Selected Predictor Features: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Response Feature: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="n">resp</span><span class="p">]))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Selected Predictor Features: ['Por', 'Brittle']
Standardized Selected Predictor Features: ['sPor', 'sBrittle']
Response Feature: [['Prod']]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Prod</th>
      <th>sPor</th>
      <th>sBrittle</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>1339.165488</td>
      <td>-0.982256</td>
      <td>2.358297</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>3383.979252</td>
      <td>-0.881032</td>
      <td>-0.141332</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>2509.686720</td>
      <td>-0.327677</td>
      <td>1.748113</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>5514.421023</td>
      <td>0.903875</td>
      <td>-0.592585</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>3532.020478</td>
      <td>0.853263</td>
      <td>-2.640962</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let‚Äôs demonstrate the reverse transform from standardized features back to the original features.</p>
<ul class="simple">
<li><p>we won‚Äôt need this in our workflow since the we only need to forward transform the predictor features to train the model and make predictions</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'Backtransformed: </span><span class="se">\n</span><span class="s1">        Por    Brittle'</span><span class="p">)</span>
<span class="n">transform</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_spred</span><span class="p">])[:</span><span class="mi">5</span><span class="p">,:]</span>        <span class="c1"># check the reverse standardization</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Backtransformed: 
        Por    Brittle
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>array([[12.08, 81.4 ],
       [12.38, 46.17],
       [14.02, 72.8 ],
       [17.67, 39.81],
       [17.52, 10.94]])
</pre></div>
</div>
</div>
</div>
<p>We can compare the output above with the original porosity and brittleness. The reverse transform works!</p>
<ul class="simple">
<li><p>We will use this method to return to original feature units when needed.</p></li>
<li><p>In general, the back transformation is not needed for predictor features, well only forward transform the predictor features to make predictions of the response feature.</p></li>
<li><p>In this example, we don‚Äôt need to transform the response feature while building our model. The response feature distribution is well-behaved and there is not theory in k-nearest neighbours that expects a specific range or distribution share for the response feature.</p></li>
</ul>
</section>
<section id="feature-ranges">
<h2>Feature Ranges</h2>
<p>Let‚Äôs set some ranges for plotting. Note for the standardized predictor features we will use -3.5 to 3.5 as the limits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">]</span>                        <span class="c1"># selected predictor features min and max</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-and-test-split">
<h2>Train and Test Split</h2>
<p>For convenience and simplicity we use scikit-learn‚Äôs random train and test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_spred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train DataFrame with both X and y (remove all other features)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># make one testin DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs first check the univariate statistics of Porosity, Brittleness and Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">resplabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a6e3b01d9e6230c6eb26e1b06c604aa2fc175bb399d25bcd7794d5fb4b1b1e46.png" src="../Images/2447bd1e6857b017d16d4197616a3dc1.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/a6e3b01d9e6230c6eb26e1b06c604aa2fc175bb399d25bcd7794d5fb4b1b1e46.png"/>
</div>
</div>
<p>The distributions are well behaved,</p>
<ul class="simple">
<li><p>we cannot observe obvious gaps nor truncations.</p></li>
<li><p>check coverage of the train and test data</p></li>
</ul>
<p>Let‚Äôs look at a scatter plot of Porosity vs. Brittleness with points colored by Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># train data plot</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> 
                 <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Train '</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">resplabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                               <span class="c1"># test data plot</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> 
                 <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Test '</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">resplabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c88383d908cf65a54e1601379bf0b36cdbfab09eeae0ff5cc37587387fd084c.png" src="../Images/0b1f8f8266faddc853479c3aab599c2e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4c88383d908cf65a54e1601379bf0b36cdbfab09eeae0ff5cc37587387fd084c.png"/>
</div>
</div>
<p>This problem looks nonlinear and could not be modeled with simple linear regression.</p>
<ul class="simple">
<li><p>It appears there is a sweet spot for Brittleness and increasing Porosity is always beneficial for Production.</p></li>
</ul>
</section>
<section id="instantiate-fit-and-predict-with-k-nearest-neighbour">
<h2>Instantiate, Fit and Predict with k-nearest Neighbour</h2>
<p>Let‚Äôs instantiate, fit and predict with a k-nearest neighbour model.</p>
<ul class="simple">
<li><p>instantiate it with the hyperparameters, k-nearest neighbours</p></li>
<li><p>train with the training data, we use the standard fit function from scikit-learn</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                 <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>
</pre></div>
</div>
</div>
</div>
<p>We have set the hyperparameters:</p>
<ul class="simple">
<li><p>weights = averaging weights for the prediction given the nearest neighbours. ‚Äòuniform‚Äô is arithmetic average, while ‚Äòdistance‚Äô is inverse distance weighting.</p></li>
<li><p>n_neighbours = maximum number of neighbours. Note, we constrain our prediction by limiting it to 5 nearest neighbours.</p></li>
<li><p>p = distance metric power or Minkowski metric (1 = Manhattan distance, 2 for Euclidian distance) for finding the nearest neighbours.</p></li>
</ul>
<p>Now we are ready to fit our model for prediction of Production given Porosity and Brittleness.</p>
<ul class="simple">
<li><p>We will use our two functions defined above to visualize the k-nearest neighbour prediction over the feature space and the cross plot of actual and estimated production for the training data along with three model metrics from the sklearn.metric module.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="c1"># plt.subplot(223)                                              # model accuracy check</span>
<span class="c1"># check_model(neigh_fit,X_train[sel_spred[0]],X_train[sel_spred[1]],X_test[sel_spred[0]],X_test[sel_spred[1]],ymin,ymax,</span>
<span class="c1">#             y_train[resp[0]],y_test[resp[0]],'K Nearest Neighbour Regression Model Accuracy')</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8687713a2a5e6441f354a7136a11c925434235dd1930a34a508287b1aed9f7e5.png" src="../Images/8a097688955c9a933b8a09894a1a0ea5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8687713a2a5e6441f354a7136a11c925434235dd1930a34a508287b1aed9f7e5.png"/>
</div>
</div>
<p>The model looks good:</p>
<ul class="simple">
<li><p>the nonparametric approach is quite flexible to fit the nonlinear response patterns in the predictor feature space</p></li>
<li><p>we can see some search artifacts due to limited k nearest data and the use of uniform weighting</p></li>
<li><p>we have dense data for this low dimensional problem (only 2 predictor features)</p></li>
<li><p>the testing and training data are consistent and close to each other in the predictor feature space</p></li>
</ul>
<p>Let‚Äôs try to overfit the model by using a very large k hyperparameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'K Nearest Neighbour Regression Model Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/57e183c41e9ee9d084d79c733d18bfe2ce2f5e0504c9b7b75db9ad994fc637cb.png" src="../Images/7a8fad6c8ab65ba24660fe87eb558d34.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/57e183c41e9ee9d084d79c733d18bfe2ce2f5e0504c9b7b75db9ad994fc637cb.png"/>
</div>
</div>
<p>Note that this smoothed out the response, and the predictions are approaching the global mean.</p>
<ul class="simple">
<li><p>we have an underfit model.</p></li>
</ul>
<p>Next let‚Äôs use a smaller k hyperparameter for our k-nearest neighbours prediction model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                  <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'K Nearest Neighbour Regression Model Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/36151afeb7ee7ec97d8f9695513890616f1d619cbc81c9e9a734492d90c1e86f.png" src="../Images/652c1c3e20ca9e893f0cf17db9352459.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/36151afeb7ee7ec97d8f9695513890616f1d619cbc81c9e9a734492d90c1e86f.png"/>
</div>
</div>
<p>Now we have an extreme overfit model.</p>
<ul class="simple">
<li><p>The training MSE is 0.0 and the testing error is quite high.</p></li>
<li><p>Note, some of our predictions in our overfit model are outside the plotting min and max response feature values.</p></li>
</ul>
<p>Let‚Äôs try to use a L1, Manhattan distance to find the k nearest neighbours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                 <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'K Nearest Neighbour Regression Model Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/58118fcb46c0eb738a754ea3e1103828cda85f1f5eea8dc2d12b6e69215213d3.png" src="../Images/3a4e29a43415592363cfc3314ffd6b4b.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/58118fcb46c0eb738a754ea3e1103828cda85f1f5eea8dc2d12b6e69215213d3.png"/>
</div>
</div>
<p>Compare this prediction model to our first model, all we changes is the distance search for the k nearest samples to Manhattan from Euclidean distance.</p>
<ul class="simple">
<li><p>the search artifacts are now aligned on the features (the rays are oriented in the x and y directions)</p></li>
</ul>
</section>
<section id="hyperparameter-tuning-for-k-nearest-neighbours">
<h2>Hyperparameter Tuning for k-Nearest Neighbours</h2>
<p>Let‚Äôs check this out as we tune the hyper parameters.</p>
<p>So what does the <span class="math notranslate nohighlight">\(k\)</span> do?</p>
<ul class="simple">
<li><p>small <span class="math notranslate nohighlight">\(k\)</span> hyperparameter results in a local specific prediction model over the predictor feature space</p></li>
<li><p>large <span class="math notranslate nohighlight">\(k\)</span> hyperparameter results in a more smooth, globally fit prediction model over the predictor features space</p></li>
</ul>
<p>This is analogous to the low to high complexity we have observed with other models (like decision trees).</p>
<ul class="simple">
<li><p>small <span class="math notranslate nohighlight">\(k\)</span> is complex</p></li>
<li><p>large <span class="math notranslate nohighlight">\(k\)</span> is simple</p></li>
</ul>
<p>We need to tune the complexity to optimize model performance.</p>
</section>
<section id="tuning-the-hyperparameters">
<h2>Tuning the Hyperparameters</h2>
<p>Let‚Äôs loop over multiple <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours for average and inverse distance estimates to access the best hyperparameters with respect to accuracy in testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>                                                         <span class="c1"># set initial, lowest k hyperparameter</span>
<span class="n">dist_error</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">unif_error</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">k_mat</span> <span class="o">=</span> <span class="p">[]</span>                  <span class="c1"># make lists to store the results</span>
<span class="k">while</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">150</span><span class="p">:</span>                                               <span class="c1"># loop over the k hyperparameter</span>
    <span class="n">neigh_dist</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># instantiate the model</span>
    <span class="n">neigh_dist_fit</span> <span class="o">=</span> <span class="n">neigh_dist</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>          <span class="c1"># train the model with the training data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh_dist_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>                   <span class="c1"># predict over the testing cases</span>
    <span class="n">MSE</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>           <span class="c1"># calculate the MSE testing</span>
    <span class="n">dist_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                                    <span class="c1"># add to the list of MSE</span>
    
    <span class="n">neigh_unif</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">neigh_unif_fit</span> <span class="o">=</span> <span class="n">neigh_unif</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>          <span class="c1"># train the model with the training data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh_unif_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>                   <span class="c1"># predict over the testing cases</span>
    <span class="n">MSE</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>           <span class="c1"># calculate the MSE testing</span>
    <span class="n">unif_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                                    <span class="c1"># add to the list of MSE</span>
    
    <span class="n">k_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>                                           <span class="c1"># append k to an array for plotting</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>Now let‚Äôs plot the result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">dist_error</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'inverse distance weighted'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">unif_error</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'arithmetic average'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Testing Error vs. Number of Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">750000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01eac05af310de41e5fc30ed84e0dd7ffbc211efc97eea008ec63bd1c8ef9a09.png" src="../Images/fe795ea54d585888e2632307876aaa72.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/01eac05af310de41e5fc30ed84e0dd7ffbc211efc97eea008ec63bd1c8ef9a09.png"/>
</div>
</div>
<p>What can we observe from this result?</p>
<ul class="simple">
<li><p>at <span class="math notranslate nohighlight">\(k = 12\)</span> nearest neighbours we minimize the mean square error in testing.</p></li>
<li><p>we have better performance with the inverse distance weighted than the arithmetic average (uniform weighting of k nearest training data in predictor feature space)</p></li>
</ul>
<p>There is an optimum degree of specificity / complexity to our model.</p>
<ul class="simple">
<li><p>1 nearest neighbour is a very locally specific model (overfit)</p></li>
<li><p>many nearest neighbours includes too much information and is too general (underfit)</p></li>
</ul>
<p>We are observing the accuracy vs. complexity trade-off for the <span class="math notranslate nohighlight">\(k\)</span> nearest neighbour model.</p>
</section>
<section id="k-fold-cross-validation">
<h2>k-fold Cross Validation</h2>
<p>It is useful to evaluate the performance of our model by observing the accuracy vs. complexity trade-off.</p>
<p>Yet, what we really want to do is rigorously test our model performance.  We should perform a more rigorous cross validation that does a better job evaluating over different sets of training and testing data. scikit learn has a built in cross validation method called cross_val_score that we can use to:</p>
<ol class="arabic simple">
<li><p>Apply k-fold approach with iterative separation of training and testing data</p></li>
<li><p>Automate the model construction, looping over folds and averaging the metric of interest</p></li>
</ol>
<p>Let‚Äôs try it out on our k nearest neighbour prediction with variable number of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours.  Note the cross validation is set to use 4 processors, but still will likely take a couple of minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">score</span> <span class="o">=</span> <span class="p">[]</span>                                                  <span class="c1"># code modified from StackOverFlow by Dimosthenis</span>
<span class="n">k_mat</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">150</span><span class="p">):</span>
    <span class="n">neigh_dist</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">neigh_dist</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'sPor'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s1">'sBrittle'</span><span class="p">]],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">'Prod'</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                             <span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span> <span class="c1"># Perform 7-fold cross validation</span>
    <span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">k_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The output is an array of average scores (MSE) over the k-folds for each level of complexity (number of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours), along with an array with the <span class="math notranslate nohighlight">\(k\)</span>s.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'k-fold Cross Validation Error (MSE) vs. k Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">150</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1400000</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3486b059575a23212d8aafc3a96a97665590c325236271232ebf8b699313ea39.png" src="../Images/d79973afda6b57fc45418841e4ff114d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/3486b059575a23212d8aafc3a96a97665590c325236271232ebf8b699313ea39.png"/>
</div>
</div>
<p>With the hyperparameter of 10 nearest neighbours we get the greatest accuracy in k-fold cross validation model testing.</p>
</section>
<section id="predictor-feature-standardization">
<h2>Predictor Feature Standardization</h2>
<p>We have standardized the predictor feature to remove the influence of their ranges.</p>
<ul class="simple">
<li><p>What would happen if we worked with the original predictor features?</p></li>
</ul>
<p>Let‚Äôs try it out.</p>
<ul class="simple">
<li><p>we first apply train and test split with the original features, without standardization</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">y_train_orig</span><span class="p">,</span> <span class="n">y_test_orig</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>

<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">,</span><span class="n">y_train_orig</span><span class="p">)</span>                <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8c3133ce421b3030fdd8a00084845ccd1d24e4e798c75f636c0920eebed4d5c6.png" src="../Images/7c1a8ce67e0629a7c8b0a3ceccdf2686.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8c3133ce421b3030fdd8a00084845ccd1d24e4e798c75f636c0920eebed4d5c6.png"/>
</div>
</div>
<p>Do you see the horizontal banding?  The larger range of magnitudes of brittleness vs. porosity results in this banding.</p>
<ul class="simple">
<li><p>distances in the feature space are more sensitive to the relative changes in brittleness than porosity</p></li>
</ul>
<p>Let‚Äôs convert porosity to a fraction and observe the change in our predictor due to the arbitrary decision to work with porosity as a fraction vs. a percentage.</p>
<ul class="simple">
<li><p>by applying a <span class="math notranslate nohighlight">\(\frac{1}{100}\)</span> factor to all the porosity values.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">y_train_orig</span><span class="p">,</span> <span class="n">y_test_orig</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>

<span class="n">X_train_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">/</span><span class="mf">100.0</span>
<span class="n">X_test_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">/</span><span class="mf">100.0</span>

<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">,</span><span class="n">y_train_orig</span><span class="p">)</span>                <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e98632fa73beaf85be54462502e9cd2b26c6bc804f11e5ba193bd5a17f99b64d.png" src="../Images/bf1f50f1e62336305668f4aff28ac682.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/e98632fa73beaf85be54462502e9cd2b26c6bc804f11e5ba193bd5a17f99b64d.png"/>
</div>
</div>
<ul class="simple">
<li><p>this banding effect gets even more severe as we convert from percentage to fractional porosity, because distances in porosity appear so much closer than in brittleness, just because of the difference in feature ranges.</p></li>
</ul>
<p>Our distance metric for assigning nearest neighbours is quite sensitive to the feature units.  We should always standardize all predictor features (put them on equal footing) before we use them to build our <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbour regression model!</p>
</section>
<section id="k-nearest-neighbour-regression-in-scikit-learn-with-pipelines">
<h2>k Nearest Neighbour Regression in scikit-learn with Pipelines</h2>
<p>The need to standardize features, train, tune and retrain the tuned model with all the data may seem to be a lot of work!</p>
<ul class="simple">
<li><p>one solution is to use the Pipeline object from scikit-learn.</p></li>
</ul>
<p>Here‚Äôs some highlights on Pipelines.</p>
<section id="machine-learning-modeling-pipelines-basics">
<h3>Machine Learning Modeling Pipelines Basics</h3>
<p>Machine learning workflows can be complicated, with various steps:</p>
<ul class="simple">
<li><p>data preparation, feature engineering transformations</p></li>
<li><p>model parameter fitting</p></li>
<li><p>model hyperparameter tuning</p></li>
<li><p>modeling method selection</p></li>
<li><p>searching over a large combinatorial of hyperparameters</p></li>
<li><p>training and testing model runs</p></li>
</ul>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to automate the determination of the best model (AutoML)</p>
</section>
<section id="k-nearest-neighbours-with-pipelines">
<h3>k-Nearest Neighbours with Pipelines</h3>
<p>Here‚Äôs compact, safe code for the entire model training and tuning process with scikit-learn pipelines</p>
<ul class="simple">
<li><p>the GridSearchCV object actually becomes the prediction model, with tuned hyperparameters retrained on all of the data!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>

<span class="n">folds</span> <span class="o">=</span> <span class="mi">4</span>                                                   <span class="c1"># number of k folds</span>
<span class="n">k_min</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">k_max</span> <span class="o">=</span> <span class="mi">150</span>                                       <span class="c1"># range of k hyperparameter to consider</span>

<span class="n">X_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span>                                 <span class="c1"># all the samples for the original features</span>
<span class="n">y_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>                             <span class="c1"># warning this becomes a series, 1D ndarray with label</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>                                           <span class="c1"># the machine learning workflow as a pipeline object</span>
    <span class="p">(</span><span class="s1">'scaler'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">'knear'</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>                                                  <span class="c1"># the machine learning workflow method's parameters</span>
    <span class="s1">'scaler'</span><span class="p">:</span> <span class="p">[</span><span class="n">StandardScaler</span><span class="p">()],</span>
    <span class="s1">'knear__n_neighbors'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">),</span>
    <span class="s1">'knear__metric'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'euclidean'</span><span class="p">],</span>
    <span class="s1">'knear__p'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
    <span class="s1">'knear__weights'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'distance'</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_cv_tuned</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">'neg_mean_squared_error'</span><span class="p">,</span> <span class="c1"># grid search cross validation </span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                             <span class="n">refit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pipe</span><span class="p">,</span><span class="n">y_pipe</span><span class="p">)</span>                                      <span class="c1"># fit model with tuned hyperparameters</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">visualize_tuned_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">'knear__n_neighbors'</span><span class="p">],</span> <span class="c1"># visualize the error vs. k </span>
                      <span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'param_knear__n_neighbors'</span><span class="p">],</span>
                      <span class="nb">abs</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'mean_test_score'</span><span class="p">]))</span>              

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                            <span class="c1"># visualize the tuned model</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'All Data and Tuned and Retrained k-Nearest Neighbours'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png" src="../Images/4cddeaa35cf9ea49e9a36b802755dc3a.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png"/>
</div>
</div>
</section>
<section id="check-the-tuned-hyperparameters">
<h3>Check the Tuned Hyperparameters</h3>
<p>In the GridSearchCV model object, there is a built in dictionary called best_params_ that includes all the tuned hyperparameters.</p>
<ul class="simple">
<li><p>note, over the range of k‚Äôs the selected k, n_neighbors</p></li>
<li><p>also, the other hyperparameters were specified, but we could have provided a range and scenarios for each to explore with the grid search method</p></li>
</ul>
<p>When tuning more than 1 hyperparameter, the runtime will increase with the combinatorial of hyperparameters and the resulting model loss function, e.g., cv_results_[‚Äòmean_test_score‚Äô], is sorted over all the hyperparameter cases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>{'knear__metric': 'euclidean',
 'knear__n_neighbors': 11,
 'knear__p': 2,
 'knear__weights': 'distance',
 'scaler': StandardScaler()}
</pre></div>
</div>
</div>
</div>
<p>It is also useful to look at the entire model object for more information. Including:</p>
<ul class="simple">
<li><p>the pipeline and all cases considered for the hyperparameter tuning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">grid_cv_tuned</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "‚ñ∏";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "‚ñæ";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[('scaler', StandardScaler()),
                                       ('knear', KNeighborsRegressor())]),
             param_grid={'knear__metric': ['euclidean'],
                         'knear__n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         'knear__p': [2], 'knear__weights': ['distance'],
                         'scaler': [StandardScaler()]},
             scoring='neg_mean_squared_error')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"/><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[('scaler', StandardScaler()),
                                       ('knear', KNeighborsRegressor())]),
             param_grid={'knear__metric': ['euclidean'],
                         'knear__n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         'knear__p': [2], 'knear__weights': ['distance'],
                         'scaler': [StandardScaler()]},
             scoring='neg_mean_squared_error')</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"/><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('scaler', StandardScaler()), ('knear', KNeighborsRegressor())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"/><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"/><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsRegressor</label><div class="sk-toggleable__content"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
</section>
</section>
<section id="comments">
<h2>Comments</h2>
<p>This was a basic treatment of k-nearest neighbours. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
</section>
<section id="about-the-author">
<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
</section>
<section id="want-to-work-together">
<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
</section>
<section id="more-resources-available-at-twitter-github-website-googlescholar-book-youtube-applied-geostats-in-python-e-book-linkedin">
<h2>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></h2>
</section>
&#13;

<h2>Motivations for k-nearest Neighbours Regression</h2>
<p>There are many good reasons to cover k-nearest neighbours regression. In addition to being a simple, interpretable and flexible predictive machine learning model, it also demonstrates important concepts,</p>
<ul class="simple">
<li><p><strong>non-parametric predictive model</strong> - that learns the form of the relationships from the data, i.e., no prior assumption about the form of the relationship</p></li>
<li><p><strong>instance-based, lazy learning</strong> - model training is postponed until prediction is required, no precalculation of the model. i.e., prediction requires access to the data</p></li>
<li><p><strong>hyperparameter tuning</strong> - with a understandable hyperparameters that control model fit</p></li>
<li><p><strong>very flexible, versatile predictive model</strong> - performs well in many situations</p></li>
</ul>
&#13;

<h2>Convolution</h2>
<p>In fact, k-nearest neighbours is analogous to spatial estimation through weighted averaging within a local neighbourhood.</p>
<figure style="text-align: center;">
  <img src="../Images/0cfb5694654b0332a568b81d0ae25755.png" style="display: block; margin: 0 auto; width: 50%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/knearest/spatial_interpolation.png"/>
  <figcaption style="text-align: center;">Prediction modeling a spatial interpolation in predictor feature space.</figcaption>
</figure>
<p>The k-nearest neighbours approach is similar to a convolution approach for spatial interpolation. Convolution is the integral product of two functions, after one is reversed and shifted by <span class="math notranslate nohighlight">\(\tau\)</span>.</p>
<ul class="simple">
<li><p>one interpretation is smoothing a function with weighting function, <span class="math notranslate nohighlight">\(ùëì(\Delta)\)</span>, is applied to calculate the weighted average of function, <span class="math notranslate nohighlight">\(ùëî(x)\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ 
(f * g)(x) = \int_{-\infty}^{\infty} f(\tau) g(x - \tau) \, d\tau 
\]</div>
<p>this easily extends into multidimensional</p>
<div class="math notranslate nohighlight">
\[
(f * g)(x, y, z) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(\tau_x, \tau_y, \tau_z) g(x - \tau_x, y - \tau_y, z - \tau_z) \, d\tau_x \, d\tau_y \, d\tau_z
\]</div>
<p>The choice of which function is shifted before integration does not change the result, the convolution operator has commutativity,</p>
<div class="math notranslate nohighlight">
\[ 
(f * g)(x) = \int_{-\infty}^{\infty} f(\tau) g(x - \tau) \, d\tau 
\]</div>
<div class="math notranslate nohighlight">
\[
(f * g)(x) = \int_{-\infty}^{\infty} f(x - \tau) g(\tau) \, d\tau 
\]</div>
<ul class="simple">
<li><p>if either function is reflected then convolution is equivalent to cross-correlation, measure of similarity between 2 signals as a function of displacement.</p></li>
</ul>
<p>To demonstrate convolution with an exhaustive <span class="math notranslate nohighlight">\(g(x)\)</span> and sparsely sampled <span class="math notranslate nohighlight">\(g(x)\)</span> I built out an <a class="reference external" href="https://github.com/GeostatsGuy/DataScienceInteractivePython/blob/main/Interactive_Convolution_kNearest.ipynb">interactive Python convolution dashboard</a>,</p>
<figure style="text-align: center;">
  <img src="../Images/f55c37e0f7da98a233affd5fbd5ba38c.png" style="display: block; margin: 0 auto; width: 100%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/knearest/interactive_convolution.png"/>
  <figcaption style="text-align: center;">Interactive Python dashboard to demonstrate convolution.</figcaption>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">scipy.ndimage</span> <span class="kn">import</span> <span class="n">convolve1d</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">73073</span>                                                  <span class="c1"># random number seed</span>

<span class="n">kr</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">kloc</span> <span class="o">=</span> <span class="mi">45</span>                                             <span class="c1"># kernel radius, kernel location for example point</span>

<span class="n">df_denpor</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/1D_por_perm_smooth.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub </span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                    
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">],</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'f(x)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Exhaustive Case: Original and Convolved Function'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kr</span> <span class="o">+</span> <span class="mi">1</span>                                             <span class="c1"># make uniform kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span>                                 <span class="c1"># normalize kernel to sum to one for unbiasedness</span>

<span class="n">convolved</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'same'</span><span class="p">)</span> <span class="c1"># convolution</span>

<span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">trim</span> <span class="o">=</span> <span class="n">k</span> <span class="o">//</span> <span class="mi">2</span>  <span class="c1"># how many values to trim from each edge</span>
<span class="n">convolved_valid</span> <span class="o">=</span> <span class="n">convolved</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">convolved</span>
<span class="n">depth_valid</span> <span class="o">=</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">convolved_pt</span> <span class="o">=</span> <span class="n">convolved_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()];</span> <span class="n">depth_pt</span> <span class="o">=</span> <span class="n">depth_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">convolved_valid</span><span class="p">,</span><span class="n">depth_valid</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$(f * g)(x)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">convolved_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$g(\tau)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Kernel'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Weight (unitless)'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/58f0d6ec82ae506386975d87b4fbaa3fa88f321e3ef516e9f956402a156d2751.png" src="../Images/83364c0e2e061f041cd64b882996eb7e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/58f0d6ec82ae506386975d87b4fbaa3fa88f321e3ef516e9f956402a156d2751.png"/>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">astropy.convolution.convolve</span> <span class="k">as</span> <span class="nn">convolve</span>               <span class="c1"># sparse data convolution</span>
<span class="n">frac</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por_Sparse'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
<span class="n">nan_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">frac</span><span class="p">)),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df_denpor</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">nan_indices</span><span class="p">,</span> <span class="s1">'Por_Sparse'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                    
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por_Sparse'</span><span class="p">],</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'f(x) Sparse'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">],</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'f(x) Exhaustive'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">26</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Sparse Case: Original and Convolved Function'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kr</span> <span class="o">+</span> <span class="mi">1</span>                                             <span class="c1"># make uniform kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span>                                 <span class="c1"># normalize kernel to sum to one for unbiasedness</span>

<span class="n">convolved</span> <span class="o">=</span> <span class="n">convolve</span><span class="p">(</span><span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Por_Sparse'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">boundary</span><span class="o">=</span><span class="s1">'extend'</span><span class="p">,</span><span class="n">nan_treatment</span><span class="o">=</span><span class="s1">'interpolate'</span><span class="p">,</span><span class="n">normalize_kernel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># convolve</span>

<span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">trim</span> <span class="o">=</span> <span class="n">k</span> <span class="o">//</span> <span class="mi">2</span>  <span class="c1"># how many values to trim from each edge</span>
<span class="n">convolved_valid</span> <span class="o">=</span> <span class="n">convolved</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">convolved</span>
<span class="n">depth_valid</span> <span class="o">=</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">trim</span><span class="p">:</span><span class="o">-</span><span class="n">trim</span><span class="p">]</span> <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">df_denpor</span><span class="p">[</span><span class="s1">'Depth'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">convolved_pt</span> <span class="o">=</span> <span class="n">convolved_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()];</span> <span class="n">depth_pt</span> <span class="o">=</span> <span class="n">depth_valid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">depth_valid</span> <span class="o">-</span> <span class="n">kloc</span><span class="p">)</span><span class="o">.</span><span class="n">argmin</span><span class="p">()]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">convolved_valid</span><span class="p">,</span><span class="n">depth_valid</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$(f * g)(x)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Porosity (%)'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">22</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">convolved_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$g(\tau)$'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">]);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">,</span><span class="n">kr</span><span class="o">+</span><span class="n">kloc</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Kernel'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.35</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],[</span><span class="n">depth_pt</span><span class="p">,</span><span class="n">depth_pt</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">'--'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Depth (m)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Weight (unitless)'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>WARNING: nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this. [astropy.convolution.convolve]
</pre></div>
</div>
<img alt="_images/ae797e2e907bd48f0c7b524dd697136f6a863602289a91dc8e372c930f4a72c1.png" src="../Images/2eab3ef179c50a4d663c4b21d6e38124.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/ae797e2e907bd48f0c7b524dd697136f6a863602289a91dc8e372c930f4a72c1.png"/>
</div>
</div>
<p>While it is useful to review and discuss convolution, k-nearest neighbours departs from convolution with the specification of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours to include in the weighted average,</p>
<ul class="simple">
<li><p>specifying <span class="math notranslate nohighlight">\(k\)</span> results in a locally adaptive window size, the local neighbourhood extends far enough to find <span class="math notranslate nohighlight">\(k\)</span> training data</p></li>
</ul>
<figure style="text-align: center;">
  <img src="../Images/2ffab60ca866a945ae26ac4aab566a02.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/knearest/adaptive_window.png"/>
  <figcaption style="text-align: center;">For a given $k$ number of nearest neighbours data are collected from farther away in sparse data regions of the predictor feature space.</figcaption>
</figure>
&#13;

<h2>k-nearest Neighbours Hyperparameters</h2>
<p>Now let‚Äôs discuss the k-nearest neighbours hyperparameters.</p>
<ol class="arabic simple">
<li><p><strong>k number of nearest data</strong> - to utilize for prediction</p></li>
<li><p><strong>data weighting</strong> - for example uniform weighting (use local training data average), inverse distance weighting</p></li>
</ol>
<p>Note, for the case of inverse distance weighting, the method is analogous to inverse distance weighted interpolation with a maximum number of local data constraint commonly applied for spatial interpolation. Inverse distance is available in GeostatsPy for spatial mapping.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Distance Metric</strong> - training data within the predictor feature space are ranked by distance, closest to farthest, a variety of distance metrics may be applied, including:</p></li>
</ol>
<ul class="simple">
<li><p>Euclidian distance</p></li>
</ul>
<p>\begin{equation}<br/>
d_i = \sqrt{\sum_{\alpha = 1}^{m} \left(x_{\alpha,i} - x_{\alpha,0}\right)^2}
\end{equation}</p>
<ul class="simple">
<li><p>Minkowski Distance - a generalized form of distance with well-known Manhattan and Euclidean distances are special cases,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
d_{(i,i')} = \left( \sum_{j=1}^{m} \left( x_{(j,i)} - x_{(j,i')} \right)^p \right)^{\frac{1}{p}}
\]</div>
<ul class="simple">
<li><p>when <span class="math notranslate nohighlight">\(p=2\)</span>, this becomes the Euclidean distance</p></li>
<li><p>when <span class="math notranslate nohighlight">\(p=1\)</span> it becomes the Manhattan distance</p></li>
</ul>
&#13;

<h2>Load the Required Libraries</h2>
<p>We will also need some standard packages. These should have been installed with Anaconda 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="o">%</span><span class="k">matplotlib</span> inline                                         
<span class="n">suppress_warnings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>
<span class="kn">import</span> <span class="nn">math</span>                                                   <span class="c1"># square root operator</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                            <span class="c1"># arrays and matrix math</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>                                      <span class="c1"># statistical methods</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                                           <span class="c1"># DataFrames</span>
<span class="kn">import</span> <span class="nn">pandas.plotting</span> <span class="k">as</span> <span class="nn">pd_plot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                               <span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="p">(</span><span class="n">MultipleLocator</span><span class="p">,</span><span class="n">AutoMinorLocator</span><span class="p">,</span><span class="n">FuncFormatter</span><span class="p">)</span> <span class="c1"># control of axes ticks</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>                  <span class="c1"># custom color maps</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>                                         <span class="c1"># for matrix scatter plots</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>              <span class="c1"># standardize the features</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>             <span class="c1"># for nearest k neighbours</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                                   <span class="c1"># measures to check our models</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">cross_val_score</span><span class="p">,</span><span class="n">train_test_split</span><span class="p">,</span><span class="n">GridSearchCV</span><span class="p">,</span><span class="n">KFold</span><span class="p">)</span> <span class="c1"># model tuning</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">,</span><span class="n">make_pipeline</span><span class="p">)</span>         <span class="c1"># machine learning modeling pipeline</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>                     <span class="c1"># custom displays</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>                                         <span class="c1"># default color bar, no bias and friendly for color vision defeciency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">axisbelow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>                                <span class="c1"># grid behind plotting elements</span>
<span class="k">if</span> <span class="n">suppress_warnings</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>  
    <span class="kn">import</span> <span class="nn">warnings</span>                                           <span class="c1"># suppress any warnings for this demonstration</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span> 
<span class="n">seed</span> <span class="o">=</span> <span class="mi">13</span>                                                     <span class="c1"># random number seed for workflow repeatability</span>
</pre></div>
</div>
</div>
</div>
<p>If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing ‚Äòpython -m pip install [package-name]‚Äô. More assistance is available with the respective package docs.</p>
&#13;

<h2>Declare Functions</h2>
<p>Let‚Äôs define a couple of functions to streamline plotting correlation matrices, visualization of a decision tree regression model, and the addition specified percentiles and major and minor gridlines to our plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">comma_format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span>

<span class="k">def</span> <span class="nf">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">,</span><span class="n">nominal</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">ylabel</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span> <span class="c1"># feature ranking plot</span>
    <span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">);</span> <span class="n">mask_low</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">-</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">nominal</span><span class="o">-</span><span class="n">mmin</span><span class="p">);</span> <span class="n">mask_high</span> <span class="o">=</span> <span class="n">nominal</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="p">(</span><span class="n">mmax</span><span class="o">-</span><span class="n">nominal</span><span class="p">);</span> <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">metric</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span><span class="s1">'r--'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'dodgerblue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">mpred</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">nominal</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'lightcoral'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_low</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&lt;</span> <span class="n">mask_low</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mpred</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">mpred</span><span class="p">,</span><span class="n">mask_high</span><span class="p">),</span><span class="n">metric</span><span class="p">,</span><span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="n">mask_high</span><span class="p">),</span><span class="n">interpolate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Predictor Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">mmin</span><span class="p">,</span><span class="n">mmax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">1.5</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">();</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">limits</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>                 <span class="c1"># plots a graphical correlation matrix </span>
    <span class="n">my_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'RdBu_r'</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>          
    <span class="n">newcolors</span> <span class="o">=</span> <span class="n">my_colormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="n">white</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">white_low</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">-</span> <span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">);</span> <span class="n">white_high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span><span class="o">+</span><span class="n">mask</span><span class="o">*</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">newcolors</span><span class="p">[</span><span class="n">white_low</span><span class="p">:</span><span class="n">white_high</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">white</span>                <span class="c1"># mask all correlations less than abs(0.8)</span>
    <span class="n">newcmp</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">newcolors</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">*</span><span class="n">limits</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">limits</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">newcmp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_label_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],[</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="mf">0.5</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="n">m</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span>
    
<span class="k">def</span> <span class="nf">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xfeature</span><span class="p">,</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">,</span><span class="n">response</span><span class="p">,</span><span class="n">z_min</span><span class="p">,</span><span class="n">z_max</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">axes_commas</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span> <span class="c1"># plots the data points and the decision tree prediction </span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">cmap_temp</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span>
    <span class="n">xplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span><span class="o">-</span><span class="n">x_min</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">;</span> <span class="n">yplot_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_max</span><span class="o">-</span><span class="n">y_min</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">xplot_step</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">yplot_step</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">z_min</span><span class="p">,</span> <span class="n">z_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> 
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xfeature</span><span class="p">,</span><span class="n">yfeature</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'white'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_temp</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">z_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">z_max</span><span class="p">,</span> 
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xfeature</span><span class="o">.</span><span class="n">name</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">yfeature</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">);</span> <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">axes_commas</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Z</span>
    
<span class="k">def</span> <span class="nf">visualize_tuned_model</span><span class="p">(</span><span class="n">k_tuned</span><span class="p">,</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score_mat</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score_mat</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> 
                <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">k_tuned</span><span class="p">,</span><span class="n">k_tuned</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000000</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),</span><span class="n">label</span><span class="o">=</span><span class="s1">'tuned'</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'k-fold Cross Validation Error (MSE) vs. k Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Nearest Neighbours'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">score_mat</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">check_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">rtrain</span><span class="p">,</span><span class="n">rtest</span><span class="p">,</span><span class="n">title</span><span class="p">):</span> <span class="c1"># plots the estimated vs. the actual  </span>
    <span class="n">predict_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">])</span>
    <span class="n">predict_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'darkorange'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rtest</span><span class="p">,</span><span class="n">predict_test</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Actual Production (MCFPD)'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimated Production (MCFPD)'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span><span class="n">head_length</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">head_width</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">MSE_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">)</span>
    <span class="n">Var_Explained_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">)</span>
    <span class="n">cor_train</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">rtrain</span><span class="p">,</span><span class="n">predict_train</span><span class="p">))</span>
    <span class="n">MSE_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">rtest</span><span class="p">,</span><span class="n">predict_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Train MSE: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_train</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span><span class="p">),[</span><span class="mf">0.05</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">,</span><span class="mf">0.95</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">])</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Test MSE:  '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">MSE_test</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span><span class="p">),[</span><span class="mf">0.05</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">,</span><span class="mf">0.90</span><span class="o">*</span><span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">+</span><span class="n">ymin</span><span class="p">])</span>
    <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
    <span class="c1"># print('Mean Squared Error on Training = ', round(MSE_test,2),', Variance Explained =', round(Var_Explained,2),'Cor =', round(cor,2))</span>

<span class="k">def</span> <span class="nf">weighted_percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">perc</span><span class="p">):</span>                 <span class="c1"># calculate weighted percentile (iambr on StackOverflow @ https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy/32216049) </span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> 
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> 
    <span class="n">cdf</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">perc</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">histogram_bounds</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">color</span><span class="p">):</span>                   <span class="c1"># add uncertainty bounds to a histogram          </span>
    <span class="n">p10</span> <span class="o">=</span> <span class="n">weighted_percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="mf">0.1</span><span class="p">);</span> <span class="n">avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">);</span> <span class="n">p90</span> <span class="o">=</span> <span class="n">weighted_percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p10</span><span class="p">,</span><span class="n">p10</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">avg</span><span class="p">,</span><span class="n">avg</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p90</span><span class="p">,</span><span class="n">p90</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">45</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">add_grid</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="c1"># add y grids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s1">'minor'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">());</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_minor_locator</span><span class="p">(</span><span class="n">AutoMinorLocator</span><span class="p">())</span> <span class="c1"># turn on minor ticks </span>

<span class="k">def</span> <span class="nf">display_sidebyside</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>                                <span class="c1"># display DataFrames side-by-side (ChatGPT 4.0 generated Spet, 2024)</span>
    <span class="n">html_str</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">html_str</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>  <span class="c1"># Using .head() for the first few rows</span>
    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s1">'&lt;div style="display: flex;"&gt;</span><span class="si">{</span><span class="n">html_str</span><span class="si">}</span><span class="s1">&lt;/div&gt;'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Set the Working Directory</h2>
<p>I always like to do this so I don‚Äôt lose files and to simplify subsequent read and writes (avoid including the full address each time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="c1">#os.chdir("c:/PGE383")                                        # set the working directory</span>
</pre></div>
</div>
</div>
</div>
<p>You will have to update the part in quotes with your own working directory and the format is different on a Mac (e.g. ‚Äú~/PGE‚Äù).</p>
&#13;

<h2>Loading Tabular Data</h2>
<p>Here‚Äôs the command to load our comma delimited data file in to a Pandas‚Äô DataFrame object.</p>
<p>Let‚Äôs load the provided multivariate, spatial dataset ‚Äòunconv_MV.csv‚Äô. This dataset has variables from 1,000 unconventional wells including:</p>
<ul class="simple">
<li><p>well average porosity</p></li>
<li><p>log transform of permeability (to linearize the relationships with other variables)</p></li>
<li><p>acoustic impedance (kg/m^3 x m/s x 10^6)</p></li>
<li><p>brittleness ratio (%)</p></li>
<li><p>total organic carbon (%)</p></li>
<li><p>vitrinite reflectance (%)</p></li>
<li><p>initial production 90 day average (MCFPD).</p></li>
</ul>
<p>Note, the dataset is synthetic.</p>
<p>We load it with the pandas ‚Äòread_csv‚Äô function into a DataFrame we called ‚Äòmy_data‚Äô and then preview it to make sure it loaded correctly.</p>
&#13;

<h2>Optional: Add Random Noise to the Response Feature</h2>
<p>We can do this to observe the impact of data noise on overfit and hyperparameter tuning.</p>
<ul class="simple">
<li><p>This is for experiential learning, of course we wouldn‚Äôt add random noise to our data</p></li>
<li><p>We set the random number seed for reproducibility</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df_load</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv'</span><span class="p">)</span> <span class="c1"># load data from Dr. Pyrcz's GitHub  </span>
<span class="n">df_load</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span>                                 <span class="c1"># copy all rows and columns 1 through 8, note 0 column is removed</span>

<span class="n">response</span> <span class="o">=</span> <span class="s1">'Prod'</span>                                             <span class="c1"># specify the response feature</span>
<span class="n">add_noise</span> <span class="o">=</span> <span class="kc">True</span>                                              <span class="c1"># set True to add noise to response feature to demonstrate overfit</span>
<span class="n">noise_stdev</span> <span class="o">=</span> <span class="mi">500</span>                                             <span class="c1"># amount of noise to add to response feature to demonstrate overfit</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>                                   <span class="c1"># set the random number seed</span>
<span class="k">if</span> <span class="n">add_noise</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">df_load</span><span class="p">[</span><span class="n">response</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_load</span><span class="p">[</span><span class="n">response</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">noise_stdev</span><span class="p">,</span><span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_load</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">response</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="s1">'columns'</span><span class="p">)</span>                         <span class="c1"># make predictor and response DataFrames</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_load</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">response</span><span class="p">]</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>               <span class="c1"># store the names of the features</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">resp</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

<span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">24.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">85.0</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">2.9</span><span class="p">]</span> <span class="c1"># set the minumum and maximum values for plotting</span>
<span class="n">ymin</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">;</span> <span class="n">ymax</span> <span class="o">=</span> <span class="mf">9000.0</span>

<span class="n">predlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity (%)'</span><span class="p">,</span><span class="s1">'Permeability (mD)'</span><span class="p">,</span><span class="s1">'Acoustic Impedance (kg/m2s*10^6)'</span><span class="p">,</span><span class="s1">'Brittleness Ratio (%)'</span><span class="p">,</span> <span class="c1"># set the names for plotting</span>
             <span class="s1">'Total Organic Carbon (%)'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance (%)'</span><span class="p">]</span>
<span class="n">resplabel</span> <span class="o">=</span> <span class="s1">'Normalized Initial Production (MCFPD)'</span>

<span class="n">predtitle</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Porosity'</span><span class="p">,</span><span class="s1">'Permeability'</span><span class="p">,</span><span class="s1">'Acoustic Impedance'</span><span class="p">,</span><span class="s1">'Brittleness Ratio'</span><span class="p">,</span> <span class="c1"># set the units for plotting</span>
             <span class="s1">'Total Organic Carbon'</span><span class="p">,</span><span class="s1">'Vitrinite Reflectance'</span><span class="p">]</span>
<span class="n">resptitle</span> <span class="o">=</span> <span class="s1">'Initial Production'</span>

<span class="n">featurelabel</span> <span class="o">=</span> <span class="n">predlabel</span> <span class="o">+</span> <span class="p">[</span><span class="n">resplabel</span><span class="p">]</span>                        <span class="c1"># make feature labels and titles for concise code</span>
<span class="n">featuretitle</span> <span class="o">=</span> <span class="n">predtitle</span> <span class="o">+</span> <span class="p">[</span><span class="n">resptitle</span><span class="p">]</span>

<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">mpred</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># make one DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Visualize the DataFrame</h2>
<p>Visualizing the DataFrame is useful first check of the data.</p>
<ul class="simple">
<li><p>many things can go wrong, e.g., we loaded the wrong data, all the features did not load, etc.</p></li>
</ul>
<p>We can preview by utilizing the ‚Äòhead‚Äô DataFrame member function (with a nice and clean format, see below).</p>
<ul class="simple">
<li><p>add parameter ‚Äòn=13‚Äô to see the first 13 rows of the dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Prod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>1339.165488</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>3383.979252</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>2509.686720</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>5514.421023</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>3532.020478</td>
    </tr>
    <tr>
      <th>5</th>
      <td>14.53</td>
      <td>4.81</td>
      <td>2.69</td>
      <td>53.60</td>
      <td>0.94</td>
      <td>1.67</td>
      <td>4283.543382</td>
    </tr>
    <tr>
      <th>6</th>
      <td>13.49</td>
      <td>3.60</td>
      <td>2.93</td>
      <td>63.71</td>
      <td>0.80</td>
      <td>1.85</td>
      <td>3627.906723</td>
    </tr>
    <tr>
      <th>7</th>
      <td>11.58</td>
      <td>3.03</td>
      <td>3.25</td>
      <td>53.00</td>
      <td>0.69</td>
      <td>1.93</td>
      <td>3101.539533</td>
    </tr>
    <tr>
      <th>8</th>
      <td>12.52</td>
      <td>2.72</td>
      <td>2.43</td>
      <td>65.77</td>
      <td>0.95</td>
      <td>1.98</td>
      <td>3213.391047</td>
    </tr>
    <tr>
      <th>9</th>
      <td>13.25</td>
      <td>3.94</td>
      <td>3.71</td>
      <td>66.20</td>
      <td>1.14</td>
      <td>2.65</td>
      <td>2200.204701</td>
    </tr>
    <tr>
      <th>10</th>
      <td>15.04</td>
      <td>4.39</td>
      <td>2.22</td>
      <td>61.11</td>
      <td>1.08</td>
      <td>1.77</td>
      <td>3433.752662</td>
    </tr>
    <tr>
      <th>11</th>
      <td>16.19</td>
      <td>6.30</td>
      <td>2.29</td>
      <td>49.10</td>
      <td>1.53</td>
      <td>1.86</td>
      <td>4465.007131</td>
    </tr>
    <tr>
      <th>12</th>
      <td>16.82</td>
      <td>5.42</td>
      <td>2.80</td>
      <td>66.65</td>
      <td>1.17</td>
      <td>1.98</td>
      <td>4373.060709</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
&#13;

<h2>Summary Statistics for Tabular Data</h2>
<p>There are a lot of efficient methods to calculate summary statistics from tabular data in DataFrames. The describe command provides count, mean, minimum, maximum in a nice data table.</p>
<ul class="simple">
<li><p>we have some negative TOC values! Let‚Äôs check the distribution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                     <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>200.0</td>
      <td>14.991150</td>
      <td>2.971176</td>
      <td>6.550000</td>
      <td>12.912500</td>
      <td>15.070000</td>
      <td>17.40250</td>
      <td>23.550000</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>200.0</td>
      <td>4.330750</td>
      <td>1.731014</td>
      <td>1.130000</td>
      <td>3.122500</td>
      <td>4.035000</td>
      <td>5.28750</td>
      <td>9.870000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>200.0</td>
      <td>2.968850</td>
      <td>0.566885</td>
      <td>1.280000</td>
      <td>2.547500</td>
      <td>2.955000</td>
      <td>3.34500</td>
      <td>4.630000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>200.0</td>
      <td>48.161950</td>
      <td>14.129455</td>
      <td>10.940000</td>
      <td>37.755000</td>
      <td>49.510000</td>
      <td>58.26250</td>
      <td>84.330000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>200.0</td>
      <td>0.990450</td>
      <td>0.481588</td>
      <td>-0.190000</td>
      <td>0.617500</td>
      <td>1.030000</td>
      <td>1.35000</td>
      <td>2.180000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>200.0</td>
      <td>1.964300</td>
      <td>0.300827</td>
      <td>0.930000</td>
      <td>1.770000</td>
      <td>1.960000</td>
      <td>2.14250</td>
      <td>2.870000</td>
    </tr>
    <tr>
      <th>Prod</th>
      <td>200.0</td>
      <td>3842.630027</td>
      <td>1594.301295</td>
      <td>803.640483</td>
      <td>2551.414599</td>
      <td>3626.229052</td>
      <td>4739.73408</td>
      <td>9021.792491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>There are just a couple slightly negative values, let‚Äôs just truncate them at zero. We   can use this command below to set all TOC values in the DataFrame that are less than 0.0 as 0.0, otherwise we keep the original TOC value.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">_get_numeric_data</span><span class="p">()</span>                                  <span class="c1"># get the numerical values</span>
<span class="n">num</span><span class="p">[</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                                              <span class="c1"># truncate negative values to 0.0</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>                                     <span class="c1"># calculate summary statistics for the data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Por</th>
      <td>200.0</td>
      <td>14.991150</td>
      <td>2.971176</td>
      <td>6.550000</td>
      <td>12.912500</td>
      <td>15.070000</td>
      <td>17.40250</td>
      <td>23.550000</td>
    </tr>
    <tr>
      <th>Perm</th>
      <td>200.0</td>
      <td>4.330750</td>
      <td>1.731014</td>
      <td>1.130000</td>
      <td>3.122500</td>
      <td>4.035000</td>
      <td>5.28750</td>
      <td>9.870000</td>
    </tr>
    <tr>
      <th>AI</th>
      <td>200.0</td>
      <td>2.968850</td>
      <td>0.566885</td>
      <td>1.280000</td>
      <td>2.547500</td>
      <td>2.955000</td>
      <td>3.34500</td>
      <td>4.630000</td>
    </tr>
    <tr>
      <th>Brittle</th>
      <td>200.0</td>
      <td>48.161950</td>
      <td>14.129455</td>
      <td>10.940000</td>
      <td>37.755000</td>
      <td>49.510000</td>
      <td>58.26250</td>
      <td>84.330000</td>
    </tr>
    <tr>
      <th>TOC</th>
      <td>200.0</td>
      <td>0.991950</td>
      <td>0.478264</td>
      <td>0.000000</td>
      <td>0.617500</td>
      <td>1.030000</td>
      <td>1.35000</td>
      <td>2.180000</td>
    </tr>
    <tr>
      <th>VR</th>
      <td>200.0</td>
      <td>1.964300</td>
      <td>0.300827</td>
      <td>0.930000</td>
      <td>1.770000</td>
      <td>1.960000</td>
      <td>2.14250</td>
      <td>2.870000</td>
    </tr>
    <tr>
      <th>Prod</th>
      <td>200.0</td>
      <td>3842.630027</td>
      <td>1594.301295</td>
      <td>803.640483</td>
      <td>2551.414599</td>
      <td>3626.229052</td>
      <td>4739.73408</td>
      <td>9021.792491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is good that we checked the summary statistics.</p>
<ul class="simple">
<li><p>there are no obvious issues</p></li>
<li><p>check out the range of values for each feature to set up and adjust plotting limits. See above.</p></li>
</ul>
&#13;

<h2>Calculate the Correlation Matrix and Correlation with Response Ranking</h2>
<p>Let‚Äôs perform with correlation analysis. We can calculate and view the correlation matrix and correlation to the response features with these previously declared functions.</p>
<ul class="simple">
<li><p>correlation analysis is based on the assumption of linear relationships, but it is a good start</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">correlation</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_corr</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span><span class="s1">'Correlation Matrix'</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>           <span class="c1"># using our correlation matrix visualization function</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">feature_rank_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">correlation</span><span class="p">,</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="s1">'Feature Ranking, Correlation with '</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">'Correlation'</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9ccb60421ffa42bec24f02270e0cb19e4ab0827d13308e827a76a7a86b2c0dc6.png" src="../Images/6194a66796a23a77575acb7c89abb176.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/9ccb60421ffa42bec24f02270e0cb19e4ab0827d13308e827a76a7a86b2c0dc6.png"/>
</div>
</div>
<p>Note the 1.0 diagonal resulting from the correlation of each variable with themselves.</p>
<p>This looks good.  There is a mix of correlation magnitudes. Of course, correlation coefficients are limited to degree of linear correlations.</p>
<ul class="simple">
<li><p>Let‚Äôs look at the matrix scatter plot to see the pairwise relationship between the features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">pairgrid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">,</span><span class="s1">'Perm'</span><span class="p">,</span><span class="s1">'AI'</span><span class="p">,</span><span class="s1">'Brittle'</span><span class="p">,</span><span class="s1">'TOC'</span><span class="p">,</span><span class="s1">'Prod'</span><span class="p">])</span> <span class="c1"># matrix scatter plots</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_upper</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'k'</span><span class="p">)</span><span class="c1"># Map a density plot to the lower triangle</span>
<span class="n">pairgrid</span> <span class="o">=</span> <span class="n">pairgrid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">inferno</span><span class="p">,</span> 
                              <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_levels</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pairgrid</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c23ae18eda1e533de50c2330dba444a3862043169ebd7569532055f40e72e5f.png" src="../Images/18798d69cb2a69a3c10006380bba6873.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4c23ae18eda1e533de50c2330dba444a3862043169ebd7569532055f40e72e5f.png"/>
</div>
</div>
&#13;

<h2>Working with Only Two Predictor Features</h2>
<p>Let‚Äôs simplify the problem to 2 predictor features, Porosity and Brittleness to predict Production rate.  By working with only 2 features, it is very easy to visualize the segmentation of the feature space (it is only 2D and can be shown completely on a single plot).</p>
&#13;

<h2>Standardizing Predictor Features</h2>
<p>The k-nearest neighbour method uses a nearest training sample search in feature space (like k-means clustering). To remove the impact feature range from the approach we standardize the features.</p>
<ul class="simple">
<li><p>we will standardize our predictor features to have a mean of zero and a variance of one.</p></li>
<li><p>we use the scikit-learn preprocessing module to simplify this step and provide a convenient and safe reverse transform.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">if1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">if2</span> <span class="o">=</span> <span class="mi">3</span>                                              <span class="c1"># selected predictor features</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>                                 <span class="c1"># instantiate feature standardization method</span>

<span class="n">sel_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">pred</span><span class="p">[</span><span class="n">if1</span><span class="p">],</span><span class="n">pred</span><span class="p">[</span><span class="n">if2</span><span class="p">]]</span>
<span class="n">sel_features</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">+</span> <span class="p">[</span><span class="n">resp</span><span class="p">]</span>

<span class="n">spredlabel</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Standardized '</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">predlabel</span><span class="p">]</span> <span class="c1"># standardized predictors list</span>

<span class="n">sel_spredlabel</span> <span class="o">=</span> <span class="p">[</span><span class="n">spredlabel</span><span class="p">[</span><span class="n">if1</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">spredlabel</span><span class="p">[</span><span class="n">if2</span><span class="p">]]</span> 

<span class="n">sel_spred</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'s'</span> <span class="o">+</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">sel_pred</span><span class="p">]</span>           <span class="c1"># standardized predictors list</span>

<span class="n">df</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>
<span class="n">df</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># standardize the data features to mean = 0, var = 1.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Selected Predictor Features: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sel_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Standardized Selected Predictor Features: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Response Feature: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="n">resp</span><span class="p">]))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Selected Predictor Features: ['Por', 'Brittle']
Standardized Selected Predictor Features: ['sPor', 'sBrittle']
Response Feature: [['Prod']]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th/>
      <th>Por</th>
      <th>Perm</th>
      <th>AI</th>
      <th>Brittle</th>
      <th>TOC</th>
      <th>VR</th>
      <th>Prod</th>
      <th>sPor</th>
      <th>sBrittle</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12.08</td>
      <td>2.92</td>
      <td>2.80</td>
      <td>81.40</td>
      <td>1.16</td>
      <td>2.31</td>
      <td>1339.165488</td>
      <td>-0.982256</td>
      <td>2.358297</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.38</td>
      <td>3.53</td>
      <td>3.22</td>
      <td>46.17</td>
      <td>0.89</td>
      <td>1.88</td>
      <td>3383.979252</td>
      <td>-0.881032</td>
      <td>-0.141332</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14.02</td>
      <td>2.59</td>
      <td>4.01</td>
      <td>72.80</td>
      <td>0.89</td>
      <td>2.72</td>
      <td>2509.686720</td>
      <td>-0.327677</td>
      <td>1.748113</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.67</td>
      <td>6.75</td>
      <td>2.63</td>
      <td>39.81</td>
      <td>1.08</td>
      <td>1.88</td>
      <td>5514.421023</td>
      <td>0.903875</td>
      <td>-0.592585</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.52</td>
      <td>4.57</td>
      <td>3.18</td>
      <td>10.94</td>
      <td>1.51</td>
      <td>1.90</td>
      <td>3532.020478</td>
      <td>0.853263</td>
      <td>-2.640962</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let‚Äôs demonstrate the reverse transform from standardized features back to the original features.</p>
<ul class="simple">
<li><p>we won‚Äôt need this in our workflow since the we only need to forward transform the predictor features to train the model and make predictions</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'Backtransformed: </span><span class="se">\n</span><span class="s1">        Por    Brittle'</span><span class="p">)</span>
<span class="n">transform</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_spred</span><span class="p">])[:</span><span class="mi">5</span><span class="p">,:]</span>        <span class="c1"># check the reverse standardization</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Backtransformed: 
        Por    Brittle
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>array([[12.08, 81.4 ],
       [12.38, 46.17],
       [14.02, 72.8 ],
       [17.67, 39.81],
       [17.52, 10.94]])
</pre></div>
</div>
</div>
</div>
<p>We can compare the output above with the original porosity and brittleness. The reverse transform works!</p>
<ul class="simple">
<li><p>We will use this method to return to original feature units when needed.</p></li>
<li><p>In general, the back transformation is not needed for predictor features, well only forward transform the predictor features to make predictions of the response feature.</p></li>
<li><p>In this example, we don‚Äôt need to transform the response feature while building our model. The response feature distribution is well-behaved and there is not theory in k-nearest neighbours that expects a specific range or distribution share for the response feature.</p></li>
</ul>
&#13;

<h2>Feature Ranges</h2>
<p>Let‚Äôs set some ranges for plotting. Note for the standardized predictor features we will use -3.5 to 3.5 as the limits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">Xmin</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">];</span> <span class="n">Xmax</span> <span class="o">=</span> <span class="p">[</span><span class="mf">25.0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">]</span>                        <span class="c1"># selected predictor features min and max</span>
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Train and Test Split</h2>
<p>For convenience and simplicity we use scikit-learn‚Äôs random train and test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_spred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># make one train DataFrame with both X and y (remove all other features)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># make one testin DataFrame with both X and y (remove all other features)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs first check the univariate statistics of Porosity, Brittleness and Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nbins</span> <span class="o">=</span> <span class="mi">20</span>                                                    <span class="c1"># number of histogram bins</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'darkorange'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">],</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">'red'</span><span class="p">,</span><span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">'black'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">nbins</span><span class="p">),</span><span class="n">label</span><span class="o">=</span><span class="s1">'Test'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">resplabel</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">);</span> <span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a6e3b01d9e6230c6eb26e1b06c604aa2fc175bb399d25bcd7794d5fb4b1b1e46.png" src="../Images/2447bd1e6857b017d16d4197616a3dc1.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/a6e3b01d9e6230c6eb26e1b06c604aa2fc175bb399d25bcd7794d5fb4b1b1e46.png"/>
</div>
</div>
<p>The distributions are well behaved,</p>
<ul class="simple">
<li><p>we cannot observe obvious gaps nor truncations.</p></li>
<li><p>check coverage of the train and test data</p></li>
</ul>
<p>Let‚Äôs look at a scatter plot of Porosity vs. Brittleness with points colored by Production.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># train data plot</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> 
                 <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Train '</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">resplabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                               <span class="c1"># test data plot</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">ymin</span><span class="p">,</span> 
                 <span class="n">vmax</span><span class="o">=</span><span class="n">ymax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Test '</span> <span class="o">+</span> <span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' vs. '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' and '</span> <span class="o">+</span> <span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">sel_spredlabel</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">orientation</span> <span class="o">=</span> <span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="n">resplabel</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">FuncFormatter</span><span class="p">(</span><span class="n">comma_format</span><span class="p">))</span>
<span class="n">add_grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4c88383d908cf65a54e1601379bf0b36cdbfab09eeae0ff5cc37587387fd084c.png" src="../Images/0b1f8f8266faddc853479c3aab599c2e.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/4c88383d908cf65a54e1601379bf0b36cdbfab09eeae0ff5cc37587387fd084c.png"/>
</div>
</div>
<p>This problem looks nonlinear and could not be modeled with simple linear regression.</p>
<ul class="simple">
<li><p>It appears there is a sweet spot for Brittleness and increasing Porosity is always beneficial for Production.</p></li>
</ul>
&#13;

<h2>Instantiate, Fit and Predict with k-nearest Neighbour</h2>
<p>Let‚Äôs instantiate, fit and predict with a k-nearest neighbour model.</p>
<ul class="simple">
<li><p>instantiate it with the hyperparameters, k-nearest neighbours</p></li>
<li><p>train with the training data, we use the standard fit function from scikit-learn</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                 <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>
</pre></div>
</div>
</div>
</div>
<p>We have set the hyperparameters:</p>
<ul class="simple">
<li><p>weights = averaging weights for the prediction given the nearest neighbours. ‚Äòuniform‚Äô is arithmetic average, while ‚Äòdistance‚Äô is inverse distance weighting.</p></li>
<li><p>n_neighbours = maximum number of neighbours. Note, we constrain our prediction by limiting it to 5 nearest neighbours.</p></li>
<li><p>p = distance metric power or Minkowski metric (1 = Manhattan distance, 2 for Euclidian distance) for finding the nearest neighbours.</p></li>
</ul>
<p>Now we are ready to fit our model for prediction of Production given Porosity and Brittleness.</p>
<ul class="simple">
<li><p>We will use our two functions defined above to visualize the k-nearest neighbour prediction over the feature space and the cross plot of actual and estimated production for the training data along with three model metrics from the sklearn.metric module.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="c1"># plt.subplot(223)                                              # model accuracy check</span>
<span class="c1"># check_model(neigh_fit,X_train[sel_spred[0]],X_train[sel_spred[1]],X_test[sel_spred[0]],X_test[sel_spred[1]],ymin,ymax,</span>
<span class="c1">#             y_train[resp[0]],y_test[resp[0]],'K Nearest Neighbour Regression Model Accuracy')</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8687713a2a5e6441f354a7136a11c925434235dd1930a34a508287b1aed9f7e5.png" src="../Images/8a097688955c9a933b8a09894a1a0ea5.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8687713a2a5e6441f354a7136a11c925434235dd1930a34a508287b1aed9f7e5.png"/>
</div>
</div>
<p>The model looks good:</p>
<ul class="simple">
<li><p>the nonparametric approach is quite flexible to fit the nonlinear response patterns in the predictor feature space</p></li>
<li><p>we can see some search artifacts due to limited k nearest data and the use of uniform weighting</p></li>
<li><p>we have dense data for this low dimensional problem (only 2 predictor features)</p></li>
<li><p>the testing and training data are consistent and close to each other in the predictor feature space</p></li>
</ul>
<p>Let‚Äôs try to overfit the model by using a very large k hyperparameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'K Nearest Neighbour Regression Model Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/57e183c41e9ee9d084d79c733d18bfe2ce2f5e0504c9b7b75db9ad994fc637cb.png" src="../Images/7a8fad6c8ab65ba24660fe87eb558d34.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/57e183c41e9ee9d084d79c733d18bfe2ce2f5e0504c9b7b75db9ad994fc637cb.png"/>
</div>
</div>
<p>Note that this smoothed out the response, and the predictions are approaching the global mean.</p>
<ul class="simple">
<li><p>we have an underfit model.</p></li>
</ul>
<p>Next let‚Äôs use a smaller k hyperparameter for our k-nearest neighbours prediction model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                  <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'K Nearest Neighbour Regression Model Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/36151afeb7ee7ec97d8f9695513890616f1d619cbc81c9e9a734492d90c1e86f.png" src="../Images/652c1c3e20ca9e893f0cf17db9352459.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/36151afeb7ee7ec97d8f9695513890616f1d619cbc81c9e9a734492d90c1e86f.png"/>
</div>
</div>
<p>Now we have an extreme overfit model.</p>
<ul class="simple">
<li><p>The training MSE is 0.0 and the testing error is quite high.</p></li>
<li><p>Note, some of our predictions in our overfit model are outside the plotting min and max response feature values.</p></li>
</ul>
<p>Let‚Äôs try to use a L1, Manhattan distance to find the k nearest neighbours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_neighbours</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span>                 <span class="c1"># model hyperparameters</span>
<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbours</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># instantiate the prediction model</span>

<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>                        <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>                                              <span class="c1"># model accuracy check</span>
<span class="n">check_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_train</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">X_test</span><span class="p">[</span><span class="n">sel_spred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="s1">'K Nearest Neighbour Regression Model Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">2.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/58118fcb46c0eb738a754ea3e1103828cda85f1f5eea8dc2d12b6e69215213d3.png" src="../Images/3a4e29a43415592363cfc3314ffd6b4b.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/58118fcb46c0eb738a754ea3e1103828cda85f1f5eea8dc2d12b6e69215213d3.png"/>
</div>
</div>
<p>Compare this prediction model to our first model, all we changes is the distance search for the k nearest samples to Manhattan from Euclidean distance.</p>
<ul class="simple">
<li><p>the search artifacts are now aligned on the features (the rays are oriented in the x and y directions)</p></li>
</ul>
&#13;

<h2>Hyperparameter Tuning for k-Nearest Neighbours</h2>
<p>Let‚Äôs check this out as we tune the hyper parameters.</p>
<p>So what does the <span class="math notranslate nohighlight">\(k\)</span> do?</p>
<ul class="simple">
<li><p>small <span class="math notranslate nohighlight">\(k\)</span> hyperparameter results in a local specific prediction model over the predictor feature space</p></li>
<li><p>large <span class="math notranslate nohighlight">\(k\)</span> hyperparameter results in a more smooth, globally fit prediction model over the predictor features space</p></li>
</ul>
<p>This is analogous to the low to high complexity we have observed with other models (like decision trees).</p>
<ul class="simple">
<li><p>small <span class="math notranslate nohighlight">\(k\)</span> is complex</p></li>
<li><p>large <span class="math notranslate nohighlight">\(k\)</span> is simple</p></li>
</ul>
<p>We need to tune the complexity to optimize model performance.</p>
&#13;

<h2>Tuning the Hyperparameters</h2>
<p>Let‚Äôs loop over multiple <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours for average and inverse distance estimates to access the best hyperparameters with respect to accuracy in testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>                                                         <span class="c1"># set initial, lowest k hyperparameter</span>
<span class="n">dist_error</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">unif_error</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">k_mat</span> <span class="o">=</span> <span class="p">[]</span>                  <span class="c1"># make lists to store the results</span>
<span class="k">while</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">150</span><span class="p">:</span>                                               <span class="c1"># loop over the k hyperparameter</span>
    <span class="n">neigh_dist</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># instantiate the model</span>
    <span class="n">neigh_dist_fit</span> <span class="o">=</span> <span class="n">neigh_dist</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>          <span class="c1"># train the model with the training data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh_dist_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>                   <span class="c1"># predict over the testing cases</span>
    <span class="n">MSE</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>           <span class="c1"># calculate the MSE testing</span>
    <span class="n">dist_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                                    <span class="c1"># add to the list of MSE</span>
    
    <span class="n">neigh_unif</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'uniform'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">neigh_unif_fit</span> <span class="o">=</span> <span class="n">neigh_unif</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>          <span class="c1"># train the model with the training data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh_unif_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>                   <span class="c1"># predict over the testing cases</span>
    <span class="n">MSE</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>           <span class="c1"># calculate the MSE testing</span>
    <span class="n">unif_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                                    <span class="c1"># add to the list of MSE</span>
    
    <span class="n">k_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>                                           <span class="c1"># append k to an array for plotting</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>Now let‚Äôs plot the result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">dist_error</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'inverse distance weighted'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">unif_error</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">'arithmetic average'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Testing Error vs. Number of Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">750000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01eac05af310de41e5fc30ed84e0dd7ffbc211efc97eea008ec63bd1c8ef9a09.png" src="../Images/fe795ea54d585888e2632307876aaa72.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/01eac05af310de41e5fc30ed84e0dd7ffbc211efc97eea008ec63bd1c8ef9a09.png"/>
</div>
</div>
<p>What can we observe from this result?</p>
<ul class="simple">
<li><p>at <span class="math notranslate nohighlight">\(k = 12\)</span> nearest neighbours we minimize the mean square error in testing.</p></li>
<li><p>we have better performance with the inverse distance weighted than the arithmetic average (uniform weighting of k nearest training data in predictor feature space)</p></li>
</ul>
<p>There is an optimum degree of specificity / complexity to our model.</p>
<ul class="simple">
<li><p>1 nearest neighbour is a very locally specific model (overfit)</p></li>
<li><p>many nearest neighbours includes too much information and is too general (underfit)</p></li>
</ul>
<p>We are observing the accuracy vs. complexity trade-off for the <span class="math notranslate nohighlight">\(k\)</span> nearest neighbour model.</p>
&#13;

<h2>k-fold Cross Validation</h2>
<p>It is useful to evaluate the performance of our model by observing the accuracy vs. complexity trade-off.</p>
<p>Yet, what we really want to do is rigorously test our model performance.  We should perform a more rigorous cross validation that does a better job evaluating over different sets of training and testing data. scikit learn has a built in cross validation method called cross_val_score that we can use to:</p>
<ol class="arabic simple">
<li><p>Apply k-fold approach with iterative separation of training and testing data</p></li>
<li><p>Automate the model construction, looping over folds and averaging the metric of interest</p></li>
</ol>
<p>Let‚Äôs try it out on our k nearest neighbour prediction with variable number of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours.  Note the cross validation is set to use 4 processors, but still will likely take a couple of minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">score</span> <span class="o">=</span> <span class="p">[]</span>                                                  <span class="c1"># code modified from StackOverFlow by Dimosthenis</span>
<span class="n">k_mat</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">150</span><span class="p">):</span>
    <span class="n">neigh_dist</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">neigh_dist</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'sPor'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s1">'sBrittle'</span><span class="p">]],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">'Prod'</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                             <span class="n">scoring</span> <span class="o">=</span> <span class="s2">"neg_mean_squared_error"</span><span class="p">)</span> <span class="c1"># Perform 7-fold cross validation</span>
    <span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="n">k_mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The output is an array of average scores (MSE) over the k-folds for each level of complexity (number of <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours), along with an array with the <span class="math notranslate nohighlight">\(k\)</span>s.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span><span class="n">score</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'k-fold Cross Validation Error (MSE) vs. k Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Nearest Neighbours'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Mean Square Error'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">150</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1400000</span><span class="p">]);</span> <span class="n">add_grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3486b059575a23212d8aafc3a96a97665590c325236271232ebf8b699313ea39.png" src="../Images/d79973afda6b57fc45418841e4ff114d.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/3486b059575a23212d8aafc3a96a97665590c325236271232ebf8b699313ea39.png"/>
</div>
</div>
<p>With the hyperparameter of 10 nearest neighbours we get the greatest accuracy in k-fold cross validation model testing.</p>
&#13;

<h2>Predictor Feature Standardization</h2>
<p>We have standardized the predictor feature to remove the influence of their ranges.</p>
<ul class="simple">
<li><p>What would happen if we worked with the original predictor features?</p></li>
</ul>
<p>Let‚Äôs try it out.</p>
<ul class="simple">
<li><p>we first apply train and test split with the original features, without standardization</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">y_train_orig</span><span class="p">,</span> <span class="n">y_test_orig</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>

<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">,</span><span class="n">y_train_orig</span><span class="p">)</span>                <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8c3133ce421b3030fdd8a00084845ccd1d24e4e798c75f636c0920eebed4d5c6.png" src="../Images/7c1a8ce67e0629a7c8b0a3ceccdf2686.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/8c3133ce421b3030fdd8a00084845ccd1d24e4e798c75f636c0920eebed4d5c6.png"/>
</div>
</div>
<p>Do you see the horizontal banding?  The larger range of magnitudes of brittleness vs. porosity results in this banding.</p>
<ul class="simple">
<li><p>distances in the feature space are more sensitive to the relative changes in brittleness than porosity</p></li>
</ul>
<p>Let‚Äôs convert porosity to a fraction and observe the change in our predictor due to the arbitrary decision to work with porosity as a fraction vs. a percentage.</p>
<ul class="simple">
<li><p>by applying a <span class="math notranslate nohighlight">\(\frac{1}{100}\)</span> factor to all the porosity values.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">y_train_orig</span><span class="p">,</span> <span class="n">y_test_orig</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">],</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">],</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">73073</span><span class="p">)</span>

<span class="n">X_train_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">/</span><span class="mf">100.0</span>
<span class="n">X_test_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test_orig</span><span class="p">[</span><span class="s1">'Por'</span><span class="p">]</span><span class="o">/</span><span class="mf">100.0</span>

<span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s1">'distance'</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">neigh_fit</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">,</span><span class="n">y_train_orig</span><span class="p">)</span>                <span class="c1"># train the model with the training data</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                                              <span class="c1"># training data vs. the model predictions</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_train</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                    <span class="s1">'Training Data and k Nearest Neighbours'</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                              <span class="c1"># testing data vs. the model predictions</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">neigh_fit</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span><span class="n">X_test_orig</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">y_test</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'Testing Data and k Nearest Neighbours'</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'Hyperparameters'</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">3.2</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'weights: '</span> <span class="o">+</span> <span class="n">weights</span><span class="p">,[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.9</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'n neighbours: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_neighbours</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.6</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'distance norm: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">),[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.3</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e98632fa73beaf85be54462502e9cd2b26c6bc804f11e5ba193bd5a17f99b64d.png" src="../Images/bf1f50f1e62336305668f4aff28ac682.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/e98632fa73beaf85be54462502e9cd2b26c6bc804f11e5ba193bd5a17f99b64d.png"/>
</div>
</div>
<ul class="simple">
<li><p>this banding effect gets even more severe as we convert from percentage to fractional porosity, because distances in porosity appear so much closer than in brittleness, just because of the difference in feature ranges.</p></li>
</ul>
<p>Our distance metric for assigning nearest neighbours is quite sensitive to the feature units.  We should always standardize all predictor features (put them on equal footing) before we use them to build our <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbour regression model!</p>
&#13;

<h2>k Nearest Neighbour Regression in scikit-learn with Pipelines</h2>
<p>The need to standardize features, train, tune and retrain the tuned model with all the data may seem to be a lot of work!</p>
<ul class="simple">
<li><p>one solution is to use the Pipeline object from scikit-learn.</p></li>
</ul>
<p>Here‚Äôs some highlights on Pipelines.</p>
<section id="machine-learning-modeling-pipelines-basics">
<h3>Machine Learning Modeling Pipelines Basics</h3>
<p>Machine learning workflows can be complicated, with various steps:</p>
<ul class="simple">
<li><p>data preparation, feature engineering transformations</p></li>
<li><p>model parameter fitting</p></li>
<li><p>model hyperparameter tuning</p></li>
<li><p>modeling method selection</p></li>
<li><p>searching over a large combinatorial of hyperparameters</p></li>
<li><p>training and testing model runs</p></li>
</ul>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to automate the determination of the best model (AutoML)</p>
</section>
<section id="k-nearest-neighbours-with-pipelines">
<h3>k-Nearest Neighbours with Pipelines</h3>
<p>Here‚Äôs compact, safe code for the entire model training and tuning process with scikit-learn pipelines</p>
<ul class="simple">
<li><p>the GridSearchCV object actually becomes the prediction model, with tuned hyperparameters retrained on all of the data!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>

<span class="n">folds</span> <span class="o">=</span> <span class="mi">4</span>                                                   <span class="c1"># number of k folds</span>
<span class="n">k_min</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">k_max</span> <span class="o">=</span> <span class="mi">150</span>                                       <span class="c1"># range of k hyperparameter to consider</span>

<span class="n">X_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span>                                 <span class="c1"># all the samples for the original features</span>
<span class="n">y_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>                             <span class="c1"># warning this becomes a series, 1D ndarray with label</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>                                           <span class="c1"># the machine learning workflow as a pipeline object</span>
    <span class="p">(</span><span class="s1">'scaler'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">'knear'</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>                                                  <span class="c1"># the machine learning workflow method's parameters</span>
    <span class="s1">'scaler'</span><span class="p">:</span> <span class="p">[</span><span class="n">StandardScaler</span><span class="p">()],</span>
    <span class="s1">'knear__n_neighbors'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">),</span>
    <span class="s1">'knear__metric'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'euclidean'</span><span class="p">],</span>
    <span class="s1">'knear__p'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
    <span class="s1">'knear__weights'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'distance'</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_cv_tuned</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">'neg_mean_squared_error'</span><span class="p">,</span> <span class="c1"># grid search cross validation </span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                             <span class="n">refit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pipe</span><span class="p">,</span><span class="n">y_pipe</span><span class="p">)</span>                                      <span class="c1"># fit model with tuned hyperparameters</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">visualize_tuned_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">'knear__n_neighbors'</span><span class="p">],</span> <span class="c1"># visualize the error vs. k </span>
                      <span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'param_knear__n_neighbors'</span><span class="p">],</span>
                      <span class="nb">abs</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'mean_test_score'</span><span class="p">]))</span>              

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                            <span class="c1"># visualize the tuned model</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'All Data and Tuned and Retrained k-Nearest Neighbours'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png" src="../Images/4cddeaa35cf9ea49e9a36b802755dc3a.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png"/>
</div>
</div>
</section>
<section id="check-the-tuned-hyperparameters">
<h3>Check the Tuned Hyperparameters</h3>
<p>In the GridSearchCV model object, there is a built in dictionary called best_params_ that includes all the tuned hyperparameters.</p>
<ul class="simple">
<li><p>note, over the range of k‚Äôs the selected k, n_neighbors</p></li>
<li><p>also, the other hyperparameters were specified, but we could have provided a range and scenarios for each to explore with the grid search method</p></li>
</ul>
<p>When tuning more than 1 hyperparameter, the runtime will increase with the combinatorial of hyperparameters and the resulting model loss function, e.g., cv_results_[‚Äòmean_test_score‚Äô], is sorted over all the hyperparameter cases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>{'knear__metric': 'euclidean',
 'knear__n_neighbors': 11,
 'knear__p': 2,
 'knear__weights': 'distance',
 'scaler': StandardScaler()}
</pre></div>
</div>
</div>
</div>
<p>It is also useful to look at the entire model object for more information. Including:</p>
<ul class="simple">
<li><p>the pipeline and all cases considered for the hyperparameter tuning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">grid_cv_tuned</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "‚ñ∏";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "‚ñæ";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[('scaler', StandardScaler()),
                                       ('knear', KNeighborsRegressor())]),
             param_grid={'knear__metric': ['euclidean'],
                         'knear__n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         'knear__p': [2], 'knear__weights': ['distance'],
                         'scaler': [StandardScaler()]},
             scoring='neg_mean_squared_error')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"/><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[('scaler', StandardScaler()),
                                       ('knear', KNeighborsRegressor())]),
             param_grid={'knear__metric': ['euclidean'],
                         'knear__n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         'knear__p': [2], 'knear__weights': ['distance'],
                         'scaler': [StandardScaler()]},
             scoring='neg_mean_squared_error')</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"/><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('scaler', StandardScaler()), ('knear', KNeighborsRegressor())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"/><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"/><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsRegressor</label><div class="sk-toggleable__content"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
</section>
&#13;

<h3>Machine Learning Modeling Pipelines Basics</h3>
<p>Machine learning workflows can be complicated, with various steps:</p>
<ul class="simple">
<li><p>data preparation, feature engineering transformations</p></li>
<li><p>model parameter fitting</p></li>
<li><p>model hyperparameter tuning</p></li>
<li><p>modeling method selection</p></li>
<li><p>searching over a large combinatorial of hyperparameters</p></li>
<li><p>training and testing model runs</p></li>
</ul>
<p>Pipelines are a scikit-learn class that allows for the encapsulation of a sequence of data preparation and modeling steps</p>
<ul class="simple">
<li><p>then we can treat the pipeline as an object in our much condensed workflow</p></li>
</ul>
<p>The pipeline class allows us to:</p>
<ul class="simple">
<li><p>improve code readability and to keep everything straight</p></li>
<li><p>avoid common workflow problems like data leakage, testing data informing model parameter training</p></li>
<li><p>abstract common machine learning modeling and focus on building the best model possible</p></li>
</ul>
<p>The fundamental philosophy is to treat machine learning as a combinatorial search to automate the determination of the best model (AutoML)</p>
&#13;

<h3>k-Nearest Neighbours with Pipelines</h3>
<p>Here‚Äôs compact, safe code for the entire model training and tuning process with scikit-learn pipelines</p>
<ul class="simple">
<li><p>the GridSearchCV object actually becomes the prediction model, with tuned hyperparameters retrained on all of the data!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">os</span>                                                     <span class="c1"># to set current working directory </span>

<span class="n">folds</span> <span class="o">=</span> <span class="mi">4</span>                                                   <span class="c1"># number of k folds</span>
<span class="n">k_min</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">k_max</span> <span class="o">=</span> <span class="mi">150</span>                                       <span class="c1"># range of k hyperparameter to consider</span>

<span class="n">X_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">sel_pred</span><span class="p">]</span>                                 <span class="c1"># all the samples for the original features</span>
<span class="n">y_pipe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>                             <span class="c1"># warning this becomes a series, 1D ndarray with label</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>                                           <span class="c1"># the machine learning workflow as a pipeline object</span>
    <span class="p">(</span><span class="s1">'scaler'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">'knear'</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>                                                  <span class="c1"># the machine learning workflow method's parameters</span>
    <span class="s1">'scaler'</span><span class="p">:</span> <span class="p">[</span><span class="n">StandardScaler</span><span class="p">()],</span>
    <span class="s1">'knear__n_neighbors'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k_min</span><span class="p">,</span><span class="n">k_max</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">),</span>
    <span class="s1">'knear__metric'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'euclidean'</span><span class="p">],</span>
    <span class="s1">'knear__p'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
    <span class="s1">'knear__weights'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'distance'</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_cv_tuned</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">'neg_mean_squared_error'</span><span class="p">,</span> <span class="c1"># grid search cross validation </span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                             <span class="n">refit</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pipe</span><span class="p">,</span><span class="n">y_pipe</span><span class="p">)</span>                                      <span class="c1"># fit model with tuned hyperparameters</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">visualize_tuned_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">'knear__n_neighbors'</span><span class="p">],</span> <span class="c1"># visualize the error vs. k </span>
                      <span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'param_knear__n_neighbors'</span><span class="p">],</span>
                      <span class="nb">abs</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">'mean_test_score'</span><span class="p">]))</span>              

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                                            <span class="c1"># visualize the tuned model</span>
<span class="n">visualize_model</span><span class="p">(</span><span class="n">grid_cv_tuned</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">sel_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span><span class="n">Xmin</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">Xmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="n">resp</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span>
                <span class="s1">'All Data and Tuned and Retrained k-Nearest Neighbours'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png" src="../Images/4cddeaa35cf9ea49e9a36b802755dc3a.png" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_images/83fd2c84c5d45efc2ab0262137bbbdafd882df6ec6ab4098a5b6e277724e7c05.png"/>
</div>
</div>
&#13;

<h3>Check the Tuned Hyperparameters</h3>
<p>In the GridSearchCV model object, there is a built in dictionary called best_params_ that includes all the tuned hyperparameters.</p>
<ul class="simple">
<li><p>note, over the range of k‚Äôs the selected k, n_neighbors</p></li>
<li><p>also, the other hyperparameters were specified, but we could have provided a range and scenarios for each to explore with the grid search method</p></li>
</ul>
<p>When tuning more than 1 hyperparameter, the runtime will increase with the combinatorial of hyperparameters and the resulting model loss function, e.g., cv_results_[‚Äòmean_test_score‚Äô], is sorted over all the hyperparameter cases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">grid_cv_tuned</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>{'knear__metric': 'euclidean',
 'knear__n_neighbors': 11,
 'knear__p': 2,
 'knear__weights': 'distance',
 'scaler': StandardScaler()}
</pre></div>
</div>
</div>
</div>
<p>It is also useful to look at the entire model object for more information. Including:</p>
<ul class="simple">
<li><p>the pipeline and all cases considered for the hyperparameter tuning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">grid_cv_tuned</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "‚ñ∏";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "‚ñæ";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[('scaler', StandardScaler()),
                                       ('knear', KNeighborsRegressor())]),
             param_grid={'knear__metric': ['euclidean'],
                         'knear__n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         'knear__p': [2], 'knear__weights': ['distance'],
                         'scaler': [StandardScaler()]},
             scoring='neg_mean_squared_error')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"/><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=False),
             estimator=Pipeline(steps=[('scaler', StandardScaler()),
                                       ('knear', KNeighborsRegressor())]),
             param_grid={'knear__metric': ['euclidean'],
                         'knear__n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,
        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,
        40,  41,  42,  43,  44,  45,...
        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,
        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,
       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,
       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,
       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,
       144, 145, 146, 147, 148, 149]),
                         'knear__p': [2], 'knear__weights': ['distance'],
                         'scaler': [StandardScaler()]},
             scoring='neg_mean_squared_error')</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"/><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('scaler', StandardScaler()), ('knear', KNeighborsRegressor())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"/><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"/><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsRegressor</label><div class="sk-toggleable__content"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
&#13;

<h2>Comments</h2>
<p>This was a basic treatment of k-nearest neighbours. Much more could be done and discussed, I have many more resources. Check out my <a class="reference external" href="https://michaelpyrcz.com/my-resources">shared resource inventory</a> and the YouTube lecture links at the start of this chapter with resource links in the videos‚Äô descriptions.</p>
<p>I hope this is helpful,</p>
<p><em>Michael</em></p>
&#13;

<h2>About the Author</h2>
<figure style="text-align: center;">
  <img src="../Images/eb709b2c0a0c715da01ae0165efdf3b2.png" style="display: block; margin: 0 auto; width: 70%;" data-original-src="https://geostatsguy.github.io/MachineLearningDemos_Book/_static/intro/michael_pyrcz_officeshot_jacket.jpg"/>
  <figcaption style="text-align: center;"> Professor Michael Pyrcz in his office on the 40 acres, campus of The University of Texas at Austin.
</figcaption>
</figure>
<p>Michael Pyrcz is a professor in the <a class="reference external" href="https://cockrell.utexas.edu/faculty-directory/alphabetical/p">Cockrell School of Engineering</a>, and the <a class="reference external" href="https://www.jsg.utexas.edu/researcher/michael_pyrcz/">Jackson School of Geosciences</a>, at <a class="reference external" href="https://www.utexas.edu/">The University of Texas at Austin</a>, where he researches and teaches subsurface, spatial data analytics, geostatistics, and machine learning. Michael is also,</p>
<ul class="simple">
<li><p>the principal investigator of the <a class="reference external" href="https://fri.cns.utexas.edu/energy-analytics">Energy Analytics</a> freshmen research initiative and a core faculty in the Machine Learn Laboratory in the College of Natural Sciences, The University of Texas at Austin</p></li>
<li><p>an associate editor for <a class="reference external" href="https://www.sciencedirect.com/journal/computers-and-geosciences/about/editorial-board">Computers and Geosciences</a>, and a board member for <a class="reference external" href="https://link.springer.com/journal/11004/editorial-board">Mathematical Geosciences</a>, the International Association for Mathematical Geosciences.</p></li>
</ul>
<p>Michael has written over 70 <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en">peer-reviewed publications</a>, a <a class="reference external" href="https://pypi.org/project/geostatspy/">Python package</a> for spatial data analytics, co-authored a textbook on spatial data analytics, <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Geostatistical Reservoir Modeling</a> and author of two recently released e-books, <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostatistics in Python: a Hands-on Guide with GeostatsPy</a> and <a class="reference external" href="https://geostatsguy.github.io/MachineLearningDemos_Book/intro.html">Applied Machine Learning in Python: a Hands-on Guide with Code</a>.</p>
<p>All of Michael‚Äôs university lectures are available on his <a class="reference external" href="https://www.youtube.com/@GeostatsGuyLectures">YouTube Channel</a> with links to 100s of Python interactive dashboards and well-documented workflows in over 40 repositories on his <a class="reference external" href="https://github.com/GeostatsGuy">GitHub account</a>, to support any interested students and working professionals with evergreen content. To find out more about Michael‚Äôs work and shared educational resources visit his <span class="xref myst">Website</span>.</p>
&#13;

<h2>Want to Work Together?</h2>
<p>I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.</p>
<ul class="simple">
<li><p>Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I‚Äôd be happy to drop by and work with you!</p></li>
<li><p>Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PI is Professor John Foster)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!</p></li>
<li><p>I can be reached at <a class="reference external" href="mailto:mpyrcz%40austin.utexas.edu">mpyrcz<span>@</span>austin<span>.</span>utexas<span>.</span>edu</a>.</p></li>
</ul>
<p>I‚Äôm always happy to discuss,</p>
<p><em>Michael</em></p>
<p>Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin</p>
&#13;

<h2>More Resources Available at: <a class="reference external" href="https://twitter.com/geostatsguy">Twitter</a> | <a class="reference external" href="https://github.com/GeostatsGuy">GitHub</a> | <a class="reference external" href="http://michaelpyrcz.com">Website</a> | <a class="reference external" href="https://scholar.google.com/citations?user=QVZ20eQAAAAJ&amp;hl=en&amp;oi=ao">GoogleScholar</a> | <a class="reference external" href="https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446">Book</a> | <a class="reference external" href="https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig">YouTube</a>  | <a class="reference external" href="https://geostatsguy.github.io/GeostatsPyDemos_Book/intro.html">Applied Geostats in Python e-book</a> | <a class="reference external" href="https://www.linkedin.com/in/michael-pyrcz-61a648a1">LinkedIn</a></h2>
    
</body>
</html>