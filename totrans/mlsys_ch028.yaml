- en: Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Teaching machine learning systems requires a holistic, end-to-end perspective
    that encompasses the complete pipeline from data collection through deployment
    and maintenance. However, traditional ML systems education faces significant practical
    barriers: students cannot realistically train trillion-parameter models, collect
    millions of labeled images, or deploy systems at cloud scale within academic constraints.
    Embedded machine learning provides an elegant solution to this pedagogical challenge,
    offering a complete systems experience within accessible hardware and time constraints.
    Working within the severe resource limitations of embedded devices—typically 2MB
    of RAM and 1MB of flash storage—students encounter the same fundamental engineering
    trade-offs that define large-scale ML systems, but in a tangible, hands-on environment
    where every optimization decision has immediate, observable consequences.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Laboratory Development**'
  prefs: []
  type: TYPE_NORMAL
- en: These hands-on laboratories were developed by [Marcelo Rovai](https://github.com/Mjrovai),
    bringing decades of embedded systems expertise to create accessible, practical
    learning experiences that bridge theory with real-world implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Why Embedded ML for ML Systems Education?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Traditional machine learning education often focuses on algorithmic development
    in unconstrained cloud environments with abundant computational resources. While
    this approach builds important theoretical foundations, it can obscure the engineering
    realities that define most real-world AI deployments. Embedded machine learning
    provides a uniquely effective pedagogical framework for several key reasons, organized
    here from foundational requirements through learning effectiveness to real-world
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Economic Accessibility:** Professional-grade development boards cost $20-50,
    making hands-on learning accessible without requiring expensive cloud computing
    credits or specialized laboratory infrastructure. Students can own and experiment
    with hardware beyond formal course boundaries.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Immediate, Tangible Feedback:** Physical interactions—LEDs indicating classification
    results, buzzers responding to audio events, motors controlled by gesture recognition—transform
    abstract algorithmic concepts into concrete, observable behaviors. This immediate
    feedback accelerates learning and debugging.'
  prefs: []
  type: TYPE_NORMAL
- en: '**End-to-End System Understanding:** Unlike cloud-based exercises where infrastructure
    is abstracted away, embedded systems require students to understand the complete
    pipeline from sensor data acquisition through inference to actuator control. This
    comprehensive view reveals the interdependencies that characterize real-world
    ML systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource Constraints Drive Engineering Excellence:** Working within 2MB of
    RAM and 1MB of flash storage forces students to confront optimization decisions
    typically hidden in cloud deployments. Every design choice—from model architecture
    to data preprocessing—has immediate, measurable consequences for system performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Interdisciplinary Skill Development:** Embedded ML bridges computer science,
    electrical engineering, and systems design, preparing students for the increasingly
    interdisciplinary nature of modern technology development.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Industry Relevance:** The majority of deployed AI systems operate on edge
    devices rather than in data centers. Skills developed in embedded contexts directly
    transfer to mobile applications, IoT deployments, and autonomous systems.'
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites and Preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Mathematical Background:** Students should possess working knowledge of linear
    algebra, basic probability theory, and differential calculus. While advanced mathematical
    sophistication is not required, comfort with matrix operations and elementary
    optimization concepts will enhance learning outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming Competency:** Proficiency in Python programming is essential.
    Familiarity with C/C++ programming accelerates progress but is not strictly required
    as introductory exercises provide adequate scaffolding.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hardware Experience:** No prior embedded systems experience is assumed. Laboratory
    exercises include comprehensive setup procedures and troubleshooting guidance
    appropriate for students new to hardware development.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Learning Objectives**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon completion of the laboratory sequence, students will demonstrate competency
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource-Constrained Optimization:** Deploy ML models within 2MB RAM constraints
    while achieving real-time inference performance on microcontroller hardware.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Power-Efficient System Design:** Implement always-on sensing applications
    with battery life measured in months, not hours, through proper power management
    techniques.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Multi-Modal Data Processing:** Integrate vision, audio, and sensor data streams
    in unified embedded systems while maintaining performance constraints.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Professional Development Workflows:** Use industry-standard toolchains including
    TensorFlow Lite, Edge Impulse, and embedded debugging environments for complete
    development cycles.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Laboratory Exercise Categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To achieve these learning objectives, the curriculum is organized into specific
    exercise categories, each targeting different aspects of embedded AI system development.
  prefs: []
  type: TYPE_NORMAL
- en: Computer Vision Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The computer vision laboratory sequence addresses the fundamental challenge
    of processing high-dimensional visual data on resource-constrained hardware, demonstrating
    optimization techniques required for real-time performance within embedded system
    constraints.
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Classification Systems:** Students implement object recognition algorithms
    that demonstrate trade-offs between model complexity and inference speed, paralleling
    computational challenges in smartphone cameras and autonomous vehicle systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Object Detection and Localization:** Advanced exercises extend beyond classification
    to spatial object localization, implementing detection algorithms similar to those
    in security systems and industrial automation.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vision-Language Integration:** Cutting-edge exercises combine visual processing
    with natural language understanding, demonstrating how advanced AI functionality
    can be deployed on edge devices.'
  prefs: []
  type: TYPE_NORMAL
- en: Audio and Temporal Data Processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Audio processing laboratories focus on continuous data stream analysis while
    maintaining minimal power consumption, particularly relevant for always-on sensing
    applications where battery life is paramount.
  prefs: []
  type: TYPE_NORMAL
- en: '**Keyword Spotting Systems:** Students implement voice interface systems demonstrating
    the engineering challenges of continuous audio monitoring while preserving battery
    life, paralleling approaches in commercial voice assistants.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Motion and Activity Recognition:** Time-series analysis exercises using inertial
    measurement data teach pattern extraction from continuous sensor streams, mirroring
    functionality in fitness tracking and health monitoring devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Audio Event Classification:** Advanced exercises extend beyond speech recognition
    to general acoustic event detection for security monitoring and environmental
    sensing applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Laboratory Platform Compatibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These exercise categories are implemented across multiple hardware platforms,
    each offering different capabilities and constraints. This platform diversity
    ensures students experience the full spectrum of embedded AI deployment scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 21.1](ch028.xhtml#tbl-lab-compatibility) provides a comprehensive mapping
    of laboratory exercises to supported hardware platforms, enabling curriculum planners
    to design learning sequences appropriate for available resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 21.1: Laboratory Exercise Compatibility Matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Exercise Category** | **Arduino Nicla** | **XIAOML Kit** | **Grove Vision
    AI V2** | **Raspberry Pi** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Getting Started** | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| **Image Classification** | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| **Object Detection** | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| **Keyword Spotting** | ✓ | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| **Motion Classification** | ✓ | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| **No-Code Applications** |  |  | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| **Large Language Models** |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| **Vision Language Models** |  |  |  | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| **DSP/Feature Engr.** | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: Core Data Modalities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The laboratory exercises described above are organized around three fundamental
    data modalities that represent the majority of embedded AI applications. Understanding
    these modalities provides important theoretical context for the engineering challenges
    students will encounter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Visual Data Processing:** Image and video analysis demands the highest computational
    resources, requiring optimization techniques to process high-dimensional data
    within severe memory constraints while maintaining real-time performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Temporal Audio Analysis:** Audio processing and time-series sensor analysis
    require continuous data stream processing while maintaining ultra-low power consumption,
    demonstrating critical trade-offs between computational complexity and energy
    efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sensor Fusion and Multi-Modal Systems:** Advanced applications combine multiple
    data sources to achieve functionality impossible with single-modality approaches,
    managing increased system complexity while maintaining embedded performance constraints.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this foundation of learning objectives, exercise categories, platform options,
    and theoretical understanding in place, students are ready to begin their embedded
    ML journey.
  prefs: []
  type: TYPE_NORMAL
- en: Students should begin by consulting the [Hardware Kits](kits.qmd) chapter to
    understand platform capabilities and select appropriate hardware based on their
    learning objectives and budget constraints.
  prefs: []
  type: TYPE_NORMAL
- en: The [IDE Setup](ide_setup.qmd) chapter provides comprehensive setup procedures,
    software installation guidance, and troubleshooting resources for all supported
    platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Next Steps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After completing hardware selection and development environment setup, you’re
    ready to begin the laboratory exercises. The setup process varies by platform
    and typically takes 30-60 minutes to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'For detailed platform-specific setup instructions, refer to the individual
    setup guides:'
  prefs: []
  type: TYPE_NORMAL
- en: '[XIAOML Kit Setup](ch038.xhtml#sec-setup-overview-d638)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Arduino Nicla Vision Setup](ch032.xhtml#sec-setup-overview-dcdd)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Grove Vision AI V2 Setup](ch045.xhtml#sec-setup-nocode-applications-introduction-b740)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Raspberry Pi Setup](ch049.xhtml#sec-setup-overview-0ec9)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
