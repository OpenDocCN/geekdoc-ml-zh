["```py\nimport numpy as np                                            # arrays\nimport pandas as pd                                           # dataframes\nimport matplotlib.pyplot as plt                               # plotting\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, AutoLocator) # control of axes ticks\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor # variance inflation factor\nfrom sklearn.impute import SimpleImputer                      # basic imputation method\nfrom sklearn.experimental import enable_iterative_imputer     # required for MICE imputation\nfrom sklearn.impute import IterativeImputer                   # MICE imputation\nfrom sklearn.impute import KNNImputer                         # k-nearest neighbour imputation method\nfrom sklearn.model_selection import train_test_split          # train and test split\nfrom sklearn.linear_model import LinearRegression             # linear regression\nfrom sklearn.preprocessing import StandardScaler              # standardize the features\nfrom sklearn.preprocessing import MinMaxScaler                # min and max normalization\nfrom sklearn.preprocessing import KBinsDiscretizer            # k-bin discretizer\nfrom sklearn.neighbors import KNeighborsRegressor             # K-nearest neighbours\nfrom sklearn.ensemble import RandomForestRegressor            # random forest method\nfrom sklearn.feature_selection import mutual_info_regression  # mutual information\nfrom sklearn.metrics import mean_absolute_error               # mean absolute error\nfrom sklearn.metrics import normalized_mutual_info_score      # normalized mutual information\nfrom sklearn import tree                                      # decision tree\nfrom sklearn.tree import DecisionTreeRegressor                # regression tree\nfrom sklearn.tree import plot_tree                            # plot the decision tree\nfrom sklearn import metrics                                   # measures to check our models\nimport shap                                                   # Shapley values for feature ranking\nplt.rc('axes', axisbelow=True)                                # set axes and grids in the background for all plots\nimport math                                                  \nseed = 13\ncmap = plt.cm.inferno                                         # a good colormap for folks with color perception issues\nutcolor = '#BF5700'                                           # burnt orange, Hook'em! \n```", "```py\nIProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html \n```", "```py\ndef add_grid():                                               # add grid lines\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\ndf = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv\") # load the data from my github repo\ndf_missing = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_missing.csv\") \ndf_spatial = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv\") \nndarray_2D = np.loadtxt(\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_AI.csv\", \n                     delimiter=\",\")\nnp.random.seed(seed=seed+7)                                     # set random number seed for reproducibility\ndf['Prod'] = df['Prod'] + np.random.normal(loc=0.0,scale=600.0,size=len(df)) # add noise to demonstrate overfit and hyperparameter tuning \n```", "```py\nX = df.iloc[:,1:-1]; y = df.iloc[:,[-1]]                      # separate predictor and response, assumes response is the last features\nX_missing = df_missing.iloc[:,1:-1]; y_missing = df_missing.iloc[:,[-1]] # separate predictor and response, assumes response is the last features\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                test_size=0.2, random_state=seed)             # train and test split\nlinear_model = LinearRegression().fit(X_train,y_train)        # instantiate and train linear regression model, no hyperparmeters\ny_hat_train = linear_model.predict(X_train)                   # predict over the training data\ny_hat_test = linear_model.predict(X_test)                     # predict over the training data\nlinear_1pred_model = LinearRegression().fit(X_train[['Por']].values,y_train) # linear regression model with only 1 predictor feature\nlinear_2pred_model = LinearRegression().fit(X_train[['Por','Brittle']].values,y_train) # linear regression model with only 1 predictor feature \n```", "```py\nnormalizer = MinMaxScaler()                                   # instantiate the min/max normalizer\nnorm_array = normalizer.fit_transform(X)                      # normalize the predictor features \nX_norm = pd.DataFrame(norm_array, columns=X.columns)          # convert output to a DataFrame\nbeta_linear_model = LinearRegression().fit(X_norm,y)   # instantiate and train linear regression model, no hyperparmeters\nbeta_coef_df = pd.DataFrame({'Feature': list(X.columns),'Beta Coefficient': list(np.abs(linear_model.coef_.ravel()))})\nbeta_coef_df.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Beta Coefficient (normalized)'); plt.ylim(0,1000)\nplt.title('Feature Ranking: Beta Coefficients'); add_grid(); plt.show() \n```", "```py\ncorrelations = df.corr().loc[X.columns, y.columns[0]]         # calculate correlation matrix and extract the pred. rows for the response column\ncorrelations.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Correlation Coefficient'); plt.ylim(-1,1);\nplt.title('Feature Ranking: Correlation Coefficients'); plt.axhline(y=0.0, color='black', linestyle='--'); add_grid(); plt.show() \n```", "```py\nrank_correlations = df.corr(method='spearman').loc[X.columns, y.columns[0]] # calculate Spearman correlation with same method as Pearson above\nrank_correlations.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Rank Correlation Coefficient'); plt.ylim(-1,1); \nplt.title('Feature Ranking: Rank Correlation Coefficients'); plt.axhline(y=0.0, color='black', linestyle='--'); add_grid(); plt.show() \n```", "```py\nplt.scatter(y_train,y_hat_train,color='orange',edgecolor='black',label=r'Training Data',zorder=10) # scatter plot\nplt.scatter(y_test,y_hat_test,color=utcolor,edgecolor='black',label=r'Testing Data',zorder=10)\nplt.ylabel('Estimated Production (MCFPD)'); plt.xlabel('Truth Production (MCFPD)'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid(); \n```", "```py\nplt.scatter(y_test,y_hat_test,color=utcolor,edgecolor='black',label=r'Testing Data',zorder=10) # scatter plot\nplt.ylabel('Estimated Production (MCFPD)'); plt.xlabel('Truth Production (MCFPD)'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid() \n```", "```py\nplt.scatter(y_train,y_hat_train,color=utcolor,edgecolor='black',label=r'Training Data',zorder=10) # scatter plot\nplt.ylabel('Estimated Production (MCFPD)'); plt.xlabel('Truth Production (MCFPD)'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid(); \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\nnp.random.seed(seed=seed)                                     # set random seed for repeatability\ndf_temp['Prod'] = df_temp['Prod'] + np.random.normal(loc=0.0,scale=100.0,size=len(df_temp)) # add a feature of ones called 'Ones'\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp['Ones'] = np.ones((len(df_temp)))                     # add a feature of ones called 'Ones'\ndf_temp.head() \n```", "```py\ndf_new = pd.DataFrame({'Ones':np.ones((100)),'Zeros':np.zeros((100))}) # make new DataFrame\ndf_new.head() \n```", "```py\ndf.head(n=13)                                                 # display the first n rows of the DataFrame \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp.rename(columns={'Por':'Porosity (%)'},inplace=True)   # rename 'Por' features as 'Porosity'\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp.drop(columns=['Well','Por','AI'],inplace=True)        # remove features 'Well','Por' and 'AI'\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp = df_temp.drop(df.index[[0, 2, 4]])                   # removes samples 0, 2 and 4\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp = df_temp[df_temp['Por'] > 13.0]                      # remove all samples with 'Por' <= 13%\ndf_temp.head() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\n\nbeta_coef_df = pd.DataFrame({'Feature': list(X.columns),'Tree-based Feature Importance': list(tree_model.feature_importances_.ravel())})\nbeta_coef_df.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Feature Importance'); plt.ylim(0,1)\nplt.title('Feature Ranking: Decision Tree Feature Importance'); add_grid(); plt.show() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\ny_test_temp = y_test.copy(deep=True)\ny_test_temp['Estimated Prod'] = tree_model.predict(X_test)    # predict over the training data\ny_test_temp.head() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\ny_train_temp = y_train.copy(deep=True)\ny_train_temp['Estimated Prod'] = tree_model.predict(X_train)  # predict over the training data\ny_train_temp.head() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\nplot_tree(tree_model, feature_names=X_train.columns, filled=True); plt.show() # plot the decision tree \n```", "```py\ntuned_leaf_node = 15;                                         # decision tree model hyperparameters\ntuned_tree_model = tree.DecisionTreeRegressor(max_leaf_nodes=tuned_leaf_node).fit(X,y) # instantiate the prediction model\ny_hat = tuned_tree_model.predict(X)                           # predict over the testing cases\nplt.scatter(y,y_hat,color=utcolor,edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid(); \n```", "```py\nleaf_node = 2                                                 # set initial hyperparameter\nMSE_tree_list = []; leaf_node_list = []                       # make lists to store the results\nwhile leaf_node <= 100:                                       # loop over the number of leaf nodes hyperparameter\n    tree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instandiate and train the model\n    y_hat_test = tree_model.predict(X_test)                   # predict over the testing cases\n    MSE_tree = metrics.mean_squared_error(y_test,y_hat_test)  # calculate the MSE testing\n    MSE_tree_list.append(MSE_tree)                            # add to the list of MSE\n    leaf_node_list.append(leaf_node)                          # append leaf node to an array for plotting\n    leaf_node = leaf_node + 1\n\ntuned_leaf_nodes = leaf_node_list[np.argmin(MSE_tree_list)]           # get the k that minimizes the testing MSE\n\nplt.subplot(111)\nplt.scatter(leaf_node_list,MSE_tree_list,s=None, c=utcolor, alpha=1.0, linewidths=0.3, edgecolors=\"black\") # plot testing MSE vs. hyperparameter\nplt.axvline(x=tuned_leaf_nodes, color='red', linestyle='--') \nplt.annotate('Tuned Leaf Nodes = ' + str(tuned_leaf_nodes),[tuned_leaf_nodes+1,0.8e6],color='red',rotation= 90)\nplt.title('Tree: Withheld Testing Error vs. Number of Leaf Nodes'); plt.xlabel('Number of Leaf Nodes'); plt.ylabel('Test Mean Square Error')\nadd_grid() \n```", "```py\nselected_predictor_features = ['Por','Perm','AI','Brittle']   # set the selected predictor features\nresponse_feature = ['Prod']                                   # set the response feature\nfeatures = selected_predictor_features + response_feature     # build a list of selected predictor and response features\ndf_selected = df.loc[:,features]                              # slice the DataFrame\ndf_selected.head() \n```", "```py\nselected_predictor_features = [1,2,3,4,7]                     # set the selected predictor features\ndf_selected_predictor = df.iloc[:,selected_predictor_features] # slice the DataFrame\ndf_selected_predictor.head() \n```", "```py\nX = df.loc[:,['Por','AI','VR']]                               # extract the list the predictor feature by name\ny = df.loc[:,['Prod']]                                        # extract the response feature\nprint('Predictor features: ' + str(X.columns.tolist()) + '\\nResponse feature: ' + y.columns[0]) \n```", "```py\nPredictor features: ['Por', 'AI', 'VR']\nResponse feature: Prod \n```", "```py\nX = df.iloc[:,1:-1]; y = df.iloc[:,[-1]]                      # extract by assuming 2nd to 2nd last are predictors and last is response feature\nprint('Predictor features: ' + str(X.columns.tolist()) + '\\nResponse feature: ' + y.columns[0]) \n```", "```py\nPredictor features: ['Por', 'Perm', 'AI', 'Brittle', 'TOC', 'VR']\nResponse feature: Prod \n```", "```py\nplt.hist(df['Por'],color='darkorange',edgecolor='black',bins=20); plt.xlabel('Porosity (%)'); plt.ylabel('Frequency') # histogram\nplt.title('Porosity Distribution'); add_grid(); plt.show() \n```", "```py\nplt.hist(df['Por'],color='darkorange',edgecolor='black',weights = np.ones(len(df))/len(df),bins=20) # normalized histogram\nplt.title('Porosity Distribution'); plt.xlabel('Porosity (%)'); plt.ylabel('Probability'); add_grid(); plt.show() \n```", "```py\nim = plt.imshow(ndarray_2D,extent = [0,10000,0,10000],vmin=1500,vmax=6500,cmap = cmap) # plot of 2D ndarray, image or map feature\ncbar = plt.colorbar(im, orientation=\"vertical\", ticks=np.linspace(2500, 7500, 10)); plt.xlabel('X (m)'); plt.ylabel('Y (m)')\ncbar.set_label(r'Acoustic Impedence ($\\frac{kg}{m^3} \\cdot \\frac{m}{s} \\cdot 10^3$)', rotation=270, labelpad=20)\nplt.title('Acoustic Impedance'); plt.show() \n```", "```py\nim = plt.imshow(ndarray_2D,extent = [0,10000,0,10000],vmin=1500,vmax=6500,cmap = cmap,alpha=0.8,zorder=-1) # plot of 2D ndarray, image or map feature\nsc = plt.scatter(df_spatial['X'],df_spatial['Y'],c=df_spatial['AI'],s=20,edgecolor='black',vmin=1500,vmax=6500,cmap = cmap,zorder=10)\ncbar = plt.colorbar(im, orientation=\"vertical\", ticks=np.linspace(2500, 7500, 10)); plt.xlabel('X (m)'); plt.ylabel('Y (m)')\ncbar.set_label(r'Acoustic Impedence ($\\frac{kg}{m^3} \\cdot \\frac{m}{s} \\cdot 10^3$)', rotation=270, labelpad=20)\nplt.title('Acoustic Impedance Image and Samples at Wells'); plt.show() \n```", "```py\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")    # instantiate Multiple Imputation by Chained Equations (MICE) imputer\nX_imputed = knn_imputer.fit_transform(X_missing)              # train and apply MICE to impute the missing data\nX_imputed = pd.DataFrame(X_imputed, columns=X_missing.columns,index=X_missing.index) # make imputed results into a DataFrame with same columns as X\nX_imputed.describe()                                          # preview the DataFrame \n```", "```py\nn_neighbours = 10; p = 2; weights = 'uniform'                 # KNN model hyperparameters\nknn_model = KNeighborsRegressor(weights = weights, n_neighbors=n_neighbours, p = p).fit(X_train,y_train) # instantiate the prediction model\ny_test_temp = y_test.copy(deep=True)\ny_test_temp['Estimated Prod'] = knn_model.predict(X_test)     # predict over the training data\ny_test_temp.head() \n```", "```py\nn_neighbours = 10; p = 2; weights = 'uniform'                 # KNN model hyperparameters\nknn_model = KNeighborsRegressor(weights = weights, n_neighbors=n_neighbours, p = p).fit(X_train,y_train) # instantiate the prediction model\ny_train_temp = y_train.copy(deep=True)\ny_train_temp['Estimated Prod'] = knn_model.predict(X_train)   # predict over the training data\ny_train_temp.head() \n```", "```py\nk = 1; p = 2; weights = 'uniform'                             # KNN model hyperparameters\nneigh = KNeighborsRegressor(weights = weights, n_neighbors=k, p = p) # instantiate the prediction model\nknn_model = neigh.fit(X_train,y_train)                        # train the model with the training data\ny_train_hat = knn_model.predict(X_train)                      # predict over the testing cases\ny_test_hat = knn_model.predict(X_test)                        # predict over the testing cases\nplt.scatter(y_train,y_train_hat,color='orange',edgecolor='black',label=r'Training Data',zorder=10) # scatter plot\nplt.scatter(y_test,y_test_hat,color=utcolor,edgecolor='black',label=r'Testing Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid() \n```", "```py\ntuned_k = 15; p = 2; weights = 'uniform'                      # KNN model hyperparameters\nknn_tuned_model = KNeighborsRegressor(weights = weights, n_neighbors=tuned_k, p = 2).fit(X,y) # retrain the tuned model with all data\ny_hat = knn_tuned_model.predict(X)                            # predict over the testing cases\nplt.scatter(y,y_hat,color=utcolor,edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid() \n```", "```py\nk = 1; weights = 'uniform'                                    # set initial, lowest k hyperparameter\nMSE_knn_list = []; k_list = []                                # make lists to store the results\nwhile k <= 150:                                               # loop over the k hyperparameter\n    knn_model = KNeighborsRegressor(weights = weights, n_neighbors=k, p = 2).fit(X_train,y_train) # instandiate and train the model\n    y_test_hat = knn_model.predict(X_test)                    # predict over the testing cases\n    MSE = metrics.mean_squared_error(y_test,y_test_hat)       # calculate the MSE testing\n    MSE_knn_list.append(MSE)                                  # add to the list of MSE\n    k_list.append(k)                                          # append k to an array for plotting\n    k = k + 1\n\ntuned_k = k_list[np.argmin(MSE_knn_list)]                     # get the k that minimizes the testing MSE\n\nplt.subplot(111)                                              # plot the testing error vs. hyperparameter\nplt.scatter(k_list,MSE_knn_list,s=None, c=utcolor, alpha=0.8, linewidths=0.3, edgecolors=\"black\") \nplt.axvline(x=tuned_k, color='red', linestyle='--'); plt.annotate('Tuned k = ' + str(tuned_k),[tuned_k+3,2.0e6],color='red',rotation= 90)\nplt.title('KNN: Testing Error vs. Number of Nearest Neighbours'); plt.xlabel('Number of Nearest Neighbours'); plt.ylabel('Testing Mean Square Error')\nadd_grid() \n```", "```py\ncoef_df = pd.DataFrame({'Feature': ['Intercept'] + list(X.columns),'Coefficient': list(linear_model.intercept_) + list(linear_model.coef_.ravel())})\ncoef_df \n```", "```py\ny_test_temp = y_test.copy(deep=True)                          # make a deep copy of the y test DataFrame\ny_test_temp['Estimated Prod'] = linear_model.predict(X_test)  # predict over the training data\ny_test_temp.head() \n```", "```py\ny_train_temp = y_train.copy(deep=True)                        # make a deep copy of the y train DataFrame\ny_train_temp['Estimated Prod'] = linear_model.predict(X_train)# predict over the training data\ny_train_temp.head() \n```", "```py\nlinear_model = LinearRegression().fit(X_train,y_train)        # instantiate and train linear regression model, no hyperparmeters\ncoef_df = pd.DataFrame({'Feature': ['Intercept'] + list(X.columns),'Coefficient': list(linear_model.intercept_) + list(linear_model.coef_.ravel())})\ncoef_df \n```", "```py\ndf_listwise = df_missing.dropna(how='any',inplace=False)      # listwise deletion\ndf_listwise.describe() \n```", "```py\nxmin=0; xmax=10000; ymin=0; ymax=10000; vmin=0.1; vmax=0.27   # set plot limits and feature limits\nsc = plt.scatter(df_spatial['X'],df_spatial['Y'],c=df_spatial['Porosity'],s=20,edgecolor='black',vmin=vmin,vmax=vmax,cmap = cmap)\ncbar = plt.colorbar(sc, orientation=\"vertical\", ticks=np.linspace(vmin,vmax,10)); plt.xlabel('X (m)'); plt.ylabel('Y (m)')\ncbar.set_label(r'Porosity (fraction)', rotation=270, labelpad=20); plt.xlim(0,10000); plt.ylim(0,10000); add_grid()\nplt.title('Location Map: Porosity'); plt.show() \n```", "```py\nmean_imputer = SimpleImputer(strategy='mean')                 # instantiate mean imputor\nX_imputed = mean_imputer.fit_transform(X_missing)             # train and apply MICE to impute the missing data\nX_imputed = pd.DataFrame(X_imputed, columns=X_missing.columns,index=X_missing.index) # make imputed results into a DataFrame with same columns as X\nX_imputed.describe()                                          # preview the DataFrame \n```", "```py\nprint('Dataframe Minimum:'); print(df.min())                  # using pandas DataFrame's min and max member functions\nprint('\\nDataframe Maximum:'); print(df.max()) \n```", "```py\nDataframe Minimum:\nWell         1.000000\nPor          6.550000\nPerm         1.130000\nAI           1.280000\nBrittle     10.940000\nTOC         -0.190000\nVR           0.930000\nProd       463.579973\ndtype: float64\n\nDataframe Maximum:\nWell        200.000000\nPor          23.550000\nPerm          9.870000\nAI            4.630000\nBrittle      84.330000\nTOC           2.180000\nVR            2.870000\nProd       8428.187903\ndtype: float64 \n```", "```py\nprint('2D ndarray Minimum:'); print(np.min(ndarray_2D))       # using NumPy's min and max functions that flatten internally\nprint('\\n2D ndarray Maximum:'); print(np.max(ndarray_2D)) \n```", "```py\n2D ndarray Minimum:\n1516.949331702811\n\n2D ndarray Maximum:\n6735.039007281679 \n```", "```py\nx_values = np.linspace(5,25,100).reshape(-1,1)                # array of equally space values in the predictor feature\ny_hat_linear_1pred = linear_1pred_model.predict(x_values)     # predict over the predictor feature values\nplt.plot(np.linspace(5,25,100),y_hat_linear_1pred,color='red',lw=2) # plot the predictions vs. the predictor values\nplt.xlabel('Porosity (%)'); plt.ylabel('Production (MCFPD)'); add_grid(); plt.xlim(5,25); plt.show() \n```", "```py\nXX1, XX2 = np.meshgrid(np.arange(5,25.5,0.5),np.arange(0,102.5,2.5)) # get a regular grid of response feature values\ny_hat = linear_2pred_model.predict(np.c_[XX1.ravel(), XX2.ravel()]).reshape(-1)   # predict over grid and convert to a 1D vector\nsc = plt.scatter(XX1.ravel(),XX2.ravel(),c=y_hat,marker='s',s=50,vmin=0,vmax=10000,cmap=cmap) # convert XX1/2 to 1D vectors use for scatter plot\ncbar = plt.colorbar(sc, orientation=\"vertical\", ticks=np.linspace(0, 10000, 13)); cbar.set_label(r'Production (MCFPD)', rotation=270, labelpad=20)\nplt.xlabel('Porosity (%)'); plt.ylabel('Brittleness (%)'); plt.xlim(5,25); plt.ylim(0,100); plt.show() \n```", "```py\nMSE_test = metrics.mean_absolute_error(y_test,y_hat_test)     # calculate the training MSE\nprint('Model Training MAE: ' + str(MSE_test))                 # print the training MSE \n```", "```py\nModel Training MAE: 679.7220485741077 \n```", "```py\nMSE_train = metrics.mean_absolute_error(y_train,y_hat_train)  # calculate the training MSE\nprint('Model Training MAE: ' + str(MSE_train))                # print the training MSE \n```", "```py\nModel Training MAE: 713.4026730760603 \n```", "```py\nMSE_test = metrics.mean_squared_error(y_test,y_hat_test)      # calculate the training MSE\nprint('Model Training MSE: ' + str(MSE_test))                 # print the training MSE \n```", "```py\nModel Training MSE: 731861.1594257785 \n```", "```py\nMSE_train = metrics.mean_squared_error(y_train,y_hat_train)   # calculate the training MSE\nprint('Model Training MSE: ' + str(MSE_train))                # print the training MSE \n```", "```py\nModel Training MSE: 805986.6842431575 \n```", "```py\nmice_imputer = IterativeImputer(random_state = seed,max_iter=100) # instantiate Multiple Imputation by Chained Equations (MICE) imputer\nX_imputed = mice_imputer.fit_transform(X_missing)             # train and apply MICE to impute the missing data\nX_imputed = pd.DataFrame(X_imputed, columns=X_missing.columns,index=X_missing.index) # make imputed results into a DataFrame with same columns as X\nX_imputed.describe()                                          # preview the DataFrame \n```", "```py\nmi = mutual_info_regression(X, y.values.ravel(),random_state=0) # calculuate mutual information\nmi_series = pd.Series(mi, index=X.columns)                    # convert ndarray to pandas series (column of a DataFrame) for ease of plotting\nmi_series.plot(color=utcolor,style='o'); \nplt.xlabel('Predictor Features'); plt.ylabel('Mutual Information'); plt.ylim(0,1.5); plt.title('Feature Ranking: Mutual Information')\nadd_grid(); plt.show() \n```", "```py\nkbd = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile') # instantiate dicretizer\nX_binned = pd.DataFrame(kbd.fit_transform(X), columns=X.columns) # discretize the predictor features\ny_bins = pd.qcut(y.values.ravel(), q=10, labels=False, duplicates='drop') # discretize the response features\nnmi_scores = []\nfor col in X_binned.columns:                                  # loop over predictor features \n    nmi = normalized_mutual_info_score(X_binned[col], y_bins) # calculate normalize mutual information\n    nmi_scores.append(nmi)\nnmi_series = pd.Series(nmi_scores, index=X.columns)\nnmi_series.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Normalized Mutual Information'); plt.ylim(0,1)\nplt.title('Feature Ranking: Normalized Mutual Information')\nfor yvalue in np.arange(0.2,1.0,0.2):\n    plt.axhline(y=yvalue, color='black', linestyle='--')      # add interpretation lines\nadd_grid(); plt.show() \n```", "```py\nnormalizer = MinMaxScaler()                                   # instantiate min / max normalizer \nnorm_array = normalizer.fit_transform(X)                      # normalize the predictor features \nX_norm = pd.DataFrame(norm_array, columns=X.columns)          # convert output to a DataFrame\nX_norm.describe()                                             # preview the DataFrame \n```", "```py\nmax_leaf_node_tuned = 40; num_tree = 20; max_features = 2                # random forest model hyperparameters\nrandom_forest = RandomForestRegressor(max_leaf_nodes=max_leaf_node_tuned,random_state=seed,n_estimators=num_tree,max_features=max_features,\n                                       oob_score=True,bootstrap=True)\nrandom_forest.fit(X,y.values.ravel())\ny_rf_hat = random_forest.predict(X)                      # predict over the testing cases\nplt.scatter(y,y_rf_hat,color='orange',edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Tuned Random Forest: Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid() \n```", "```py\nmax_leaf_node = 5; num_tree = 20; max_features = 2                # random forest model hyperparameters\nrandom_forest = RandomForestRegressor(max_leaf_nodes=max_leaf_node,random_state=seed,n_estimators=num_tree,max_features=max_features,\n                                       oob_score=True,bootstrap=True)\nrandom_forest.fit(X,y.values.ravel())\ny_rf_hat = random_forest.predict(X)                      # predict over the testing cases\nplt.scatter(y,y_rf_hat,color='orange',edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Random Forest: Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid() \n```", "```py\nmax_leaf_node_mat = np.arange(2,100,2)                        # set the random forest hyperparameters\nmax_features = 1\ntrained_forests = []\nMSE_oob_list = []; node_list = []\n\nindex = 1\nfor max_leaf_node in max_leaf_node_mat:                       # loop over number of trees in our random forest\n    trained_forest = RandomForestRegressor(max_leaf_nodes=max_leaf_node, random_state=seed,n_estimators=num_tree,\n            oob_score = True,bootstrap=True,max_features=max_features).fit(X = X, y = y.values.ravel())\n    trained_forests.append(trained_forest)\n    oob_y_hat = trained_forest.oob_prediction_\n    oob_y = y[oob_y_hat > 0.0]; oob_y_hat = oob_y_hat[oob_y_hat > 0.0]; # remove if not estimated\n    MSE_oob_list.append(metrics.mean_squared_error(oob_y,oob_y_hat)); node_list.append(max_leaf_node)\n    index = index + 1\n\ntuned_node = node_list[np.argmin(MSE_oob_list)]               # get the k that minimizes the testing MSE\n\nplt.subplot(121)\nplt.scatter(node_list,MSE_oob_list,color='darkorange',edgecolor='black',alpha=0.8,s=30,zorder=10)\nplt.plot(node_list,MSE_oob_list,color='black',ls='--',zorder=1)\nplt.axvline(x=tuned_node, color='red', linestyle='--')\nplt.annotate('Tuned Max Leaf Nodes = ' + str(tuned_node),[tuned_node+1,1.2e6],color='red',rotation= 90)\nplt.xlabel('Number of Leaf Nodes'); plt.ylabel('Mean Square Error')\nplt.title('Out-of-Bag Mean Square Error vs Maximum Number of Leaf Nodes')\nadd_grid(); plt.xlim(0,100)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=0.8, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nplt.scatter(X['Por'],y['Prod'],color='darkorange',edgecolor='black',s=20); plt.xlabel('Porosity (%)'); plt.ylabel('Permeability (mD)')\nadd_grid(); plt.title('Permeability vs. Porosity'); plt.show(); \n```", "```py\nscaler = StandardScaler()                                     # instantiate standardizer \nstandard_array = scaler.fit_transform(X)                      # standardize the predictor features \nX_stand = pd.DataFrame(standard_array, columns=X.columns)     # convert output to a DataFrame\nX_stand.describe()                                            # preview the DataFrame \n```", "```py\nmax_leaf_nodes = 20\ntree_shap_model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes).fit(X, y)\nexplainer = shap.Explainer(tree_shap_model, X)                          # Explain the model with SHAP\nshap_values = explainer.shap_values(X)\nshap_avg = np.average(np.abs(shap_values),axis = 0)\nshap_df = pd.DataFrame({'Feature': list(X.columns),'Shapley Values': list(shap_avg)}); shap_df.set_index('Feature',inplace=True)\nshap_df.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Shapley Values (average, absolute)'); plt.ylim(0,2000)\nplt.title('Feature Ranking: Global Shapley Values'); add_grid(); plt.show() \n```", "```py\ndf.describe()                                                 # calculate the summary statistics of each feature \n```", "```py\ntest_proportion = 0.2                                         # set the proportion of withheld testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion, random_state=seed) # train and test split \n```", "```py\nvif_data = pd.Series(                                         # loop over predictor features and store result in pandas series for ease of plotting\n    [variance_inflation_factor(X.values, i) for i in range(X.values.shape[1])],\n    index=X.columns)\nvif_data.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Variance Inflation Factor (unitless)'); plt.ylim(0,100)\nplt.axhline(y=1, color='black', linestyle='--'); plt.axhline(y=10, color='black', linestyle='--');\nadd_grid(); plt.title('Feature Ranking: Variance Inflation Factor'); plt.show() \n```", "```py\nimport numpy as np                                            # arrays\nimport pandas as pd                                           # dataframes\nimport matplotlib.pyplot as plt                               # plotting\nfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, AutoLocator) # control of axes ticks\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor # variance inflation factor\nfrom sklearn.impute import SimpleImputer                      # basic imputation method\nfrom sklearn.experimental import enable_iterative_imputer     # required for MICE imputation\nfrom sklearn.impute import IterativeImputer                   # MICE imputation\nfrom sklearn.impute import KNNImputer                         # k-nearest neighbour imputation method\nfrom sklearn.model_selection import train_test_split          # train and test split\nfrom sklearn.linear_model import LinearRegression             # linear regression\nfrom sklearn.preprocessing import StandardScaler              # standardize the features\nfrom sklearn.preprocessing import MinMaxScaler                # min and max normalization\nfrom sklearn.preprocessing import KBinsDiscretizer            # k-bin discretizer\nfrom sklearn.neighbors import KNeighborsRegressor             # K-nearest neighbours\nfrom sklearn.ensemble import RandomForestRegressor            # random forest method\nfrom sklearn.feature_selection import mutual_info_regression  # mutual information\nfrom sklearn.metrics import mean_absolute_error               # mean absolute error\nfrom sklearn.metrics import normalized_mutual_info_score      # normalized mutual information\nfrom sklearn import tree                                      # decision tree\nfrom sklearn.tree import DecisionTreeRegressor                # regression tree\nfrom sklearn.tree import plot_tree                            # plot the decision tree\nfrom sklearn import metrics                                   # measures to check our models\nimport shap                                                   # Shapley values for feature ranking\nplt.rc('axes', axisbelow=True)                                # set axes and grids in the background for all plots\nimport math                                                  \nseed = 13\ncmap = plt.cm.inferno                                         # a good colormap for folks with color perception issues\nutcolor = '#BF5700'                                           # burnt orange, Hook'em! \n```", "```py\nIProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html \n```", "```py\ndef add_grid():                                               # add grid lines\n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\ndf = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv\") # load the data from my github repo\ndf_missing = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_missing.csv\") \ndf_spatial = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_sample_data.csv\") \nndarray_2D = np.loadtxt(\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/12_AI.csv\", \n                     delimiter=\",\")\nnp.random.seed(seed=seed+7)                                     # set random number seed for reproducibility\ndf['Prod'] = df['Prod'] + np.random.normal(loc=0.0,scale=600.0,size=len(df)) # add noise to demonstrate overfit and hyperparameter tuning \n```", "```py\nX = df.iloc[:,1:-1]; y = df.iloc[:,[-1]]                      # separate predictor and response, assumes response is the last features\nX_missing = df_missing.iloc[:,1:-1]; y_missing = df_missing.iloc[:,[-1]] # separate predictor and response, assumes response is the last features\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                test_size=0.2, random_state=seed)             # train and test split\nlinear_model = LinearRegression().fit(X_train,y_train)        # instantiate and train linear regression model, no hyperparmeters\ny_hat_train = linear_model.predict(X_train)                   # predict over the training data\ny_hat_test = linear_model.predict(X_test)                     # predict over the training data\nlinear_1pred_model = LinearRegression().fit(X_train[['Por']].values,y_train) # linear regression model with only 1 predictor feature\nlinear_2pred_model = LinearRegression().fit(X_train[['Por','Brittle']].values,y_train) # linear regression model with only 1 predictor feature \n```", "```py\nnormalizer = MinMaxScaler()                                   # instantiate the min/max normalizer\nnorm_array = normalizer.fit_transform(X)                      # normalize the predictor features \nX_norm = pd.DataFrame(norm_array, columns=X.columns)          # convert output to a DataFrame\nbeta_linear_model = LinearRegression().fit(X_norm,y)   # instantiate and train linear regression model, no hyperparmeters\nbeta_coef_df = pd.DataFrame({'Feature': list(X.columns),'Beta Coefficient': list(np.abs(linear_model.coef_.ravel()))})\nbeta_coef_df.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Beta Coefficient (normalized)'); plt.ylim(0,1000)\nplt.title('Feature Ranking: Beta Coefficients'); add_grid(); plt.show() \n```", "```py\ncorrelations = df.corr().loc[X.columns, y.columns[0]]         # calculate correlation matrix and extract the pred. rows for the response column\ncorrelations.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Correlation Coefficient'); plt.ylim(-1,1);\nplt.title('Feature Ranking: Correlation Coefficients'); plt.axhline(y=0.0, color='black', linestyle='--'); add_grid(); plt.show() \n```", "```py\nrank_correlations = df.corr(method='spearman').loc[X.columns, y.columns[0]] # calculate Spearman correlation with same method as Pearson above\nrank_correlations.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Rank Correlation Coefficient'); plt.ylim(-1,1); \nplt.title('Feature Ranking: Rank Correlation Coefficients'); plt.axhline(y=0.0, color='black', linestyle='--'); add_grid(); plt.show() \n```", "```py\nplt.scatter(y_train,y_hat_train,color='orange',edgecolor='black',label=r'Training Data',zorder=10) # scatter plot\nplt.scatter(y_test,y_hat_test,color=utcolor,edgecolor='black',label=r'Testing Data',zorder=10)\nplt.ylabel('Estimated Production (MCFPD)'); plt.xlabel('Truth Production (MCFPD)'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid(); \n```", "```py\nplt.scatter(y_test,y_hat_test,color=utcolor,edgecolor='black',label=r'Testing Data',zorder=10) # scatter plot\nplt.ylabel('Estimated Production (MCFPD)'); plt.xlabel('Truth Production (MCFPD)'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid() \n```", "```py\nplt.scatter(y_train,y_hat_train,color=utcolor,edgecolor='black',label=r'Training Data',zorder=10) # scatter plot\nplt.ylabel('Estimated Production (MCFPD)'); plt.xlabel('Truth Production (MCFPD)'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid(); \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\nnp.random.seed(seed=seed)                                     # set random seed for repeatability\ndf_temp['Prod'] = df_temp['Prod'] + np.random.normal(loc=0.0,scale=100.0,size=len(df_temp)) # add a feature of ones called 'Ones'\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp['Ones'] = np.ones((len(df_temp)))                     # add a feature of ones called 'Ones'\ndf_temp.head() \n```", "```py\ndf_new = pd.DataFrame({'Ones':np.ones((100)),'Zeros':np.zeros((100))}) # make new DataFrame\ndf_new.head() \n```", "```py\ndf.head(n=13)                                                 # display the first n rows of the DataFrame \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp.rename(columns={'Por':'Porosity (%)'},inplace=True)   # rename 'Por' features as 'Porosity'\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp.drop(columns=['Well','Por','AI'],inplace=True)        # remove features 'Well','Por' and 'AI'\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp = df_temp.drop(df.index[[0, 2, 4]])                   # removes samples 0, 2 and 4\ndf_temp.head() \n```", "```py\ndf_temp = df.copy(deep=True)                                  # make a deep copy of the DataFrame\ndf_temp = df_temp[df_temp['Por'] > 13.0]                      # remove all samples with 'Por' <= 13%\ndf_temp.head() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\n\nbeta_coef_df = pd.DataFrame({'Feature': list(X.columns),'Tree-based Feature Importance': list(tree_model.feature_importances_.ravel())})\nbeta_coef_df.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Feature Importance'); plt.ylim(0,1)\nplt.title('Feature Ranking: Decision Tree Feature Importance'); add_grid(); plt.show() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\ny_test_temp = y_test.copy(deep=True)\ny_test_temp['Estimated Prod'] = tree_model.predict(X_test)    # predict over the training data\ny_test_temp.head() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\ny_train_temp = y_train.copy(deep=True)\ny_train_temp['Estimated Prod'] = tree_model.predict(X_train)  # predict over the training data\ny_train_temp.head() \n```", "```py\nleaf_node = 5                                                 # decision tree model hyperparameters\ntree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instantiate the prediction model\nplot_tree(tree_model, feature_names=X_train.columns, filled=True); plt.show() # plot the decision tree \n```", "```py\ntuned_leaf_node = 15;                                         # decision tree model hyperparameters\ntuned_tree_model = tree.DecisionTreeRegressor(max_leaf_nodes=tuned_leaf_node).fit(X,y) # instantiate the prediction model\ny_hat = tuned_tree_model.predict(X)                           # predict over the testing cases\nplt.scatter(y,y_hat,color=utcolor,edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid(); \n```", "```py\nleaf_node = 2                                                 # set initial hyperparameter\nMSE_tree_list = []; leaf_node_list = []                       # make lists to store the results\nwhile leaf_node <= 100:                                       # loop over the number of leaf nodes hyperparameter\n    tree_model = tree.DecisionTreeRegressor(max_leaf_nodes=leaf_node).fit(X_train,y_train) # instandiate and train the model\n    y_hat_test = tree_model.predict(X_test)                   # predict over the testing cases\n    MSE_tree = metrics.mean_squared_error(y_test,y_hat_test)  # calculate the MSE testing\n    MSE_tree_list.append(MSE_tree)                            # add to the list of MSE\n    leaf_node_list.append(leaf_node)                          # append leaf node to an array for plotting\n    leaf_node = leaf_node + 1\n\ntuned_leaf_nodes = leaf_node_list[np.argmin(MSE_tree_list)]           # get the k that minimizes the testing MSE\n\nplt.subplot(111)\nplt.scatter(leaf_node_list,MSE_tree_list,s=None, c=utcolor, alpha=1.0, linewidths=0.3, edgecolors=\"black\") # plot testing MSE vs. hyperparameter\nplt.axvline(x=tuned_leaf_nodes, color='red', linestyle='--') \nplt.annotate('Tuned Leaf Nodes = ' + str(tuned_leaf_nodes),[tuned_leaf_nodes+1,0.8e6],color='red',rotation= 90)\nplt.title('Tree: Withheld Testing Error vs. Number of Leaf Nodes'); plt.xlabel('Number of Leaf Nodes'); plt.ylabel('Test Mean Square Error')\nadd_grid() \n```", "```py\nselected_predictor_features = ['Por','Perm','AI','Brittle']   # set the selected predictor features\nresponse_feature = ['Prod']                                   # set the response feature\nfeatures = selected_predictor_features + response_feature     # build a list of selected predictor and response features\ndf_selected = df.loc[:,features]                              # slice the DataFrame\ndf_selected.head() \n```", "```py\nselected_predictor_features = [1,2,3,4,7]                     # set the selected predictor features\ndf_selected_predictor = df.iloc[:,selected_predictor_features] # slice the DataFrame\ndf_selected_predictor.head() \n```", "```py\nX = df.loc[:,['Por','AI','VR']]                               # extract the list the predictor feature by name\ny = df.loc[:,['Prod']]                                        # extract the response feature\nprint('Predictor features: ' + str(X.columns.tolist()) + '\\nResponse feature: ' + y.columns[0]) \n```", "```py\nPredictor features: ['Por', 'AI', 'VR']\nResponse feature: Prod \n```", "```py\nX = df.iloc[:,1:-1]; y = df.iloc[:,[-1]]                      # extract by assuming 2nd to 2nd last are predictors and last is response feature\nprint('Predictor features: ' + str(X.columns.tolist()) + '\\nResponse feature: ' + y.columns[0]) \n```", "```py\nPredictor features: ['Por', 'Perm', 'AI', 'Brittle', 'TOC', 'VR']\nResponse feature: Prod \n```", "```py\nplt.hist(df['Por'],color='darkorange',edgecolor='black',bins=20); plt.xlabel('Porosity (%)'); plt.ylabel('Frequency') # histogram\nplt.title('Porosity Distribution'); add_grid(); plt.show() \n```", "```py\nplt.hist(df['Por'],color='darkorange',edgecolor='black',weights = np.ones(len(df))/len(df),bins=20) # normalized histogram\nplt.title('Porosity Distribution'); plt.xlabel('Porosity (%)'); plt.ylabel('Probability'); add_grid(); plt.show() \n```", "```py\nim = plt.imshow(ndarray_2D,extent = [0,10000,0,10000],vmin=1500,vmax=6500,cmap = cmap) # plot of 2D ndarray, image or map feature\ncbar = plt.colorbar(im, orientation=\"vertical\", ticks=np.linspace(2500, 7500, 10)); plt.xlabel('X (m)'); plt.ylabel('Y (m)')\ncbar.set_label(r'Acoustic Impedence ($\\frac{kg}{m^3} \\cdot \\frac{m}{s} \\cdot 10^3$)', rotation=270, labelpad=20)\nplt.title('Acoustic Impedance'); plt.show() \n```", "```py\nim = plt.imshow(ndarray_2D,extent = [0,10000,0,10000],vmin=1500,vmax=6500,cmap = cmap,alpha=0.8,zorder=-1) # plot of 2D ndarray, image or map feature\nsc = plt.scatter(df_spatial['X'],df_spatial['Y'],c=df_spatial['AI'],s=20,edgecolor='black',vmin=1500,vmax=6500,cmap = cmap,zorder=10)\ncbar = plt.colorbar(im, orientation=\"vertical\", ticks=np.linspace(2500, 7500, 10)); plt.xlabel('X (m)'); plt.ylabel('Y (m)')\ncbar.set_label(r'Acoustic Impedence ($\\frac{kg}{m^3} \\cdot \\frac{m}{s} \\cdot 10^3$)', rotation=270, labelpad=20)\nplt.title('Acoustic Impedance Image and Samples at Wells'); plt.show() \n```", "```py\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")    # instantiate Multiple Imputation by Chained Equations (MICE) imputer\nX_imputed = knn_imputer.fit_transform(X_missing)              # train and apply MICE to impute the missing data\nX_imputed = pd.DataFrame(X_imputed, columns=X_missing.columns,index=X_missing.index) # make imputed results into a DataFrame with same columns as X\nX_imputed.describe()                                          # preview the DataFrame \n```", "```py\nn_neighbours = 10; p = 2; weights = 'uniform'                 # KNN model hyperparameters\nknn_model = KNeighborsRegressor(weights = weights, n_neighbors=n_neighbours, p = p).fit(X_train,y_train) # instantiate the prediction model\ny_test_temp = y_test.copy(deep=True)\ny_test_temp['Estimated Prod'] = knn_model.predict(X_test)     # predict over the training data\ny_test_temp.head() \n```", "```py\nn_neighbours = 10; p = 2; weights = 'uniform'                 # KNN model hyperparameters\nknn_model = KNeighborsRegressor(weights = weights, n_neighbors=n_neighbours, p = p).fit(X_train,y_train) # instantiate the prediction model\ny_train_temp = y_train.copy(deep=True)\ny_train_temp['Estimated Prod'] = knn_model.predict(X_train)   # predict over the training data\ny_train_temp.head() \n```", "```py\nk = 1; p = 2; weights = 'uniform'                             # KNN model hyperparameters\nneigh = KNeighborsRegressor(weights = weights, n_neighbors=k, p = p) # instantiate the prediction model\nknn_model = neigh.fit(X_train,y_train)                        # train the model with the training data\ny_train_hat = knn_model.predict(X_train)                      # predict over the testing cases\ny_test_hat = knn_model.predict(X_test)                        # predict over the testing cases\nplt.scatter(y_train,y_train_hat,color='orange',edgecolor='black',label=r'Training Data',zorder=10) # scatter plot\nplt.scatter(y_test,y_test_hat,color=utcolor,edgecolor='black',label=r'Testing Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid() \n```", "```py\ntuned_k = 15; p = 2; weights = 'uniform'                      # KNN model hyperparameters\nknn_tuned_model = KNeighborsRegressor(weights = weights, n_neighbors=tuned_k, p = 2).fit(X,y) # retrain the tuned model with all data\ny_hat = knn_tuned_model.predict(X)                            # predict over the testing cases\nplt.scatter(y,y_hat,color=utcolor,edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000); add_grid() \n```", "```py\nk = 1; weights = 'uniform'                                    # set initial, lowest k hyperparameter\nMSE_knn_list = []; k_list = []                                # make lists to store the results\nwhile k <= 150:                                               # loop over the k hyperparameter\n    knn_model = KNeighborsRegressor(weights = weights, n_neighbors=k, p = 2).fit(X_train,y_train) # instandiate and train the model\n    y_test_hat = knn_model.predict(X_test)                    # predict over the testing cases\n    MSE = metrics.mean_squared_error(y_test,y_test_hat)       # calculate the MSE testing\n    MSE_knn_list.append(MSE)                                  # add to the list of MSE\n    k_list.append(k)                                          # append k to an array for plotting\n    k = k + 1\n\ntuned_k = k_list[np.argmin(MSE_knn_list)]                     # get the k that minimizes the testing MSE\n\nplt.subplot(111)                                              # plot the testing error vs. hyperparameter\nplt.scatter(k_list,MSE_knn_list,s=None, c=utcolor, alpha=0.8, linewidths=0.3, edgecolors=\"black\") \nplt.axvline(x=tuned_k, color='red', linestyle='--'); plt.annotate('Tuned k = ' + str(tuned_k),[tuned_k+3,2.0e6],color='red',rotation= 90)\nplt.title('KNN: Testing Error vs. Number of Nearest Neighbours'); plt.xlabel('Number of Nearest Neighbours'); plt.ylabel('Testing Mean Square Error')\nadd_grid() \n```", "```py\ncoef_df = pd.DataFrame({'Feature': ['Intercept'] + list(X.columns),'Coefficient': list(linear_model.intercept_) + list(linear_model.coef_.ravel())})\ncoef_df \n```", "```py\ny_test_temp = y_test.copy(deep=True)                          # make a deep copy of the y test DataFrame\ny_test_temp['Estimated Prod'] = linear_model.predict(X_test)  # predict over the training data\ny_test_temp.head() \n```", "```py\ny_train_temp = y_train.copy(deep=True)                        # make a deep copy of the y train DataFrame\ny_train_temp['Estimated Prod'] = linear_model.predict(X_train)# predict over the training data\ny_train_temp.head() \n```", "```py\nlinear_model = LinearRegression().fit(X_train,y_train)        # instantiate and train linear regression model, no hyperparmeters\ncoef_df = pd.DataFrame({'Feature': ['Intercept'] + list(X.columns),'Coefficient': list(linear_model.intercept_) + list(linear_model.coef_.ravel())})\ncoef_df \n```", "```py\ndf_listwise = df_missing.dropna(how='any',inplace=False)      # listwise deletion\ndf_listwise.describe() \n```", "```py\nxmin=0; xmax=10000; ymin=0; ymax=10000; vmin=0.1; vmax=0.27   # set plot limits and feature limits\nsc = plt.scatter(df_spatial['X'],df_spatial['Y'],c=df_spatial['Porosity'],s=20,edgecolor='black',vmin=vmin,vmax=vmax,cmap = cmap)\ncbar = plt.colorbar(sc, orientation=\"vertical\", ticks=np.linspace(vmin,vmax,10)); plt.xlabel('X (m)'); plt.ylabel('Y (m)')\ncbar.set_label(r'Porosity (fraction)', rotation=270, labelpad=20); plt.xlim(0,10000); plt.ylim(0,10000); add_grid()\nplt.title('Location Map: Porosity'); plt.show() \n```", "```py\nmean_imputer = SimpleImputer(strategy='mean')                 # instantiate mean imputor\nX_imputed = mean_imputer.fit_transform(X_missing)             # train and apply MICE to impute the missing data\nX_imputed = pd.DataFrame(X_imputed, columns=X_missing.columns,index=X_missing.index) # make imputed results into a DataFrame with same columns as X\nX_imputed.describe()                                          # preview the DataFrame \n```", "```py\nprint('Dataframe Minimum:'); print(df.min())                  # using pandas DataFrame's min and max member functions\nprint('\\nDataframe Maximum:'); print(df.max()) \n```", "```py\nDataframe Minimum:\nWell         1.000000\nPor          6.550000\nPerm         1.130000\nAI           1.280000\nBrittle     10.940000\nTOC         -0.190000\nVR           0.930000\nProd       463.579973\ndtype: float64\n\nDataframe Maximum:\nWell        200.000000\nPor          23.550000\nPerm          9.870000\nAI            4.630000\nBrittle      84.330000\nTOC           2.180000\nVR            2.870000\nProd       8428.187903\ndtype: float64 \n```", "```py\nprint('2D ndarray Minimum:'); print(np.min(ndarray_2D))       # using NumPy's min and max functions that flatten internally\nprint('\\n2D ndarray Maximum:'); print(np.max(ndarray_2D)) \n```", "```py\n2D ndarray Minimum:\n1516.949331702811\n\n2D ndarray Maximum:\n6735.039007281679 \n```", "```py\nx_values = np.linspace(5,25,100).reshape(-1,1)                # array of equally space values in the predictor feature\ny_hat_linear_1pred = linear_1pred_model.predict(x_values)     # predict over the predictor feature values\nplt.plot(np.linspace(5,25,100),y_hat_linear_1pred,color='red',lw=2) # plot the predictions vs. the predictor values\nplt.xlabel('Porosity (%)'); plt.ylabel('Production (MCFPD)'); add_grid(); plt.xlim(5,25); plt.show() \n```", "```py\nXX1, XX2 = np.meshgrid(np.arange(5,25.5,0.5),np.arange(0,102.5,2.5)) # get a regular grid of response feature values\ny_hat = linear_2pred_model.predict(np.c_[XX1.ravel(), XX2.ravel()]).reshape(-1)   # predict over grid and convert to a 1D vector\nsc = plt.scatter(XX1.ravel(),XX2.ravel(),c=y_hat,marker='s',s=50,vmin=0,vmax=10000,cmap=cmap) # convert XX1/2 to 1D vectors use for scatter plot\ncbar = plt.colorbar(sc, orientation=\"vertical\", ticks=np.linspace(0, 10000, 13)); cbar.set_label(r'Production (MCFPD)', rotation=270, labelpad=20)\nplt.xlabel('Porosity (%)'); plt.ylabel('Brittleness (%)'); plt.xlim(5,25); plt.ylim(0,100); plt.show() \n```", "```py\nMSE_test = metrics.mean_absolute_error(y_test,y_hat_test)     # calculate the training MSE\nprint('Model Training MAE: ' + str(MSE_test))                 # print the training MSE \n```", "```py\nModel Training MAE: 679.7220485741077 \n```", "```py\nMSE_train = metrics.mean_absolute_error(y_train,y_hat_train)  # calculate the training MSE\nprint('Model Training MAE: ' + str(MSE_train))                # print the training MSE \n```", "```py\nModel Training MAE: 713.4026730760603 \n```", "```py\nMSE_test = metrics.mean_squared_error(y_test,y_hat_test)      # calculate the training MSE\nprint('Model Training MSE: ' + str(MSE_test))                 # print the training MSE \n```", "```py\nModel Training MSE: 731861.1594257785 \n```", "```py\nMSE_train = metrics.mean_squared_error(y_train,y_hat_train)   # calculate the training MSE\nprint('Model Training MSE: ' + str(MSE_train))                # print the training MSE \n```", "```py\nModel Training MSE: 805986.6842431575 \n```", "```py\nmice_imputer = IterativeImputer(random_state = seed,max_iter=100) # instantiate Multiple Imputation by Chained Equations (MICE) imputer\nX_imputed = mice_imputer.fit_transform(X_missing)             # train and apply MICE to impute the missing data\nX_imputed = pd.DataFrame(X_imputed, columns=X_missing.columns,index=X_missing.index) # make imputed results into a DataFrame with same columns as X\nX_imputed.describe()                                          # preview the DataFrame \n```", "```py\nmi = mutual_info_regression(X, y.values.ravel(),random_state=0) # calculuate mutual information\nmi_series = pd.Series(mi, index=X.columns)                    # convert ndarray to pandas series (column of a DataFrame) for ease of plotting\nmi_series.plot(color=utcolor,style='o'); \nplt.xlabel('Predictor Features'); plt.ylabel('Mutual Information'); plt.ylim(0,1.5); plt.title('Feature Ranking: Mutual Information')\nadd_grid(); plt.show() \n```", "```py\nkbd = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile') # instantiate dicretizer\nX_binned = pd.DataFrame(kbd.fit_transform(X), columns=X.columns) # discretize the predictor features\ny_bins = pd.qcut(y.values.ravel(), q=10, labels=False, duplicates='drop') # discretize the response features\nnmi_scores = []\nfor col in X_binned.columns:                                  # loop over predictor features \n    nmi = normalized_mutual_info_score(X_binned[col], y_bins) # calculate normalize mutual information\n    nmi_scores.append(nmi)\nnmi_series = pd.Series(nmi_scores, index=X.columns)\nnmi_series.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Normalized Mutual Information'); plt.ylim(0,1)\nplt.title('Feature Ranking: Normalized Mutual Information')\nfor yvalue in np.arange(0.2,1.0,0.2):\n    plt.axhline(y=yvalue, color='black', linestyle='--')      # add interpretation lines\nadd_grid(); plt.show() \n```", "```py\nnormalizer = MinMaxScaler()                                   # instantiate min / max normalizer \nnorm_array = normalizer.fit_transform(X)                      # normalize the predictor features \nX_norm = pd.DataFrame(norm_array, columns=X.columns)          # convert output to a DataFrame\nX_norm.describe()                                             # preview the DataFrame \n```", "```py\nmax_leaf_node_tuned = 40; num_tree = 20; max_features = 2                # random forest model hyperparameters\nrandom_forest = RandomForestRegressor(max_leaf_nodes=max_leaf_node_tuned,random_state=seed,n_estimators=num_tree,max_features=max_features,\n                                       oob_score=True,bootstrap=True)\nrandom_forest.fit(X,y.values.ravel())\ny_rf_hat = random_forest.predict(X)                      # predict over the testing cases\nplt.scatter(y,y_rf_hat,color='orange',edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Tuned Random Forest: Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid() \n```", "```py\nmax_leaf_node = 5; num_tree = 20; max_features = 2                # random forest model hyperparameters\nrandom_forest = RandomForestRegressor(max_leaf_nodes=max_leaf_node,random_state=seed,n_estimators=num_tree,max_features=max_features,\n                                       oob_score=True,bootstrap=True)\nrandom_forest.fit(X,y.values.ravel())\ny_rf_hat = random_forest.predict(X)                      # predict over the testing cases\nplt.scatter(y,y_rf_hat,color='orange',edgecolor='black',label=r'All Data',zorder=10) # scatter plot\nplt.ylabel('Estimated'); plt.xlabel('Truth'); plt.title('Random Forest: Cross Validation Plot'); plt.legend(loc = 'upper left')\nplt.plot([0,8000],[0,8000],color='red'); plt.xlim(0,8000,); plt.ylim(0,8000) \nadd_grid() \n```", "```py\nmax_leaf_node_mat = np.arange(2,100,2)                        # set the random forest hyperparameters\nmax_features = 1\ntrained_forests = []\nMSE_oob_list = []; node_list = []\n\nindex = 1\nfor max_leaf_node in max_leaf_node_mat:                       # loop over number of trees in our random forest\n    trained_forest = RandomForestRegressor(max_leaf_nodes=max_leaf_node, random_state=seed,n_estimators=num_tree,\n            oob_score = True,bootstrap=True,max_features=max_features).fit(X = X, y = y.values.ravel())\n    trained_forests.append(trained_forest)\n    oob_y_hat = trained_forest.oob_prediction_\n    oob_y = y[oob_y_hat > 0.0]; oob_y_hat = oob_y_hat[oob_y_hat > 0.0]; # remove if not estimated\n    MSE_oob_list.append(metrics.mean_squared_error(oob_y,oob_y_hat)); node_list.append(max_leaf_node)\n    index = index + 1\n\ntuned_node = node_list[np.argmin(MSE_oob_list)]               # get the k that minimizes the testing MSE\n\nplt.subplot(121)\nplt.scatter(node_list,MSE_oob_list,color='darkorange',edgecolor='black',alpha=0.8,s=30,zorder=10)\nplt.plot(node_list,MSE_oob_list,color='black',ls='--',zorder=1)\nplt.axvline(x=tuned_node, color='red', linestyle='--')\nplt.annotate('Tuned Max Leaf Nodes = ' + str(tuned_node),[tuned_node+1,1.2e6],color='red',rotation= 90)\nplt.xlabel('Number of Leaf Nodes'); plt.ylabel('Mean Square Error')\nplt.title('Out-of-Bag Mean Square Error vs Maximum Number of Leaf Nodes')\nadd_grid(); plt.xlim(0,100)\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=0.8, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nplt.scatter(X['Por'],y['Prod'],color='darkorange',edgecolor='black',s=20); plt.xlabel('Porosity (%)'); plt.ylabel('Permeability (mD)')\nadd_grid(); plt.title('Permeability vs. Porosity'); plt.show(); \n```", "```py\nscaler = StandardScaler()                                     # instantiate standardizer \nstandard_array = scaler.fit_transform(X)                      # standardize the predictor features \nX_stand = pd.DataFrame(standard_array, columns=X.columns)     # convert output to a DataFrame\nX_stand.describe()                                            # preview the DataFrame \n```", "```py\nmax_leaf_nodes = 20\ntree_shap_model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes).fit(X, y)\nexplainer = shap.Explainer(tree_shap_model, X)                          # Explain the model with SHAP\nshap_values = explainer.shap_values(X)\nshap_avg = np.average(np.abs(shap_values),axis = 0)\nshap_df = pd.DataFrame({'Feature': list(X.columns),'Shapley Values': list(shap_avg)}); shap_df.set_index('Feature',inplace=True)\nshap_df.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Shapley Values (average, absolute)'); plt.ylim(0,2000)\nplt.title('Feature Ranking: Global Shapley Values'); add_grid(); plt.show() \n```", "```py\ndf.describe()                                                 # calculate the summary statistics of each feature \n```", "```py\ntest_proportion = 0.2                                         # set the proportion of withheld testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion, random_state=seed) # train and test split \n```", "```py\nvif_data = pd.Series(                                         # loop over predictor features and store result in pandas series for ease of plotting\n    [variance_inflation_factor(X.values, i) for i in range(X.values.shape[1])],\n    index=X.columns)\nvif_data.plot(color=utcolor,style='o'); plt.xlabel('Predictor Features'); plt.ylabel('Variance Inflation Factor (unitless)'); plt.ylim(0,100)\nplt.axhline(y=1, color='black', linestyle='--'); plt.axhline(y=10, color='black', linestyle='--');\nadd_grid(); plt.title('Feature Ranking: Variance Inflation Factor'); plt.show() \n```"]