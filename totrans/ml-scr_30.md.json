["```py\n## Import numpy and visualization packages\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import datasets\n\n## Import Boston and standardize\nnp.random.seed(123)\nboston = datasets.load_boston()\nX_boston = boston['data']\nX_boston = (X_boston - X_boston.mean(0))/(X_boston.std(0))\ny_boston = boston['target']\n\n## Train-test split\nnp.random.seed(123)\ntest_frac = 0.25\ntest_size = int(len(y_boston)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y_boston)), test_size, replace = False)\nX_boston_train = np.delete(X_boston, test_idxs, 0)\ny_boston_train = np.delete(y_boston, test_idxs, 0)\nX_boston_test = X_boston[test_idxs]\ny_boston_test = y_boston[test_idxs]\n\n## Import cancer and standardize\nnp.random.seed(123)\ncancer = datasets.load_breast_cancer()\nX_cancer = cancer['data']\nX_cancer = (X_cancer - X_cancer.mean(0))/(X_cancer.std(0))\ny_cancer = 1*(cancer['target'] == 1)\n\n## Train-test split\nnp.random.seed(123)\ntest_frac = 0.25\ntest_size = int(len(y_cancer)*test_frac)\ntest_idxs = np.random.choice(np.arange(len(y_cancer)), test_size, replace = False)\nX_cancer_train = np.delete(X_cancer, test_idxs, 0)\ny_cancer_train = np.delete(y_cancer, test_idxs, 0)\nX_cancer_test = X_cancer[test_idxs]\ny_cancer_test = y_cancer[test_idxs] \n```", "```py\n## Activation Functions \ndef ReLU(h):\n    return np.maximum(h, 0)\n\ndef sigmoid(h):\n    return 1/(1 + np.exp(-h))\n\ndef linear(h):\n    return h\n\nactivation_function_dict = {'ReLU':ReLU, 'sigmoid':sigmoid, 'linear':linear} \n```", "```py\nclass FeedForwardNeuralNetwork:\n\n    def fit(self, X, y, n_hidden, f1 = 'ReLU', f2 = 'linear', loss = 'RSS', lr = 1e-5, n_iter = 1e3, seed = None):\n\n        ## Store Information\n        self.X = X\n        self.y = y.reshape(len(y), -1)\n        self.N = len(X)\n        self.D_X = self.X.shape[1]\n        self.D_y = self.y.shape[1]\n        self.D_h = n_hidden\n        self.f1, self.f2 = f1, f2\n        self.loss = loss\n        self.lr = lr\n        self.n_iter = int(n_iter)\n        self.seed = seed\n\n        ## Instantiate Weights\n        np.random.seed(self.seed)\n        self.W1 = np.random.randn(self.D_h, self.D_X)/5\n        self.c1 = np.random.randn(self.D_h, 1)/5\n        self.W2 = np.random.randn(self.D_y, self.D_h)/5\n        self.c2 = np.random.randn(self.D_y, 1)/5\n\n        ## Instantiate Outputs\n        self.h1 = np.dot(self.W1, self.X.T) + self.c1\n        self.z1 = activation_function_dict[f1](self.h1)\n        self.h2 = np.dot(self.W2, self.z1) + self.c2\n        self.yhat = activation_function_dict[f2](self.h2)\n\n        ## Fit Weights\n        for iteration in range(self.n_iter):\n\n            dL_dW2 = 0\n            dL_dc2 = 0\n            dL_dW1 = 0\n            dL_dc1 = 0\n\n            for n in range(self.N):\n\n                # dL_dyhat\n                if loss == 'RSS':\n                    dL_dyhat = -2*(self.y[n] - self.yhat[:,n]).T # (1, D_y)\n                elif loss == 'log':\n                    dL_dyhat = (-(self.y[n]/self.yhat[:,n]) + (1-self.y[n])/(1-self.yhat[:,n])).T # (1, D_y)\n\n                ## LAYER 2 ## \n                # dyhat_dh2 \n                if f2 == 'linear':\n                    dyhat_dh2 = np.eye(self.D_y) # (D_y, D_y)\n                elif f2 == 'sigmoid':\n                    dyhat_dh2 = np.diag(sigmoid(self.h2[:,n])*(1-sigmoid(self.h2[:,n]))) # (D_y, D_y)\n\n                # dh2_dc2\n                dh2_dc2 = np.eye(self.D_y) # (D_y, D_y)\n\n                # dh2_dW2 \n                dh2_dW2 = np.zeros((self.D_y, self.D_y, self.D_h)) # (D_y, (D_y, D_h)) \n                for i in range(self.D_y):\n                    dh2_dW2[i] = self.z1[:,n] \n\n                # dh2_dz1\n                dh2_dz1 = self.W2 # (D_y, D_h)\n\n                ## LAYER 1 ##\n                # dz1_dh1\n                if f1 == 'ReLU':\n                    dz1_dh1 = 1*np.diag(self.h1[:,n] > 0) # (D_h, D_h) \n                elif f1 == 'linear':\n                    dz1_dh1 = np.eye(self.D_h) # (D_h, D_h)\n\n                # dh1_dc1 \n                dh1_dc1 = np.eye(self.D_h) # (D_h, D_h)\n\n                # dh1_dW1\n                dh1_dW1 = np.zeros((self.D_h, self.D_h, self.D_X)) # (D_h, (D_h, D_X))\n                for i in range(self.D_h):\n                    dh1_dW1[i] = self.X[n]\n\n                ## DERIVATIVES W.R.T. LOSS ## \n                dL_dh2 = dL_dyhat @ dyhat_dh2\n                dL_dW2 += dL_dh2 @ dh2_dW2\n                dL_dc2 += dL_dh2 @ dh2_dc2\n                dL_dh1 = dL_dh2 @ dh2_dz1 @ dz1_dh1\n                dL_dW1 += dL_dh1 @ dh1_dW1\n                dL_dc1 += dL_dh1 @ dh1_dc1\n\n            ## Update Weights\n            self.W1 -= self.lr * dL_dW1\n            self.c1 -= self.lr * dL_dc1.reshape(-1, 1)           \n            self.W2 -= self.lr * dL_dW2            \n            self.c2 -= self.lr * dL_dc2.reshape(-1, 1)                    \n\n            ## Update Outputs\n            self.h1 = np.dot(self.W1, self.X.T) + self.c1\n            self.z1 = activation_function_dict[f1](self.h1)\n            self.h2 = np.dot(self.W2, self.z1) + self.c2\n            self.yhat = activation_function_dict[f2](self.h2)\n\n    def predict(self, X_test):\n        self.h1 = np.dot(self.W1, X_test.T) + self.c1\n        self.z1 = activation_function_dict[self.f1](self.h1)\n        self.h2 = np.dot(self.W2, self.z1) + self.c2\n        self.yhat = activation_function_dict[self.f2](self.h2)        \n        return self.yhat \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_boston_train, y_boston_train, n_hidden = 8)\ny_boston_test_hat = ffnn.predict(X_boston_test)\n\nfig, ax = plt.subplots()\nsns.scatterplot(y_boston_test, y_boston_test_hat[0])\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'$y$ vs. $\\hat{y}$')\nsns.despine() \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_cancer_train, y_cancer_train, n_hidden = 8,\n         loss = 'log', f2 = 'sigmoid', seed = 123, lr = 1e-4)\ny_cancer_test_hat = ffnn.predict(X_cancer_test)\nnp.mean(y_cancer_test_hat.round() == y_cancer_test) \n```", "```py\n0.9929577464788732 \n```", "```py\nclass FeedForwardNeuralNetwork:\n\n    def fit(self, X, Y, n_hidden, f1 = 'ReLU', f2 = 'linear', loss = 'RSS', lr = 1e-5, n_iter = 5e3, seed = None):\n\n        ## Store Information\n        self.X = X\n        self.Y = Y.reshape(len(Y), -1)\n        self.N = len(X)\n        self.D_X = self.X.shape[1]\n        self.D_Y = self.Y.shape[1]\n        self.Xt = self.X.T\n        self.Yt = self.Y.T\n        self.D_h = n_hidden\n        self.f1, self.f2 = f1, f2\n        self.loss = loss\n        self.lr = lr\n        self.n_iter = int(n_iter)\n        self.seed = seed\n\n        ## Instantiate Weights\n        np.random.seed(self.seed)\n        self.W1 = np.random.randn(self.D_h, self.D_X)/5\n        self.c1 = np.random.randn(self.D_h, 1)/5\n        self.W2 = np.random.randn(self.D_Y, self.D_h)/5\n        self.c2 = np.random.randn(self.D_Y, 1)/5\n\n        ## Instantiate Outputs\n        self.H1 = (self.W1 @ self.Xt) + self.c1\n        self.Z1 = activation_function_dict[self.f1](self.H1)\n        self.H2 = (self.W2 @ self.Z1) + self.c2\n        self.Yhatt = activation_function_dict[self.f2](self.H2)\n\n        ## Fit Weights\n        for iteration in range(self.n_iter):\n\n            # Yhat #\n            if self.loss == 'RSS':\n                self.dL_dYhatt = -(self.Yt - self.Yhatt) # (D_Y x N)\n            elif self.loss == 'log':\n                self.dL_dYhatt = (-(self.Yt/self.Yhatt) + (1-self.Yt)/(1-self.Yhatt)) # (D_y x N)\n\n            # H2 #\n            if self.f2 == 'linear':\n                self.dYhatt_dH2 = np.ones((self.D_Y, self.N))\n            elif self.f2 == 'sigmoid':\n                self.dYhatt_dH2 = sigmoid(self.H2) * (1- sigmoid(self.H2))\n            self.dL_dH2 = self.dL_dYhatt * self.dYhatt_dH2 # (D_Y x N)\n\n            # c2 # \n            self.dL_dc2 = np.sum(self.dL_dH2, 1) # (D_y)\n\n            # W2 # \n            self.dL_dW2 = np.tensordot(self.dL_dH2, self.Z1, (1,1)) # (D_Y x D_h)\n\n            # Z1 #\n            self.dL_dZ1 = np.tensordot(self.W2, self.dL_dH2, (0, 0)) # (D_h x N)\n\n            # H1 #\n            if self.f1 == 'ReLU':\n                self.dL_dH1 = self.dL_dZ1 * np.maximum(self.H1, 0) # (D_h x N)\n            elif self.f1 == 'linear':\n                self.dL_dH1 = self.dL_dZ1 # (D_h x N)\n\n            # c1 #\n            self.dL_dc1 = np.sum(self.dL_dH1, 1) # (D_h)\n\n            # W1 # \n            self.dL_dW1 = np.tensordot(self.dL_dH1, self.Xt, (1,1)) # (D_h, D_X)\n\n            ## Update Weights\n            self.W1 -= self.lr * self.dL_dW1\n            self.c1 -= self.lr * self.dL_dc1.reshape(-1, 1)           \n            self.W2 -= self.lr * self.dL_dW2            \n            self.c2 -= self.lr * self.dL_dc2.reshape(-1, 1)                    \n\n            ## Update Outputs\n            self.H1 = (self.W1 @ self.Xt) + self.c1\n            self.Z1 = activation_function_dict[self.f1](self.H1)\n            self.H2 = (self.W2 @ self.Z1) + self.c2\n            self.Yhatt = activation_function_dict[self.f2](self.H2)  \n\n    def predict(self, X_test):\n        X_testt = X_test.T\n        self.h1 = (self.W1 @ X_testt) + self.c1\n        self.z1 = activation_function_dict[self.f1](self.h1)\n        self.h2 = (self.W2 @ self.z1) + self.c2\n        self.Yhatt = activation_function_dict[self.f2](self.h2)        \n        return self.Yhatt \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_boston_train, y_boston_train, n_hidden = 8)\ny_boston_test_hat = ffnn.predict(X_boston_test)\n\nfig, ax = plt.subplots()\nsns.scatterplot(y_boston_test, y_boston_test_hat[0])\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'$y$ vs. $\\hat{y}$')\nsns.despine() \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_cancer_train, y_cancer_train, n_hidden = 8,\n         loss = 'log', f2 = 'sigmoid', seed = 123, lr = 1e-4)\ny_cancer_test_hat = ffnn.predict(X_cancer_test)\nnp.mean(y_cancer_test_hat.round() == y_cancer_test) \n```", "```py\n0.9929577464788732 \n```", "```py\nclass FeedForwardNeuralNetwork:\n\n    def fit(self, X, y, n_hidden, f1 = 'ReLU', f2 = 'linear', loss = 'RSS', lr = 1e-5, n_iter = 1e3, seed = None):\n\n        ## Store Information\n        self.X = X\n        self.y = y.reshape(len(y), -1)\n        self.N = len(X)\n        self.D_X = self.X.shape[1]\n        self.D_y = self.y.shape[1]\n        self.D_h = n_hidden\n        self.f1, self.f2 = f1, f2\n        self.loss = loss\n        self.lr = lr\n        self.n_iter = int(n_iter)\n        self.seed = seed\n\n        ## Instantiate Weights\n        np.random.seed(self.seed)\n        self.W1 = np.random.randn(self.D_h, self.D_X)/5\n        self.c1 = np.random.randn(self.D_h, 1)/5\n        self.W2 = np.random.randn(self.D_y, self.D_h)/5\n        self.c2 = np.random.randn(self.D_y, 1)/5\n\n        ## Instantiate Outputs\n        self.h1 = np.dot(self.W1, self.X.T) + self.c1\n        self.z1 = activation_function_dict[f1](self.h1)\n        self.h2 = np.dot(self.W2, self.z1) + self.c2\n        self.yhat = activation_function_dict[f2](self.h2)\n\n        ## Fit Weights\n        for iteration in range(self.n_iter):\n\n            dL_dW2 = 0\n            dL_dc2 = 0\n            dL_dW1 = 0\n            dL_dc1 = 0\n\n            for n in range(self.N):\n\n                # dL_dyhat\n                if loss == 'RSS':\n                    dL_dyhat = -2*(self.y[n] - self.yhat[:,n]).T # (1, D_y)\n                elif loss == 'log':\n                    dL_dyhat = (-(self.y[n]/self.yhat[:,n]) + (1-self.y[n])/(1-self.yhat[:,n])).T # (1, D_y)\n\n                ## LAYER 2 ## \n                # dyhat_dh2 \n                if f2 == 'linear':\n                    dyhat_dh2 = np.eye(self.D_y) # (D_y, D_y)\n                elif f2 == 'sigmoid':\n                    dyhat_dh2 = np.diag(sigmoid(self.h2[:,n])*(1-sigmoid(self.h2[:,n]))) # (D_y, D_y)\n\n                # dh2_dc2\n                dh2_dc2 = np.eye(self.D_y) # (D_y, D_y)\n\n                # dh2_dW2 \n                dh2_dW2 = np.zeros((self.D_y, self.D_y, self.D_h)) # (D_y, (D_y, D_h)) \n                for i in range(self.D_y):\n                    dh2_dW2[i] = self.z1[:,n] \n\n                # dh2_dz1\n                dh2_dz1 = self.W2 # (D_y, D_h)\n\n                ## LAYER 1 ##\n                # dz1_dh1\n                if f1 == 'ReLU':\n                    dz1_dh1 = 1*np.diag(self.h1[:,n] > 0) # (D_h, D_h) \n                elif f1 == 'linear':\n                    dz1_dh1 = np.eye(self.D_h) # (D_h, D_h)\n\n                # dh1_dc1 \n                dh1_dc1 = np.eye(self.D_h) # (D_h, D_h)\n\n                # dh1_dW1\n                dh1_dW1 = np.zeros((self.D_h, self.D_h, self.D_X)) # (D_h, (D_h, D_X))\n                for i in range(self.D_h):\n                    dh1_dW1[i] = self.X[n]\n\n                ## DERIVATIVES W.R.T. LOSS ## \n                dL_dh2 = dL_dyhat @ dyhat_dh2\n                dL_dW2 += dL_dh2 @ dh2_dW2\n                dL_dc2 += dL_dh2 @ dh2_dc2\n                dL_dh1 = dL_dh2 @ dh2_dz1 @ dz1_dh1\n                dL_dW1 += dL_dh1 @ dh1_dW1\n                dL_dc1 += dL_dh1 @ dh1_dc1\n\n            ## Update Weights\n            self.W1 -= self.lr * dL_dW1\n            self.c1 -= self.lr * dL_dc1.reshape(-1, 1)           \n            self.W2 -= self.lr * dL_dW2            \n            self.c2 -= self.lr * dL_dc2.reshape(-1, 1)                    \n\n            ## Update Outputs\n            self.h1 = np.dot(self.W1, self.X.T) + self.c1\n            self.z1 = activation_function_dict[f1](self.h1)\n            self.h2 = np.dot(self.W2, self.z1) + self.c2\n            self.yhat = activation_function_dict[f2](self.h2)\n\n    def predict(self, X_test):\n        self.h1 = np.dot(self.W1, X_test.T) + self.c1\n        self.z1 = activation_function_dict[self.f1](self.h1)\n        self.h2 = np.dot(self.W2, self.z1) + self.c2\n        self.yhat = activation_function_dict[self.f2](self.h2)        \n        return self.yhat \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_boston_train, y_boston_train, n_hidden = 8)\ny_boston_test_hat = ffnn.predict(X_boston_test)\n\nfig, ax = plt.subplots()\nsns.scatterplot(y_boston_test, y_boston_test_hat[0])\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'$y$ vs. $\\hat{y}$')\nsns.despine() \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_cancer_train, y_cancer_train, n_hidden = 8,\n         loss = 'log', f2 = 'sigmoid', seed = 123, lr = 1e-4)\ny_cancer_test_hat = ffnn.predict(X_cancer_test)\nnp.mean(y_cancer_test_hat.round() == y_cancer_test) \n```", "```py\n0.9929577464788732 \n```", "```py\nclass FeedForwardNeuralNetwork:\n\n    def fit(self, X, Y, n_hidden, f1 = 'ReLU', f2 = 'linear', loss = 'RSS', lr = 1e-5, n_iter = 5e3, seed = None):\n\n        ## Store Information\n        self.X = X\n        self.Y = Y.reshape(len(Y), -1)\n        self.N = len(X)\n        self.D_X = self.X.shape[1]\n        self.D_Y = self.Y.shape[1]\n        self.Xt = self.X.T\n        self.Yt = self.Y.T\n        self.D_h = n_hidden\n        self.f1, self.f2 = f1, f2\n        self.loss = loss\n        self.lr = lr\n        self.n_iter = int(n_iter)\n        self.seed = seed\n\n        ## Instantiate Weights\n        np.random.seed(self.seed)\n        self.W1 = np.random.randn(self.D_h, self.D_X)/5\n        self.c1 = np.random.randn(self.D_h, 1)/5\n        self.W2 = np.random.randn(self.D_Y, self.D_h)/5\n        self.c2 = np.random.randn(self.D_Y, 1)/5\n\n        ## Instantiate Outputs\n        self.H1 = (self.W1 @ self.Xt) + self.c1\n        self.Z1 = activation_function_dict[self.f1](self.H1)\n        self.H2 = (self.W2 @ self.Z1) + self.c2\n        self.Yhatt = activation_function_dict[self.f2](self.H2)\n\n        ## Fit Weights\n        for iteration in range(self.n_iter):\n\n            # Yhat #\n            if self.loss == 'RSS':\n                self.dL_dYhatt = -(self.Yt - self.Yhatt) # (D_Y x N)\n            elif self.loss == 'log':\n                self.dL_dYhatt = (-(self.Yt/self.Yhatt) + (1-self.Yt)/(1-self.Yhatt)) # (D_y x N)\n\n            # H2 #\n            if self.f2 == 'linear':\n                self.dYhatt_dH2 = np.ones((self.D_Y, self.N))\n            elif self.f2 == 'sigmoid':\n                self.dYhatt_dH2 = sigmoid(self.H2) * (1- sigmoid(self.H2))\n            self.dL_dH2 = self.dL_dYhatt * self.dYhatt_dH2 # (D_Y x N)\n\n            # c2 # \n            self.dL_dc2 = np.sum(self.dL_dH2, 1) # (D_y)\n\n            # W2 # \n            self.dL_dW2 = np.tensordot(self.dL_dH2, self.Z1, (1,1)) # (D_Y x D_h)\n\n            # Z1 #\n            self.dL_dZ1 = np.tensordot(self.W2, self.dL_dH2, (0, 0)) # (D_h x N)\n\n            # H1 #\n            if self.f1 == 'ReLU':\n                self.dL_dH1 = self.dL_dZ1 * np.maximum(self.H1, 0) # (D_h x N)\n            elif self.f1 == 'linear':\n                self.dL_dH1 = self.dL_dZ1 # (D_h x N)\n\n            # c1 #\n            self.dL_dc1 = np.sum(self.dL_dH1, 1) # (D_h)\n\n            # W1 # \n            self.dL_dW1 = np.tensordot(self.dL_dH1, self.Xt, (1,1)) # (D_h, D_X)\n\n            ## Update Weights\n            self.W1 -= self.lr * self.dL_dW1\n            self.c1 -= self.lr * self.dL_dc1.reshape(-1, 1)           \n            self.W2 -= self.lr * self.dL_dW2            \n            self.c2 -= self.lr * self.dL_dc2.reshape(-1, 1)                    \n\n            ## Update Outputs\n            self.H1 = (self.W1 @ self.Xt) + self.c1\n            self.Z1 = activation_function_dict[self.f1](self.H1)\n            self.H2 = (self.W2 @ self.Z1) + self.c2\n            self.Yhatt = activation_function_dict[self.f2](self.H2)  \n\n    def predict(self, X_test):\n        X_testt = X_test.T\n        self.h1 = (self.W1 @ X_testt) + self.c1\n        self.z1 = activation_function_dict[self.f1](self.h1)\n        self.h2 = (self.W2 @ self.z1) + self.c2\n        self.Yhatt = activation_function_dict[self.f2](self.h2)        \n        return self.Yhatt \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_boston_train, y_boston_train, n_hidden = 8)\ny_boston_test_hat = ffnn.predict(X_boston_test)\n\nfig, ax = plt.subplots()\nsns.scatterplot(y_boston_test, y_boston_test_hat[0])\nax.set(xlabel = r'$y$', ylabel = r'$\\hat{y}$', title = r'$y$ vs. $\\hat{y}$')\nsns.despine() \n```", "```py\nffnn = FeedForwardNeuralNetwork()\nffnn.fit(X_cancer_train, y_cancer_train, n_hidden = 8,\n         loss = 'log', f2 = 'sigmoid', seed = 123, lr = 1e-4)\ny_cancer_test_hat = ffnn.predict(X_cancer_test)\nnp.mean(y_cancer_test_hat.round() == y_cancer_test) \n```", "```py\n0.9929577464788732 \n```"]