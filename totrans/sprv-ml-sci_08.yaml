- en: 4  Justification to Use Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4  使用机器学习的理由
- en: 原文：[https://ml-science-book.com/justification.html](https://ml-science-book.com/justification.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ml-science-book.com/justification.html](https://ml-science-book.com/justification.html)
- en: '[Justifying Machine Learning For Science](./part-one.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[为科学证明机器学习的合理性](./part-one.html)'
- en: '[4  Justification to Use Machine Learning](./justification.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4  使用机器学习的理由](./justification.html)'
- en: We have demonstrated that prediction is an essential goal in science. Great!
    But how does machine learning help scientists make predictions? And, what value
    does it add to existing predictive modeling approaches? What are good reasons
    for using machine learning in science?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经证明预测是科学中的一个基本目标。太好了！但机器学习是如何帮助科学家进行预测的？它为现有的预测建模方法增加了什么价值？在科学中使用机器学习有哪些合理的理由？
- en: In this chapter, we justify the use of machine learning in science both epistemically
    and pragmatically.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们从认识论和实用主义的角度论证了机器学习在科学中的应用。
- en: With the blessing of the Elder Council, tornado prediction became the first
    machine learning project in Raven Science. Rattle teamed up with the tornado expert
    Krarah. Krarah was responsible for the data, and Rattle for the training and modeling.
    Within one month, they had created a model that outperformed all previous tornado
    prediction models. Eureka! A new paradigm was born.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在长老会的祝福下，龙卷风预测成为了Raven Science的第一个机器学习项目。Rattle与龙卷风专家Kراه合作。Kراه负责数据，Rattle负责训练和建模。在一个月内，他们创建了一个优于所有先前龙卷风预测模型的模型。哇！一个新的范式诞生了。
- en: '![](../Images/ffcd19acdb07f5d042720d6d89c2ba2c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ffcd19acdb07f5d042720d6d89c2ba2c.png)'
- en: 4.1 Machine Learning has a clear notion of success
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 机器学习有明确的成功概念
- en: In science, the quality of models is often assessed in a lengthy and non-transparent
    manner. Social aspects such as the reputation of the researchers who developed
    the model, the opinion of other scientific authorities, or the amount of funding
    for the research program can play as important a role in model assessment as the
    predictive capacity of the model [[1]](references.html#ref-kuhn1997structure).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学中，模型的质量通常以耗时且不透明的方式进行评估。社会因素，如开发模型的科研人员的声誉、其他科学权威的意见或研究项目的资金量，在模型评估中可能发挥的作用与模型预测能力一样重要
    [[1]](references.html#ref-kuhn1997structure)。
- en: 'In comparison, machine learning offers a very transparent notion to assess
    model quality: a good model is one that has a low average prediction error on
    an unseen test dataset. The idea behind this assessment is that a model with a
    low empirical error on a test set is expected to make few errors on the task to
    be solved. This inference from the test to the so-called *generalization error*
    is even demonstrably correct if the test data is a random and representative data
    sample of the task.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相比，机器学习提供了一个非常透明的模型质量评估概念：一个好的模型是在未见过的测试数据集上平均预测误差低的模型。这种评估背后的想法是，在测试集上具有低经验误差的模型预计在要解决的问题上犯的错误很少。如果测试数据是任务的随机且具有代表性的数据样本，那么从测试到所谓的*泛化误差*的这种推断甚至可以证明是正确的。
- en: Furthermore, not only is the goal of modeling very transparent, but the feedback
    that researchers receive is also quick to obtain and comes in quantified form.
    In this way, scientists can check their modeling intuitions throughout the modeling
    process on an almost purely empirical basis and even compare their models with
    entirely different modeling schools.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，建模的目标非常透明，研究人员收到的反馈也很快获得，并以量化的形式呈现。这样，科学家可以在建模过程中几乎完全基于经验地检验他们的建模直觉，甚至可以将他们的模型与完全不同的建模学派进行比较。
- en: This transparency about what makes a good model enables scientists to work towards
    a common goal. We discuss the concept of generalization in [Chapter 7](generalization.html).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关于什么使模型好的透明度使科学家能够朝着共同的目标努力。我们在[第7章](generalization.html)中讨论了泛化的概念。
- en: 4.2 Machine learning adapts the model to the world
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 机器学习使模型适应世界
- en: Most approaches where mathematical models are fit to data, for example, statistical
    models or simulations, come with a constrained functional form. Like assuming
    a linear, exponential, inverse, or additive relationship between variables. Such
    constraints usually reflect the domain knowledge of the researcher. For example,
    if you know that a certain fertilizer is less effective in dry climates, you may
    add an interaction term.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数将数学模型拟合到数据中的方法，例如统计模型或模拟，都带有约束的函数形式。例如，假设变量之间存在线性、指数、倒数或加性关系。这些约束通常反映了研究者的领域知识。例如，如果你知道某种肥料在干旱气候中效果较差，你可能会添加一个交互项。
- en: 'While incorporating domain knowledge sounds smart, it can be dangerous: Your
    modeling success will depend on the reliability of your domain knowledge and your
    skill in encoding it. A researcher who only knows linear models will assume linearity
    in all contexts, whether it is a conscious choice or not. Misspecified models
    will lead to wrong conclusions and therefore to bad science [[2]](references.html#ref-dennis2019errors).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然融入领域知识听起来很聪明，但它可能很危险：你的建模成功将取决于你领域知识的可靠性以及你编码它的技能。一个只知道线性模型的研究者可能会在所有情况下都假设线性关系，无论这是否是有意识的抉择。模型指定不当会导致错误的结论，因此会导致不良的科学
    [[2]](references.html#ref-dennis2019errors)。
- en: 'In machine learning, the model classes – like neural networks or random forests
    – are more flexible and powerful. They can, in principle, approximate any function.[¹](#fn1)
    You don’t need to know that there is an interaction between humidity and fertilizer
    effectiveness to build a good model. The algorithm will learn this interaction
    from the data. There is a shift in burden, the modeling success rests not on your
    domain knowledge anymore but on the size and quality of your data. Equipped with
    enough data, even non-domain experts can find highly predictive models. Indeed,
    there is a trade-off: with lots of data, domain knowledge is secondary; with little
    data, on the other hand, domain knowledge is key.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，模型类别——如神经网络或随机森林——更加灵活和强大。原则上，它们可以近似任何函数。[¹](#fn1) 你不需要知道湿度和肥料效果之间存在相互作用，就可以构建一个好的模型。算法将从数据中学习这种相互作用。负担有所转移，建模成功不再依赖于你的领域知识，而是取决于你数据的大小和质量。有了足够的数据，即使是非领域专家也能找到高度预测性的模型。事实上，这里有一个权衡：数据量大时，领域知识是次要的；另一方面，数据量少时，领域知识是关键的。
- en: We will discuss the role of domain knowledge and how to incorporate it in machine
    learning modeling in [Chapter 8](domain.html).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第8章[Chapter 8](domain.html)中讨论领域知识的作用以及如何在机器学习建模中融入它。
- en: 4.3 Machine learning handles various data structures
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 机器学习处理各种数据结构
- en: 'The more complex the data structures become, the more difficult it becomes
    to make assumptions and follow a traditional modeling approach. This becomes evident
    if we leave the realm of tabular data and consider images, text, and geospatial
    data. This is where machine learning can shine. Machine learning successfully
    handles various data types, such as tabular [[5]](references.html#ref-gao2020machine),
    image [[6]](references.html#ref-erickson2017machine), geospatial [[7]](references.html#ref-ren2021deep),
    sound [[8]](references.html#ref-oikarinen2019deep), graphs [[9]](references.html#ref-hu2020open),
    or text data [[10]](references.html#ref-neethu2013sentiment). There is often lots
    of data, but it’s not always in perfect shape:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据结构的复杂化，做出假设和遵循传统建模方法变得更加困难。如果我们离开表格数据的领域，考虑图像、文本和地理空间数据，这一点就会变得明显。这正是机器学习可以大放异彩的地方。机器学习成功地处理了各种数据类型，例如表格
    [[5]](references.html#ref-gao2020machine)、图像 [[6]](references.html#ref-erickson2017machine)、地理空间
    [[7]](references.html#ref-ren2021deep)、声音 [[8]](references.html#ref-oikarinen2019deep)、图
    [[9]](references.html#ref-hu2020open) 或文本数据 [[10]](references.html#ref-neethu2013sentiment)。数据通常很多，但并不总是处于完美的状态：
- en: Most data wasn’t produced by controlled experiments but comes from the messy
    world.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数数据并非来自受控实验，而是来自混乱的世界。
- en: Data is often high-dimensional without indication of what’s relevant and what’s
    not.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据通常是高维的，没有指示哪些是相关的，哪些不是。
- en: Data can come in various forms (text, images, audio, etc.) and is not restricted
    to tables with clearly interpretable columns.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可以以各种形式出现（文本、图像、音频等），并不局限于具有清晰可解释列的表格。
- en: Unlike approaches such as classic statistical modeling, machine learning can
    deal with these problems. All you need is data! Well, we exaggerate a bit here,
    but you get the idea. Dealing with diverse data is not merely practical but also
    epistemic. If diverse data sources point to similar insights, this strongly supports
    the validity of these insights [[11]](references.html#ref-earman1992bayes).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与经典统计建模等方法不同，机器学习可以处理这些问题。你所需要的只是数据！好吧，我们在这里有点夸张，但你的想法应该很清楚。处理多样化的数据不仅实用，而且具有认识论意义。如果多样化的数据来源指向相似的见解，这强烈支持这些见解的有效性
    [[11]](references.html#ref-earman1992bayes)。
- en: 4.4 Machine learning allows you to work on new questions
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 机器学习使你能够探索新的问题
- en: 'Machine learning has enabled scientists to leverage data to solve specific
    problems that they hadn’t been able to “solve” before using other approaches:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习使科学家能够利用数据来解决他们以前使用其他方法无法“解决”的特定问题：
- en: '**Translating texts:** Machine translation is older than machine learning,
    but, let’s be honest, it was too bad to be useful. Before machine learning was
    mature enough and embraced, rule-based systems and statistical machine translation
    were used.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本翻译：** 机器翻译比机器学习历史更悠久，但，让我们说实话，它太糟糕了以至于没有用。在机器学习足够成熟并被接受之前，使用了基于规则的系统和统计机器翻译。'
- en: '**Diagnosis of diseases based on X-ray images:** Before machine learning, techniques
    like template matching and rule-based algorithms were used. Only machine learning
    made it possible to make huge progress in this task.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于X射线图像的疾病诊断：** 在机器学习之前，使用了模板匹配和基于规则的算法等技术。只有机器学习使得在这个任务上取得巨大进步成为可能。'
- en: '**Drug discovery:** Traditionally, drug discovery involved a lot of trial and
    error. Machine learning has made it possible to analyze huge amounts of data and
    predict how different drugs might interact with targets in the body. In the future,
    this may greatly accelerate the process of drug discovery.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**药物发现：** 传统上，药物发现涉及大量的试错。机器学习使得分析大量数据并预测不同药物可能如何与体内的靶点相互作用成为可能。在未来，这可能会极大地加速药物发现的过程。'
- en: For such research questions, machine learning is finally offering routes toward
    studying them systematically, built on empirical data. Paraphrasing Wittgenstein
    – the limits of my modeling are the limits of my world. This implies that extending
    the limits of modeling with machine learning extends the realm of phenomena scientists
    can investigate.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这样的研究问题，机器学习终于提供了基于经验数据的系统研究途径。借用维特根斯坦的话——我的模型限制是我世界的限制。这意味着通过机器学习扩展模型限制可以扩展科学家可以研究的现象领域。
- en: 4.5 Don’t undervalue machine learning because it is new
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 不要因为它是新的就低估机器学习
- en: 'Compared to other modeling approaches, machine learning has a short history.
    Differential equations or linear models, for instance, have existed for hundreds
    of years. Historically, new modeling approaches like machine learning always had
    a hard time establishing themselves:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他建模方法相比，机器学习的历史较短。例如，微分方程或线性模型已经存在了数百年。从历史上看，像机器学习这样的新建模方法总是很难确立自己：
- en: Einstein’s theory of relativity relied on non-Euclidean geometry – an unusual
    branch of mathematics for these endeavors – which was one of the reasons why he
    was met with skepticism.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱因斯坦的相对论理论依赖于非欧几里得几何——对这些努力来说是一个不寻常的数学分支——这也是他受到怀疑的原因之一。
- en: Probabilistic models were first completely rejected in linguistics due to the
    dominance of logical methods. Today, they are well-established.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于逻辑方法的统治地位，概率模型最初在语言学中被完全拒绝。今天，它们已经得到了很好的确立。
- en: In econometrics, graphical causal models have a hard time asserting themselves
    against the prevailing framework of potential outcomes.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在计量经济学中，图形因果模型在对抗潜在结果的主流框架时显得力不从心。
- en: 'The novelty of an approach should neither be taken as an argument in favor
    nor against using a certain modeling approach. The essential question is: Can
    the tool help answer the question you have set out to address?'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法的新颖性不应被视为支持或反对使用某种建模方法的论据。关键问题是：这个工具能否帮助你回答你设定的那个问题？
- en: 4.6 Further justifications for machine learning
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 机器学习的进一步正当理由
- en: 'There are further justifications for using machine learning in science:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学中使用机器学习还有进一步的正当理由：
- en: '**Time efficiency:** Accurate machine learning models can often be built time-efficiently
    by researchers. There is less pre-processing needed compared to other approaches
    and large parts of the model selection and training process can be automated.
    Also, there is great support for machine learning packages in popular programming
    languages like Python (e.g., scikit-learn, PyTorch, or TensorFlow) or R (e.g.,
    mlr3 or tidymodels).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间效率：** 研究人员通常可以高效地构建准确的机器学习模型。与其它方法相比，预处理所需的工作较少，模型选择和训练过程的大部分可以自动化。此外，在流行的编程语言（如Python（例如，scikit-learn、PyTorch或TensorFlow）或R（例如，mlr3或tidymodels））中，对机器学习包的支持也非常强大。'
- en: '**Computational efficiency:** In some situations, machine learning can be computationally
    cheaper than traditional modeling. Machine learning models can, for example, be
    used as fast surrogate models for simulations from physics or material science
    that are computationally very intense [[12]](references.html#ref-toledo2021deep).
    Machine learning weather prediction can run on your laptop, unlike numerical methods
    that demand the world’s biggest computing clusters [[13]](references.html#ref-lam2023learning).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算效率：** 在某些情况下，机器学习在计算上可能比传统建模更便宜。例如，机器学习模型可以用作快速代理模型，用于从物理或材料科学中进行的计算非常密集的模拟
    [[12]](references.html#ref-toledo2021deep)。机器学习天气预报可以在你的笔记本电脑上运行，而传统的数值方法则需要世界上最大的计算集群
    [[13]](references.html#ref-lam2023learning)。'
- en: '**Basis for theory:** Machine learning may support you with the knowledge needed
    to build classical theory-based models. They may show which features contain predictive
    information and how features interact.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理论基础：** 机器学习可以为你提供构建基于经典理论模型所需的知识。它们可能表明哪些特征包含预测信息，以及特征如何相互作用。'
- en: '**Effective for operationalized goals:** Machine learning is ideal if the aim
    can be easily encoded in a single metric. If you are confident in your metric,
    machine learning will provide you with the means to optimize for it.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适用于可操作的目标：** 如果目标可以轻松地编码在一个单一指标中，机器学习是理想的。如果你对自己的指标有信心，机器学习将为你提供优化它的手段。'
- en: '[1]T. S. Kuhn, *The structure of scientific revolutions*, vol. 962\. University
    of Chicago press Chicago, 1997.[2]B. Dennis, J. M. Ponciano, M. L. Taper, and
    S. R. Lele, “Errors in statistical inference under model misspecification: Evidence,
    hypothesis testing, and AIC,” *Frontiers in Ecology and Evolution*, vol. 7, p.
    372, 2019, doi: [10.3389/fevo.2019.00372](https://doi.org/10.3389/fevo.2019.00372).[3]K.
    Hornik, “Approximation capabilities of multilayer feedforward networks,” *Neural
    networks*, vol. 4, no. 2, pp. 251–257, 1991, doi: [10.1016/0893-6080(91)90009-T](https://doi.org/10.1016/0893-6080(91)90009-T).[4]Y.
    Lu and J. Lu, “A universal approximation theorem of deep neural networks for expressing
    probability distributions,” *Advances in neural information processing systems*,
    vol. 33, pp. 3094–3105, 2020, doi: [10.5555/3495724.3495984](https://doi.org/10.5555/3495724.3495984).[5]Y.
    Gao *et al.*, “Machine learning based early warning system enables accurate mortality
    risk prediction for COVID-19,” *Nature communications*, vol. 11, no. 1, p. 5033,
    2020, doi: [10.5281/zenodo.3991113](https://doi.org/10.5281/zenodo.3991113).[6]B.
    J. Erickson, P. Korfiatis, Z. Akkus, and T. L. Kline, “Machine learning for medical
    imaging,” *Radiographics*, vol. 37, no. 2, pp. 505–515, 2017, doi: [10.1148/rg.2017160130](https://doi.org/10.1148/rg.2017160130).[7]X.
    Ren *et al.*, “Deep learning-based weather prediction: A survey,” *Big Data Research*,
    vol. 23, p. 100178, 2021, doi: [10.1016/j.bdr.2020.100178](https://doi.org/10.1016/j.bdr.2020.100178).[8]T.
    Oikarinen *et al.*, “Deep convolutional network for animal sound classification
    and source attribution using dual audio recordings,” *The Journal of the Acoustical
    Society of America*, vol. 145, no. 2, pp. 654–662, 2019, doi: [10.1121/1.5097583](https://doi.org/10.1121/1.5097583).[9]W.
    Hu *et al.*, “Open graph benchmark: Datasets for machine learning on graphs,”
    *Advances in neural information processing systems*, vol. 33, pp. 22118–22133,
    2020, doi: [doi/10.5555/3495724.3497579](https://doi.org/doi/10.5555/3495724.3497579).[10]M.
    Neethu and R. Rajasree, “Sentiment analysis in twitter using machine learning
    techniques,” in *2013 fourth international conference on computing, communications
    and networking technologies (ICCCNT)*, IEEE, 2013, pp. 1–5\. doi: [10.1109/ICCCNT.2013.6726818](https://doi.org/10.1109/ICCCNT.2013.6726818).[11]J.
    Earman, “Bayes or bust? A critical examination of bayesian confirmation theory.”
    MIT Press, 1992.[12]J. Q. Toledo-Marı́n, G. Fox, J. P. Sluka, and J. A. Glazier,
    “Deep learning approaches to surrogates for solving the diffusion equation for
    mechanistic real-world simulations,” *Frontiers in Physiology*, vol. 12, p. 667828,
    2021, doi: [10.3389/fphys.2021.667828](https://doi.org/10.3389/fphys.2021.667828).[13]R.
    Lam *et al.*, “Learning skillful medium-range global weather forecasting,” *Science*,
    p. eadi2336, 2023, doi: [10.1126/science.adi2336](https://doi.org/10.1126/science.adi2336).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]T. S. Kuhn, *《科学革命的结构》*, 第962卷. 芝加哥大学出版社芝加哥, 1997年。[2]B. Dennis, J. M. Ponciano,
    M. L. Taper, 和 S. R. Lele, “在模型误设下的统计推断错误：证据、假设检验和AIC,” *《生态与进化前沿》*, 第7卷, 第372页,
    2019年, doi: [10.3389/fevo.2019.00372](https://doi.org/10.3389/fevo.2019.00372)。[3]K.
    Hornik, “多层前馈网络的逼近能力,” *《神经网络》*, 第4卷, 第2期, 第251–257页, 1991年, doi: [10.1016/0893-6080(91)90009-T](https://doi.org/10.1016/0893-6080(91)90009-T)。[4]Y.
    Lu 和 J. Lu, “用于表示概率分布的深度神经网络通用逼近定理,” *《神经信息处理系统进展》*, 第33卷, 第3094–3105页, 2020年,
    doi: [10.5555/3495724.3495984](https://doi.org/10.5555/3495724.3495984)。[5]Y.
    Gao 等人, “基于机器学习的早期预警系统可准确预测COVID-19的死亡率风险,” *《自然通讯》*, 第11卷, 第1期, 第5033页, 2020年,
    doi: [10.5281/zenodo.3991113](https://doi.org/10.5281/zenodo.3991113)。[6]B. J.
    Erickson, P. Korfiatis, Z. Akkus 和 T. L. Kline, “医学影像中的机器学习,” *《放射学杂志》*, 第37卷,
    第2期, 第505–515页, 2017年, doi: [10.1148/rg.2017160130](https://doi.org/10.1148/rg.2017160130)。[7]X.
    Ren 等人, “基于深度学习的天气预测：综述,” *《大数据研究》*, 第23卷, 第100178页, 2021年, doi: [10.1016/j.bdr.2020.100178](https://doi.org/10.1016/j.bdr.2020.100178)。[8]T.
    Oikarinen 等人, “使用双音频记录的动物声音分类和源归因的深度卷积网络,” *《美国声学学会杂志》*, 第145卷, 第2期, 第654–662页,
    2019年, doi: [10.1121/1.5097583](https://doi.org/10.1121/1.5097583)。[9]W. Hu 等人,
    “开放图基准：图上机器学习的数据集,” *《神经信息处理系统进展》*, 第33卷, 第22118–22133页, 2020年, doi: [doi/10.5555/3495724.3497579](https://doi.org/doi/10.5555/3495724.3497579)。[10]M.
    Neethu 和 R. Rajasree, “使用机器学习技术在Twitter上进行情感分析,” 在 *2013年第四国际计算、通信和网络技术会议（ICCCNT）*
    中, IEEE, 2013年, 第1–5页。doi: [10.1109/ICCCNT.2013.6726818](https://doi.org/10.1109/ICCCNT.2013.6726818)。[11]J.
    Earman, “贝叶斯还是崩溃？对贝叶斯确认理论的批判性考察。” MIT出版社, 1992年。[12]J. Q. Toledo-Marı́n, G. Fox,
    J. P. Sluka 和 J. A. Glazier, “解决扩散方程的代理方法用于机制现实世界模拟的深度学习方法,” *《生理学前沿》*, 第12卷,
    第667828页, 2021年, doi: [10.3389/fphys.2021.667828](https://doi.org/10.3389/fphys.2021.667828)。[13]R.
    Lam 等人, “学习熟练的中程全球天气预报,” *《科学》*, 第eadi2336页, 2023年, doi: [10.1126/science.adi2336](https://doi.org/10.1126/science.adi2336)。'
- en: '* * *'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Many hypotheses classes in machine learning are universal approximators of some
    form; that is, they lie dense within the space of (continuous/step) functions
    [[3]](references.html#ref-hornik1991approximation), [[4]](references.html#ref-lu2020universal).
    While this is not a super special property, e.g., also polynomials lie dense in
    the space of continuous functions, it at least expresses that there is in principle
    a model that approximates any possible relationship well. This is different compared
    to classical statistical models that rely on small model classes; even the best
    model within such a class may be overall a bad model to capture the true relationship
    between predictors and target.[↩︎](#fnref1)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习中许多假设类都是某种形式的通用逼近器；也就是说，它们在（连续/步进）函数的空间中密集分布 [[3]](references.html#ref-hornik1991approximation),
    [[4]](references.html#ref-lu2020universal)。虽然这并不是一个超级特殊的属性，例如，多项式也密集分布在连续函数的空间中，但它至少表达了在原则上存在一个模型可以很好地逼近任何可能的关系。这与依赖于小模型类的经典统计模型不同；即使在这样一个类别中，最好的模型也可能是一个整体上捕捉预测变量和目标之间真实关系的糟糕模型。[↩︎](#fnref1)
