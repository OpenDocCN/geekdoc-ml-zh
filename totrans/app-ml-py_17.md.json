["```py\nignore_warnings = True                                        # ignore warnings?\nimport numpy as np                                            # ndarrays for gridded data\nimport pandas as pd                                           # DataFrames for tabular data\nimport os                                                     # set working directory, run executables\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.ticker import (MultipleLocator,AutoMinorLocator,NullLocator,FuncFormatter) # control of axes ticks\nimport matplotlib.patches as patches                          # add square to matrix plot\nfrom scipy import stats                                       # summary statistics\nimport math                                                   # trigonometry etc.\nimport scipy.signal as signal                                 # kernel for moving window calculation\nimport random                                                 # for random numbers\nimport seaborn as sns                                         # for matrix scatter plots\nfrom scipy import linalg                                      # for linear regression\n\nfrom sklearn.random_projection import GaussianRandomProjection # random projection\nfrom sklearn.random_projection import johnson_lindenstrauss_min_dim\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.preprocessing import StandardScaler              # standardize features\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map\nseed = 42                                                     # random number seed \n```", "```py\ndef comma_format(x, pos):\n    return f'{int(x):,}'\n\ndef add_grid():                                            \n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"c:/PGE383\")                                        # set the working directory \n```", "```py\n#df = pd.read_csv('unconv_MV_v4.csv')                         # load our data table\ndf = pd.read_csv(r'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv')\ndf['TOC'] = np.where(df['TOC']<0.0, 0.0, df['TOC']) # set TOC < 0.0 as 0.0, otherwise leave the same \n```", "```py\ndf.head(n=13)                                                 # we could also use this command for a table preview \n```", "```py\ndf.describe().transpose()                                     # display summary statistics \n```", "```py\nPormin = np.min(df['Por'].values)          # extract ndarray of data table column\nPormax = np.max(df['Por'].values)          # and calculate min and max \n```", "```py\npormin = 6.0; pormax = 24.0; porname = 'Porosity (%)'; portitle = 'Porosity'\npermmin = 0.0; permmax = 10; permname = 'Permeability (mD)'; permtitle = 'Permeability'                \nAImin = 1.0; AImax = 5.0; AIname = 'Acoustic Impedance (kg/m2s*10^6)'; AItitle = 'Acoustic Impedance'\nbrmin = 10.0; brmax = 85.0; brname = 'Brittleness Ratio (%)'; brtitle = 'Brittleness'\nTOCmin = 0.0; TOCmax = 2.2; TOCname = 'Total Organic Carbon (%)'; TOCtitle = 'Total Organic Carbon' \nVRmin = 0.9; VRmax = 2.9; VRname = 'Vitrinite Reflectance (%)'; VRtitle = 'Vitrinite Reflectance'\nprodmin = 500.0; prodmax = 9000.0; prodname = 'Normalized Initial Production (MCFPD)'; prodtitle = 'Normalized Initial Production' \n```", "```py\nsns.pairplot(df,vars=['Por','Perm','AI','Brittle','TOC','VR','Prod'],markers='o',plot_kws={'alpha': 0.2})\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.6, top=0.6, wspace=0.3, hspace=0.2); plt.show() \n```", "```py\nfeatures = ['Por','Perm','AI','Brittle','TOC','VR']\nx = df.loc[:,features].values\nmu = np.mean(x, axis=0)\nsd = np.std(x, axis=0)\nxs = StandardScaler().fit_transform(x)\n\nns_features = []\nfor i in range(0,len(features)):\n    df['NS_'+features[i]] = xs[:,i]\n    ns_features.append('NS_'+features[i]) \n\ndf.head(n=13) \n```", "```py\nbins = [0,2500,5000,7500,10000]                # assign the production bins (these are the fence posts)\nlabels = ['low', 'med', 'high', 'vhigh']       # assign the labels\ncategory = pd.cut(df['Prod'],bins,labels=labels)     # make the 1D array with the labels for our data\ndf['tProd'] = category                                # add the new ordinal production feature to our DataFrames \ndf.head()\ndpalette = sns.color_palette(\"rocket_r\",n_colors = 4)\npalette = sns.color_palette(\"rocket\") \n```", "```py\nplot = sns.pairplot(df[ns_features + ['tProd']],markers='o',hue = 'tProd', palette = dpalette,diag_kws={'edgecolor':'black'},plot_kws=dict(s=50, edgecolor=\"black\", linewidth=0.5))\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.5, top=1.5, wspace=0.3, hspace=0.2)\nplt.show() \n```", "```py\nn_components = 6; seed = 73058\nrp = GaussianRandomProjection(n_components=n_components,random_state = seed)\n\ndists = euclidean_distances(df[ns_features], squared=False).ravel()\nnonzero = dists != 0   # select only non-identical samples pairs\ndists = dists[nonzero]\n\nprojected_data = rp.fit_transform(df[ns_features])\nprojected_dists = euclidean_distances(projected_data, squared=False).ravel()[nonzero]\n\nplt.subplot(221)\nplt.scatter(dists,projected_dists,c='darkorange',alpha=0.6,edgecolor = 'black')\nplt.arrow(0,0,200,200,width=0.02,color='black',head_length=0.0,head_width=0.0)\nplt.xlim(0,15); plt.ylim(0,15); add_grid()\nplt.xlabel(\"Pairwise Distance: original space\"); plt.ylabel(\"Pairwise Distance: projected space\")\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nrates = projected_dists / dists\nprint(\"Distance Ratio, mean: %0.2f, standard deviation %0.2f.\" % (np.mean(rates), np.std(rates)))\n\nplt.subplot(222)\nplt.hist(rates, bins=50, range=(0., 2.),color = 'darkorange', alpha = 0.6, edgecolor='k')\nplt.xlabel(\"Distance Ratio: projected / original\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nplt.subplot(223)\nplt.hist(dists, bins=50, range=(0., 15.),color = 'darkorange', alpha = 0.6, edgecolor='k')\nplt.xlabel(\"Pairwise Distance\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Original Data\")\n\nplt.subplot(224)\nplt.hist(projected_dists, bins=50, range=(0., 15.),color = 'darkorange', alpha = 0.6, edgecolor='k')\nplt.xlabel(\"Pairwise Distance\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nDistance Ratio, mean: 0.83, standard deviation 0.16. \n```", "```py\northogonal_check = np.dot(rp.components_.T, rp.components_)\n\nfig, ax = plt.subplots()\ncax = ax.imshow(orthogonal_check,cmap=plt.cm.grey,vmin=-1,vmax=1.0,interpolation='None',zorder=1)\n#cbar = plt.colorbar(); cbar.set_label('Value')\n\nmatrix_size = orthogonal_check.shape[0]  # Assuming the matrix is square (m x m)\nsquare_size = 1  # Each square has size 1x1\n\nfor i in range(matrix_size):\n    # Add a square around each diagonal element\n    square = patches.Rectangle((i - 0.5, i - 0.5),square_size,square_size,linewidth=3, edgecolor='white', facecolor='none')\n    ax.add_patch(square)\n\n# Add a colorbar\ncbar = fig.colorbar(cax)\ncbar.set_label('Value', rotation=90, labelpad=15)  # Set label for colorbar\n\nplt.title(r'Orthogonal Check, $R_p^T R_p$')\nplt.xlabel('Columns'); plt.ylabel('Rows')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\n---------------------------------------------------------------------------\nAttributeError  Traceback (most recent call last)\nCell In[13], line 4\n  1 orthogonal_check = np.dot(rp.components_.T, rp.components_)\n  3 fig, ax = plt.subplots()\n----> 4 cax = ax.imshow(orthogonal_check,cmap=plt.cm.grey,vmin=-1,vmax=1.0,interpolation='None',zorder=1)\n  5 #cbar = plt.colorbar(); cbar.set_label('Value')\n  7 matrix_size = orthogonal_check.shape[0]  # Assuming the matrix is square (m x m)\n\nAttributeError: module 'matplotlib.cm' has no attribute 'grey' \n```", "```py\nm = 100                                                       # number of dimensions\nn_samples = 1000                                              # number of samples\n\nnp.random.seed(seed = seed)                                   # set the random seed\nmean_vector = np.zeros(m)                                     # mean vector (zero mean for all variables)\n\nrandom_matrix = np.random.rand(m, m)                          # step 1: generate a random matrix \ncorrelation_matrix = np.dot(random_matrix, random_matrix.T)   # step 2: create a symmetric correlation matrix\ncorrelation_matrix = (correlation_matrix + correlation_matrix.T) / 2 # step 3: symmetrize the correlation matrix (ensures the matrix is symmetric)\nnp.fill_diagonal(correlation_matrix, 1)                       # step 4: normalize to have ones on the diagonal (this ensures unit variances)\n\n# Ensure the covariance matrix is positive semi-definite using eigendecomposition\neigvals, eigvecs = np.linalg.eigh(correlation_matrix)         # eigendecomposition of the correlation matrix\neigvals = np.maximum(eigvals, 1e-6)                           # set any negative eigenvalues to a small positive value\ncov_matrix = eigvecs @ np.diag(eigvals) @ eigvecs.T           # reconstruct the covariance matrix\n\nbig_data = np.random.multivariate_normal(mean_vector, cov_matrix, size=n_samples) # step 6: generate the multi-dimensional Gaussian dataset\ndf_big_data = pd.DataFrame(big_data, columns=[f\"Dim_{i+1}\" for i in range(m)]) # convert the data into a pandas DataFrame \n```", "```py\nn_components = 5; seed = 73058\nrp_big = GaussianRandomProjection(n_components=n_components,random_state = seed)\n\ndists = euclidean_distances(df_big_data, squared=False).ravel()\nnonzero = dists != 0   # select only non-identical samples pairs\ndists = dists[nonzero]\n\nprojected_data = rp_big.fit_transform(df_big_data)\nprojected_dists = euclidean_distances(projected_data, squared=False).ravel()[nonzero]\n\nplt.subplot(121)\nplt.scatter(dists,projected_dists,c='red',alpha=0.2,edgecolor = 'black')\nplt.arrow(0,0,10000,10000,width=0.02,color='black',head_length=0.0,head_width=0.0)\nplt.xlabel(\"Pairwise Distance: original space\")\nplt.ylabel(\"Pairwise Distance: projected space\")\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\nplt.xlim([0,400]); plt.ylim([0,400]); add_grid()\n\nrates = projected_dists / dists\nprint(\"Distance Ratio, mean: %0.2f, standard deviation %0.2f.\" % (np.mean(rates), np.std(rates)))\n\nplt.subplot(122)\nplt.hist(rates, bins=50, range=(0., 2.),color = 'red', alpha = 0.2, edgecolor='k')\nplt.xlabel(\"Distance Ratio: projected / original\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nDistance Ratio, mean: 0.95, standard deviation 0.02. \n```", "```py\northogonal_check_big = np.dot(rp_big.components_.T, rp_big.components_)\nfig, ax = plt.subplots()\ncax = ax.imshow(orthogonal_check_big,cmap=plt.cm.grey,vmin=-1,vmax=1.5,interpolation='None',zorder=1)\n\nmatrix_size = orthogonal_check.shape[0]                       # assuming the matrix is square (m x m)\nsquare_size = 1                                               # each square has size 1x1\n\ncbar = fig.colorbar(cax); cbar.set_label('Value', rotation=90, labelpad=15) \n\nplt.title(r'Orthogonal Check, $R_p^T R_p$'); plt.xlabel('Columns'); plt.ylabel('Rows')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nm = 1000                                                      # number of dimensions\nn_samples = 1000                                              # number of samples\nn_components = 200                                            # number of components \nseed = 73058                                                  # random seed\n\nnp.random.seed(seed = seed)                                   # set the random seed\nmean_vector = np.zeros(m)                                     # mean vector (zero mean for all variables)\n\nrandom_matrix = np.random.rand(m, m)                          # step 1: generate a random matrix \ncorrelation_matrix = np.dot(random_matrix, random_matrix.T)   # step 2: create a symmetric correlation matrix\ncorrelation_matrix = (correlation_matrix + correlation_matrix.T) / 2 # step 3: symmetrize the correlation matrix (ensures the matrix is symmetric)\nnp.fill_diagonal(correlation_matrix, 1)                       # step 4: normalize to have ones on the diagonal (this ensures unit variances)\n\n# Ensure the covariance matrix is positive semi-definite using eigendecomposition\neigvals, eigvecs = np.linalg.eigh(correlation_matrix)         # eigendecomposition of the correlation matrix\neigvals = np.maximum(eigvals, 1e-6)                           # set any negative eigenvalues to a small positive value\ncov_matrix = eigvecs @ np.diag(eigvals) @ eigvecs.T           # reconstruct the covariance matrix\n\nvery_big_data = np.random.multivariate_normal(mean_vector, cov_matrix, size=n_samples) # step 6: generate the multi-dimensional Gaussian dataset\ndf_very_big_data = pd.DataFrame(very_big_data, columns=[f\"Dim_{i+1}\" for i in range(m)]) # convert the data into a pandas DataFrame\n\nrp_very_big = GaussianRandomProjection(n_components=n_components,random_state = seed)\n\ndists = euclidean_distances(df_very_big_data, squared=False).ravel()\nnonzero = dists != 0                                          # select only non-identical samples pairs\ndists = dists[nonzero]\n\nprojected_data = rp_very_big.fit_transform(df_very_big_data)\nprojected_dists = euclidean_distances(projected_data, squared=False).ravel()[nonzero]\n\nplt.subplot(121)\nplt.scatter(dists,projected_dists,c='red',alpha=0.2,edgecolor = 'black')\nplt.arrow(0,0,10000,10000,width=0.02,color='black',head_length=0.0,head_width=0.0)\nplt.xlabel(\"Pairwise Distance: original space\")\nplt.ylabel(\"Pairwise Distance: projected space\")\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\nplt.xlim([0,400]); plt.ylim([0,400]); add_grid()\n\northogonal_check_very_big = np.dot(rp_very_big.components_.T, rp_very_big.components_)\n\nplt.subplot(122)\nim = plt.imshow(orthogonal_check_very_big,cmap=plt.cm.grey,vmin=-1,vmax=1.5,interpolation='None',zorder=1)\nmatrix_size = orthogonal_check.shape[0]                       # assuming the matrix is square (m x m)\nsquare_size = 1                                               # each square has size 1x1\ncbar = fig.colorbar(im); cbar.set_label('Value', rotation=90, labelpad=15) \nplt.title(r'Orthogonal Check, $R_p^T R_p$'); plt.xlabel('Columns'); plt.ylabel('Rows')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nignore_warnings = True                                        # ignore warnings?\nimport numpy as np                                            # ndarrays for gridded data\nimport pandas as pd                                           # DataFrames for tabular data\nimport os                                                     # set working directory, run executables\nimport matplotlib.pyplot as plt                               # for plotting\nfrom matplotlib.ticker import (MultipleLocator,AutoMinorLocator,NullLocator,FuncFormatter) # control of axes ticks\nimport matplotlib.patches as patches                          # add square to matrix plot\nfrom scipy import stats                                       # summary statistics\nimport math                                                   # trigonometry etc.\nimport scipy.signal as signal                                 # kernel for moving window calculation\nimport random                                                 # for random numbers\nimport seaborn as sns                                         # for matrix scatter plots\nfrom scipy import linalg                                      # for linear regression\n\nfrom sklearn.random_projection import GaussianRandomProjection # random projection\nfrom sklearn.random_projection import johnson_lindenstrauss_min_dim\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.preprocessing import StandardScaler              # standardize features\nplt.rc('axes', axisbelow=True)                                # plot all grids below the plot elements\nif ignore_warnings == True:                                   \n    import warnings\n    warnings.filterwarnings('ignore')\ncmap = plt.cm.inferno                                         # color map\nseed = 42                                                     # random number seed \n```", "```py\ndef comma_format(x, pos):\n    return f'{int(x):,}'\n\ndef add_grid():                                            \n    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks \n```", "```py\n#os.chdir(\"c:/PGE383\")                                        # set the working directory \n```", "```py\n#df = pd.read_csv('unconv_MV_v4.csv')                         # load our data table\ndf = pd.read_csv(r'https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/unconv_MV_v4.csv')\ndf['TOC'] = np.where(df['TOC']<0.0, 0.0, df['TOC']) # set TOC < 0.0 as 0.0, otherwise leave the same \n```", "```py\ndf.head(n=13)                                                 # we could also use this command for a table preview \n```", "```py\ndf.describe().transpose()                                     # display summary statistics \n```", "```py\nPormin = np.min(df['Por'].values)          # extract ndarray of data table column\nPormax = np.max(df['Por'].values)          # and calculate min and max \n```", "```py\npormin = 6.0; pormax = 24.0; porname = 'Porosity (%)'; portitle = 'Porosity'\npermmin = 0.0; permmax = 10; permname = 'Permeability (mD)'; permtitle = 'Permeability'                \nAImin = 1.0; AImax = 5.0; AIname = 'Acoustic Impedance (kg/m2s*10^6)'; AItitle = 'Acoustic Impedance'\nbrmin = 10.0; brmax = 85.0; brname = 'Brittleness Ratio (%)'; brtitle = 'Brittleness'\nTOCmin = 0.0; TOCmax = 2.2; TOCname = 'Total Organic Carbon (%)'; TOCtitle = 'Total Organic Carbon' \nVRmin = 0.9; VRmax = 2.9; VRname = 'Vitrinite Reflectance (%)'; VRtitle = 'Vitrinite Reflectance'\nprodmin = 500.0; prodmax = 9000.0; prodname = 'Normalized Initial Production (MCFPD)'; prodtitle = 'Normalized Initial Production' \n```", "```py\nsns.pairplot(df,vars=['Por','Perm','AI','Brittle','TOC','VR','Prod'],markers='o',plot_kws={'alpha': 0.2})\nplt.subplots_adjust(left=0.0, bottom=0.0, right=0.6, top=0.6, wspace=0.3, hspace=0.2); plt.show() \n```", "```py\nfeatures = ['Por','Perm','AI','Brittle','TOC','VR']\nx = df.loc[:,features].values\nmu = np.mean(x, axis=0)\nsd = np.std(x, axis=0)\nxs = StandardScaler().fit_transform(x)\n\nns_features = []\nfor i in range(0,len(features)):\n    df['NS_'+features[i]] = xs[:,i]\n    ns_features.append('NS_'+features[i]) \n\ndf.head(n=13) \n```", "```py\nbins = [0,2500,5000,7500,10000]                # assign the production bins (these are the fence posts)\nlabels = ['low', 'med', 'high', 'vhigh']       # assign the labels\ncategory = pd.cut(df['Prod'],bins,labels=labels)     # make the 1D array with the labels for our data\ndf['tProd'] = category                                # add the new ordinal production feature to our DataFrames \ndf.head()\ndpalette = sns.color_palette(\"rocket_r\",n_colors = 4)\npalette = sns.color_palette(\"rocket\") \n```", "```py\nplot = sns.pairplot(df[ns_features + ['tProd']],markers='o',hue = 'tProd', palette = dpalette,diag_kws={'edgecolor':'black'},plot_kws=dict(s=50, edgecolor=\"black\", linewidth=0.5))\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.5, top=1.5, wspace=0.3, hspace=0.2)\nplt.show() \n```", "```py\nn_components = 6; seed = 73058\nrp = GaussianRandomProjection(n_components=n_components,random_state = seed)\n\ndists = euclidean_distances(df[ns_features], squared=False).ravel()\nnonzero = dists != 0   # select only non-identical samples pairs\ndists = dists[nonzero]\n\nprojected_data = rp.fit_transform(df[ns_features])\nprojected_dists = euclidean_distances(projected_data, squared=False).ravel()[nonzero]\n\nplt.subplot(221)\nplt.scatter(dists,projected_dists,c='darkorange',alpha=0.6,edgecolor = 'black')\nplt.arrow(0,0,200,200,width=0.02,color='black',head_length=0.0,head_width=0.0)\nplt.xlim(0,15); plt.ylim(0,15); add_grid()\nplt.xlabel(\"Pairwise Distance: original space\"); plt.ylabel(\"Pairwise Distance: projected space\")\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nrates = projected_dists / dists\nprint(\"Distance Ratio, mean: %0.2f, standard deviation %0.2f.\" % (np.mean(rates), np.std(rates)))\n\nplt.subplot(222)\nplt.hist(rates, bins=50, range=(0., 2.),color = 'darkorange', alpha = 0.6, edgecolor='k')\nplt.xlabel(\"Distance Ratio: projected / original\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nplt.subplot(223)\nplt.hist(dists, bins=50, range=(0., 15.),color = 'darkorange', alpha = 0.6, edgecolor='k')\nplt.xlabel(\"Pairwise Distance\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Original Data\")\n\nplt.subplot(224)\nplt.hist(projected_dists, bins=50, range=(0., 15.),color = 'darkorange', alpha = 0.6, edgecolor='k')\nplt.xlabel(\"Pairwise Distance\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=2.1, wspace=0.2, hspace=0.2); plt.show() \n```", "```py\nDistance Ratio, mean: 0.83, standard deviation 0.16. \n```", "```py\northogonal_check = np.dot(rp.components_.T, rp.components_)\n\nfig, ax = plt.subplots()\ncax = ax.imshow(orthogonal_check,cmap=plt.cm.grey,vmin=-1,vmax=1.0,interpolation='None',zorder=1)\n#cbar = plt.colorbar(); cbar.set_label('Value')\n\nmatrix_size = orthogonal_check.shape[0]  # Assuming the matrix is square (m x m)\nsquare_size = 1  # Each square has size 1x1\n\nfor i in range(matrix_size):\n    # Add a square around each diagonal element\n    square = patches.Rectangle((i - 0.5, i - 0.5),square_size,square_size,linewidth=3, edgecolor='white', facecolor='none')\n    ax.add_patch(square)\n\n# Add a colorbar\ncbar = fig.colorbar(cax)\ncbar.set_label('Value', rotation=90, labelpad=15)  # Set label for colorbar\n\nplt.title(r'Orthogonal Check, $R_p^T R_p$')\nplt.xlabel('Columns'); plt.ylabel('Rows')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\n---------------------------------------------------------------------------\nAttributeError  Traceback (most recent call last)\nCell In[13], line 4\n  1 orthogonal_check = np.dot(rp.components_.T, rp.components_)\n  3 fig, ax = plt.subplots()\n----> 4 cax = ax.imshow(orthogonal_check,cmap=plt.cm.grey,vmin=-1,vmax=1.0,interpolation='None',zorder=1)\n  5 #cbar = plt.colorbar(); cbar.set_label('Value')\n  7 matrix_size = orthogonal_check.shape[0]  # Assuming the matrix is square (m x m)\n\nAttributeError: module 'matplotlib.cm' has no attribute 'grey' \n```", "```py\nm = 100                                                       # number of dimensions\nn_samples = 1000                                              # number of samples\n\nnp.random.seed(seed = seed)                                   # set the random seed\nmean_vector = np.zeros(m)                                     # mean vector (zero mean for all variables)\n\nrandom_matrix = np.random.rand(m, m)                          # step 1: generate a random matrix \ncorrelation_matrix = np.dot(random_matrix, random_matrix.T)   # step 2: create a symmetric correlation matrix\ncorrelation_matrix = (correlation_matrix + correlation_matrix.T) / 2 # step 3: symmetrize the correlation matrix (ensures the matrix is symmetric)\nnp.fill_diagonal(correlation_matrix, 1)                       # step 4: normalize to have ones on the diagonal (this ensures unit variances)\n\n# Ensure the covariance matrix is positive semi-definite using eigendecomposition\neigvals, eigvecs = np.linalg.eigh(correlation_matrix)         # eigendecomposition of the correlation matrix\neigvals = np.maximum(eigvals, 1e-6)                           # set any negative eigenvalues to a small positive value\ncov_matrix = eigvecs @ np.diag(eigvals) @ eigvecs.T           # reconstruct the covariance matrix\n\nbig_data = np.random.multivariate_normal(mean_vector, cov_matrix, size=n_samples) # step 6: generate the multi-dimensional Gaussian dataset\ndf_big_data = pd.DataFrame(big_data, columns=[f\"Dim_{i+1}\" for i in range(m)]) # convert the data into a pandas DataFrame \n```", "```py\nn_components = 5; seed = 73058\nrp_big = GaussianRandomProjection(n_components=n_components,random_state = seed)\n\ndists = euclidean_distances(df_big_data, squared=False).ravel()\nnonzero = dists != 0   # select only non-identical samples pairs\ndists = dists[nonzero]\n\nprojected_data = rp_big.fit_transform(df_big_data)\nprojected_dists = euclidean_distances(projected_data, squared=False).ravel()[nonzero]\n\nplt.subplot(121)\nplt.scatter(dists,projected_dists,c='red',alpha=0.2,edgecolor = 'black')\nplt.arrow(0,0,10000,10000,width=0.02,color='black',head_length=0.0,head_width=0.0)\nplt.xlabel(\"Pairwise Distance: original space\")\nplt.ylabel(\"Pairwise Distance: projected space\")\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\nplt.xlim([0,400]); plt.ylim([0,400]); add_grid()\n\nrates = projected_dists / dists\nprint(\"Distance Ratio, mean: %0.2f, standard deviation %0.2f.\" % (np.mean(rates), np.std(rates)))\n\nplt.subplot(122)\nplt.hist(rates, bins=50, range=(0., 2.),color = 'red', alpha = 0.2, edgecolor='k')\nplt.xlabel(\"Distance Ratio: projected / original\"); plt.ylabel(\"Frequency\"); add_grid()\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nDistance Ratio, mean: 0.95, standard deviation 0.02. \n```", "```py\northogonal_check_big = np.dot(rp_big.components_.T, rp_big.components_)\nfig, ax = plt.subplots()\ncax = ax.imshow(orthogonal_check_big,cmap=plt.cm.grey,vmin=-1,vmax=1.5,interpolation='None',zorder=1)\n\nmatrix_size = orthogonal_check.shape[0]                       # assuming the matrix is square (m x m)\nsquare_size = 1                                               # each square has size 1x1\n\ncbar = fig.colorbar(cax); cbar.set_label('Value', rotation=90, labelpad=15) \n\nplt.title(r'Orthogonal Check, $R_p^T R_p$'); plt.xlabel('Columns'); plt.ylabel('Rows')\nplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```", "```py\nm = 1000                                                      # number of dimensions\nn_samples = 1000                                              # number of samples\nn_components = 200                                            # number of components \nseed = 73058                                                  # random seed\n\nnp.random.seed(seed = seed)                                   # set the random seed\nmean_vector = np.zeros(m)                                     # mean vector (zero mean for all variables)\n\nrandom_matrix = np.random.rand(m, m)                          # step 1: generate a random matrix \ncorrelation_matrix = np.dot(random_matrix, random_matrix.T)   # step 2: create a symmetric correlation matrix\ncorrelation_matrix = (correlation_matrix + correlation_matrix.T) / 2 # step 3: symmetrize the correlation matrix (ensures the matrix is symmetric)\nnp.fill_diagonal(correlation_matrix, 1)                       # step 4: normalize to have ones on the diagonal (this ensures unit variances)\n\n# Ensure the covariance matrix is positive semi-definite using eigendecomposition\neigvals, eigvecs = np.linalg.eigh(correlation_matrix)         # eigendecomposition of the correlation matrix\neigvals = np.maximum(eigvals, 1e-6)                           # set any negative eigenvalues to a small positive value\ncov_matrix = eigvecs @ np.diag(eigvals) @ eigvecs.T           # reconstruct the covariance matrix\n\nvery_big_data = np.random.multivariate_normal(mean_vector, cov_matrix, size=n_samples) # step 6: generate the multi-dimensional Gaussian dataset\ndf_very_big_data = pd.DataFrame(very_big_data, columns=[f\"Dim_{i+1}\" for i in range(m)]) # convert the data into a pandas DataFrame\n\nrp_very_big = GaussianRandomProjection(n_components=n_components,random_state = seed)\n\ndists = euclidean_distances(df_very_big_data, squared=False).ravel()\nnonzero = dists != 0                                          # select only non-identical samples pairs\ndists = dists[nonzero]\n\nprojected_data = rp_very_big.fit_transform(df_very_big_data)\nprojected_dists = euclidean_distances(projected_data, squared=False).ravel()[nonzero]\n\nplt.subplot(121)\nplt.scatter(dists,projected_dists,c='red',alpha=0.2,edgecolor = 'black')\nplt.arrow(0,0,10000,10000,width=0.02,color='black',head_length=0.0,head_width=0.0)\nplt.xlabel(\"Pairwise Distance: original space\")\nplt.ylabel(\"Pairwise Distance: projected space\")\nplt.title(\"Pairwise Distance: Projected to %d Components\" % n_components)\nplt.xlim([0,400]); plt.ylim([0,400]); add_grid()\n\northogonal_check_very_big = np.dot(rp_very_big.components_.T, rp_very_big.components_)\n\nplt.subplot(122)\nim = plt.imshow(orthogonal_check_very_big,cmap=plt.cm.grey,vmin=-1,vmax=1.5,interpolation='None',zorder=1)\nmatrix_size = orthogonal_check.shape[0]                       # assuming the matrix is square (m x m)\nsquare_size = 1                                               # each square has size 1x1\ncbar = fig.colorbar(im); cbar.set_label('Value', rotation=90, labelpad=15) \nplt.title(r'Orthogonal Check, $R_p^T R_p$'); plt.xlabel('Columns'); plt.ylabel('Rows')\n\nplt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.2, hspace=0.3); plt.show() \n```"]