- en: 6  Bare-Bones Machine Learning is Insufficient
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6  纯粹的机器学习是不够的
- en: 原文：[https://ml-science-book.com/insufficient.html](https://ml-science-book.com/insufficient.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ml-science-book.com/insufficient.html](https://ml-science-book.com/insufficient.html)
- en: '[Justifying Machine Learning For Science](./part-one.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[为科学证明机器学习的合理性](./part-one.html)'
- en: '[6  Bare-Bones Machine Learning is Insufficient](./insufficient.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6  纯粹的机器学习是不够的](./insufficient.html)'
- en: Even though machine learning has great merits when it comes to prediction, it
    clashes with other scientific goals like control, explanations, and reasoning.
    This chapter highlights more concretely and practically the insufficiencies of
    bare-bones machine learning as a scientific methodology.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器学习在预测方面具有很大的优点，但它与其他科学目标（如控制、解释和推理）相冲突。本章更具体、更实际地强调了纯粹机器学习作为科学方法的不足。
- en: The veteran scientists’ concerns about machine learning were not misplaced.
    Over time, the tornado system began to act up. False positives and false negatives
    became more common. Krarah consulted Rattle, but even she was puzzled. Rattle
    concluded that the problems were not specific to tornado prediction, but systemic
    to machine learning. They had to be fixed.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 老牌科学家对机器学习的担忧并非没有道理。随着时间的推移，龙卷风系统开始出现问题。假阳性和假阴性变得更加常见。Kراه咨询了Rattle，但即使是她也感到困惑。Rattle得出结论，这些问题并非特定于龙卷风预测，而是机器学习系统性的问题。他们必须得到解决。
- en: '![](../Images/86c10560731ea401cc3d41fe917f8942.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86c10560731ea401cc3d41fe917f8942.png)'
- en: 6.1 Low test error is not enough
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 低测试误差不足
- en: 'As we highlighted in [Chapter 4](justification.html), machine learning has
    a transparent notion of what makes a good model: a good model has low error on
    an unseen test set and in consequence a low generalization error. However, this
    notion is empty if it is not equipped with an underlying theory of generalization.
    When can you infer that the model performance generalizes from just knowing the
    error on a test set? Are there guarantees that certain learning algorithms must
    yield models with low expected error?'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第4章](justification.html)中强调的，机器学习有一个明确的关于什么是一个好模型的概念：一个好的模型在未见过的测试集上有低误差，因此具有低泛化误差。然而，如果没有一个潜在的一般化理论，这个概念就是空洞的。你如何仅从知道测试集上的误差来推断模型性能的泛化？是否有保证某些学习算法必须产生具有低期望误差的模型？
- en: In [Chapter 7](generalization.html), we present statistical learning theory
    as the main contender for a theory of generalization in machine learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](generalization.html)中，我们介绍了统计学习理论作为机器学习一般化理论的主要竞争者。
- en: However, the standard notion of generalization only reflects the predictive
    capacities of models on data from the same distribution. Extrapolation to completely
    new scenarios or data from different distributions is not encompassed in the standard
    notion of generalization. It therefore has limited bite, especially in science,
    where the goal is to generalize from models to insights about the phenomenon.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，标准的一般化概念只反映了模型在相同分布的数据上的预测能力。将外推到完全新的场景或不同分布的数据并不包含在标准的一般化概念中。因此，它在科学中具有有限的适用性，因为科学的目标是从模型到对现象的洞察的泛化。
- en: In [Chapter 7](generalization.html), we therefore also discuss broader conceptions
    of generalization. [Chapter 11](robustness.html) on robustness, moreover, shows
    how to define generalization under distribution shifts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](generalization.html)中，我们因此也讨论了更广泛的一般化概念。[第11章](robustness.html)关于鲁棒性，此外，展示了如何在分布变化下定义一般化。
- en: 6.2 Domain knowledge is overlooked
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 领域知识被忽视
- en: 'Science builds on prior knowledge to produce knowledge. Bare-bones machine
    learning disrupts both ends of this knowledge flow: You expect the model to figure
    out relations from the data, and get out an opaque prediction model. The focus
    shifts from epistemology to utility, from science to engineering. You tinker with
    the model to improve a metric. If machine learning is fully embraced in its bare-bones
    form, a lot of domain knowledge is left unused, and there is little new knowledge
    to gain.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 科学建立在先验知识的基础上来产生知识。纯粹的机器学习破坏了这一知识流的两个端点：你期望模型从数据中找出关系，并输出一个不透明的预测模型。焦点从认识论转向了效用，从科学转向了工程。你调整模型以提高一个指标。如果完全接受其纯粹形式的机器学习，那么很多领域知识就被浪费了，而且几乎没有新的知识可以获取。
- en: 'However, coherence with background knowledge makes scientific models more valuable.
    It is smart to incorporate additional information[¹](#fn1). Compare that to statistical
    modeling or differential equations: These modeling approaches encourage, even
    require, the formulation of prior knowledge in terms of distribution assumptions
    and equations. And you get interpretable estimates back that help you better understand
    the phenomenon you study.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与背景知识的协调使科学模型更有价值。纳入额外信息[¹](#fn1)是明智的。将其与统计建模或微分方程比较：这些建模方法鼓励甚至要求用分布假设和方程来表述先验知识。你得到可解释的估计，这有助于你更好地理解你研究的现象。
- en: 'In [Chapter 8](domain.html), we argue that you can take a domain-knowledge-driven
    approach with machine learning as well. Even better: Thanks to the focus on predictive
    performance, you can evaluate your domain knowledge in terms of predictive performance.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](domain.html)中，我们论证了你也可以用机器学习采取领域知识驱动的途径。更好的是：由于对预测性能的关注，你可以用预测性能来评估你的领域知识。
- en: 6.3 Predictions cannot be easily explained and interpreted
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 预测难以解释和解释
- en: 'Interpretability enables you to justify models and reason about phenomena.
    But machine learning models are generally not inherently interpretable, because
    they may have a complex functional form that is adjusted to data – they are black-boxes.
    This makes it difficult to understand how the model behaves and what it relies
    on:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性使你能够证明模型并推理现象。但机器学习模型通常不是固有的可解释的，因为它们可能具有复杂的功能形式，这种形式是根据数据调整的——它们是黑盒。这使得很难理解模型的行为以及它依赖于什么：
- en: What were the most influential features?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最有影响力的特征是什么？
- en: Which features did the model learn?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型学习了哪些特征？
- en: Why did the model make a certain prediction?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么模型做出了这样的预测？
- en: We show in [Chapter 9](interpretability.html) how to use interpretability techniques
    to improve models and gain insights from them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第[第9章](interpretability.html)中展示了如何使用可解释性技术来改进模型并从中获得洞察。
- en: 6.4 Predictive performance is at odds with causality
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 预测性能与因果关系相矛盾
- en: The world we live and act in is a gigantic causal mechanism. Bare-bones machine
    learning models however ignore the causal dimension of things. All they care about
    is making better predictions, and they rely on whatever statistical dependency
    to pursue this goal. Do you want to know your COVID risk? Alright, the machine
    learning model needs your shoe size, salary, and the football ranking of your
    local club.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活和行动的世界是一个巨大的因果关系机制。然而，基础机器学习模型却忽略了事物的因果关系维度。它们所关心的只是做出更好的预测，并且依赖于任何统计依赖性来实现这一目标。你想知道你的COVID风险吗？好吧，机器学习模型需要你的鞋码、薪水和你当地俱乐部的足球排名。
- en: But scientists want to separate between causes, effects, or spuriously correlated
    features. Physicians want to know why certain people have COVID and others don’t.
    They want to develop drugs and prescribe treatments that make people healthy.
    To answer these questions, causality must be taken into account.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但科学家们想要区分原因、效果或偶然相关的特征。医生们想知道为什么有些人患有COVID而其他人没有。他们希望开发药物并开具治疗处方，使人们恢复健康。为了回答这些问题，必须考虑因果关系。
- en: We’ll show in [Chapter 10](causality.html) how the combination of causal inference
    and machine learning allows you to find causal dependencies, learn causal models,
    and estimate causal effects.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第10章](causality.html)中展示因果推理与机器学习的结合如何帮助你找到因果关系，学习因果模型，并估计因果关系。
- en: 6.5 Models lack robustness in deployment
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 模型在部署中缺乏鲁棒性
- en: 'Bare-bones machine learning provides predictive models, but only for a static
    environment. This means machine learning models are only accurate, if:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 基础机器学习提供预测模型，但仅适用于静态环境。这意味着如果：
- en: they are applied to data that is similar to the training data, and
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们被应用于与训练数据相似的数据，并且
- en: the data structure remains intact during deployment.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构在部署过程中保持完整。
- en: In the wild, phenomena are complex. Data changes constantly, external factors
    enter, measurement devices produce errors, time moves, and observation targets
    shift. If you want to use machine learning models in your scientific pipeline,
    you have to make them robust tools under real-world conditions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在野外，现象是复杂的。数据不断变化，外部因素介入，测量设备产生误差，时间流逝，观察目标转移。如果你想在你的科学流程中使用机器学习模型，你必须使它们在现实世界条件下成为鲁棒的工具。
- en: We show in [Chapter 11](robustness.html) what types of robustness you may be
    interested in and discuss strategies such as data augmentation that help you robustify
    your model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第11章（robustness.html）中展示了你可能感兴趣的稳健性类型，并讨论了如数据增强等帮助你使模型稳健化的策略。
- en: 6.6 Predictions come without uncertainty quantification
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.6 预测结果缺乏不确定性量化
- en: Proper uncertainty quantification is crucial when high-stakes decisions are
    made in the real world. However, bare-bones machine learning models only provide
    point predictions. Some models, such as Bayesian models, come with built-in uncertainty
    quantification, but limiting the model class to these models may result in a loss
    in predictive performance. Perhaps the best-performing model is a random forest.
    If you choose the best-performing model, you might get one without built-in uncertainty
    quantification. Even when model outputs look like probabilities because they are
    between zero and one (yes, we’re talking to you, softmaxers), they often cannot
    be interpreted as ‘real’ probabilities when models aren’t well calibrated.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中做出高风险决策时，适当的确定性量化至关重要。然而，简单的机器学习模型只提供点预测。一些模型，如贝叶斯模型，自带不确定性量化，但将模型类别限制在这些模型可能会导致预测性能的损失。也许表现最好的模型是随机森林。如果你选择表现最好的模型，你可能会得到一个没有内置不确定性量化的模型。即使模型输出看起来像概率，因为它们在零和一之间（是的，我们在和你说话，softmaxers），当模型没有良好校准时，它们通常不能被解释为“真实”的概率。
- en: We discuss the philosophy behind uncertainty in machine learning, calibration,
    and model-agnostic methods for uncertainty quantification in [Chapter 12](uncertainty.html).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第12章（uncertainty.html）中讨论了机器学习中不确定性的哲学、校准以及用于不确定性量化的模型无关方法。
- en: 6.7 No consensus on standards for reproducibility
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.7 对于可重现性的标准没有共识
- en: 'There are many standards for how to document code, data, and models for others
    to reproduce results. Reproducibility is key to:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于如何为他人记录代码、数据和模型以便重现结果，存在许多标准。可重现性对于以下方面至关重要：
- en: being transparent about what you did to achieve high performance,
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透明地说明你做了什么以实现高性能，
- en: allowing others to test your work and gain trust in it,
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许他人测试你的工作并对其建立信任，
- en: reliably building on your results, and
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠地建立在你结果的基础上，
- en: making your code reusable for potential applications.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使你的代码可用于潜在的应用。
- en: Unfortunately, many papers that use machine learning in science do not allow
    for reproducibility [[1]](references.html#ref-mcdermott2021reproducibility). Often,
    important information is missing such as on the weight initialization, training
    epochs, hyperparameters, or random seeds. Also, preprocessing steps might not
    be listed, and the code is poorly documented or poorly implemented.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，许多在科学研究中使用机器学习的论文不允许重现性 [[1]](references.html#ref-mcdermott2021reproducibility)。通常，重要的信息缺失，例如权重初始化、训练轮次、超参数或随机种子。此外，预处理步骤可能没有列出，代码的文档或实现可能很差。
- en: We discuss standards for reproducibility of machine learning in science in [Chapter
    13](reproducibility.html).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第13章（reproducibility.html）中讨论了科学中机器学习可重现性的标准。
- en: 6.8 Missing standards for reporting
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.8 报告标准的缺失
- en: In science, it is of central importance to make transparent why a scientific
    model is suitable and what data it explains. In machine learning, researchers
    still need to determine what information is scientifically relevant. Predictive
    performance on the test set is indeed important. But what about the importance
    of features? Or information about the data collection or the model selection?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学领域，清晰地说明为什么一个科学模型是合适的以及它解释了哪些数据，这一点至关重要。在机器学习中，研究人员仍然需要确定哪些信息是科学相关的。测试集上的预测性能确实很重要。但特征的重要性呢？或者关于数据收集或模型选择的信息呢？
- en: We discuss different standards for reporting model results in chapter [Chapter
    14](reporting.html). We provide a high-level view of how to group these standards
    and some best practices for publication.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第14章（reporting.html）中讨论了报告模型结果的不同标准。我们提供了一个如何将这些标准分组的高级视图以及一些出版最佳实践。
- en: '[1]M. B. McDermott, S. Wang, N. Marinsek, R. Ranganath, L. Foschini, and M.
    Ghassemi, “Reproducibility in machine learning for health research: Still a ways
    to go,” *Science Translational Medicine*, vol. 13, no. 586, p. eabb1655, 2021,
    doi: [10.1126/scitranslmed.abb1655](https://doi.org/10.1126/scitranslmed.abb1655).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]M. B. McDermott, S. Wang, N. Marinsek, R. Ranganath, L. Foschini, and M.
    Ghassemi, “Reproducibility in machine learning for health research: Still a ways
    to go,” *Science Translational Medicine*, vol. 13, no. 586, p. eabb1655, 2021,
    doi: [10.1126/scitranslmed.abb1655](https://doi.org/10.1126/scitranslmed.abb1655).'
- en: '* * *'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Usually scientific theories are informed by a lot of historical data; thus,
    in a certain way incorporating background knowledge increases the data support.[↩︎](#fnref1)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常，科学理论都受到大量历史数据的启发；因此，以某种方式融入背景知识可以增加数据支持。[↩︎](#fnref1)
