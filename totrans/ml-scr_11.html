<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Implementation</h1>
<blockquote>原文：<a href="https://dafriedman97.github.io/mlbook/content/c2/code.html">https://dafriedman97.github.io/mlbook/content/c2/code.html</a></blockquote>

<p>This section shows how the linear regression extensions discussed in this chapter are typically fit in Python. First let’s import the <a class="reference internal" href="../appendix/data.html"><span class="doc">Boston housing</span></a> dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="regularized-regression">
<h2>Regularized Regression</h2>
<p>Both Ridge and Lasso regression can be easily fit using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. A bare-bones implementation is provided below. Note that the regularization parameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> (which we called <span class="math notranslate nohighlight">\(\lambda\)</span>) is chosen arbitrarily.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Ridge</span>
<span class="n">ridge_model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">)</span>
<span class="n">ridge_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># Lasso</span>
<span class="n">lasso_model</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">)</span>
<span class="n">lasso_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>In practice, however, we want to choose <code class="docutils literal notranslate"><span class="pre">alpha</span></code> through cross validation. This is easily implemented in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> by designating a set of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> values to try and fitting the model with <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> or <code class="docutils literal notranslate"><span class="pre">LassoCV</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">LassoCV</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

<span class="c1"># Ridge</span>
<span class="n">ridgeCV_model</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">ridgeCV_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Lasso</span>
<span class="n">lassoCV_model</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">lassoCV_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>We can then see which values of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> performed best with the following.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'Ridge alpha:'</span><span class="p">,</span> <span class="n">ridgeCV</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Lasso alpha:'</span><span class="p">,</span> <span class="n">lassoCV</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Ridge alpha: 0.01
Lasso alpha: 1.0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bayesian-regression">
<h2>Bayesian Regression</h2>
<p>We can also fit Bayesian regression using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> (though another popular package is <code class="docutils literal notranslate"><span class="pre">pymc3</span></code>). A very straightforward implementation is provided below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">BayesianRidge</span>
<span class="n">bayes_model</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">()</span>
<span class="n">bayes_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>This is not, however, identical to our construction in the previous section since it infers the <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> parameters, rather than taking those as fixed inputs. More information can be found <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression">here</a>. The hidden chunk below demonstrates a hacky solution for running Bayesian regression in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> using known values for <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span>, though it is hard to imagine a practical reason to do so</p>
<div class="toggle docutils container">
<p>By default, Bayesian regression in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> treats <span class="math notranslate nohighlight">\(\alpha = \frac{1}{\sigma^2}\)</span> and <span class="math notranslate nohighlight">\(\lambda = \frac{1}{\tau}\)</span> as random variables and assigns them the following prior distributions</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\alpha &amp;\sim \text{Gamma}(\alpha_1, \alpha_2) 
\\
\lambda &amp;\sim \text{Gamma}(\lambda_1, \lambda_2).
\end{aligned}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(E(\alpha) = \frac{\alpha_1}{\alpha_2}\)</span> and <span class="math notranslate nohighlight">\(E(\lambda) = \frac{\lambda_1}{\lambda_2}\)</span>. To <em>fix</em> <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span>, we can provide an extremely strong prior on <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span>, guaranteeing that their estimates will be approximately equal to their expected value.</p>
<p>Suppose we want to use <span class="math notranslate nohighlight">\(\sigma^2 = 11.8\)</span> and <span class="math notranslate nohighlight">\(\tau = 10\)</span>, or equivalently <span class="math notranslate nohighlight">\(\alpha = \frac{1}{11.8}\)</span>, <span class="math notranslate nohighlight">\(\lambda = \frac{1}{10}\)</span>. Then let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\alpha_1 &amp;= 10000 \cdot \frac{1}{11.8}, \\
\alpha_2 &amp;= 10000, \\
\lambda_1 &amp;= 10000 \cdot \frac{1}{10}, \\
\lambda_2 &amp;= 10000.
\end{aligned}
\end{split}\]</div>
<p>This guarantees that <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> will be approximately equal to their pre-determined values. This can be implemented in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> as follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span/><span class="n">big_number</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">5</span>

<span class="c1"># alpha</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">11.8</span>
<span class="n">alpha_1</span> <span class="o">=</span> <span class="n">big_number</span><span class="o">*</span><span class="n">alpha</span>
<span class="n">alpha_2</span> <span class="o">=</span> <span class="n">big_number</span>

<span class="c1"># lambda </span>
<span class="n">lam</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span>
<span class="n">lambda_1</span> <span class="o">=</span> <span class="n">big_number</span><span class="o">*</span><span class="n">lam</span>
<span class="n">lambda_2</span> <span class="o">=</span> <span class="n">big_number</span>

<span class="c1"># fit </span>
<span class="n">bayes_model</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">(</span><span class="n">alpha_1</span> <span class="o">=</span> <span class="n">alpha_1</span><span class="p">,</span> <span class="n">alpha_2</span> <span class="o">=</span> <span class="n">alpha_2</span><span class="p">,</span> <span class="n">alpha_init</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">,</span>
                     <span class="n">lambda_1</span> <span class="o">=</span> <span class="n">lambda_1</span><span class="p">,</span> <span class="n">lambda_2</span> <span class="o">=</span> <span class="n">lambda_2</span><span class="p">,</span> <span class="n">lambda_init</span> <span class="o">=</span> <span class="n">lam</span><span class="p">)</span>
<span class="n">bayes_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="poisson-regression">
<h2>Poisson Regression</h2>
<p>GLMs are most commonly fit in Python through the <code class="docutils literal notranslate"><span class="pre">GLM</span></code> class from <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. A simple Poisson regression example is given below.</p>
<p>As we saw in the GLM concept section, a GLM is comprised of a random distribution and a link function. We identify the random distribution through the <code class="docutils literal notranslate"><span class="pre">family</span></code> argument to <code class="docutils literal notranslate"><span class="pre">GLM</span></code> (e.g. below, we specify the <code class="docutils literal notranslate"><span class="pre">Poisson</span></code> family). The default link function depends on the random distribution. By default, the Poisson model uses the link function</p>
<div class="math notranslate nohighlight">
\[
\eta_n = g(\mu_n) = \log(\lambda_n),
\]</div>
<p>which is what we use below. For more information on the possible distributions and link functions, check out the <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> GLM <a class="reference external" href="https://www.statsmodels.org/stable/glm.html">docs</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="n">X_train_with_constant</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">poisson_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Poisson</span><span class="p">())</span>
<span class="n">poisson_model</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
</div>
&#13;

<h2>Regularized Regression</h2>
<p>Both Ridge and Lasso regression can be easily fit using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. A bare-bones implementation is provided below. Note that the regularization parameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> (which we called <span class="math notranslate nohighlight">\(\lambda\)</span>) is chosen arbitrarily.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Ridge</span>
<span class="n">ridge_model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">)</span>
<span class="n">ridge_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># Lasso</span>
<span class="n">lasso_model</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">)</span>
<span class="n">lasso_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>In practice, however, we want to choose <code class="docutils literal notranslate"><span class="pre">alpha</span></code> through cross validation. This is easily implemented in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> by designating a set of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> values to try and fitting the model with <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> or <code class="docutils literal notranslate"><span class="pre">LassoCV</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">LassoCV</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

<span class="c1"># Ridge</span>
<span class="n">ridgeCV_model</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">ridgeCV_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Lasso</span>
<span class="n">lassoCV_model</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">lassoCV_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>We can then see which values of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> performed best with the following.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="s1">'Ridge alpha:'</span><span class="p">,</span> <span class="n">ridgeCV</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Lasso alpha:'</span><span class="p">,</span> <span class="n">lassoCV</span><span class="o">.</span><span class="n">alpha_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Ridge alpha: 0.01
Lasso alpha: 1.0
</pre></div>
</div>
</div>
</div>
&#13;

<h2>Bayesian Regression</h2>
<p>We can also fit Bayesian regression using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> (though another popular package is <code class="docutils literal notranslate"><span class="pre">pymc3</span></code>). A very straightforward implementation is provided below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">BayesianRidge</span>
<span class="n">bayes_model</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">()</span>
<span class="n">bayes_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>This is not, however, identical to our construction in the previous section since it infers the <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> parameters, rather than taking those as fixed inputs. More information can be found <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression">here</a>. The hidden chunk below demonstrates a hacky solution for running Bayesian regression in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> using known values for <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span>, though it is hard to imagine a practical reason to do so</p>
<div class="toggle docutils container">
<p>By default, Bayesian regression in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> treats <span class="math notranslate nohighlight">\(\alpha = \frac{1}{\sigma^2}\)</span> and <span class="math notranslate nohighlight">\(\lambda = \frac{1}{\tau}\)</span> as random variables and assigns them the following prior distributions</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\alpha &amp;\sim \text{Gamma}(\alpha_1, \alpha_2) 
\\
\lambda &amp;\sim \text{Gamma}(\lambda_1, \lambda_2).
\end{aligned}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(E(\alpha) = \frac{\alpha_1}{\alpha_2}\)</span> and <span class="math notranslate nohighlight">\(E(\lambda) = \frac{\lambda_1}{\lambda_2}\)</span>. To <em>fix</em> <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span>, we can provide an extremely strong prior on <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span>, guaranteeing that their estimates will be approximately equal to their expected value.</p>
<p>Suppose we want to use <span class="math notranslate nohighlight">\(\sigma^2 = 11.8\)</span> and <span class="math notranslate nohighlight">\(\tau = 10\)</span>, or equivalently <span class="math notranslate nohighlight">\(\alpha = \frac{1}{11.8}\)</span>, <span class="math notranslate nohighlight">\(\lambda = \frac{1}{10}\)</span>. Then let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\alpha_1 &amp;= 10000 \cdot \frac{1}{11.8}, \\
\alpha_2 &amp;= 10000, \\
\lambda_1 &amp;= 10000 \cdot \frac{1}{10}, \\
\lambda_2 &amp;= 10000.
\end{aligned}
\end{split}\]</div>
<p>This guarantees that <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\tau\)</span> will be approximately equal to their pre-determined values. This can be implemented in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> as follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span/><span class="n">big_number</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">5</span>

<span class="c1"># alpha</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">11.8</span>
<span class="n">alpha_1</span> <span class="o">=</span> <span class="n">big_number</span><span class="o">*</span><span class="n">alpha</span>
<span class="n">alpha_2</span> <span class="o">=</span> <span class="n">big_number</span>

<span class="c1"># lambda </span>
<span class="n">lam</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span>
<span class="n">lambda_1</span> <span class="o">=</span> <span class="n">big_number</span><span class="o">*</span><span class="n">lam</span>
<span class="n">lambda_2</span> <span class="o">=</span> <span class="n">big_number</span>

<span class="c1"># fit </span>
<span class="n">bayes_model</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">(</span><span class="n">alpha_1</span> <span class="o">=</span> <span class="n">alpha_1</span><span class="p">,</span> <span class="n">alpha_2</span> <span class="o">=</span> <span class="n">alpha_2</span><span class="p">,</span> <span class="n">alpha_init</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">,</span>
                     <span class="n">lambda_1</span> <span class="o">=</span> <span class="n">lambda_1</span><span class="p">,</span> <span class="n">lambda_2</span> <span class="o">=</span> <span class="n">lambda_2</span><span class="p">,</span> <span class="n">lambda_init</span> <span class="o">=</span> <span class="n">lam</span><span class="p">)</span>
<span class="n">bayes_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
&#13;

<h2>Poisson Regression</h2>
<p>GLMs are most commonly fit in Python through the <code class="docutils literal notranslate"><span class="pre">GLM</span></code> class from <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. A simple Poisson regression example is given below.</p>
<p>As we saw in the GLM concept section, a GLM is comprised of a random distribution and a link function. We identify the random distribution through the <code class="docutils literal notranslate"><span class="pre">family</span></code> argument to <code class="docutils literal notranslate"><span class="pre">GLM</span></code> (e.g. below, we specify the <code class="docutils literal notranslate"><span class="pre">Poisson</span></code> family). The default link function depends on the random distribution. By default, the Poisson model uses the link function</p>
<div class="math notranslate nohighlight">
\[
\eta_n = g(\mu_n) = \log(\lambda_n),
\]</div>
<p>which is what we use below. For more information on the possible distributions and link functions, check out the <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> GLM <a class="reference external" href="https://www.statsmodels.org/stable/glm.html">docs</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="n">X_train_with_constant</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">poisson_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Poisson</span><span class="p">())</span>
<span class="n">poisson_model</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
    
</body>
</html>